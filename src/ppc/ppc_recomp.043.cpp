#include "ppc_recomp_shared.h"

PPC_FUNC_IMPL(__imp__sub_8257CAD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r27,-32246
	r27.s64 = -2113273856;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r30,0
	r30.s64 = 0;
	// lis r10,-32242
	ctx.r10.s64 = -2113011712;
	// addi r26,r27,-27456
	r26.s64 = r27.s64 + -27456;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// addi r9,r11,592
	ctx.r9.s64 = r11.s64 + 592;
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// addi r8,r10,7548
	ctx.r8.s64 = ctx.r10.s64 + 7548;
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// li r28,1
	r28.s64 = 1;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// addi r29,r31,96
	r29.s64 = r31.s64 + 96;
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// lfs f31,-12(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + -12);
	f31.f64 = double(temp.f32);
	// stw r30,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r30.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r30,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r30.u32);
	// addi r11,r31,44
	r11.s64 = r31.s64 + 44;
	// stw r8,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r8.u32);
	// stfs f31,44(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 44, temp.u32);
	// stw r30,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r30.u32);
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// stw r30,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r30.u32);
	// stw r30,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r30.u32);
	// stw r30,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r30.u32);
	// stw r30,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r30.u32);
	// stw r30,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r30.u32);
	// stw r30,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r30.u32);
	// stb r30,84(r31)
	PPC_STORE_U8(r31.u32 + 84, r30.u8);
	// stb r28,85(r31)
	PPC_STORE_U8(r31.u32 + 85, r28.u8);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r7,-32242
	ctx.r7.s64 = -2113011712;
	// addi r3,r29,32
	ctx.r3.s64 = r29.s64 + 32;
	// addi r6,r7,8980
	ctx.r6.s64 = ctx.r7.s64 + 8980;
	// stw r6,96(r31)
	PPC_STORE_U32(r31.u32 + 96, ctx.r6.u32);
	// bl 0x82402308
	sub_82402308(ctx, base);
	// lis r5,-32253
	ctx.r5.s64 = -2113732608;
	// stb r28,296(r31)
	PPC_STORE_U8(r31.u32 + 296, r28.u8);
	// stb r30,297(r31)
	PPC_STORE_U8(r31.u32 + 297, r30.u8);
	// lfs f13,24524(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r26.u32 + 24524);
	ctx.f13.f64 = double(temp.f32);
	// stb r30,308(r31)
	PPC_STORE_U8(r31.u32 + 308, r30.u8);
	// lfs f12,-27456(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -27456);
	ctx.f12.f64 = double(temp.f32);
	// stb r30,309(r31)
	PPC_STORE_U8(r31.u32 + 309, r30.u8);
	// addi r3,r31,336
	ctx.r3.s64 = r31.s64 + 336;
	// addi r11,r29,160
	r11.s64 = r29.s64 + 160;
	// lfs f0,-30440(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -30440);
	f0.f64 = double(temp.f32);
	// stfs f0,264(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 264, temp.u32);
	// stfs f0,268(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 268, temp.u32);
	// stfs f13,272(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 272, temp.u32);
	// stfs f13,276(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 276, temp.u32);
	// stfs f12,256(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 256, temp.u32);
	// stfs f31,260(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 260, temp.u32);
	// stfs f31,280(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 280, temp.u32);
	// stfs f31,284(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 284, temp.u32);
	// stfs f31,288(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 288, temp.u32);
	// stfs f31,292(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 292, temp.u32);
	// stfs f12,300(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 300, temp.u32);
	// stfs f31,304(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 304, temp.u32);
	// stb r28,320(r31)
	PPC_STORE_U8(r31.u32 + 320, r28.u8);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r4,-32242
	ctx.r4.s64 = -2113011712;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r11,r4,9640
	r11.s64 = ctx.r4.s64 + 9640;
	// stw r3,364(r31)
	PPC_STORE_U32(r31.u32 + 364, ctx.r3.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r11,336(r31)
	PPC_STORE_U32(r31.u32 + 336, r11.u32);
	// addi r11,r31,380
	r11.s64 = r31.s64 + 380;
	// stb r30,368(r31)
	PPC_STORE_U8(r31.u32 + 368, r30.u8);
	// stw r30,372(r31)
	PPC_STORE_U32(r31.u32 + 372, r30.u32);
	// stw r30,376(r31)
	PPC_STORE_U32(r31.u32 + 376, r30.u32);
	// stw r30,380(r31)
	PPC_STORE_U32(r31.u32 + 380, r30.u32);
	// stw r30,384(r31)
	PPC_STORE_U32(r31.u32 + 384, r30.u32);
	// stw r30,388(r31)
	PPC_STORE_U32(r31.u32 + 388, r30.u32);
	// stw r30,392(r31)
	PPC_STORE_U32(r31.u32 + 392, r30.u32);
	// stw r30,396(r31)
	PPC_STORE_U32(r31.u32 + 396, r30.u32);
	// stw r30,400(r31)
	PPC_STORE_U32(r31.u32 + 400, r30.u32);
	// stw r30,404(r31)
	PPC_STORE_U32(r31.u32 + 404, r30.u32);
	// stw r30,408(r31)
	PPC_STORE_U32(r31.u32 + 408, r30.u32);
	// stb r30,412(r31)
	PPC_STORE_U8(r31.u32 + 412, r30.u8);
	// addi r11,r31,396
	r11.s64 = r31.s64 + 396;
	// stw r10,416(r31)
	PPC_STORE_U32(r31.u32 + 416, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r30,420(r31)
	PPC_STORE_U32(r31.u32 + 420, r30.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_8257CAD0) {
	__imp__sub_8257CAD0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257CC48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x8257ccf8
	sub_8257CCF8(ctx, base);
	// clrlwi r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257cc80
	if (cr6.eq) goto loc_8257CC80;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8257CC80:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8257CC48) {
	__imp__sub_8257CC48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257CC98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r31,r30,24
	r31.s64 = r30.s64 + 24;
	// lwz r3,28(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(28) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257ccbc
	if (cr6.eq) goto loc_8257CCBC;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_8257CCBC:
	// addi r29,r30,8
	r29.s64 = r30.s64 + 8;
	// li r30,0
	r30.s64 = 0;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// lwz r3,4(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + int32_t(4) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257cce0
	if (cr6.eq) goto loc_8257CCE0;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_8257CCE0:
	// stw r30,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r30.u32);
	// stw r30,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r30.u32);
	// stw r30,12(r29)
	PPC_STORE_U32(r29.u32 + 12, r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8257CC98) {
	__imp__sub_8257CC98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257CCF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r28,r31,396
	r28.s64 = r31.s64 + 396;
	// lwz r3,396(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(396) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257cd20
	if (cr6.eq) goto loc_8257CD20;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8257CD20:
	// li r30,0
	r30.s64 = 0;
	// addi r29,r31,380
	r29.s64 = r31.s64 + 380;
	// stw r30,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r30.u32);
	// lwz r3,380(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(380) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257cd40
	if (cr6.eq) goto loc_8257CD40;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8257CD40:
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// stw r30,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r30.u32);
	// addi r11,r31,336
	r11.s64 = r31.s64 + 336;
	// addi r29,r10,-4548
	r29.s64 = ctx.r10.s64 + -4548;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// stw r29,336(r31)
	PPC_STORE_U32(r31.u32 + 336, r29.u32);
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,348(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(348) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,348(r31)
	PPC_STORE_U32(r31.u32 + 348, r30.u32);
	// stw r29,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r29.u32);
	// addi r11,r31,96
	r11.s64 = r31.s64 + 96;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,108(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(108) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,108(r31)
	PPC_STORE_U32(r31.u32 + 108, r30.u32);
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// bl 0x8257cc98
	sub_8257CC98(ctx, base);
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// addi r8,r9,12052
	ctx.r8.s64 = ctx.r9.s64 + 12052;
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// stw r8,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r8.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// lis r7,-32246
	ctx.r7.s64 = -2113273856;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r6,r7,23084
	ctx.r6.s64 = ctx.r7.s64 + 23084;
	// stw r6,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r6.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8257CCF8) {
	__imp__sub_8257CCF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257CDC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// mr r27,r30
	r27.u64 = r30.u64;
	// lwz r11,372(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(372) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8257cdec
	if (!cr6.eq) goto loc_8257CDEC;
	// li r27,1
	r27.s64 = 1;
	// stw r27,372(r31)
	PPC_STORE_U32(r31.u32 + 372, r27.u32);
loc_8257CDEC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r9,r31,96
	ctx.r9.s64 = r31.s64 + 96;
	// stw r30,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r30.u32);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// stw r30,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r30.u32);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// stw r30,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r30.u32);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r8,r31,336
	ctx.r8.s64 = r31.s64 + 336;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// lis r29,-31927
	r29.s64 = -2092367872;
	// lis r6,-31926
	ctx.r6.s64 = -2092302336;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r6,-30476
	ctx.r5.s64 = ctx.r6.s64 + -30476;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r28,152(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + int32_t(152) );
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// bl 0x828ce060
	sub_828CE060(ctx, base);
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// addi r7,r10,28344
	ctx.r7.s64 = ctx.r10.s64 + 28344;
loc_8257CE6C:
	// mfmsr r8
	// mtmsrd r13,1
	// lwarx r9,0,r7
	reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r9.u64 = __builtin_bswap32(reserved.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwcx. r9,0,r7
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), reserved.s32, __builtin_bswap32(ctx.r9.s32));
	cr0.so = xer.so;
	// mtmsrd r8,1
	// bne 0x8257ce6c
	if (!cr0.eq) goto loc_8257CE6C;
	// lwz r11,372(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(372) );
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8257cf08
	if (cr6.eq) goto loc_8257CF08;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x8257ceb0
	if (cr6.eq) goto loc_8257CEB0;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-216
	ctx.r4.s64 = r11.s64 + -216;
	// bl 0x82275368
	sub_82275368(ctx, base);
	// b 0x8257cf60
	goto loc_8257CF60;
loc_8257CEB0:
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// li r4,5
	ctx.r4.s64 = 5;
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b218
	sub_8240B218(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,-248
	ctx.r4.s64 = r11.s64 + -248;
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82b398a8
	sub_82B398A8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// b 0x8257cf5c
	goto loc_8257CF5C;
loc_8257CF08:
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b218
	sub_8240B218(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,-276
	ctx.r4.s64 = r11.s64 + -276;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82b398a8
	sub_82B398A8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
loc_8257CF5C:
	// bl 0x821c6868
	sub_821C6868(ctx, base);
loc_8257CF60:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,23044
	ctx.r4.s64 = r11.s64 + 23044;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// lwz r3,40(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// bl 0x8259d6c8
	sub_8259D6C8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r10,-30488
	ctx.r4.s64 = ctx.r10.s64 + -30488;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82837218
	sub_82837218(ctx, base);
	// clrlwi r9,r27,24
	ctx.r9.u64 = r27.u32 & 0xFF;
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8257cfc4
	if (cr6.eq) goto loc_8257CFC4;
	// li r4,8
	ctx.r4.s64 = 8;
	// bl 0x828c9b78
	sub_828C9B78(ctx, base);
	// b 0x8257cfd4
	goto loc_8257CFD4;
loc_8257CFC4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(24) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_8257CFD4:
	// lwz r11,372(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(372) );
	// li r10,-1
	ctx.r10.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r10,416(r31)
	PPC_STORE_U32(r31.u32 + 416, ctx.r10.u32);
	// stw r11,376(r31)
	PPC_STORE_U32(r31.u32 + 376, r11.u32);
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257cffc
	if (cr6.eq) goto loc_8257CFFC;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_8257CFFC:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8257CDC0) {
	__imp__sub_8257CDC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257D008) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82583490
	sub_82583490(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// li r29,0
	r29.s64 = 0;
	// stb r11,85(r31)
	PPC_STORE_U8(r31.u32 + 85, r11.u8);
	// addi r3,r31,128
	ctx.r3.s64 = r31.s64 + 128;
	// stw r29,420(r31)
	PPC_STORE_U32(r31.u32 + 420, r29.u32);
	// bl 0x82834da0
	sub_82834DA0(ctx, base);
	// lbz r10,84(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 84);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257d07c
	if (cr6.eq) goto loc_8257D07C;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// addi r3,r31,68
	ctx.r3.s64 = r31.s64 + 68;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r30,152(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x82581388
	sub_82581388(ctx, base);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// ble cr6,0x8257d070
	if (!cr6.gt) goto loc_8257D070;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// bl 0x828cea28
	sub_828CEA28(ctx, base);
loc_8257D070:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// bl 0x828ce468
	sub_828CE468(ctx, base);
loc_8257D07C:
	// stw r29,376(r31)
	PPC_STORE_U32(r31.u32 + 376, r29.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8257D008) {
	__imp__sub_8257D008(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257D088) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82583560
	sub_82583560(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r30,0
	r30.s64 = 0;
	// addi r8,r11,28344
	ctx.r8.s64 = r11.s64 + 28344;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r30.u32);
loc_8257D0B8:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r7
	reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r7
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8257d0b8
	if (!cr0.eq) goto loc_8257D0B8;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
loc_8257D0D8:
	// mfmsr r5
	// mtmsrd r13,1
	// lwarx r6,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r6.u64 = __builtin_bswap32(reserved.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// stwcx. r6,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r6.s32));
	cr0.so = xer.so;
	// mtmsrd r5,1
	// bne 0x8257d0d8
	if (!cr0.eq) goto loc_8257D0D8;
	// lis r28,-31927
	r28.s64 = -2092367872;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(60) );
	// bl 0x8259db00
	sub_8259DB00(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8257d1f0
	sub_8257D1F0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r11,416(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(416) );
	// lwz r29,4(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + int32_t(4) );
	// cmpw cr6,r29,r11
	cr6.compare<int32_t>(r29.s32, r11.s32, xer);
	// beq cr6,0x8257d178
	if (cr6.eq) goto loc_8257D178;
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// addi r5,r31,396
	ctx.r5.s64 = r31.s64 + 396;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
	// lwz r10,396(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(396) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8257d15c
	if (!cr6.eq) goto loc_8257D15C;
	// stb r30,85(r31)
	PPC_STORE_U8(r31.u32 + 85, r30.u8);
	// b 0x8257d164
	goto loc_8257D164;
loc_8257D15C:
	// li r11,1
	r11.s64 = 1;
	// stb r11,85(r31)
	PPC_STORE_U8(r31.u32 + 85, r11.u8);
loc_8257D164:
	// addi r3,r31,96
	ctx.r3.s64 = r31.s64 + 96;
	// bl 0x828cf168
	sub_828CF168(ctx, base);
	// addi r3,r31,336
	ctx.r3.s64 = r31.s64 + 336;
	// bl 0x828d0aa0
	sub_828D0AA0(ctx, base);
	// stw r29,416(r31)
	PPC_STORE_U32(r31.u32 + 416, r29.u32);
loc_8257D178:
	// addi r3,r27,12
	ctx.r3.s64 = r27.s64 + 12;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r27,8
	ctx.r3.s64 = r27.s64 + 8;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// addi r10,r11,-301
	ctx.r10.s64 = r11.s64 + -301;
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// xori r7,r8,1
	ctx.r7.u64 = ctx.r8.u64 ^ 1;
	// clrlwi r6,r7,24
	ctx.r6.u64 = ctx.r7.u32 & 0xFF;
	// stb r7,368(r31)
	PPC_STORE_U8(r31.u32 + 368, ctx.r7.u8);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x8257d1b4
	if (!cr6.eq) goto loc_8257D1B4;
	// addi r3,r31,128
	ctx.r3.s64 = r31.s64 + 128;
	// bl 0x82834da0
	sub_82834DA0(ctx, base);
loc_8257D1B4:
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// addi r30,r31,44
	r30.s64 = r31.s64 + 44;
	// lbz r5,368(r31)
	ctx.r5.u64 = PPC_LOAD_U8(r31.u32 + 368);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(152) );
	// bl 0x828ce4e8
	sub_828CE4E8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x828ce180
	sub_828CE180(ctx, base);
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8257D088) {
	__imp__sub_8257D088(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257D1F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r4,r30,8
	ctx.r4.s64 = r30.s64 + 8;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// addi r4,r30,12
	ctx.r4.s64 = r30.s64 + 12;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8257D1F0) {
	__imp__sub_8257D1F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257D250) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r27,-31927
	r27.s64 = -2092367872;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r4,26788(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmpwi cr6,r11,140
	cr6.compare<int32_t>(r11.s32, 140, xer);
	// lwz r10,28(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(28) );
	// lwz r24,52(r4)
	r24.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(52) );
	// lwz r28,60(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(60) );
	// bgt cr6,0x8257dc70
	if (cr6.gt) goto loc_8257DC70;
	// beq cr6,0x8257dc4c
	if (cr6.eq) goto loc_8257DC4C;
	// addi r11,r11,-3
	r11.s64 = r11.s64 + -3;
	// cmplwi cr6,r11,82
	cr6.compare<uint32_t>(r11.u32, 82, xer);
	// bgt cr6,0x8257df90
	if (cr6.gt) goto loc_8257DF90;
	// lis r12,-32168
	r12.s64 = -2108162048;
	// addi r12,r12,-11604
	r12.s64 = r12.s64 + -11604;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_8257D3F8;
	case 1:
		goto loc_8257DF90;
	case 2:
		goto loc_8257DF90;
	case 3:
		goto loc_8257DF90;
	case 4:
		goto loc_8257DF90;
	case 5:
		goto loc_8257DF90;
	case 6:
		goto loc_8257DF90;
	case 7:
		goto loc_8257DF90;
	case 8:
		goto loc_8257DF90;
	case 9:
		goto loc_8257DF90;
	case 10:
		goto loc_8257DF90;
	case 11:
		goto loc_8257DF90;
	case 12:
		goto loc_8257DF90;
	case 13:
		goto loc_8257DF90;
	case 14:
		goto loc_8257DF90;
	case 15:
		goto loc_8257DF90;
	case 16:
		goto loc_8257DF90;
	case 17:
		goto loc_8257DF90;
	case 18:
		goto loc_8257DF90;
	case 19:
		goto loc_8257DF90;
	case 20:
		goto loc_8257DF90;
	case 21:
		goto loc_8257DF90;
	case 22:
		goto loc_8257DF90;
	case 23:
		goto loc_8257DF90;
	case 24:
		goto loc_8257DF90;
	case 25:
		goto loc_8257DF90;
	case 26:
		goto loc_8257DF90;
	case 27:
		goto loc_8257DF90;
	case 28:
		goto loc_8257DF90;
	case 29:
		goto loc_8257DF90;
	case 30:
		goto loc_8257DF90;
	case 31:
		goto loc_8257DF90;
	case 32:
		goto loc_8257DF90;
	case 33:
		goto loc_8257DF90;
	case 34:
		goto loc_8257DF90;
	case 35:
		goto loc_8257DF90;
	case 36:
		goto loc_8257DF90;
	case 37:
		goto loc_8257DF90;
	case 38:
		goto loc_8257DF90;
	case 39:
		goto loc_8257DF90;
	case 40:
		goto loc_8257DF90;
	case 41:
		goto loc_8257DF90;
	case 42:
		goto loc_8257DF90;
	case 43:
		goto loc_8257DF90;
	case 44:
		goto loc_8257DF90;
	case 45:
		goto loc_8257DF90;
	case 46:
		goto loc_8257DF90;
	case 47:
		goto loc_8257DF90;
	case 48:
		goto loc_8257DF90;
	case 49:
		goto loc_8257DF90;
	case 50:
		goto loc_8257DF90;
	case 51:
		goto loc_8257DF90;
	case 52:
		goto loc_8257DF90;
	case 53:
		goto loc_8257DF90;
	case 54:
		goto loc_8257DF90;
	case 55:
		goto loc_8257DF90;
	case 56:
		goto loc_8257DF90;
	case 57:
		goto loc_8257DF90;
	case 58:
		goto loc_8257DF90;
	case 59:
		goto loc_8257DF90;
	case 60:
		goto loc_8257DF90;
	case 61:
		goto loc_8257DF90;
	case 62:
		goto loc_8257DF90;
	case 63:
		goto loc_8257DF90;
	case 64:
		goto loc_8257DF90;
	case 65:
		goto loc_8257DF90;
	case 66:
		goto loc_8257DF90;
	case 67:
		goto loc_8257DF90;
	case 68:
		goto loc_8257DF90;
	case 69:
		goto loc_8257DF90;
	case 70:
		goto loc_8257DF90;
	case 71:
		goto loc_8257DF90;
	case 72:
		goto loc_8257DF90;
	case 73:
		goto loc_8257DF90;
	case 74:
		goto loc_8257DF90;
	case 75:
		goto loc_8257DF90;
	case 76:
		goto loc_8257DF90;
	case 77:
		goto loc_8257D828;
	case 78:
		goto loc_8257D828;
	case 79:
		goto loc_8257DF90;
	case 80:
		goto loc_8257D8E8;
	case 81:
		goto loc_8257DF90;
	case 82:
		goto loc_8257D980;
	default:
		__builtin_unreachable();
	}
	// lwz r18,-11272(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-11272) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-10200(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-10200) );
	// lwz r18,-10200(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-10200) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-10008(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-10008) );
	// lwz r18,-8304(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8304) );
	// lwz r18,-9856(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-9856) );
loc_8257D3F8:
	// lwz r3,396(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + int32_t(396) );
	// addi r26,r29,396
	r26.s64 = r29.s64 + 396;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257df90
	if (cr6.eq) goto loc_8257DF90;
	// bl 0x827417e0
	sub_827417E0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257df90
	if (cr6.eq) goto loc_8257DF90;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(0) );
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257d43c
	if (cr6.eq) goto loc_8257D43C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// stw r10,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r10.u32);
	// stw r9,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r9.u32);
	// b 0x8257d444
	goto loc_8257D444;
loc_8257D43C:
	// stw r28,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r28.u32);
	// stw r28,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r28.u32);
loc_8257D444:
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// addi r25,r11,-28544
	r25.s64 = r11.s64 + -28544;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x822a97a8
	sub_822A97A8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257df90
	if (cr6.eq) goto loc_8257DF90;
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r28.u32);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r5,r1,124
	ctx.r5.s64 = ctx.r1.s64 + 124;
	// addi r4,r11,-29244
	ctx.r4.s64 = r11.s64 + -29244;
	// bl 0x823a5128
	sub_823A5128(ctx, base);
	// lwz r3,26788(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// mr r31,r28
	r31.u64 = r28.u64;
	// bl 0x821c7d38
	sub_821C7D38(ctx, base);
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// lwz r10,52(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(52) );
	// rlwinm r9,r10,23,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8257d588
	if (cr6.eq) goto loc_8257D588;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257d4c4
	if (cr6.eq) goto loc_8257D4C4;
	// lbz r10,137(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 137);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8257d58c
	goto loc_8257D58C;
loc_8257D4C4:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r28,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8257d530
	if (!cr0.gt) goto loc_8257D530;
loc_8257D4E0:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,137
	cr6.compare<int32_t>(ctx.r7.s32, 137, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8257d500
	if (cr6.lt) goto loc_8257D500;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_8257D500:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8257d51c
	if (cr6.eq) goto loc_8257D51C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8257d524
	goto loc_8257D524;
loc_8257D51C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8257D524:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8257d4e0
	if (cr6.gt) goto loc_8257D4E0;
	// stw r10,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r10.u32);
loc_8257D530:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8257d574
	if (cr6.eq) goto loc_8257D574;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,137
	cr6.compare<int32_t>(r11.s32, 137, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8257d54c
	if (cr6.gt) goto loc_8257D54C;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8257D54C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257d574
	if (!cr6.eq) goto loc_8257D574;
	// ld r11,128(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(132) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8257d58c
	goto loc_8257D58C;
loc_8257D574:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8257d58c
	goto loc_8257D58C;
loc_8257D588:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8257D58C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// lwz r30,124(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(124) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257d5fc
	if (cr6.eq) goto loc_8257D5FC;
	// lbz r11,73(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 73);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257d5fc
	if (cr6.eq) goto loc_8257D5FC;
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// bne cr6,0x8257d5fc
	if (!cr6.eq) goto loc_8257D5FC;
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,-196
	ctx.r4.s64 = ctx.r10.s64 + -196;
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,156
	ctx.r3.s64 = ctx.r1.s64 + 156;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r6,38
	ctx.r6.s64 = 38;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c28
	return;
loc_8257D5FC:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r4,188
	ctx.r4.s64 = 188;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r7,168(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(168) );
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x824fda50
	sub_824FDA50(ctx, base);
	// clrlwi r9,r3,24
	ctx.r9.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8257d62c
	if (cr6.eq) goto loc_8257D62C;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x824fdaf8
	sub_824FDAF8(ctx, base);
loc_8257D62C:
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x825a5a40
	sub_825A5A40(ctx, base);
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// bne cr6,0x8257d658
	if (!cr6.eq) goto loc_8257D658;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(24) );
	// addi r3,r29,24
	ctx.r3.s64 = r29.s64 + 24;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_8257D658:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(0) );
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r28.u32);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(16) );
	// cmpwi cr6,r10,16
	cr6.compare<int32_t>(ctx.r10.s32, 16, xer);
	// bne cr6,0x8257df90
	if (!cr6.eq) goto loc_8257DF90;
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x822a97a8
	sub_822A97A8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257df90
	if (cr6.eq) goto loc_8257DF90;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r30,r11,-15532
	r30.s64 = r11.s64 + -15532;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x822a97a8
	sub_822A97A8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257df90
	if (cr6.eq) goto loc_8257DF90;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r31,r11,-15516
	r31.s64 = r11.s64 + -15516;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x822a97a8
	sub_822A97A8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257df90
	if (cr6.eq) goto loc_8257DF90;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r5,r1,124
	ctx.r5.s64 = ctx.r1.s64 + 124;
	// addi r4,r11,-15496
	ctx.r4.s64 = r11.s64 + -15496;
	// bl 0x823d4fc8
	sub_823D4FC8(ctx, base);
	// lwz r11,124(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(124) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8257df90
	if (cr6.eq) goto loc_8257DF90;
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// beq cr6,0x8257df90
	if (cr6.eq) goto loc_8257DF90;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,-156
	ctx.r4.s64 = r11.s64 + -156;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// addi r4,r10,11628
	ctx.r4.s64 = ctx.r10.s64 + 11628;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(0) );
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(16) );
	// cmpwi cr6,r9,16
	cr6.compare<int32_t>(ctx.r9.s32, 16, xer);
	// bne cr6,0x8257d784
	if (!cr6.eq) goto loc_8257D784;
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x822a97a8
	sub_822A97A8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257d784
	if (cr6.eq) goto loc_8257D784;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x822a97a8
	sub_822A97A8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257d784
	if (cr6.eq) goto loc_8257D784;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x822a97a8
	sub_822A97A8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257d784
	if (cr6.eq) goto loc_8257D784;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r4,r11,-8608
	ctx.r4.s64 = r11.s64 + -8608;
	// bl 0x82345978
	sub_82345978(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// li r5,-1
	ctx.r5.s64 = -1;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// b 0x8257d798
	goto loc_8257D798;
loc_8257D784:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,3224
	ctx.r4.s64 = r11.s64 + 3224;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
loc_8257D798:
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x82b38b78
	sub_82B38B78(ctx, base);
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// li r3,48
	ctx.r3.s64 = 48;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r31,52(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257d818
	if (cr6.eq) goto loc_8257D818;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r4,r11,-30492
	ctx.r4.s64 = r11.s64 + -30492;
	// li r6,-1
	ctx.r6.s64 = -1;
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// bl 0x823bd140
	sub_823BD140(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257d818
	if (cr6.eq) goto loc_8257D818;
	// stw r3,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r3.u32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x8240d440
	sub_8240D440(ctx, base);
loc_8257D818:
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c28
	return;
loc_8257D828:
	// addi r3,r29,128
	ctx.r3.s64 = r29.s64 + 128;
	// bl 0x82834da0
	sub_82834DA0(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,-24940
	ctx.r4.s64 = r11.s64 + -24940;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r31,r29,380
	r31.s64 = r29.s64 + 380;
	// addi r3,r28,4
	ctx.r3.s64 = r28.s64 + 4;
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(8) );
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
	// li r9,15
	ctx.r9.s64 = 15;
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// stw r9,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r9.u32);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// addi r3,r11,68
	ctx.r3.s64 = r11.s64 + 68;
	// bl 0x8247d010
	sub_8247D010(ctx, base);
	// lwz r30,0(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// addi r3,r30,228
	ctx.r3.s64 = r30.s64 + 228;
	// cmplw cr6,r3,r31
	cr6.compare<uint32_t>(ctx.r3.u32, r31.u32, xer);
	// beq cr6,0x8257d8a8
	if (cr6.eq) goto loc_8257D8A8;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8218df70
	sub_8218DF70(ctx, base);
loc_8257D8A8:
	// li r10,5
	ctx.r10.s64 = 5;
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r10,220(r30)
	PPC_STORE_U32(r30.u32 + 220, ctx.r10.u32);
	// li r4,15
	ctx.r4.s64 = 15;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336838
	sub_82336838(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// li r4,15
	ctx.r4.s64 = 15;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336598
	sub_82336598(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336d70
	sub_82336D70(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c28
	return;
loc_8257D8E8:
	// li r11,1
	r11.s64 = 1;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// stw r11,420(r29)
	PPC_STORE_U32(r29.u32 + 420, r11.u32);
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,-24940
	ctx.r4.s64 = ctx.r10.s64 + -24940;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r3,r29,44
	ctx.r3.s64 = r29.s64 + 44;
	// lwz r8,56(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(152) );
	// bl 0x828ce468
	sub_828CE468(ctx, base);
	// addi r5,r29,380
	ctx.r5.s64 = r29.s64 + 380;
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(8) );
	// addi r3,r28,4
	ctx.r3.s64 = r28.s64 + 4;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
	// addi r3,r29,24
	ctx.r3.s64 = r29.s64 + 24;
	// bl 0x828c9d10
	sub_828C9D10(ctx, base);
	// lis r7,-32244
	ctx.r7.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r7,-124
	ctx.r4.s64 = ctx.r7.s64 + -124;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b090
	sub_8240B090(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c28
	return;
loc_8257D980:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r28,0
	r28.s64 = 0;
	// addi r30,r11,28340
	r30.s64 = r11.s64 + 28340;
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r28.u32);
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
loc_8257D994:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8257d994
	if (!cr0.eq) goto loc_8257D994;
	// lwz r4,380(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + int32_t(380) );
	// addi r31,r29,380
	r31.s64 = r29.s64 + 380;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8257d9e8
	if (cr6.eq) goto loc_8257D9E8;
	// addi r3,r1,164
	ctx.r3.s64 = ctx.r1.s64 + 164;
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,140
	ctx.r3.s64 = ctx.r1.s64 + 140;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,140
	ctx.r3.s64 = ctx.r1.s64 + 140;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
loc_8257D9E8:
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// stw r28,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r28.u32);
loc_8257D9F0:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x8257d9f0
	if (!cr0.eq) goto loc_8257D9F0;
	// lwz r4,396(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + int32_t(396) );
	// addi r30,r29,396
	r30.s64 = r29.s64 + 396;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8257da44
	if (cr6.eq) goto loc_8257DA44;
	// addi r3,r1,168
	ctx.r3.s64 = ctx.r1.s64 + 168;
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
loc_8257DA44:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x825a6220
	sub_825A6220(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257dbb4
	if (cr6.eq) goto loc_8257DBB4;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// stw r28,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r28.u32);
	// addi r8,r11,28344
	ctx.r8.s64 = r11.s64 + 28344;
loc_8257DA6C:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8257da6c
	if (!cr0.eq) goto loc_8257DA6C;
	// lis r7,-31926
	ctx.r7.s64 = -2092302336;
	// lwz r11,-30472(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(-30472) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257daa4
	if (!cr6.eq) goto loc_8257DAA4;
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r5,r11,63
	ctx.r5.s64 = r11.s64 + 63;
	// b 0x8257daa8
	goto loc_8257DAA8;
loc_8257DAA4:
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_8257DAA8:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// addi r4,r11,-96
	ctx.r4.s64 = r11.s64 + -96;
	// bl 0x821e3a10
	sub_821E3A10(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// addi r3,r29,24
	ctx.r3.s64 = r29.s64 + 24;
	// bl 0x828c9b78
	sub_828C9B78(ctx, base);
	// stw r28,420(r29)
	PPC_STORE_U32(r29.u32 + 420, r28.u32);
	// stw r28,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r28.u32);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// stw r28,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r28.u32);
	// li r5,-1
	ctx.r5.s64 = -1;
	// stw r28,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r28.u32);
	// addi r4,r9,-44
	ctx.r4.s64 = ctx.r9.s64 + -44;
	// stw r28,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r28.u32);
	// addi r3,r1,172
	ctx.r3.s64 = ctx.r1.s64 + 172;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r8,-32246
	ctx.r8.s64 = -2113273856;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// addi r4,r8,11628
	ctx.r4.s64 = ctx.r8.s64 + 11628;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// addi r5,r1,124
	ctx.r5.s64 = ctx.r1.s64 + 124;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b38b78
	sub_82B38B78(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r7,-32246
	ctx.r7.s64 = -2113273856;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// addi r4,r7,14020
	ctx.r4.s64 = ctx.r7.s64 + 14020;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b38b78
	sub_82B38B78(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82287710
	sub_82287710(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r6,38
	ctx.r6.s64 = 38;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c28
	return;
loc_8257DBB4:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,-16
	ctx.r4.s64 = r11.s64 + -16;
	// addi r3,r1,180
	ctx.r3.s64 = ctx.r1.s64 + 180;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// addi r4,r10,11628
	ctx.r4.s64 = ctx.r10.s64 + 11628;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x82b38b78
	sub_82B38B78(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// addi r3,r1,184
	ctx.r3.s64 = ctx.r1.s64 + 184;
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82287710
	sub_82287710(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r6,38
	ctx.r6.s64 = 38;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c28
	return;
loc_8257DC4C:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-30948
	ctx.r5.s64 = r11.s64 + -30948;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c28
	return;
loc_8257DC70:
	// cmpwi cr6,r11,141
	cr6.compare<int32_t>(r11.s32, 141, xer);
	// beq cr6,0x8257df74
	if (cr6.eq) goto loc_8257DF74;
	// cmpwi cr6,r11,310
	cr6.compare<int32_t>(r11.s32, 310, xer);
	// beq cr6,0x8257dedc
	if (cr6.eq) goto loc_8257DEDC;
	// cmpwi cr6,r11,311
	cr6.compare<int32_t>(r11.s32, 311, xer);
	// bne cr6,0x8257df90
	if (!cr6.eq) goto loc_8257DF90;
	// li r28,0
	r28.s64 = 0;
	// lis r9,-31927
	ctx.r9.s64 = -2092367872;
	// stw r28,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r28.u32);
	// addi r8,r9,28340
	ctx.r8.s64 = ctx.r9.s64 + 28340;
loc_8257DC98:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwcx. r11,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x8257dc98
	if (!cr0.eq) goto loc_8257DC98;
	// lwz r4,396(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + int32_t(396) );
	// addi r30,r29,396
	r30.s64 = r29.s64 + 396;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8257dcec
	if (cr6.eq) goto loc_8257DCEC;
	// addi r3,r1,188
	ctx.r3.s64 = ctx.r1.s64 + 188;
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,148
	ctx.r3.s64 = ctx.r1.s64 + 148;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,148
	ctx.r3.s64 = ctx.r1.s64 + 148;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
loc_8257DCEC:
	// addi r31,r29,380
	r31.s64 = r29.s64 + 380;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x825a67c8
	sub_825A67C8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257de4c
	if (cr6.eq) goto loc_8257DE4C;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// stw r28,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r28.u32);
	// addi r8,r11,28344
	ctx.r8.s64 = r11.s64 + 28344;
loc_8257DD18:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8257dd18
	if (!cr0.eq) goto loc_8257DD18;
	// lis r7,-31926
	ctx.r7.s64 = -2092302336;
	// lwz r11,-30472(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(-30472) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257dd50
	if (!cr6.eq) goto loc_8257DD50;
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r5,r11,63
	ctx.r5.s64 = r11.s64 + 63;
	// b 0x8257dd54
	goto loc_8257DD54;
loc_8257DD50:
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_8257DD54:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// addi r4,r11,-96
	ctx.r4.s64 = r11.s64 + -96;
	// bl 0x821e3a10
	sub_821E3A10(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// addi r3,r29,24
	ctx.r3.s64 = r29.s64 + 24;
	// bl 0x828c9b78
	sub_828C9B78(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b0e8
	sub_8240B0E8(ctx, base);
	// stw r28,420(r29)
	PPC_STORE_U32(r29.u32 + 420, r28.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r28,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r28.u32);
	// addi r3,r29,96
	ctx.r3.s64 = r29.s64 + 96;
	// stw r28,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r28.u32);
	// stw r28,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r28.u32);
	// stw r28,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r28.u32);
	// stb r9,85(r29)
	PPC_STORE_U8(r29.u32 + 85, ctx.r9.u8);
	// bl 0x828cf168
	sub_828CF168(ctx, base);
	// lis r8,-32244
	ctx.r8.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r8,52
	ctx.r4.s64 = ctx.r8.s64 + 52;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r7,-32246
	ctx.r7.s64 = -2113273856;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// addi r4,r7,11628
	ctx.r4.s64 = ctx.r7.s64 + 11628;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82b38b78
	sub_82B38B78(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// addi r3,r1,196
	ctx.r3.s64 = ctx.r1.s64 + 196;
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82287710
	sub_82287710(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r6,38
	ctx.r6.s64 = 38;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c28
	return;
loc_8257DE4C:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,88
	ctx.r4.s64 = r11.s64 + 88;
	// addi r3,r1,200
	ctx.r3.s64 = ctx.r1.s64 + 200;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// addi r4,r10,11628
	ctx.r4.s64 = ctx.r10.s64 + 11628;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82b38b78
	sub_82B38B78(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// addi r3,r1,204
	ctx.r3.s64 = ctx.r1.s64 + 204;
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82287710
	sub_82287710(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r6,38
	ctx.r6.s64 = 38;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c28
	return;
loc_8257DEDC:
	// li r11,2
	r11.s64 = 2;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// stw r11,420(r29)
	PPC_STORE_U32(r29.u32 + 420, r11.u32);
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,-24940
	ctx.r4.s64 = ctx.r10.s64 + -24940;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r3,r29,44
	ctx.r3.s64 = r29.s64 + 44;
	// lwz r8,56(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(152) );
	// bl 0x828ce468
	sub_828CE468(ctx, base);
	// addi r5,r29,380
	ctx.r5.s64 = r29.s64 + 380;
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(8) );
	// addi r3,r28,4
	ctx.r3.s64 = r28.s64 + 4;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
	// addi r3,r29,24
	ctx.r3.s64 = r29.s64 + 24;
	// bl 0x828ca1c8
	sub_828CA1C8(ctx, base);
	// lis r7,-32244
	ctx.r7.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r7,16
	ctx.r4.s64 = ctx.r7.s64 + 16;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b090
	sub_8240B090(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c28
	return;
loc_8257DF74:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-30944
	ctx.r5.s64 = r11.s64 + -30944;
	// addi r3,r1,216
	ctx.r3.s64 = ctx.r1.s64 + 216;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,216
	ctx.r3.s64 = ctx.r1.s64 + 216;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_8257DF90:
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_8257D250) {
	__imp__sub_8257D250(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257DF98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r23{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r4,-26
	r11.s64 = ctx.r4.s64 + -26;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,47
	cr6.compare<uint32_t>(r11.u32, 47, xer);
	// bgt cr6,0x8257e2e4
	if (cr6.gt) goto loc_8257E2E4;
	// lis r12,-32168
	r12.s64 = -2108162048;
	// addi r12,r12,-8244
	r12.s64 = r12.s64 + -8244;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_8257E258;
	case 1:
		goto loc_8257E258;
	case 2:
		goto loc_8257E2E4;
	case 3:
		goto loc_8257E2E4;
	case 4:
		goto loc_8257E2E4;
	case 5:
		goto loc_8257E2E4;
	case 6:
		goto loc_8257E2E4;
	case 7:
		goto loc_8257E2E4;
	case 8:
		goto loc_8257E2E4;
	case 9:
		goto loc_8257E2E4;
	case 10:
		goto loc_8257E0D4;
	case 11:
		goto loc_8257E0E4;
	case 12:
		goto loc_8257E2E4;
	case 13:
		goto loc_8257E2E4;
	case 14:
		goto loc_8257E2E4;
	case 15:
		goto loc_8257E2E4;
	case 16:
		goto loc_8257E2E4;
	case 17:
		goto loc_8257E2E4;
	case 18:
		goto loc_8257E2E4;
	case 19:
		goto loc_8257E2E4;
	case 20:
		goto loc_8257E2E4;
	case 21:
		goto loc_8257E2E4;
	case 22:
		goto loc_8257E2E4;
	case 23:
		goto loc_8257E2E4;
	case 24:
		goto loc_8257E2E4;
	case 25:
		goto loc_8257E2E4;
	case 26:
		goto loc_8257E2E4;
	case 27:
		goto loc_8257E2E4;
	case 28:
		goto loc_8257E2E4;
	case 29:
		goto loc_8257E2E4;
	case 30:
		goto loc_8257E2E4;
	case 31:
		goto loc_8257E2E4;
	case 32:
		goto loc_8257E2E4;
	case 33:
		goto loc_8257E284;
	case 34:
		goto loc_8257E2E4;
	case 35:
		goto loc_8257E2E4;
	case 36:
		goto loc_8257E2E4;
	case 37:
		goto loc_8257E2E4;
	case 38:
		goto loc_8257E2E4;
	case 39:
		goto loc_8257E2E4;
	case 40:
		goto loc_8257E2E4;
	case 41:
		goto loc_8257E2E4;
	case 42:
		goto loc_8257E2E4;
	case 43:
		goto loc_8257E2E4;
	case 44:
		goto loc_8257E2E4;
	case 45:
		goto loc_8257E2E4;
	case 46:
		goto loc_8257E0B0;
	case 47:
		goto loc_8257E08C;
	default:
		__builtin_unreachable();
	}
	// lwz r18,-7592(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7592) );
	// lwz r18,-7592(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7592) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7980(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7980) );
	// lwz r18,-7964(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7964) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7548(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7548) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-7452(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-7452) );
	// lwz r18,-8016(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8016) );
	// lwz r18,-8052(r23)
	r18.u64 = PPC_LOAD_U32(r23.u32 + int32_t(-8052) );
loc_8257E08C:
	// lwz r11,420(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(420) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8257e2e4
	if (!cr6.eq) goto loc_8257E2E4;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b748
	sub_8240B748(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_8257E0B0:
	// lwz r11,420(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(420) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8257e2e4
	if (!cr6.eq) goto loc_8257E2E4;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b650
	sub_8240B650(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_8257E0D4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82583140
	sub_82583140(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_8257E0E4:
	// lwz r11,420(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(420) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8257e214
	if (cr6.eq) goto loc_8257E214;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r30,0
	r30.s64 = 0;
	// addi r8,r11,28344
	ctx.r8.s64 = r11.s64 + 28344;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r30.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r30.u32);
loc_8257E10C:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r7
	reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r7
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8257e10c
	if (!cr0.eq) goto loc_8257E10C;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
loc_8257E12C:
	// mfmsr r5
	// mtmsrd r13,1
	// lwarx r6,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r6.u64 = __builtin_bswap32(reserved.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// stwcx. r6,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r6.s32));
	cr0.so = xer.so;
	// mtmsrd r5,1
	// bne 0x8257e12c
	if (!cr0.eq) goto loc_8257E12C;
	// lis r29,-31927
	r29.s64 = -2092367872;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(60) );
	// bl 0x8259db00
	sub_8259DB00(ctx, base);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmpwi cr6,r11,301
	cr6.compare<int32_t>(r11.s32, 301, xer);
	// beq cr6,0x8257e18c
	if (cr6.eq) goto loc_8257E18C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82583340
	sub_82583340(ctx, base);
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_8257E18C:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(24) );
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,120
	ctx.r4.s64 = ctx.r9.s64 + 120;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r8,56(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// stw r30,420(r31)
	PPC_STORE_U32(r31.u32 + 420, r30.u32);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b0e8
	sub_8240B0E8(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// stw r30,380(r31)
	PPC_STORE_U32(r31.u32 + 380, r30.u32);
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// stw r30,384(r31)
	PPC_STORE_U32(r31.u32 + 384, r30.u32);
	// addi r11,r31,380
	r11.s64 = r31.s64 + 380;
	// stw r30,388(r31)
	PPC_STORE_U32(r31.u32 + 388, r30.u32);
	// stw r30,392(r31)
	PPC_STORE_U32(r31.u32 + 392, r30.u32);
	// stb r7,85(r31)
	PPC_STORE_U8(r31.u32 + 85, ctx.r7.u8);
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_8257E214:
	// lis r30,-31927
	r30.s64 = -2092367872;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259dd48
	sub_8259DD48(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257e248
	if (cr6.eq) goto loc_8257E248;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b000
	sub_8240B000(ctx, base);
	// addi r3,r31,128
	ctx.r3.s64 = r31.s64 + 128;
	// bl 0x82834da0
	sub_82834DA0(ctx, base);
loc_8257E248:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82583340
	sub_82583340(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_8257E258:
	// lbz r11,84(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 84);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257e2e4
	if (cr6.eq) goto loc_8257E2E4;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r6,152(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x828ce240
	sub_828CE240(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_8257E284:
	// lbz r10,320(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 320);
	// addi r11,r31,96
	r11.s64 = r31.s64 + 96;
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// stb r8,320(r31)
	PPC_STORE_U8(r31.u32 + 320, ctx.r8.u8);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x8257e2cc
	if (cr6.eq) goto loc_8257E2CC;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,0
	ctx.r9.s64 = 0;
	// stb r10,200(r11)
	PPC_STORE_U8(r11.u32 + 200, ctx.r10.u8);
	// lis r8,-32246
	ctx.r8.s64 = -2113273856;
	// stb r9,201(r11)
	PPC_STORE_U8(r11.u32 + 201, ctx.r9.u8);
	// addi r11,r11,160
	r11.s64 = r11.s64 + 160;
	// addi r3,r11,52
	ctx.r3.s64 = r11.s64 + 52;
	// lfs f1,-27468(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -27468);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82834498
	sub_82834498(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_8257E2CC:
	// li r30,0
	r30.s64 = 0;
	// addi r10,r11,160
	ctx.r10.s64 = r11.s64 + 160;
	// stb r30,200(r11)
	PPC_STORE_U8(r11.u32 + 200, r30.u8);
	// stb r30,201(r11)
	PPC_STORE_U8(r11.u32 + 201, r30.u8);
	// stb r30,212(r11)
	PPC_STORE_U8(r11.u32 + 212, r30.u8);
	// stb r30,213(r11)
	PPC_STORE_U8(r11.u32 + 213, r30.u8);
loc_8257E2E4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8257DF98) {
	__imp__sub_8257DF98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257E2F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bnelr cr6
	if (!cr6.eq) return;
	// cmpwi cr6,r4,36
	cr6.compare<int32_t>(ctx.r4.s32, 36, xer);
	// bnelr cr6
	if (!cr6.eq) return;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x823380c0
	sub_823380C0(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_8257E2F0) {
	__imp__sub_8257E2F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257E318) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8257E318) {
	__imp__sub_8257E318(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257E320) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// lis r26,-32246
	r26.s64 = -2113273856;
	// li r30,0
	r30.s64 = 0;
	// lis r10,-32242
	ctx.r10.s64 = -2113011712;
	// addi r9,r11,636
	ctx.r9.s64 = r11.s64 + 636;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// addi r25,r26,-27456
	r25.s64 = r26.s64 + -27456;
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// addi r8,r10,7560
	ctx.r8.s64 = ctx.r10.s64 + 7560;
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// li r27,-1
	r27.s64 = -1;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// li r29,1
	r29.s64 = 1;
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// addi r28,r31,92
	r28.s64 = r31.s64 + 92;
	// stw r30,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r30.u32);
	// lfs f31,-12(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + -12);
	f31.f64 = double(temp.f32);
	// stw r30,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r30.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r8,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r8.u32);
	// addi r11,r31,48
	r11.s64 = r31.s64 + 48;
	// stw r27,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r27.u32);
	// stfs f31,48(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 48, temp.u32);
	// stw r30,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r30.u32);
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// stw r30,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r30.u32);
	// stw r30,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r30.u32);
	// stw r30,68(r31)
	PPC_STORE_U32(r31.u32 + 68, r30.u32);
	// stw r30,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r30.u32);
	// stw r30,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r30.u32);
	// stw r30,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r30.u32);
	// stb r30,88(r31)
	PPC_STORE_U8(r31.u32 + 88, r30.u8);
	// stb r29,89(r31)
	PPC_STORE_U8(r31.u32 + 89, r29.u8);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r7,-32242
	ctx.r7.s64 = -2113011712;
	// lis r6,-32253
	ctx.r6.s64 = -2113732608;
	// lfs f13,24524(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r25.u32 + 24524);
	ctx.f13.f64 = double(temp.f32);
	// addi r5,r7,9016
	ctx.r5.s64 = ctx.r7.s64 + 9016;
	// lfs f12,-27456(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + -27456);
	ctx.f12.f64 = double(temp.f32);
	// addi r3,r31,188
	ctx.r3.s64 = r31.s64 + 188;
	// stw r5,92(r31)
	PPC_STORE_U32(r31.u32 + 92, ctx.r5.u32);
	// addi r11,r28,28
	r11.s64 = r28.s64 + 28;
	// stb r29,160(r31)
	PPC_STORE_U8(r31.u32 + 160, r29.u8);
	// stb r30,161(r31)
	PPC_STORE_U8(r31.u32 + 161, r30.u8);
	// lfs f0,-30440(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -30440);
	f0.f64 = double(temp.f32);
	// stb r30,172(r31)
	PPC_STORE_U8(r31.u32 + 172, r30.u8);
	// stb r30,173(r31)
	PPC_STORE_U8(r31.u32 + 173, r30.u8);
	// stfs f0,128(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 128, temp.u32);
	// stfs f0,132(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 132, temp.u32);
	// stfs f13,136(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 136, temp.u32);
	// stfs f13,140(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 140, temp.u32);
	// stfs f12,120(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 120, temp.u32);
	// stfs f31,124(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 124, temp.u32);
	// stfs f31,144(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 144, temp.u32);
	// stfs f31,148(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 148, temp.u32);
	// stfs f31,152(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 152, temp.u32);
	// stfs f31,156(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 156, temp.u32);
	// stfs f12,164(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 164, temp.u32);
	// stfs f31,168(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 168, temp.u32);
	// stb r29,184(r31)
	PPC_STORE_U8(r31.u32 + 184, r29.u8);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r4,-32242
	ctx.r4.s64 = -2113011712;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r11,r4,9640
	r11.s64 = ctx.r4.s64 + 9640;
	// li r10,4
	ctx.r10.s64 = 4;
	// stw r3,216(r31)
	PPC_STORE_U32(r31.u32 + 216, ctx.r3.u32);
	// stw r11,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r11.u32);
	// lis r9,-32242
	ctx.r9.s64 = -2113011712;
	// stw r10,220(r31)
	PPC_STORE_U32(r31.u32 + 220, ctx.r10.u32);
	// stw r30,228(r31)
	PPC_STORE_U32(r31.u32 + 228, r30.u32);
	// addi r8,r9,-11412
	ctx.r8.s64 = ctx.r9.s64 + -11412;
	// stw r30,232(r31)
	PPC_STORE_U32(r31.u32 + 232, r30.u32);
	// stw r30,236(r31)
	PPC_STORE_U32(r31.u32 + 236, r30.u32);
	// stw r30,240(r31)
	PPC_STORE_U32(r31.u32 + 240, r30.u32);
	// stw r30,244(r31)
	PPC_STORE_U32(r31.u32 + 244, r30.u32);
	// stw r30,248(r31)
	PPC_STORE_U32(r31.u32 + 248, r30.u32);
	// stw r30,252(r31)
	PPC_STORE_U32(r31.u32 + 252, r30.u32);
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// stb r30,261(r31)
	PPC_STORE_U8(r31.u32 + 261, r30.u8);
	// stw r8,264(r31)
	PPC_STORE_U32(r31.u32 + 264, ctx.r8.u32);
	// addi r11,r31,228
	r11.s64 = r31.s64 + 228;
	// stb r30,268(r31)
	PPC_STORE_U8(r31.u32 + 268, r30.u8);
	// addi r11,r31,244
	r11.s64 = r31.s64 + 244;
	// stb r30,269(r31)
	PPC_STORE_U8(r31.u32 + 269, r30.u8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stb r29,288(r31)
	PPC_STORE_U8(r31.u32 + 288, r29.u8);
	// stw r27,292(r31)
	PPC_STORE_U32(r31.u32 + 292, r27.u32);
	// stb r30,296(r31)
	PPC_STORE_U8(r31.u32 + 296, r30.u8);
	// stb r30,297(r31)
	PPC_STORE_U8(r31.u32 + 297, r30.u8);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_8257E320) {
	__imp__sub_8257E320(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257E4A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x8257e4f8
	sub_8257E4F8(ctx, base);
	// clrlwi r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257e4e0
	if (cr6.eq) goto loc_8257E4E0;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8257E4E0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8257E4A8) {
	__imp__sub_8257E4A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257E4F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r28,r31,244
	r28.s64 = r31.s64 + 244;
	// lwz r3,244(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(244) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257e520
	if (cr6.eq) goto loc_8257E520;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8257E520:
	// li r30,0
	r30.s64 = 0;
	// addi r29,r31,228
	r29.s64 = r31.s64 + 228;
	// stw r30,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r30.u32);
	// lwz r3,228(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(228) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257e540
	if (cr6.eq) goto loc_8257E540;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8257E540:
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// stw r30,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r30.u32);
	// addi r11,r31,188
	r11.s64 = r31.s64 + 188;
	// addi r29,r10,-4548
	r29.s64 = ctx.r10.s64 + -4548;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// stw r29,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r29.u32);
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,200(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(200) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,200(r31)
	PPC_STORE_U32(r31.u32 + 200, r30.u32);
	// stw r29,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r29.u32);
	// addi r11,r31,92
	r11.s64 = r31.s64 + 92;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,104(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(104) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r30.u32);
	// addi r3,r31,48
	ctx.r3.s64 = r31.s64 + 48;
	// bl 0x8257cc98
	sub_8257CC98(ctx, base);
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// addi r8,r9,12052
	ctx.r8.s64 = ctx.r9.s64 + 12052;
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// stw r8,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r8.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// lis r7,-32246
	ctx.r7.s64 = -2113273856;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r6,r7,23084
	ctx.r6.s64 = ctx.r7.s64 + 23084;
	// stw r6,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r6.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8257E4F8) {
	__imp__sub_8257E4F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257E5C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-31927
	r30.s64 = -2092367872;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lwz r8,56(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// lwz r29,152(r8)
	r29.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(152) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// li r28,0
	r28.s64 = 0;
	// addi r7,r31,92
	ctx.r7.s64 = r31.s64 + 92;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// stw r28,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r28.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r28,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r28.u32);
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r6,r31,188
	ctx.r6.s64 = r31.s64 + 188;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// lis r5,-31926
	ctx.r5.s64 = -2092302336;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r5,-30476
	ctx.r5.s64 = ctx.r5.s64 + -30476;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r31,48
	ctx.r3.s64 = r31.s64 + 48;
	// bl 0x828ce060
	sub_828CE060(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lis r4,-31926
	ctx.r4.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r4,-30484
	ctx.r4.s64 = ctx.r4.s64 + -30484;
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r27,152(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + int32_t(152) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r8,88(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(88) );
	// lwz r7,4(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(4) );
	// lwz r3,0(r7)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(0) );
	// bl 0x8222c210
	sub_8222C210(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r6,56(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// lwz r27,152(r6)
	r27.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(152) );
	// bl 0x823fd238
	sub_823FD238(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257e6b8
	if (cr6.eq) goto loc_8257E6B8;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(16) );
	// stw r27,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r27.u32);
	// b 0x8257e6bc
	goto loc_8257E6BC;
loc_8257E6B8:
	// li r11,-1
	r11.s64 = -1;
loc_8257E6BC:
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,23044
	ctx.r4.s64 = r11.s64 + 23044;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,144
	ctx.r4.s64 = ctx.r10.s64 + 144;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// lwz r27,40(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82b398a8
	sub_82B398A8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// bl 0x8259d6c8
	sub_8259D6C8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,176
	ctx.r4.s64 = ctx.r9.s64 + 176;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r8,-32244
	ctx.r8.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r8,244
	ctx.r4.s64 = ctx.r8.s64 + 244;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x823f87c0
	sub_823F87C0(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823f87c0
	sub_823F87C0(ctx, base);
	// lis r7,-31926
	ctx.r7.s64 = -2092302336;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r7,-30488
	ctx.r4.s64 = ctx.r7.s64 + -30488;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82837218
	sub_82837218(ctx, base);
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + int32_t(24) );
	// addi r29,r31,24
	r29.s64 = r31.s64 + 24;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r5,4(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(4) );
	// mtctr r5
	ctr.u64 = ctx.r5.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r4,220(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(220) );
	// cmpwi cr6,r4,5
	cr6.compare<int32_t>(ctx.r4.s32, 5, xer);
	// bne cr6,0x8257e7f0
	if (!cr6.eq) goto loc_8257E7F0;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8257ca28
	sub_8257CA28(ctx, base);
	// addi r4,r31,228
	ctx.r4.s64 = r31.s64 + 228;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82835508
	sub_82835508(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b090
	sub_8240B090(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x828cb288
	sub_828CB288(ctx, base);
	// stb r28,89(r31)
	PPC_STORE_U8(r31.u32 + 89, r28.u8);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8257e830
	sub_8257E830(ctx, base);
	// b 0x8257e800
	goto loc_8257E800;
loc_8257E7F0:
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// li r4,6
	ctx.r4.s64 = 6;
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b218
	sub_8240B218(ctx, base);
loc_8257E800:
	// li r11,-1
	r11.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r11,292(r31)
	PPC_STORE_U32(r31.u32 + 292, r11.u32);
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257e828
	if (cr6.eq) goto loc_8257E828;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_8257E828:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8257E5C0) {
	__imp__sub_8257E5C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257E830) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r31,48
	ctx.r3.s64 = r31.s64 + 48;
	// bl 0x82356430
	sub_82356430(ctx, base);
	// addi r3,r31,32
	ctx.r3.s64 = r31.s64 + 32;
	// bl 0x82356430
	sub_82356430(ctx, base);
	// addi r3,r31,16
	ctx.r3.s64 = r31.s64 + 16;
	// bl 0x82356430
	sub_82356430(ctx, base);
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8257E830) {
	__imp__sub_8257E830(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257E890) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82583490
	sub_82583490(ctx, base);
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// bl 0x828cbb40
	sub_828CBB40(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// stb r11,89(r31)
	PPC_STORE_U8(r31.u32 + 89, r11.u8);
	// addi r4,r31,44
	ctx.r4.s64 = r31.s64 + 44;
	// lwz r11,26788(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26788) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fda78
	sub_823FDA78(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8257E890) {
	__imp__sub_8257E890(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257E8E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r11,292(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(292) );
	// lwz r30,4(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + int32_t(4) );
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// beq cr6,0x8257ea00
	if (cr6.eq) goto loc_8257EA00;
	// lis r29,-31927
	r29.s64 = -2092367872;
	// lwz r11,220(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(220) );
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r10,60(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(60) );
	// bne cr6,0x8257e968
	if (!cr6.eq) goto loc_8257E968;
	// addis r11,r30,-2
	r11.s64 = r30.s64 + -131072;
	// addic. r11,r11,30986
	xer.ca = r11.u32 > 4294936309;
	r11.s64 = r11.s64 + 30986;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8257e958
	if (cr0.eq) goto loc_8257E958;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x8257e948
	if (cr6.eq) goto loc_8257E948;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x8257e968
	if (!cr6.eq) goto loc_8257E968;
	// li r4,11
	ctx.r4.s64 = 11;
	// bl 0x82580ff0
	sub_82580FF0(ctx, base);
	// b 0x8257e978
	goto loc_8257E978;
loc_8257E948:
	// li r4,10
	ctx.r4.s64 = 10;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82580ff0
	sub_82580FF0(ctx, base);
	// b 0x8257e978
	goto loc_8257E978;
loc_8257E958:
	// li r4,9
	ctx.r4.s64 = 9;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82580ff0
	sub_82580FF0(ctx, base);
	// b 0x8257e978
	goto loc_8257E978;
loc_8257E968:
	// addi r5,r31,244
	ctx.r5.s64 = r31.s64 + 244;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r10,4
	ctx.r3.s64 = ctx.r10.s64 + 4;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
loc_8257E978:
	// lwz r11,244(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(244) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257e9cc
	if (!cr6.eq) goto loc_8257E9CC;
	// addi r3,r31,72
	ctx.r3.s64 = r31.s64 + 72;
	// bl 0x82581388
	sub_82581388(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x8257e9ac
	if (!cr6.gt) goto loc_8257E9AC;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// addi r3,r31,48
	ctx.r3.s64 = r31.s64 + 48;
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(152) );
	// bl 0x828cea28
	sub_828CEA28(ctx, base);
loc_8257E9AC:
	// lwz r11,220(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(220) );
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r10,89(r31)
	PPC_STORE_U8(r31.u32 + 89, ctx.r10.u8);
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// bne cr6,0x8257e9ec
	if (!cr6.eq) goto loc_8257E9EC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8257edf0
	sub_8257EDF0(ctx, base);
	// b 0x8257e9ec
	goto loc_8257E9EC;
loc_8257E9CC:
	// lwz r11,220(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(220) );
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// bne cr6,0x8257e9e4
	if (!cr6.eq) goto loc_8257E9E4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8257ec78
	sub_8257EC78(ctx, base);
	// b 0x8257e9ec
	goto loc_8257E9EC;
loc_8257E9E4:
	// li r11,1
	r11.s64 = 1;
	// stb r11,89(r31)
	PPC_STORE_U8(r31.u32 + 89, r11.u8);
loc_8257E9EC:
	// addi r3,r31,92
	ctx.r3.s64 = r31.s64 + 92;
	// bl 0x828d0220
	sub_828D0220(ctx, base);
	// addi r3,r31,188
	ctx.r3.s64 = r31.s64 + 188;
	// bl 0x828d1208
	sub_828D1208(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(r31.u32 + 292, r30.u32);
loc_8257EA00:
	// addi r3,r28,12
	ctx.r3.s64 = r28.s64 + 12;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r28,8
	ctx.r3.s64 = r28.s64 + 8;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8257E8E0) {
	__imp__sub_8257E8E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257EA18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82583560
	sub_82583560(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r30,0
	r30.s64 = 0;
	// addi r8,r11,28344
	ctx.r8.s64 = r11.s64 + 28344;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r30.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r30.u32);
loc_8257EA48:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r7
	reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r7
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8257ea48
	if (!cr0.eq) goto loc_8257EA48;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
loc_8257EA68:
	// mfmsr r5
	// mtmsrd r13,1
	// lwarx r6,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r6.u64 = __builtin_bswap32(reserved.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// stwcx. r6,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r6.s32));
	cr0.so = xer.so;
	// mtmsrd r5,1
	// bne 0x8257ea68
	if (!cr0.eq) goto loc_8257EA68;
	// lis r28,-31927
	r28.s64 = -2092367872;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(60) );
	// bl 0x8259db00
	sub_8259DB00(ctx, base);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8257d1f0
	sub_8257D1F0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8257e8e0
	sub_8257E8E0(ctx, base);
	// lbz r11,297(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 297);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257eaf8
	if (cr6.eq) goto loc_8257EAF8;
	// addi r29,r31,296
	r29.s64 = r31.s64 + 296;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82834510
	sub_82834510(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257eb10
	if (cr6.eq) goto loc_8257EB10;
	// stb r30,0(r29)
	PPC_STORE_U8(r29.u32 + 0, r30.u8);
	// addi r3,r31,92
	ctx.r3.s64 = r31.s64 + 92;
	// stb r30,1(r29)
	PPC_STORE_U8(r29.u32 + 1, r30.u8);
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(92) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8257eb10
	goto loc_8257EB10;
loc_8257EAF8:
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r3,r31,48
	ctx.r3.s64 = r31.s64 + 48;
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(152) );
	// bl 0x828ce4e8
	sub_828CE4E8(ctx, base);
loc_8257EB10:
	// addi r3,r31,48
	ctx.r3.s64 = r31.s64 + 48;
	// bl 0x828ce180
	sub_828CE180(ctx, base);
	// lwz r11,264(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(264) );
	// addi r29,r31,264
	r29.s64 = r31.s64 + 264;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lbz r9,261(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 261);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8257eb84
	if (cr6.eq) goto loc_8257EB84;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82846aa0
	sub_82846AA0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257eb84
	if (!cr6.eq) goto loc_8257EB84;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,304
	ctx.r4.s64 = r11.s64 + 304;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// stb r30,261(r31)
	PPC_STORE_U8(r31.u32 + 261, r30.u8);
loc_8257EB84:
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8257EA18) {
	__imp__sub_8257EA18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257EBA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r31,r28,244
	r31.s64 = r28.s64 + 244;
	// lwz r11,244(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(244) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257ec70
	if (cr6.eq) goto loc_8257EC70;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r30,52(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825a70a8
	sub_825A70A8(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257ec70
	if (cr6.eq) goto loc_8257EC70;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825a6f30
	sub_825A6F30(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257ec1c
	if (cr6.eq) goto loc_8257EC1C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825a6d90
	sub_825A6D90(ctx, base);
	// b 0x8257ec60
	goto loc_8257EC60;
loc_8257EC1C:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r4,28
	ctx.r4.s64 = 28;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r7,168(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(168) );
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x824fda50
	sub_824FDA50(ctx, base);
	// clrlwi r9,r3,24
	ctx.r9.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8257ec4c
	if (cr6.eq) goto loc_8257EC4C;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x824fdaf8
	sub_824FDAF8(ctx, base);
loc_8257EC4C:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r28,228
	ctx.r4.s64 = r28.s64 + 228;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825a6b00
	sub_825A6B00(ctx, base);
loc_8257EC60:
	// addi r3,r28,92
	ctx.r3.s64 = r28.s64 + 92;
	// bl 0x828d0220
	sub_828D0220(ctx, base);
	// addi r3,r28,188
	ctx.r3.s64 = r28.s64 + 188;
	// bl 0x828d1208
	sub_828D1208(ctx, base);
loc_8257EC70:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8257EBA0) {
	__imp__sub_8257EBA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257EC78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r29,-31927
	r29.s64 = -2092367872;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r4,44(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(44) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// lwz r28,52(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// bl 0x823fdbf0
	sub_823FDBF0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(36) );
	// rlwinm r9,r10,17,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8257eda0
	if (cr6.eq) goto loc_8257EDA0;
	// lwz r11,140(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(140) );
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257ece4
	if (cr6.eq) goto loc_8257ECE4;
	// lbz r11,15(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 15);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x8257eda4
	goto loc_8257EDA4;
loc_8257ECE4:
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + int32_t(76) );
	// li r11,0
	r11.s64 = 0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8257ed50
	if (!cr0.gt) goto loc_8257ED50;
loc_8257ED00:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,15
	cr6.compare<int32_t>(ctx.r7.s32, 15, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8257ed20
	if (cr6.lt) goto loc_8257ED20;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8257ED20:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8257ed3c
	if (cr6.eq) goto loc_8257ED3C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8257ed44
	goto loc_8257ED44;
loc_8257ED3C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8257ED44:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8257ed00
	if (cr6.gt) goto loc_8257ED00;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8257ED50:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8257ed90
	if (cr6.eq) goto loc_8257ED90;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8257ed6c
	if (cr6.gt) goto loc_8257ED6C;
	// li r11,0
	r11.s64 = 0;
loc_8257ED6C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257ed90
	if (!cr6.eq) goto loc_8257ED90;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8257eda4
	goto loc_8257EDA4;
loc_8257ED90:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8257eda4
	goto loc_8257EDA4;
loc_8257EDA0:
	// li r10,0
	ctx.r10.s64 = 0;
loc_8257EDA4:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257edbc
	if (cr6.eq) goto loc_8257EDBC;
	// addi r4,r30,244
	ctx.r4.s64 = r30.s64 + 244;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x82574e70
	sub_82574E70(ctx, base);
loc_8257EDBC:
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257ede8
	if (!cr6.eq) goto loc_8257EDE8;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r30,244
	ctx.r4.s64 = r30.s64 + 244;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x825a71a0
	sub_825A71A0(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r4,44(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(44) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fdb78
	sub_823FDB78(ctx, base);
loc_8257EDE8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8257EC78) {
	__imp__sub_8257EC78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257EDF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257ee44
	if (cr6.eq) goto loc_8257EE44;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257ee40
	if (cr6.eq) goto loc_8257EE40;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8257ee48
	goto loc_8257EE48;
loc_8257EE40:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8257EE44:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8257EE48:
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// mr r29,r31
	r29.u64 = r31.u64;
	// rlwinm r9,r10,17,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8257ef4c
	if (cr6.eq) goto loc_8257EF4C;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257ee88
	if (cr6.eq) goto loc_8257EE88;
	// lbz r10,15(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 15);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8257ef50
	goto loc_8257EF50;
loc_8257EE88:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8257eef4
	if (!cr0.gt) goto loc_8257EEF4;
loc_8257EEA4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,15
	cr6.compare<int32_t>(ctx.r7.s32, 15, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8257eec4
	if (cr6.lt) goto loc_8257EEC4;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8257EEC4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8257eee0
	if (cr6.eq) goto loc_8257EEE0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8257eee8
	goto loc_8257EEE8;
loc_8257EEE0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8257EEE8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8257eea4
	if (cr6.gt) goto loc_8257EEA4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8257EEF4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8257ef38
	if (cr6.eq) goto loc_8257EF38;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8257ef10
	if (cr6.gt) goto loc_8257EF10;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8257EF10:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257ef38
	if (!cr6.eq) goto loc_8257EF38;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8257ef50
	goto loc_8257EF50;
loc_8257EF38:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8257ef50
	goto loc_8257EF50;
loc_8257EF4C:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8257EF50:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f094
	if (cr6.eq) goto loc_8257F094;
	// lis r30,-31927
	r30.s64 = -2092367872;
	// lwz r4,44(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(44) );
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fdbf0
	sub_823FDBF0(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,17,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 17) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257f060
	if (cr6.eq) goto loc_8257F060;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257efa8
	if (cr6.eq) goto loc_8257EFA8;
	// lbz r11,15(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 15);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// li r11,1
	r11.s64 = 1;
	// lwz r31,4(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// b 0x8257f064
	goto loc_8257F064;
loc_8257EFA8:
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8257f010
	if (!cr0.gt) goto loc_8257F010;
loc_8257EFC0:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,15
	cr6.compare<int32_t>(ctx.r7.s32, 15, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8257efe0
	if (cr6.lt) goto loc_8257EFE0;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8257EFE0:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8257effc
	if (cr6.eq) goto loc_8257EFFC;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8257f004
	goto loc_8257F004;
loc_8257EFFC:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8257F004:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8257efc0
	if (cr6.gt) goto loc_8257EFC0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8257F010:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8257f050
	if (cr6.eq) goto loc_8257F050;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8257f02c
	if (cr6.gt) goto loc_8257F02C;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8257F02C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257f050
	if (!cr6.eq) goto loc_8257F050;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x8257f064
	goto loc_8257F064;
loc_8257F050:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x8257f064
	goto loc_8257F064;
loc_8257F060:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8257F064:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f094
	if (cr6.eq) goto loc_8257F094;
	// addi r4,r29,12
	ctx.r4.s64 = r29.s64 + 12;
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// bl 0x82576b88
	sub_82576B88(ctx, base);
	// lbz r10,61(r29)
	ctx.r10.u64 = PPC_LOAD_U8(r29.u32 + 61);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// stb r10,61(r31)
	PPC_STORE_U8(r31.u32 + 61, ctx.r10.u8);
	// lwz r4,44(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(44) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fdb78
	sub_823FDB78(ctx, base);
loc_8257F094:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8257EDF0) {
	__imp__sub_8257EDF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257F0A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r24,-31927
	r24.s64 = -2092367872;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r11,26788(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + int32_t(26788) );
	// lwz r4,44(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(44) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// lwz r25,52(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// bl 0x823fdbf0
	sub_823FDBF0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r31,r28
	r31.u64 = r28.u64;
	// lwz r11,36(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(36) );
	// mr r30,r28
	r30.u64 = r28.u64;
	// rlwinm r10,r11,17,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 17) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257f1d0
	if (cr6.eq) goto loc_8257F1D0;
	// lwz r11,140(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f114
	if (cr6.eq) goto loc_8257F114;
	// lbz r10,15(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 15);
	// lwz r11,72(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r11,1
	r11.s64 = 1;
	// lwz r3,4(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8257f1d4
	goto loc_8257F1D4;
loc_8257F114:
	// lwz r10,72(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + int32_t(72) );
	// lwz r6,76(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + int32_t(76) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8257f180
	if (!cr0.gt) goto loc_8257F180;
loc_8257F130:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,15
	cr6.compare<int32_t>(ctx.r7.s32, 15, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8257f150
	if (cr6.lt) goto loc_8257F150;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_8257F150:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8257f16c
	if (cr6.eq) goto loc_8257F16C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8257f174
	goto loc_8257F174;
loc_8257F16C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8257F174:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8257f130
	if (cr6.gt) goto loc_8257F130;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8257F180:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8257f1c0
	if (cr6.eq) goto loc_8257F1C0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8257f19c
	if (cr6.gt) goto loc_8257F19C;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8257F19C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257f1c0
	if (!cr6.eq) goto loc_8257F1C0;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x8257f1d4
	goto loc_8257F1D4;
loc_8257F1C0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x8257f1d4
	goto loc_8257F1D4;
loc_8257F1D0:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8257F1D4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f21c
	if (cr6.eq) goto loc_8257F21C;
	// addi r4,r27,244
	ctx.r4.s64 = r27.s64 + 244;
	// bl 0x82574e70
	sub_82574E70(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f1f8
	if (cr6.eq) goto loc_8257F1F8;
	// li r31,1
	r31.s64 = 1;
loc_8257F1F8:
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f21c
	if (cr6.eq) goto loc_8257F21C;
	// lwz r3,0(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// bl 0x82741840
	sub_82741840(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f21c
	if (cr6.eq) goto loc_8257F21C;
	// li r30,1
	r30.s64 = 1;
loc_8257F21C:
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f274
	if (cr6.eq) goto loc_8257F274;
	// addi r3,r27,72
	ctx.r3.s64 = r27.s64 + 72;
	// bl 0x82581388
	sub_82581388(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8257f490
	if (!cr6.eq) goto loc_8257F490;
	// addi r31,r27,244
	r31.s64 = r27.s64 + 244;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x825a7478
	sub_825A7478(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x825a7478
	sub_825A7478(ctx, base);
	// lwz r11,26788(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + int32_t(26788) );
	// lwz r4,44(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(44) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fdb78
	sub_823FDB78(ctx, base);
	// b 0x8257f490
	goto loc_8257F490;
loc_8257F274:
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257f490
	if (!cr6.eq) goto loc_8257F490;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82580388
	sub_82580388(ctx, base);
	// addi r30,r27,244
	r30.s64 = r27.s64 + 244;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x825a71a0
	sub_825A71A0(ctx, base);
	// lis r29,-31927
	r29.s64 = -2092367872;
	// lwz r11,26912(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26912) );
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(88) );
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// bl 0x8222c210
	sub_8222C210(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8257f2d8
	if (cr6.eq) goto loc_8257F2D8;
	// lbz r11,144(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8257f2dc
	if (!cr6.eq) goto loc_8257F2DC;
loc_8257F2D8:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8257F2DC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f458
	if (cr6.eq) goto loc_8257F458;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257f458
	if (cr6.eq) goto loc_8257F458;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82577a30
	sub_82577A30(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f458
	if (cr6.eq) goto loc_8257F458;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x826182a0
	sub_826182A0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257f33c
	if (!cr6.eq) goto loc_8257F33C;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82618320
	sub_82618320(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r11,r28
	r11.u64 = r28.u64;
	// beq cr6,0x8257f340
	if (cr6.eq) goto loc_8257F340;
loc_8257F33C:
	// li r11,1
	r11.s64 = 1;
loc_8257F340:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f458
	if (cr6.eq) goto loc_8257F458;
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(36) );
	// mr r11,r28
	r11.u64 = r28.u64;
	// rlwinm r9,r10,15,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8257f440
	if (cr6.eq) goto loc_8257F440;
	// lwz r11,140(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(140) );
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f388
	if (cr6.eq) goto loc_8257F388;
	// lbz r11,17(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 17);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x8257f444
	goto loc_8257F444;
loc_8257F388:
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + int32_t(76) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8257f3f0
	if (!cr0.gt) goto loc_8257F3F0;
loc_8257F3A0:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,17
	cr6.compare<int32_t>(ctx.r7.s32, 17, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8257f3c0
	if (cr6.lt) goto loc_8257F3C0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_8257F3C0:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8257f3dc
	if (cr6.eq) goto loc_8257F3DC;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8257f3e4
	goto loc_8257F3E4;
loc_8257F3DC:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8257F3E4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8257f3a0
	if (cr6.gt) goto loc_8257F3A0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8257F3F0:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8257f430
	if (cr6.eq) goto loc_8257F430;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,17
	cr6.compare<int32_t>(r11.s32, 17, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8257f40c
	if (cr6.gt) goto loc_8257F40C;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8257F40C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257f430
	if (!cr6.eq) goto loc_8257F430;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8257f444
	goto loc_8257F444;
loc_8257F430:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8257f444
	goto loc_8257F444;
loc_8257F440:
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
loc_8257F444:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257f458
	if (cr6.eq) goto loc_8257F458;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x824686c8
	sub_824686C8(ctx, base);
loc_8257F458:
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x825a71a0
	sub_825A71A0(ctx, base);
	// lwz r11,26788(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + int32_t(26788) );
	// lwz r4,44(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(44) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fdb78
	sub_823FDB78(ctx, base);
	// lwz r11,26912(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26912) );
	// li r4,229
	ctx.r4.s64 = 229;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r10,168(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(168) );
	// lwz r3,4(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// bl 0x821b5478
	sub_821B5478(ctx, base);
loc_8257F490:
	// addi r3,r27,92
	ctx.r3.s64 = r27.s64 + 92;
	// bl 0x828d0220
	sub_828D0220(ctx, base);
	// addi r3,r27,188
	ctx.r3.s64 = r27.s64 + 188;
	// bl 0x828d1208
	sub_828D1208(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_8257F0A0) {
	__imp__sub_8257F0A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257F4A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// li r24,0
	r24.s64 = 0;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f4fc
	if (cr6.eq) goto loc_8257F4FC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257f4f8
	if (cr6.eq) goto loc_8257F4F8;
	// rotlwi r6,r10,0
	ctx.r6.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8257f500
	goto loc_8257F500;
loc_8257F4F8:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8257F4FC:
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
loc_8257F500:
	// lis r22,-31927
	r22.s64 = -2092367872;
	// lwz r4,36(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(36) );
	// mr r25,r24
	r25.u64 = r24.u64;
	// rlwinm r11,r4,17,31,31
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 17) & 0x1;
	// mr r23,r24
	r23.u64 = r24.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r3,26788(r22)
	ctx.r3.u64 = PPC_LOAD_U32(r22.u32 + int32_t(26788) );
	// lwz r20,52(r3)
	r20.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(52) );
	// beq cr6,0x8257f5f8
	if (cr6.eq) goto loc_8257F5F8;
	// lwz r11,140(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f548
	if (cr6.eq) goto loc_8257F548;
	// lbz r10,15(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 15);
	// lwz r11,72(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8257f5f4
	goto loc_8257F5F4;
loc_8257F548:
	// lwz r10,72(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(72) );
	// lwz r5,76(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(76) );
	// stw r24,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r24.u32);
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8257f5b4
	if (!cr0.gt) goto loc_8257F5B4;
loc_8257F564:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,15
	cr6.compare<int32_t>(ctx.r7.s32, 15, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8257f584
	if (cr6.lt) goto loc_8257F584;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
loc_8257F584:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8257f5a0
	if (cr6.eq) goto loc_8257F5A0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8257f5a8
	goto loc_8257F5A8;
loc_8257F5A0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8257F5A8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8257f564
	if (cr6.gt) goto loc_8257F564;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_8257F5B4:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x8257f5ec
	if (cr6.eq) goto loc_8257F5EC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8257f5d0
	if (cr6.gt) goto loc_8257F5D0;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_8257F5D0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257f5ec
	if (!cr6.eq) goto loc_8257F5EC;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// b 0x8257f5f0
	goto loc_8257F5F0;
loc_8257F5EC:
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
loc_8257F5F0:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_8257F5F4:
	// mr r25,r11
	r25.u64 = r11.u64;
loc_8257F5F8:
	// rlwinm r11,r4,19,31,31
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 19) & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f6d8
	if (cr6.eq) goto loc_8257F6D8;
	// lwz r11,140(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f628
	if (cr6.eq) goto loc_8257F628;
	// lbz r10,13(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 13);
	// lwz r11,72(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8257f6d4
	goto loc_8257F6D4;
loc_8257F628:
	// lwz r10,72(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(72) );
	// lwz r6,76(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(76) );
	// stw r24,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r24.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8257f694
	if (!cr0.gt) goto loc_8257F694;
loc_8257F644:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,13
	cr6.compare<int32_t>(ctx.r7.s32, 13, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8257f664
	if (cr6.lt) goto loc_8257F664;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
loc_8257F664:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8257f680
	if (cr6.eq) goto loc_8257F680;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8257f688
	goto loc_8257F688;
loc_8257F680:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8257F688:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8257f644
	if (cr6.gt) goto loc_8257F644;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_8257F694:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8257f6cc
	if (cr6.eq) goto loc_8257F6CC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,13
	cr6.compare<int32_t>(r11.s32, 13, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8257f6b0
	if (cr6.gt) goto loc_8257F6B0;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_8257F6B0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257f6cc
	if (!cr6.eq) goto loc_8257F6CC;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// b 0x8257f6d0
	goto loc_8257F6D0;
loc_8257F6CC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_8257F6D0:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_8257F6D4:
	// mr r23,r11
	r23.u64 = r11.u64;
loc_8257F6D8:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8257f97c
	if (cr6.eq) goto loc_8257F97C;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x8257f97c
	if (cr6.eq) goto loc_8257F97C;
	// stw r24,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r24.u32);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// stw r24,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r24.u32);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// stw r24,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r24.u32);
	// bl 0x8261bb48
	sub_8261BB48(ctx, base);
	// stw r24,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r24.u32);
	// stw r24,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r24.u32);
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// stw r24,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r24.u32);
	// addi r4,r21,244
	ctx.r4.s64 = r21.s64 + 244;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x825a85a0
	sub_825A85A0(ctx, base);
	// lwz r3,148(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(148) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257f964
	if (cr6.eq) goto loc_8257F964;
	// lwz r11,152(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(152) );
	// subf r10,r3,r11
	ctx.r10.s64 = r11.s64 - ctx.r3.s64;
	// srawi. r11,r10,2
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	r11.s64 = ctx.r10.s32 >> 2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8257f960
	if (cr0.eq) goto loc_8257F960;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r28,r24
	r28.u64 = r24.u64;
	// mr r27,r24
	r27.u64 = r24.u64;
	// addi r26,r11,28344
	r26.s64 = r11.s64 + 28344;
loc_8257F748:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257f964
	if (cr6.eq) goto loc_8257F964;
	// lwz r11,152(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(152) );
	// subf r10,r3,r11
	ctx.r10.s64 = r11.s64 - ctx.r3.s64;
	// srawi r11,r10,2
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	r11.s64 = ctx.r10.s32 >> 2;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// bge cr6,0x8257f960
	if (!cr6.lt) goto loc_8257F960;
	// lwzx r5,r3,r27
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + r27.u32);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8261b978
	sub_8261B978(ctx, base);
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(160) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f94c
	if (cr6.eq) goto loc_8257F94C;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82571b60
	sub_82571B60(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// stw r24,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r24.u32);
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
loc_8257F798:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x8257f798
	if (!cr0.eq) goto loc_8257F798;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(132) );
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(136) );
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8257f7c8
	if (!cr6.gt) goto loc_8257F7C8;
	// twi 31,r0,22
loc_8257F7C8:
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// stw r9,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
	// ld r8,104(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// std r8,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r8.u64);
	// lwz r30,112(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// lwz r31,116(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
loc_8257F7E4:
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8257f7f0
	if (!cr6.gt) goto loc_8257F7F0;
	// twi 31,r0,22
loc_8257F7F0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8257f804
	if (cr6.eq) goto loc_8257F804;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// beq cr6,0x8257f808
	if (cr6.eq) goto loc_8257F808;
loc_8257F804:
	// twi 31,r0,22
loc_8257F808:
	// cmplw cr6,r31,r10
	cr6.compare<uint32_t>(r31.u32, ctx.r10.u32, xer);
	// beq cr6,0x8257f89c
	if (cr6.eq) goto loc_8257F89C;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8257f81c
	if (!cr6.eq) goto loc_8257F81C;
	// twi 31,r0,22
loc_8257F81C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(8) );
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x8257f82c
	if (cr6.lt) goto loc_8257F82C;
	// twi 31,r0,22
loc_8257F82C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82571b60
	sub_82571B60(ctx, base);
	// and r11,r3,r29
	r11.u64 = ctx.r3.u64 & r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f87c
	if (cr6.eq) goto loc_8257F87C;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + int32_t(26788) );
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259da00
	sub_8259DA00(ctx, base);
loc_8257F87C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(8) );
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x8257f88c
	if (cr6.lt) goto loc_8257F88C;
	// twi 31,r0,22
loc_8257F88C:
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(136) );
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(132) );
	// b 0x8257f7e4
	goto loc_8257F7E4;
loc_8257F89C:
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r4,160(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(160) );
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + int32_t(26788) );
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259da00
	sub_8259DA00(ctx, base);
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(160) );
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(16) );
	// addi r3,r11,-17
	ctx.r3.s64 = r11.s64 + -17;
	// cmplwi cr6,r3,6
	cr6.compare<uint32_t>(ctx.r3.u32, 6, xer);
	// bgt cr6,0x8257f8f4
	if (cr6.gt) goto loc_8257F8F4;
	// bl 0x825a8340
	sub_825A8340(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// b 0x8257f8f8
	goto loc_8257F8F8;
loc_8257F8F4:
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
loc_8257F8F8:
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x825802a0
	sub_825802A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + int32_t(26788) );
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259da00
	sub_8259DA00(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r3,160(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(160) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257f94c
	if (cr6.eq) goto loc_8257F94C;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8257F94C:
	// lwz r3,148(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(148) );
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// stw r24,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r24.u32);
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// b 0x8257f748
	goto loc_8257F748;
loc_8257F960:
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_8257F964:
	// stw r24,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r24.u32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stw r24,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r24.u32);
	// stw r24,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r24.u32);
	// bl 0x8233d9a8
	sub_8233D9A8(ctx, base);
	// lwz r3,26788(r22)
	ctx.r3.u64 = PPC_LOAD_U32(r22.u32 + int32_t(26788) );
loc_8257F97C:
	// lwz r3,8(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// lwz r4,44(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + int32_t(44) );
	// bl 0x823fdbf0
	sub_823FDBF0(ctx, base);
	// addi r31,r21,244
	r31.s64 = r21.s64 + 244;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x825a7e98
	sub_825A7E98(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x825a7e98
	sub_825A7E98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257f9cc
	if (cr6.eq) goto loc_8257F9CC;
	// lwz r11,26788(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + int32_t(26788) );
	// lwz r4,44(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + int32_t(44) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fdb78
	sub_823FDB78(ctx, base);
loc_8257F9CC:
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// b 0x82ca2c18
	return;
}

PPC_WEAK_FUNC(sub_8257F4A8) {
	__imp__sub_8257F4A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257F9D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-31927
	r30.s64 = -2092367872;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r31,-91
	ctx.r3.s64 = r31.s64 + -91;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// cmplwi cr6,r3,6
	cr6.compare<uint32_t>(ctx.r3.u32, 6, xer);
	// lwz r28,52(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// bgt cr6,0x8257fa10
	if (cr6.gt) goto loc_8257FA10;
	// bl 0x825a82c8
	sub_825A82C8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x8257fa14
	goto loc_8257FA14;
loc_8257FA10:
	// li r27,0
	r27.s64 = 0;
loc_8257FA14:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257fa54
	if (cr6.eq) goto loc_8257FA54;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257fa50
	if (cr6.eq) goto loc_8257FA50;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8257fa58
	goto loc_8257FA58;
loc_8257FA50:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8257FA54:
	// li r11,0
	r11.s64 = 0;
loc_8257FA58:
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// rlwinm r9,r10,17,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8257fba4
	if (cr6.eq) goto loc_8257FBA4;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257fa8c
	if (cr6.eq) goto loc_8257FA8C;
	// lbz r10,15(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 15);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r3,4(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8257fb3c
	goto loc_8257FB3C;
loc_8257FA8C:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// subf r8,r10,r6
	ctx.r8.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r8,3
	xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x7) != 0);
	r11.s64 = ctx.r8.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8257fafc
	if (!cr0.gt) goto loc_8257FAFC;
loc_8257FAAC:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,15
	cr6.compare<int32_t>(ctx.r7.s32, 15, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8257facc
	if (cr6.lt) goto loc_8257FACC;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8257FACC:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8257fae8
	if (cr6.eq) goto loc_8257FAE8;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8257faf0
	goto loc_8257FAF0;
loc_8257FAE8:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8257FAF0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8257faac
	if (cr6.gt) goto loc_8257FAAC;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8257FAFC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8257fb34
	if (cr6.eq) goto loc_8257FB34;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8257fb18
	if (cr6.gt) goto loc_8257FB18;
	// li r11,0
	r11.s64 = 0;
loc_8257FB18:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257fb34
	if (!cr6.eq) goto loc_8257FB34;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// b 0x8257fb38
	goto loc_8257FB38;
loc_8257FB34:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_8257FB38:
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_8257FB3C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257fba4
	if (cr6.eq) goto loc_8257FBA4;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x82575030
	sub_82575030(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257fba4
	if (cr6.eq) goto loc_8257FBA4;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82580388
	sub_82580388(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r4,44(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + int32_t(44) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fdbf0
	sub_823FDBF0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x825a83b8
	sub_825A83B8(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x825a83b8
	sub_825A83B8(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r4,44(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + int32_t(44) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fdb78
	sub_823FDB78(ctx, base);
loc_8257FBA4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8257F9D8) {
	__imp__sub_8257F9D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8257FBB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r26,-31927
	r26.s64 = -2092367872;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r11,26788(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(26788) );
	// lwz r4,44(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(44) );
	// addi r24,r11,8
	r24.s64 = r11.s64 + 8;
	// lwz r25,52(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fdbf0
	sub_823FDBF0(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// li r29,0
	r29.s64 = 0;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8257fc24
	if (cr6.eq) goto loc_8257FC24;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257fc20
	if (cr6.eq) goto loc_8257FC20;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8257fc28
	goto loc_8257FC28;
loc_8257FC20:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8257FC24:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8257FC28:
	// lwz r9,36(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// rlwinm r8,r9,17,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 17) & 0x1;
	// addi r28,r10,28344
	r28.s64 = ctx.r10.s64 + 28344;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x8257fe00
	if (cr6.eq) goto loc_8257FE00;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8257fc64
	if (cr6.eq) goto loc_8257FC64;
	// lbz r10,15(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 15);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r3,4(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8257fd10
	goto loc_8257FD10;
loc_8257FC64:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8257fcd0
	if (!cr0.gt) goto loc_8257FCD0;
loc_8257FC80:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,15
	cr6.compare<int32_t>(ctx.r7.s32, 15, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8257fca0
	if (cr6.lt) goto loc_8257FCA0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_8257FCA0:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8257fcbc
	if (cr6.eq) goto loc_8257FCBC;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8257fcc4
	goto loc_8257FCC4;
loc_8257FCBC:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8257FCC4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8257fc80
	if (cr6.gt) goto loc_8257FC80;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8257FCD0:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8257fd08
	if (cr6.eq) goto loc_8257FD08;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8257fcec
	if (cr6.gt) goto loc_8257FCEC;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8257FCEC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8257fd08
	if (!cr6.eq) goto loc_8257FD08;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// b 0x8257fd0c
	goto loc_8257FD0C;
loc_8257FD08:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_8257FD0C:
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_8257FD10:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257fe00
	if (cr6.eq) goto loc_8257FE00;
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r29.u32);
	// bl 0x825707c0
	sub_825707C0(ctx, base);
	// mr r31,r29
	r31.u64 = r29.u64;
	// mr r30,r29
	r30.u64 = r29.u64;
loc_8257FD34:
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257fdf4
	if (cr6.eq) goto loc_8257FDF4;
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(120) );
	// subf r10,r3,r11
	ctx.r10.s64 = r11.s64 - ctx.r3.s64;
	// srawi r11,r10,2
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	r11.s64 = ctx.r10.s32 >> 2;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bge cr6,0x8257fdf0
	if (!cr6.lt) goto loc_8257FDF0;
	// lwzx r3,r30,r3
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + ctx.r3.u32);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// stw r29,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r29.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// stw r3,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r3.u32);
	// beq cr6,0x8257fd7c
	if (cr6.eq) goto loc_8257FD7C;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82741b18
	sub_82741B18(ctx, base);
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
loc_8257FD7C:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// lwz r11,26788(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(26788) );
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259da00
	sub_8259DA00(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
loc_8257FDAC:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8257fdac
	if (!cr0.eq) goto loc_8257FDAC;
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8257fde0
	if (cr6.eq) goto loc_8257FDE0;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8257FDE0:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// b 0x8257fd34
	goto loc_8257FD34;
loc_8257FDF0:
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_8257FDF4:
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r29.u32);
loc_8257FE00:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r31,r11,344
	r31.s64 = r11.s64 + 344;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,15
	ctx.r3.s64 = 15;
	// bl 0x8283fd80
	sub_8283FD80(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
loc_8257FE38:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8257fe38
	if (!cr0.eq) goto loc_8257FE38;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r7,0(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + int32_t(0) );
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,40(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(40) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_8257FE84:
	// mfmsr r4
	// mtmsrd r13,1
	// lwarx r5,0,r3
	reserved.u32 = *(uint32_t*)(base + ctx.r3.u32);
	ctx.r5.u64 = __builtin_bswap32(reserved.u32);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// stwcx. r5,0,r3
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r3.u32), reserved.s32, __builtin_bswap32(ctx.r5.s32));
	cr0.so = xer.so;
	// mtmsrd r4,1
	// bne 0x8257fe84
	if (!cr0.eq) goto loc_8257FE84;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r31,r11,372
	r31.s64 = r11.s64 + 372;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,15
	ctx.r3.s64 = 15;
	// bl 0x8283fd80
	sub_8283FD80(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
loc_8257FED8:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8257fed8
	if (!cr0.eq) goto loc_8257FED8;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r7,0(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + int32_t(0) );
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,40(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(40) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_8257FF24:
	// mfmsr r4
	// mtmsrd r13,1
	// lwarx r5,0,r3
	reserved.u32 = *(uint32_t*)(base + ctx.r3.u32);
	ctx.r5.u64 = __builtin_bswap32(reserved.u32);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// stwcx. r5,0,r3
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r3.u32), reserved.s32, __builtin_bswap32(ctx.r5.s32));
	cr0.so = xer.so;
	// mtmsrd r4,1
	// bne 0x8257ff24
	if (!cr0.eq) goto loc_8257FF24;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r31,r11,400
	r31.s64 = r11.s64 + 400;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,15
	ctx.r3.s64 = 15;
	// bl 0x8283fd80
	sub_8283FD80(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
loc_8257FF78:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8257ff78
	if (!cr0.eq) goto loc_8257FF78;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r7,0(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + int32_t(0) );
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,40(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(40) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_8257FFC4:
	// mfmsr r4
	// mtmsrd r13,1
	// lwarx r5,0,r3
	reserved.u32 = *(uint32_t*)(base + ctx.r3.u32);
	ctx.r5.u64 = __builtin_bswap32(reserved.u32);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// stwcx. r5,0,r3
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r3.u32), reserved.s32, __builtin_bswap32(ctx.r5.s32));
	cr0.so = xer.so;
	// mtmsrd r4,1
	// bne 0x8257ffc4
	if (!cr0.eq) goto loc_8257FFC4;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r31,r11,432
	r31.s64 = r11.s64 + 432;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,15
	ctx.r3.s64 = 15;
	// bl 0x8283fd80
	sub_8283FD80(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
loc_82580018:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x82580018
	if (!cr0.eq) goto loc_82580018;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r7,0(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + int32_t(0) );
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,40(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(40) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_82580064:
	// mfmsr r4
	// mtmsrd r13,1
	// lwarx r5,0,r3
	reserved.u32 = *(uint32_t*)(base + ctx.r3.u32);
	ctx.r5.u64 = __builtin_bswap32(reserved.u32);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// stwcx. r5,0,r3
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r3.u32), reserved.s32, __builtin_bswap32(ctx.r5.s32));
	cr0.so = xer.so;
	// mtmsrd r4,1
	// bne 0x82580064
	if (!cr0.eq) goto loc_82580064;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r31,r11,464
	r31.s64 = r11.s64 + 464;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,15
	ctx.r3.s64 = 15;
	// bl 0x8283fd80
	sub_8283FD80(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
loc_825800B8:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x825800b8
	if (!cr0.eq) goto loc_825800B8;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r7,0(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + int32_t(0) );
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,40(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(40) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_82580104:
	// mfmsr r4
	// mtmsrd r13,1
	// lwarx r5,0,r3
	reserved.u32 = *(uint32_t*)(base + ctx.r3.u32);
	ctx.r5.u64 = __builtin_bswap32(reserved.u32);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// stwcx. r5,0,r3
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r3.u32), reserved.s32, __builtin_bswap32(ctx.r5.s32));
	cr0.so = xer.so;
	// mtmsrd r4,1
	// bne 0x82580104
	if (!cr0.eq) goto loc_82580104;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r31,r11,492
	r31.s64 = r11.s64 + 492;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,15
	ctx.r3.s64 = 15;
	// bl 0x8283fd80
	sub_8283FD80(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
loc_82580158:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x82580158
	if (!cr0.eq) goto loc_82580158;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r7,0(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + int32_t(0) );
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,40(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(40) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_825801A4:
	// mfmsr r4
	// mtmsrd r13,1
	// lwarx r5,0,r3
	reserved.u32 = *(uint32_t*)(base + ctx.r3.u32);
	ctx.r5.u64 = __builtin_bswap32(reserved.u32);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// stwcx. r5,0,r3
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r3.u32), reserved.s32, __builtin_bswap32(ctx.r5.s32));
	cr0.so = xer.so;
	// mtmsrd r4,1
	// bne 0x825801a4
	if (!cr0.eq) goto loc_825801A4;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r31,r11,520
	r31.s64 = r11.s64 + 520;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,15
	ctx.r3.s64 = 15;
	// bl 0x8283fd80
	sub_8283FD80(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
loc_825801F8:
	// mfmsr r8
	// mtmsrd r13,1
	// lwarx r9,0,r10
	reserved.u32 = *(uint32_t*)(base + ctx.r10.u32);
	ctx.r9.u64 = __builtin_bswap32(reserved.u32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// stwcx. r9,0,r10
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r10.u32), reserved.s32, __builtin_bswap32(ctx.r9.s32));
	cr0.so = xer.so;
	// mtmsrd r8,1
	// bne 0x825801f8
	if (!cr0.eq) goto loc_825801F8;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r7,0(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + int32_t(0) );
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,40(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(40) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
loc_82580240:
	// mfmsr r4
	// mtmsrd r13,1
	// lwarx r5,0,r28
	reserved.u32 = *(uint32_t*)(base + r28.u32);
	ctx.r5.u64 = __builtin_bswap32(reserved.u32);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// stwcx. r5,0,r28
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + r28.u32), reserved.s32, __builtin_bswap32(ctx.r5.s32));
	cr0.so = xer.so;
	// mtmsrd r4,1
	// bne 0x82580240
	if (!cr0.eq) goto loc_82580240;
	// li r31,91
	r31.s64 = 91;
loc_82580260:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x825a83b8
	sub_825A83B8(ctx, base);
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x825a83b8
	sub_825A83B8(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplwi cr6,r31,97
	cr6.compare<uint32_t>(r31.u32, 97, xer);
	// ble cr6,0x82580260
	if (!cr6.gt) goto loc_82580260;
	// lwz r4,44(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(44) );
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(r24.u32 + int32_t(0) );
	// bl 0x823fdb78
	sub_823FDB78(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_8257FBB0) {
	__imp__sub_8257FBB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825802A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r24{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r5,-90
	r11.s64 = ctx.r5.s64 + -90;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bgt cr6,0x82580358
	if (cr6.gt) goto loc_82580358;
	// lis r12,-32168
	r12.s64 = -2108162048;
	// addi r12,r12,728
	r12.s64 = r12.s64 + 728;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_825802F8;
	case 1:
		goto loc_82580304;
	case 2:
		goto loc_82580310;
	case 3:
		goto loc_8258031C;
	case 4:
		goto loc_82580328;
	case 5:
		goto loc_82580334;
	case 6:
		goto loc_82580340;
	case 7:
		goto loc_8258034C;
	default:
		__builtin_unreachable();
	}
	// lwz r18,760(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(760) );
	// lwz r18,772(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(772) );
	// lwz r18,784(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(784) );
	// lwz r18,796(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(796) );
	// lwz r18,808(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(808) );
	// lwz r18,820(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(820) );
	// lwz r18,832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(832) );
	// lwz r18,844(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(844) );
loc_825802F8:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,548
	ctx.r4.s64 = r11.s64 + 548;
	// b 0x82580360
	goto loc_82580360;
loc_82580304:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,344
	ctx.r4.s64 = r11.s64 + 344;
	// b 0x82580360
	goto loc_82580360;
loc_82580310:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,372
	ctx.r4.s64 = r11.s64 + 372;
	// b 0x82580360
	goto loc_82580360;
loc_8258031C:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,400
	ctx.r4.s64 = r11.s64 + 400;
	// b 0x82580360
	goto loc_82580360;
loc_82580328:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,432
	ctx.r4.s64 = r11.s64 + 432;
	// b 0x82580360
	goto loc_82580360;
loc_82580334:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,464
	ctx.r4.s64 = r11.s64 + 464;
	// b 0x82580360
	goto loc_82580360;
loc_82580340:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,492
	ctx.r4.s64 = r11.s64 + 492;
	// b 0x82580360
	goto loc_82580360;
loc_8258034C:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,520
	ctx.r4.s64 = r11.s64 + 520;
	// b 0x82580360
	goto loc_82580360;
loc_82580358:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,576
	ctx.r4.s64 = r11.s64 + 576;
loc_82580360:
	// li r5,-1
	ctx.r5.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825802A0) {
	__imp__sub_825802A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82580388) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r29,0
	r29.s64 = 0;
	// addi r22,r11,28344
	r22.s64 = r11.s64 + 28344;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
loc_825803AC:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x825803ac
	if (!cr0.eq) goto loc_825803AC;
	// stw r29,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r29.u32);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// stw r29,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r29.u32);
	// stw r29,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r29.u32);
loc_825803D8:
	// mfmsr r6
	// mtmsrd r13,1
	// lwarx r7,0,r5
	reserved.u32 = *(uint32_t*)(base + ctx.r5.u32);
	ctx.r7.u64 = __builtin_bswap32(reserved.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// stwcx. r7,0,r5
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r5.u32), reserved.s32, __builtin_bswap32(ctx.r7.s32));
	cr0.so = xer.so;
	// mtmsrd r6,1
	// bne 0x825803d8
	if (!cr0.eq) goto loc_825803D8;
	// mr r11,r22
	r11.u64 = r22.u64;
	// stw r29,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r29.u32);
loc_825803FC:
	// mfmsr r3
	// mtmsrd r13,1
	// lwarx r4,0,r11
	reserved.u32 = *(uint32_t*)(base + r11.u32);
	ctx.r4.u64 = __builtin_bswap32(reserved.u32);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// stwcx. r4,0,r11
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + r11.u32), reserved.s32, __builtin_bswap32(ctx.r4.s32));
	cr0.so = xer.so;
	// mtmsrd r3,1
	// bne 0x825803fc
	if (!cr0.eq) goto loc_825803FC;
	// lis r24,-31927
	r24.s64 = -2092367872;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r11,26788(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + int32_t(26788) );
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(60) );
	// bl 0x8259db00
	sub_8259DB00(ctx, base);
	// lwz r9,132(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(132) );
	// addi r25,r21,244
	r25.s64 = r21.s64 + 244;
	// lwz r4,244(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + int32_t(244) );
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addis r31,r9,-2
	r31.s64 = ctx.r9.s64 + -131072;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// addi r31,r31,31072
	r31.s64 = r31.s64 + 31072;
	// bne cr6,0x82580460
	if (!cr6.eq) goto loc_82580460;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// bl 0x825802a0
	sub_825802A0(ctx, base);
	// b 0x82580464
	goto loc_82580464;
loc_82580460:
	// bl 0x827414a0
	sub_827414A0(ctx, base);
loc_82580464:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + int32_t(26788) );
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259da00
	sub_8259DA00(ctx, base);
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + int32_t(0) );
	// mr r23,r29
	r23.u64 = r29.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x825804bc
	if (!cr6.eq) goto loc_825804BC;
	// addi r3,r31,-91
	ctx.r3.s64 = r31.s64 + -91;
	// cmplwi cr6,r3,6
	cr6.compare<uint32_t>(ctx.r3.u32, 6, xer);
	// bgt cr6,0x825804b8
	if (cr6.gt) goto loc_825804B8;
	// bl 0x825a82c8
	sub_825A82C8(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// b 0x825804bc
	goto loc_825804BC;
loc_825804B8:
	// mr r23,r29
	r23.u64 = r29.u64;
loc_825804BC:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825804fc
	if (cr6.eq) goto loc_825804FC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825804f8
	if (cr6.eq) goto loc_825804F8;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x82580500
	goto loc_82580500;
loc_825804F8:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_825804FC:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82580500:
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// rlwinm r9,r10,17,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82580714
	if (cr6.eq) goto loc_82580714;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82580534
	if (cr6.eq) goto loc_82580534;
	// lbz r9,15(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 15);
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r11,r9,3
	r11.u64 = rotl32(ctx.r9.u32, 3);
	// add r8,r11,r10
	ctx.r8.u64 = r11.u64 + ctx.r10.u64;
	// lwz r27,4(r8)
	r27.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(4) );
	// b 0x825805e0
	goto loc_825805E0;
loc_82580534:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r29,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825805a0
	if (!cr0.gt) goto loc_825805A0;
loc_82580550:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,15
	cr6.compare<int32_t>(ctx.r7.s32, 15, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82580570
	if (cr6.lt) goto loc_82580570;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_82580570:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258058c
	if (cr6.eq) goto loc_8258058C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82580594
	goto loc_82580594;
loc_8258058C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82580594:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82580550
	if (cr6.gt) goto loc_82580550;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_825805A0:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825805d8
	if (cr6.eq) goto loc_825805D8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825805bc
	if (cr6.gt) goto loc_825805BC;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_825805BC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825805d8
	if (!cr6.eq) goto loc_825805D8;
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// b 0x825805dc
	goto loc_825805DC;
loc_825805D8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_825805DC:
	// lwz r27,4(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_825805E0:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82580714
	if (cr6.eq) goto loc_82580714;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82571b60
	sub_82571B60(ctx, base);
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r29.u32);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x825707c0
	sub_825707C0(ctx, base);
	// mr r30,r29
	r30.u64 = r29.u64;
	// mr r28,r29
	r28.u64 = r29.u64;
loc_82580618:
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82580708
	if (cr6.eq) goto loc_82580708;
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(120) );
	// subf r10,r3,r11
	ctx.r10.s64 = r11.s64 - ctx.r3.s64;
	// srawi r11,r10,2
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	r11.s64 = ctx.r10.s32 >> 2;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bge cr6,0x82580704
	if (!cr6.lt) goto loc_82580704;
	// mr r31,r29
	r31.u64 = r29.u64;
	// blt cr6,0x82580644
	if (cr6.lt) goto loc_82580644;
	// twi 31,r0,22
loc_82580644:
	// lwzx r3,r28,r3
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + ctx.r3.u32);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// stw r29,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r29.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// stw r3,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r3.u32);
	// beq cr6,0x8258066c
	if (cr6.eq) goto loc_8258066C;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82741b18
	sub_82741B18(ctx, base);
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
loc_8258066C:
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + int32_t(0) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82580688
	if (!cr6.eq) goto loc_82580688;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(16) );
	// cmpw cr6,r11,r23
	cr6.compare<int32_t>(r11.s32, r23.s32, xer);
	// bne cr6,0x825806a8
	if (!cr6.eq) goto loc_825806A8;
	// b 0x825806a4
	goto loc_825806A4;
loc_82580688:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82571b60
	sub_82571B60(ctx, base);
	// and r11,r3,r26
	r11.u64 = ctx.r3.u64 & r26.u64;
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825806a8
	if (cr6.eq) goto loc_825806A8;
loc_825806A4:
	// li r31,1
	r31.s64 = 1;
loc_825806A8:
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825806e4
	if (cr6.eq) goto loc_825806E4;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// lwz r11,26788(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + int32_t(26788) );
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259da00
	sub_8259DA00(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
loc_825806E4:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825806f4
	if (cr6.eq) goto loc_825806F4;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_825806F4:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// b 0x82580618
	goto loc_82580618;
loc_82580704:
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_82580708:
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r29.u32);
loc_82580714:
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + int32_t(0) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258076c
	if (cr6.eq) goto loc_8258076C;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(16) );
	// addi r3,r11,-17
	ctx.r3.s64 = r11.s64 + -17;
	// cmplwi cr6,r3,6
	cr6.compare<uint32_t>(ctx.r3.u32, 6, xer);
	// bgt cr6,0x8258073c
	if (cr6.gt) goto loc_8258073C;
	// bl 0x825a8340
	sub_825A8340(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// b 0x82580740
	goto loc_82580740;
loc_8258073C:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
loc_82580740:
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x825802a0
	sub_825802A0(ctx, base);
	// lwz r11,26788(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + int32_t(26788) );
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259da00
	sub_8259DA00(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_8258076C:
	// addi r3,r1,140
	ctx.r3.s64 = ctx.r1.s64 + 140;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
loc_82580778:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x82580778
	if (!cr0.eq) goto loc_82580778;
	// stw r29,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r29.u32);
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
loc_825807A4:
	// mfmsr r7
	// mtmsrd r13,1
	// lwarx r8,0,r6
	reserved.u32 = *(uint32_t*)(base + ctx.r6.u32);
	ctx.r8.u64 = __builtin_bswap32(reserved.u32);
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// stwcx. r8,0,r6
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r6.u32), reserved.s32, __builtin_bswap32(ctx.r8.s32));
	cr0.so = xer.so;
	// mtmsrd r7,1
	// bne 0x825807a4
	if (!cr0.eq) goto loc_825807A4;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
loc_825807C8:
	// mfmsr r4
	// mtmsrd r13,1
	// lwarx r5,0,r22
	reserved.u32 = *(uint32_t*)(base + r22.u32);
	ctx.r5.u64 = __builtin_bswap32(reserved.u32);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// stwcx. r5,0,r22
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + r22.u32), reserved.s32, __builtin_bswap32(ctx.r5.s32));
	cr0.so = xer.so;
	// mtmsrd r4,1
	// bne 0x825807c8
	if (!cr0.eq) goto loc_825807C8;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c1c
	return;
}

PPC_WEAK_FUNC(sub_82580388) {
	__imp__sub_82580388(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825807F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r24{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r29,26788(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r4,44(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(44) );
	// lwz r27,52(r29)
	r27.u64 = PPC_LOAD_U32(r29.u32 + int32_t(52) );
	// lwz r3,8(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + int32_t(8) );
	// bl 0x823fdbf0
	sub_823FDBF0(ctx, base);
	// lwz r4,4(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(4) );
	// addi r11,r4,-3
	r11.s64 = ctx.r4.s64 + -3;
	// cmplwi cr6,r11,138
	cr6.compare<uint32_t>(r11.u32, 138, xer);
	// bgt cr6,0x82580bac
	if (cr6.gt) goto loc_82580BAC;
	// lis r12,-32168
	r12.s64 = -2108162048;
	// addi r12,r12,2116
	r12.s64 = r12.s64 + 2116;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82580A70;
	case 1:
		goto loc_82580BAC;
	case 2:
		goto loc_82580BAC;
	case 3:
		goto loc_82580BAC;
	case 4:
		goto loc_82580BAC;
	case 5:
		goto loc_82580BAC;
	case 6:
		goto loc_82580BAC;
	case 7:
		goto loc_82580BAC;
	case 8:
		goto loc_82580BAC;
	case 9:
		goto loc_82580BAC;
	case 10:
		goto loc_82580BAC;
	case 11:
		goto loc_82580BAC;
	case 12:
		goto loc_82580BAC;
	case 13:
		goto loc_82580BAC;
	case 14:
		goto loc_82580BAC;
	case 15:
		goto loc_82580BAC;
	case 16:
		goto loc_82580BAC;
	case 17:
		goto loc_82580BAC;
	case 18:
		goto loc_82580BAC;
	case 19:
		goto loc_82580BAC;
	case 20:
		goto loc_82580BAC;
	case 21:
		goto loc_82580BAC;
	case 22:
		goto loc_82580BAC;
	case 23:
		goto loc_82580BAC;
	case 24:
		goto loc_82580BAC;
	case 25:
		goto loc_82580BAC;
	case 26:
		goto loc_82580BAC;
	case 27:
		goto loc_82580BAC;
	case 28:
		goto loc_82580BAC;
	case 29:
		goto loc_82580BAC;
	case 30:
		goto loc_82580BAC;
	case 31:
		goto loc_82580BAC;
	case 32:
		goto loc_82580BAC;
	case 33:
		goto loc_82580BAC;
	case 34:
		goto loc_82580BAC;
	case 35:
		goto loc_82580BAC;
	case 36:
		goto loc_82580BAC;
	case 37:
		goto loc_82580BAC;
	case 38:
		goto loc_82580BAC;
	case 39:
		goto loc_82580BAC;
	case 40:
		goto loc_82580BAC;
	case 41:
		goto loc_82580BAC;
	case 42:
		goto loc_82580BAC;
	case 43:
		goto loc_82580BAC;
	case 44:
		goto loc_82580BAC;
	case 45:
		goto loc_82580BAC;
	case 46:
		goto loc_82580BAC;
	case 47:
		goto loc_82580BAC;
	case 48:
		goto loc_82580BAC;
	case 49:
		goto loc_82580BAC;
	case 50:
		goto loc_82580BAC;
	case 51:
		goto loc_82580BAC;
	case 52:
		goto loc_82580BAC;
	case 53:
		goto loc_82580BAC;
	case 54:
		goto loc_82580BAC;
	case 55:
		goto loc_82580BAC;
	case 56:
		goto loc_82580BAC;
	case 57:
		goto loc_82580BAC;
	case 58:
		goto loc_82580BAC;
	case 59:
		goto loc_82580BAC;
	case 60:
		goto loc_82580BAC;
	case 61:
		goto loc_82580BAC;
	case 62:
		goto loc_82580BAC;
	case 63:
		goto loc_82580BAC;
	case 64:
		goto loc_82580BAC;
	case 65:
		goto loc_82580BAC;
	case 66:
		goto loc_82580BAC;
	case 67:
		goto loc_82580BAC;
	case 68:
		goto loc_82580BAC;
	case 69:
		goto loc_82580BAC;
	case 70:
		goto loc_82580BAC;
	case 71:
		goto loc_82580BAC;
	case 72:
		goto loc_82580BAC;
	case 73:
		goto loc_82580BAC;
	case 74:
		goto loc_82580BAC;
	case 75:
		goto loc_82580BAC;
	case 76:
		goto loc_82580BAC;
	case 77:
		goto loc_82580BAC;
	case 78:
		goto loc_82580BAC;
	case 79:
		goto loc_82580BAC;
	case 80:
		goto loc_82580BAC;
	case 81:
		goto loc_82580B20;
	case 82:
		goto loc_82580BAC;
	case 83:
		goto loc_82580B20;
	case 84:
		goto loc_82580B20;
	case 85:
		goto loc_82580B20;
	case 86:
		goto loc_82580B34;
	case 87:
		goto loc_82580B44;
	case 88:
		goto loc_82580B54;
	case 89:
		goto loc_82580B54;
	case 90:
		goto loc_82580B54;
	case 91:
		goto loc_82580B54;
	case 92:
		goto loc_82580B54;
	case 93:
		goto loc_82580B54;
	case 94:
		goto loc_82580B54;
	case 95:
		goto loc_82580BAC;
	case 96:
		goto loc_82580BAC;
	case 97:
		goto loc_82580BAC;
	case 98:
		goto loc_82580BAC;
	case 99:
		goto loc_82580BAC;
	case 100:
		goto loc_82580BAC;
	case 101:
		goto loc_82580BAC;
	case 102:
		goto loc_82580BAC;
	case 103:
		goto loc_82580BAC;
	case 104:
		goto loc_82580BAC;
	case 105:
		goto loc_82580BAC;
	case 106:
		goto loc_82580BAC;
	case 107:
		goto loc_82580BAC;
	case 108:
		goto loc_82580BAC;
	case 109:
		goto loc_82580BAC;
	case 110:
		goto loc_82580BAC;
	case 111:
		goto loc_82580BAC;
	case 112:
		goto loc_82580BAC;
	case 113:
		goto loc_82580BAC;
	case 114:
		goto loc_82580BAC;
	case 115:
		goto loc_82580BAC;
	case 116:
		goto loc_82580BAC;
	case 117:
		goto loc_82580BAC;
	case 118:
		goto loc_82580BAC;
	case 119:
		goto loc_82580BAC;
	case 120:
		goto loc_82580BAC;
	case 121:
		goto loc_82580BAC;
	case 122:
		goto loc_82580BAC;
	case 123:
		goto loc_82580BAC;
	case 124:
		goto loc_82580BAC;
	case 125:
		goto loc_82580BAC;
	case 126:
		goto loc_82580BAC;
	case 127:
		goto loc_82580BAC;
	case 128:
		goto loc_82580BAC;
	case 129:
		goto loc_82580BAC;
	case 130:
		goto loc_82580BAC;
	case 131:
		goto loc_82580BAC;
	case 132:
		goto loc_82580BAC;
	case 133:
		goto loc_82580BAC;
	case 134:
		goto loc_82580BAC;
	case 135:
		goto loc_82580BAC;
	case 136:
		goto loc_82580BAC;
	case 137:
		goto loc_82580B8C;
	case 138:
		goto loc_82580B64;
	default:
		__builtin_unreachable();
	}
	// lwz r18,2672(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2672) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2848(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2848) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2848(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2848) );
	// lwz r18,2848(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2848) );
	// lwz r18,2848(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2848) );
	// lwz r18,2868(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2868) );
	// lwz r18,2884(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2884) );
	// lwz r18,2900(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2900) );
	// lwz r18,2900(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2900) );
	// lwz r18,2900(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2900) );
	// lwz r18,2900(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2900) );
	// lwz r18,2900(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2900) );
	// lwz r18,2900(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2900) );
	// lwz r18,2900(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2900) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2988(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2988) );
	// lwz r18,2956(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2956) );
	// lwz r18,2916(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(2916) );
loc_82580A70:
	// lwz r11,244(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(244) );
	// addi r31,r30,244
	r31.s64 = r30.s64 + 244;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82580bac
	if (cr6.eq) goto loc_82580BAC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82580aa4
	if (cr6.eq) goto loc_82580AA4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// b 0x82580aac
	goto loc_82580AAC;
loc_82580AA4:
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
loc_82580AAC:
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r7,r11,-28544
	ctx.r7.s64 = r11.s64 + -28544;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// bl 0x822a97a8
	sub_822A97A8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82580bac
	if (cr6.eq) goto loc_82580BAC;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-29244
	ctx.r4.s64 = r11.s64 + -29244;
	// bl 0x823a5128
	sub_823A5128(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// cmpwi cr6,r10,24
	cr6.compare<int32_t>(ctx.r10.s32, 24, xer);
	// bne cr6,0x82580b10
	if (!cr6.eq) goto loc_82580B10;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x825a5a40
	sub_825A5A40(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,28(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + int32_t(28) );
	// bl 0x82336f98
	sub_82336F98(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82580B10:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8257f0a0
	sub_8257F0A0(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82580B20:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8257eba0
	sub_8257EBA0(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82580B34:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8257f4a8
	sub_8257F4A8(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82580B44:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8257fbb0
	sub_8257FBB0(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82580B54:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8257f9d8
	sub_8257F9D8(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82580B64:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lwz r4,26788(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-30944
	ctx.r5.s64 = r11.s64 + -30944;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82580B8C:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lwz r4,26788(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-30948
	ctx.r5.s64 = r11.s64 + -30948;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_82580BAC:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_825807F0) {
	__imp__sub_825807F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82580BB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r24{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// addi r3,r31,264
	ctx.r3.s64 = r31.s64 + 264;
	// lwz r11,264(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(264) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi r9,r3,24
	ctx.r9.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82580f10
	if (!cr6.eq) goto loc_82580F10;
	// addi r11,r30,-26
	r11.s64 = r30.s64 + -26;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bgt cr6,0x82580f10
	if (cr6.gt) goto loc_82580F10;
	// lis r12,-32168
	r12.s64 = -2108162048;
	// addi r12,r12,3092
	r12.s64 = r12.s64 + 3092;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82580E7C;
	case 1:
		goto loc_82580E7C;
	case 2:
		goto loc_82580F10;
	case 3:
		goto loc_82580F10;
	case 4:
		goto loc_82580F10;
	case 5:
		goto loc_82580F10;
	case 6:
		goto loc_82580F10;
	case 7:
		goto loc_82580F10;
	case 8:
		goto loc_82580F10;
	case 9:
		goto loc_82580F10;
	case 10:
		goto loc_82580D30;
	case 11:
		goto loc_82580D78;
	case 12:
		goto loc_82580F10;
	case 13:
		goto loc_82580D40;
	case 14:
		goto loc_82580F10;
	case 15:
		goto loc_82580F10;
	case 16:
		goto loc_82580F10;
	case 17:
		goto loc_82580F10;
	case 18:
		goto loc_82580F10;
	case 19:
		goto loc_82580F10;
	case 20:
		goto loc_82580F10;
	case 21:
		goto loc_82580F10;
	case 22:
		goto loc_82580F10;
	case 23:
		goto loc_82580F10;
	case 24:
		goto loc_82580F10;
	case 25:
		goto loc_82580F10;
	case 26:
		goto loc_82580F10;
	case 27:
		goto loc_82580F10;
	case 28:
		goto loc_82580F10;
	case 29:
		goto loc_82580F10;
	case 30:
		goto loc_82580F10;
	case 31:
		goto loc_82580F10;
	case 32:
		goto loc_82580F10;
	case 33:
		goto loc_82580EB0;
	case 34:
		goto loc_82580F10;
	case 35:
		goto loc_82580F10;
	case 36:
		goto loc_82580F10;
	case 37:
		goto loc_82580F10;
	case 38:
		goto loc_82580F10;
	case 39:
		goto loc_82580F10;
	case 40:
		goto loc_82580F10;
	case 41:
		goto loc_82580F10;
	case 42:
		goto loc_82580F10;
	case 43:
		goto loc_82580F10;
	case 44:
		goto loc_82580F10;
	case 45:
		goto loc_82580F10;
	case 46:
		goto loc_82580D04;
	case 47:
		goto loc_82580CD8;
	case 48:
		goto loc_82580F10;
	default:
		__builtin_unreachable();
	}
	// lwz r18,3708(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3708) );
	// lwz r18,3708(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3708) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3376(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3376) );
	// lwz r18,3448(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3448) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3392(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3392) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3760(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3760) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
	// lwz r18,3332(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3332) );
	// lwz r18,3288(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3288) );
	// lwz r18,3856(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(3856) );
loc_82580CD8:
	// lwz r11,220(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(220) );
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// beq cr6,0x82580f10
	if (cr6.eq) goto loc_82580F10;
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// bne cr6,0x82580f10
	if (!cr6.eq) goto loc_82580F10;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b748
	sub_8240B748(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_82580D04:
	// lwz r11,220(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(220) );
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// beq cr6,0x82580f10
	if (cr6.eq) goto loc_82580F10;
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// bne cr6,0x82580f10
	if (!cr6.eq) goto loc_82580F10;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b650
	sub_8240B650(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_82580D30:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82583140
	sub_82583140(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_82580D40:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,-30828
	ctx.r5.s64 = ctx.r10.s64 + -30828;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r4,26788(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8257eba0
	sub_8257EBA0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_82580D78:
	// lis r30,-31927
	r30.s64 = -2092367872;
	// lwz r11,220(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(220) );
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bne cr6,0x82580e40
	if (!cr6.eq) goto loc_82580E40;
	// bl 0x8259dd48
	sub_8259DD48(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82580e6c
	if (cr6.eq) goto loc_82580E6C;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b0e8
	sub_8240B0E8(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,228(r31)
	PPC_STORE_U32(r31.u32 + 228, r11.u32);
	// addi r4,r31,44
	ctx.r4.s64 = r31.s64 + 44;
	// stw r11,232(r31)
	PPC_STORE_U32(r31.u32 + 232, r11.u32);
	// stw r11,236(r31)
	PPC_STORE_U32(r31.u32 + 236, r11.u32);
	// stw r11,240(r31)
	PPC_STORE_U32(r31.u32 + 240, r11.u32);
	// addi r11,r31,228
	r11.s64 = r31.s64 + 228;
	// stb r10,89(r31)
	PPC_STORE_U8(r31.u32 + 89, ctx.r10.u8);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fda78
	sub_823FDA78(ctx, base);
	// li r9,14
	ctx.r9.s64 = 14;
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// addi r3,r11,68
	ctx.r3.s64 = r11.s64 + 68;
	// bl 0x8247d010
	sub_8247D010(ctx, base);
	// lwz r8,0(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// li r7,2
	ctx.r7.s64 = 2;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,14
	ctx.r4.s64 = 14;
	// stw r7,372(r8)
	PPC_STORE_U32(ctx.r8.u32 + 372, ctx.r7.u32);
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336838
	sub_82336838(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// li r4,14
	ctx.r4.s64 = 14;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336598
	sub_82336598(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336d70
	sub_82336D70(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_82580E40:
	// bl 0x8259dd48
	sub_8259DD48(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82580e6c
	if (cr6.eq) goto loc_82580E6C;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b000
	sub_8240B000(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// addi r4,r31,44
	ctx.r4.s64 = r31.s64 + 44;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// bl 0x823fda78
	sub_823FDA78(ctx, base);
loc_82580E6C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82583340
	sub_82583340(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_82580E7C:
	// lbz r11,88(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 88);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82580f10
	if (cr6.eq) goto loc_82580F10;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,48
	ctx.r3.s64 = r31.s64 + 48;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r6,152(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x828ce240
	sub_828CE240(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_82580EB0:
	// lbz r11,184(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 184);
	// addi r10,r31,92
	ctx.r10.s64 = r31.s64 + 92;
	// cntlzw r9,r11
	ctx.r9.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// stb r8,184(r31)
	PPC_STORE_U8(r31.u32 + 184, ctx.r8.u8);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82580ef8
	if (cr6.eq) goto loc_82580EF8;
	// li r11,1
	r11.s64 = 1;
	// li r9,0
	ctx.r9.s64 = 0;
	// stb r11,68(r10)
	PPC_STORE_U8(ctx.r10.u32 + 68, r11.u8);
	// lis r8,-32246
	ctx.r8.s64 = -2113273856;
	// stb r9,69(r10)
	PPC_STORE_U8(ctx.r10.u32 + 69, ctx.r9.u8);
	// addi r11,r10,28
	r11.s64 = ctx.r10.s64 + 28;
	// addi r3,r11,52
	ctx.r3.s64 = r11.s64 + 52;
	// lfs f1,-27468(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -27468);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82834498
	sub_82834498(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_82580EF8:
	// li r11,0
	r11.s64 = 0;
	// addi r9,r10,28
	ctx.r9.s64 = ctx.r10.s64 + 28;
	// stb r11,68(r10)
	PPC_STORE_U8(ctx.r10.u32 + 68, r11.u8);
	// stb r11,69(r10)
	PPC_STORE_U8(ctx.r10.u32 + 69, r11.u8);
	// stb r11,80(r10)
	PPC_STORE_U8(ctx.r10.u32 + 80, r11.u8);
	// stb r11,81(r10)
	PPC_STORE_U8(ctx.r10.u32 + 81, r11.u8);
loc_82580F10:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82580BB8) {
	__imp__sub_82580BB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82580F18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
	// lwz r4,26788(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,28(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(28) );
	// lwz r11,40(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(40) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x82580f6c
	if (!cr6.eq) goto loc_82580F6C;
	// cmpwi cr6,r9,36
	cr6.compare<int32_t>(ctx.r9.s32, 36, xer);
	// bne cr6,0x82580f6c
	if (!cr6.eq) goto loc_82580F6C;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x823380c0
	sub_823380C0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82580F6C:
	// addi r31,r3,264
	r31.s64 = ctx.r3.s64 + 264;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x82580fdc
	if (!cr6.eq) goto loc_82580FDC;
	// cmpwi cr6,r9,46
	cr6.compare<int32_t>(ctx.r9.s32, 46, xer);
	// bne cr6,0x82580fdc
	if (!cr6.eq) goto loc_82580FDC;
	// lbz r11,4(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82580f9c
	if (!cr6.eq) goto loc_82580F9C;
	// lbz r11,5(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 5);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq cr6,0x82580fa0
	if (cr6.eq) goto loc_82580FA0;
loc_82580F9C:
	// li r11,0
	r11.s64 = 0;
loc_82580FA0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82580fdc
	if (cr6.eq) goto loc_82580FDC;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-30828
	ctx.r5.s64 = r11.s64 + -30828;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(16) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82580FDC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82580F18) {
	__imp__sub_82580F18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82580FF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// li r24,0
	r24.s64 = 0;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82581048
	if (cr6.eq) goto loc_82581048;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82581044
	if (cr6.eq) goto loc_82581044;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8258104c
	goto loc_8258104C;
loc_82581044:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82581048:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_8258104C:
	// lwz r9,36(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// rlwinm r8,r9,17,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 17) & 0x1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82581144
	if (cr6.eq) goto loc_82581144;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82581088
	if (cr6.eq) goto loc_82581088;
	// lbz r10,15(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 15);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r11,1
	r11.s64 = 1;
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x82581148
	goto loc_82581148;
loc_82581088:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r24,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r24.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825810f4
	if (!cr0.gt) goto loc_825810F4;
loc_825810A4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,15
	cr6.compare<int32_t>(ctx.r7.s32, 15, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825810c4
	if (cr6.lt) goto loc_825810C4;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
loc_825810C4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825810e0
	if (cr6.eq) goto loc_825810E0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825810e8
	goto loc_825810E8;
loc_825810E0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825810E8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825810a4
	if (cr6.gt) goto loc_825810A4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_825810F4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82581134
	if (cr6.eq) goto loc_82581134;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82581110
	if (cr6.gt) goto loc_82581110;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82581110:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82581134
	if (!cr6.eq) goto loc_82581134;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x82581148
	goto loc_82581148;
loc_82581134:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x82581148
	goto loc_82581148;
loc_82581144:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82581148:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// stw r24,244(r30)
	PPC_STORE_U32(r30.u32 + 244, r24.u32);
	// stw r24,248(r30)
	PPC_STORE_U32(r30.u32 + 248, r24.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r24,252(r30)
	PPC_STORE_U32(r30.u32 + 252, r24.u32);
	// stw r24,256(r30)
	PPC_STORE_U32(r30.u32 + 256, r24.u32);
	// bne cr6,0x82581170
	if (!cr6.eq) goto loc_82581170;
	// addi r11,r30,244
	r11.s64 = r30.s64 + 244;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	return;
loc_82581170:
	// stw r24,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r24.u32);
	// addi r25,r30,244
	r25.s64 = r30.s64 + 244;
	// stw r24,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r24.u32);
	// addi r31,r10,12
	r31.s64 = ctx.r10.s64 + 12;
	// stw r24,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r24.u32);
	// lwz r30,16(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(16) );
	// lwz r11,20(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(20) );
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// ble cr6,0x82581198
	if (!cr6.gt) goto loc_82581198;
	// twi 31,r0,22
loc_82581198:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// ble cr6,0x825811ac
	if (!cr6.gt) goto loc_825811AC;
	// twi 31,r0,22
loc_825811AC:
	// cmplw cr6,r31,r31
	cr6.compare<uint32_t>(r31.u32, r31.u32, xer);
	// beq cr6,0x825811b8
	if (cr6.eq) goto loc_825811B8;
	// twi 31,r0,22
loc_825811B8:
	// cmplw cr6,r30,r10
	cr6.compare<uint32_t>(r30.u32, ctx.r10.u32, xer);
	// beq cr6,0x82581208
	if (cr6.eq) goto loc_82581208;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x825811cc
	if (cr6.lt) goto loc_825811CC;
	// twi 31,r0,22
loc_825811CC:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825811f0
	if (cr6.eq) goto loc_825811F0;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(16) );
	// cmpw cr6,r11,r29
	cr6.compare<int32_t>(r11.s32, r29.s32, xer);
	// bne cr6,0x825811f0
	if (!cr6.eq) goto loc_825811F0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82576f48
	sub_82576F48(ctx, base);
loc_825811F0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x82581200
	if (cr6.lt) goto loc_82581200;
	// twi 31,r0,22
loc_82581200:
	// addi r30,r30,24
	r30.s64 = r30.s64 + 24;
	// b 0x82581198
	goto loc_82581198;
loc_82581208:
	// lwz r31,100(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r28,104(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(104) );
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// ble cr6,0x8258121c
	if (!cr6.gt) goto loc_8258121C;
	// twi 31,r0,22
loc_8258121C:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r26,r11,-28544
	r26.s64 = r11.s64 + -28544;
	// ld r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lwz r27,80(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// lwz r30,84(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
loc_82581240:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// ble cr6,0x8258124c
	if (!cr6.gt) goto loc_8258124C;
	// twi 31,r0,22
loc_8258124C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82581260
	if (cr6.eq) goto loc_82581260;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// beq cr6,0x82581264
	if (cr6.eq) goto loc_82581264;
loc_82581260:
	// twi 31,r0,22
loc_82581264:
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// beq cr6,0x82581338
	if (cr6.eq) goto loc_82581338;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x82581278
	if (!cr6.eq) goto loc_82581278;
	// twi 31,r0,22
loc_82581278:
	// lwz r29,8(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// blt cr6,0x82581288
	if (cr6.lt) goto loc_82581288;
	// twi 31,r0,22
loc_82581288:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825812bc
	if (cr6.eq) goto loc_825812BC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x822a97a8
	sub_822A97A8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x825812d0
	if (!cr6.eq) goto loc_825812D0;
loc_825812BC:
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// blt cr6,0x825812c8
	if (cr6.lt) goto loc_825812C8;
	// twi 31,r0,22
loc_825812C8:
	// addi r30,r30,16
	r30.s64 = r30.s64 + 16;
	// b 0x82581240
	goto loc_82581240;
loc_825812D0:
	// cmplw cr6,r25,r30
	cr6.compare<uint32_t>(r25.u32, r30.u32, xer);
	// beq cr6,0x825812ec
	if (cr6.eq) goto loc_825812EC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8218df70
	sub_8218DF70(ctx, base);
	// lwz r28,104(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(104) );
	// lwz r31,100(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
loc_825812EC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8258137c
	if (cr6.eq) goto loc_8258137C;
	// mr r30,r28
	r30.u64 = r28.u64;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82581374
	if (cr6.eq) goto loc_82581374;
loc_82581300:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82581314
	if (cr6.eq) goto loc_82581314;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_82581314:
	// stw r24,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r24.u32);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// bne cr6,0x82581300
	if (!cr6.eq) goto loc_82581300;
	// lwz r31,100(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	return;
loc_82581338:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8258137c
	if (cr6.eq) goto loc_8258137C;
	// mr r30,r28
	r30.u64 = r28.u64;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82581374
	if (cr6.eq) goto loc_82581374;
loc_8258134C:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82581360
	if (cr6.eq) goto loc_82581360;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_82581360:
	// stw r24,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r24.u32);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// bne cr6,0x8258134c
	if (!cr6.eq) goto loc_8258134C;
	// lwz r31,100(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
loc_82581374:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_8258137C:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_82580FF0) {
	__imp__sub_82580FF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82581388) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(4) );
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// ble cr6,0x8258139c
	if (!cr6.gt) goto loc_8258139C;
	// twi 31,r0,22
loc_8258139C:
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// addi r10,r11,-4
	ctx.r10.s64 = r11.s64 + -4;
	// stw r3,-16(r1)
	PPC_STORE_U32(ctx.r1.u32 + -16, ctx.r3.u32);
	// stw r11,-12(r1)
	PPC_STORE_U32(ctx.r1.u32 + -12, r11.u32);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ld r8,-16(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// std r8,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r8.u64);
	// bgt cr6,0x825813c8
	if (cr6.gt) goto loc_825813C8;
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(4) );
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x825813cc
	if (!cr6.lt) goto loc_825813CC;
loc_825813C8:
	// twi 31,r0,22
loc_825813CC:
	// lwz r10,-16(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-16) );
	// addi r3,r11,-4
	ctx.r3.s64 = r11.s64 + -4;
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(8) );
	// cmplw cr6,r3,r9
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, xer);
	// bltlr cr6
	if (cr6.lt) return;
	// twi 31,r0,22
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82581388) {
	__imp__sub_82581388(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825813E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,16383
	r11.s64 = 1073676288;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// ori r10,r11,65535
	ctx.r10.u64 = r11.u64 | 65535;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplw cr6,r30,r10
	cr6.compare<uint32_t>(r30.u32, ctx.r10.u32, xer);
	// ble cr6,0x8258141c
	if (!cr6.gt) goto loc_8258141C;
	// bl 0x82684b38
	sub_82684B38(ctx, base);
	// b 0x82581440
	goto loc_82581440;
loc_8258141C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82333f78
	sub_82333F78(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r10,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r10.u32);
loc_82581440:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825813E8) {
	__imp__sub_825813E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82581460) {
	PPC_FUNC_PROLOGUE();
	// b 0x82846778
	sub_82846778(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82581460) {
	__imp__sub_82581460(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82581468) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r4,r11,-30364
	ctx.r4.s64 = r11.s64 + -30364;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r29,152(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825814bc
	if (cr6.eq) goto loc_825814BC;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(152) );
	// bl 0x823f9040
	sub_823F9040(ctx, base);
loc_825814BC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82581468) {
	__imp__sub_82581468(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825814C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,28(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825814e4
	if (!cr6.eq) goto loc_825814E4;
	// lbz r11,29(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 29);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// beq cr6,0x825814e8
	if (cr6.eq) goto loc_825814E8;
loc_825814E4:
	// li r11,1
	r11.s64 = 1;
loc_825814E8:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825814C8) {
	__imp__sub_825814C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825814F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// lbz r11,29(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 29);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82581520
	if (!cr6.eq) goto loc_82581520;
	// li r4,4
	ctx.r4.s64 = 4;
loc_82581520:
	// bl 0x82581468
	sub_82581468(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r11,29(r31)
	PPC_STORE_U8(r31.u32 + 29, r11.u8);
	// lis r9,-31927
	ctx.r9.s64 = -2092367872;
	// stb r10,28(r31)
	PPC_STORE_U8(r31.u32 + 28, ctx.r10.u8);
	// lis r8,-31926
	ctx.r8.s64 = -2092302336;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r8,-30368
	ctx.r4.s64 = ctx.r8.s64 + -30368;
	// lwz r11,26788(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(26788) );
	// lwz r7,56(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r3,152(r7)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(152) );
	// bl 0x828374b8
	sub_828374B8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825814F0) {
	__imp__sub_825814F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82581570) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// li r11,0
	r11.s64 = 0;
	// li r4,5
	ctx.r4.s64 = 5;
	// stb r11,28(r3)
	PPC_STORE_U8(ctx.r3.u32 + 28, r11.u8);
	// b 0x82581468
	sub_82581468(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82581570) {
	__imp__sub_82581570(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82581580) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,29(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 29);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bnelr cr6
	if (!cr6.eq) return;
	// li r11,1
	r11.s64 = 1;
	// li r4,2
	ctx.r4.s64 = 2;
	// stb r11,29(r3)
	PPC_STORE_U8(ctx.r3.u32 + 29, r11.u8);
	// b 0x82581468
	sub_82581468(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82581580) {
	__imp__sub_82581580(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258159C) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258159C) {
	__imp__sub_8258159C(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825815A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82583560
	sub_82583560(ctx, base);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(24) );
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825815A0) {
	__imp__sub_825815A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825815E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,24(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(24) );
	// addi r31,r3,24
	r31.s64 = ctx.r3.s64 + 24;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi r9,r3,24
	ctx.r9.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8258162c
	if (!cr6.eq) goto loc_8258162C;
	// cmpwi cr6,r30,36
	cr6.compare<int32_t>(r30.s32, 36, xer);
	// bne cr6,0x8258162c
	if (!cr6.eq) goto loc_8258162C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x828460c0
	sub_828460C0(ctx, base);
loc_8258162C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825815E0) {
	__imp__sub_825815E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82581648) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r30,0
	r30.s64 = 0;
	// lis r10,-32242
	ctx.r10.s64 = -2113011712;
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r8,r11,1220
	ctx.r8.s64 = r11.s64 + 1220;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// addi r7,r10,9776
	ctx.r7.s64 = ctx.r10.s64 + 9776;
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// li r5,-1
	ctx.r5.s64 = -1;
	// stw r8,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r8.u32);
	// lfs f31,-27468(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -27468);
	f31.f64 = double(temp.f32);
	// stw r30,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r30.u32);
	// li r4,-1
	ctx.r4.s64 = -1;
	// stw r30,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r30.u32);
	// addi r29,r31,104
	r29.s64 = r31.s64 + 104;
	// stw r30,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r30.u32);
	// addi r11,r31,52
	r11.s64 = r31.s64 + 52;
	// stw r30,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r30.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r30,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r30.u32);
	// addi r11,r31,32
	r11.s64 = r31.s64 + 32;
	// stw r7,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r7.u32);
	// stfs f31,52(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 52, temp.u32);
	// stw r30,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r30.u32);
	// stw r30,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r30.u32);
	// stw r30,68(r31)
	PPC_STORE_U32(r31.u32 + 68, r30.u32);
	// stw r30,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r30.u32);
	// stw r30,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r30.u32);
	// stw r30,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r30.u32);
	// stw r30,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r30.u32);
	// stb r30,92(r31)
	PPC_STORE_U8(r31.u32 + 92, r30.u8);
	// stb r6,93(r31)
	PPC_STORE_U8(r31.u32 + 93, ctx.r6.u8);
	// stw r5,96(r31)
	PPC_STORE_U32(r31.u32 + 96, ctx.r5.u32);
	// stw r4,100(r31)
	PPC_STORE_U32(r31.u32 + 100, ctx.r4.u32);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r11,-32242
	r11.s64 = -2113011712;
	// stw r30,132(r31)
	PPC_STORE_U32(r31.u32 + 132, r30.u32);
	// addi r3,r29,36
	ctx.r3.s64 = r29.s64 + 36;
	// addi r10,r11,11100
	ctx.r10.s64 = r11.s64 + 11100;
	// stw r30,136(r31)
	PPC_STORE_U32(r31.u32 + 136, r30.u32);
	// stw r10,104(r31)
	PPC_STORE_U32(r31.u32 + 104, ctx.r10.u32);
	// bl 0x82885d68
	sub_82885D68(ctx, base);
	// addi r3,r29,92
	ctx.r3.s64 = r29.s64 + 92;
	// bl 0x82885d68
	sub_82885D68(ctx, base);
	// addi r3,r31,252
	ctx.r3.s64 = r31.s64 + 252;
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r9,-32242
	ctx.r9.s64 = -2113011712;
	// stw r30,280(r31)
	PPC_STORE_U32(r31.u32 + 280, r30.u32);
	// addi r29,r31,288
	r29.s64 = r31.s64 + 288;
	// addi r8,r9,11676
	ctx.r8.s64 = ctx.r9.s64 + 11676;
	// stw r30,284(r31)
	PPC_STORE_U32(r31.u32 + 284, r30.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r8,252(r31)
	PPC_STORE_U32(r31.u32 + 252, ctx.r8.u32);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r7,-32242
	ctx.r7.s64 = -2113011712;
	// stw r30,316(r31)
	PPC_STORE_U32(r31.u32 + 316, r30.u32);
	// addi r3,r29,36
	ctx.r3.s64 = r29.s64 + 36;
	// addi r6,r7,12084
	ctx.r6.s64 = ctx.r7.s64 + 12084;
	// stw r30,320(r31)
	PPC_STORE_U32(r31.u32 + 320, r30.u32);
	// stw r6,288(r31)
	PPC_STORE_U32(r31.u32 + 288, ctx.r6.u32);
	// bl 0x82885d68
	sub_82885D68(ctx, base);
	// stfs f31,380(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 380, temp.u32);
	// addi r3,r31,384
	ctx.r3.s64 = r31.s64 + 384;
	// bl 0x828d40a8
	sub_828D40A8(ctx, base);
	// addi r3,r31,428
	ctx.r3.s64 = r31.s64 + 428;
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r5,-32242
	ctx.r5.s64 = -2113011712;
	// stb r30,456(r31)
	PPC_STORE_U8(r31.u32 + 456, r30.u8);
	// addi r3,r31,464
	ctx.r3.s64 = r31.s64 + 464;
	// addi r4,r5,15480
	ctx.r4.s64 = ctx.r5.s64 + 15480;
	// stw r30,460(r31)
	PPC_STORE_U32(r31.u32 + 460, r30.u32);
	// stw r4,428(r31)
	PPC_STORE_U32(r31.u32 + 428, ctx.r4.u32);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r11,-32242
	r11.s64 = -2113011712;
	// addi r3,r31,492
	ctx.r3.s64 = r31.s64 + 492;
	// addi r10,r11,16020
	ctx.r10.s64 = r11.s64 + 16020;
	// stw r10,464(r31)
	PPC_STORE_U32(r31.u32 + 464, ctx.r10.u32);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r9,-32242
	ctx.r9.s64 = -2113011712;
	// addi r3,r31,520
	ctx.r3.s64 = r31.s64 + 520;
	// addi r8,r9,16536
	ctx.r8.s64 = ctx.r9.s64 + 16536;
	// stw r8,492(r31)
	PPC_STORE_U32(r31.u32 + 492, ctx.r8.u32);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r7,-32242
	ctx.r7.s64 = -2113011712;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r6,r7,16776
	ctx.r6.s64 = ctx.r7.s64 + 16776;
	// stw r6,520(r31)
	PPC_STORE_U32(r31.u32 + 520, ctx.r6.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82581648) {
	__imp__sub_82581648(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825817D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82581968
	sub_82581968(ctx, base);
	// clrlwi r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82581808
	if (cr6.eq) goto loc_82581808;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82581808:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825817D0) {
	__imp__sub_825817D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82581820) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r31,92
	r30.s64 = r31.s64 + 92;
	// addi r3,r30,36
	ctx.r3.s64 = r30.s64 + 36;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r30,8
	ctx.r3.s64 = r30.s64 + 8;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r30,r31,36
	r30.s64 = r31.s64 + 36;
	// addi r3,r30,36
	ctx.r3.s64 = r30.s64 + 36;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r30,8
	ctx.r3.s64 = r30.s64 + 8;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r10,r11,-4548
	ctx.r10.s64 = r11.s64 + -4548;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(12) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r9,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82581820) {
	__imp__sub_82581820(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825818A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r31,36
	r30.s64 = r31.s64 + 36;
	// addi r3,r30,36
	ctx.r3.s64 = r30.s64 + 36;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r30,8
	ctx.r3.s64 = r30.s64 + 8;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r10,r11,-4548
	ctx.r10.s64 = r11.s64 + -4548;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(12) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r9,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825818A0) {
	__imp__sub_825818A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82581908) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r31,40
	ctx.r3.s64 = r31.s64 + 40;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r31,28
	ctx.r3.s64 = r31.s64 + 28;
	// bl 0x8292bb38
	sub_8292BB38(ctx, base);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r10,r11,-4548
	ctx.r10.s64 = r11.s64 + -4548;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(12) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r9,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r9.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82581908) {
	__imp__sub_82581908(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82581968) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// addi r11,r31,520
	r11.s64 = r31.s64 + 520;
	// addi r29,r10,-4548
	r29.s64 = ctx.r10.s64 + -4548;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// stw r29,520(r31)
	PPC_STORE_U32(r31.u32 + 520, r29.u32);
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,532(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(532) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// addi r11,r31,492
	r11.s64 = r31.s64 + 492;
	// stw r30,532(r31)
	PPC_STORE_U32(r31.u32 + 532, r30.u32);
	// stw r29,492(r31)
	PPC_STORE_U32(r31.u32 + 492, r29.u32);
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,504(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(504) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,504(r31)
	PPC_STORE_U32(r31.u32 + 504, r30.u32);
	// stw r29,464(r31)
	PPC_STORE_U32(r31.u32 + 464, r29.u32);
	// addi r11,r31,464
	r11.s64 = r31.s64 + 464;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,476(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(476) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,476(r31)
	PPC_STORE_U32(r31.u32 + 476, r30.u32);
	// stw r29,428(r31)
	PPC_STORE_U32(r31.u32 + 428, r29.u32);
	// addi r11,r31,428
	r11.s64 = r31.s64 + 428;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,440(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(440) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,440(r31)
	PPC_STORE_U32(r31.u32 + 440, r30.u32);
	// addi r3,r31,384
	ctx.r3.s64 = r31.s64 + 384;
	// bl 0x82581908
	sub_82581908(ctx, base);
	// addi r3,r31,288
	ctx.r3.s64 = r31.s64 + 288;
	// bl 0x825818a0
	sub_825818A0(ctx, base);
	// stw r29,252(r31)
	PPC_STORE_U32(r31.u32 + 252, r29.u32);
	// addi r11,r31,252
	r11.s64 = r31.s64 + 252;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,264(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(264) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,264(r31)
	PPC_STORE_U32(r31.u32 + 264, r30.u32);
	// addi r3,r31,104
	ctx.r3.s64 = r31.s64 + 104;
	// bl 0x82581820
	sub_82581820(ctx, base);
	// addi r3,r31,52
	ctx.r3.s64 = r31.s64 + 52;
	// bl 0x8257cc98
	sub_8257CC98(ctx, base);
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r11,r31,32
	r11.s64 = r31.s64 + 32;
	// addi r8,r9,12052
	ctx.r8.s64 = ctx.r9.s64 + 12052;
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// stw r8,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r8.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// lis r7,-32246
	ctx.r7.s64 = -2113273856;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r6,r7,23084
	ctx.r6.s64 = ctx.r7.s64 + 23084;
	// stw r6,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r6.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82581968) {
	__imp__sub_82581968(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82581A68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// li r28,0
	r28.s64 = 0;
	// li r9,-1
	ctx.r9.s64 = -1;
	// li r8,-1
	ctx.r8.s64 = -1;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// stw r9,96(r30)
	PPC_STORE_U32(r30.u32 + 96, ctx.r9.u32);
	// cmpwi cr6,r7,2
	cr6.compare<int32_t>(ctx.r7.s32, 2, xer);
	// stw r8,100(r30)
	PPC_STORE_U32(r30.u32 + 100, ctx.r8.u32);
	// stw r28,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r28.u32);
	// stw r28,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r28.u32);
	// bne cr6,0x82581b04
	if (!cr6.eq) goto loc_82581B04;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,1156
	ctx.r4.s64 = r11.s64 + 1156;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r29,r11,26788
	r29.s64 = r11.s64 + 26788;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r31,r30,384
	r31.s64 = r30.s64 + 384;
	// lwz r4,24(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(24) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x828d4298
	sub_828D4298(ctx, base);
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// b 0x82581d3c
	goto loc_82581D3C;
loc_82581B04:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r4,7
	ctx.r4.s64 = 7;
	// addi r29,r11,26788
	r29.s64 = r11.s64 + 26788;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b218
	sub_8240B218(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r3,0(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// bne cr6,0x82581b48
	if (!cr6.eq) goto loc_82581B48;
	// bl 0x8222c210
	sub_8222C210(ctx, base);
	// b 0x82581b4c
	goto loc_82581B4C;
loc_82581B48:
	// bl 0x828beec0
	sub_828BEEC0(ctx, base);
loc_82581B4C:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r30,104
	r11.s64 = r30.s64 + 104;
	// stw r31,132(r30)
	PPC_STORE_U32(r30.u32 + 132, r31.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r10,r30,252
	ctx.r10.s64 = r30.s64 + 252;
	// stw r31,280(r30)
	PPC_STORE_U32(r30.u32 + 280, r31.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r9,r30,288
	ctx.r9.s64 = r30.s64 + 288;
	// stw r31,316(r30)
	PPC_STORE_U32(r30.u32 + 316, r31.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82581bb4
	if (cr6.eq) goto loc_82581BB4;
	// lbz r11,144(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82581bb8
	if (!cr6.eq) goto loc_82581BB8;
loc_82581BB4:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82581BB8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82581ce4
	if (cr6.eq) goto loc_82581CE4;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(40) );
	// mr r11,r28
	r11.u64 = r28.u64;
	// rlwinm r9,r10,7,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82581cbc
	if (cr6.eq) goto loc_82581CBC;
	// lwz r11,140(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82581c00
	if (cr6.eq) goto loc_82581C00;
	// lbz r10,57(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 57);
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x82581cc0
	goto loc_82581CC0;
loc_82581C00:
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(72) );
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + int32_t(76) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82581c6c
	if (!cr0.gt) goto loc_82581C6C;
loc_82581C1C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,57
	cr6.compare<int32_t>(ctx.r7.s32, 57, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82581c3c
	if (cr6.lt) goto loc_82581C3C;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_82581C3C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82581c58
	if (cr6.eq) goto loc_82581C58;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82581c60
	goto loc_82581C60;
loc_82581C58:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82581C60:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82581c1c
	if (cr6.gt) goto loc_82581C1C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82581C6C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82581cac
	if (cr6.eq) goto loc_82581CAC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,57
	cr6.compare<int32_t>(r11.s32, 57, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82581c88
	if (cr6.gt) goto loc_82581C88;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82581C88:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82581cac
	if (!cr6.eq) goto loc_82581CAC;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82581cc0
	goto loc_82581CC0;
loc_82581CAC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82581cc0
	goto loc_82581CC0;
loc_82581CBC:
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
loc_82581CC0:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82581ce4
	if (cr6.eq) goto loc_82581CE4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bne cr6,0x82581cdc
	if (!cr6.eq) goto loc_82581CDC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
loc_82581CDC:
	// addi r3,r30,384
	ctx.r3.s64 = r30.s64 + 384;
	// bl 0x828d4298
	sub_828D4298(ctx, base);
loc_82581CE4:
	// addi r11,r30,384
	r11.s64 = r30.s64 + 384;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r10,r30,428
	ctx.r10.s64 = r30.s64 + 428;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r9,r30,464
	ctx.r9.s64 = r30.s64 + 464;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r8,r30,492
	ctx.r8.s64 = r30.s64 + 492;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r7,r30,520
	ctx.r7.s64 = r30.s64 + 520;
	// stw r7,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r7.u32);
loc_82581D3C:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(0) );
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r10,-30148
	ctx.r5.s64 = ctx.r10.s64 + -30148;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// addi r3,r30,52
	ctx.r3.s64 = r30.s64 + 52;
	// lwz r6,152(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x828ce060
	sub_828CE060(ctx, base);
	// lwz r8,32(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + int32_t(32) );
	// addi r3,r30,32
	ctx.r3.s64 = r30.s64 + 32;
	// stb r28,93(r30)
	PPC_STORE_U8(r30.u32 + 93, r28.u8);
	// lwz r7,4(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(4) );
	// mtctr r7
	ctr.u64 = ctx.r7.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r6,-32245
	ctx.r6.s64 = -2113208320;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r6,-5460
	ctx.r4.s64 = ctx.r6.s64 + -5460;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82582658
	sub_82582658(ctx, base);
	// clrlwi r5,r3,24
	ctx.r5.u64 = ctx.r3.u32 & 0xFF;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// cntlzw r11,r5
	r11.u64 = ctx.r5.u32 == 0 ? 32 : __builtin_clz(ctx.r5.u32);
	// li r3,16
	ctx.r3.s64 = 16;
	// rlwinm r5,r11,27,31,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r6,0
	ctx.r6.s64 = 0;
	// bl 0x8283f948
	sub_8283F948(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(0) );
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r10,-30144
	ctx.r4.s64 = ctx.r10.s64 + -30144;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r3,152(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x82837218
	sub_82837218(ctx, base);
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82581df0
	if (cr6.eq) goto loc_82581DF0;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_82581DF0:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82581A68) {
	__imp__sub_82581A68(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82581DF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc0
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x82583560
	sub_82583560(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r20,0
	r20.s64 = 0;
	// addi r8,r11,28344
	ctx.r8.s64 = r11.s64 + 28344;
	// stw r20,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r20.u32);
	// stw r20,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r20.u32);
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// stw r20,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r20.u32);
loc_82581E28:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r7
	reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r7
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x82581e28
	if (!cr0.eq) goto loc_82581E28;
	// stw r20,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r20.u32);
loc_82581E48:
	// mfmsr r5
	// mtmsrd r13,1
	// lwarx r6,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r6.u64 = __builtin_bswap32(reserved.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// stwcx. r6,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r6.s32));
	cr0.so = xer.so;
	// mtmsrd r5,1
	// bne 0x82581e48
	if (!cr0.eq) goto loc_82581E48;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(60) );
	// bl 0x8259db00
	sub_8259DB00(ctx, base);
	// lwz r11,96(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(96) );
	// lwz r19,112(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// cmpw cr6,r11,r19
	cr6.compare<int32_t>(r11.s32, r19.s32, xer);
	// beq cr6,0x82582230
	if (cr6.eq) goto loc_82582230;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r10,-30140
	ctx.r4.s64 = ctx.r10.s64 + -30140;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r31,152(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// lis r8,-31926
	ctx.r8.s64 = -2092302336;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r4,r8,-30136
	ctx.r4.s64 = ctx.r8.s64 + -30136;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// lis r7,-31926
	ctx.r7.s64 = -2092302336;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r4,r7,-30132
	ctx.r4.s64 = ctx.r7.s64 + -30132;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// lis r6,-31926
	ctx.r6.s64 = -2092302336;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// addi r4,r6,-30128
	ctx.r4.s64 = ctx.r6.s64 + -30128;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// lis r5,-31926
	ctx.r5.s64 = -2092302336;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r4,r5,-30124
	ctx.r4.s64 = ctx.r5.s64 + -30124;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// lis r4,-31926
	ctx.r4.s64 = -2092302336;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// addi r4,r4,-30108
	ctx.r4.s64 = ctx.r4.s64 + -30108;
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// addi r4,r11,-30116
	ctx.r4.s64 = r11.s64 + -30116;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// addi r4,r10,-30112
	ctx.r4.s64 = ctx.r10.s64 + -30112;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// cmpwi cr6,r19,301
	cr6.compare<int32_t>(r19.s32, 301, xer);
	// beq cr6,0x82581fac
	if (cr6.eq) goto loc_82581FAC;
	// cmpwi cr6,r19,150
	cr6.compare<int32_t>(r19.s32, 150, xer);
	// beq cr6,0x82581fac
	if (cr6.eq) goto loc_82581FAC;
	// cmpwi cr6,r19,68
	cr6.compare<int32_t>(r19.s32, 68, xer);
	// bne cr6,0x82581fa4
	if (!cr6.eq) goto loc_82581FA4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82582658
	sub_82582658(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82581fac
	if (cr6.eq) goto loc_82581FAC;
loc_82581FA4:
	// li r11,1
	r11.s64 = 1;
	// b 0x82581fb0
	goto loc_82581FB0;
loc_82581FAC:
	// mr r11,r20
	r11.u64 = r20.u64;
loc_82581FB0:
	// clrlwi r29,r11,24
	r29.u64 = r11.u32 & 0xFF;
	// addi r18,r30,52
	r18.s64 = r30.s64 + 52;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x828ce4e8
	sub_828CE4E8(ctx, base);
	// stw r19,96(r30)
	PPC_STORE_U32(r30.u32 + 96, r19.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82582054
	if (cr6.eq) goto loc_82582054;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
loc_82582054:
	// addi r11,r19,-60
	r11.s64 = r19.s64 + -60;
	// cmplwi cr6,r11,9
	cr6.compare<uint32_t>(r11.u32, 9, xer);
	// bgt cr6,0x82582210
	if (cr6.gt) goto loc_82582210;
	// lis r12,-32168
	r12.s64 = -2108162048;
	// addi r12,r12,8312
	r12.s64 = r12.s64 + 8312;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_825820A0;
	case 1:
		goto loc_8258218C;
	case 2:
		goto loc_825821B8;
	case 3:
		goto loc_82582210;
	case 4:
		goto loc_825820A0;
	case 5:
		goto loc_825820CC;
	case 6:
		goto loc_825820F8;
	case 7:
		goto loc_82582124;
	case 8:
		goto loc_82582158;
	case 9:
		goto loc_825821E4;
	default:
		__builtin_unreachable();
	}
	// lwz r18,8352(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(8352) );
	// lwz r18,8588(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(8588) );
	// lwz r18,8632(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(8632) );
	// lwz r18,8720(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(8720) );
	// lwz r18,8352(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(8352) );
	// lwz r18,8396(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(8396) );
	// lwz r18,8440(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(8440) );
	// lwz r18,8484(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(8484) );
	// lwz r18,8536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(8536) );
	// lwz r18,8676(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(8676) );
loc_825820A0:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82582210
	if (cr6.eq) goto loc_82582210;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// addi r3,r30,76
	ctx.r3.s64 = r30.s64 + 76;
	// bl 0x82581388
	sub_82581388(ctx, base);
	// stw r20,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r20.u32);
	// b 0x82582210
	goto loc_82582210;
loc_825820CC:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82582210
	if (cr6.eq) goto loc_82582210;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// addi r3,r30,76
	ctx.r3.s64 = r30.s64 + 76;
	// bl 0x82581388
	sub_82581388(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// b 0x8258220c
	goto loc_8258220C;
loc_825820F8:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82582210
	if (cr6.eq) goto loc_82582210;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// addi r3,r30,76
	ctx.r3.s64 = r30.s64 + 76;
	// bl 0x82581388
	sub_82581388(ctx, base);
	// li r11,2
	r11.s64 = 2;
	// b 0x8258220c
	goto loc_8258220C;
loc_82582124:
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// mr r31,r20
	r31.u64 = r20.u64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82582148
	if (cr6.eq) goto loc_82582148;
	// li r31,3
	r31.s64 = 3;
loc_82582148:
	// addi r3,r30,76
	ctx.r3.s64 = r30.s64 + 76;
	// bl 0x82581388
	sub_82581388(ctx, base);
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// b 0x82582210
	goto loc_82582210;
loc_82582158:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82582230
	if (cr6.eq) goto loc_82582230;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82582210
	if (cr6.eq) goto loc_82582210;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// addi r3,r30,76
	ctx.r3.s64 = r30.s64 + 76;
	// bl 0x82581388
	sub_82581388(ctx, base);
	// li r11,4
	r11.s64 = 4;
	// b 0x8258220c
	goto loc_8258220C;
loc_8258218C:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82582210
	if (cr6.eq) goto loc_82582210;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// addi r3,r30,76
	ctx.r3.s64 = r30.s64 + 76;
	// bl 0x82581388
	sub_82581388(ctx, base);
	// li r11,5
	r11.s64 = 5;
	// b 0x8258220c
	goto loc_8258220C;
loc_825821B8:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82582210
	if (cr6.eq) goto loc_82582210;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// addi r3,r30,76
	ctx.r3.s64 = r30.s64 + 76;
	// bl 0x82581388
	sub_82581388(ctx, base);
	// li r11,6
	r11.s64 = 6;
	// b 0x8258220c
	goto loc_8258220C;
loc_825821E4:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82582210
	if (cr6.eq) goto loc_82582210;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// addi r3,r30,76
	ctx.r3.s64 = r30.s64 + 76;
	// bl 0x82581388
	sub_82581388(ctx, base);
	// li r11,7
	r11.s64 = 7;
loc_8258220C:
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_82582210:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82582230
	if (cr6.eq) goto loc_82582230;
	// addi r3,r30,76
	ctx.r3.s64 = r30.s64 + 76;
	// bl 0x82581388
	sub_82581388(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// bl 0x828ce7c8
	sub_828CE7C8(ctx, base);
loc_82582230:
	// addi r3,r30,52
	ctx.r3.s64 = r30.s64 + 52;
	// bl 0x828ce180
	sub_828CE180(ctx, base);
	// lwz r31,116(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// lwz r11,100(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(100) );
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// beq cr6,0x82582298
	if (cr6.eq) goto loc_82582298;
	// cmpwi cr6,r19,62
	cr6.compare<int32_t>(r19.s32, 62, xer);
	// bne cr6,0x82582274
	if (!cr6.eq) goto loc_82582274;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r30,32
	ctx.r3.s64 = r30.s64 + 32;
	// bl 0x828d2238
	sub_828D2238(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82582288
	if (cr6.eq) goto loc_82582288;
	// addi r3,r30,492
	ctx.r3.s64 = r30.s64 + 492;
	// bl 0x828d6890
	sub_828D6890(ctx, base);
	// b 0x82582288
	goto loc_82582288;
loc_82582274:
	// cmpwi cr6,r19,69
	cr6.compare<int32_t>(r19.s32, 69, xer);
	// bne cr6,0x82582288
	if (!cr6.eq) goto loc_82582288;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r30,520
	ctx.r3.s64 = r30.s64 + 520;
	// bl 0x828d6f38
	sub_828D6F38(ctx, base);
loc_82582288:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r30,464
	ctx.r3.s64 = r30.s64 + 464;
	// bl 0x828d61d0
	sub_828D61D0(ctx, base);
	// stw r31,100(r30)
	PPC_STORE_U32(r30.u32 + 100, r31.u32);
loc_82582298:
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82ca2c10
	return;
}

PPC_WEAK_FUNC(sub_82581DF8) {
	__imp__sub_82581DF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825822B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(4) );
	// cmpwi cr6,r11,140
	cr6.compare<int32_t>(r11.s32, 140, xer);
	// beq cr6,0x82582348
	if (cr6.eq) goto loc_82582348;
	// cmpwi cr6,r11,141
	cr6.compare<int32_t>(r11.s32, 141, xer);
	// beq cr6,0x82582324
	if (cr6.eq) goto loc_82582324;
	// cmpwi cr6,r11,150
	cr6.compare<int32_t>(r11.s32, 150, xer);
	// bne cr6,0x8258236c
	if (!cr6.eq) goto loc_8258236C;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,156(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(156) );
	// bl 0x822641f0
	sub_822641F0(ctx, base);
	// lwz r31,40(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82cbc150
	sub_82CBC150(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8258236c
	if (cr6.eq) goto loc_8258236C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82cbc610
	sub_82CBC610(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82582324:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,-30944
	ctx.r5.s64 = ctx.r10.s64 + -30944;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,26788(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// b 0x82582368
	goto loc_82582368;
loc_82582348:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,-30948
	ctx.r5.s64 = ctx.r10.s64 + -30948;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r4,26788(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
loc_82582368:
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_8258236C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825822B0) {
	__imp__sub_825822B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82582380) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r24{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r29,-26
	r11.s64 = r29.s64 + -26;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// cmplwi cr6,r11,47
	cr6.compare<uint32_t>(r11.u32, 47, xer);
	// bgt cr6,0x82582540
	if (cr6.gt) goto loc_82582540;
	// lis r30,-31927
	r30.s64 = -2092367872;
	// lis r12,-32168
	r12.s64 = -2108162048;
	// addi r12,r12,9152
	r12.s64 = r12.s64 + 9152;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82582524;
	case 1:
		goto loc_82582524;
	case 2:
		goto loc_82582540;
	case 3:
		goto loc_82582540;
	case 4:
		goto loc_82582540;
	case 5:
		goto loc_82582540;
	case 6:
		goto loc_82582540;
	case 7:
		goto loc_82582540;
	case 8:
		goto loc_82582540;
	case 9:
		goto loc_82582540;
	case 10:
		goto loc_825824D8;
	case 11:
		goto loc_825824E8;
	case 12:
		goto loc_82582540;
	case 13:
		goto loc_82582540;
	case 14:
		goto loc_82582540;
	case 15:
		goto loc_82582540;
	case 16:
		goto loc_82582540;
	case 17:
		goto loc_82582540;
	case 18:
		goto loc_82582540;
	case 19:
		goto loc_82582540;
	case 20:
		goto loc_82582540;
	case 21:
		goto loc_82582540;
	case 22:
		goto loc_82582540;
	case 23:
		goto loc_82582540;
	case 24:
		goto loc_82582540;
	case 25:
		goto loc_82582540;
	case 26:
		goto loc_82582540;
	case 27:
		goto loc_82582540;
	case 28:
		goto loc_82582540;
	case 29:
		goto loc_82582540;
	case 30:
		goto loc_82582540;
	case 31:
		goto loc_82582540;
	case 32:
		goto loc_82582540;
	case 33:
		goto loc_82582540;
	case 34:
		goto loc_82582540;
	case 35:
		goto loc_82582540;
	case 36:
		goto loc_82582540;
	case 37:
		goto loc_82582540;
	case 38:
		goto loc_82582540;
	case 39:
		goto loc_82582540;
	case 40:
		goto loc_82582540;
	case 41:
		goto loc_82582540;
	case 42:
		goto loc_82582540;
	case 43:
		goto loc_82582540;
	case 44:
		goto loc_82582540;
	case 45:
		goto loc_82582540;
	case 46:
		goto loc_825824AC;
	case 47:
		goto loc_82582480;
	default:
		__builtin_unreachable();
	}
	// lwz r18,9508(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9508) );
	// lwz r18,9508(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9508) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9432(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9432) );
	// lwz r18,9448(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9448) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9536(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9536) );
	// lwz r18,9388(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9388) );
	// lwz r18,9344(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(9344) );
loc_82582480:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82582540
	if (cr6.eq) goto loc_82582540;
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// bne cr6,0x82582540
	if (!cr6.eq) goto loc_82582540;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b748
	sub_8240B748(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_825824AC:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82582540
	if (cr6.eq) goto loc_82582540;
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// bne cr6,0x82582540
	if (!cr6.eq) goto loc_82582540;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b650
	sub_8240B650(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_825824D8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82583140
	sub_82583140(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_825824E8:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82582548
	if (cr6.eq) goto loc_82582548;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259dd48
	sub_8259DD48(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258251c
	if (cr6.eq) goto loc_8258251C;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b000
	sub_8240B000(ctx, base);
loc_8258251C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82583340
	sub_82583340(ctx, base);
loc_82582524:
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r31,52
	ctx.r3.s64 = r31.s64 + 52;
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r6,152(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(152) );
	// bl 0x828ce240
	sub_828CE240(ctx, base);
loc_82582540:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82582548:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(28) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x825825fc
	if (!cr6.eq) goto loc_825825FC;
	// li r11,22
	r11.s64 = 22;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// addi r3,r11,68
	ctx.r3.s64 = r11.s64 + 68;
	// bl 0x8247d010
	sub_8247D010(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,22
	ctx.r4.s64 = 22;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r30,0(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// bl 0x82336838
	sub_82336838(ctx, base);
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r8,8(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(8) );
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336d70
	sub_82336D70(ctx, base);
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r6,16(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(16) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r4,-32244
	ctx.r4.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r4,120
	ctx.r4.s64 = ctx.r4.s64 + 120;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_825825FC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825832b0
	sub_825832B0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82582380) {
	__imp__sub_82582380(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82582610) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82583490
	sub_82583490(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// addi r3,r31,52
	ctx.r3.s64 = r31.s64 + 52;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// bl 0x828ced00
	sub_828CED00(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82582610) {
	__imp__sub_82582610(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82582658) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,192
	ctx.r3.s64 = r11.s64 + 192;
	// lwz r11,196(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(196) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825826b8
	if (cr6.eq) goto loc_825826B8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825826dc
	if (cr6.eq) goto loc_825826DC;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825826b8
	if (cr6.eq) goto loc_825826B8;
	// lbz r11,144(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x825826bc
	if (!cr6.eq) goto loc_825826BC;
loc_825826B8:
	// li r11,0
	r11.s64 = 0;
loc_825826BC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r3,r9,1
	ctx.r3.u64 = ctx.r9.u64 ^ 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
loc_825826DC:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x825826b8
	goto loc_825826B8;
}

PPC_WEAK_FUNC(sub_82582658) {
	__imp__sub_82582658(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825826E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stfd f29,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, f29.u64);
	// stfd f30,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, f30.u64);
	// stfd f31,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r27,-32246
	r27.s64 = -2113273856;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r10,r27,-2932
	ctx.r10.s64 = r27.s64 + -2932;
	// li r30,0
	r30.s64 = 0;
	// addi r9,r11,1332
	ctx.r9.s64 = r11.s64 + 1332;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// li r29,1
	r29.s64 = 1;
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// addi r28,r31,72
	r28.s64 = r31.s64 + 72;
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// lfs f31,-24536(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -24536);
	f31.f64 = double(temp.f32);
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// addi r11,r31,28
	r11.s64 = r31.s64 + 28;
	// stb r30,24(r31)
	PPC_STORE_U8(r31.u32 + 24, r30.u8);
	// stfs f31,28(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 28, temp.u32);
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// stw r30,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r30.u32);
	// stw r30,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r30.u32);
	// stw r30,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r30.u32);
	// stw r30,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r30.u32);
	// stw r30,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r30.u32);
	// stw r30,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r30.u32);
	// stb r30,68(r31)
	PPC_STORE_U8(r31.u32 + 68, r30.u8);
	// stb r29,69(r31)
	PPC_STORE_U8(r31.u32 + 69, r29.u8);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r8,-32242
	ctx.r8.s64 = -2113011712;
	// addi r3,r28,28
	ctx.r3.s64 = r28.s64 + 28;
	// addi r7,r8,17636
	ctx.r7.s64 = ctx.r8.s64 + 17636;
	// stw r7,72(r31)
	PPC_STORE_U32(r31.u32 + 72, ctx.r7.u32);
	// bl 0x8237c3f0
	sub_8237C3F0(ctx, base);
	// lis r6,-32246
	ctx.r6.s64 = -2113273856;
	// li r5,-1
	ctx.r5.s64 = -1;
	// lfs f29,-2932(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + -2932);
	f29.f64 = double(temp.f32);
	// addi r3,r31,184
	ctx.r3.s64 = r31.s64 + 184;
	// stw r5,112(r31)
	PPC_STORE_U32(r31.u32 + 112, ctx.r5.u32);
	// stfs f31,148(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 148, temp.u32);
	// stfs f31,152(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 152, temp.u32);
	// stw r30,144(r31)
	PPC_STORE_U32(r31.u32 + 144, r30.u32);
	// lfs f30,-18828(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -18828);
	f30.f64 = double(temp.f32);
	// stb r30,156(r31)
	PPC_STORE_U8(r31.u32 + 156, r30.u8);
	// stfs f30,160(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 160, temp.u32);
	// stb r30,157(r31)
	PPC_STORE_U8(r31.u32 + 157, r30.u8);
	// stfs f30,164(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 164, temp.u32);
	// stb r30,176(r31)
	PPC_STORE_U8(r31.u32 + 176, r30.u8);
	// stfs f29,168(r31)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r31.u32 + 168, temp.u32);
	// stb r29,177(r31)
	PPC_STORE_U8(r31.u32 + 177, r29.u8);
	// stfs f29,172(r31)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// stw r29,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r29.u32);
	// bl 0x828d9110
	sub_828D9110(ctx, base);
	// addi r3,r31,312
	ctx.r3.s64 = r31.s64 + 312;
	// bl 0x828d99b0
	sub_828D99B0(ctx, base);
	// addi r3,r31,408
	ctx.r3.s64 = r31.s64 + 408;
	// bl 0x828da1b8
	sub_828DA1B8(ctx, base);
	// stfs f31,520(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 520, temp.u32);
	// stfs f31,524(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 524, temp.u32);
	// stw r30,516(r31)
	PPC_STORE_U32(r31.u32 + 516, r30.u32);
	// stfs f30,532(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 532, temp.u32);
	// stb r30,528(r31)
	PPC_STORE_U8(r31.u32 + 528, r30.u8);
	// stfs f30,536(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 536, temp.u32);
	// stb r30,529(r31)
	PPC_STORE_U8(r31.u32 + 529, r30.u8);
	// stfs f29,540(r31)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r31.u32 + 540, temp.u32);
	// stb r30,548(r31)
	PPC_STORE_U8(r31.u32 + 548, r30.u8);
	// stfs f29,544(r31)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r31.u32 + 544, temp.u32);
	// stb r29,549(r31)
	PPC_STORE_U8(r31.u32 + 549, r29.u8);
	// stw r29,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r29.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f29,-72(r1)
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f30,-64(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f31,-56(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_825826E8) {
	__imp__sub_825826E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82582828) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// addi r3,r31,408
	ctx.r3.s64 = r31.s64 + 408;
	// bl 0x825828f8
	sub_825828F8(ctx, base);
	// addi r30,r31,312
	r30.s64 = r31.s64 + 312;
	// addi r3,r30,28
	ctx.r3.s64 = r30.s64 + 28;
	// bl 0x8247d138
	sub_8247D138(ctx, base);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r3,r30,8
	ctx.r3.s64 = r30.s64 + 8;
	// addi r27,r11,-4548
	r27.s64 = r11.s64 + -4548;
	// stw r27,312(r31)
	PPC_STORE_U32(r31.u32 + 312, r27.u32);
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,324(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(324) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// li r29,0
	r29.s64 = 0;
	// addi r30,r31,184
	r30.s64 = r31.s64 + 184;
	// stw r29,324(r31)
	PPC_STORE_U32(r31.u32 + 324, r29.u32);
	// addi r3,r30,28
	ctx.r3.s64 = r30.s64 + 28;
	// bl 0x8247d138
	sub_8247D138(ctx, base);
	// stw r27,184(r31)
	PPC_STORE_U32(r31.u32 + 184, r27.u32);
	// addi r3,r30,8
	ctx.r3.s64 = r30.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,196(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(196) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r29,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r29.u32);
	// addi r30,r31,72
	r30.s64 = r31.s64 + 72;
	// addi r3,r30,28
	ctx.r3.s64 = r30.s64 + 28;
	// bl 0x8247d138
	sub_8247D138(ctx, base);
	// stw r27,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r27.u32);
	// addi r3,r30,8
	ctx.r3.s64 = r30.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,84(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(84) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r29,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r29.u32);
	// addi r3,r31,28
	ctx.r3.s64 = r31.s64 + 28;
	// bl 0x8257cc98
	sub_8257CC98(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r9,r10,23084
	ctx.r9.s64 = ctx.r10.s64 + 23084;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// clrlwi r8,r28,31
	ctx.r8.u64 = r28.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x825828f0
	if (cr6.eq) goto loc_825828F0;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_825828F0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82582828) {
	__imp__sub_82582828(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825828F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r31,100
	r30.s64 = r31.s64 + 100;
	// lwz r3,104(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(104) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82582928
	if (cr6.eq) goto loc_82582928;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82582928:
	// li r29,0
	r29.s64 = 0;
	// addi r3,r31,28
	ctx.r3.s64 = r31.s64 + 28;
	// stw r29,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r29.u32);
	// stw r29,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r29.u32);
	// bl 0x8247d138
	sub_8247D138(ctx, base);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r10,r11,-4548
	ctx.r10.s64 = r11.s64 + -4548;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(12) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r29,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r29.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_825828F8) {
	__imp__sub_825828F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82582968) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r30,-31927
	r30.s64 = -2092367872;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x823381b8
	sub_823381B8(ctx, base);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825829b0
	if (cr6.eq) goto loc_825829B0;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(4) );
	// b 0x825829b4
	goto loc_825829B4;
loc_825829B0:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_825829B4:
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,-732
	ctx.r4.s64 = r11.s64 + -732;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r9,r31,72
	ctx.r9.s64 = r31.s64 + 72;
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r29,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r29.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r8,r31,184
	ctx.r8.s64 = r31.s64 + 184;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r7,r31,312
	ctx.r7.s64 = r31.s64 + 312;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r7,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r7.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r6,r31,408
	ctx.r6.s64 = r31.s64 + 408;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r6,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r6.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// lis r4,-32244
	ctx.r4.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r4,-308
	ctx.r4.s64 = ctx.r4.s64 + -308;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r31,28
	ctx.r3.s64 = r31.s64 + 28;
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r6,152(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(152) );
	// bl 0x828ce060
	sub_828CE060(ctx, base);
	// stb r29,69(r31)
	PPC_STORE_U8(r31.u32 + 69, r29.u8);
	// li r4,8
	ctx.r4.s64 = 8;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b218
	sub_8240B218(ctx, base);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cntlzw r8,r10
	ctx.r8.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lis r9,-31926
	ctx.r9.s64 = -2092302336;
	// rlwinm r7,r8,27,31,31
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// li r5,1
	ctx.r5.s64 = 1;
	// xori r10,r7,1
	ctx.r10.u64 = ctx.r7.u64 ^ 1;
	// addi r4,r9,-30016
	ctx.r4.s64 = ctx.r9.s64 + -30016;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// stw r6,552(r31)
	PPC_STORE_U32(r31.u32 + 552, ctx.r6.u32);
	// lwz r3,56(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r3,152(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(152) );
	// bl 0x82837218
	sub_82837218(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82582ad8
	if (cr6.eq) goto loc_82582AD8;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_82582AD8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82582968) {
	__imp__sub_82582968(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82582AE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82583560
	sub_82583560(ctx, base);
	// addi r3,r31,28
	ctx.r3.s64 = r31.s64 + 28;
	// bl 0x828ce180
	sub_828CE180(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82582AE0) {
	__imp__sub_82582AE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82582B18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82583490
	sub_82583490(ctx, base);
	// addi r3,r31,28
	ctx.r3.s64 = r31.s64 + 28;
	// bl 0x828ced00
	sub_828CED00(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82582B18) {
	__imp__sub_82582B18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82582B50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,304
	ctx.r4.s64 = r11.s64 + 304;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r29,-31927
	r29.s64 = -2092367872;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r3,r31,52
	ctx.r3.s64 = r31.s64 + 52;
	// stb r9,24(r31)
	PPC_STORE_U8(r31.u32 + 24, ctx.r9.u8);
	// bl 0x82581388
	sub_82581388(ctx, base);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// addi r30,r31,28
	r30.s64 = r31.s64 + 28;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,0(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// bl 0x828ce830
	sub_828CE830(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lbz r5,24(r31)
	ctx.r5.u64 = PPC_LOAD_U8(r31.u32 + 24);
	// lwz r7,56(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(152) );
	// bl 0x828ce4e8
	sub_828CE4E8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82582bf0
	sub_82582BF0(ctx, base);
	// lis r6,-32246
	ctx.r6.s64 = -2113273856;
	// lfs f0,-27468(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -27468);
	f0.f64 = double(temp.f32);
	// stfs f0,28(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 28, temp.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82582B50) {
	__imp__sub_82582B50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82582BF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r10,-30020
	ctx.r4.s64 = ctx.r10.s64 + -30020;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r30,152(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// clrlwi r8,r31,24
	ctx.r8.u64 = r31.u32 & 0xFF;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// cntlzw r7,r8
	ctx.r7.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r11,r7,27,31,31
	r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x1;
	// addi r5,r11,2
	ctx.r5.s64 = r11.s64 + 2;
	// bl 0x823f9140
	sub_823F9140(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82582BF0) {
	__imp__sub_82582BF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82582C60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r24{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// lwz r11,26788(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r9,44(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(44) );
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82582e40
	if (!cr6.eq) goto loc_82582E40;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,28340
	ctx.r6.s64 = r11.s64 + 28340;
	// stw r7,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r7.u32);
loc_82582C94:
	// mfmsr r8
	// mtmsrd r13,1
	// lwarx r9,0,r6
	reserved.u32 = *(uint32_t*)(base + ctx.r6.u32);
	ctx.r9.u64 = __builtin_bswap32(reserved.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwcx. r9,0,r6
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r6.u32), reserved.s32, __builtin_bswap32(ctx.r9.s32));
	cr0.so = xer.so;
	// mtmsrd r8,1
	// bne 0x82582c94
	if (!cr0.eq) goto loc_82582C94;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(4) );
	// addi r11,r11,-70
	r11.s64 = r11.s64 + -70;
	// cmplwi cr6,r11,71
	cr6.compare<uint32_t>(r11.u32, 71, xer);
	// bgt cr6,0x82582e38
	if (cr6.gt) goto loc_82582E38;
	// lis r12,-32168
	r12.s64 = -2108162048;
	// addi r12,r12,11480
	r12.s64 = r12.s64 + 11480;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82582E38;
	case 1:
		goto loc_82582E38;
	case 2:
		goto loc_82582E38;
	case 3:
		goto loc_82582E38;
	case 4:
		goto loc_82582E38;
	case 5:
		goto loc_82582E38;
	case 6:
		goto loc_82582E38;
	case 7:
		goto loc_82582E38;
	case 8:
		goto loc_82582E38;
	case 9:
		goto loc_82582E38;
	case 10:
		goto loc_82582E38;
	case 11:
		goto loc_82582E38;
	case 12:
		goto loc_82582E38;
	case 13:
		goto loc_82582E38;
	case 14:
		goto loc_82582E38;
	case 15:
		goto loc_82582E38;
	case 16:
		goto loc_82582E38;
	case 17:
		goto loc_82582E38;
	case 18:
		goto loc_82582E38;
	case 19:
		goto loc_82582E38;
	case 20:
		goto loc_82582E38;
	case 21:
		goto loc_82582E38;
	case 22:
		goto loc_82582E38;
	case 23:
		goto loc_82582E38;
	case 24:
		goto loc_82582E38;
	case 25:
		goto loc_82582E38;
	case 26:
		goto loc_82582E38;
	case 27:
		goto loc_82582E38;
	case 28:
		goto loc_82582E38;
	case 29:
		goto loc_82582E38;
	case 30:
		goto loc_82582E38;
	case 31:
		goto loc_82582E38;
	case 32:
		goto loc_82582E38;
	case 33:
		goto loc_82582E38;
	case 34:
		goto loc_82582E38;
	case 35:
		goto loc_82582E38;
	case 36:
		goto loc_82582E38;
	case 37:
		goto loc_82582E38;
	case 38:
		goto loc_82582E38;
	case 39:
		goto loc_82582E38;
	case 40:
		goto loc_82582E38;
	case 41:
		goto loc_82582E38;
	case 42:
		goto loc_82582E38;
	case 43:
		goto loc_82582E38;
	case 44:
		goto loc_82582E38;
	case 45:
		goto loc_82582E38;
	case 46:
		goto loc_82582E38;
	case 47:
		goto loc_82582E38;
	case 48:
		goto loc_82582E38;
	case 49:
		goto loc_82582E38;
	case 50:
		goto loc_82582E38;
	case 51:
		goto loc_82582E38;
	case 52:
		goto loc_82582E38;
	case 53:
		goto loc_82582E38;
	case 54:
		goto loc_82582E38;
	case 55:
		goto loc_82582E38;
	case 56:
		goto loc_82582E38;
	case 57:
		goto loc_82582E38;
	case 58:
		goto loc_82582E38;
	case 59:
		goto loc_82582E38;
	case 60:
		goto loc_82582E38;
	case 61:
		goto loc_82582E38;
	case 62:
		goto loc_82582E38;
	case 63:
		goto loc_82582E38;
	case 64:
		goto loc_82582E38;
	case 65:
		goto loc_82582E38;
	case 66:
		goto loc_82582E38;
	case 67:
		goto loc_82582E38;
	case 68:
		goto loc_82582E38;
	case 69:
		goto loc_82582E38;
	case 70:
		goto loc_82582E18;
	case 71:
		goto loc_82582DF8;
	default:
		__builtin_unreachable();
	}
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11832(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11832) );
	// lwz r18,11800(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11800) );
	// lwz r18,11768(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(11768) );
loc_82582DF8:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lwz r4,26788(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26788) );
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-30944
	ctx.r5.s64 = r11.s64 + -30944;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// b 0x82582e34
	goto loc_82582E34;
loc_82582E18:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lwz r4,26788(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26788) );
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-30948
	ctx.r5.s64 = r11.s64 + -30948;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
loc_82582E34:
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_82582E38:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
loc_82582E40:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82582C60) {
	__imp__sub_82582C60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82582E50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r24{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r4,-36
	r11.s64 = ctx.r4.s64 + -36;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,37
	cr6.compare<uint32_t>(r11.u32, 37, xer);
	// bgt cr6,0x82583110
	if (cr6.gt) goto loc_82583110;
	// lis r12,-32168
	r12.s64 = -2108162048;
	// addi r12,r12,11908
	r12.s64 = r12.s64 + 11908;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82582F74;
	case 1:
		goto loc_825830C4;
	case 2:
		goto loc_82583110;
	case 3:
		goto loc_82583110;
	case 4:
		goto loc_82583110;
	case 5:
		goto loc_82583110;
	case 6:
		goto loc_82583110;
	case 7:
		goto loc_82583110;
	case 8:
		goto loc_82583110;
	case 9:
		goto loc_82583110;
	case 10:
		goto loc_82583110;
	case 11:
		goto loc_82583110;
	case 12:
		goto loc_82583110;
	case 13:
		goto loc_82583110;
	case 14:
		goto loc_82583110;
	case 15:
		goto loc_82583110;
	case 16:
		goto loc_82583110;
	case 17:
		goto loc_82583110;
	case 18:
		goto loc_82583110;
	case 19:
		goto loc_82583110;
	case 20:
		goto loc_82583110;
	case 21:
		goto loc_82583110;
	case 22:
		goto loc_82583110;
	case 23:
		goto loc_82583110;
	case 24:
		goto loc_82583110;
	case 25:
		goto loc_82583110;
	case 26:
		goto loc_82583110;
	case 27:
		goto loc_82583110;
	case 28:
		goto loc_82583110;
	case 29:
		goto loc_82583110;
	case 30:
		goto loc_82583110;
	case 31:
		goto loc_82583110;
	case 32:
		goto loc_82583110;
	case 33:
		goto loc_82583110;
	case 34:
		goto loc_82583110;
	case 35:
		goto loc_82583110;
	case 36:
		goto loc_82582F48;
	case 37:
		goto loc_82582F1C;
	default:
		__builtin_unreachable();
	}
	// lwz r18,12148(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12148) );
	// lwz r18,12484(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12484) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12560(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12560) );
	// lwz r18,12104(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12104) );
	// lwz r18,12060(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(12060) );
loc_82582F1C:
	// lbz r11,24(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82583134
	if (!cr6.eq) goto loc_82583134;
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// bne cr6,0x82583134
	if (!cr6.eq) goto loc_82583134;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b748
	sub_8240B748(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
loc_82582F48:
	// lbz r11,24(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82583134
	if (!cr6.eq) goto loc_82583134;
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// bne cr6,0x82583134
	if (!cr6.eq) goto loc_82583134;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b650
	sub_8240B650(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
loc_82582F74:
	// lbz r11,24(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82582fa8
	if (cr6.eq) goto loc_82582FA8;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// addi r3,r31,28
	ctx.r3.s64 = r31.s64 + 28;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r6,152(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x828ce240
	sub_828CE240(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82582b50
	sub_82582B50(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
loc_82582FA8:
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// li r11,0
	r11.s64 = 0;
	// addi r7,r10,28344
	ctx.r7.s64 = ctx.r10.s64 + 28344;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
loc_82582FC4:
	// mfmsr r8
	// mtmsrd r13,1
	// lwarx r9,0,r6
	reserved.u32 = *(uint32_t*)(base + ctx.r6.u32);
	ctx.r9.u64 = __builtin_bswap32(reserved.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwcx. r9,0,r6
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r6.u32), reserved.s32, __builtin_bswap32(ctx.r9.s32));
	cr0.so = xer.so;
	// mtmsrd r8,1
	// bne 0x82582fc4
	if (!cr0.eq) goto loc_82582FC4;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
loc_82582FE4:
	// mfmsr r4
	// mtmsrd r13,1
	// lwarx r5,0,r7
	reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r5.u64 = __builtin_bswap32(reserved.u32);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// stwcx. r5,0,r7
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), reserved.s32, __builtin_bswap32(ctx.r5.s32));
	cr0.so = xer.so;
	// mtmsrd r4,1
	// bne 0x82582fe4
	if (!cr0.eq) goto loc_82582FE4;
	// lis r30,-31927
	r30.s64 = -2092367872;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(60) );
	// bl 0x8259db00
	sub_8259DB00(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,1292
	ctx.r4.s64 = r11.s64 + 1292;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r29,r10,-70
	r29.s64 = ctx.r10.s64 + -70;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r30,r31,28
	r30.s64 = r31.s64 + 28;
	// stb r8,24(r31)
	PPC_STORE_U8(r31.u32 + 24, ctx.r8.u8);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r7,56(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r28,152(r7)
	r28.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(152) );
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x828ce4e8
	sub_828CE4E8(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x828ce580
	sub_828CE580(ctx, base);
	// lis r6,-32246
	ctx.r6.s64 = -2113273856;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lfs f0,-27468(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -27468);
	f0.f64 = double(temp.f32);
	// stfs f0,28(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 28, temp.u32);
	// bl 0x828ce7c8
	sub_828CE7C8(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82582bf0
	sub_82582BF0(ctx, base);
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
loc_825830C4:
	// lbz r11,24(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// bne cr6,0x825830f0
	if (!cr6.eq) goto loc_825830F0;
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b000
	sub_8240B000(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82583340
	sub_82583340(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
loc_825830F0:
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// addi r3,r31,28
	ctx.r3.s64 = r31.s64 + 28;
	// lwz r6,152(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x828ce240
	sub_828CE240(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82582b50
	sub_82582B50(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
loc_82583110:
	// lbz r11,24(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82583134
	if (cr6.eq) goto loc_82583134;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// addi r3,r31,28
	ctx.r3.s64 = r31.s64 + 28;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r6,152(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x828ce240
	sub_828CE240(ctx, base);
loc_82583134:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82582E50) {
	__imp__sub_82582E50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583140) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-31927
	r30.s64 = -2092367872;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,56(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// bl 0x823fe8f8
	sub_823FE8F8(ctx, base);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r11,-16924
	ctx.r3.s64 = r11.s64 + -16924;
	// bl 0x82188cf0
	sub_82188CF0(ctx, base);
	// clrlwi r29,r3,1
	r29.u64 = ctx.r3.u32 & 0x7FFFFFFF;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f89b0
	sub_823F89B0(ctx, base);
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r4,r10,-16912
	ctx.r4.s64 = ctx.r10.s64 + -16912;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x823f8a38
	sub_823F8A38(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x825831d0
	if (cr6.eq) goto loc_825831D0;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(24) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_825831D0:
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259dd48
	sub_8259DD48(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258320c
	if (!cr6.eq) goto loc_8258320C;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lwz r4,26788(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-30828
	ctx.r5.s64 = r11.s64 + -30828;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_8258320C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82583140) {
	__imp__sub_82583140(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583218) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,56(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// bl 0x823fe8f8
	sub_823FE8F8(ctx, base);
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r10,-16900
	ctx.r3.s64 = ctx.r10.s64 + -16900;
	// bl 0x82188cf0
	sub_82188CF0(ctx, base);
	// clrlwi r30,r3,1
	r30.u64 = ctx.r3.u32 & 0x7FFFFFFF;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f89b0
	sub_823F89B0(ctx, base);
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r4,r9,-16912
	ctx.r4.s64 = ctx.r9.s64 + -16912;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x823f8a38
	sub_823F8A38(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x825832a8
	if (cr6.eq) goto loc_825832A8;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(24) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_825832A8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82583218) {
	__imp__sub_82583218(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825832B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259dd48
	sub_8259DD48(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825832fc
	if (cr6.eq) goto loc_825832FC;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336f98
	sub_82336F98(ctx, base);
	// b 0x82583324
	goto loc_82583324;
loc_825832FC:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82583218
	sub_82583218(ctx, base);
	// lis r11,-31926
	r11.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,26788(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// addi r5,r11,-30832
	ctx.r5.s64 = r11.s64 + -30832;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_82583324:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825832B0) {
	__imp__sub_825832B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583340) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// bl 0x8259dd48
	sub_8259DD48(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825833e8
	if (cr6.eq) goto loc_825833E8;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// lwz r30,28(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// addi r3,r30,68
	ctx.r3.s64 = r30.s64 + 68;
	// bl 0x8247d010
	sub_8247D010(ctx, base);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r30,0(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// bl 0x82336610
	sub_82336610(ctx, base);
	// clrlwi r8,r3,24
	ctx.r8.u64 = ctx.r3.u32 & 0xFF;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// cntlzw r7,r8
	ctx.r7.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r4,r7,27,31,31
	ctx.r4.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x1;
	// bl 0x8240f040
	sub_8240F040(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// li r6,30
	ctx.r6.s64 = 30;
	// lwz r5,56(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// stw r6,148(r5)
	PPC_STORE_U32(ctx.r5.u32 + 148, ctx.r6.u32);
	// lwz r3,56(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// bl 0x823fe8f8
	sub_823FE8F8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x823f89b0
	sub_823F89B0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// bl 0x823f9040
	sub_823F9040(ctx, base);
	// b 0x82583410
	goto loc_82583410;
loc_825833E8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82583218
	sub_82583218(ctx, base);
	// lis r11,-31926
	r11.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,26788(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// addi r5,r11,-30832
	ctx.r5.s64 = r11.s64 + -30832;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_82583410:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82583340) {
	__imp__sub_82583340(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583428) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,-30928
	ctx.r5.s64 = ctx.r10.s64 + -30928;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,26788(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258346c
	if (cr6.eq) goto loc_8258346C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_8258346C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82583428) {
	__imp__sub_82583428(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583480) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	return;
}

PPC_WEAK_FUNC(sub_82583480) {
	__imp__sub_82583480(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583490) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + int32_t(12) );
	// li r11,0
	r11.s64 = 0;
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(16) );
	// addi r4,r31,8
	ctx.r4.s64 = r31.s64 + 8;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// stw r8,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r8.u32);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// ld r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// ld r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// bl 0x82350c18
	sub_82350C18(ctx, base);
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lwz r6,40(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(40) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82583544
	if (cr6.eq) goto loc_82583544;
	// lwz r5,8(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// addi r28,r3,4
	r28.s64 = ctx.r3.s64 + 4;
	// lwz r4,12(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(12) );
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// beq cr6,0x82583544
	if (cr6.eq) goto loc_82583544;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x829ff3e8
	sub_829FF3E8(ctx, base);
	// lwz r30,8(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + int32_t(8) );
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r31,r29
	r31.u64 = r29.u64;
	// cmplw cr6,r29,r30
	cr6.compare<uint32_t>(r29.u32, r30.u32, xer);
	// beq cr6,0x82583540
	if (cr6.eq) goto loc_82583540;
loc_8258352C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ff648
	sub_829FF648(ctx, base);
	// addi r31,r31,8
	r31.s64 = r31.s64 + 8;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// bne cr6,0x8258352c
	if (!cr6.eq) goto loc_8258352C;
loc_82583540:
	// stw r29,8(r28)
	PPC_STORE_U32(r28.u32 + 8, r29.u32);
loc_82583544:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// bl 0x8240b000
	sub_8240B000(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82583490) {
	__imp__sub_82583490(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583560) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r31,12(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + int32_t(12) );
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(16) );
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x825835c0
	if (cr6.eq) goto loc_825835C0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,2948(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2948);
	f31.f64 = double(temp.f32);
loc_82583594:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + int32_t(16) );
	// addi r31,r31,8
	r31.s64 = r31.s64 + 8;
	// cmplw cr6,r31,r9
	cr6.compare<uint32_t>(r31.u32, ctx.r9.u32, xer);
	// bne cr6,0x82583594
	if (!cr6.eq) goto loc_82583594;
loc_825835C0:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825835ec
	if (cr6.eq) goto loc_825835EC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_825835EC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// lfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82583560) {
	__imp__sub_82583560(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583608) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(4) );
	// li r11,0
	r11.s64 = 0;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// stw r9,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r9.u32);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// ld r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// ld r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// bl 0x82350c18
	sub_82350C18(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82583608) {
	__imp__sub_82583608(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583658) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r3,r31,72
	ctx.r3.s64 = r31.s64 + 72;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r31,68
	ctx.r3.s64 = r31.s64 + 68;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r10,r11,23084
	ctx.r10.s64 = r11.s64 + 23084;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// clrlwi r9,r30,31
	ctx.r9.u64 = r30.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x825836b0
	if (cr6.eq) goto loc_825836B0;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_825836B0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82583658) {
	__imp__sub_82583658(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825836C8) {
	PPC_FUNC_PROLOGUE();
	// b 0x82583938
	sub_82583938(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_825836C8) {
	__imp__sub_825836C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825836D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x82583560
	sub_82583560(ctx, base);
	// lbz r11,32(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825838c4
	if (cr6.eq) goto loc_825838C4;
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(76) );
	// addi r3,r30,76
	ctx.r3.s64 = r30.s64 + 76;
	// cmplwi cr6,r11,997
	cr6.compare<uint32_t>(r11.u32, 997, xer);
	// beq cr6,0x825838c4
	if (cr6.eq) goto loc_825838C4;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82cbc558
	sub_82CBC558(ctx, base);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x825838c0
	if (!cr6.eq) goto loc_825838C0;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82583748
	if (cr6.eq) goto loc_82583748;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// bgt cr6,0x8258374c
	if (cr6.gt) goto loc_8258374C;
loc_82583748:
	// twi 31,r0,22
loc_8258374C:
	// lwz r28,24(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + int32_t(24) );
	// mr r31,r29
	r31.u64 = r29.u64;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(28) );
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// rlwinm r9,r10,12,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258384c
	if (cr6.eq) goto loc_8258384C;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82583790
	if (cr6.eq) goto loc_82583790;
	// lbz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 20);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r11,1
	r11.s64 = 1;
	// lwz r31,4(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x82583850
	goto loc_82583850;
loc_82583790:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825837fc
	if (!cr0.gt) goto loc_825837FC;
loc_825837AC:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,20
	cr6.compare<int32_t>(ctx.r7.s32, 20, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825837cc
	if (cr6.lt) goto loc_825837CC;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_825837CC:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825837e8
	if (cr6.eq) goto loc_825837E8;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825837f0
	goto loc_825837F0;
loc_825837E8:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825837F0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825837ac
	if (cr6.gt) goto loc_825837AC;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_825837FC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258383c
	if (cr6.eq) goto loc_8258383C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82583818
	if (cr6.gt) goto loc_82583818;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82583818:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258383c
	if (!cr6.eq) goto loc_8258383C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x82583850
	goto loc_82583850;
loc_8258383C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x82583850
	goto loc_82583850;
loc_8258384C:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82583850:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825838c0
	if (cr6.eq) goto loc_825838C0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824321f8
	sub_824321F8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825838c0
	if (cr6.eq) goto loc_825838C0;
	// addi r4,r30,34
	ctx.r4.s64 = r30.s64 + 34;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r31,52
	ctx.r3.s64 = r31.s64 + 52;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82436748
	sub_82436748(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,28(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(28) );
	// bl 0x828c8440
	sub_828C8440(ctx, base);
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r4,-29988(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(-29988) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
loc_825838C0:
	// stb r29,32(r30)
	PPC_STORE_U8(r30.u32 + 32, r29.u8);
loc_825838C4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_825836D0) {
	__imp__sub_825836D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825838D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,32(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82583924
	if (!cr6.eq) goto loc_82583924;
	// cmpwi cr6,r4,37
	cr6.compare<int32_t>(ctx.r4.s32, 37, xer);
	// beq cr6,0x8258390c
	if (cr6.eq) goto loc_8258390C;
	// cmpwi cr6,r4,38
	cr6.compare<int32_t>(ctx.r4.s32, 38, xer);
	// bne cr6,0x82583924
	if (!cr6.eq) goto loc_82583924;
	// bl 0x82584a00
	sub_82584A00(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
loc_8258390C:
	// bl 0x82583938
	sub_82583938(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336f98
	sub_82336F98(ctx, base);
loc_82583924:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825838D0) {
	__imp__sub_825838D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583938) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,24(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82583998
	if (cr6.eq) goto loc_82583998;
	// li r11,0
	r11.s64 = 0;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// stb r11,24(r3)
	PPC_STORE_U8(ctx.r3.u32 + 24, r11.u8);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r4,52(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(52) );
	// lwz r3,32(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(32) );
	// bl 0x827ce400
	sub_827CE400(ctx, base);
	// lis r8,-31926
	ctx.r8.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,26788(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// addi r5,r8,-30744
	ctx.r5.s64 = ctx.r8.s64 + -30744;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_82583998:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82583938) {
	__imp__sub_82583938(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825839B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// li r4,10
	ctx.r4.s64 = 10;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,56(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// bl 0x823fe6f0
	sub_823FE6F0(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r4,52(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(52) );
	// lwz r3,32(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(32) );
	// bl 0x827ce238
	sub_827CE238(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,10
	ctx.r4.s64 = 10;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336838
	sub_82336838(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336d70
	sub_82336D70(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x823381b8
	sub_823381B8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82583a3c
	if (cr6.eq) goto loc_82583A3C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82583A3C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82583ad8
	sub_82583AD8(ctx, base);
	// addi r11,r30,28
	r11.s64 = r30.s64 + 28;
	// rotlwi r11,r29,0
	r11.u64 = rotl32(r29.u32, 0);
	// stw r29,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r29.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82583a6c
	if (cr6.eq) goto loc_82583A6C;
	// lbz r11,144(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82583a70
	if (!cr6.eq) goto loc_82583A70;
loc_82583A6C:
	// li r11,0
	r11.s64 = 0;
loc_82583A70:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82583a94
	if (cr6.eq) goto loc_82583A94;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82583ce8
	sub_82583CE8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82583eb8
	sub_82583EB8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825845a0
	sub_825845A0(ctx, base);
loc_82583A94:
	// li r11,1
	r11.s64 = 1;
	// lwz r4,26788(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// stb r11,24(r30)
	PPC_STORE_U8(r30.u32 + 24, r11.u8);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,-30748
	ctx.r5.s64 = ctx.r10.s64 + -30748;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82583ad0
	if (cr6.eq) goto loc_82583AD0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82583AD0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_825839B0) {
	__imp__sub_825839B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583AD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,2804
	ctx.r4.s64 = r11.s64 + 2804;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// lwz r11,26788(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26788) );
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82583b28
	if (cr6.eq) goto loc_82583B28;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// bgt cr6,0x82583b2c
	if (cr6.gt) goto loc_82583B2C;
loc_82583B28:
	// twi 31,r0,22
loc_82583B2C:
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// lwz r31,24(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(24) );
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r10,-29908
	ctx.r4.s64 = ctx.r10.s64 + -29908;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r9,-31926
	ctx.r9.s64 = -2092302336;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r4,-29980(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(-29980) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// lis r8,-31926
	ctx.r8.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r8,-29904
	ctx.r4.s64 = ctx.r8.s64 + -29904;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r7,-31926
	ctx.r7.s64 = -2092302336;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r4,-29976(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(-29976) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// lis r6,-31926
	ctx.r6.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r6,-29900
	ctx.r4.s64 = ctx.r6.s64 + -29900;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r4,-31926
	ctx.r4.s64 = -2092302336;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r4,-29968(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(-29968) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r11,-29896
	ctx.r4.s64 = r11.s64 + -29896;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r4,-29960(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(-29960) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// lis r9,-31926
	ctx.r9.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r9,-29892
	ctx.r4.s64 = ctx.r9.s64 + -29892;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r8,-31926
	ctx.r8.s64 = -2092302336;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r4,-29956(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(-29956) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// lis r7,-31926
	ctx.r7.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r7,-29888
	ctx.r4.s64 = ctx.r7.s64 + -29888;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r6,-31926
	ctx.r6.s64 = -2092302336;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,-29952(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(-29952) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82583AD8) {
	__imp__sub_82583AD8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583CE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r4,28(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(28) );
	// li r31,0
	r31.s64 = 0;
	// lwz r5,26788(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,36(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(36) );
	// rlwinm r9,r10,12,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0x1;
	// lwz r8,56(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + int32_t(56) );
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// lwz r30,52(r8)
	r30.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(52) );
	// beq cr6,0x82583e0c
	if (cr6.eq) goto loc_82583E0C;
	// lwz r11,140(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82583d48
	if (cr6.eq) goto loc_82583D48;
	// lbz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 20);
	// lwz r11,72(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82583e10
	goto loc_82583E10;
loc_82583D48:
	// lwz r10,72(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(72) );
	// lwz r6,76(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82583db4
	if (!cr0.gt) goto loc_82583DB4;
loc_82583D64:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,20
	cr6.compare<int32_t>(ctx.r7.s32, 20, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82583d84
	if (cr6.lt) goto loc_82583D84;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82583D84:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82583da0
	if (cr6.eq) goto loc_82583DA0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82583da8
	goto loc_82583DA8;
loc_82583DA0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82583DA8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82583d64
	if (cr6.gt) goto loc_82583D64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82583DB4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82583df8
	if (cr6.eq) goto loc_82583DF8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82583dd0
	if (cr6.gt) goto loc_82583DD0;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82583DD0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82583df8
	if (!cr6.eq) goto loc_82583DF8;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82583e10
	goto loc_82583E10;
loc_82583DF8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82583e10
	goto loc_82583E10;
loc_82583E0C:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82583E10:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82583eb0
	if (cr6.eq) goto loc_82583EB0;
	// lwz r11,32(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + int32_t(32) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82583e44
	if (cr6.eq) goto loc_82583E44;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// bgt cr6,0x82583e48
	if (cr6.gt) goto loc_82583E48;
loc_82583E44:
	// twi 31,r0,22
loc_82583E48:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r29,24(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + int32_t(24) );
	// bl 0x828c8440
	sub_828C8440(ctx, base);
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,-29988(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(-29988) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824321f8
	sub_824321F8(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// cntlzw r8,r10
	ctx.r8.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// addi r4,r9,1792
	ctx.r4.s64 = ctx.r9.s64 + 1792;
	// rlwinm r11,r8,27,31,31
	r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r31,r11,1
	r31.s64 = r11.s64 + 1;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x823f9040
	sub_823F9040(ctx, base);
loc_82583EB0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82583CE8) {
	__imp__sub_82583CE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82583EB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, f29.u64);
	// stfd f30,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, f30.u64);
	// stfd f31,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(28) );
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// rlwinm r9,r10,17,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82583fd0
	if (cr6.eq) goto loc_82583FD0;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82583f14
	if (cr6.eq) goto loc_82583F14;
	// lbz r10,47(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 47);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r11,1
	r11.s64 = 1;
	// lwz r31,4(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x82583fd4
	goto loc_82583FD4;
loc_82583F14:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82583f80
	if (!cr0.gt) goto loc_82583F80;
loc_82583F30:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,47
	cr6.compare<int32_t>(ctx.r7.s32, 47, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82583f50
	if (cr6.lt) goto loc_82583F50;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82583F50:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82583f6c
	if (cr6.eq) goto loc_82583F6C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82583f74
	goto loc_82583F74;
loc_82583F6C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82583F74:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82583f30
	if (cr6.gt) goto loc_82583F30;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82583F80:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82583fc0
	if (cr6.eq) goto loc_82583FC0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,47
	cr6.compare<int32_t>(r11.s32, 47, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82583f9c
	if (cr6.gt) goto loc_82583F9C;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82583F9C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82583fc0
	if (!cr6.eq) goto loc_82583FC0;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x82583fd4
	goto loc_82583FD4;
loc_82583FC0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x82583fd4
	goto loc_82583FD4;
loc_82583FD0:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82583FD4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825840b4
	if (cr6.eq) goto loc_825840B4;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825840c8
	sub_825840C8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825842f0
	sub_825842F0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82584448
	sub_82584448(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584034
	if (cr6.eq) goto loc_82584034;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bgt cr6,0x82584038
	if (cr6.gt) goto loc_82584038;
loc_82584034:
	// twi 31,r0,22
loc_82584038:
	// lis r30,-32246
	r30.s64 = -2113273856;
	// lfs f0,44(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 44);
	f0.f64 = double(temp.f32);
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// lwz r29,4(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// addi r9,r30,-17928
	ctx.r9.s64 = r30.s64 + -17928;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,-29948(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(-29948) );
	// lfs f31,-9528(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -9528);
	f31.f64 = double(temp.f32);
	// fadds f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 + f31.f64));
	// lfs f29,-9924(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -9924);
	f29.f64 = double(temp.f32);
	// lfs f30,1128(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 1128);
	f30.f64 = double(temp.f32);
	// fmuls f12,f13,f29
	ctx.f12.f64 = double(float(ctx.f13.f64 * f29.f64));
	// fmuls f1,f12,f30
	ctx.f1.f64 = double(float(ctx.f12.f64 * f30.f64));
	// bl 0x8257c348
	sub_8257C348(ctx, base);
	// lfs f11,48(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// lis r8,-31926
	ctx.r8.s64 = -2092302336;
	// fsubs f10,f11,f31
	ctx.f10.f64 = static_cast<float>(ctx.f11.f64 - f31.f64);
	// lfs f0,-17928(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + -17928);
	f0.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,-29940(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(-29940) );
	// fmuls f9,f10,f0
	ctx.f9.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fmuls f1,f9,f30
	ctx.f1.f64 = double(float(ctx.f9.f64 * f30.f64));
	// bl 0x8257c348
	sub_8257C348(ctx, base);
	// lfs f8,52(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	ctx.f8.f64 = double(temp.f32);
	// lis r7,-31926
	ctx.r7.s64 = -2092302336;
	// fadds f7,f8,f31
	ctx.f7.f64 = double(float(ctx.f8.f64 + f31.f64));
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,-29932(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(-29932) );
	// fmuls f6,f7,f29
	ctx.f6.f64 = double(float(ctx.f7.f64 * f29.f64));
	// fmuls f1,f6,f30
	ctx.f1.f64 = double(float(ctx.f6.f64 * f30.f64));
	// bl 0x8257c348
	sub_8257C348(ctx, base);
loc_825840B4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f30,-48(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82583EB8) {
	__imp__sub_82583EB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825840C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584108
	if (cr6.eq) goto loc_82584108;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// bgt cr6,0x8258410c
	if (cr6.gt) goto loc_8258410C;
loc_82584108:
	// twi 31,r0,22
loc_8258410C:
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// lwz r26,24(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + int32_t(24) );
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// addi r4,r10,-29884
	ctx.r4.s64 = ctx.r10.s64 + -29884;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82287710
	sub_82287710(ctx, base);
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// addi r4,r9,16
	ctx.r4.s64 = ctx.r9.s64 + 16;
	// bl 0x82b38f30
	sub_82B38F30(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r30,0
	r30.s64 = 0;
	// addi r28,r11,28340
	r28.s64 = r11.s64 + 28340;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
loc_82584164:
	// mfmsr r7
	// mtmsrd r13,1
	// lwarx r8,0,r6
	reserved.u32 = *(uint32_t*)(base + ctx.r6.u32);
	ctx.r8.u64 = __builtin_bswap32(reserved.u32);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stwcx. r8,0,r6
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r6.u32), reserved.s32, __builtin_bswap32(ctx.r8.s32));
	cr0.so = xer.so;
	// mtmsrd r7,1
	// bne 0x82584164
	if (!cr0.eq) goto loc_82584164;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// lwz r4,48(r5)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r5.u32 + int32_t(48) );
	// rlwinm r3,r4,31,31,31
	ctx.r3.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825841cc
	if (cr6.eq) goto loc_825841CC;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,1812
	ctx.r4.s64 = r11.s64 + 1812;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// b 0x82584288
	goto loc_82584288;
loc_825841CC:
	// stw r30,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r30.u32);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// stw r30,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r30.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r30,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r30.u32);
	// bl 0x82756e18
	sub_82756E18(ctx, base);
	// lwz r27,116(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// lwz r29,120(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(120) );
	// mr r31,r27
	r31.u64 = r27.u64;
	// cmplw cr6,r27,r29
	cr6.compare<uint32_t>(r27.u32, r29.u32, xer);
	// beq cr6,0x82584268
	if (cr6.eq) goto loc_82584268;
loc_825841F8:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82b38e60
	sub_82B38E60(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
loc_82584228:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x82584228
	if (!cr0.eq) goto loc_82584228;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r30.u32);
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// beq cr6,0x82584268
	if (cr6.eq) goto loc_82584268;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82b38e60
	sub_82B38E60(ctx, base);
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bne cr6,0x825841f8
	if (!cr6.eq) goto loc_825841F8;
loc_82584268:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82584288
	if (cr6.eq) goto loc_82584288;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8239c0d8
	sub_8239C0D8(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_82584288:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r4,-29984(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(-29984) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
loc_825842A8:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x825842a8
	if (!cr0.eq) goto loc_825842A8;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
loc_825842CC:
	// mfmsr r6
	// mtmsrd r13,1
	// lwarx r7,0,r28
	reserved.u32 = *(uint32_t*)(base + r28.u32);
	ctx.r7.u64 = __builtin_bswap32(reserved.u32);
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
	// stwcx. r7,0,r28
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + r28.u32), reserved.s32, __builtin_bswap32(ctx.r7.s32));
	cr0.so = xer.so;
	// mtmsrd r6,1
	// bne 0x825842cc
	if (!cr0.eq) goto loc_825842CC;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_825840C8) {
	__imp__sub_825840C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825842F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584334
	if (cr6.eq) goto loc_82584334;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r11,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	r11.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bgt cr6,0x82584338
	if (cr6.gt) goto loc_82584338;
loc_82584334:
	// twi 31,r0,22
loc_82584338:
	// li r31,0
	r31.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// stw r31,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r31.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// bl 0x8276ef48
	sub_8276EF48(ctx, base);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r31.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8276ef48
	sub_8276EF48(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// lis r10,-32064
	ctx.r10.s64 = -2101346304;
	// addi r6,r11,1840
	ctx.r6.s64 = r11.s64 + 1840;
	// li r7,3
	ctx.r7.s64 = 3;
	// addi r5,r10,-1472
	ctx.r5.s64 = ctx.r10.s64 + -1472;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825848b0
	sub_825848B0(ctx, base);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// lis r8,-32099
	ctx.r8.s64 = -2103640064;
	// addi r6,r9,1412
	ctx.r6.s64 = ctx.r9.s64 + 1412;
	// li r7,3
	ctx.r7.s64 = 3;
	// addi r5,r8,-6032
	ctx.r5.s64 = ctx.r8.s64 + -6032;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825848b0
	sub_825848B0(ctx, base);
	// lis r7,-32244
	ctx.r7.s64 = -2113142784;
	// lis r5,-32064
	ctx.r5.s64 = -2101346304;
	// addi r6,r7,1856
	ctx.r6.s64 = ctx.r7.s64 + 1856;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r5,-1472
	ctx.r5.s64 = ctx.r5.s64 + -1472;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825848b0
	sub_825848B0(ctx, base);
	// lis r4,-32244
	ctx.r4.s64 = -2113142784;
	// lis r3,-32099
	ctx.r3.s64 = -2103640064;
	// addi r6,r4,1440
	ctx.r6.s64 = ctx.r4.s64 + 1440;
	// addi r5,r3,-6032
	ctx.r5.s64 = ctx.r3.s64 + -6032;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825848b0
	sub_825848B0(ctx, base);
	// lwz r31,84(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82584418
	if (cr6.eq) goto loc_82584418;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(88) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82584cb0
	sub_82584CB0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_82584418:
	// lwz r31,100(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8258443c
	if (cr6.eq) goto loc_8258443C;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(104) );
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82584cb0
	sub_82584CB0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_8258443C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_825842F0) {
	__imp__sub_825842F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82584448) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stfd f29,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, f29.u64);
	// stfd f30,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, f30.u64);
	// stfd f31,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r11,32(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// lwz r9,28(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82584494
	if (cr6.eq) goto loc_82584494;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// subf r8,r9,r10
	ctx.r8.s64 = ctx.r10.s64 - ctx.r9.s64;
	// srawi r10,r8,2
	xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r8.s32 >> 2;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bgt cr6,0x82584498
	if (cr6.gt) goto loc_82584498;
loc_82584494:
	// twi 31,r0,22
loc_82584498:
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r26,4(r9)
	r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825844bc
	if (cr6.eq) goto loc_825844BC;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// subf r9,r10,r11
	ctx.r9.s64 = r11.s64 - ctx.r10.s64;
	// srawi r11,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	r11.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r11,9
	cr6.compare<uint32_t>(r11.u32, 9, xer);
	// bgt cr6,0x825844c0
	if (cr6.gt) goto loc_825844C0;
loc_825844BC:
	// twi 31,r0,22
loc_825844C0:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r29,36(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(36) );
	// bl 0x82268468
	sub_82268468(ctx, base);
	// lis r31,-31926
	r31.s64 = -2092302336;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r4,-29924(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(-29924) );
	// bl 0x8257b408
	sub_8257B408(ctx, base);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// clrlwi r30,r30,24
	r30.u64 = r30.u32 & 0xFF;
	// addi r10,r11,-16800
	ctx.r10.s64 = r11.s64 + -16800;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lfs f29,-16800(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -16800);
	f29.f64 = double(temp.f32);
	// lfs f31,-10656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -10656);
	f31.f64 = double(temp.f32);
	// lfs f30,-11052(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11052);
	f30.f64 = double(temp.f32);
	// beq cr6,0x82584520
	if (cr6.eq) goto loc_82584520;
	// lfs f0,120(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 120);
	f0.f64 = double(temp.f32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// fadds f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 + f31.f64));
	// lwz r4,-29924(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(-29924) );
	// fmuls f12,f13,f30
	ctx.f12.f64 = double(float(ctx.f13.f64 * f30.f64));
	// fmuls f1,f12,f29
	ctx.f1.f64 = double(float(ctx.f12.f64 * f29.f64));
	// bl 0x8257c348
	sub_8257C348(ctx, base);
loc_82584520:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8226b098
	sub_8226B098(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82584544
	if (!cr6.eq) goto loc_82584544;
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// li r5,1
	ctx.r5.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82584548
	if (!cr6.eq) goto loc_82584548;
loc_82584544:
	// li r5,0
	ctx.r5.s64 = 0;
loc_82584548:
	// lis r31,-31926
	r31.s64 = -2092302336;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,-29920(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(-29920) );
	// bl 0x8257b408
	sub_8257B408(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82584588
	if (!cr6.eq) goto loc_82584588;
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584588
	if (cr6.eq) goto loc_82584588;
	// lfs f0,116(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 116);
	f0.f64 = double(temp.f32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// fadds f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 + f31.f64));
	// lwz r4,-29920(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(-29920) );
	// fmuls f12,f13,f30
	ctx.f12.f64 = double(float(ctx.f13.f64 * f30.f64));
	// fmuls f1,f12,f29
	ctx.f1.f64 = double(float(ctx.f12.f64 * f29.f64));
	// bl 0x8257c348
	sub_8257C348(ctx, base);
loc_82584588:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f29,-80(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f30,-72(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82584448) {
	__imp__sub_82584448(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825845A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stfd f29,-96(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -96, f29.u64);
	// stfd f30,-88(r1)
	PPC_STORE_U64(ctx.r1.u32 + -88, f30.u64);
	// stfd f31,-80(r1)
	PPC_STORE_U64(ctx.r1.u32 + -80, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// lwz r4,26788(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r11,32(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(32) );
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825845e8
	if (cr6.eq) goto loc_825845E8;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// subf r9,r10,r11
	ctx.r9.s64 = r11.s64 - ctx.r10.s64;
	// srawi r11,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	r11.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r11,9
	cr6.compare<uint32_t>(r11.u32, 9, xer);
	// bgt cr6,0x825845ec
	if (cr6.gt) goto loc_825845EC;
loc_825845E8:
	// twi 31,r0,22
loc_825845EC:
	// lwz r11,28(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(28) );
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r26,36(r10)
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(36) );
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// lwz r9,52(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// rlwinm r8,r9,29,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x825846f4
	if (cr6.eq) goto loc_825846F4;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82584638
	if (cr6.eq) goto loc_82584638;
	// lbz r10,131(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 131);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r11,1
	r11.s64 = 1;
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x825846f8
	goto loc_825846F8;
loc_82584638:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r5,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r5.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825846a4
	if (!cr0.gt) goto loc_825846A4;
loc_82584654:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,131
	cr6.compare<int32_t>(ctx.r7.s32, 131, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82584674
	if (cr6.lt) goto loc_82584674;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
loc_82584674:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82584690
	if (cr6.eq) goto loc_82584690;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82584698
	goto loc_82584698;
loc_82584690:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82584698:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82584654
	if (cr6.gt) goto loc_82584654;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_825846A4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825846e4
	if (cr6.eq) goto loc_825846E4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,131
	cr6.compare<int32_t>(r11.s32, 131, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825846c0
	if (cr6.gt) goto loc_825846C0;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
loc_825846C0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825846e4
	if (!cr6.eq) goto loc_825846E4;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x825846f8
	goto loc_825846F8;
loc_825846E4:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x825846f8
	goto loc_825846F8;
loc_825846F4:
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
loc_825846F8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// lis r27,-31926
	r27.s64 = -2092302336;
	// lis r28,-31926
	r28.s64 = -2092302336;
	// lis r29,-31926
	r29.s64 = -2092302336;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258485c
	if (cr6.eq) goto loc_8258485C;
	// lwz r11,20(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(20) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258485c
	if (cr6.eq) goto loc_8258485C;
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(16) );
	// li r25,1
	r25.s64 = 1;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82584734
	if (!cr6.eq) goto loc_82584734;
	// twi 31,r0,22
loc_82584734:
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// beq cr6,0x8258476c
	if (cr6.eq) goto loc_8258476C;
loc_8258474C:
	// mfmsr r8
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r8,1
	// bne 0x8258474c
	if (!cr0.eq) goto loc_8258474C;
	// lwz r4,26788(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
loc_8258476C:
	// lwz r11,32(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(32) );
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r11,28(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584794
	if (cr6.eq) goto loc_82584794;
	// lwz r9,32(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(32) );
	// subf r8,r11,r9
	ctx.r8.s64 = ctx.r9.s64 - r11.s64;
	// srawi r9,r8,2
	xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x3) != 0);
	ctx.r9.s64 = ctx.r8.s32 >> 2;
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bgt cr6,0x82584798
	if (cr6.gt) goto loc_82584798;
loc_82584794:
	// twi 31,r0,22
loc_82584798:
	// lis r24,-32246
	r24.s64 = -2113273856;
	// lfs f0,8(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	f0.f64 = double(temp.f32);
	// lwz r31,4(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// addi r10,r24,-16800
	ctx.r10.s64 = r24.s64 + -16800;
	// lwz r4,-29944(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + int32_t(-29944) );
	// subf r9,r5,r31
	ctx.r9.s64 = r31.s64 - ctx.r5.s64;
	// lwz r30,4(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// cntlzw r8,r9
	ctx.r8.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// lfs f29,-10656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -10656);
	f29.f64 = double(temp.f32);
	// rlwinm r5,r8,27,31,31
	ctx.r5.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// fadds f13,f0,f29
	ctx.f13.f64 = double(float(f0.f64 + f29.f64));
	// lfs f0,-11052(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11052);
	f0.f64 = double(temp.f32);
	// fmuls f31,f13,f0
	f31.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x8257b408
	sub_8257B408(ctx, base);
	// lfs f30,-16800(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r24.u32 + -16800);
	f30.f64 = double(temp.f32);
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x825847f0
	if (!cr6.eq) goto loc_825847F0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,-29944(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + int32_t(-29944) );
	// fmuls f1,f31,f30
	ctx.f1.f64 = double(float(f31.f64 * f30.f64));
	// bl 0x8257c348
	sub_8257C348(ctx, base);
loc_825847F0:
	// addi r11,r31,-1
	r11.s64 = r31.s64 + -1;
	// lwz r4,-29936(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(-29936) );
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r5,r10,27,31,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// bl 0x8257b408
	sub_8257B408(ctx, base);
	// cmpwi cr6,r31,1
	cr6.compare<int32_t>(r31.s32, 1, xer);
	// bne cr6,0x82584824
	if (!cr6.eq) goto loc_82584824;
	// fsubs f0,f29,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = static_cast<float>(f29.f64 - f31.f64);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,-29936(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(-29936) );
	// fmuls f1,f0,f30
	ctx.f1.f64 = double(float(f0.f64 * f30.f64));
	// bl 0x8257c348
	sub_8257C348(ctx, base);
loc_82584824:
	// addi r11,r31,-2
	r11.s64 = r31.s64 + -2;
	// lwz r4,-29928(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(-29928) );
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r5,r10,27,31,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// bl 0x8257b408
	sub_8257B408(ctx, base);
	// cmpwi cr6,r31,2
	cr6.compare<int32_t>(r31.s32, 2, xer);
	// bne cr6,0x82584854
	if (!cr6.eq) goto loc_82584854;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,-29928(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(-29928) );
	// fmuls f1,f31,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(f31.f64 * f30.f64));
	// bl 0x8257c348
	sub_8257C348(ctx, base);
loc_82584854:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x829ff648
	sub_829FF648(ctx, base);
loc_8258485C:
	// clrlwi r11,r25,24
	r11.u64 = r25.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82584898
	if (!cr6.eq) goto loc_82584898;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,-29944(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + int32_t(-29944) );
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8257b408
	sub_8257B408(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r4,-29936(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(-29936) );
	// bl 0x8257b408
	sub_8257B408(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r4,-29928(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(-29928) );
	// bl 0x8257b408
	sub_8257B408(ctx, base);
loc_82584898:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f29,-96(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// lfd f30,-88(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// lfd f31,-80(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_825845A0) {
	__imp__sub_825845A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825848B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// mr r22,r5
	r22.u64 = ctx.r5.u64;
	// mr r21,r6
	r21.u64 = ctx.r6.u64;
	// mr r19,r7
	r19.u64 = ctx.r7.u64;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825848fc
	if (cr6.eq) goto loc_825848FC;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// bgt cr6,0x82584900
	if (cr6.gt) goto loc_82584900;
loc_825848FC:
	// twi 31,r0,22
loc_82584900:
	// li r23,0
	r23.s64 = 0;
	// lwz r27,24(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + int32_t(24) );
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// mr r30,r23
	r30.u64 = r23.u64;
	// beq cr6,0x825849f8
	if (cr6.eq) goto loc_825849F8;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// lis r9,-31927
	ctx.r9.s64 = -2092367872;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// mr r28,r23
	r28.u64 = r23.u64;
	// addi r20,r10,23400
	r20.s64 = ctx.r10.s64 + 23400;
	// addi r26,r9,28340
	r26.s64 = ctx.r9.s64 + 28340;
	// addi r25,r11,1876
	r25.s64 = r11.s64 + 1876;
loc_82584930:
	// addi r29,r30,1
	r29.s64 = r30.s64 + 1;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82584d48
	sub_82584D48(ctx, base);
	// lis r4,-32484
	ctx.r4.s64 = -2128871424;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// ori r4,r4,40389
	ctx.r4.u64 = ctx.r4.u64 | 40389;
	// bl 0x821f3c28
	sub_821F3C28(ctx, base);
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + int32_t(4) );
	// lwz r10,8(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + int32_t(8) );
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r8,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	ctx.r8.s64 = ctx.r9.s32 >> 3;
	// cmplw cr6,r30,r8
	cr6.compare<uint32_t>(r30.u32, ctx.r8.u32, xer);
	// bge cr6,0x825849d8
	if (!cr6.lt) goto loc_825849D8;
	// add r3,r28,r11
	ctx.r3.u64 = r28.u64 + r11.u64;
	// mtctr r22
	ctr.u64 = r22.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
loc_825849B4:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x825849b4
	if (!cr0.eq) goto loc_825849B4;
	// stw r23,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r23.u32);
	// b 0x825849e8
	goto loc_825849E8;
loc_825849D8:
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8257c720
	sub_8257C720(ctx, base);
loc_825849E8:
	// mr r30,r29
	r30.u64 = r29.u64;
	// addi r28,r28,8
	r28.s64 = r28.s64 + 8;
	// cmplw cr6,r29,r19
	cr6.compare<uint32_t>(r29.u32, r19.u32, xer);
	// blt cr6,0x82584930
	if (cr6.lt) goto loc_82584930;
loc_825849F8:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x82ca2c14
	return;
}

PPC_WEAK_FUNC(sub_825848B0) {
	__imp__sub_825848B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82584A00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,28(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(28) );
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// rlwinm r9,r10,12,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82584b1c
	if (cr6.eq) goto loc_82584B1C;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82584a54
	if (cr6.eq) goto loc_82584A54;
	// lbz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 20);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82584b20
	goto loc_82584B20;
loc_82584A54:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r9,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r9.u32);
	// subf r8,r10,r6
	ctx.r8.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// srawi. r11,r8,3
	xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x7) != 0);
	r11.s64 = ctx.r8.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82584ac4
	if (!cr0.gt) goto loc_82584AC4;
loc_82584A74:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,20
	cr6.compare<int32_t>(ctx.r7.s32, 20, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82584a94
	if (cr6.lt) goto loc_82584A94;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82584A94:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82584ab0
	if (cr6.eq) goto loc_82584AB0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82584ab8
	goto loc_82584AB8;
loc_82584AB0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82584AB8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82584a74
	if (cr6.gt) goto loc_82584A74;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_82584AC4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82584b08
	if (cr6.eq) goto loc_82584B08;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82584ae0
	if (cr6.gt) goto loc_82584AE0;
	// li r11,0
	r11.s64 = 0;
loc_82584AE0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82584b08
	if (!cr6.eq) goto loc_82584B08;
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82584b20
	goto loc_82584B20;
loc_82584B08:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82584b20
	goto loc_82584B20;
loc_82584B1C:
	// li r11,0
	r11.s64 = 0;
loc_82584B20:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584ca4
	if (cr6.eq) goto loc_82584CA4;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x824321f8
	sub_824321F8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584ca4
	if (cr6.eq) goto loc_82584CA4;
	// addi r27,r26,76
	r27.s64 = r26.s64 + 76;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r11,r27
	r11.u64 = r27.u64;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82584B54:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82584b54
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82584B54;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x824366b8
	sub_824366B8(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// addi r28,r10,-28040
	r28.s64 = ctx.r10.s64 + -28040;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x82584b84
	if (cr6.eq) goto loc_82584B84;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_82584B84:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82b393b8
	sub_82B393B8(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584bb4
	if (cr6.eq) goto loc_82584BB4;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_82584BB4:
	// addi r31,r26,34
	r31.s64 = r26.s64 + 34;
	// li r4,17
	ctx.r4.s64 = 17;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82ca42d0
	sub_82CA42D0(ctx, base);
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r11,-29916
	ctx.r4.s64 = r11.s64 + -29916;
	// addi r29,r26,68
	r29.s64 = r26.s64 + 68;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r10,-29912
	ctx.r4.s64 = ctx.r10.s64 + -29912;
	// addi r30,r26,72
	r30.s64 = r26.s64 + 72;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r9,-31927
	ctx.r9.s64 = -2092367872;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,26912(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(26912) );
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,156(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(156) );
	// bl 0x822641f0
	sub_822641F0(ctx, base);
	// lwz r11,72(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(72) );
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// lwz r3,40(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584c5c
	if (cr6.eq) goto loc_82584C5C;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_82584C5C:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(0) );
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584c70
	if (cr6.eq) goto loc_82584C70;
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_82584C70:
	// lis r4,8192
	ctx.r4.s64 = 536870912;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// li r9,17
	ctx.r9.s64 = 17;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// ori r4,r4,4
	ctx.r4.u64 = ctx.r4.u64 | 4;
	// bl 0x82cbc600
	sub_82CBC600(ctx, base);
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// bne cr6,0x82584c9c
	if (!cr6.eq) goto loc_82584C9C;
	// li r11,1
	r11.s64 = 1;
	// stb r11,32(r26)
	PPC_STORE_U8(r26.u32 + 32, r11.u8);
loc_82584C9C:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
loc_82584CA4:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82584A00) {
	__imp__sub_82584A00(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82584CB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// cmplw cr6,r4,r28
	cr6.compare<uint32_t>(ctx.r4.u32, r28.u32, xer);
	// beq cr6,0x82584d3c
	if (cr6.eq) goto loc_82584D3C;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r29,0
	r29.s64 = 0;
	// addi r30,r11,28344
	r30.s64 = r11.s64 + 28344;
loc_82584CD8:
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
loc_82584CE4:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x82584ce4
	if (!cr0.eq) goto loc_82584CE4;
	// stw r29,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r29.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
loc_82584D10:
	// mfmsr r7
	// mtmsrd r13,1
	// lwarx r8,0,r6
	reserved.u32 = *(uint32_t*)(base + ctx.r6.u32);
	ctx.r8.u64 = __builtin_bswap32(reserved.u32);
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// stwcx. r8,0,r6
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r6.u32), reserved.s32, __builtin_bswap32(ctx.r8.s32));
	cr0.so = xer.so;
	// mtmsrd r7,1
	// bne 0x82584d10
	if (!cr0.eq) goto loc_82584D10;
	// stw r29,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r29.u32);
	// addi r31,r31,8
	r31.s64 = r31.s64 + 8;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82584cd8
	if (!cr6.eq) goto loc_82584CD8;
loc_82584D3C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82584CB0) {
	__imp__sub_82584CB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82584D48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,64
	ctx.r4.s64 = 64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// bl 0x82ca4578
	sub_82CA4578(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82584D48) {
	__imp__sub_82584D48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82584D98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,84
	ctx.r3.s64 = 84;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82584ddc
	if (cr6.eq) goto loc_82584DDC;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x822ab298
	sub_822AB298(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r10,r11,2072
	ctx.r10.s64 = r11.s64 + 2072;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// b 0x82584de0
	goto loc_82584DE0;
loc_82584DDC:
	// li r4,0
	ctx.r4.s64 = 0;
loc_82584DE0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x822bffa0
	sub_822BFFA0(ctx, base);
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82584df8
	if (cr6.eq) goto loc_82584DF8;
	// bl 0x82180b28
	sub_82180B28(ctx, base);
loc_82584DF8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82584D98) {
	__imp__sub_82584D98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82584E08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,8
	ctx.r3.s64 = 8;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82584e5c
	if (cr6.eq) goto loc_82584E5C;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r9,r11,-32248
	ctx.r9.s64 = r11.s64 + -32248;
	// addi r8,r10,2428
	ctx.r8.s64 = ctx.r10.s64 + 2428;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// stw r7,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r7.u32);
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// b 0x82584e60
	goto loc_82584E60;
loc_82584E5C:
	// li r11,0
	r11.s64 = 0;
loc_82584E60:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x82584e7c
	if (cr6.eq) goto loc_82584E7C;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x82584e84
	goto loc_82584E84;
loc_82584E7C:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_82584E84:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82584E08) {
	__imp__sub_82584E08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82584EA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// mr r30,r28
	r30.u64 = r28.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584ef4
	if (cr6.eq) goto loc_82584EF4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82584f48
	if (cr6.eq) goto loc_82584F48;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584ef4
	if (cr6.eq) goto loc_82584EF4;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82584ef8
	if (!cr6.eq) goto loc_82584EF8;
loc_82584EF4:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82584EF8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825852ac
	if (cr6.eq) goto loc_825852AC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,15,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82585018
	if (cr6.eq) goto loc_82585018;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82584f54
	if (cr6.eq) goto loc_82584F54;
	// lbz r10,49(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 49);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258501c
	goto loc_8258501C;
loc_82584F48:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82584ef4
	goto loc_82584EF4;
loc_82584F54:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82584fc0
	if (!cr0.gt) goto loc_82584FC0;
loc_82584F70:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,49
	cr6.compare<int32_t>(ctx.r7.s32, 49, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82584f90
	if (cr6.lt) goto loc_82584F90;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_82584F90:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82584fac
	if (cr6.eq) goto loc_82584FAC;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82584fb4
	goto loc_82584FB4;
loc_82584FAC:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82584FB4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82584f70
	if (cr6.gt) goto loc_82584F70;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82584FC0:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82585004
	if (cr6.eq) goto loc_82585004;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82584fdc
	if (cr6.gt) goto loc_82584FDC;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82584FDC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82585004
	if (!cr6.eq) goto loc_82585004;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258501c
	goto loc_8258501C;
loc_82585004:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258501c
	goto loc_8258501C;
loc_82585018:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8258501C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825852ac
	if (cr6.eq) goto loc_825852AC;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r10,112(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(112) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blt cr6,0x82585060
	if (cr6.lt) goto loc_82585060;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x822982f8
	sub_822982F8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x82585064
	if (!cr6.eq) goto loc_82585064;
loc_82585060:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82585064:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585298
	if (cr6.eq) goto loc_82585298;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x822c7420
	sub_822C7420(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82585298
	if (cr6.eq) goto loc_82585298;
	// lbz r10,76(r29)
	ctx.r10.u64 = PPC_LOAD_U8(r29.u32 + 76);
	// mr r11,r28
	r11.u64 = r28.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82585098
	if (!cr6.eq) goto loc_82585098;
	// lbz r11,77(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 77);
loc_82585098:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825850c0
	if (!cr6.eq) goto loc_825850C0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// mr r11,r28
	r11.u64 = r28.u64;
	// bne cr6,0x825850b4
	if (!cr6.eq) goto loc_825850B4;
	// lbz r11,78(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 78);
loc_825850B4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585298
	if (cr6.eq) goto loc_82585298;
loc_825850C0:
	// lwz r9,24(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + int32_t(24) );
	// li r30,12
	r30.s64 = 12;
	// lwz r6,28(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + int32_t(28) );
	// addi r31,r29,20
	r31.s64 = r29.s64 + 20;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// subf r11,r9,r6
	r11.s64 = ctx.r6.s64 - ctx.r9.s64;
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// divw. r11,r11,r30
	r11.s32 = r11.s32 / r30.s32;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82585140
	if (!cr0.gt) goto loc_82585140;
loc_825850E8:
	// srawi r10,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r10.s64 = r11.s32 >> 1;
	// rlwinm r8,r10,1,0,30
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// cmpwi cr6,r7,2
	cr6.compare<int32_t>(ctx.r7.s32, 2, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82585110
	if (cr6.lt) goto loc_82585110;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_82585110:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258512c
	if (cr6.eq) goto loc_8258512C;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r9,r9,12
	ctx.r9.s64 = ctx.r9.s64 + 12;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82585134
	goto loc_82585134;
loc_8258512C:
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82585134:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825850e8
	if (cr6.gt) goto loc_825850E8;
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
loc_82585140:
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// beq cr6,0x82585178
	if (cr6.eq) goto loc_82585178;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258515c
	if (cr6.gt) goto loc_8258515C;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8258515C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82585178
	if (!cr6.eq) goto loc_82585178;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// b 0x8258517c
	goto loc_8258517C;
loc_82585178:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_8258517C:
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + int32_t(28) );
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82585194
	if (cr6.eq) goto loc_82585194;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x82585198
	goto loc_82585198;
loc_82585194:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82585198:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825851b8
	if (cr6.eq) goto loc_825851B8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// li r4,32
	ctx.r4.s64 = 32;
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(48) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_825851B8:
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r9,r6
	r11.s64 = ctx.r6.s64 - ctx.r9.s64;
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// divw. r11,r11,r30
	r11.s32 = r11.s32 / r30.s32;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82585230
	if (!cr0.gt) goto loc_82585230;
loc_825851D8:
	// srawi r10,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r10.s64 = r11.s32 >> 1;
	// rlwinm r8,r10,1,0,30
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// cmpwi cr6,r7,3
	cr6.compare<int32_t>(ctx.r7.s32, 3, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82585200
	if (cr6.lt) goto loc_82585200;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_82585200:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258521c
	if (cr6.eq) goto loc_8258521C;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r9,r9,12
	ctx.r9.s64 = ctx.r9.s64 + 12;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82585224
	goto loc_82585224;
loc_8258521C:
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82585224:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825851d8
	if (cr6.gt) goto loc_825851D8;
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
loc_82585230:
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// beq cr6,0x82585268
	if (cr6.eq) goto loc_82585268;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258524c
	if (cr6.gt) goto loc_8258524C;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8258524C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82585268
	if (!cr6.eq) goto loc_82585268;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// b 0x8258526c
	goto loc_8258526C;
loc_82585268:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_8258526C:
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + int32_t(28) );
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82585284
	if (cr6.eq) goto loc_82585284;
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x82585288
	goto loc_82585288;
loc_82585284:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82585288:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585298
	if (cr6.eq) goto loc_82585298;
	// stb r28,12(r5)
	PPC_STORE_U8(ctx.r5.u32 + 12, r28.u8);
loc_82585298:
	// lis r11,-32241
	r11.s64 = -2112946176;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r10,r11,5732
	ctx.r10.s64 = r11.s64 + 5732;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_825852AC:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82584EA0) {
	__imp__sub_82584EA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825852B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,40(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(40) );
	// li r31,0
	r31.s64 = 0;
	// rlwinm r10,r11,15,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825853cc
	if (cr6.eq) goto loc_825853CC;
	// lwz r11,140(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585308
	if (cr6.eq) goto loc_82585308;
	// lbz r10,49(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 49);
	// lwz r11,72(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825853d0
	goto loc_825853D0;
loc_82585308:
	// lwz r10,72(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(72) );
	// lwz r6,76(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82585374
	if (!cr0.gt) goto loc_82585374;
loc_82585324:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,49
	cr6.compare<int32_t>(ctx.r7.s32, 49, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82585344
	if (cr6.lt) goto loc_82585344;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82585344:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82585360
	if (cr6.eq) goto loc_82585360;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82585368
	goto loc_82585368;
loc_82585360:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82585368:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82585324
	if (cr6.gt) goto loc_82585324;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82585374:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825853b8
	if (cr6.eq) goto loc_825853B8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82585390
	if (cr6.gt) goto loc_82585390;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82585390:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825853b8
	if (!cr6.eq) goto loc_825853B8;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825853d0
	goto loc_825853D0;
loc_825853B8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825853d0
	goto loc_825853D0;
loc_825853CC:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_825853D0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258542c
	if (cr6.eq) goto loc_8258542C;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,5
	ctx.r4.s64 = 5;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x826df5a0
	sub_826DF5A0(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r10,r11,2072
	ctx.r10.s64 = r11.s64 + 2072;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lwz r8,84(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(84) );
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x821acc20
	sub_821ACC20(ctx, base);
	// clrlwi r7,r31,24
	ctx.r7.u64 = r31.u32 & 0xFF;
	// li r3,1
	ctx.r3.s64 = 1;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82585430
	if (!cr6.eq) goto loc_82585430;
loc_8258542C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82585430:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825852B8) {
	__imp__sub_825852B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82585448) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,36(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(36) );
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// rlwinm r9,r10,4,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82585554
	if (cr6.eq) goto loc_82585554;
	// lwz r11,140(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(140) );
	// lwz r10,72(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585498
	if (cr6.eq) goto loc_82585498;
	// lbz r11,28(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 28);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x82585558
	goto loc_82585558;
loc_82585498:
	// lwz r6,76(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(76) );
	// li r11,0
	r11.s64 = 0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82585504
	if (!cr0.gt) goto loc_82585504;
loc_825854B4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,28
	cr6.compare<int32_t>(ctx.r7.s32, 28, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825854d4
	if (cr6.lt) goto loc_825854D4;
	// li r7,0
	ctx.r7.s64 = 0;
loc_825854D4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825854f0
	if (cr6.eq) goto loc_825854F0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825854f8
	goto loc_825854F8;
loc_825854F0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825854F8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825854b4
	if (cr6.gt) goto loc_825854B4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82585504:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82585544
	if (cr6.eq) goto loc_82585544;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82585520
	if (cr6.gt) goto loc_82585520;
	// li r11,0
	r11.s64 = 0;
loc_82585520:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82585544
	if (!cr6.eq) goto loc_82585544;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82585558
	goto loc_82585558;
loc_82585544:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82585558
	goto loc_82585558;
loc_82585554:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82585558:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82585574
	if (cr6.eq) goto loc_82585574;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lbz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U8(r31.u32 + 8);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// bl 0x82494378
	sub_82494378(ctx, base);
loc_82585574:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82585448) {
	__imp__sub_82585448(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82585588) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31950
	r11.s64 = -2093875200;
	// lwz r10,40(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(40) );
	// lis r9,-32240
	ctx.r9.s64 = -2112880640;
	// rlwinm r8,r10,15,31,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0x1;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// lfd f0,-27376(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -27376);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// lfd f13,2232(r9)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r9.u32 + 2232);
	// fmul f0,f0,f13
	f0.f64 = f0.f64 * ctx.f13.f64;
	// fctiwz f13,f0
	ctx.f13.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
	// stfd f13,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f13.u64);
	// lwz r29,84(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// beq cr6,0x825856bc
	if (cr6.eq) goto loc_825856BC;
	// lwz r11,140(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825855f8
	if (cr6.eq) goto loc_825855F8;
	// lbz r10,49(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 49);
	// lwz r11,72(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825856c0
	goto loc_825856C0;
loc_825855F8:
	// lwz r10,72(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(72) );
	// lwz r6,76(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82585664
	if (!cr0.gt) goto loc_82585664;
loc_82585614:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,49
	cr6.compare<int32_t>(ctx.r7.s32, 49, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82585634
	if (cr6.lt) goto loc_82585634;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82585634:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82585650
	if (cr6.eq) goto loc_82585650;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82585658
	goto loc_82585658;
loc_82585650:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82585658:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82585614
	if (cr6.gt) goto loc_82585614;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82585664:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825856a8
	if (cr6.eq) goto loc_825856A8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82585680
	if (cr6.gt) goto loc_82585680;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82585680:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825856a8
	if (!cr6.eq) goto loc_825856A8;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825856c0
	goto loc_825856C0;
loc_825856A8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825856c0
	goto loc_825856C0;
loc_825856BC:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_825856C0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585734
	if (cr6.eq) goto loc_82585734;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,6
	ctx.r4.s64 = 6;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x826df5a0
	sub_826DF5A0(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r10,r11,2072
	ctx.r10.s64 = r11.s64 + 2072;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lwz r8,84(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(84) );
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x821acc20
	sub_821ACC20(ctx, base);
	// clrlwi r7,r31,24
	ctx.r7.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82585734
	if (cr6.eq) goto loc_82585734;
	// lis r11,-31950
	r11.s64 = -2093875200;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,-27380(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(-27380) );
	// subf r9,r10,r11
	ctx.r9.s64 = r11.s64 - ctx.r10.s64;
	// cmpw cr6,r9,r29
	cr6.compare<int32_t>(ctx.r9.s32, r29.s32, xer);
	// bgt cr6,0x82585738
	if (cr6.gt) goto loc_82585738;
loc_82585734:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82585738:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82585588) {
	__imp__sub_82585588(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82585740) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r28,0
	r28.s64 = 0;
	// mr r29,r28
	r29.u64 = r28.u64;
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82585858
	if (cr6.eq) goto loc_82585858;
	// lwz r11,140(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585794
	if (cr6.eq) goto loc_82585794;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258585c
	goto loc_8258585C;
loc_82585794:
	// lwz r10,72(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(72) );
	// lwz r6,76(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + int32_t(76) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82585800
	if (!cr0.gt) goto loc_82585800;
loc_825857B0:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825857d0
	if (cr6.lt) goto loc_825857D0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_825857D0:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825857ec
	if (cr6.eq) goto loc_825857EC;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825857f4
	goto loc_825857F4;
loc_825857EC:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825857F4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825857b0
	if (cr6.gt) goto loc_825857B0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82585800:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82585844
	if (cr6.eq) goto loc_82585844;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258581c
	if (cr6.gt) goto loc_8258581C;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8258581C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82585844
	if (!cr6.eq) goto loc_82585844;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258585c
	goto loc_8258585C;
loc_82585844:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258585c
	goto loc_8258585C;
loc_82585858:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8258585C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585acc
	if (cr6.eq) goto loc_82585ACC;
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(44) );
	// mr r31,r28
	r31.u64 = r28.u64;
	// rlwinm r10,r11,19,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258596c
	if (cr6.eq) goto loc_8258596C;
	// lwz r11,140(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825858a8
	if (cr6.eq) goto loc_825858A8;
	// lbz r10,77(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 77);
	// lwz r11,72(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82585970
	goto loc_82585970;
loc_825858A8:
	// lwz r10,72(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(72) );
	// lwz r6,76(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + int32_t(76) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82585914
	if (!cr0.gt) goto loc_82585914;
loc_825858C4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,77
	cr6.compare<int32_t>(ctx.r7.s32, 77, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825858e4
	if (cr6.lt) goto loc_825858E4;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_825858E4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82585900
	if (cr6.eq) goto loc_82585900;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82585908
	goto loc_82585908;
loc_82585900:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82585908:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825858c4
	if (cr6.gt) goto loc_825858C4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82585914:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82585958
	if (cr6.eq) goto loc_82585958;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,77
	cr6.compare<int32_t>(r11.s32, 77, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82585930
	if (cr6.gt) goto loc_82585930;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82585930:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82585958
	if (!cr6.eq) goto loc_82585958;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82585970
	goto loc_82585970;
loc_82585958:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82585970
	goto loc_82585970;
loc_8258596C:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82585970:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825859a8
	if (cr6.eq) goto loc_825859A8;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,112(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(112) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r8,140(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(140) );
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_825859A8:
	// lwz r3,20(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + int32_t(20) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825859c0
	if (cr6.eq) goto loc_825859C0;
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x821e8870
	sub_821E8870(ctx, base);
	// b 0x825859c4
	goto loc_825859C4;
loc_825859C0:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_825859C4:
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825859dc
	if (cr6.eq) goto loc_825859DC;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823c88f0
	sub_823C88F0(ctx, base);
loc_825859DC:
	// li r3,384
	ctx.r3.s64 = 384;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82585a5c
	if (cr6.eq) goto loc_82585A5C;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8248d630
	sub_8248D630(ctx, base);
	// lis r11,-32243
	r11.s64 = -2113077248;
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// addi r9,r11,24808
	ctx.r9.s64 = r11.s64 + 24808;
	// addi r8,r10,5732
	ctx.r8.s64 = ctx.r10.s64 + 5732;
	// li r7,-1
	ctx.r7.s64 = -1;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// stw r8,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r8.u32);
	// li r3,16
	ctx.r3.s64 = 16;
	// stw r28,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r28.u32);
	// stw r7,60(r31)
	PPC_STORE_U32(r31.u32 + 60, ctx.r7.u32);
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82585a30
	if (cr6.eq) goto loc_82585A30;
	// stw r3,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r3.u32);
loc_82585A30:
	// addic. r11,r3,4
	xer.ca = ctx.r3.u32 > 4294967291;
	r11.s64 = ctx.r3.s64 + 4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82585a3c
	if (cr0.eq) goto loc_82585A3C;
	// stw r3,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r3.u32);
loc_82585A3C:
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r28,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r28.u32);
	// addi r3,r31,96
	ctx.r3.s64 = r31.s64 + 96;
	// bl 0x827b5e90
	sub_827B5E90(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x827b3970
	sub_827B3970(ctx, base);
	// b 0x82585a60
	goto loc_82585A60;
loc_82585A5C:
	// mr r31,r28
	r31.u64 = r28.u64;
loc_82585A60:
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82585a7c
	if (cr6.eq) goto loc_82585A7C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x82585a84
	goto loc_82585A84;
loc_82585A7C:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
loc_82585A84:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823c8810
	sub_823C8810(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// addi r11,r31,96
	r11.s64 = r31.s64 + 96;
	// stb r28,28(r31)
	PPC_STORE_U8(r31.u32 + 28, r28.u8);
	// li r9,112
	ctx.r9.s64 = 112;
	// li r8,128
	ctx.r8.s64 = 128;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,144
	ctx.r6.s64 = 144;
	// lfs f0,-27468(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -27468);
	f0.f64 = double(temp.f32);
	// li r5,96
	ctx.r5.s64 = 96;
	// stb r7,44(r31)
	PPC_STORE_U8(r31.u32 + 44, ctx.r7.u8);
	// stfs f0,36(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 36, temp.u32);
	// stfs f0,32(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 32, temp.u32);
	// lvx128 v0,r11,r9
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r11.u32 + ctx.r9.u32) & ~0xF), VectorMaskL));
	// stvx128 v0,r11,r8
	ea = (r11.u32 + ctx.r8.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// stvx128 v0,r11,r6
	ea = (r11.u32 + ctx.r6.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// stvx128 v0,r11,r5
	ea = (r11.u32 + ctx.r5.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
loc_82585ACC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82585740) {
	__imp__sub_82585740(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82585AD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-31950
	r11.s64 = -2093875200;
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(4) );
	// lwz r11,-27380(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(-27380) );
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// li r11,1
	r11.s64 = 1;
	// bge cr6,0x82585af4
	if (!cr6.lt) goto loc_82585AF4;
	// li r11,0
	r11.s64 = 0;
loc_82585AF4:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82585AD8) {
	__imp__sub_82585AD8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82585B00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// li r28,0
	r28.s64 = 0;
	// lwz r11,36(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(36) );
	// rlwinm r10,r11,4,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 4) & 0x1;
	// mr r11,r28
	r11.u64 = r28.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82585c0c
	if (cr6.eq) goto loc_82585C0C;
	// lwz r11,140(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585b50
	if (cr6.eq) goto loc_82585B50;
	// lbz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 28);
	// lwz r11,72(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x82585c10
	goto loc_82585C10;
loc_82585B50:
	// lwz r10,72(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + int32_t(72) );
	// lwz r6,76(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + int32_t(76) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82585bbc
	if (!cr0.gt) goto loc_82585BBC;
loc_82585B6C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,28
	cr6.compare<int32_t>(ctx.r7.s32, 28, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82585b8c
	if (cr6.lt) goto loc_82585B8C;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_82585B8C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82585ba8
	if (cr6.eq) goto loc_82585BA8;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82585bb0
	goto loc_82585BB0;
loc_82585BA8:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82585BB0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82585b6c
	if (cr6.gt) goto loc_82585B6C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82585BBC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82585bfc
	if (cr6.eq) goto loc_82585BFC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82585bd8
	if (cr6.gt) goto loc_82585BD8;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82585BD8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82585bfc
	if (!cr6.eq) goto loc_82585BFC;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82585c10
	goto loc_82585C10;
loc_82585BFC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82585c10
	goto loc_82585C10;
loc_82585C0C:
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
loc_82585C10:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82585c34
	if (cr6.eq) goto loc_82585C34;
	// lwz r10,84(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(84) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82585c34
	if (!cr6.eq) goto loc_82585C34;
	// lwz r11,100(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(100) );
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x82585de0
	if (!cr6.eq) goto loc_82585DE0;
loc_82585C34:
	// lwz r11,40(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(40) );
	// mr r30,r28
	r30.u64 = r28.u64;
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82585d34
	if (cr6.eq) goto loc_82585D34;
	// lwz r11,140(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(140) );
	// lwz r10,72(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585c74
	if (cr6.eq) goto loc_82585C74;
	// lbz r11,33(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82585d38
	goto loc_82585D38;
loc_82585C74:
	// lwz r6,76(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + int32_t(76) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82585cdc
	if (!cr0.gt) goto loc_82585CDC;
loc_82585C8C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82585cac
	if (cr6.lt) goto loc_82585CAC;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_82585CAC:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82585cc8
	if (cr6.eq) goto loc_82585CC8;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82585cd0
	goto loc_82585CD0;
loc_82585CC8:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82585CD0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82585c8c
	if (cr6.gt) goto loc_82585C8C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82585CDC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82585d20
	if (cr6.eq) goto loc_82585D20;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82585cf8
	if (cr6.gt) goto loc_82585CF8;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82585CF8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82585d20
	if (!cr6.eq) goto loc_82585D20;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82585d38
	goto loc_82585D38;
loc_82585D20:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82585d38
	goto loc_82585D38;
loc_82585D34:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82585D38:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585de0
	if (cr6.eq) goto loc_82585DE0;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(20) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82585d5c
	if (cr6.eq) goto loc_82585D5C;
	// li r4,14
	ctx.r4.s64 = 14;
	// bl 0x821e8870
	sub_821E8870(ctx, base);
	// b 0x82585d60
	goto loc_82585D60;
loc_82585D5C:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_82585D60:
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82585de0
	if (!cr6.eq) goto loc_82585DE0;
	// li r3,28
	ctx.r3.s64 = 28;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82585da4
	if (cr6.eq) goto loc_82585DA4;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x82335168
	sub_82335168(ctx, base);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// stb r28,20(r31)
	PPC_STORE_U8(r31.u32 + 20, r28.u8);
	// mr r11,r31
	r11.u64 = r31.u64;
	// addi r9,r10,-26456
	ctx.r9.s64 = ctx.r10.s64 + -26456;
	// stw r28,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r28.u32);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// b 0x82585da8
	goto loc_82585DA8;
loc_82585DA4:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82585DA8:
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585dd0
	if (cr6.eq) goto loc_82585DD0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823c8810
	sub_823C8810(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82585DD0:
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823c8810
	sub_823C8810(ctx, base);
loc_82585DE0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82585B00) {
	__imp__sub_82585B00(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82585DE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,1
	r11.s64 = 1;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stb r11,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r11.u8);
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(124) );
	// bl 0x825bb2c0
	sub_825BB2C0(ctx, base);
	// lis r8,-32246
	ctx.r8.s64 = -2113273856;
	// lis r7,-32246
	ctx.r7.s64 = -2113273856;
	// lfs f0,-27468(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -27468);
	f0.f64 = double(temp.f32);
	// stfs f0,24(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 24, temp.u32);
	// stfs f0,20(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// stfs f0,28(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 28, temp.u32);
	// lfs f0,-28512(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -28512);
	f0.f64 = double(temp.f32);
	// stfs f0,32(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 32, temp.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82585DE8) {
	__imp__sub_82585DE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82585E50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stb r11,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r11.u8);
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(124) );
	// bl 0x825bb370
	sub_825BB370(ctx, base);
	// lwz r3,36(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(36) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82585e94
	if (cr6.eq) goto loc_82585E94;
	// bl 0x828daf08
	sub_828DAF08(ctx, base);
loc_82585E94:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82585E50) {
	__imp__sub_82585E50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82585EA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr1{};
	PPCCRRegister cr2{};
	PPCCRRegister cr3{};
	PPCCRRegister cr4{};
	PPCCRRegister cr5{};
	PPCCRRegister cr6{};
	PPCCRRegister cr7{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCVRegister v125{};
	PPCVRegister v126{};
	PPCVRegister v127{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// addi r12,r1,-112
	r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82ca7500
	// li r12,-208
	r12.s64 = -208;
	// stvx128 v125,r1,r12
	ea = (ctx.r1.u32 + r12.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(v125), &VectorMaskL[(ea & 0xF) * 16]);
	// li r12,-192
	r12.s64 = -192;
	// stvx128 v126,r1,r12
	ea = (ctx.r1.u32 + r12.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(v126), &VectorMaskL[(ea & 0xF) * 16]);
	// li r12,-176
	r12.s64 = -176;
	// stvx128 v127,r1,r12
	ea = (ctx.r1.u32 + r12.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(v127), &VectorMaskL[(ea & 0xF) * 16]);
	// stwu r1,-432(r1)
	ea = -432 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// li r20,0
	r20.s64 = 0;
	// addi r22,r23,4
	r22.s64 = r23.s64 + 4;
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + int32_t(8) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585f20
	if (cr6.eq) goto loc_82585F20;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82585f70
	if (cr6.eq) goto loc_82585F70;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585f20
	if (cr6.eq) goto loc_82585F20;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82585f24
	if (!cr6.eq) goto loc_82585F24;
loc_82585F20:
	// mr r11,r20
	r11.u64 = r20.u64;
loc_82585F24:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586af8
	if (cr6.eq) goto loc_82586AF8;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// mr r31,r20
	r31.u64 = r20.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,18,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82586028
	if (cr6.eq) goto loc_82586028;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82585f7c
	if (cr6.eq) goto loc_82585F7C;
	// lbz r10,110(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 110);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r31,4(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x82586028
	goto loc_82586028;
loc_82585F70:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82585f20
	goto loc_82585F20;
loc_82585F7C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r20.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82585fe8
	if (!cr0.gt) goto loc_82585FE8;
loc_82585F98:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,110
	cr6.compare<int32_t>(ctx.r7.s32, 110, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82585fb8
	if (cr6.lt) goto loc_82585FB8;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
loc_82585FB8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82585fd4
	if (cr6.eq) goto loc_82585FD4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82585fdc
	goto loc_82585FDC;
loc_82585FD4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82585FDC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82585f98
	if (cr6.gt) goto loc_82585F98;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_82585FE8:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82586020
	if (cr6.eq) goto loc_82586020;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,110
	cr6.compare<int32_t>(r11.s32, 110, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82586004
	if (cr6.gt) goto loc_82586004;
	// mr r11,r20
	r11.u64 = r20.u64;
loc_82586004:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82586020
	if (!cr6.eq) goto loc_82586020;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// b 0x82586024
	goto loc_82586024;
loc_82586020:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_82586024:
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_82586028:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r25,124(r3)
	r25.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(124) );
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82586af8
	if (cr6.eq) goto loc_82586AF8;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82586af8
	if (cr6.eq) goto loc_82586AF8;
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + int32_t(0) );
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwz r10,92(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(92) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r20,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r20.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82586af8
	if (cr6.eq) goto loc_82586AF8;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8218dd60
	sub_8218DD60(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586af8
	if (cr6.eq) goto loc_82586AF8;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// lbz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 104);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82586af8
	if (!cr6.eq) goto loc_82586AF8;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(68) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// ld r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r24,r11,-27444
	r24.s64 = r11.s64 + -27444;
	// lwz r8,0(r23)
	ctx.r8.u64 = PPC_LOAD_U32(r23.u32 + int32_t(0) );
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// std r9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r9.u64);
	// lfs f0,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// lfs f31,-24(r24)
	temp.u32 = PPC_LOAD_U32(r24.u32 + -24);
	f31.f64 = double(temp.f32);
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// stfs f31,80(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lwz r10,80(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(80) );
	// lvlx v0,0,r5
	temp.u32 = r0.u32 + ctx.r5.u32;
	simd::store_shuffled(ctx.v0,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// lfs f13,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// stfs f31,96(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lvlx v13,0,r11
	temp.u32 = r0.u32 + r11.u32;
	simd::store_shuffled(ctx.v13,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vrlimi128 v13,v0,4,3
	simd::store_f32(ctx.v13.f32, simd::blend_f32<4>(simd::load_f32(ctx.v13.f32), simd::permute_f32<57>(simd::load_f32(ctx.v0.f32))));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v12,0,r7
	temp.u32 = r0.u32 + ctx.r7.u32;
	simd::store_shuffled(ctx.v12,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// lvlx v11,0,r6
	temp.u32 = r0.u32 + ctx.r6.u32;
	simd::store_shuffled(ctx.v11,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vrlimi128 v11,v12,4,3
	simd::store_f32(ctx.v11.f32, simd::blend_f32<4>(simd::load_f32(ctx.v11.f32), simd::permute_f32<57>(simd::load_f32(ctx.v12.f32))));
	// vrlimi128 v11,v13,3,2
	simd::store_f32(ctx.v11.f32, simd::blend_f32<3>(simd::load_f32(ctx.v11.f32), simd::permute_f32<78>(simd::load_f32(ctx.v13.f32))));
	// stvx128 v11,r0,r9
	ea = (ctx.r9.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v11), &VectorMaskL[(ea & 0xF) * 16]);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// lwz r7,0(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + int32_t(0) );
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// lwz r6,76(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(76) );
	// lvx128 v125,r0,r8
	simd::store_shuffled(v125, simd::load_and_shuffle(base + ((ctx.r8.u32) & ~0xF), VectorMaskL));
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r4,80(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(80) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lvx128 v1,r0,r5
	simd::store_shuffled(ctx.v1, simd::load_and_shuffle(base + ((ctx.r5.u32) & ~0xF), VectorMaskL));
	// mtctr r4
	ctr.u64 = ctx.r4.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// vspltisw v1,0
	simd::store_i32(ctx.v1.u32, simd::set1_i32(int32_t(0x0)));
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	f29.f64 = ctx.f1.f64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,80(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(80) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r9,0(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + int32_t(0) );
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// vor128 v1,v125,v125
	simd::store_i8(ctx.v1.u8, simd::load_i8(v125.u8));
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// lwz r8,44(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(44) );
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r7,0(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + int32_t(0) );
	// fmr f26,f1
	ctx.fpscr.disableFlushMode();
	f26.f64 = ctx.f1.f64;
	// stfs f26,80(r1)
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// lwz r6,76(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(76) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lfs f0,-408(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r24.u32 + -408);
	f0.f64 = double(temp.f32);
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// addi r21,r11,-28336
	r21.s64 = r11.s64 + -28336;
	// lvx128 v10,r0,r3
	simd::store_shuffled(ctx.v10, simd::load_and_shuffle(base + ((ctx.r3.u32) & ~0xF), VectorMaskL));
	// fmuls f12,f26,f0
	ctx.f12.f64 = double(float(f26.f64 * f0.f64));
	// lvx128 v0,r0,r21
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r21.u32) & ~0xF), VectorMaskL));
	// vand v9,v10,v0
	simd::store_u8(ctx.v9.u8, simd::and_u8(simd::load_u8(ctx.v10.u8), simd::load_u8(ctx.v0.u8)));
	// vmsum3fp128 v8,v9,v10
	ctx.fpscr.enableFlushModeUnconditional();
	simd::store_f32_aligned(ctx.v8.f32, simd::dp_f32(simd::load_f32_aligned(ctx.v9.f32), simd::load_f32_aligned(ctx.v10.f32), 0xEF));
	// lis r11,-32240
	r11.s64 = -2112880640;
	// lis r28,-31950
	r28.s64 = -2093875200;
	// addi r30,r11,368
	r30.s64 = r11.s64 + 368;
	// stvx128 v8,r0,r5
	ea = (ctx.r5.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v8), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f11,144(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f11.f64 = double(temp.f32);
	// fsqrts f27,f11
	f27.f64 = double(simd::sqrt_f32(float(ctx.f11.f64)));
	// fcmpu cr6,f27,f12
	cr6.compare(f27.f64, ctx.f12.f64);
	// ble cr6,0x8258625c
	if (!cr6.gt) goto loc_8258625C;
	// lfs f13,28(r23)
	temp.u32 = PPC_LOAD_U32(r23.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,24512(r24)
	temp.u32 = PPC_LOAD_U32(r24.u32 + 24512);
	f0.f64 = double(temp.f32);
	// fadds f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f12,28(r23)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r23.u32 + 28, temp.u32);
	// lfs f13,9340(r24)
	temp.u32 = PPC_LOAD_U32(r24.u32 + 9340);
	ctx.f13.f64 = double(temp.f32);
	// fmr f11,f12
	ctx.f11.f64 = ctx.f12.f64;
	// fcmpu cr6,f11,f31
	cr6.compare(ctx.f11.f64, f31.f64);
	// mfcr r11
	r11.u64 = 0;
	r11.u64 |= (cr0.lt ? 0x80000000 : 0);
	r11.u64 |= (cr0.gt ? 0x40000000 : 0);
	r11.u64 |= (cr0.eq ? 0x20000000 : 0);
	r11.u64 |= (cr0.so ? 0x10000000 : 0);
	r11.u64 |= (cr1.lt ? 0x08000000 : 0);
	r11.u64 |= (cr1.gt ? 0x04000000 : 0);
	r11.u64 |= (cr1.eq ? 0x02000000 : 0);
	r11.u64 |= (cr1.so ? 0x01000000 : 0);
	r11.u64 |= (cr2.lt ? 0x00800000 : 0);
	r11.u64 |= (cr2.gt ? 0x00400000 : 0);
	r11.u64 |= (cr2.eq ? 0x00200000 : 0);
	r11.u64 |= (cr2.so ? 0x00100000 : 0);
	r11.u64 |= (cr3.lt ? 0x00080000 : 0);
	r11.u64 |= (cr3.gt ? 0x00040000 : 0);
	r11.u64 |= (cr3.eq ? 0x00020000 : 0);
	r11.u64 |= (cr3.so ? 0x00010000 : 0);
	r11.u64 |= (cr4.lt ? 0x00008000 : 0);
	r11.u64 |= (cr4.gt ? 0x00004000 : 0);
	r11.u64 |= (cr4.eq ? 0x00002000 : 0);
	r11.u64 |= (cr4.so ? 0x00001000 : 0);
	r11.u64 |= (cr5.lt ? 0x00000800 : 0);
	r11.u64 |= (cr5.gt ? 0x00000400 : 0);
	r11.u64 |= (cr5.eq ? 0x00000200 : 0);
	r11.u64 |= (cr5.so ? 0x00000100 : 0);
	r11.u64 |= (cr6.lt ? 0x00000080 : 0);
	r11.u64 |= (cr6.gt ? 0x00000040 : 0);
	r11.u64 |= (cr6.eq ? 0x00000020 : 0);
	r11.u64 |= (cr6.so ? 0x00000010 : 0);
	r11.u64 |= (cr7.lt ? 0x00000008 : 0);
	r11.u64 |= (cr7.gt ? 0x00000004 : 0);
	r11.u64 |= (cr7.eq ? 0x00000002 : 0);
	r11.u64 |= (cr7.so ? 0x00000001 : 0);
	// rlwinm r10,r11,27,29,29
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x4;
	// lfs f0,-24792(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + -24792);
	f0.f64 = double(temp.f32);
	// rlwinm r9,r11,30,29,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x4;
	// or r8,r10,r9
	ctx.r8.u64 = ctx.r10.u64 | ctx.r9.u64;
	// lfsx f10,r30,r8
	temp.u32 = PPC_LOAD_U32(r30.u32 + ctx.r8.u32);
	ctx.f10.f64 = double(temp.f32);
	// fsel f9,f10,f11,f31
	ctx.f9.f64 = ctx.f10.f64 >= 0.0 ? ctx.f11.f64 : f31.f64;
	// fsubs f8,f9,f0
	ctx.f8.f64 = static_cast<float>(ctx.f9.f64 - f0.f64);
	// fcmpu cr6,f8,f31
	cr6.compare(ctx.f8.f64, f31.f64);
	// mfcr r7
	ctx.r7.u64 = 0;
	ctx.r7.u64 |= (cr0.lt ? 0x80000000 : 0);
	ctx.r7.u64 |= (cr0.gt ? 0x40000000 : 0);
	ctx.r7.u64 |= (cr0.eq ? 0x20000000 : 0);
	ctx.r7.u64 |= (cr0.so ? 0x10000000 : 0);
	ctx.r7.u64 |= (cr1.lt ? 0x08000000 : 0);
	ctx.r7.u64 |= (cr1.gt ? 0x04000000 : 0);
	ctx.r7.u64 |= (cr1.eq ? 0x02000000 : 0);
	ctx.r7.u64 |= (cr1.so ? 0x01000000 : 0);
	ctx.r7.u64 |= (cr2.lt ? 0x00800000 : 0);
	ctx.r7.u64 |= (cr2.gt ? 0x00400000 : 0);
	ctx.r7.u64 |= (cr2.eq ? 0x00200000 : 0);
	ctx.r7.u64 |= (cr2.so ? 0x00100000 : 0);
	ctx.r7.u64 |= (cr3.lt ? 0x00080000 : 0);
	ctx.r7.u64 |= (cr3.gt ? 0x00040000 : 0);
	ctx.r7.u64 |= (cr3.eq ? 0x00020000 : 0);
	ctx.r7.u64 |= (cr3.so ? 0x00010000 : 0);
	ctx.r7.u64 |= (cr4.lt ? 0x00008000 : 0);
	ctx.r7.u64 |= (cr4.gt ? 0x00004000 : 0);
	ctx.r7.u64 |= (cr4.eq ? 0x00002000 : 0);
	ctx.r7.u64 |= (cr4.so ? 0x00001000 : 0);
	ctx.r7.u64 |= (cr5.lt ? 0x00000800 : 0);
	ctx.r7.u64 |= (cr5.gt ? 0x00000400 : 0);
	ctx.r7.u64 |= (cr5.eq ? 0x00000200 : 0);
	ctx.r7.u64 |= (cr5.so ? 0x00000100 : 0);
	ctx.r7.u64 |= (cr6.lt ? 0x00000080 : 0);
	ctx.r7.u64 |= (cr6.gt ? 0x00000040 : 0);
	ctx.r7.u64 |= (cr6.eq ? 0x00000020 : 0);
	ctx.r7.u64 |= (cr6.so ? 0x00000010 : 0);
	ctx.r7.u64 |= (cr7.lt ? 0x00000008 : 0);
	ctx.r7.u64 |= (cr7.gt ? 0x00000004 : 0);
	ctx.r7.u64 |= (cr7.eq ? 0x00000002 : 0);
	ctx.r7.u64 |= (cr7.so ? 0x00000001 : 0);
	// rlwinm r6,r7,27,29,29
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x4;
	// rlwinm r5,r7,30,29,29
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 30) & 0x4;
	// or r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 | ctx.r5.u64;
	// lfsx f7,r30,r4
	temp.u32 = PPC_LOAD_U32(r30.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsel f6,f7,f0,f9
	ctx.f6.f64 = ctx.f7.f64 >= 0.0 ? f0.f64 : ctx.f9.f64;
	// stfs f6,28(r23)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r23.u32 + 28, temp.u32);
	// lfs f5,32(r23)
	temp.u32 = PPC_LOAD_U32(r23.u32 + 32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f5,f13
	ctx.f4.f64 = static_cast<float>(ctx.f5.f64 - ctx.f13.f64);
	// stfs f4,32(r23)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r23.u32 + 32, temp.u32);
	// b 0x82586264
	goto loc_82586264;
loc_8258625C:
	// stfs f31,28(r23)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r23.u32 + 28, temp.u32);
	// stfs f30,32(r23)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r23.u32 + 32, temp.u32);
loc_82586264:
	// lfs f13,32(r23)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r23.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// fsubs f12,f13,f29
	ctx.f12.f64 = static_cast<float>(ctx.f13.f64 - f29.f64);
	// lis r27,-32246
	r27.s64 = -2113273856;
	// mr r29,r20
	r29.u64 = r20.u64;
	// lfs f0,-25888(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -25888);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f12,f31
	cr6.compare(ctx.f12.f64, f31.f64);
	// mfcr r10
	ctx.r10.u64 = 0;
	ctx.r10.u64 |= (cr0.lt ? 0x80000000 : 0);
	ctx.r10.u64 |= (cr0.gt ? 0x40000000 : 0);
	ctx.r10.u64 |= (cr0.eq ? 0x20000000 : 0);
	ctx.r10.u64 |= (cr0.so ? 0x10000000 : 0);
	ctx.r10.u64 |= (cr1.lt ? 0x08000000 : 0);
	ctx.r10.u64 |= (cr1.gt ? 0x04000000 : 0);
	ctx.r10.u64 |= (cr1.eq ? 0x02000000 : 0);
	ctx.r10.u64 |= (cr1.so ? 0x01000000 : 0);
	ctx.r10.u64 |= (cr2.lt ? 0x00800000 : 0);
	ctx.r10.u64 |= (cr2.gt ? 0x00400000 : 0);
	ctx.r10.u64 |= (cr2.eq ? 0x00200000 : 0);
	ctx.r10.u64 |= (cr2.so ? 0x00100000 : 0);
	ctx.r10.u64 |= (cr3.lt ? 0x00080000 : 0);
	ctx.r10.u64 |= (cr3.gt ? 0x00040000 : 0);
	ctx.r10.u64 |= (cr3.eq ? 0x00020000 : 0);
	ctx.r10.u64 |= (cr3.so ? 0x00010000 : 0);
	ctx.r10.u64 |= (cr4.lt ? 0x00008000 : 0);
	ctx.r10.u64 |= (cr4.gt ? 0x00004000 : 0);
	ctx.r10.u64 |= (cr4.eq ? 0x00002000 : 0);
	ctx.r10.u64 |= (cr4.so ? 0x00001000 : 0);
	ctx.r10.u64 |= (cr5.lt ? 0x00000800 : 0);
	ctx.r10.u64 |= (cr5.gt ? 0x00000400 : 0);
	ctx.r10.u64 |= (cr5.eq ? 0x00000200 : 0);
	ctx.r10.u64 |= (cr5.so ? 0x00000100 : 0);
	ctx.r10.u64 |= (cr6.lt ? 0x00000080 : 0);
	ctx.r10.u64 |= (cr6.gt ? 0x00000040 : 0);
	ctx.r10.u64 |= (cr6.eq ? 0x00000020 : 0);
	ctx.r10.u64 |= (cr6.so ? 0x00000010 : 0);
	ctx.r10.u64 |= (cr7.lt ? 0x00000008 : 0);
	ctx.r10.u64 |= (cr7.gt ? 0x00000004 : 0);
	ctx.r10.u64 |= (cr7.eq ? 0x00000002 : 0);
	ctx.r10.u64 |= (cr7.so ? 0x00000001 : 0);
	// rlwinm r9,r10,27,29,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x4;
	// rlwinm r8,r10,30,29,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x4;
	// or r7,r9,r8
	ctx.r7.u64 = ctx.r9.u64 | ctx.r8.u64;
	// lfsx f11,r30,r7
	temp.u32 = PPC_LOAD_U32(r30.u32 + ctx.r7.u32);
	ctx.f11.f64 = double(temp.f32);
	// fsel f10,f11,f13,f29
	ctx.f10.f64 = ctx.f11.f64 >= 0.0 ? ctx.f13.f64 : f29.f64;
	// fsubs f9,f10,f30
	ctx.f9.f64 = static_cast<float>(ctx.f10.f64 - f30.f64);
	// fcmpu cr6,f9,f31
	cr6.compare(ctx.f9.f64, f31.f64);
	// mfcr r6
	ctx.r6.u64 = 0;
	ctx.r6.u64 |= (cr0.lt ? 0x80000000 : 0);
	ctx.r6.u64 |= (cr0.gt ? 0x40000000 : 0);
	ctx.r6.u64 |= (cr0.eq ? 0x20000000 : 0);
	ctx.r6.u64 |= (cr0.so ? 0x10000000 : 0);
	ctx.r6.u64 |= (cr1.lt ? 0x08000000 : 0);
	ctx.r6.u64 |= (cr1.gt ? 0x04000000 : 0);
	ctx.r6.u64 |= (cr1.eq ? 0x02000000 : 0);
	ctx.r6.u64 |= (cr1.so ? 0x01000000 : 0);
	ctx.r6.u64 |= (cr2.lt ? 0x00800000 : 0);
	ctx.r6.u64 |= (cr2.gt ? 0x00400000 : 0);
	ctx.r6.u64 |= (cr2.eq ? 0x00200000 : 0);
	ctx.r6.u64 |= (cr2.so ? 0x00100000 : 0);
	ctx.r6.u64 |= (cr3.lt ? 0x00080000 : 0);
	ctx.r6.u64 |= (cr3.gt ? 0x00040000 : 0);
	ctx.r6.u64 |= (cr3.eq ? 0x00020000 : 0);
	ctx.r6.u64 |= (cr3.so ? 0x00010000 : 0);
	ctx.r6.u64 |= (cr4.lt ? 0x00008000 : 0);
	ctx.r6.u64 |= (cr4.gt ? 0x00004000 : 0);
	ctx.r6.u64 |= (cr4.eq ? 0x00002000 : 0);
	ctx.r6.u64 |= (cr4.so ? 0x00001000 : 0);
	ctx.r6.u64 |= (cr5.lt ? 0x00000800 : 0);
	ctx.r6.u64 |= (cr5.gt ? 0x00000400 : 0);
	ctx.r6.u64 |= (cr5.eq ? 0x00000200 : 0);
	ctx.r6.u64 |= (cr5.so ? 0x00000100 : 0);
	ctx.r6.u64 |= (cr6.lt ? 0x00000080 : 0);
	ctx.r6.u64 |= (cr6.gt ? 0x00000040 : 0);
	ctx.r6.u64 |= (cr6.eq ? 0x00000020 : 0);
	ctx.r6.u64 |= (cr6.so ? 0x00000010 : 0);
	ctx.r6.u64 |= (cr7.lt ? 0x00000008 : 0);
	ctx.r6.u64 |= (cr7.gt ? 0x00000004 : 0);
	ctx.r6.u64 |= (cr7.eq ? 0x00000002 : 0);
	ctx.r6.u64 |= (cr7.so ? 0x00000001 : 0);
	// rlwinm r5,r6,27,29,29
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 27) & 0x4;
	// rlwinm r4,r6,30,29,29
	ctx.r4.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x4;
	// or r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 | ctx.r4.u64;
	// lfsx f8,r30,r3
	temp.u32 = PPC_LOAD_U32(r30.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsel f7,f8,f30,f10
	ctx.f7.f64 = ctx.f8.f64 >= 0.0 ? f30.f64 : ctx.f10.f64;
	// stfs f7,32(r23)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(r23.u32 + 32, temp.u32);
	// lvx128 v0,r0,r21
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r21.u32) & ~0xF), VectorMaskL));
	// vand128 v0,v125,v0
	simd::store_u8(ctx.v0.u8, simd::and_u8(simd::load_u8(v125.u8), simd::load_u8(ctx.v0.u8)));
	// vmsum3fp128 v13,v0,v125
	ctx.fpscr.enableFlushModeUnconditional();
	simd::store_f32_aligned(ctx.v13.f32, simd::dp_f32(simd::load_f32_aligned(ctx.v0.f32), simd::load_f32_aligned(v125.f32), 0xEF));
	// stvx128 v13,r0,r11
	ea = (r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v13), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f6,144(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// fsqrts f5,f6
	ctx.f5.f64 = double(simd::sqrt_f32(float(ctx.f6.f64)));
	// fcmpu cr6,f5,f0
	cr6.compare(ctx.f5.f64, f0.f64);
	// ble cr6,0x825862e0
	if (!cr6.gt) goto loc_825862E0;
	// li r29,1
	r29.s64 = 1;
loc_825862E0:
	// lis r11,-32241
	r11.s64 = -2112946176;
	// stw r20,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r20.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// addi r9,r11,5732
	ctx.r9.s64 = r11.s64 + 5732;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// stw r10,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r10.u32);
	// stw r9,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r9.u32);
	// mr r31,r20
	r31.u64 = r20.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r8,40(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r7,r8,15,31,31
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 15) & 0x1;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82586404
	if (cr6.eq) goto loc_82586404;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586340
	if (cr6.eq) goto loc_82586340;
	// lbz r10,49(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 49);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82586408
	goto loc_82586408;
loc_82586340:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r20.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825863ac
	if (!cr0.gt) goto loc_825863AC;
loc_8258635C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,49
	cr6.compare<int32_t>(ctx.r7.s32, 49, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258637c
	if (cr6.lt) goto loc_8258637C;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
loc_8258637C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82586398
	if (cr6.eq) goto loc_82586398;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825863a0
	goto loc_825863A0;
loc_82586398:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825863A0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258635c
	if (cr6.gt) goto loc_8258635C;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_825863AC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825863f0
	if (cr6.eq) goto loc_825863F0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825863c8
	if (cr6.gt) goto loc_825863C8;
	// mr r11,r20
	r11.u64 = r20.u64;
loc_825863C8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825863f0
	if (!cr6.eq) goto loc_825863F0;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82586408
	goto loc_82586408;
loc_825863F0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82586408
	goto loc_82586408;
loc_82586404:
	// mr r11,r20
	r11.u64 = r20.u64;
loc_82586408:
	// clrlwi r10,r11,24
	ctx.r10.u64 = r11.u32 & 0xFF;
	// lis r11,-32241
	r11.s64 = -2112946176;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// addi r26,r11,5732
	r26.s64 = r11.s64 + 5732;
	// beq cr6,0x82586498
	if (cr6.eq) goto loc_82586498;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(88) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi r9,r3,24
	ctx.r9.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82586498
	if (cr6.eq) goto loc_82586498;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r10,112(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(112) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// bl 0x82978470
	sub_82978470(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r19,8(r19)
	r19.u64 = PPC_LOAD_U32(r19.u32 + int32_t(8) );
	// stw r26,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r26.u32);
	// stw r19,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r19.u32);
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// cmpwi cr6,r19,0
	cr6.compare<int32_t>(r19.s32, 0, xer);
	// stw r20,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r20.u32);
	// blt cr6,0x82586498
	if (cr6.lt) goto loc_82586498;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x822982f8
	sub_822982F8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x8258649c
	if (!cr6.eq) goto loc_8258649C;
loc_82586498:
	// mr r11,r20
	r11.u64 = r20.u64;
loc_8258649C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825864e4
	if (cr6.eq) goto loc_825864E4;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x822b5598
	sub_822B5598(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825864e4
	if (!cr6.eq) goto loc_825864E4;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x822bdbc0
	sub_822BDBC0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825864e4
	if (!cr6.eq) goto loc_825864E4;
	// lwz r3,36(r23)
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + int32_t(36) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82586aec
	if (cr6.eq) goto loc_82586AEC;
	// bl 0x828daf08
	sub_828DAF08(ctx, base);
	// b 0x82586aec
	goto loc_82586AEC;
loc_825864E4:
	// clrlwi r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586564
	if (cr6.eq) goto loc_82586564;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82586564
	if (cr6.eq) goto loc_82586564;
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(120) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x82586518
	if (cr6.lt) goto loc_82586518;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x822982f8
	sub_822982F8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x8258651c
	if (!cr6.eq) goto loc_8258651C;
loc_82586518:
	// mr r11,r20
	r11.u64 = r20.u64;
loc_8258651C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586564
	if (cr6.eq) goto loc_82586564;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x822b5598
	sub_822B5598(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82586564
	if (!cr6.eq) goto loc_82586564;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x822bdbc0
	sub_822BDBC0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586564
	if (cr6.eq) goto loc_82586564;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82586564:
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + int32_t(0) );
	// vor128 v1,v125,v125
	simd::store_i8(ctx.v1.u8, simd::load_i8(v125.u8));
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(68) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// fmr f29,f31
	ctx.fpscr.disableFlushMode();
	f29.f64 = f31.f64;
	// fmr f30,f31
	f30.f64 = f31.f64;
	// bl 0x821f5a90
	sub_821F5A90(ctx, base);
	// lfs f28,-25888(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + -25888);
	f28.f64 = double(temp.f32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// fmr f1,f28
	ctx.f1.f64 = f28.f64;
	// bl 0x821ee7c8
	sub_821EE7C8(ctx, base);
	// fcmpu cr6,f1,f28
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f28.f64);
	// ble cr6,0x825865c8
	if (!cr6.gt) goto loc_825865C8;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r9,r11,-28384
	ctx.r9.s64 = r11.s64 + -28384;
	// lvx128 v13,r0,r10
	simd::store_shuffled(ctx.v13, simd::load_and_shuffle(base + ((ctx.r10.u32) & ~0xF), VectorMaskL));
	// lvx128 v0,r0,r9
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((ctx.r9.u32) & ~0xF), VectorMaskL));
	// vand128 v127,v13,v0
	simd::store_u8(v127.u8, simd::and_u8(simd::load_u8(ctx.v13.u8), simd::load_u8(ctx.v0.u8)));
	// b 0x825865d0
	goto loc_825865D0;
loc_825865C8:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lvx128 v127,r0,r11
	simd::store_shuffled(v127, simd::load_and_shuffle(base + ((r11.u32) & ~0xF), VectorMaskL));
loc_825865D0:
	// addi r11,r1,176
	r11.s64 = ctx.r1.s64 + 176;
	// lvx128 v13,r0,r21
	simd::store_shuffled(ctx.v13, simd::load_and_shuffle(base + ((r21.u32) & ~0xF), VectorMaskL));
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// lvx128 v0,r0,r11
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r11.u32) & ~0xF), VectorMaskL));
	// vand v13,v0,v13
	simd::store_u8(ctx.v13.u8, simd::and_u8(simd::load_u8(ctx.v0.u8), simd::load_u8(ctx.v13.u8)));
	// lfd f1,2432(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + 2432);
	// vor128 v126,v0,v0
	simd::store_i8(v126.u8, simd::load_i8(ctx.v0.u8));
	// vmsum3fp128 v12,v13,v127
	ctx.fpscr.enableFlushModeUnconditional();
	simd::store_f32_aligned(ctx.v12.f32, simd::dp_f32(simd::load_f32_aligned(ctx.v13.f32), simd::load_f32_aligned(v127.f32), 0xEF));
	// stvx128 v12,r0,r9
	ea = (ctx.r9.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v12), &VectorMaskL[(ea & 0xF) * 16]);
	// bl 0x82239e88
	sub_82239E88(ctx, base);
	// frsp f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64));
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x825867c8
	if (!cr6.lt) goto loc_825867C8;
	// lfs f29,18744(r24)
	temp.u32 = PPC_LOAD_U32(r24.u32 + 18744);
	f29.f64 = double(temp.f32);
	// fsubs f13,f0,f29
	ctx.f13.f64 = static_cast<float>(f0.f64 - f29.f64);
	// lfs f28,-12(r24)
	temp.u32 = PPC_LOAD_U32(r24.u32 + -12);
	f28.f64 = double(temp.f32);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// mfcr r11
	r11.u64 = 0;
	r11.u64 |= (cr0.lt ? 0x80000000 : 0);
	r11.u64 |= (cr0.gt ? 0x40000000 : 0);
	r11.u64 |= (cr0.eq ? 0x20000000 : 0);
	r11.u64 |= (cr0.so ? 0x10000000 : 0);
	r11.u64 |= (cr1.lt ? 0x08000000 : 0);
	r11.u64 |= (cr1.gt ? 0x04000000 : 0);
	r11.u64 |= (cr1.eq ? 0x02000000 : 0);
	r11.u64 |= (cr1.so ? 0x01000000 : 0);
	r11.u64 |= (cr2.lt ? 0x00800000 : 0);
	r11.u64 |= (cr2.gt ? 0x00400000 : 0);
	r11.u64 |= (cr2.eq ? 0x00200000 : 0);
	r11.u64 |= (cr2.so ? 0x00100000 : 0);
	r11.u64 |= (cr3.lt ? 0x00080000 : 0);
	r11.u64 |= (cr3.gt ? 0x00040000 : 0);
	r11.u64 |= (cr3.eq ? 0x00020000 : 0);
	r11.u64 |= (cr3.so ? 0x00010000 : 0);
	r11.u64 |= (cr4.lt ? 0x00008000 : 0);
	r11.u64 |= (cr4.gt ? 0x00004000 : 0);
	r11.u64 |= (cr4.eq ? 0x00002000 : 0);
	r11.u64 |= (cr4.so ? 0x00001000 : 0);
	r11.u64 |= (cr5.lt ? 0x00000800 : 0);
	r11.u64 |= (cr5.gt ? 0x00000400 : 0);
	r11.u64 |= (cr5.eq ? 0x00000200 : 0);
	r11.u64 |= (cr5.so ? 0x00000100 : 0);
	r11.u64 |= (cr6.lt ? 0x00000080 : 0);
	r11.u64 |= (cr6.gt ? 0x00000040 : 0);
	r11.u64 |= (cr6.eq ? 0x00000020 : 0);
	r11.u64 |= (cr6.so ? 0x00000010 : 0);
	r11.u64 |= (cr7.lt ? 0x00000008 : 0);
	r11.u64 |= (cr7.gt ? 0x00000004 : 0);
	r11.u64 |= (cr7.eq ? 0x00000002 : 0);
	r11.u64 |= (cr7.so ? 0x00000001 : 0);
	// rlwinm r10,r11,27,29,29
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x4;
	// rlwinm r9,r11,30,29,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x4;
	// or r8,r10,r9
	ctx.r8.u64 = ctx.r10.u64 | ctx.r9.u64;
	// lfsx f12,r30,r8
	temp.u32 = PPC_LOAD_U32(r30.u32 + ctx.r8.u32);
	ctx.f12.f64 = double(temp.f32);
	// fsel f11,f12,f0,f29
	ctx.f11.f64 = ctx.f12.f64 >= 0.0 ? f0.f64 : f29.f64;
	// fsubs f10,f11,f28
	ctx.f10.f64 = static_cast<float>(ctx.f11.f64 - f28.f64);
	// fcmpu cr6,f10,f31
	cr6.compare(ctx.f10.f64, f31.f64);
	// mfcr r7
	ctx.r7.u64 = 0;
	ctx.r7.u64 |= (cr0.lt ? 0x80000000 : 0);
	ctx.r7.u64 |= (cr0.gt ? 0x40000000 : 0);
	ctx.r7.u64 |= (cr0.eq ? 0x20000000 : 0);
	ctx.r7.u64 |= (cr0.so ? 0x10000000 : 0);
	ctx.r7.u64 |= (cr1.lt ? 0x08000000 : 0);
	ctx.r7.u64 |= (cr1.gt ? 0x04000000 : 0);
	ctx.r7.u64 |= (cr1.eq ? 0x02000000 : 0);
	ctx.r7.u64 |= (cr1.so ? 0x01000000 : 0);
	ctx.r7.u64 |= (cr2.lt ? 0x00800000 : 0);
	ctx.r7.u64 |= (cr2.gt ? 0x00400000 : 0);
	ctx.r7.u64 |= (cr2.eq ? 0x00200000 : 0);
	ctx.r7.u64 |= (cr2.so ? 0x00100000 : 0);
	ctx.r7.u64 |= (cr3.lt ? 0x00080000 : 0);
	ctx.r7.u64 |= (cr3.gt ? 0x00040000 : 0);
	ctx.r7.u64 |= (cr3.eq ? 0x00020000 : 0);
	ctx.r7.u64 |= (cr3.so ? 0x00010000 : 0);
	ctx.r7.u64 |= (cr4.lt ? 0x00008000 : 0);
	ctx.r7.u64 |= (cr4.gt ? 0x00004000 : 0);
	ctx.r7.u64 |= (cr4.eq ? 0x00002000 : 0);
	ctx.r7.u64 |= (cr4.so ? 0x00001000 : 0);
	ctx.r7.u64 |= (cr5.lt ? 0x00000800 : 0);
	ctx.r7.u64 |= (cr5.gt ? 0x00000400 : 0);
	ctx.r7.u64 |= (cr5.eq ? 0x00000200 : 0);
	ctx.r7.u64 |= (cr5.so ? 0x00000100 : 0);
	ctx.r7.u64 |= (cr6.lt ? 0x00000080 : 0);
	ctx.r7.u64 |= (cr6.gt ? 0x00000040 : 0);
	ctx.r7.u64 |= (cr6.eq ? 0x00000020 : 0);
	ctx.r7.u64 |= (cr6.so ? 0x00000010 : 0);
	ctx.r7.u64 |= (cr7.lt ? 0x00000008 : 0);
	ctx.r7.u64 |= (cr7.gt ? 0x00000004 : 0);
	ctx.r7.u64 |= (cr7.eq ? 0x00000002 : 0);
	ctx.r7.u64 |= (cr7.so ? 0x00000001 : 0);
	// rlwinm r6,r7,27,29,29
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x4;
	// rlwinm r5,r7,30,29,29
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 30) & 0x4;
	// or r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 | ctx.r5.u64;
	// lfsx f9,r30,r4
	temp.u32 = PPC_LOAD_U32(r30.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsel f1,f9,f28,f11
	ctx.f1.f64 = ctx.f9.f64 >= 0.0 ? f28.f64 : ctx.f11.f64;
	// bl 0x82260900
	sub_82260900(ctx, base);
	// vpermwi128 v0,v127,99
	simd::store_i32(ctx.v0.u32, simd::permute_i32_dispatch(simd::load_i32(v127.u32), 0x9C));
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// vpermwi128 v13,v126,135
	simd::store_i32(ctx.v13.u32, simd::permute_i32_dispatch(simd::load_i32(v126.u32), 0x78));
	// frsp f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = double(float(ctx.f1.f64));
	// vpermwi128 v12,v127,135
	simd::store_i32(ctx.v12.u32, simd::permute_i32_dispatch(simd::load_i32(v127.u32), 0x78));
	// vpermwi128 v11,v126,99
	simd::store_i32(ctx.v11.u32, simd::permute_i32_dispatch(simd::load_i32(v126.u32), 0x9C));
	// vmulfp128 v10,v13,v0
	ctx.fpscr.enableFlushModeUnconditional();
	simd::store_f32_aligned(ctx.v10.f32, simd::mul_f32(simd::load_f32_aligned(ctx.v13.f32), simd::load_f32_aligned(ctx.v0.f32)));
	// vmulfp128 v9,v11,v12
	simd::store_f32_aligned(ctx.v9.f32, simd::mul_f32(simd::load_f32_aligned(ctx.v11.f32), simd::load_f32_aligned(ctx.v12.f32)));
	// vsubfp v8,v9,v10
	simd::store_f32_aligned(ctx.v8.f32, simd::sub_f32(simd::load_f32_aligned(ctx.v9.f32), simd::load_f32_aligned(ctx.v10.f32)));
	// stvx128 v8,r0,r3
	ea = (ctx.r3.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v8), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f8,104(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f8.f64 = double(temp.f32);
	// fcmpu cr6,f8,f31
	cr6.compare(ctx.f8.f64, f31.f64);
	// ble cr6,0x82586690
	if (!cr6.gt) goto loc_82586690;
	// fmuls f30,f30,f29
	f30.f64 = double(float(f30.f64 * f29.f64));
loc_82586690:
	// lis r11,-31950
	r11.s64 = -2093875200;
	// lfs f12,32(r23)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r23.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// fabs f0,f30
	f0.u64 = f30.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmr f29,f30
	f29.f64 = f30.f64;
	// lfd f13,-27376(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -27376);
	// fdiv f11,f12,f13
	ctx.f11.f64 = ctx.f12.f64 / ctx.f13.f64;
	// frsp f13,f11
	ctx.f13.f64 = double(float(ctx.f11.f64));
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x825866bc
	if (!cr6.gt) goto loc_825866BC;
	// fdivs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 / f0.f64));
	// fmuls f29,f0,f30
	f29.f64 = double(float(f0.f64 * f30.f64));
loc_825866BC:
	// lwz r11,4(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825866fc
	if (cr6.eq) goto loc_825866FC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258693c
	if (cr6.eq) goto loc_8258693C;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825866fc
	if (cr6.eq) goto loc_825866FC;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82586700
	if (!cr6.eq) goto loc_82586700;
loc_825866FC:
	// mr r11,r20
	r11.u64 = r20.u64;
loc_82586700:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586aec
	if (cr6.eq) goto loc_82586AEC;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// bl 0x82889a20
	sub_82889A20(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// stfs f28,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// addi r9,r10,-28240
	ctx.r9.s64 = ctx.r10.s64 + -28240;
	// lvlx v0,0,r11
	temp.u32 = r0.u32 + r11.u32;
	simd::store_shuffled(ctx.v0,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vspltw v13,v0,0
	simd::store_i32(ctx.v13.u32, simd::broadcast_lane_i32(simd::load_i32(ctx.v0.u32), 3));
	// lvx128 v0,r0,r9
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((ctx.r9.u32) & ~0xF), VectorMaskL));
	// vand v2,v13,v0
	simd::store_u8(ctx.v2.u8, simd::and_u8(simd::load_u8(ctx.v13.u8), simd::load_u8(ctx.v0.u8)));
	// bl 0x828786b8
	sub_828786B8(ctx, base);
	// lfs f11,28(r23)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r23.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f30,f11
	ctx.f10.f64 = double(float(f30.f64 * ctx.f11.f64));
	// lis r8,-32240
	ctx.r8.s64 = -2112880640;
	// lfs f0,0(r24)
	temp.u32 = PPC_LOAD_U32(r24.u32 + 0);
	f0.f64 = double(temp.f32);
	// fmuls f12,f26,f0
	ctx.f12.f64 = double(float(f26.f64 * f0.f64));
	// lfs f13,2424(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2424);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f10,f13
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f0,-24792(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + -24792);
	f0.f64 = double(temp.f32);
	// fneg f9,f0
	ctx.f9.u64 = f0.u64 ^ 0x8000000000000000;
	// fsubs f7,f8,f9
	ctx.f7.f64 = static_cast<float>(ctx.f8.f64 - ctx.f9.f64);
	// fcmpu cr6,f7,f31
	cr6.compare(ctx.f7.f64, f31.f64);
	// mfcr r7
	ctx.r7.u64 = 0;
	ctx.r7.u64 |= (cr0.lt ? 0x80000000 : 0);
	ctx.r7.u64 |= (cr0.gt ? 0x40000000 : 0);
	ctx.r7.u64 |= (cr0.eq ? 0x20000000 : 0);
	ctx.r7.u64 |= (cr0.so ? 0x10000000 : 0);
	ctx.r7.u64 |= (cr1.lt ? 0x08000000 : 0);
	ctx.r7.u64 |= (cr1.gt ? 0x04000000 : 0);
	ctx.r7.u64 |= (cr1.eq ? 0x02000000 : 0);
	ctx.r7.u64 |= (cr1.so ? 0x01000000 : 0);
	ctx.r7.u64 |= (cr2.lt ? 0x00800000 : 0);
	ctx.r7.u64 |= (cr2.gt ? 0x00400000 : 0);
	ctx.r7.u64 |= (cr2.eq ? 0x00200000 : 0);
	ctx.r7.u64 |= (cr2.so ? 0x00100000 : 0);
	ctx.r7.u64 |= (cr3.lt ? 0x00080000 : 0);
	ctx.r7.u64 |= (cr3.gt ? 0x00040000 : 0);
	ctx.r7.u64 |= (cr3.eq ? 0x00020000 : 0);
	ctx.r7.u64 |= (cr3.so ? 0x00010000 : 0);
	ctx.r7.u64 |= (cr4.lt ? 0x00008000 : 0);
	ctx.r7.u64 |= (cr4.gt ? 0x00004000 : 0);
	ctx.r7.u64 |= (cr4.eq ? 0x00002000 : 0);
	ctx.r7.u64 |= (cr4.so ? 0x00001000 : 0);
	ctx.r7.u64 |= (cr5.lt ? 0x00000800 : 0);
	ctx.r7.u64 |= (cr5.gt ? 0x00000400 : 0);
	ctx.r7.u64 |= (cr5.eq ? 0x00000200 : 0);
	ctx.r7.u64 |= (cr5.so ? 0x00000100 : 0);
	ctx.r7.u64 |= (cr6.lt ? 0x00000080 : 0);
	ctx.r7.u64 |= (cr6.gt ? 0x00000040 : 0);
	ctx.r7.u64 |= (cr6.eq ? 0x00000020 : 0);
	ctx.r7.u64 |= (cr6.so ? 0x00000010 : 0);
	ctx.r7.u64 |= (cr7.lt ? 0x00000008 : 0);
	ctx.r7.u64 |= (cr7.gt ? 0x00000004 : 0);
	ctx.r7.u64 |= (cr7.eq ? 0x00000002 : 0);
	ctx.r7.u64 |= (cr7.so ? 0x00000001 : 0);
	// rlwinm r6,r7,27,29,29
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x4;
	// rlwinm r5,r7,30,29,29
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 30) & 0x4;
	// or r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 | ctx.r5.u64;
	// lfsx f6,r30,r4
	temp.u32 = PPC_LOAD_U32(r30.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsel f5,f6,f8,f9
	ctx.f5.f64 = ctx.f6.f64 >= 0.0 ? ctx.f8.f64 : ctx.f9.f64;
	// fsubs f4,f5,f0
	ctx.f4.f64 = static_cast<float>(ctx.f5.f64 - f0.f64);
	// fcmpu cr6,f4,f31
	cr6.compare(ctx.f4.f64, f31.f64);
	// mfcr r3
	ctx.r3.u64 = 0;
	ctx.r3.u64 |= (cr0.lt ? 0x80000000 : 0);
	ctx.r3.u64 |= (cr0.gt ? 0x40000000 : 0);
	ctx.r3.u64 |= (cr0.eq ? 0x20000000 : 0);
	ctx.r3.u64 |= (cr0.so ? 0x10000000 : 0);
	ctx.r3.u64 |= (cr1.lt ? 0x08000000 : 0);
	ctx.r3.u64 |= (cr1.gt ? 0x04000000 : 0);
	ctx.r3.u64 |= (cr1.eq ? 0x02000000 : 0);
	ctx.r3.u64 |= (cr1.so ? 0x01000000 : 0);
	ctx.r3.u64 |= (cr2.lt ? 0x00800000 : 0);
	ctx.r3.u64 |= (cr2.gt ? 0x00400000 : 0);
	ctx.r3.u64 |= (cr2.eq ? 0x00200000 : 0);
	ctx.r3.u64 |= (cr2.so ? 0x00100000 : 0);
	ctx.r3.u64 |= (cr3.lt ? 0x00080000 : 0);
	ctx.r3.u64 |= (cr3.gt ? 0x00040000 : 0);
	ctx.r3.u64 |= (cr3.eq ? 0x00020000 : 0);
	ctx.r3.u64 |= (cr3.so ? 0x00010000 : 0);
	ctx.r3.u64 |= (cr4.lt ? 0x00008000 : 0);
	ctx.r3.u64 |= (cr4.gt ? 0x00004000 : 0);
	ctx.r3.u64 |= (cr4.eq ? 0x00002000 : 0);
	ctx.r3.u64 |= (cr4.so ? 0x00001000 : 0);
	ctx.r3.u64 |= (cr5.lt ? 0x00000800 : 0);
	ctx.r3.u64 |= (cr5.gt ? 0x00000400 : 0);
	ctx.r3.u64 |= (cr5.eq ? 0x00000200 : 0);
	ctx.r3.u64 |= (cr5.so ? 0x00000100 : 0);
	ctx.r3.u64 |= (cr6.lt ? 0x00000080 : 0);
	ctx.r3.u64 |= (cr6.gt ? 0x00000040 : 0);
	ctx.r3.u64 |= (cr6.eq ? 0x00000020 : 0);
	ctx.r3.u64 |= (cr6.so ? 0x00000010 : 0);
	ctx.r3.u64 |= (cr7.lt ? 0x00000008 : 0);
	ctx.r3.u64 |= (cr7.gt ? 0x00000004 : 0);
	ctx.r3.u64 |= (cr7.eq ? 0x00000002 : 0);
	ctx.r3.u64 |= (cr7.so ? 0x00000001 : 0);
	// rlwinm r11,r3,27,29,29
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 27) & 0x4;
	// fcmpu cr6,f27,f12
	cr6.compare(f27.f64, ctx.f12.f64);
	// rlwinm r10,r3,30,29,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 30) & 0x4;
	// or r9,r11,r10
	ctx.r9.u64 = r11.u64 | ctx.r10.u64;
	// lfsx f3,r30,r9
	temp.u32 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsel f29,f3,f0,f5
	f29.f64 = ctx.f3.f64 >= 0.0 ? f0.f64 : ctx.f5.f64;
	// ble cr6,0x825867c8
	if (!cr6.gt) goto loc_825867C8;
	// fabs f13,f30
	ctx.f13.u64 = f30.u64 & 0x7FFFFFFFFFFFFFFF;
	// lis r11,-32240
	r11.s64 = -2112880640;
	// lfs f0,2252(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2252);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x825867c8
	if (!cr6.gt) goto loc_825867C8;
	// fmr f29,f31
	f29.f64 = f31.f64;
loc_825867C8:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// bl 0x821f5a90
	sub_821F5A90(ctx, base);
	// stfs f29,24(r23)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r23.u32 + 24, temp.u32);
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f2,-28492(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28492);
	ctx.f2.f64 = double(temp.f32);
	// lvx128 v127,r0,r10
	simd::store_shuffled(v127, simd::load_and_shuffle(base + ((ctx.r10.u32) & ~0xF), VectorMaskL));
	// vor128 v1,v127,v127
	simd::store_i8(ctx.v1.u8, simd::load_i8(v127.u8));
	// bl 0x8223a048
	sub_8223A048(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// lwz r31,0(r25)
	r31.u64 = PPC_LOAD_U32(r25.u32 + int32_t(0) );
	// lwz r8,68(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + int32_t(68) );
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// ld r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// ld r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// ld r6,0(r7)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r7.u32 + 0);
	// ld r7,8(r7)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r7.u32 + 8);
	// bl 0x822331d0
	sub_822331D0(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(104) );
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// ld r4,0(r6)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r6.u32 + 0);
	// ld r5,8(r6)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r6.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lfs f0,10848(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r24.u32 + 10848);
	f0.f64 = double(temp.f32);
	// fmuls f12,f30,f0
	ctx.f12.f64 = double(float(f30.f64 * f0.f64));
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// lis r9,-32240
	ctx.r9.s64 = -2112880640;
	// lfs f10,20(r23)
	temp.u32 = PPC_LOAD_U32(r23.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fabs f9,f10
	ctx.f9.u64 = ctx.f10.u64 & 0x7FFFFFFFFFFFFFFF;
	// lfs f0,1976(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1976);
	f0.f64 = double(temp.f32);
	// lfs f13,360(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 360);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f11,f12,f0
	ctx.f11.f64 = static_cast<float>(ctx.f12.f64 - f0.f64);
	// fcmpu cr6,f11,f31
	cr6.compare(ctx.f11.f64, f31.f64);
	// mfcr r8
	ctx.r8.u64 = 0;
	ctx.r8.u64 |= (cr0.lt ? 0x80000000 : 0);
	ctx.r8.u64 |= (cr0.gt ? 0x40000000 : 0);
	ctx.r8.u64 |= (cr0.eq ? 0x20000000 : 0);
	ctx.r8.u64 |= (cr0.so ? 0x10000000 : 0);
	ctx.r8.u64 |= (cr1.lt ? 0x08000000 : 0);
	ctx.r8.u64 |= (cr1.gt ? 0x04000000 : 0);
	ctx.r8.u64 |= (cr1.eq ? 0x02000000 : 0);
	ctx.r8.u64 |= (cr1.so ? 0x01000000 : 0);
	ctx.r8.u64 |= (cr2.lt ? 0x00800000 : 0);
	ctx.r8.u64 |= (cr2.gt ? 0x00400000 : 0);
	ctx.r8.u64 |= (cr2.eq ? 0x00200000 : 0);
	ctx.r8.u64 |= (cr2.so ? 0x00100000 : 0);
	ctx.r8.u64 |= (cr3.lt ? 0x00080000 : 0);
	ctx.r8.u64 |= (cr3.gt ? 0x00040000 : 0);
	ctx.r8.u64 |= (cr3.eq ? 0x00020000 : 0);
	ctx.r8.u64 |= (cr3.so ? 0x00010000 : 0);
	ctx.r8.u64 |= (cr4.lt ? 0x00008000 : 0);
	ctx.r8.u64 |= (cr4.gt ? 0x00004000 : 0);
	ctx.r8.u64 |= (cr4.eq ? 0x00002000 : 0);
	ctx.r8.u64 |= (cr4.so ? 0x00001000 : 0);
	ctx.r8.u64 |= (cr5.lt ? 0x00000800 : 0);
	ctx.r8.u64 |= (cr5.gt ? 0x00000400 : 0);
	ctx.r8.u64 |= (cr5.eq ? 0x00000200 : 0);
	ctx.r8.u64 |= (cr5.so ? 0x00000100 : 0);
	ctx.r8.u64 |= (cr6.lt ? 0x00000080 : 0);
	ctx.r8.u64 |= (cr6.gt ? 0x00000040 : 0);
	ctx.r8.u64 |= (cr6.eq ? 0x00000020 : 0);
	ctx.r8.u64 |= (cr6.so ? 0x00000010 : 0);
	ctx.r8.u64 |= (cr7.lt ? 0x00000008 : 0);
	ctx.r8.u64 |= (cr7.gt ? 0x00000004 : 0);
	ctx.r8.u64 |= (cr7.eq ? 0x00000002 : 0);
	ctx.r8.u64 |= (cr7.so ? 0x00000001 : 0);
	// rlwinm r7,r8,27,29,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x4;
	// rlwinm r6,r8,30,29,29
	ctx.r6.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 30) & 0x4;
	// or r5,r7,r6
	ctx.r5.u64 = ctx.r7.u64 | ctx.r6.u64;
	// lfsx f8,r30,r5
	temp.u32 = PPC_LOAD_U32(r30.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsel f7,f8,f12,f0
	ctx.f7.f64 = ctx.f8.f64 >= 0.0 ? ctx.f12.f64 : f0.f64;
	// fsubs f6,f7,f13
	ctx.f6.f64 = static_cast<float>(ctx.f7.f64 - ctx.f13.f64);
	// fcmpu cr6,f6,f31
	cr6.compare(ctx.f6.f64, f31.f64);
	// mfcr r4
	ctx.r4.u64 = 0;
	ctx.r4.u64 |= (cr0.lt ? 0x80000000 : 0);
	ctx.r4.u64 |= (cr0.gt ? 0x40000000 : 0);
	ctx.r4.u64 |= (cr0.eq ? 0x20000000 : 0);
	ctx.r4.u64 |= (cr0.so ? 0x10000000 : 0);
	ctx.r4.u64 |= (cr1.lt ? 0x08000000 : 0);
	ctx.r4.u64 |= (cr1.gt ? 0x04000000 : 0);
	ctx.r4.u64 |= (cr1.eq ? 0x02000000 : 0);
	ctx.r4.u64 |= (cr1.so ? 0x01000000 : 0);
	ctx.r4.u64 |= (cr2.lt ? 0x00800000 : 0);
	ctx.r4.u64 |= (cr2.gt ? 0x00400000 : 0);
	ctx.r4.u64 |= (cr2.eq ? 0x00200000 : 0);
	ctx.r4.u64 |= (cr2.so ? 0x00100000 : 0);
	ctx.r4.u64 |= (cr3.lt ? 0x00080000 : 0);
	ctx.r4.u64 |= (cr3.gt ? 0x00040000 : 0);
	ctx.r4.u64 |= (cr3.eq ? 0x00020000 : 0);
	ctx.r4.u64 |= (cr3.so ? 0x00010000 : 0);
	ctx.r4.u64 |= (cr4.lt ? 0x00008000 : 0);
	ctx.r4.u64 |= (cr4.gt ? 0x00004000 : 0);
	ctx.r4.u64 |= (cr4.eq ? 0x00002000 : 0);
	ctx.r4.u64 |= (cr4.so ? 0x00001000 : 0);
	ctx.r4.u64 |= (cr5.lt ? 0x00000800 : 0);
	ctx.r4.u64 |= (cr5.gt ? 0x00000400 : 0);
	ctx.r4.u64 |= (cr5.eq ? 0x00000200 : 0);
	ctx.r4.u64 |= (cr5.so ? 0x00000100 : 0);
	ctx.r4.u64 |= (cr6.lt ? 0x00000080 : 0);
	ctx.r4.u64 |= (cr6.gt ? 0x00000040 : 0);
	ctx.r4.u64 |= (cr6.eq ? 0x00000020 : 0);
	ctx.r4.u64 |= (cr6.so ? 0x00000010 : 0);
	ctx.r4.u64 |= (cr7.lt ? 0x00000008 : 0);
	ctx.r4.u64 |= (cr7.gt ? 0x00000004 : 0);
	ctx.r4.u64 |= (cr7.eq ? 0x00000002 : 0);
	ctx.r4.u64 |= (cr7.so ? 0x00000001 : 0);
	// rlwinm r3,r4,27,29,29
	ctx.r3.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x4;
	// rlwinm r11,r4,30,29,29
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x4;
	// or r10,r3,r11
	ctx.r10.u64 = ctx.r3.u64 | r11.u64;
	// lfsx f5,r30,r10
	temp.u32 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsel f0,f5,f13,f7
	f0.f64 = ctx.f5.f64 >= 0.0 ? ctx.f13.f64 : ctx.f7.f64;
	// fabs f4,f0
	ctx.f4.u64 = f0.u64 & 0x7FFFFFFFFFFFFFFF;
	// fcmpu cr6,f4,f9
	cr6.compare(ctx.f4.f64, ctx.f9.f64);
	// ble cr6,0x825868c4
	if (!cr6.gt) goto loc_825868C4;
	// stfs f0,20(r23)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r23.u32 + 20, temp.u32);
loc_825868C4:
	// lfs f0,20(r23)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r23.u32 + 20);
	f0.f64 = double(temp.f32);
	// fabs f12,f0
	ctx.f12.u64 = f0.u64 & 0x7FFFFFFFFFFFFFFF;
	// lfs f13,-25888(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -25888);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// ble cr6,0x825868fc
	if (!cr6.gt) goto loc_825868FC;
	// fabs f12,f0
	ctx.f12.u64 = f0.u64 & 0x7FFFFFFFFFFFFFFF;
	// lfs f13,-404(r24)
	temp.u32 = PPC_LOAD_U32(r24.u32 + -404);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f11,f0,f12
	ctx.f11.f64 = double(float(f0.f64 / ctx.f12.f64));
	// fnmsubs f10,f11,f13,f0
	ctx.f10.f64 = -double(std::fma(float(ctx.f11.f64), float(ctx.f13.f64), -float(f0.f64)));
	// stfs f10,20(r23)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r23.u32 + 20, temp.u32);
	// fabs f9,f10
	ctx.f9.u64 = ctx.f10.u64 & 0x7FFFFFFFFFFFFFFF;
	// fcmpu cr6,f9,f13
	cr6.compare(ctx.f9.f64, ctx.f13.f64);
	// bge cr6,0x825868fc
	if (!cr6.lt) goto loc_825868FC;
	// stfs f31,20(r23)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r23.u32 + 20, temp.u32);
loc_825868FC:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,52(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(52) );
	// rlwinm r10,r11,14,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 14) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82586a04
	if (cr6.eq) goto loc_82586A04;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586948
	if (cr6.eq) goto loc_82586948;
	// lbz r10,146(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 146);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x82586a0c
	goto loc_82586A0C;
loc_8258693C:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x825866fc
	goto loc_825866FC;
loc_82586948:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r20.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825869b4
	if (!cr0.gt) goto loc_825869B4;
loc_82586964:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,146
	cr6.compare<int32_t>(ctx.r7.s32, 146, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82586984
	if (cr6.lt) goto loc_82586984;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
loc_82586984:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825869a0
	if (cr6.eq) goto loc_825869A0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825869a8
	goto loc_825869A8;
loc_825869A0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825869A8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82586964
	if (cr6.gt) goto loc_82586964;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_825869B4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825869f4
	if (cr6.eq) goto loc_825869F4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,146
	cr6.compare<int32_t>(r11.s32, 146, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825869d0
	if (cr6.gt) goto loc_825869D0;
	// mr r11,r20
	r11.u64 = r20.u64;
loc_825869D0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825869f4
	if (!cr6.eq) goto loc_825869F4;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82586a0c
	goto loc_82586A0C;
loc_825869F4:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82586a0c
	goto loc_82586A0C;
loc_82586A04:
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// mr r10,r20
	ctx.r10.u64 = r20.u64;
loc_82586A0C:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82586a30
	if (cr6.eq) goto loc_82586A30;
	// lbz r11,36(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586a30
	if (cr6.eq) goto loc_82586A30;
	// lfs f0,17792(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r24.u32 + 17792);
	f0.f64 = double(temp.f32);
	// fmuls f0,f26,f0
	f0.f64 = double(float(f26.f64 * f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
loc_82586A30:
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + int32_t(0) );
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi r9,r3,24
	ctx.r9.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82586a9c
	if (cr6.eq) goto loc_82586A9C;
	// lvx128 v0,r0,r21
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r21.u32) & ~0xF), VectorMaskL));
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// vand128 v0,v125,v0
	simd::store_u8(ctx.v0.u8, simd::and_u8(simd::load_u8(v125.u8), simd::load_u8(ctx.v0.u8)));
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r8,r1,144
	ctx.r8.s64 = ctx.r1.s64 + 144;
	// vmsum3fp128 v13,v0,v125
	ctx.fpscr.enableFlushMode();
	simd::store_f32_aligned(ctx.v13.f32, simd::dp_f32(simd::load_f32_aligned(ctx.v0.f32), simd::load_f32_aligned(v125.f32), 0xEF));
	// lvlx v12,0,r10
	temp.u32 = r0.u32 + ctx.r10.u32;
	simd::store_shuffled(ctx.v12,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vspltw v11,v12,0
	simd::store_i32(ctx.v11.u32, simd::broadcast_lane_i32(simd::load_i32(ctx.v12.u32), 3));
	// vmulfp128 v10,v127,v11
	simd::store_f32_aligned(ctx.v10.f32, simd::mul_f32(simd::load_f32_aligned(v127.f32), simd::load_f32_aligned(ctx.v11.f32)));
	// stvx128 v13,r0,r11
	ea = (r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v13), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f0,192(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	f0.f64 = double(temp.f32);
	// fsqrts f13,f0
	ctx.f13.f64 = double(simd::sqrt_f32(float(f0.f64)));
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lvlx v9,0,r9
	temp.u32 = r0.u32 + ctx.r9.u32;
	simd::store_shuffled(ctx.v9,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vspltw v8,v9,0
	simd::store_i32(ctx.v8.u32, simd::broadcast_lane_i32(simd::load_i32(ctx.v9.u32), 3));
	// vmulfp128 v7,v10,v8
	ctx.fpscr.enableFlushModeUnconditional();
	simd::store_f32_aligned(ctx.v7.f32, simd::mul_f32(simd::load_f32_aligned(ctx.v10.f32), simd::load_f32_aligned(ctx.v8.f32)));
	// stvx128 v7,r0,r8
	ea = (ctx.r8.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v7), &VectorMaskL[(ea & 0xF) * 16]);
	// b 0x82586ab4
	goto loc_82586AB4;
loc_82586A9C:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// lvlx v0,0,r11
	temp.u32 = r0.u32 + r11.u32;
	simd::store_shuffled(ctx.v0,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vspltw v13,v0,0
	simd::store_i32(ctx.v13.u32, simd::broadcast_lane_i32(simd::load_i32(ctx.v0.u32), 3));
	// vmulfp128 v12,v125,v13
	ctx.fpscr.enableFlushMode();
	simd::store_f32_aligned(ctx.v12.f32, simd::mul_f32(simd::load_f32_aligned(v125.f32), simd::load_f32_aligned(ctx.v13.f32)));
	// stvx128 v12,r0,r10
	ea = (ctx.r10.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v12), &VectorMaskL[(ea & 0xF) * 16]);
loc_82586AB4:
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + int32_t(0) );
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// lwz r10,76(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// lwz r8,0(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + int32_t(0) );
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lvx128 v1,r0,r9
	simd::store_shuffled(ctx.v1, simd::load_and_shuffle(base + ((ctx.r9.u32) & ~0xF), VectorMaskL));
	// lwz r7,128(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(128) );
	// mtctr r7
	ctr.u64 = ctx.r7.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82586AEC:
	// stw r26,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r26.u32);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82586AF8:
	// addi r1,r1,432
	ctx.r1.s64 = ctx.r1.s64 + 432;
	// li r0,-208
	r0.s64 = -208;
	// lvx128 v125,r1,r0
	simd::store_shuffled(v125, simd::load_and_shuffle(base + ((ctx.r1.u32 + r0.u32) & ~0xF), VectorMaskL));
	// li r0,-192
	r0.s64 = -192;
	// lvx128 v126,r1,r0
	simd::store_shuffled(v126, simd::load_and_shuffle(base + ((ctx.r1.u32 + r0.u32) & ~0xF), VectorMaskL));
	// li r0,-176
	r0.s64 = -176;
	// lvx128 v127,r1,r0
	simd::store_shuffled(v127, simd::load_and_shuffle(base + ((ctx.r1.u32 + r0.u32) & ~0xF), VectorMaskL));
	// addi r12,r1,-112
	r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82ca754c
	// b 0x82ca2c14
	return;
}

PPC_WEAK_FUNC(sub_82585EA8) {
	__imp__sub_82585EA8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82586B20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(8) );
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r31,r4,4
	r31.s64 = ctx.r4.s64 + 4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586b7c
	if (cr6.eq) goto loc_82586B7C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82586be8
	if (cr6.eq) goto loc_82586BE8;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586b7c
	if (cr6.eq) goto loc_82586B7C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82586b80
	if (!cr6.eq) goto loc_82586B80;
loc_82586B7C:
	// li r11,0
	r11.s64 = 0;
loc_82586B80:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586c04
	if (cr6.eq) goto loc_82586C04;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// bl 0x821f5a90
	sub_821F5A90(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f1,-25888(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -25888);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821ee7c8
	sub_821EE7C8(ctx, base);
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r8,r9,-27456
	ctx.r8.s64 = ctx.r9.s64 + -27456;
	// lfs f0,-12(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -12);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// beq cr6,0x82586bf4
	if (cr6.eq) goto loc_82586BF4;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r9,r11,-28384
	ctx.r9.s64 = r11.s64 + -28384;
	// lvx128 v13,r0,r10
	simd::store_shuffled(ctx.v13, simd::load_and_shuffle(base + ((ctx.r10.u32) & ~0xF), VectorMaskL));
	// lvx128 v0,r0,r9
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((ctx.r9.u32) & ~0xF), VectorMaskL));
	// vand v0,v13,v0
	simd::store_u8(ctx.v0.u8, simd::and_u8(simd::load_u8(ctx.v13.u8), simd::load_u8(ctx.v0.u8)));
	// stvx128 v0,r0,r30
	ea = (r30.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// b 0x82586c30
	goto loc_82586C30;
loc_82586BE8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82586b7c
	goto loc_82586B7C;
loc_82586BF4:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lvx128 v0,r0,r11
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r11.u32) & ~0xF), VectorMaskL));
	// stvx128 v0,r0,r30
	ea = (r30.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// b 0x82586c30
	goto loc_82586C30;
loc_82586C04:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r8,r9,-28256
	ctx.r8.s64 = ctx.r9.s64 + -28256;
	// lfs f0,-27456(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -27456);
	f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r10
	temp.u32 = r0.u32 + ctx.r10.u32;
	simd::store_shuffled(ctx.v0,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vspltw v13,v0,0
	simd::store_i32(ctx.v13.u32, simd::broadcast_lane_i32(simd::load_i32(ctx.v0.u32), 3));
	// lvx128 v0,r0,r8
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((ctx.r8.u32) & ~0xF), VectorMaskL));
	// vand v12,v13,v0
	simd::store_u8(ctx.v12.u8, simd::and_u8(simd::load_u8(ctx.v13.u8), simd::load_u8(ctx.v0.u8)));
	// stvx128 v12,r0,r30
	ea = (r30.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v12), &VectorMaskL[(ea & 0xF) * 16]);
loc_82586C30:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82586B20) {
	__imp__sub_82586B20(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82586C50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82335168
	sub_82335168(ctx, base);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// li r11,0
	r11.s64 = 0;
	// addi r9,r10,2200
	ctx.r9.s64 = ctx.r10.s64 + 2200;
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// stw r11,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r11.u32);
	// stw r8,60(r31)
	PPC_STORE_U32(r31.u32 + 60, ctx.r8.u32);
	// stw r11,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82586C50) {
	__imp__sub_82586C50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82586CB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(64) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82586d20
	if (cr6.eq) goto loc_82586D20;
	// addi r9,r3,4
	ctx.r9.s64 = ctx.r3.s64 + 4;
loc_82586CE4:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x82586ce4
	if (!cr0.eq) goto loc_82586CE4;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82586d18
	if (!cr6.eq) goto loc_82586D18;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82586D18:
	// li r11,0
	r11.s64 = 0;
	// stw r11,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r11.u32);
loc_82586D20:
	// addi r3,r31,52
	ctx.r3.s64 = r31.s64 + 52;
	// bl 0x829ff648
	sub_829FF648(ctx, base);
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// bl 0x829ff648
	sub_829FF648(ctx, base);
	// addi r3,r31,36
	ctx.r3.s64 = r31.s64 + 36;
	// bl 0x829ff648
	sub_829FF648(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825962a8
	sub_825962A8(ctx, base);
	// clrlwi r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586d58
	if (cr6.eq) goto loc_82586D58;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82586D58:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82586CB8) {
	__imp__sub_82586CB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82586D70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r11,1
	r11.s64 = 1;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// stb r11,16(r26)
	PPC_STORE_U8(r26.u32 + 16, r11.u8);
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(124) );
	// bl 0x825bb2c0
	sub_825BB2C0(ctx, base);
	// lis r8,-32246
	ctx.r8.s64 = -2113273856;
	// lis r7,-31950
	ctx.r7.s64 = -2093875200;
	// lfs f0,-27468(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -27468);
	f0.f64 = double(temp.f32);
	// li r27,0
	r27.s64 = 0;
	// stfs f0,28(r26)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r26.u32 + 28, temp.u32);
	// stfs f0,24(r26)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r26.u32 + 24, temp.u32);
	// addi r30,r26,4
	r30.s64 = r26.s64 + 4;
	// stb r27,20(r26)
	PPC_STORE_U8(r26.u32 + 20, r27.u8);
	// lwz r11,-27380(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(-27380) );
	// stw r11,32(r26)
	PPC_STORE_U32(r26.u32 + 32, r11.u32);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(8) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586e08
	if (cr6.eq) goto loc_82586E08;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82586e60
	if (cr6.eq) goto loc_82586E60;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586e08
	if (cr6.eq) goto loc_82586E08;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82586e0c
	if (!cr6.eq) goto loc_82586E0C;
loc_82586E08:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82586E0C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825877c4
	if (cr6.eq) goto loc_825877C4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r25,2
	r25.s64 = 2;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,29,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82586f30
	if (cr6.eq) goto loc_82586F30;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586e6c
	if (cr6.eq) goto loc_82586E6C;
	// lbz r10,99(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 99);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82586f38
	goto loc_82586F38;
loc_82586E60:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82586e08
	goto loc_82586E08;
loc_82586E6C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82586ed8
	if (!cr0.gt) goto loc_82586ED8;
loc_82586E88:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,99
	cr6.compare<int32_t>(ctx.r7.s32, 99, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82586ea8
	if (cr6.lt) goto loc_82586EA8;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
loc_82586EA8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82586ec4
	if (cr6.eq) goto loc_82586EC4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82586ecc
	goto loc_82586ECC;
loc_82586EC4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82586ECC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82586e88
	if (cr6.gt) goto loc_82586E88;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_82586ED8:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82586f1c
	if (cr6.eq) goto loc_82586F1C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,99
	cr6.compare<int32_t>(r11.s32, 99, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82586ef4
	if (cr6.gt) goto loc_82586EF4;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82586EF4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82586f1c
	if (!cr6.eq) goto loc_82586F1C;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82586f38
	goto loc_82586F38;
loc_82586F1C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82586f38
	goto loc_82586F38;
loc_82586F30:
	// lwz r31,104(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(104) );
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82586F38:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586f88
	if (cr6.eq) goto loc_82586F88;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82586f6c
	if (cr6.eq) goto loc_82586F6C;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// stw r27,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r27.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r10,r11,-32268
	ctx.r10.s64 = r11.s64 + -32268;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// b 0x82586f70
	goto loc_82586F70;
loc_82586F6C:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
loc_82586F70:
	// addi r3,r26,36
	ctx.r3.s64 = r26.s64 + 36;
	// bl 0x8238a848
	sub_8238A848(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,36(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + int32_t(36) );
	// bl 0x822b3bb0
	sub_822B3BB0(ctx, base);
	// lwz r25,16(r31)
	r25.u64 = PPC_LOAD_U32(r31.u32 + int32_t(16) );
loc_82586F88:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,11,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 11) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82587090
	if (cr6.eq) goto loc_82587090;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82586fcc
	if (cr6.eq) goto loc_82586FCC;
	// lbz r10,21(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 21);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r28,r11
	r28.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587098
	goto loc_82587098;
loc_82586FCC:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82587038
	if (!cr0.gt) goto loc_82587038;
loc_82586FE8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,21
	cr6.compare<int32_t>(ctx.r7.s32, 21, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82587008
	if (cr6.lt) goto loc_82587008;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
loc_82587008:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82587024
	if (cr6.eq) goto loc_82587024;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258702c
	goto loc_8258702C;
loc_82587024:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258702C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82586fe8
	if (cr6.gt) goto loc_82586FE8;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_82587038:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258707c
	if (cr6.eq) goto loc_8258707C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82587054
	if (cr6.gt) goto loc_82587054;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82587054:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258707c
	if (!cr6.eq) goto loc_8258707C;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r28,r11
	r28.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587098
	goto loc_82587098;
loc_8258707C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r28,r11
	r28.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587098
	goto loc_82587098;
loc_82587090:
	// lwz r28,104(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(104) );
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82587098:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825877c4
	if (cr6.eq) goto loc_825877C4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,13,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825871ac
	if (cr6.eq) goto loc_825871AC;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825870e8
	if (cr6.eq) goto loc_825870E8;
	// lbz r10,19(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 19);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825871b4
	goto loc_825871B4;
loc_825870E8:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82587154
	if (!cr0.gt) goto loc_82587154;
loc_82587104:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,19
	cr6.compare<int32_t>(ctx.r7.s32, 19, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82587124
	if (cr6.lt) goto loc_82587124;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
loc_82587124:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82587140
	if (cr6.eq) goto loc_82587140;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82587148
	goto loc_82587148;
loc_82587140:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82587148:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82587104
	if (cr6.gt) goto loc_82587104;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_82587154:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82587198
	if (cr6.eq) goto loc_82587198;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82587170
	if (cr6.gt) goto loc_82587170;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82587170:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82587198
	if (!cr6.eq) goto loc_82587198;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825871b4
	goto loc_825871B4;
loc_82587198:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825871b4
	goto loc_825871B4;
loc_825871AC:
	// lwz r29,104(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(104) );
	// mr r11,r27
	r11.u64 = r27.u64;
loc_825871B4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825877c4
	if (cr6.eq) goto loc_825877C4;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,1948
	ctx.r4.s64 = r11.s64 + 1948;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r31,r27
	r31.u64 = r27.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 36);
	// clrlwi r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x825872e0
	if (cr6.eq) goto loc_825872E0;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258721c
	if (cr6.eq) goto loc_8258721C;
	// lbz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 24);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825872e4
	goto loc_825872E4;
loc_8258721C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82587288
	if (!cr0.gt) goto loc_82587288;
loc_82587238:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,24
	cr6.compare<int32_t>(ctx.r7.s32, 24, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82587258
	if (cr6.lt) goto loc_82587258;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
loc_82587258:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82587274
	if (cr6.eq) goto loc_82587274;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258727c
	goto loc_8258727C;
loc_82587274:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258727C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82587238
	if (cr6.gt) goto loc_82587238;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_82587288:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825872cc
	if (cr6.eq) goto loc_825872CC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,24
	cr6.compare<int32_t>(r11.s32, 24, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825872a4
	if (cr6.gt) goto loc_825872A4;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_825872A4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825872cc
	if (!cr6.eq) goto loc_825872CC;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825872e4
	goto loc_825872E4;
loc_825872CC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825872e4
	goto loc_825872E4;
loc_825872E0:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_825872E4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825875d0
	if (cr6.eq) goto loc_825875D0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824fff48
	sub_824FFF48(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x825875d0
	if (cr6.eq) goto loc_825875D0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r31,r27
	r31.u64 = r27.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,4,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 4) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258740c
	if (cr6.eq) goto loc_8258740C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587348
	if (cr6.eq) goto loc_82587348;
	// lbz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 28);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587410
	goto loc_82587410;
loc_82587348:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825873b4
	if (!cr0.gt) goto loc_825873B4;
loc_82587364:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,28
	cr6.compare<int32_t>(ctx.r7.s32, 28, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82587384
	if (cr6.lt) goto loc_82587384;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
loc_82587384:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825873a0
	if (cr6.eq) goto loc_825873A0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825873a8
	goto loc_825873A8;
loc_825873A0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825873A8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82587364
	if (cr6.gt) goto loc_82587364;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_825873B4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825873f8
	if (cr6.eq) goto loc_825873F8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825873d0
	if (cr6.gt) goto loc_825873D0;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_825873D0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825873f8
	if (!cr6.eq) goto loc_825873F8;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587410
	goto loc_82587410;
loc_825873F8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587410
	goto loc_82587410;
loc_8258740C:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82587410:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825875d0
	if (cr6.eq) goto loc_825875D0;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(100) );
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x825875d0
	if (!cr6.eq) goto loc_825875D0;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(108) );
	// addi r3,r31,104
	ctx.r3.s64 = r31.s64 + 104;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825874b8
	if (cr6.eq) goto loc_825874B8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825874b4
	if (cr6.eq) goto loc_825874B4;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587464
	if (cr6.eq) goto loc_82587464;
	// lbz r10,144(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 144);
	// rlwinm r9,r10,0,25,25
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// li r10,1
	ctx.r10.s64 = 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82587468
	if (!cr6.eq) goto loc_82587468;
loc_82587464:
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
loc_82587468:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825875d0
	if (cr6.eq) goto loc_825875D0;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// rlwinm r8,r9,13,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 13) & 0x1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82587584
	if (cr6.eq) goto loc_82587584;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825874c0
	if (cr6.eq) goto loc_825874C0;
	// lbz r10,179(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 179);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587588
	goto loc_82587588;
loc_825874B4:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_825874B8:
	// mr r11,r27
	r11.u64 = r27.u64;
	// b 0x82587464
	goto loc_82587464;
loc_825874C0:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258752c
	if (!cr0.gt) goto loc_8258752C;
loc_825874DC:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,179
	cr6.compare<int32_t>(ctx.r7.s32, 179, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825874fc
	if (cr6.lt) goto loc_825874FC;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
loc_825874FC:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82587518
	if (cr6.eq) goto loc_82587518;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82587520
	goto loc_82587520;
loc_82587518:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82587520:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825874dc
	if (cr6.gt) goto loc_825874DC;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_8258752C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82587570
	if (cr6.eq) goto loc_82587570;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,179
	cr6.compare<int32_t>(r11.s32, 179, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82587548
	if (cr6.gt) goto loc_82587548;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82587548:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82587570
	if (!cr6.eq) goto loc_82587570;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587588
	goto loc_82587588;
loc_82587570:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587588
	goto loc_82587588;
loc_82587584:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82587588:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825875d0
	if (cr6.eq) goto loc_825875D0;
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(12) );
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x825875ac
	if (!cr6.eq) goto loc_825875AC;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,1964
	ctx.r4.s64 = r11.s64 + 1964;
	// b 0x825875c8
	goto loc_825875C8;
loc_825875AC:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x825875c0
	if (!cr6.eq) goto loc_825875C0;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,1972
	ctx.r4.s64 = r11.s64 + 1972;
	// b 0x825875c8
	goto loc_825875C8;
loc_825875C0:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,1984
	ctx.r4.s64 = r11.s64 + 1984;
loc_825875C8:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821da550
	sub_821DA550(ctx, base);
loc_825875D0:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// addi r4,r11,1996
	ctx.r4.s64 = r11.s64 + 1996;
	// bl 0x821da550
	sub_821DA550(ctx, base);
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x822838a0
	sub_822838A0(ctx, base);
	// addi r30,r26,44
	r30.s64 = r26.s64 + 44;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8238a848
	sub_8238A848(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r10,2000
	ctx.r4.s64 = ctx.r10.s64 + 2000;
	// bl 0x821da550
	sub_821DA550(ctx, base);
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x822838a0
	sub_822838A0(ctx, base);
	// addi r31,r26,52
	r31.s64 = r26.s64 + 52;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8238a848
	sub_8238A848(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r3,44(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + int32_t(44) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825877bc
	if (cr6.eq) goto loc_825877BC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825877bc
	if (cr6.eq) goto loc_825877BC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(16) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r8,16(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(16) );
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r25,3
	cr6.compare<int32_t>(r25.s32, 3, xer);
	// bne cr6,0x825876c4
	if (!cr6.eq) goto loc_825876C4;
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// b 0x825876c8
	goto loc_825876C8;
loc_825876C4:
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
loc_825876C8:
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,32
	ctx.r6.s64 = 32;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x821cdd88
	sub_821CDD88(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,64(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + int32_t(64) );
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmpw cr6,r3,r11
	cr6.compare<int32_t>(ctx.r3.s32, r11.s32, xer);
	// beq cr6,0x82587768
	if (cr6.eq) goto loc_82587768;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82587738
	if (cr6.eq) goto loc_82587738;
	// addi r9,r3,4
	ctx.r9.s64 = ctx.r3.s64 + 4;
loc_82587700:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x82587700
	if (!cr0.eq) goto loc_82587700;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82587734
	if (!cr6.eq) goto loc_82587734;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82587734:
	// stw r27,64(r26)
	PPC_STORE_U32(r26.u32 + 64, r27.u32);
loc_82587738:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,64(r26)
	PPC_STORE_U32(r26.u32 + 64, r11.u32);
	// beq cr6,0x82587768
	if (cr6.eq) goto loc_82587768;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
loc_8258774C:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r11
	reserved.u32 = *(uint32_t*)(base + r11.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r11
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + r11.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8258774c
	if (!cr0.eq) goto loc_8258774C;
loc_82587768:
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(104) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825877b8
	if (cr6.eq) goto loc_825877B8;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// addi r8,r11,4
	ctx.r8.s64 = r11.s64 + 4;
loc_8258777C:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8258777c
	if (!cr0.eq) goto loc_8258777C;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x825877b4
	if (!cr6.eq) goto loc_825877B4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_825877B4:
	// stw r27,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r27.u32);
loc_825877B8:
	// stw r25,60(r26)
	PPC_STORE_U32(r26.u32 + 60, r25.u32);
loc_825877BC:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_825877C4:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_82586D70) {
	__imp__sub_82586D70(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825877D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr1{};
	PPCCRRegister cr2{};
	PPCCRRegister cr3{};
	PPCCRRegister cr4{};
	PPCCRRegister cr5{};
	PPCCRRegister cr6{};
	PPCCRRegister cr7{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stfd f30,-88(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -88, f30.u64);
	// stfd f31,-80(r1)
	PPC_STORE_U64(ctx.r1.u32 + -80, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r26,0
	r26.s64 = 0;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r28,r26
	r28.u64 = r26.u64;
	// addi r25,r27,4
	r25.s64 = r27.s64 + 4;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82584ea0
	sub_82584EA0(ctx, base);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// mr r31,r26
	r31.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258782c
	if (cr6.eq) goto loc_8258782C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82587824
	if (cr6.eq) goto loc_82587824;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x82587830
	goto loc_82587830;
loc_82587824:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8258782C:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82587830:
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// rlwinm r9,r10,7,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82587930
	if (cr6.eq) goto loc_82587930;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258786c
	if (cr6.eq) goto loc_8258786C;
	// lbz r10,57(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 57);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587934
	goto loc_82587934;
loc_8258786C:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r26.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825878d8
	if (!cr0.gt) goto loc_825878D8;
loc_82587888:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,57
	cr6.compare<int32_t>(ctx.r7.s32, 57, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825878a8
	if (cr6.lt) goto loc_825878A8;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
loc_825878A8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825878c4
	if (cr6.eq) goto loc_825878C4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825878cc
	goto loc_825878CC;
loc_825878C4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825878CC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82587888
	if (cr6.gt) goto loc_82587888;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_825878D8:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258791c
	if (cr6.eq) goto loc_8258791C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,57
	cr6.compare<int32_t>(r11.s32, 57, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825878f4
	if (cr6.gt) goto loc_825878F4;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_825878F4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258791c
	if (!cr6.eq) goto loc_8258791C;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587934
	goto loc_82587934;
loc_8258791C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587934
	goto loc_82587934;
loc_82587930:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82587934:
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// addi r29,r10,-27456
	r29.s64 = ctx.r10.s64 + -27456;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lfs f30,-12(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + -12);
	f30.f64 = double(temp.f32);
	// beq cr6,0x825879c4
	if (cr6.eq) goto loc_825879C4;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,26260
	ctx.r4.s64 = r11.s64 + 26260;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8219c690
	sub_8219C690(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825879b4
	if (cr6.eq) goto loc_825879B4;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// addi r7,r11,26316
	ctx.r7.s64 = r11.s64 + 26316;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// bl 0x823b12e8
	sub_823B12E8(ctx, base);
	// lwz r6,276(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + int32_t(276) );
	// li r11,1
	r11.s64 = 1;
	// cmpw cr6,r6,r3
	cr6.compare<int32_t>(ctx.r6.s32, ctx.r3.s32, xer);
	// bge cr6,0x825879ac
	if (!cr6.lt) goto loc_825879AC;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_825879AC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// b 0x825879b8
	goto loc_825879B8;
loc_825879B4:
	// li r11,1
	r11.s64 = 1;
loc_825879B8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587f60
	if (cr6.eq) goto loc_82587F60;
loc_825879C4:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lbz r10,27028(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 27028);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82587f3c
	if (cr6.eq) goto loc_82587F3C;
	// mr r31,r26
	r31.u64 = r26.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,18,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82587ae0
	if (cr6.eq) goto loc_82587AE0;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587a1c
	if (cr6.eq) goto loc_82587A1C;
	// lbz r10,110(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 110);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587ae4
	goto loc_82587AE4;
loc_82587A1C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r26.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82587a88
	if (!cr0.gt) goto loc_82587A88;
loc_82587A38:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,110
	cr6.compare<int32_t>(ctx.r7.s32, 110, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82587a58
	if (cr6.lt) goto loc_82587A58;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
loc_82587A58:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82587a74
	if (cr6.eq) goto loc_82587A74;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82587a7c
	goto loc_82587A7C;
loc_82587A74:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82587A7C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82587a38
	if (cr6.gt) goto loc_82587A38;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_82587A88:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82587acc
	if (cr6.eq) goto loc_82587ACC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,110
	cr6.compare<int32_t>(r11.s32, 110, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82587aa4
	if (cr6.gt) goto loc_82587AA4;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82587AA4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82587acc
	if (!cr6.eq) goto loc_82587ACC;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587ae4
	goto loc_82587AE4;
loc_82587ACC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587ae4
	goto loc_82587AE4;
loc_82587AE0:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82587AE4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// lfs f31,9352(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 9352);
	f31.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587be4
	if (cr6.eq) goto loc_82587BE4;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(68) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// ld r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// lbz r11,20(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 20);
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// std r9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r9.u64);
	// lfs f0,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfs f13,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f11
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fmadds f9,f0,f13,f10
	ctx.f9.f64 = double(std::fma(float(f0.f64), float(ctx.f13.f64), float(ctx.f10.f64)));
	// fsqrts f8,f9
	ctx.f8.f64 = double(simd::sqrt_f32(float(ctx.f9.f64)));
	// fcmpu cr6,f8,f31
	cr6.compare(ctx.f8.f64, f31.f64);
	// ble cr6,0x82587ba4
	if (!cr6.gt) goto loc_82587BA4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587b50
	if (cr6.eq) goto loc_82587B50;
	// stfs f30,24(r27)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r27.u32 + 24, temp.u32);
loc_82587B50:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lfs f13,24(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// lis r31,-31950
	r31.s64 = -2093875200;
	// lfs f0,27032(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 27032);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x82587b8c
	if (cr6.lt) goto loc_82587B8C;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lfd f11,-27376(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(r31.u32 + -27376);
	// bl 0x82207928
	sub_82207928(ctx, base);
	// fdiv f0,f1,f11
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64 / ctx.f11.f64;
	// lfs f13,28(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// frsp f12,f0
	ctx.f12.f64 = double(float(f0.f64));
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f11,28(r27)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r27.u32 + 28, temp.u32);
loc_82587B8C:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lfd f11,-27376(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(r31.u32 + -27376);
	// bl 0x82207928
	sub_82207928(ctx, base);
	// stb r26,20(r27)
	PPC_STORE_U8(r27.u32 + 20, r26.u8);
	// b 0x82587bd0
	goto loc_82587BD0;
loc_82587BA4:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82587bb0
	if (!cr6.eq) goto loc_82587BB0;
	// stfs f30,24(r27)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r27.u32 + 24, temp.u32);
loc_82587BB0:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lis r11,-31950
	r11.s64 = -2093875200;
	// lfd f11,-27376(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(r11.u32 + -27376);
	// bl 0x82207928
	sub_82207928(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// stfs f30,28(r27)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r27.u32 + 28, temp.u32);
	// stb r10,20(r27)
	PPC_STORE_U8(r27.u32 + 20, ctx.r10.u8);
loc_82587BD0:
	// fdiv f0,f1,f11
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64 / ctx.f11.f64;
	// lfs f13,24(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// frsp f12,f0
	ctx.f12.f64 = double(float(f0.f64));
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f11,24(r27)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r27.u32 + 24, temp.u32);
loc_82587BE4:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,11,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 11) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82587cec
	if (cr6.eq) goto loc_82587CEC;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587c28
	if (cr6.eq) goto loc_82587C28;
	// lbz r10,21(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 21);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587cf4
	goto loc_82587CF4;
loc_82587C28:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r26.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82587c94
	if (!cr0.gt) goto loc_82587C94;
loc_82587C44:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,21
	cr6.compare<int32_t>(ctx.r7.s32, 21, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82587c64
	if (cr6.lt) goto loc_82587C64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
loc_82587C64:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82587c80
	if (cr6.eq) goto loc_82587C80;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82587c88
	goto loc_82587C88;
loc_82587C80:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82587C88:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82587c44
	if (cr6.gt) goto loc_82587C44;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_82587C94:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82587cd8
	if (cr6.eq) goto loc_82587CD8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82587cb0
	if (cr6.gt) goto loc_82587CB0;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82587CB0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82587cd8
	if (!cr6.eq) goto loc_82587CD8;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587cf4
	goto loc_82587CF4;
loc_82587CD8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587cf4
	goto loc_82587CF4;
loc_82587CEC:
	// lwz r30,92(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82587CF4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587f60
	if (cr6.eq) goto loc_82587F60;
	// lbz r11,20(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 20);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587f1c
	if (cr6.eq) goto loc_82587F1C;
	// bl 0x821ff4e0
	sub_821FF4E0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82587f60
	if (!cr6.eq) goto loc_82587F60;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mr r31,r26
	r31.u64 = r26.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82587e30
	if (cr6.eq) goto loc_82587E30;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587d6c
	if (cr6.eq) goto loc_82587D6C;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587e34
	goto loc_82587E34;
loc_82587D6C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r26.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82587dd8
	if (!cr0.gt) goto loc_82587DD8;
loc_82587D88:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82587da8
	if (cr6.lt) goto loc_82587DA8;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
loc_82587DA8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82587dc4
	if (cr6.eq) goto loc_82587DC4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82587dcc
	goto loc_82587DCC;
loc_82587DC4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82587DCC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82587d88
	if (cr6.gt) goto loc_82587D88;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_82587DD8:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82587e1c
	if (cr6.eq) goto loc_82587E1C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82587df4
	if (cr6.gt) goto loc_82587DF4;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82587DF4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82587e1c
	if (!cr6.eq) goto loc_82587E1C;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587e34
	goto loc_82587E34;
loc_82587E1C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82587e34
	goto loc_82587E34;
loc_82587E30:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82587E34:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587e70
	if (cr6.eq) goto loc_82587E70;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,2004
	ctx.r4.s64 = r11.s64 + 2004;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x823c1e08
	sub_823C1E08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_82587E70:
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82587ecc
	if (cr6.eq) goto loc_82587ECC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,3224
	ctx.r4.s64 = r11.s64 + 3224;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// li r28,1
	r28.s64 = 1;
	// addi r24,r1,80
	r24.s64 = ctx.r1.s64 + 80;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// fmr f2,f31
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f31.f64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// lfs f1,-17372(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -17372);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x828061f0
	sub_828061F0(ctx, base);
	// b 0x82587ed0
	goto loc_82587ED0;
loc_82587ECC:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_82587ED0:
	// stw r3,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82587ee8
	if (cr6.eq) goto loc_82587EE8;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8238a7e0
	sub_8238A7E0(ctx, base);
	// b 0x82587eec
	goto loc_82587EEC;
loc_82587EE8:
	// stw r26,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r26.u32);
loc_82587EEC:
	// clrlwi r11,r28,31
	r11.u64 = r28.u32 & 0x1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82587f04
	if (cr6.eq) goto loc_82587F04;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rlwinm r28,r28,0,0,30
	r28.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_82587F04:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f2338
	sub_823F2338(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x829ff648
	sub_829FF648(ctx, base);
	// b 0x82587f60
	goto loc_82587F60;
loc_82587F1C:
	// bl 0x821ff4e0
	sub_821FF4E0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587f60
	if (cr6.eq) goto loc_82587F60;
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f27a8
	sub_823F27A8(ctx, base);
	// b 0x82587f60
	goto loc_82587F60;
loc_82587F3C:
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lis r11,-31950
	r11.s64 = -2093875200;
	// lfd f11,-27376(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(r11.u32 + -27376);
	// bl 0x82207928
	sub_82207928(ctx, base);
	// fdiv f0,f1,f11
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64 / ctx.f11.f64;
	// lfs f13,28(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// frsp f12,f0
	ctx.f12.f64 = double(float(f0.f64));
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f11,28(r27)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r27.u32 + 28, temp.u32);
loc_82587F60:
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82587f88
	if (cr6.eq) goto loc_82587F88;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82587f80
	if (cr6.eq) goto loc_82587F80;
	// rotlwi r3,r10,0
	ctx.r3.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x82587f8c
	goto loc_82587F8C;
loc_82587F80:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82587F88:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_82587F8C:
	// bl 0x827fa570
	sub_827FA570(ctx, base);
	// lfs f0,28(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 28);
	f0.f64 = double(temp.f32);
	// fdivs f13,f0,f1
	ctx.f13.f64 = double(float(f0.f64 / ctx.f1.f64));
	// lfs f0,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// lis r11,-32240
	r11.s64 = -2112880640;
	// lwz r3,44(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + int32_t(44) );
	// addi r10,r11,368
	ctx.r10.s64 = r11.s64 + 368;
	// fsubs f12,f13,f0
	ctx.f12.f64 = static_cast<float>(ctx.f13.f64 - f0.f64);
	// fcmpu cr6,f12,f30
	cr6.compare(ctx.f12.f64, f30.f64);
	// mfcr r9
	ctx.r9.u64 = 0;
	ctx.r9.u64 |= (cr0.lt ? 0x80000000 : 0);
	ctx.r9.u64 |= (cr0.gt ? 0x40000000 : 0);
	ctx.r9.u64 |= (cr0.eq ? 0x20000000 : 0);
	ctx.r9.u64 |= (cr0.so ? 0x10000000 : 0);
	ctx.r9.u64 |= (cr1.lt ? 0x08000000 : 0);
	ctx.r9.u64 |= (cr1.gt ? 0x04000000 : 0);
	ctx.r9.u64 |= (cr1.eq ? 0x02000000 : 0);
	ctx.r9.u64 |= (cr1.so ? 0x01000000 : 0);
	ctx.r9.u64 |= (cr2.lt ? 0x00800000 : 0);
	ctx.r9.u64 |= (cr2.gt ? 0x00400000 : 0);
	ctx.r9.u64 |= (cr2.eq ? 0x00200000 : 0);
	ctx.r9.u64 |= (cr2.so ? 0x00100000 : 0);
	ctx.r9.u64 |= (cr3.lt ? 0x00080000 : 0);
	ctx.r9.u64 |= (cr3.gt ? 0x00040000 : 0);
	ctx.r9.u64 |= (cr3.eq ? 0x00020000 : 0);
	ctx.r9.u64 |= (cr3.so ? 0x00010000 : 0);
	ctx.r9.u64 |= (cr4.lt ? 0x00008000 : 0);
	ctx.r9.u64 |= (cr4.gt ? 0x00004000 : 0);
	ctx.r9.u64 |= (cr4.eq ? 0x00002000 : 0);
	ctx.r9.u64 |= (cr4.so ? 0x00001000 : 0);
	ctx.r9.u64 |= (cr5.lt ? 0x00000800 : 0);
	ctx.r9.u64 |= (cr5.gt ? 0x00000400 : 0);
	ctx.r9.u64 |= (cr5.eq ? 0x00000200 : 0);
	ctx.r9.u64 |= (cr5.so ? 0x00000100 : 0);
	ctx.r9.u64 |= (cr6.lt ? 0x00000080 : 0);
	ctx.r9.u64 |= (cr6.gt ? 0x00000040 : 0);
	ctx.r9.u64 |= (cr6.eq ? 0x00000020 : 0);
	ctx.r9.u64 |= (cr6.so ? 0x00000010 : 0);
	ctx.r9.u64 |= (cr7.lt ? 0x00000008 : 0);
	ctx.r9.u64 |= (cr7.gt ? 0x00000004 : 0);
	ctx.r9.u64 |= (cr7.eq ? 0x00000002 : 0);
	ctx.r9.u64 |= (cr7.so ? 0x00000001 : 0);
	// rlwinm r8,r9,27,29,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x4;
	// rlwinm r7,r9,30,29,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x4;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// or r6,r8,r7
	ctx.r6.u64 = ctx.r8.u64 | ctx.r7.u64;
	// lfsx f11,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f11.f64 = double(temp.f32);
	// fsel f31,f11,f0,f13
	f31.f64 = ctx.f11.f64 >= 0.0 ? f0.f64 : ctx.f13.f64;
	// beq cr6,0x82587ff8
	if (cr6.eq) goto loc_82587FF8;
	// lfs f1,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x822d3d80
	sub_822D3D80(ctx, base);
	// lfs f0,24524(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 24524);
	f0.f64 = double(temp.f32);
	// lwz r3,44(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + int32_t(44) );
	// fsubs f0,f1,f0
	f0.f64 = static_cast<float>(ctx.f1.f64 - f0.f64);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(20) );
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 * f31.f64));
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82587FF8:
	// lwz r3,52(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + int32_t(52) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258802c
	if (cr6.eq) goto loc_8258802C;
	// lfs f1,40(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x822d3d80
	sub_822D3D80(ctx, base);
	// lfs f0,24524(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 24524);
	f0.f64 = double(temp.f32);
	// lwz r3,52(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + int32_t(52) );
	// fsubs f0,f1,f0
	f0.f64 = static_cast<float>(ctx.f1.f64 - f0.f64);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(20) );
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 * f31.f64));
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_8258802C:
	// lwz r11,64(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(64) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588280
	if (cr6.eq) goto loc_82588280;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// li r30,2
	r30.s64 = 2;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,29,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82588138
	if (cr6.eq) goto loc_82588138;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258807c
	if (cr6.eq) goto loc_8258807C;
	// lbz r10,99(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 99);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x82588140
	goto loc_82588140;
loc_8258807C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r26.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825880e8
	if (!cr0.gt) goto loc_825880E8;
loc_82588098:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,99
	cr6.compare<int32_t>(ctx.r7.s32, 99, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825880b8
	if (cr6.lt) goto loc_825880B8;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
loc_825880B8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825880d4
	if (cr6.eq) goto loc_825880D4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825880dc
	goto loc_825880DC;
loc_825880D4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825880DC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82588098
	if (cr6.gt) goto loc_82588098;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_825880E8:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82588128
	if (cr6.eq) goto loc_82588128;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,99
	cr6.compare<int32_t>(r11.s32, 99, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82588104
	if (cr6.gt) goto loc_82588104;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82588104:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82588128
	if (!cr6.eq) goto loc_82588128;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82588140
	goto loc_82588140;
loc_82588128:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82588140
	goto loc_82588140;
loc_82588138:
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
loc_82588140:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82588150
	if (cr6.eq) goto loc_82588150;
	// lwz r30,16(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + int32_t(16) );
loc_82588150:
	// lwz r11,60(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(60) );
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// beq cr6,0x82588280
	if (cr6.eq) goto loc_82588280;
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// bne cr6,0x82588174
	if (!cr6.eq) goto loc_82588174;
	// lwz r4,52(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(52) );
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// ori r31,r28,2
	r31.u64 = r28.u64 | 2;
	// b 0x82588180
	goto loc_82588180;
loc_82588174:
	// lwz r4,44(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(44) );
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// ori r31,r28,4
	r31.u64 = r28.u64 | 4;
loc_82588180:
	// bl 0x8225fb20
	sub_8225FB20(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// beq cr6,0x825881b4
	if (cr6.eq) goto loc_825881B4;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
loc_82588198:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r11
	reserved.u32 = *(uint32_t*)(base + r11.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r11
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + r11.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x82588198
	if (!cr0.eq) goto loc_82588198;
loc_825881B4:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,64(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + int32_t(64) );
	// bl 0x82514d68
	sub_82514D68(ctx, base);
	// rlwinm r11,r31,0,29,29
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0x4;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82588220
	if (cr6.eq) goto loc_82588220;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(88) );
	// rlwinm r31,r31,0,30,28
	r31.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588220
	if (cr6.eq) goto loc_82588220;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// addi r8,r11,4
	ctx.r8.s64 = r11.s64 + 4;
loc_825881E4:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x825881e4
	if (!cr0.eq) goto loc_825881E4;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8258821c
	if (!cr6.eq) goto loc_8258821C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_8258821C:
	// stw r26,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r26.u32);
loc_82588220:
	// rlwinm r11,r31,0,30,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0x2;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8258827c
	if (cr6.eq) goto loc_8258827C;
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258827c
	if (cr6.eq) goto loc_8258827C;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// addi r8,r11,4
	ctx.r8.s64 = r11.s64 + 4;
loc_82588240:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x82588240
	if (!cr0.eq) goto loc_82588240;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82588278
	if (!cr6.eq) goto loc_82588278;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82588278:
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r26.u32);
loc_8258827C:
	// stw r30,60(r27)
	PPC_STORE_U32(r27.u32 + 60, r30.u32);
loc_82588280:
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + int32_t(4) );
	// mr r31,r26
	r31.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825882ac
	if (cr6.eq) goto loc_825882AC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825882a4
	if (cr6.eq) goto loc_825882A4;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x825882b0
	goto loc_825882B0;
loc_825882A4:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_825882AC:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_825882B0:
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// rlwinm r9,r10,20,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x825883b0
	if (cr6.eq) goto loc_825883B0;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825882ec
	if (cr6.eq) goto loc_825882EC;
	// lbz r10,44(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 44);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825883b4
	goto loc_825883B4;
loc_825882EC:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r26.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82588358
	if (!cr0.gt) goto loc_82588358;
loc_82588308:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,44
	cr6.compare<int32_t>(ctx.r7.s32, 44, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82588328
	if (cr6.lt) goto loc_82588328;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
loc_82588328:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82588344
	if (cr6.eq) goto loc_82588344;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258834c
	goto loc_8258834C;
loc_82588344:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258834C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82588308
	if (cr6.gt) goto loc_82588308;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_82588358:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258839c
	if (cr6.eq) goto loc_8258839C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,44
	cr6.compare<int32_t>(r11.s32, 44, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82588374
	if (cr6.gt) goto loc_82588374;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82588374:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258839c
	if (!cr6.eq) goto loc_8258839C;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825883b4
	goto loc_825883B4;
loc_8258839C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825883b4
	goto loc_825883B4;
loc_825883B0:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_825883B4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825883cc
	if (cr6.eq) goto loc_825883CC;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(100) );
	// ori r10,r11,12
	ctx.r10.u64 = r11.u64 | 12;
	// stw r10,100(r31)
	PPC_STORE_U32(r31.u32 + 100, ctx.r10.u32);
loc_825883CC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82588a30
	sub_82588A30(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258850c
	if (cr6.eq) goto loc_8258850C;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mr r31,r26
	r31.u64 = r26.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825884ec
	if (cr6.eq) goto loc_825884EC;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588428
	if (cr6.eq) goto loc_82588428;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825884f0
	goto loc_825884F0;
loc_82588428:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r26.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82588494
	if (!cr0.gt) goto loc_82588494;
loc_82588444:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82588464
	if (cr6.lt) goto loc_82588464;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
loc_82588464:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82588480
	if (cr6.eq) goto loc_82588480;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82588488
	goto loc_82588488;
loc_82588480:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82588488:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82588444
	if (cr6.gt) goto loc_82588444;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_82588494:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825884d8
	if (cr6.eq) goto loc_825884D8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825884b0
	if (cr6.gt) goto loc_825884B0;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_825884B0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825884d8
	if (!cr6.eq) goto loc_825884D8;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825884f0
	goto loc_825884F0;
loc_825884D8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825884f0
	goto loc_825884F0;
loc_825884EC:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_825884F0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258850c
	if (cr6.eq) goto loc_8258850C;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,35
	ctx.r4.s64 = 35;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823c84e0
	sub_823C84E0(ctx, base);
loc_8258850C:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f30,-88(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// lfd f31,-80(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_825877D0) {
	__imp__sub_825877D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82588520) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stb r28,16(r30)
	PPC_STORE_U8(r30.u32 + 16, r28.u8);
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(124) );
	// bl 0x825bb370
	sub_825BB370(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(8) );
	// addi r29,r30,4
	r29.s64 = r30.s64 + 4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588594
	if (cr6.eq) goto loc_82588594;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825885e8
	if (cr6.eq) goto loc_825885E8;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588594
	if (cr6.eq) goto loc_82588594;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82588598
	if (!cr6.eq) goto loc_82588598;
loc_82588594:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82588598:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825888c0
	if (cr6.eq) goto loc_825888C0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,29,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825886b8
	if (cr6.eq) goto loc_825886B8;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825885f4
	if (cr6.eq) goto loc_825885F4;
	// lbz r10,99(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 99);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825886c0
	goto loc_825886C0;
loc_825885E8:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82588594
	goto loc_82588594;
loc_825885F4:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82588660
	if (!cr0.gt) goto loc_82588660;
loc_82588610:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,99
	cr6.compare<int32_t>(ctx.r7.s32, 99, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82588630
	if (cr6.lt) goto loc_82588630;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_82588630:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258864c
	if (cr6.eq) goto loc_8258864C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82588654
	goto loc_82588654;
loc_8258864C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82588654:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82588610
	if (cr6.gt) goto loc_82588610;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82588660:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825886a4
	if (cr6.eq) goto loc_825886A4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,99
	cr6.compare<int32_t>(r11.s32, 99, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258867c
	if (cr6.gt) goto loc_8258867C;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8258867C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825886a4
	if (!cr6.eq) goto loc_825886A4;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825886c0
	goto loc_825886C0;
loc_825886A4:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825886c0
	goto loc_825886C0;
loc_825886B8:
	// lwz r31,80(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// mr r11,r28
	r11.u64 = r28.u64;
loc_825886C0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825886f0
	if (cr6.eq) goto loc_825886F0;
	// lwz r4,36(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(36) );
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x825886e0
	if (cr6.eq) goto loc_825886E0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8284ac10
	sub_8284AC10(ctx, base);
loc_825886E0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f1,-19240(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -19240);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x822b3ae8
	sub_822B3AE8(ctx, base);
loc_825886F0:
	// lwz r11,64(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(64) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588868
	if (cr6.eq) goto loc_82588868;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,13,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825887f8
	if (cr6.eq) goto loc_825887F8;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258873c
	if (cr6.eq) goto loc_8258873C;
	// lbz r10,19(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 19);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x82588800
	goto loc_82588800;
loc_8258873C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825887a8
	if (!cr0.gt) goto loc_825887A8;
loc_82588758:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,19
	cr6.compare<int32_t>(ctx.r7.s32, 19, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82588778
	if (cr6.lt) goto loc_82588778;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_82588778:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82588794
	if (cr6.eq) goto loc_82588794;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258879c
	goto loc_8258879C;
loc_82588794:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258879C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82588758
	if (cr6.gt) goto loc_82588758;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_825887A8:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825887e8
	if (cr6.eq) goto loc_825887E8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825887c4
	if (cr6.gt) goto loc_825887C4;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_825887C4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825887e8
	if (!cr6.eq) goto loc_825887E8;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82588800
	goto loc_82588800;
loc_825887E8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82588800
	goto loc_82588800;
loc_825887F8:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
loc_82588800:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82588868
	if (cr6.eq) goto loc_82588868;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,64(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(64) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x822ade58
	sub_822ADE58(ctx, base);
	// lwz r3,64(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(64) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82588864
	if (cr6.eq) goto loc_82588864;
	// addi r9,r3,4
	ctx.r9.s64 = ctx.r3.s64 + 4;
loc_8258882C:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x8258882c
	if (!cr0.eq) goto loc_8258882C;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82588860
	if (!cr6.eq) goto loc_82588860;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82588860:
	// stw r28,64(r30)
	PPC_STORE_U32(r30.u32 + 64, r28.u32);
loc_82588864:
	// stw r28,64(r30)
	PPC_STORE_U32(r30.u32 + 64, r28.u32);
loc_82588868:
	// lwz r3,44(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(44) );
	// addi r31,r30,44
	r31.s64 = r30.s64 + 44;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82588894
	if (cr6.eq) goto loc_82588894;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ff648
	sub_829FF648(ctx, base);
	// stw r28,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r28.u32);
loc_82588894:
	// lwz r3,52(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(52) );
	// addi r31,r30,52
	r31.s64 = r30.s64 + 52;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825888c0
	if (cr6.eq) goto loc_825888C0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ff648
	sub_829FF648(ctx, base);
	// stw r28,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r28.u32);
loc_825888C0:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825888e8
	if (cr6.eq) goto loc_825888E8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825888e0
	if (cr6.eq) goto loc_825888E0;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x825888ec
	goto loc_825888EC;
loc_825888E0:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_825888E8:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_825888EC:
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// rlwinm r9,r10,11,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 11) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x825889ec
	if (cr6.eq) goto loc_825889EC;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82588928
	if (cr6.eq) goto loc_82588928;
	// lbz r9,21(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 21);
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r11,r9,3
	r11.u64 = rotl32(ctx.r9.u32, 3);
	// add r8,r11,r10
	ctx.r8.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825889f4
	goto loc_825889F4;
loc_82588928:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82588994
	if (!cr0.gt) goto loc_82588994;
loc_82588944:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,21
	cr6.compare<int32_t>(ctx.r7.s32, 21, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82588964
	if (cr6.lt) goto loc_82588964;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_82588964:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82588980
	if (cr6.eq) goto loc_82588980;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82588988
	goto loc_82588988;
loc_82588980:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82588988:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82588944
	if (cr6.gt) goto loc_82588944;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82588994:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825889d8
	if (cr6.eq) goto loc_825889D8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825889b0
	if (cr6.gt) goto loc_825889B0;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_825889B0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825889d8
	if (!cr6.eq) goto loc_825889D8;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825889f4
	goto loc_825889F4;
loc_825889D8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825889f4
	goto loc_825889F4;
loc_825889EC:
	// lwz r31,80(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// mr r11,r28
	r11.u64 = r28.u64;
loc_825889F4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588a24
	if (cr6.eq) goto loc_82588A24;
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821ff4e0
	sub_821FF4E0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588a24
	if (cr6.eq) goto loc_82588A24;
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f27a8
	sub_823F27A8(ctx, base);
loc_82588A24:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82588520) {
	__imp__sub_82588520(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82588A30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stfd f31,-16(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -16, f31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// lfs f31,28(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 28);
	f31.f64 = double(temp.f32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588a70
	if (cr6.eq) goto loc_82588A70;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82588a6c
	if (cr6.eq) goto loc_82588A6C;
	// rotlwi r3,r10,0
	ctx.r3.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x82588a74
	goto loc_82588A74;
loc_82588A6C:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82588A70:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82588A74:
	// bl 0x827fa570
	sub_827FA570(ctx, base);
	// fcmpu cr6,f31,f1
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, ctx.f1.f64);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82588a88
	if (cr6.gt) goto loc_82588A88;
	// li r11,0
	r11.s64 = 0;
loc_82588A88:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// lfd f31,-16(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82588A30) {
	__imp__sub_82588A30(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82588AA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lbz r11,20(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82588ac8
	if (!cr6.eq) goto loc_82588AC8;
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
loc_82588AC8:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(8) );
	// li r30,0
	r30.s64 = 0;
	// addi r31,r28,4
	r31.s64 = r28.s64 + 4;
	// li r29,3
	r29.s64 = 3;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588b14
	if (cr6.eq) goto loc_82588B14;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82588b68
	if (cr6.eq) goto loc_82588B68;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588b14
	if (cr6.eq) goto loc_82588B14;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82588b18
	if (!cr6.eq) goto loc_82588B18;
loc_82588B14:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82588B18:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588c84
	if (cr6.eq) goto loc_82588C84;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82588c38
	if (cr6.eq) goto loc_82588C38;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588b74
	if (cr6.eq) goto loc_82588B74;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82588c3c
	goto loc_82588C3C;
loc_82588B68:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82588b14
	goto loc_82588B14;
loc_82588B74:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82588be0
	if (!cr0.gt) goto loc_82588BE0;
loc_82588B90:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82588bb0
	if (cr6.lt) goto loc_82588BB0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_82588BB0:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82588bcc
	if (cr6.eq) goto loc_82588BCC;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82588bd4
	goto loc_82588BD4;
loc_82588BCC:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82588BD4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82588b90
	if (cr6.gt) goto loc_82588B90;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82588BE0:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82588c24
	if (cr6.eq) goto loc_82588C24;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82588bfc
	if (cr6.gt) goto loc_82588BFC;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82588BFC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82588c24
	if (!cr6.eq) goto loc_82588C24;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82588c3c
	goto loc_82588C3C;
loc_82588C24:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82588c3c
	goto loc_82588C3C;
loc_82588C38:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82588C3C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588c84
	if (cr6.eq) goto loc_82588C84;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,2028
	ctx.r4.s64 = r11.s64 + 2028;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lfs f1,-17912(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -17912);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x823c1e08
	sub_823C1E08(ctx, base);
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.u64 = uint64_t(int32_t(std::trunc(ctx.f1.f64)));
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r29,92(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_82588C84:
	// lis r11,-31950
	r11.s64 = -2093875200;
	// lwz r10,32(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + int32_t(32) );
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,-27380(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(-27380) );
	// subf r9,r10,r11
	ctx.r9.s64 = r11.s64 - ctx.r10.s64;
	// cmpw cr6,r9,r29
	cr6.compare<int32_t>(ctx.r9.s32, r29.s32, xer);
	// ble cr6,0x82588ca4
	if (!cr6.gt) goto loc_82588CA4;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82588CA4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82588AA0) {
	__imp__sub_82588AA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82588CB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lfs f1,-6076(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6076);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82588CB0) {
	__imp__sub_82588CB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82588CC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r11,1
	r11.s64 = 1;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// stb r11,16(r28)
	PPC_STORE_U8(r28.u32 + 16, r11.u8);
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(124) );
	// bl 0x825bb2c0
	sub_825BB2C0(ctx, base);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(8) );
	// addi r30,r28,4
	r30.s64 = r28.s64 + 4;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588d38
	if (cr6.eq) goto loc_82588D38;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82588d90
	if (cr6.eq) goto loc_82588D90;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588d38
	if (cr6.eq) goto loc_82588D38;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82588d3c
	if (!cr6.eq) goto loc_82588D3C;
loc_82588D38:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82588D3C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588fbc
	if (cr6.eq) goto loc_82588FBC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r31,r29
	r31.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82588e60
	if (cr6.eq) goto loc_82588E60;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588d9c
	if (cr6.eq) goto loc_82588D9C;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82588e64
	goto loc_82588E64;
loc_82588D90:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82588d38
	goto loc_82588D38;
loc_82588D9C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82588e08
	if (!cr0.gt) goto loc_82588E08;
loc_82588DB8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82588dd8
	if (cr6.lt) goto loc_82588DD8;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_82588DD8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82588df4
	if (cr6.eq) goto loc_82588DF4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82588dfc
	goto loc_82588DFC;
loc_82588DF4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82588DFC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82588db8
	if (cr6.gt) goto loc_82588DB8;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82588E08:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82588e4c
	if (cr6.eq) goto loc_82588E4C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82588e24
	if (cr6.gt) goto loc_82588E24;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82588E24:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82588e4c
	if (!cr6.eq) goto loc_82588E4C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82588e64
	goto loc_82588E64;
loc_82588E4C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82588e64
	goto loc_82588E64;
loc_82588E60:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82588E64:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588e7c
	if (cr6.eq) goto loc_82588E7C;
	// li r4,23
	ctx.r4.s64 = 23;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823c88f0
	sub_823C88F0(ctx, base);
loc_82588E7C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r31,r29
	r31.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,11,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 11) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82588f88
	if (cr6.eq) goto loc_82588F88;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588ec4
	if (cr6.eq) goto loc_82588EC4;
	// lbz r10,21(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 21);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82588f8c
	goto loc_82588F8C;
loc_82588EC4:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82588f30
	if (!cr0.gt) goto loc_82588F30;
loc_82588EE0:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,21
	cr6.compare<int32_t>(ctx.r7.s32, 21, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82588f00
	if (cr6.lt) goto loc_82588F00;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_82588F00:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82588f1c
	if (cr6.eq) goto loc_82588F1C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82588f24
	goto loc_82588F24;
loc_82588F1C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82588F24:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82588ee0
	if (cr6.gt) goto loc_82588EE0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82588F30:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82588f74
	if (cr6.eq) goto loc_82588F74;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82588f4c
	if (cr6.gt) goto loc_82588F4C;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82588F4C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82588f74
	if (!cr6.eq) goto loc_82588F74;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82588f8c
	goto loc_82588F8C;
loc_82588F74:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82588f8c
	goto loc_82588F8C;
loc_82588F88:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82588F8C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588fbc
	if (cr6.eq) goto loc_82588FBC;
	// li r4,57
	ctx.r4.s64 = 57;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821ff4e0
	sub_821FF4E0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82588fbc
	if (!cr6.eq) goto loc_82588FBC;
	// li r4,57
	ctx.r4.s64 = 57;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f1eb0
	sub_823F1EB0(ctx, base);
loc_82588FBC:
	// li r11,-1
	r11.s64 = -1;
	// stw r11,64(r28)
	PPC_STORE_U32(r28.u32 + 64, r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82588fec
	if (cr6.eq) goto loc_82588FEC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82588fe4
	if (cr6.eq) goto loc_82588FE4;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x82588ff0
	goto loc_82588FF0;
loc_82588FE4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82588FEC:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82588FF0:
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(68) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// ld r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// ld r4,8(r9)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// bl 0x821f5a28
	sub_821F5A28(ctx, base);
	// li r8,32
	ctx.r8.s64 = 32;
	// stvx128 v1,r28,r8
	ea = (r28.u32 + ctx.r8.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v1), &VectorMaskL[(ea & 0xF) * 16]);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589048
	if (cr6.eq) goto loc_82589048;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82589040
	if (cr6.eq) goto loc_82589040;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8258904c
	goto loc_8258904C;
loc_82589040:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82589048:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8258904C:
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// lwz r10,64(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(64) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// li r8,48
	ctx.r8.s64 = 48;
	// mr r31,r29
	r31.u64 = r29.u64;
	// lvx128 v0,r0,r9
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((ctx.r9.u32) & ~0xF), VectorMaskL));
	// stvx128 v0,r28,r8
	ea = (r28.u32 + ctx.r8.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825890a0
	if (cr6.eq) goto loc_825890A0;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82589098
	if (cr6.eq) goto loc_82589098;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x825890a4
	goto loc_825890A4;
loc_82589098:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_825890A0:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_825890A4:
	// lwz r10,44(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(44) );
	// rlwinm r9,r10,19,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 19) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x825891a4
	if (cr6.eq) goto loc_825891A4;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825890e0
	if (cr6.eq) goto loc_825890E0;
	// lbz r10,77(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 77);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825891a8
	goto loc_825891A8;
loc_825890E0:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258914c
	if (!cr0.gt) goto loc_8258914C;
loc_825890FC:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,77
	cr6.compare<int32_t>(ctx.r7.s32, 77, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258911c
	if (cr6.lt) goto loc_8258911C;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_8258911C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82589138
	if (cr6.eq) goto loc_82589138;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82589140
	goto loc_82589140;
loc_82589138:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82589140:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825890fc
	if (cr6.gt) goto loc_825890FC;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258914C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82589190
	if (cr6.eq) goto loc_82589190;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,77
	cr6.compare<int32_t>(r11.s32, 77, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82589168
	if (cr6.gt) goto loc_82589168;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82589168:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82589190
	if (!cr6.eq) goto loc_82589190;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825891a8
	goto loc_825891A8;
loc_82589190:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825891a8
	goto loc_825891A8;
loc_825891A4:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_825891A8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825891c8
	if (cr6.eq) goto loc_825891C8;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_825891C8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82589698
	sub_82589698(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82588CC0) {
	__imp__sub_82588CC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825891E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lbz r11,20(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82589508
	if (!cr6.eq) goto loc_82589508;
	// addi r28,r27,4
	r28.s64 = r27.s64 + 4;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,10,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 10) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258968c
	if (cr6.eq) goto loc_8258968C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589244
	if (cr6.eq) goto loc_82589244;
	// lbz r10,118(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 118);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r30,4(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x825892f0
	goto loc_825892F0;
loc_82589244:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r26,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r26.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825892b0
	if (!cr0.gt) goto loc_825892B0;
loc_82589260:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,118
	cr6.compare<int32_t>(ctx.r7.s32, 118, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82589280
	if (cr6.lt) goto loc_82589280;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
loc_82589280:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258929c
	if (cr6.eq) goto loc_8258929C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825892a4
	goto loc_825892A4;
loc_8258929C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825892A4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82589260
	if (cr6.gt) goto loc_82589260;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_825892B0:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825892e8
	if (cr6.eq) goto loc_825892E8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,118
	cr6.compare<int32_t>(r11.s32, 118, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825892cc
	if (cr6.gt) goto loc_825892CC;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_825892CC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825892e8
	if (!cr6.eq) goto loc_825892E8;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// b 0x825892ec
	goto loc_825892EC;
loc_825892E8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_825892EC:
	// lwz r30,4(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_825892F0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8258968c
	if (cr6.eq) goto loc_8258968C;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82589698
	sub_82589698(ctx, base);
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + int32_t(16) );
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lwz r4,64(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(64) );
	// lis r11,-32242
	r11.s64 = -2113011712;
	// addi r9,r10,-27456
	ctx.r9.s64 = ctx.r10.s64 + -27456;
	// addi r29,r11,-1580
	r29.s64 = r11.s64 + -1580;
	// lfs f31,21380(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21380);
	f31.f64 = double(temp.f32);
	// lwz r31,348(r8)
	r31.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(348) );
	// cmpw cr6,r4,r31
	cr6.compare<int32_t>(ctx.r4.s32, r31.s32, xer);
	// beq cr6,0x82589390
	if (cr6.eq) goto loc_82589390;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82611748
	sub_82611748(ctx, base);
	// stw r31,64(r27)
	PPC_STORE_U32(r27.u32 + 64, r31.u32);
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// blt cr6,0x82589390
	if (cr6.lt) goto loc_82589390;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(16) );
	// lwz r11,116(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(116) );
	// addi r9,r11,35
	ctx.r9.s64 = r11.s64 + 35;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r8,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// cmpw cr6,r31,r7
	cr6.compare<int32_t>(r31.s32, ctx.r7.s32, xer);
	// bge cr6,0x82589390
	if (!cr6.lt) goto loc_82589390;
	// vspltisw v0,0
	simd::store_i32(ctx.v0.u32, simd::set1_i32(int32_t(0x0)));
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// stw r26,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r26.u32);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stvx128 v0,r0,r11
	ea = (r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// stw r29,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r29.u32);
	// stfs f31,160(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// stw r31,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r31.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// addi r9,r10,-32248
	ctx.r9.s64 = ctx.r10.s64 + -32248;
	// stw r9,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r9.u32);
loc_82589390:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r31,r26
	r31.u64 = r26.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,15,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258949c
	if (cr6.eq) goto loc_8258949C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825893d8
	if (cr6.eq) goto loc_825893D8;
	// lbz r10,49(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 49);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825894a0
	goto loc_825894A0;
loc_825893D8:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r26,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r26.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82589444
	if (!cr0.gt) goto loc_82589444;
loc_825893F4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,49
	cr6.compare<int32_t>(ctx.r7.s32, 49, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82589414
	if (cr6.lt) goto loc_82589414;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
loc_82589414:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82589430
	if (cr6.eq) goto loc_82589430;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82589438
	goto loc_82589438;
loc_82589430:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82589438:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825893f4
	if (cr6.gt) goto loc_825893F4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82589444:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82589488
	if (cr6.eq) goto loc_82589488;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82589460
	if (cr6.gt) goto loc_82589460;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82589460:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82589488
	if (!cr6.eq) goto loc_82589488;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825894a0
	goto loc_825894A0;
loc_82589488:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825894a0
	goto loc_825894A0;
loc_8258949C:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_825894A0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258968c
	if (cr6.eq) goto loc_8258968C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(88) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi r9,r3,24
	ctx.r9.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8258968c
	if (!cr6.eq) goto loc_8258968C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(16) );
	// vspltisw v0,0
	simd::store_i32(ctx.v0.u32, simd::set1_i32(int32_t(0x0)));
	// addi r10,r1,208
	ctx.r10.s64 = ctx.r1.s64 + 208;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r9,352(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(352) );
	// stw r26,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, r26.u32);
	// stvx128 v0,r0,r10
	ea = (ctx.r10.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// stw r29,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r29.u32);
	// stfs f31,224(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// stw r9,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, ctx.r9.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82ca2c30
	return;
loc_82589508:
	// li r26,0
	r26.s64 = 0;
	// addi r30,r27,4
	r30.s64 = r27.s64 + 4;
	// stb r26,20(r27)
	PPC_STORE_U8(r27.u32 + 20, r26.u8);
	// mr r31,r26
	r31.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,30,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82589620
	if (cr6.eq) goto loc_82589620;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258955c
	if (cr6.eq) goto loc_8258955C;
	// lbz r10,98(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 98);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82589624
	goto loc_82589624;
loc_8258955C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r26,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r26.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825895c8
	if (!cr0.gt) goto loc_825895C8;
loc_82589578:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,98
	cr6.compare<int32_t>(ctx.r7.s32, 98, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82589598
	if (cr6.lt) goto loc_82589598;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
loc_82589598:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825895b4
	if (cr6.eq) goto loc_825895B4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825895bc
	goto loc_825895BC;
loc_825895B4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825895BC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82589578
	if (cr6.gt) goto loc_82589578;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_825895C8:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258960c
	if (cr6.eq) goto loc_8258960C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,98
	cr6.compare<int32_t>(r11.s32, 98, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825895e4
	if (cr6.gt) goto loc_825895E4;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_825895E4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258960c
	if (!cr6.eq) goto loc_8258960C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82589624
	goto loc_82589624;
loc_8258960C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82589624
	goto loc_82589624;
loc_82589620:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82589624:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258968c
	if (cr6.eq) goto loc_8258968C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// stw r26,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r26.u32);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// lis r8,-32242
	ctx.r8.s64 = -2113011712;
	// addi r7,r9,-28256
	ctx.r7.s64 = ctx.r9.s64 + -28256;
	// lfs f0,-27456(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -27456);
	f0.f64 = double(temp.f32);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r5,r8,-1552
	ctx.r5.s64 = ctx.r8.s64 + -1552;
	// lvlx v0,0,r10
	temp.u32 = r0.u32 + ctx.r10.u32;
	simd::store_shuffled(ctx.v0,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vspltw v13,v0,0
	simd::store_i32(ctx.v13.u32, simd::broadcast_lane_i32(simd::load_i32(ctx.v0.u32), 3));
	// lvx128 v0,r0,r7
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((ctx.r7.u32) & ~0xF), VectorMaskL));
	// stw r5,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r5.u32);
	// vand v12,v13,v0
	simd::store_u8(ctx.v12.u8, simd::and_u8(simd::load_u8(ctx.v13.u8), simd::load_u8(ctx.v0.u8)));
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r31,r31,20
	r31.s64 = r31.s64 + 20;
	// addi r30,r1,96
	r30.s64 = ctx.r1.s64 + 96;
	// stvx128 v12,r0,r6
	ea = (ctx.r6.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v12), &VectorMaskL[(ea & 0xF) * 16]);
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8273da00
	sub_8273DA00(ctx, base);
loc_8258968C:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_825891E0) {
	__imp__sub_825891E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82589698) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// addi r24,r26,4
	r24.s64 = r26.s64 + 4;
	// li r31,0
	r31.s64 = 0;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(8) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825896dc
	if (cr6.eq) goto loc_825896DC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825896d4
	if (cr6.eq) goto loc_825896D4;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x825896e0
	goto loc_825896E0;
loc_825896D4:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_825896DC:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_825896E0:
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(48) );
	// rlwinm r9,r10,10,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82589764
	if (cr6.eq) goto loc_82589764;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258975c
	if (!cr6.eq) goto loc_8258975C;
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r11,76(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// subf r9,r10,r11
	ctx.r9.s64 = r11.s64 - ctx.r10.s64;
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258975c
	if (!cr0.gt) goto loc_8258975C;
loc_82589710:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,118
	cr6.compare<int32_t>(ctx.r7.s32, 118, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82589730
	if (cr6.lt) goto loc_82589730;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82589730:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258974c
	if (cr6.eq) goto loc_8258974C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82589754
	goto loc_82589754;
loc_8258974C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82589754:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82589710
	if (cr6.gt) goto loc_82589710;
loc_8258975C:
	// li r11,1
	r11.s64 = 1;
	// b 0x82589768
	goto loc_82589768;
loc_82589764:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82589768:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589cac
	if (cr6.eq) goto loc_82589CAC;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// addi r30,r1,88
	r30.s64 = ctx.r1.s64 + 88;
	// addi r29,r1,128
	r29.s64 = ctx.r1.s64 + 128;
	// addi r28,r1,160
	r28.s64 = ctx.r1.s64 + 160;
	// addi r27,r1,112
	r27.s64 = ctx.r1.s64 + 112;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x824c0928
	sub_824C0928(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589cac
	if (cr6.eq) goto loc_82589CAC;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// addi r27,r11,-6076
	r27.s64 = r11.s64 + -6076;
	// mr r29,r31
	r29.u64 = r31.u64;
	// lfs f0,-11676(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + -11676);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,10,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 10) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825898c8
	if (cr6.eq) goto loc_825898C8;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589804
	if (cr6.eq) goto loc_82589804;
	// lbz r10,118(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 118);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825898cc
	goto loc_825898CC;
loc_82589804:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82589870
	if (!cr0.gt) goto loc_82589870;
loc_82589820:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,118
	cr6.compare<int32_t>(ctx.r7.s32, 118, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82589840
	if (cr6.lt) goto loc_82589840;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82589840:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258985c
	if (cr6.eq) goto loc_8258985C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82589864
	goto loc_82589864;
loc_8258985C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82589864:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82589820
	if (cr6.gt) goto loc_82589820;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_82589870:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825898b4
	if (cr6.eq) goto loc_825898B4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,118
	cr6.compare<int32_t>(r11.s32, 118, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258988c
	if (cr6.gt) goto loc_8258988C;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258988C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825898b4
	if (!cr6.eq) goto loc_825898B4;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825898cc
	goto loc_825898CC;
loc_825898B4:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825898cc
	goto loc_825898CC;
loc_825898C8:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_825898CC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825898f0
	if (cr6.eq) goto loc_825898F0;
	// lwz r11,80(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(80) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x825898f0
	if (!cr6.gt) goto loc_825898F0;
	// lis r11,-32240
	r11.s64 = -2112880640;
	// lfs f0,2384(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2384);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
loc_825898F0:
	// mr r30,r31
	r30.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// lwz r9,64(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(64) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r8,r1,144
	ctx.r8.s64 = ctx.r1.s64 + 144;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// lfs f13,-3576(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + -3576);
	ctx.f13.f64 = double(temp.f32);
	// lis r6,-32246
	ctx.r6.s64 = -2113273856;
	// lfs f0,-21392(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -21392);
	f0.f64 = double(temp.f32);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lfs f12,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f12.f64 = double(temp.f32);
	// addi r4,r6,-28176
	ctx.r4.s64 = ctx.r6.s64 + -28176;
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// lvx128 v0,r0,r8
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((ctx.r8.u32) & ~0xF), VectorMaskL));
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// stvx128 v0,r0,r7
	ea = (ctx.r7.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f11,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// fadds f10,f11,f13
	ctx.f10.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// lvx128 v7,r0,r4
	simd::store_shuffled(ctx.v7, simd::load_and_shuffle(base + ((ctx.r4.u32) & ~0xF), VectorMaskL));
	// stfs f10,96(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lvlx v13,0,r5
	temp.u32 = r0.u32 + ctx.r5.u32;
	simd::store_shuffled(ctx.v13,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vperm v12,v0,v13,v7
	simd::store_i8(ctx.v12.u8, simd::permute_bytes(simd::load_i8(ctx.v0.u8), simd::load_i8(ctx.v13.u8), simd::load_i8(ctx.v7.u8)));
	// stvx128 v12,r0,r3
	ea = (ctx.r3.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v12), &VectorMaskL[(ea & 0xF) * 16]);
	// bgt cr6,0x82589990
	if (cr6.gt) goto loc_82589990;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// bl 0x821f5a90
	sub_821F5A90(ctx, base);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lvx128 v0,r0,r3
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((ctx.r3.u32) & ~0xF), VectorMaskL));
	// stvx128 v0,r0,r10
	ea = (ctx.r10.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
loc_82589990:
	// lwz r28,112(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// cmpwi cr6,r28,1
	cr6.compare<int32_t>(r28.s32, 1, xer);
	// bne cr6,0x82589b44
	if (!cr6.eq) goto loc_82589B44;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// mr r30,r31
	r30.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,44(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(44) );
	// rlwinm r10,r11,19,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82589aa8
	if (cr6.eq) goto loc_82589AA8;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825899e4
	if (cr6.eq) goto loc_825899E4;
	// lbz r10,77(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 77);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82589aac
	goto loc_82589AAC;
loc_825899E4:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82589a50
	if (!cr0.gt) goto loc_82589A50;
loc_82589A00:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,77
	cr6.compare<int32_t>(ctx.r7.s32, 77, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82589a20
	if (cr6.lt) goto loc_82589A20;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82589A20:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82589a3c
	if (cr6.eq) goto loc_82589A3C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82589a44
	goto loc_82589A44;
loc_82589A3C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82589A44:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82589a00
	if (cr6.gt) goto loc_82589A00;
	// stw r10,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r10.u32);
loc_82589A50:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82589a94
	if (cr6.eq) goto loc_82589A94;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,77
	cr6.compare<int32_t>(r11.s32, 77, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82589a6c
	if (cr6.gt) goto loc_82589A6C;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82589A6C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82589a94
	if (!cr6.eq) goto loc_82589A94;
	// ld r11,112(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82589aac
	goto loc_82589AAC;
loc_82589A94:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82589aac
	goto loc_82589AAC;
loc_82589AA8:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82589AAC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589acc
	if (cr6.eq) goto loc_82589ACC;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82589ACC:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// addi r30,r1,128
	r30.s64 = ctx.r1.s64 + 128;
	// addi r23,r1,80
	r23.s64 = ctx.r1.s64 + 80;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// lfs f1,0(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lvx128 v1,r0,r11
	simd::store_shuffled(ctx.v1, simd::load_and_shuffle(base + ((r11.u32) & ~0xF), VectorMaskL));
	// bl 0x824c0b90
	sub_824C0B90(ctx, base);
	// lwz r30,80(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82589b18
	if (cr6.eq) goto loc_82589B18;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x827bb550
	sub_827BB550(ctx, base);
	// li r11,48
	r11.s64 = 48;
	// stvx128 v1,r26,r11
	ea = (r26.u32 + r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v1), &VectorMaskL[(ea & 0xF) * 16]);
	// b 0x82589b4c
	goto loc_82589B4C;
loc_82589B18:
	// addi r11,r1,84
	r11.s64 = ctx.r1.s64 + 84;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// li r8,48
	ctx.r8.s64 = 48;
	// lvlx v0,0,r11
	temp.u32 = r0.u32 + r11.u32;
	simd::store_shuffled(ctx.v0,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vspltw v13,v0,0
	simd::store_i32(ctx.v13.u32, simd::broadcast_lane_i32(simd::load_i32(ctx.v0.u32), 3));
	// lvx128 v12,r0,r10
	simd::store_shuffled(ctx.v12, simd::load_and_shuffle(base + ((ctx.r10.u32) & ~0xF), VectorMaskL));
	// lvx128 v11,r0,r9
	simd::store_shuffled(ctx.v11, simd::load_and_shuffle(base + ((ctx.r9.u32) & ~0xF), VectorMaskL));
	// vmaddfp v1,v12,v13,v11
	ctx.fpscr.enableFlushMode();
	simd::store_f32_aligned(ctx.v1.f32, simd::add_f32(simd::mul_f32(simd::load_f32_aligned(ctx.v12.f32), simd::load_f32_aligned(ctx.v13.f32)), simd::load_f32_aligned(ctx.v11.f32)));
	// stvx128 v1,r26,r8
	ea = (r26.u32 + ctx.r8.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v1), &VectorMaskL[(ea & 0xF) * 16]);
	// b 0x82589b4c
	goto loc_82589B4C;
loc_82589B44:
	// li r11,48
	r11.s64 = 48;
	// lvx128 v1,r26,r11
	simd::store_shuffled(ctx.v1, simd::load_and_shuffle(base + ((r26.u32 + r11.u32) & ~0xF), VectorMaskL));
loc_82589B4C:
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82612220
	sub_82612220(ctx, base);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,44(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(44) );
	// rlwinm r10,r11,19,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82589c5c
	if (cr6.eq) goto loc_82589C5C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589ba0
	if (cr6.eq) goto loc_82589BA0;
	// lbz r10,77(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 77);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r11,1
	r11.s64 = 1;
	// lwz r31,4(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x82589c60
	goto loc_82589C60;
loc_82589BA0:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82589c0c
	if (!cr0.gt) goto loc_82589C0C;
loc_82589BBC:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,77
	cr6.compare<int32_t>(ctx.r7.s32, 77, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82589bdc
	if (cr6.lt) goto loc_82589BDC;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82589BDC:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82589bf8
	if (cr6.eq) goto loc_82589BF8;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82589c00
	goto loc_82589C00;
loc_82589BF8:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82589C00:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82589bbc
	if (cr6.gt) goto loc_82589BBC;
	// stw r10,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r10.u32);
loc_82589C0C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82589c4c
	if (cr6.eq) goto loc_82589C4C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,77
	cr6.compare<int32_t>(r11.s32, 77, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82589c28
	if (cr6.gt) goto loc_82589C28;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82589C28:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82589c4c
	if (!cr6.eq) goto loc_82589C4C;
	// ld r11,112(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x82589c60
	goto loc_82589C60;
loc_82589C4C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x82589c60
	goto loc_82589C60;
loc_82589C5C:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82589C60:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589cac
	if (cr6.eq) goto loc_82589CAC;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// lwz r9,64(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(64) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lvx128 v1,r0,r8
	simd::store_shuffled(ctx.v1, simd::load_and_shuffle(base + ((ctx.r8.u32) & ~0xF), VectorMaskL));
	// lwz r6,80(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(80) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82589CAC:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_82589698) {
	__imp__sub_82589698(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82589CB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lbz r11,16(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589e9c
	if (cr6.eq) goto loc_82589E9C;
	// li r30,0
	r30.s64 = 0;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// stb r30,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r30.u8);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(124) );
	// bl 0x825bb370
	sub_825BB370(ctx, base);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589d40
	if (cr6.eq) goto loc_82589D40;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82589d98
	if (cr6.eq) goto loc_82589D98;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589d40
	if (cr6.eq) goto loc_82589D40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82589d44
	if (!cr6.eq) goto loc_82589D44;
loc_82589D40:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82589D44:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589e9c
	if (cr6.eq) goto loc_82589E9C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r31,r30
	r31.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,11,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 11) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82589e68
	if (cr6.eq) goto loc_82589E68;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589da4
	if (cr6.eq) goto loc_82589DA4;
	// lbz r10,21(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 21);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82589e6c
	goto loc_82589E6C;
loc_82589D98:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82589d40
	goto loc_82589D40;
loc_82589DA4:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82589e10
	if (!cr0.gt) goto loc_82589E10;
loc_82589DC0:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,21
	cr6.compare<int32_t>(ctx.r7.s32, 21, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82589de0
	if (cr6.lt) goto loc_82589DE0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_82589DE0:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82589dfc
	if (cr6.eq) goto loc_82589DFC;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82589e04
	goto loc_82589E04;
loc_82589DFC:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82589E04:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82589dc0
	if (cr6.gt) goto loc_82589DC0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82589E10:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82589e54
	if (cr6.eq) goto loc_82589E54;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82589e2c
	if (cr6.gt) goto loc_82589E2C;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82589E2C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82589e54
	if (!cr6.eq) goto loc_82589E54;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82589e6c
	goto loc_82589E6C;
loc_82589E54:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82589e6c
	goto loc_82589E6C;
loc_82589E68:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82589E6C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589e9c
	if (cr6.eq) goto loc_82589E9C;
	// li r4,57
	ctx.r4.s64 = 57;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821ff4e0
	sub_821FF4E0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589e9c
	if (cr6.eq) goto loc_82589E9C;
	// li r4,57
	ctx.r4.s64 = 57;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f27a8
	sub_823F27A8(ctx, base);
loc_82589E9C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82589CB8) {
	__imp__sub_82589CB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82589EB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// li r31,0
	r31.s64 = 0;
	// addi r29,r3,4
	r29.s64 = ctx.r3.s64 + 4;
	// mr r30,r31
	r30.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82589ef8
	if (cr6.eq) goto loc_82589EF8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82589ef0
	if (cr6.eq) goto loc_82589EF0;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x82589efc
	goto loc_82589EFC;
loc_82589EF0:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82589EF8:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82589EFC:
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(48) );
	// rlwinm r9,r10,10,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82589ffc
	if (cr6.eq) goto loc_82589FFC;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82589f38
	if (cr6.eq) goto loc_82589F38;
	// lbz r10,118(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 118);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a000
	goto loc_8258A000;
loc_82589F38:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82589fa4
	if (!cr0.gt) goto loc_82589FA4;
loc_82589F54:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,118
	cr6.compare<int32_t>(ctx.r7.s32, 118, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82589f74
	if (cr6.lt) goto loc_82589F74;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82589F74:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82589f90
	if (cr6.eq) goto loc_82589F90;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82589f98
	goto loc_82589F98;
loc_82589F90:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82589F98:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82589f54
	if (cr6.gt) goto loc_82589F54;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82589FA4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82589fe8
	if (cr6.eq) goto loc_82589FE8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,118
	cr6.compare<int32_t>(r11.s32, 118, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82589fc0
	if (cr6.gt) goto loc_82589FC0;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82589FC0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82589fe8
	if (!cr6.eq) goto loc_82589FE8;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a000
	goto loc_8258A000;
loc_82589FE8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a000
	goto loc_8258A000;
loc_82589FFC:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A000:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a158
	if (cr6.eq) goto loc_8258A158;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(16) );
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(112) );
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x8258a028
	if (cr6.eq) goto loc_8258A028;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r31
	r11.u64 = r31.u64;
	// bne cr6,0x8258a02c
	if (!cr6.eq) goto loc_8258A02C;
loc_8258A028:
	// li r11,1
	r11.s64 = 1;
loc_8258A02C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a158
	if (cr6.eq) goto loc_8258A158;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258a13c
	if (cr6.eq) goto loc_8258A13C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a07c
	if (cr6.eq) goto loc_8258A07C;
	// lbz r11,33(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a140
	goto loc_8258A140;
loc_8258A07C:
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258a0e4
	if (!cr0.gt) goto loc_8258A0E4;
loc_8258A094:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258a0b4
	if (cr6.lt) goto loc_8258A0B4;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258A0B4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258a0d0
	if (cr6.eq) goto loc_8258A0D0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258a0d8
	goto loc_8258A0D8;
loc_8258A0D0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258A0D8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258a094
	if (cr6.gt) goto loc_8258A094;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258A0E4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258a128
	if (cr6.eq) goto loc_8258A128;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258a100
	if (cr6.gt) goto loc_8258A100;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A100:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258a128
	if (!cr6.eq) goto loc_8258A128;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a140
	goto loc_8258A140;
loc_8258A128:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a140
	goto loc_8258A140;
loc_8258A13C:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A140:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a158
	if (cr6.eq) goto loc_8258A158;
	// li r4,18
	ctx.r4.s64 = 18;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823c88f0
	sub_823C88F0(ctx, base);
loc_8258A158:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82589EB8) {
	__imp__sub_82589EB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258A160) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lbz r11,16(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// li r11,0
	r11.s64 = 0;
	// stb r11,16(r4)
	PPC_STORE_U8(ctx.r4.u32 + 16, r11.u8);
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(124) );
	// b 0x825bb370
	sub_825BB370(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_8258A160) {
	__imp__sub_8258A160(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258A18C) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258A18C) {
	__imp__sub_8258A18C(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258A190) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r24{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r30,r3,4
	r30.s64 = ctx.r3.s64 + 4;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a1d0
	if (cr6.eq) goto loc_8258A1D0;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258a1c8
	if (cr6.eq) goto loc_8258A1C8;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8258a1d4
	goto loc_8258A1D4;
loc_8258A1C8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8258A1D0:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A1D4:
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// rlwinm r9,r10,31,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258a2d4
	if (cr6.eq) goto loc_8258A2D4;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258a210
	if (cr6.eq) goto loc_8258A210;
	// lbz r10,33(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 33);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a2d8
	goto loc_8258A2D8;
loc_8258A210:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258a27c
	if (!cr0.gt) goto loc_8258A27C;
loc_8258A22C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258a24c
	if (cr6.lt) goto loc_8258A24C;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258A24C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258a268
	if (cr6.eq) goto loc_8258A268;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258a270
	goto loc_8258A270;
loc_8258A268:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258A270:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258a22c
	if (cr6.gt) goto loc_8258A22C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258A27C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258a2c0
	if (cr6.eq) goto loc_8258A2C0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258a298
	if (cr6.gt) goto loc_8258A298;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A298:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258a2c0
	if (!cr6.eq) goto loc_8258A2C0;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a2d8
	goto loc_8258A2D8;
loc_8258A2C0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a2d8
	goto loc_8258A2D8;
loc_8258A2D4:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A2D8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a490
	if (cr6.eq) goto loc_8258A490;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(20) );
	// lwz r10,40(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + int32_t(40) );
	// lwz r9,40(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// bne cr6,0x8258a490
	if (!cr6.eq) goto loc_8258A490;
	// lwz r11,44(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(44) );
	// cmpwi cr6,r11,13
	cr6.compare<int32_t>(r11.s32, 13, xer);
	// bne cr6,0x8258a490
	if (!cr6.eq) goto loc_8258A490;
	// lbz r11,8(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 8);
	// addi r11,r11,-11
	r11.s64 = r11.s64 + -11;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bgt cr6,0x8258a490
	if (cr6.gt) goto loc_8258A490;
	// lis r12,-32167
	r12.s64 = -2108096512;
	// addi r12,r12,-23764
	r12.s64 = r12.s64 + -23764;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_8258A33C;
	case 1:
		goto loc_8258A38C;
	case 2:
		goto loc_8258A3DC;
	case 3:
		goto loc_8258A42C;
	default:
		__builtin_unreachable();
	}
	// lwz r18,-23748(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(-23748) );
	// lwz r18,-23668(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(-23668) );
	// lwz r18,-23588(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(-23588) );
	// lwz r18,-23508(r24)
	r18.u64 = PPC_LOAD_U32(r24.u32 + int32_t(-23508) );
loc_8258A33C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// lwz r9,64(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(64) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r8,-31927
	ctx.r8.s64 = -2092367872;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,26912(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(26912) );
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r6,88(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(88) );
	// lwz r5,4(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(4) );
	// lwz r31,16(r5)
	r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + int32_t(16) );
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x8258a478
	goto loc_8258A478;
loc_8258A38C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// lwz r9,64(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(64) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r8,-31927
	ctx.r8.s64 = -2092367872;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,26912(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(26912) );
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r6,88(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(88) );
	// lwz r5,4(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(4) );
	// lwz r31,16(r5)
	r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + int32_t(16) );
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x8258a478
	goto loc_8258A478;
loc_8258A3DC:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// lwz r9,64(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(64) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r8,-31927
	ctx.r8.s64 = -2092367872;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,26912(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(26912) );
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r6,88(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(88) );
	// lwz r5,4(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(4) );
	// lwz r31,16(r5)
	r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + int32_t(16) );
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,5
	ctx.r4.s64 = 5;
	// b 0x8258a478
	goto loc_8258A478;
loc_8258A42C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// lwz r9,64(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(64) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r8,-31927
	ctx.r8.s64 = -2092367872;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,26912(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(26912) );
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r6,88(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(88) );
	// lwz r5,4(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(4) );
	// lwz r31,16(r5)
	r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + int32_t(16) );
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// li r4,6
	ctx.r4.s64 = 6;
loc_8258A478:
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,101
	ctx.r8.s64 = 101;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82279a40
	sub_82279A40(ctx, base);
loc_8258A490:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8258A190) {
	__imp__sub_8258A190(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258A498) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,1
	r11.s64 = 1;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stb r11,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r11.u8);
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(124) );
	// bl 0x825bb2c0
	sub_825BB2C0(ctx, base);
	// lis r8,-31927
	ctx.r8.s64 = -2092367872;
	// lwz r11,26788(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(26788) );
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r7,32(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r6,60(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(60) );
	// lbz r5,29(r6)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r6.u32 + 29);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// stb r5,20(r31)
	PPC_STORE_U8(r31.u32 + 20, ctx.r5.u8);
	// beq cr6,0x8258a4fc
	if (cr6.eq) goto loc_8258A4FC;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r8,60(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(60) );
	// stb r9,29(r8)
	PPC_STORE_U8(ctx.r8.u32 + 29, ctx.r9.u8);
loc_8258A4FC:
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(56) );
	// lbz r8,32(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x8258a520
	if (cr6.eq) goto loc_8258A520;
	// lbz r10,33(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 33);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// li r10,1
	ctx.r10.s64 = 1;
	// beq cr6,0x8258a524
	if (cr6.eq) goto loc_8258A524;
loc_8258A520:
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
loc_8258A524:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// stb r10,21(r31)
	PPC_STORE_U8(r31.u32 + 21, ctx.r10.u8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258a544
	if (cr6.eq) goto loc_8258A544;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r3,56(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// stb r9,32(r3)
	PPC_STORE_U8(ctx.r3.u32 + 32, ctx.r9.u8);
	// bl 0x824065f0
	sub_824065F0(ctx, base);
loc_8258A544:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258A498) {
	__imp__sub_8258A498(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258A558) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// addi r29,r3,4
	r29.s64 = ctx.r3.s64 + 4;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a5ac
	if (cr6.eq) goto loc_8258A5AC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258a604
	if (cr6.eq) goto loc_8258A604;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a5ac
	if (cr6.eq) goto loc_8258A5AC;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258a5b0
	if (!cr6.eq) goto loc_8258A5B0;
loc_8258A5AC:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A5B0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a810
	if (cr6.eq) goto loc_8258A810;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r30,r31
	r30.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258a6d4
	if (cr6.eq) goto loc_8258A6D4;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a610
	if (cr6.eq) goto loc_8258A610;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a6d8
	goto loc_8258A6D8;
loc_8258A604:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8258a5ac
	goto loc_8258A5AC;
loc_8258A610:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258a67c
	if (!cr0.gt) goto loc_8258A67C;
loc_8258A62C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258a64c
	if (cr6.lt) goto loc_8258A64C;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258A64C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258a668
	if (cr6.eq) goto loc_8258A668;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258a670
	goto loc_8258A670;
loc_8258A668:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258A670:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258a62c
	if (cr6.gt) goto loc_8258A62C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258A67C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258a6c0
	if (cr6.eq) goto loc_8258A6C0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258a698
	if (cr6.gt) goto loc_8258A698;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A698:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258a6c0
	if (!cr6.eq) goto loc_8258A6C0;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a6d8
	goto loc_8258A6D8;
loc_8258A6C0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a6d8
	goto loc_8258A6D8;
loc_8258A6D4:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A6D8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a810
	if (cr6.eq) goto loc_8258A810;
	// lbz r11,24(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258a810
	if (!cr6.eq) goto loc_8258A810;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,20,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 20) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258a7f4
	if (cr6.eq) goto loc_8258A7F4;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a734
	if (cr6.eq) goto loc_8258A734;
	// lbz r11,44(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 44);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a7f8
	goto loc_8258A7F8;
loc_8258A734:
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258a79c
	if (!cr0.gt) goto loc_8258A79C;
loc_8258A74C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,44
	cr6.compare<int32_t>(ctx.r7.s32, 44, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258a76c
	if (cr6.lt) goto loc_8258A76C;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258A76C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258a788
	if (cr6.eq) goto loc_8258A788;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258a790
	goto loc_8258A790;
loc_8258A788:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258A790:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258a74c
	if (cr6.gt) goto loc_8258A74C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258A79C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258a7e0
	if (cr6.eq) goto loc_8258A7E0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,44
	cr6.compare<int32_t>(r11.s32, 44, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258a7b8
	if (cr6.gt) goto loc_8258A7B8;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A7B8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258a7e0
	if (!cr6.eq) goto loc_8258A7E0;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a7f8
	goto loc_8258A7F8;
loc_8258A7E0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258a7f8
	goto loc_8258A7F8;
loc_8258A7F4:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A7F8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a810
	if (cr6.eq) goto loc_8258A810;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(100) );
	// ori r10,r11,15
	ctx.r10.u64 = r11.u64 | 15;
	// stw r10,100(r31)
	PPC_STORE_U32(r31.u32 + 100, ctx.r10.u32);
loc_8258A810:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8258A558) {
	__imp__sub_8258A558(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258A818) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stb r11,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r11.u8);
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(124) );
	// bl 0x825bb370
	sub_825BB370(ctx, base);
	// lis r8,-31927
	ctx.r8.s64 = -2092367872;
	// lbz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U8(r31.u32 + 20);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,26788(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(26788) );
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258a870
	if (cr6.eq) goto loc_8258A870;
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r8,60(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(60) );
	// stb r10,29(r8)
	PPC_STORE_U8(ctx.r8.u32 + 29, ctx.r10.u8);
loc_8258A870:
	// lbz r9,21(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 21);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258a88c
	if (cr6.eq) goto loc_8258A88C;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r3,56(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// stb r10,32(r3)
	PPC_STORE_U8(ctx.r3.u32 + 32, ctx.r10.u8);
	// bl 0x824065f0
	sub_824065F0(ctx, base);
loc_8258A88C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258A818) {
	__imp__sub_8258A818(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258A8A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// addi r3,r30,4
	ctx.r3.s64 = r30.s64 + 4;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(8) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258a8e8
	if (cr6.eq) goto loc_8258A8E8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258a8e4
	if (cr6.eq) goto loc_8258A8E4;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8258a8ec
	goto loc_8258A8EC;
loc_8258A8E4:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8258A8E8:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A8EC:
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(48) );
	// rlwinm r9,r10,18,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258a9d0
	if (cr6.eq) goto loc_8258A9D0;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258a920
	if (cr6.eq) goto loc_8258A920;
	// lbz r10,110(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 110);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8258a9cc
	goto loc_8258A9CC;
loc_8258A920:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258a98c
	if (!cr0.gt) goto loc_8258A98C;
loc_8258A93C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,110
	cr6.compare<int32_t>(ctx.r7.s32, 110, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258a95c
	if (cr6.lt) goto loc_8258A95C;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258A95C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258a978
	if (cr6.eq) goto loc_8258A978;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258a980
	goto loc_8258A980;
loc_8258A978:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258A980:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258a93c
	if (cr6.gt) goto loc_8258A93C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258A98C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258a9c4
	if (cr6.eq) goto loc_8258A9C4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,110
	cr6.compare<int32_t>(r11.s32, 110, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258a9a8
	if (cr6.gt) goto loc_8258A9A8;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258A9A8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258a9c4
	if (!cr6.eq) goto loc_8258A9C4;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// b 0x8258a9c8
	goto loc_8258A9C8;
loc_8258A9C4:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_8258A9C8:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_8258A9CC:
	// mr r31,r11
	r31.u64 = r11.u64;
loc_8258A9D0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lfs f31,204(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 204);
	f31.f64 = double(temp.f32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(68) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r11,r11,-17760
	r11.s64 = r11.s64 + -17760;
	// lfs f0,-9708(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -9708);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f31,f0
	cr6.compare(f31.f64, f0.f64);
	// ble cr6,0x8258aaa0
	if (!cr6.gt) goto loc_8258AAA0;
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	f0.f64 = double(temp.f32);
	// ld r10,44(r30)
	ctx.r10.u64 = PPC_LOAD_U64(r30.u32 + 44);
	// fmuls f11,f0,f0
	ctx.f11.f64 = double(float(f0.f64 * f0.f64));
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,-1104(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -1104);
	ctx.f12.f64 = double(temp.f32);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// fmadds f10,f13,f13,f11
	ctx.f10.f64 = double(std::fma(float(ctx.f13.f64), float(ctx.f13.f64), float(ctx.f11.f64)));
	// fcmpu cr6,f10,f12
	cr6.compare(ctx.f10.f64, ctx.f12.f64);
	// ble cr6,0x8258aa64
	if (!cr6.gt) goto loc_8258AA64;
	// lfs f12,-9696(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -9696);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f10.f64 = double(temp.f32);
	// fadds f11,f31,f12
	ctx.f11.f64 = double(float(f31.f64 + ctx.f12.f64));
	// lfs f9,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f10,f31
	ctx.f7.f64 = double(float(ctx.f10.f64 * f31.f64));
	// fmuls f8,f9,f31
	ctx.f8.f64 = double(float(ctx.f9.f64 * f31.f64));
	// fdivs f6,f12,f11
	ctx.f6.f64 = double(float(ctx.f12.f64 / ctx.f11.f64));
	// fadds f4,f13,f7
	ctx.f4.f64 = double(float(ctx.f13.f64 + ctx.f7.f64));
	// fadds f5,f0,f8
	ctx.f5.f64 = double(float(f0.f64 + ctx.f8.f64));
	// fmuls f2,f4,f6
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// stfs f2,80(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f3,f5,f6
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// stfs f3,84(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// ld r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r9,44(r30)
	PPC_STORE_U64(r30.u32 + 44, ctx.r9.u64);
	// b 0x8258aaa8
	goto loc_8258AAA8;
loc_8258AA64:
	// lfs f12,-1472(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -1472);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f10,f12
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmuls f6,f8,f12
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f11,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fadds f7,f0,f9
	ctx.f7.f64 = double(float(f0.f64 + ctx.f9.f64));
	// fadds f4,f13,f6
	ctx.f4.f64 = double(float(ctx.f13.f64 + ctx.f6.f64));
	// fmuls f5,f7,f11
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// stfs f5,84(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f3,f4,f11
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// stfs f3,80(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// ld r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r9,44(r30)
	PPC_STORE_U64(r30.u32 + 44, ctx.r9.u64);
	// b 0x8258aaa8
	goto loc_8258AAA8;
loc_8258AAA0:
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,44(r30)
	PPC_STORE_U64(r30.u32 + 44, r11.u64);
loc_8258AAA8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82585ea8
	sub_82585EA8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// lfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258A8A0) {
	__imp__sub_8258A8A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258AAD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82585de8
	sub_82585DE8(ctx, base);
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// li r31,0
	r31.s64 = 0;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ab14
	if (cr6.eq) goto loc_8258AB14;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258ab10
	if (cr6.eq) goto loc_8258AB10;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8258ab18
	goto loc_8258AB18;
loc_8258AB10:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8258AB14:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258AB18:
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(48) );
	// rlwinm r9,r10,18,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258ac18
	if (cr6.eq) goto loc_8258AC18;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258ab54
	if (cr6.eq) goto loc_8258AB54;
	// lbz r10,110(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 110);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258ac1c
	goto loc_8258AC1C;
loc_8258AB54:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258abc0
	if (!cr0.gt) goto loc_8258ABC0;
loc_8258AB70:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,110
	cr6.compare<int32_t>(ctx.r7.s32, 110, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258ab90
	if (cr6.lt) goto loc_8258AB90;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258AB90:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258abac
	if (cr6.eq) goto loc_8258ABAC;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258abb4
	goto loc_8258ABB4;
loc_8258ABAC:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258ABB4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258ab70
	if (cr6.gt) goto loc_8258AB70;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258ABC0:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258ac04
	if (cr6.eq) goto loc_8258AC04;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,110
	cr6.compare<int32_t>(r11.s32, 110, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258abdc
	if (cr6.gt) goto loc_8258ABDC;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258ABDC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258ac04
	if (!cr6.eq) goto loc_8258AC04;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258ac1c
	goto loc_8258AC1C;
loc_8258AC04:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258ac1c
	goto loc_8258AC1C;
loc_8258AC18:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258AC1C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ac34
	if (cr6.eq) goto loc_8258AC34;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lfs f0,-27340(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -27340);
	f0.f64 = double(temp.f32);
	// stfs f0,204(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 204, temp.u32);
loc_8258AC34:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258AAD0) {
	__imp__sub_8258AAD0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258AC48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82585e50
	sub_82585E50(ctx, base);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// li r30,0
	r30.s64 = 0;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258acac
	if (cr6.eq) goto loc_8258ACAC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258ad00
	if (cr6.eq) goto loc_8258AD00;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258acac
	if (cr6.eq) goto loc_8258ACAC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258acb0
	if (!cr6.eq) goto loc_8258ACB0;
loc_8258ACAC:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258ACB0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258adec
	if (cr6.eq) goto loc_8258ADEC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,18,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258add0
	if (cr6.eq) goto loc_8258ADD0;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ad0c
	if (cr6.eq) goto loc_8258AD0C;
	// lbz r10,110(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 110);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258add4
	goto loc_8258ADD4;
loc_8258AD00:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8258acac
	goto loc_8258ACAC;
loc_8258AD0C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258ad78
	if (!cr0.gt) goto loc_8258AD78;
loc_8258AD28:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,110
	cr6.compare<int32_t>(ctx.r7.s32, 110, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258ad48
	if (cr6.lt) goto loc_8258AD48;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_8258AD48:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258ad64
	if (cr6.eq) goto loc_8258AD64;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258ad6c
	goto loc_8258AD6C;
loc_8258AD64:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258AD6C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258ad28
	if (cr6.gt) goto loc_8258AD28;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258AD78:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258adbc
	if (cr6.eq) goto loc_8258ADBC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,110
	cr6.compare<int32_t>(r11.s32, 110, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258ad94
	if (cr6.gt) goto loc_8258AD94;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258AD94:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258adbc
	if (!cr6.eq) goto loc_8258ADBC;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258add4
	goto loc_8258ADD4;
loc_8258ADBC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258add4
	goto loc_8258ADD4;
loc_8258ADD0:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258ADD4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258adec
	if (cr6.eq) goto loc_8258ADEC;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lfs f0,-27468(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -27468);
	f0.f64 = double(temp.f32);
	// stfs f0,204(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 204, temp.u32);
loc_8258ADEC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258AC48) {
	__imp__sub_8258AC48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258AE08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stfd f30,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f30.u64);
	// stfd f31,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-31950
	ctx.r10.s64 = -2093875200;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// lis r9,-32240
	ctx.r9.s64 = -2112880640;
	// lis r8,-32240
	ctx.r8.s64 = -2112880640;
	// li r29,0
	r29.s64 = 0;
	// addi r30,r3,4
	r30.s64 = ctx.r3.s64 + 4;
	// lfd f0,-27376(r10)
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + -27376);
	// mr r31,r29
	r31.u64 = r29.u64;
	// lfd f13,1840(r9)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r9.u32 + 1840);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lfd f12,1504(r8)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r8.u32 + 1504);
	// fmul f13,f0,f13
	ctx.f13.f64 = f0.f64 * ctx.f13.f64;
	// fmul f12,f0,f12
	ctx.f12.f64 = f0.f64 * ctx.f12.f64;
	// frsp f31,f13
	f31.f64 = double(float(ctx.f13.f64));
	// frsp f30,f12
	f30.f64 = double(float(ctx.f12.f64));
	// beq cr6,0x8258ae78
	if (cr6.eq) goto loc_8258AE78;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258ae70
	if (cr6.eq) goto loc_8258AE70;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8258ae7c
	goto loc_8258AE7C;
loc_8258AE70:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8258AE78:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8258AE7C:
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// rlwinm r9,r10,23,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258af7c
	if (cr6.eq) goto loc_8258AF7C;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258aeb8
	if (cr6.eq) goto loc_8258AEB8;
	// lbz r10,137(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 137);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258af80
	goto loc_8258AF80;
loc_8258AEB8:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258af24
	if (!cr0.gt) goto loc_8258AF24;
loc_8258AED4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,137
	cr6.compare<int32_t>(ctx.r7.s32, 137, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258aef4
	if (cr6.lt) goto loc_8258AEF4;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_8258AEF4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258af10
	if (cr6.eq) goto loc_8258AF10;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258af18
	goto loc_8258AF18;
loc_8258AF10:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258AF18:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258aed4
	if (cr6.gt) goto loc_8258AED4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258AF24:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258af68
	if (cr6.eq) goto loc_8258AF68;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,137
	cr6.compare<int32_t>(r11.s32, 137, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258af40
	if (cr6.gt) goto loc_8258AF40;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8258AF40:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258af68
	if (!cr6.eq) goto loc_8258AF68;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258af80
	goto loc_8258AF80;
loc_8258AF68:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258af80
	goto loc_8258AF80;
loc_8258AF7C:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8258AF80:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258afac
	if (cr6.eq) goto loc_8258AFAC;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(12) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8258afac
	if (!cr6.eq) goto loc_8258AFAC;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f30,-48(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82ca2c3c
	return;
loc_8258AFAC:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258afd4
	if (cr6.eq) goto loc_8258AFD4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258afcc
	if (cr6.eq) goto loc_8258AFCC;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8258afd8
	goto loc_8258AFD8;
loc_8258AFCC:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8258AFD4:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8258AFD8:
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// rlwinm r9,r10,14,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 14) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258b0cc
	if (cr6.eq) goto loc_8258B0CC;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258b010
	if (cr6.eq) goto loc_8258B010;
	// lbz r10,146(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 146);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8258b0d4
	goto loc_8258B0D4;
loc_8258B010:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258b07c
	if (!cr0.gt) goto loc_8258B07C;
loc_8258B02C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,146
	cr6.compare<int32_t>(ctx.r7.s32, 146, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258b04c
	if (cr6.lt) goto loc_8258B04C;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_8258B04C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258b068
	if (cr6.eq) goto loc_8258B068;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258b070
	goto loc_8258B070;
loc_8258B068:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258B070:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258b02c
	if (cr6.gt) goto loc_8258B02C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258B07C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258b0bc
	if (cr6.eq) goto loc_8258B0BC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,146
	cr6.compare<int32_t>(r11.s32, 146, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258b098
	if (cr6.gt) goto loc_8258B098;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8258B098:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258b0bc
	if (!cr6.eq) goto loc_8258B0BC;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258b0d4
	goto loc_8258B0D4;
loc_8258B0BC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258b0d4
	goto loc_8258B0D4;
loc_8258B0CC:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_8258B0D4:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258b0f8
	if (cr6.eq) goto loc_8258B0F8;
	// lbz r11,36(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b0f8
	if (cr6.eq) goto loc_8258B0F8;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lfs f0,-9652(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -9652);
	f0.f64 = double(temp.f32);
	// fmuls f31,f31,f0
	f31.f64 = double(float(f31.f64 * f0.f64));
loc_8258B0F8:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f30,-48(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8258AE08) {
	__imp__sub_8258AE08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258B110) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// li r29,0
	r29.s64 = 0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b168
	if (cr6.eq) goto loc_8258B168;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258b1b8
	if (cr6.eq) goto loc_8258B1B8;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b168
	if (cr6.eq) goto loc_8258B168;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258b16c
	if (!cr6.eq) goto loc_8258B16C;
loc_8258B168:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8258B16C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b200
	if (cr6.eq) goto loc_8258B200;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x8258b1e4
	if (cr6.eq) goto loc_8258B1E4;
	// cmpwi cr6,r11,54
	cr6.compare<int32_t>(r11.s32, 54, xer);
	// beq cr6,0x8258b1c0
	if (cr6.eq) goto loc_8258B1C0;
	// cmpwi cr6,r11,62
	cr6.compare<int32_t>(r11.s32, 62, xer);
	// bne cr6,0x8258b200
	if (!cr6.eq) goto loc_8258B200;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r29.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r10,r11,-32224
	ctx.r10.s64 = r11.s64 + -32224;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_8258B1B8:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8258b168
	goto loc_8258B168;
loc_8258B1C0:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r29.u32);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// addi r10,r11,2428
	ctx.r10.s64 = r11.s64 + 2428;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_8258B1E4:
	// lis r11,-32245
	r11.s64 = -2113208320;
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r10,r11,-32224
	ctx.r10.s64 = r11.s64 + -32224;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
loc_8258B200:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8258B110) {
	__imp__sub_8258B110(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258B208) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCVRegister v127{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// li r12,-48
	r12.s64 = -48;
	// stvx128 v127,r1,r12
	ea = (ctx.r1.u32 + r12.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(v127), &VectorMaskL[(ea & 0xF) * 16]);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// vor128 v127,v1,v1
	simd::store_i8(v127.u8, simd::load_i8(ctx.v1.u8));
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stvx128 v127,r0,r11
	ea = (r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(v127), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f1,-25888(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -25888);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82260bc8
	sub_82260BC8(ctx, base);
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f0,-27468(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -27468);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// ble cr6,0x8258b26c
	if (!cr6.gt) goto loc_8258B26C;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lvx128 v0,r0,r11
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r11.u32) & ~0xF), VectorMaskL));
	// stvx128 v0,r0,r31
	ea = (r31.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// b 0x8258b27c
	goto loc_8258B27C;
loc_8258B26C:
	// vor128 v1,v127,v127
	simd::store_i8(ctx.v1.u8, simd::load_i8(v127.u8));
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82586b20
	sub_82586B20(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8258B27C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// li r0,-48
	r0.s64 = -48;
	// lvx128 v127,r1,r0
	simd::store_shuffled(v127, simd::load_and_shuffle(base + ((ctx.r1.u32 + r0.u32) & ~0xF), VectorMaskL));
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258B208) {
	__imp__sub_8258B208(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258B2A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r31,r3,4
	r31.s64 = ctx.r3.s64 + 4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b2e8
	if (cr6.eq) goto loc_8258B2E8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258b2e0
	if (cr6.eq) goto loc_8258B2E0;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8258b2ec
	goto loc_8258B2EC;
loc_8258B2E0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8258B2E8:
	// li r11,0
	r11.s64 = 0;
loc_8258B2EC:
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// rlwinm r9,r10,23,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258b370
	if (cr6.eq) goto loc_8258B370;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258b368
	if (!cr6.eq) goto loc_8258B368;
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r11,76(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// subf r9,r10,r11
	ctx.r9.s64 = r11.s64 - ctx.r10.s64;
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258b368
	if (!cr0.gt) goto loc_8258B368;
loc_8258B31C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,137
	cr6.compare<int32_t>(ctx.r7.s32, 137, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258b33c
	if (cr6.lt) goto loc_8258B33C;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8258B33C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258b358
	if (cr6.eq) goto loc_8258B358;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258b360
	goto loc_8258B360;
loc_8258B358:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258B360:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258b31c
	if (cr6.gt) goto loc_8258B31C;
loc_8258B368:
	// li r11,1
	r11.s64 = 1;
	// b 0x8258b374
	goto loc_8258B374;
loc_8258B370:
	// li r11,0
	r11.s64 = 0;
loc_8258B374:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b40c
	if (cr6.eq) goto loc_8258B40C;
	// lvx128 v0,r0,r30
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r30.u32) & ~0xF), VectorMaskL));
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// vmsum3fp128 v13,v0,v0
	ctx.fpscr.enableFlushMode();
	simd::store_f32_aligned(ctx.v13.f32, simd::dp_f32(simd::load_f32_aligned(ctx.v0.f32), simd::load_f32_aligned(ctx.v0.f32), 0xEF));
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lfs f0,-25888(r10)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -25888);
	f0.f64 = double(temp.f32);
	// stvx128 v13,r0,r11
	ea = (r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v13), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f13,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// fsqrts f31,f13
	f31.f64 = double(simd::sqrt_f32(float(ctx.f13.f64)));
	// fcmpu cr6,f31,f0
	cr6.compare(f31.f64, f0.f64);
	// ble cr6,0x8258b40c
	if (!cr6.gt) goto loc_8258B40C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// bl 0x821f5a90
	sub_821F5A90(ctx, base);
	// lvx128 v0,r0,r30
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r30.u32) & ~0xF), VectorMaskL));
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lvx128 v13,r0,r3
	simd::store_shuffled(ctx.v13, simd::load_and_shuffle(base + ((ctx.r3.u32) & ~0xF), VectorMaskL));
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// vmsum3fp128 v12,v0,v13
	ctx.fpscr.enableFlushMode();
	simd::store_f32_aligned(ctx.v12.f32, simd::dp_f32(simd::load_f32_aligned(ctx.v0.f32), simd::load_f32_aligned(ctx.v13.f32), 0xEF));
	// addi r8,r10,-17760
	ctx.r8.s64 = ctx.r10.s64 + -17760;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// lfs f13,-17760(r10)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -17760);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-1472(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -1472);
	f0.f64 = double(temp.f32);
	// stvx128 v12,r0,r9
	ea = (ctx.r9.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v12), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f11,f31,f0,f12
	ctx.f11.f64 = double(std::fma(float(f31.f64), float(f0.f64), float(ctx.f12.f64)));
	// fmuls f10,f11,f13
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fdivs f9,f10,f31
	ctx.f9.f64 = double(float(ctx.f10.f64 / f31.f64));
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r7
	temp.u32 = r0.u32 + ctx.r7.u32;
	simd::store_shuffled(ctx.v11,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vspltw v10,v11,0
	simd::store_i32(ctx.v10.u32, simd::broadcast_lane_i32(simd::load_i32(ctx.v11.u32), 3));
	// vmulfp128 v9,v0,v10
	ctx.fpscr.enableFlushModeUnconditional();
	simd::store_f32_aligned(ctx.v9.f32, simd::mul_f32(simd::load_f32_aligned(ctx.v0.f32), simd::load_f32_aligned(ctx.v10.f32)));
	// stvx128 v9,r0,r30
	ea = (r30.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v9), &VectorMaskL[(ea & 0xF) * 16]);
loc_8258B40C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// lfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258B2A0) {
	__imp__sub_8258B2A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258B428) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// ld r11,44(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 44);
	// lis r8,-32246
	ctx.r8.s64 = -2113273856;
	// addi r7,r1,-16
	ctx.r7.s64 = ctx.r1.s64 + -16;
	// addi r6,r1,-8
	ctx.r6.s64 = ctx.r1.s64 + -8;
	// addi r10,r1,-8
	ctx.r10.s64 = ctx.r1.s64 + -8;
	// addi r9,r1,-16
	ctx.r9.s64 = ctx.r1.s64 + -16;
	// std r11,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r11.u64);
	// lfs f0,-27468(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -27468);
	f0.f64 = double(temp.f32);
	// lfs f13,-4(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,-16(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -16, temp.u32);
	// lvlx v0,0,r7
	temp.u32 = r0.u32 + ctx.r7.u32;
	simd::store_shuffled(ctx.v0,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// lfs f12,-8(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,-8(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -8, temp.u32);
	// lvlx v13,0,r6
	temp.u32 = r0.u32 + ctx.r6.u32;
	simd::store_shuffled(ctx.v13,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vrlimi128 v13,v0,4,3
	simd::store_f32(ctx.v13.f32, simd::blend_f32<4>(simd::load_f32(ctx.v13.f32), simd::permute_f32<57>(simd::load_f32(ctx.v0.f32))));
	// stfs f13,-8(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -8, temp.u32);
	// stfs f12,-16(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -16, temp.u32);
	// lvlx v12,0,r10
	temp.u32 = r0.u32 + ctx.r10.u32;
	simd::store_shuffled(ctx.v12,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// lvlx v11,0,r9
	temp.u32 = r0.u32 + ctx.r9.u32;
	simd::store_shuffled(ctx.v11,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vrlimi128 v11,v12,4,3
	simd::store_f32(ctx.v11.f32, simd::blend_f32<4>(simd::load_f32(ctx.v11.f32), simd::permute_f32<57>(simd::load_f32(ctx.v12.f32))));
	// vrlimi128 v11,v13,3,2
	simd::store_f32(ctx.v11.f32, simd::blend_f32<3>(simd::load_f32(ctx.v11.f32), simd::permute_f32<78>(simd::load_f32(ctx.v13.f32))));
	// stvx128 v11,r0,r4
	ea = (ctx.r4.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v11), &VectorMaskL[(ea & 0xF) * 16]);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258B428) {
	__imp__sub_8258B428(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258B488) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(8) );
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r4,4
	ctx.r3.s64 = ctx.r4.s64 + 4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b4c4
	if (cr6.eq) goto loc_8258B4C4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258b4c0
	if (cr6.eq) goto loc_8258B4C0;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8258b4c8
	goto loc_8258B4C8;
loc_8258B4C0:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8258B4C4:
	// li r11,0
	r11.s64 = 0;
loc_8258B4C8:
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(68) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// ld r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// ld r4,8(r9)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// bl 0x821f5a28
	sub_821F5A28(ctx, base);
	// stvx128 v1,r0,r31
	ea = (r31.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v1), &VectorMaskL[(ea & 0xF) * 16]);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258B488) {
	__imp__sub_8258B488(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258B510) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCVRegister v127{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// li r12,-48
	r12.s64 = -48;
	// stvx128 v127,r1,r12
	ea = (ctx.r1.u32 + r12.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(v127), &VectorMaskL[(ea & 0xF) * 16]);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b55c
	if (cr6.eq) goto loc_8258B55C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258b558
	if (cr6.eq) goto loc_8258B558;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x8258b560
	goto loc_8258B560;
loc_8258B558:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8258B55C:
	// li r11,0
	r11.s64 = 0;
loc_8258B560:
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(68) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// ld r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// ld r4,8(r9)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// bl 0x821f5a28
	sub_821F5A28(ctx, base);
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lvx128 v0,r0,r30
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r30.u32) & ~0xF), VectorMaskL));
	// vor128 v127,v1,v1
	simd::store_i8(v127.u8, simd::load_i8(ctx.v1.u8));
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// vor v1,v0,v0
	simd::store_i8(ctx.v1.u8, simd::load_i8(ctx.v0.u8));
	// lwz r7,44(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(44) );
	// mtctr r7
	ctr.u64 = ctx.r7.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stfs f1,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v13,0,r6
	temp.u32 = r0.u32 + ctx.r6.u32;
	simd::store_shuffled(ctx.v13,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vspltw v12,v13,0
	simd::store_i32(ctx.v12.u32, simd::broadcast_lane_i32(simd::load_i32(ctx.v13.u32), 3));
	// vmulfp128 v11,v127,v12
	ctx.fpscr.enableFlushModeUnconditional();
	simd::store_f32_aligned(ctx.v11.f32, simd::mul_f32(simd::load_f32_aligned(v127.f32), simd::load_f32_aligned(ctx.v12.f32)));
	// stvx128 v11,r0,r30
	ea = (r30.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v11), &VectorMaskL[(ea & 0xF) * 16]);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// li r0,-48
	r0.s64 = -48;
	// lvx128 v127,r1,r0
	simd::store_shuffled(v127, simd::load_and_shuffle(base + ((ctx.r1.u32 + r0.u32) & ~0xF), VectorMaskL));
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258B510) {
	__imp__sub_8258B510(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258B5E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x82585de8
	sub_82585DE8(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(8) );
	// addi r31,r30,4
	r31.s64 = r30.s64 + 4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b640
	if (cr6.eq) goto loc_8258B640;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258b698
	if (cr6.eq) goto loc_8258B698;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b640
	if (cr6.eq) goto loc_8258B640;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258b644
	if (!cr6.eq) goto loc_8258B644;
loc_8258B640:
	// li r11,0
	r11.s64 = 0;
loc_8258B644:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b7a0
	if (cr6.eq) goto loc_8258B7A0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r31,0
	r31.s64 = 0;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,11,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 11) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258b76c
	if (cr6.eq) goto loc_8258B76C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b6a4
	if (cr6.eq) goto loc_8258B6A4;
	// lbz r10,21(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 21);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258b770
	goto loc_8258B770;
loc_8258B698:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8258b640
	goto loc_8258B640;
loc_8258B6A4:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// li r11,0
	r11.s64 = 0;
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258b714
	if (!cr0.gt) goto loc_8258B714;
loc_8258B6C4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,21
	cr6.compare<int32_t>(ctx.r7.s32, 21, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258b6e4
	if (cr6.lt) goto loc_8258B6E4;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8258B6E4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258b700
	if (cr6.eq) goto loc_8258B700;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258b708
	goto loc_8258B708;
loc_8258B700:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258B708:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258b6c4
	if (cr6.gt) goto loc_8258B6C4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258B714:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258b758
	if (cr6.eq) goto loc_8258B758;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258b730
	if (cr6.gt) goto loc_8258B730;
	// li r11,0
	r11.s64 = 0;
loc_8258B730:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258b758
	if (!cr6.eq) goto loc_8258B758;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258b770
	goto loc_8258B770;
loc_8258B758:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258b770
	goto loc_8258B770;
loc_8258B76C:
	// li r11,0
	r11.s64 = 0;
loc_8258B770:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b7a0
	if (cr6.eq) goto loc_8258B7A0;
	// li r4,18
	ctx.r4.s64 = 18;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821ff4e0
	sub_821FF4E0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258b7a0
	if (!cr6.eq) goto loc_8258B7A0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,44(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(44) );
	// bl 0x823f2240
	sub_823F2240(ctx, base);
loc_8258B7A0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258B5E0) {
	__imp__sub_8258B5E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258B7B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82585e50
	sub_82585E50(ctx, base);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b814
	if (cr6.eq) goto loc_8258B814;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258b86c
	if (cr6.eq) goto loc_8258B86C;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b814
	if (cr6.eq) goto loc_8258B814;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258b818
	if (!cr6.eq) goto loc_8258B818;
loc_8258B814:
	// li r11,0
	r11.s64 = 0;
loc_8258B818:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b974
	if (cr6.eq) goto loc_8258B974;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r31,0
	r31.s64 = 0;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,11,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 11) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258b940
	if (cr6.eq) goto loc_8258B940;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b878
	if (cr6.eq) goto loc_8258B878;
	// lbz r10,21(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 21);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258b944
	goto loc_8258B944;
loc_8258B86C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8258b814
	goto loc_8258B814;
loc_8258B878:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// li r11,0
	r11.s64 = 0;
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258b8e8
	if (!cr0.gt) goto loc_8258B8E8;
loc_8258B898:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,21
	cr6.compare<int32_t>(ctx.r7.s32, 21, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258b8b8
	if (cr6.lt) goto loc_8258B8B8;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8258B8B8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258b8d4
	if (cr6.eq) goto loc_8258B8D4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258b8dc
	goto loc_8258B8DC;
loc_8258B8D4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258B8DC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258b898
	if (cr6.gt) goto loc_8258B898;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258B8E8:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258b92c
	if (cr6.eq) goto loc_8258B92C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258b904
	if (cr6.gt) goto loc_8258B904;
	// li r11,0
	r11.s64 = 0;
loc_8258B904:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258b92c
	if (!cr6.eq) goto loc_8258B92C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258b944
	goto loc_8258B944;
loc_8258B92C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258b944
	goto loc_8258B944;
loc_8258B940:
	// li r11,0
	r11.s64 = 0;
loc_8258B944:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b974
	if (cr6.eq) goto loc_8258B974;
	// li r4,18
	ctx.r4.s64 = 18;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821ff4e0
	sub_821FF4E0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b974
	if (cr6.eq) goto loc_8258B974;
	// li r4,18
	ctx.r4.s64 = 18;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f27a8
	sub_823F27A8(ctx, base);
loc_8258B974:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258B7B8) {
	__imp__sub_8258B7B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258B988) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// addi r31,r29,4
	r31.s64 = r29.s64 + 4;
	// li r28,3
	r28.s64 = 3;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(8) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b9e4
	if (cr6.eq) goto loc_8258B9E4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258ba38
	if (cr6.eq) goto loc_8258BA38;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258b9e4
	if (cr6.eq) goto loc_8258B9E4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258b9e8
	if (!cr6.eq) goto loc_8258B9E8;
loc_8258B9E4:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258B9E8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258bb54
	if (cr6.eq) goto loc_8258BB54;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258bb08
	if (cr6.eq) goto loc_8258BB08;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ba44
	if (cr6.eq) goto loc_8258BA44;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258bb0c
	goto loc_8258BB0C;
loc_8258BA38:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8258b9e4
	goto loc_8258B9E4;
loc_8258BA44:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258bab0
	if (!cr0.gt) goto loc_8258BAB0;
loc_8258BA60:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258ba80
	if (cr6.lt) goto loc_8258BA80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_8258BA80:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258ba9c
	if (cr6.eq) goto loc_8258BA9C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258baa4
	goto loc_8258BAA4;
loc_8258BA9C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258BAA4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258ba60
	if (cr6.gt) goto loc_8258BA60;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258BAB0:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258baf4
	if (cr6.eq) goto loc_8258BAF4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258bacc
	if (cr6.gt) goto loc_8258BACC;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258BACC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258baf4
	if (!cr6.eq) goto loc_8258BAF4;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258bb0c
	goto loc_8258BB0C;
loc_8258BAF4:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258bb0c
	goto loc_8258BB0C;
loc_8258BB08:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258BB0C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258bb54
	if (cr6.eq) goto loc_8258BB54;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,2028
	ctx.r4.s64 = r11.s64 + 2028;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lfs f1,-17912(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -17912);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x823c1e08
	sub_823C1E08(ctx, base);
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.u64 = uint64_t(int32_t(std::trunc(ctx.f1.f64)));
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r28,92(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_8258BB54:
	// lis r11,-31950
	r11.s64 = -2093875200;
	// lwz r10,24(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + int32_t(24) );
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,-27380(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(-27380) );
	// subf r9,r10,r11
	ctx.r9.s64 = r11.s64 - ctx.r10.s64;
	// cmpw cr6,r9,r28
	cr6.compare<int32_t>(ctx.r9.s32, r28.s32, xer);
	// ble cr6,0x8258bb74
	if (!cr6.gt) goto loc_8258BB74;
	// li r3,0
	ctx.r3.s64 = 0;
loc_8258BB74:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8258B988) {
	__imp__sub_8258B988(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258BB80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,1
	r11.s64 = 1;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stb r11,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r11.u8);
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(124) );
	// bl 0x825bb2c0
	sub_825BB2C0(ctx, base);
	// lis r8,-31950
	ctx.r8.s64 = -2093875200;
	// lwz r11,-27380(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(-27380) );
	// addi r30,r31,4
	r30.s64 = r31.s64 + 4;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258bc08
	if (cr6.eq) goto loc_8258BC08;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258bc5c
	if (cr6.eq) goto loc_8258BC5C;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258bc08
	if (cr6.eq) goto loc_8258BC08;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258bc0c
	if (!cr6.eq) goto loc_8258BC0C;
loc_8258BC08:
	// li r11,0
	r11.s64 = 0;
loc_8258BC0C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258bd8c
	if (cr6.eq) goto loc_8258BD8C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,11,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 11) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258bd30
	if (cr6.eq) goto loc_8258BD30;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258bc68
	if (cr6.eq) goto loc_8258BC68;
	// lbz r10,21(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 21);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258bd38
	goto loc_8258BD38;
loc_8258BC5C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8258bc08
	goto loc_8258BC08;
loc_8258BC68:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// li r11,0
	r11.s64 = 0;
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258bcd8
	if (!cr0.gt) goto loc_8258BCD8;
loc_8258BC88:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,21
	cr6.compare<int32_t>(ctx.r7.s32, 21, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258bca8
	if (cr6.lt) goto loc_8258BCA8;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8258BCA8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258bcc4
	if (cr6.eq) goto loc_8258BCC4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258bccc
	goto loc_8258BCCC;
loc_8258BCC4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258BCCC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258bc88
	if (cr6.gt) goto loc_8258BC88;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258BCD8:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258bd1c
	if (cr6.eq) goto loc_8258BD1C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258bcf4
	if (cr6.gt) goto loc_8258BCF4;
	// li r11,0
	r11.s64 = 0;
loc_8258BCF4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258bd1c
	if (!cr6.eq) goto loc_8258BD1C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258bd38
	goto loc_8258BD38;
loc_8258BD1C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258bd38
	goto loc_8258BD38;
loc_8258BD30:
	// lwz r31,80(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// li r11,0
	r11.s64 = 0;
loc_8258BD38:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258bd8c
	if (cr6.eq) goto loc_8258BD8C;
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821ff4e0
	sub_821FF4E0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258bd8c
	if (!cr6.eq) goto loc_8258BD8C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,3224
	ctx.r4.s64 = r11.s64 + 3224;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// lis r5,-32768
	ctx.r5.s64 = -2147483648;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f21a0
	sub_823F21A0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_8258BD8C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258BB80) {
	__imp__sub_8258BB80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258BDA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stfd f30,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f30.u64);
	// stfd f31,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r29,r31,4
	r29.s64 = r31.s64 + 4;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82584ea0
	sub_82584EA0(ctx, base);
	// lbz r11,20(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c1e0
	if (cr6.eq) goto loc_8258C1E0;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(4) );
	// li r31,0
	r31.s64 = 0;
	// mr r30,r31
	r30.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258be20
	if (cr6.eq) goto loc_8258BE20;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258be74
	if (cr6.eq) goto loc_8258BE74;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258be20
	if (cr6.eq) goto loc_8258BE20;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258be24
	if (!cr6.eq) goto loc_8258BE24;
loc_8258BE20:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258BE24:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c1e0
	if (cr6.eq) goto loc_8258C1E0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,9,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 9) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258bf44
	if (cr6.eq) goto loc_8258BF44;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258be80
	if (cr6.eq) goto loc_8258BE80;
	// lbz r10,119(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 119);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258bf48
	goto loc_8258BF48;
loc_8258BE74:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8258be20
	goto loc_8258BE20;
loc_8258BE80:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258beec
	if (!cr0.gt) goto loc_8258BEEC;
loc_8258BE9C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,119
	cr6.compare<int32_t>(ctx.r7.s32, 119, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258bebc
	if (cr6.lt) goto loc_8258BEBC;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258BEBC:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258bed8
	if (cr6.eq) goto loc_8258BED8;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258bee0
	goto loc_8258BEE0;
loc_8258BED8:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258BEE0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258be9c
	if (cr6.gt) goto loc_8258BE9C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258BEEC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258bf30
	if (cr6.eq) goto loc_8258BF30;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,119
	cr6.compare<int32_t>(r11.s32, 119, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258bf08
	if (cr6.gt) goto loc_8258BF08;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258BF08:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258bf30
	if (!cr6.eq) goto loc_8258BF30;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258bf48
	goto loc_8258BF48;
loc_8258BF30:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258bf48
	goto loc_8258BF48;
loc_8258BF44:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258BF48:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c1e0
	if (cr6.eq) goto loc_8258C1E0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lfs f30,120(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 120);
	f30.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r30,r31
	r30.u64 = r31.u64;
	// lfs f31,-9652(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -9652);
	f31.f64 = double(temp.f32);
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r9,r10,31,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258c06c
	if (cr6.eq) goto loc_8258C06C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258bfa8
	if (cr6.eq) goto loc_8258BFA8;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c070
	goto loc_8258C070;
loc_8258BFA8:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258c014
	if (!cr0.gt) goto loc_8258C014;
loc_8258BFC4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258bfe4
	if (cr6.lt) goto loc_8258BFE4;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258BFE4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258c000
	if (cr6.eq) goto loc_8258C000;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258c008
	goto loc_8258C008;
loc_8258C000:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258C008:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258bfc4
	if (cr6.gt) goto loc_8258BFC4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258C014:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258c058
	if (cr6.eq) goto loc_8258C058;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258c030
	if (cr6.gt) goto loc_8258C030;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258C030:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258c058
	if (!cr6.eq) goto loc_8258C058;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c070
	goto loc_8258C070;
loc_8258C058:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c070
	goto loc_8258C070;
loc_8258C06C:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258C070:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c0ac
	if (cr6.eq) goto loc_8258C0AC;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,2056
	ctx.r4.s64 = r11.s64 + 2056;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x823c1e08
	sub_823C1E08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_8258C0AC:
	// fcmpu cr6,f30,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f31.f64);
	// ble cr6,0x8258c1e0
	if (!cr6.gt) goto loc_8258C1E0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258c1b8
	if (cr6.eq) goto loc_8258C1B8;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c0f8
	if (cr6.eq) goto loc_8258C0F8;
	// lbz r11,33(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c1bc
	goto loc_8258C1BC;
loc_8258C0F8:
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258c160
	if (!cr0.gt) goto loc_8258C160;
loc_8258C110:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258c130
	if (cr6.lt) goto loc_8258C130;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258C130:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258c14c
	if (cr6.eq) goto loc_8258C14C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258c154
	goto loc_8258C154;
loc_8258C14C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258C154:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258c110
	if (cr6.gt) goto loc_8258C110;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258C160:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258c1a4
	if (cr6.eq) goto loc_8258C1A4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258c17c
	if (cr6.gt) goto loc_8258C17C;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258C17C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258c1a4
	if (!cr6.eq) goto loc_8258C1A4;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c1bc
	goto loc_8258C1BC;
loc_8258C1A4:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c1bc
	goto loc_8258C1BC;
loc_8258C1B8:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258C1BC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c1e0
	if (cr6.eq) goto loc_8258C1E0;
	// li r4,14
	ctx.r4.s64 = 14;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823c88f0
	sub_823C88F0(ctx, base);
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823c86c0
	sub_823C86C0(ctx, base);
loc_8258C1E0:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f30,-48(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8258BDA8) {
	__imp__sub_8258BDA8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258C1F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stb r30,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r30.u8);
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(124) );
	// bl 0x825bb370
	sub_825BB370(ctx, base);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c26c
	if (cr6.eq) goto loc_8258C26C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258c2c0
	if (cr6.eq) goto loc_8258C2C0;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c26c
	if (cr6.eq) goto loc_8258C26C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258c270
	if (!cr6.eq) goto loc_8258C270;
loc_8258C26C:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258C270:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c3c8
	if (cr6.eq) goto loc_8258C3C8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,11,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 11) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258c390
	if (cr6.eq) goto loc_8258C390;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c2cc
	if (cr6.eq) goto loc_8258C2CC;
	// lbz r10,21(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 21);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c398
	goto loc_8258C398;
loc_8258C2C0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8258c26c
	goto loc_8258C26C;
loc_8258C2CC:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258c338
	if (!cr0.gt) goto loc_8258C338;
loc_8258C2E8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,21
	cr6.compare<int32_t>(ctx.r7.s32, 21, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258c308
	if (cr6.lt) goto loc_8258C308;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_8258C308:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258c324
	if (cr6.eq) goto loc_8258C324;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258c32c
	goto loc_8258C32C;
loc_8258C324:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258C32C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258c2e8
	if (cr6.gt) goto loc_8258C2E8;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258C338:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258c37c
	if (cr6.eq) goto loc_8258C37C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258c354
	if (cr6.gt) goto loc_8258C354;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258C354:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258c37c
	if (!cr6.eq) goto loc_8258C37C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c398
	goto loc_8258C398;
loc_8258C37C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c398
	goto loc_8258C398;
loc_8258C390:
	// lwz r31,80(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258C398:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c3c8
	if (cr6.eq) goto loc_8258C3C8;
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821ff4e0
	sub_821FF4E0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c3c8
	if (cr6.eq) goto loc_8258C3C8;
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f27a8
	sub_823F27A8(ctx, base);
loc_8258C3C8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258C1F0) {
	__imp__sub_8258C1F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258C3E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// li r11,0
	r11.s64 = 0;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// stb r11,16(r3)
	PPC_STORE_U8(ctx.r3.u32 + 16, r11.u8);
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(124) );
	// b 0x825bb370
	sub_825BB370(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_8258C3E0) {
	__imp__sub_8258C3E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258C400) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,1
	r11.s64 = 1;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stb r11,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r11.u8);
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(124) );
	// bl 0x825bb2c0
	sub_825BB2C0(ctx, base);
	// lis r8,-31950
	ctx.r8.s64 = -2093875200;
	// lis r7,-31950
	ctx.r7.s64 = -2093875200;
	// lfd f0,-27376(r8)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + -27376);
	// li r6,20
	ctx.r6.s64 = 20;
	// lfd f13,-27448(r7)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r7.u32 + -27448);
	// fmul f0,f0,f13
	f0.f64 = f0.f64 * ctx.f13.f64;
	// fctidz f13,f0
	ctx.f13.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfiwx f13,r31,r6
	PPC_STORE_U32(r31.u32 + ctx.r6.u32, ctx.f13.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258C400) {
	__imp__sub_8258C400(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258C468) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(20) );
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// bne 0x8258c5ac
	if (!cr0.eq) goto loc_8258C5AC;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// li r31,0
	r31.s64 = 0;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258c590
	if (cr6.eq) goto loc_8258C590;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c4d0
	if (cr6.eq) goto loc_8258C4D0;
	// lbz r11,33(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c594
	goto loc_8258C594;
loc_8258C4D0:
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258c538
	if (!cr0.gt) goto loc_8258C538;
loc_8258C4E8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258c508
	if (cr6.lt) goto loc_8258C508;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258C508:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258c524
	if (cr6.eq) goto loc_8258C524;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258c52c
	goto loc_8258C52C;
loc_8258C524:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258C52C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258c4e8
	if (cr6.gt) goto loc_8258C4E8;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258C538:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258c57c
	if (cr6.eq) goto loc_8258C57C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258c554
	if (cr6.gt) goto loc_8258C554;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258C554:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258c57c
	if (!cr6.eq) goto loc_8258C57C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c594
	goto loc_8258C594;
loc_8258C57C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258c594
	goto loc_8258C594;
loc_8258C590:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258C594:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c5ac
	if (cr6.eq) goto loc_8258C5AC;
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(20) );
	// bl 0x8238f4a0
	sub_8238F4A0(ctx, base);
loc_8258C5AC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258C468) {
	__imp__sub_8258C468(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258C5C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// blt cr6,0x8258c5ec
	if (cr6.lt) goto loc_8258C5EC;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(4) );
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// bge cr6,0x8258c5f8
	if (!cr6.lt) goto loc_8258C5F8;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bge cr6,0x8258c60c
	if (!cr6.lt) goto loc_8258C60C;
loc_8258C5EC:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(4) );
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// bgt cr6,0x8258c60c
	if (cr6.gt) goto loc_8258C60C;
loc_8258C5F8:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
loc_8258C60C:
	// lwz r6,4(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(4) );
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// bge cr6,0x8258c624
	if (!cr6.lt) goto loc_8258C624;
	// li r11,-1
	r11.s64 = -1;
loc_8258C624:
	// srawi r9,r10,31
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFFFFFF) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 31;
	// xor r7,r10,r9
	ctx.r7.u64 = ctx.r10.u64 ^ ctx.r9.u64;
	// subf r5,r9,r7
	ctx.r5.s64 = ctx.r7.s64 - ctx.r9.s64;
	// cmpwi cr6,r5,10
	cr6.compare<int32_t>(ctx.r5.s32, 10, xer);
	// blt cr6,0x8258c674
	if (cr6.lt) goto loc_8258C674;
	// li r7,10
	ctx.r7.s64 = 10;
loc_8258C63C:
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// divw r10,r10,r7
	ctx.r10.s32 = ctx.r10.s32 / ctx.r7.s32;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// li r11,9
	r11.s64 = 9;
	// bge cr6,0x8258c65c
	if (!cr6.lt) goto loc_8258C65C;
	// li r11,-9
	r11.s64 = -9;
loc_8258C65C:
	// srawi r5,r10,31
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFFFFFF) != 0);
	ctx.r5.s64 = ctx.r10.s32 >> 31;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// xor r4,r10,r5
	ctx.r4.u64 = ctx.r10.u64 ^ ctx.r5.u64;
	// subf r9,r5,r4
	ctx.r9.s64 = ctx.r4.s64 - ctx.r5.s64;
	// cmpwi cr6,r9,10
	cr6.compare<int32_t>(ctx.r9.s32, 10, xer);
	// bge cr6,0x8258c63c
	if (!cr6.lt) goto loc_8258C63C;
loc_8258C674:
	// add r11,r6,r11
	r11.u64 = ctx.r6.u64 + r11.u64;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// blt cr6,0x8258c698
	if (cr6.lt) goto loc_8258C698;
	// subf r10,r11,r8
	ctx.r10.s64 = ctx.r8.s64 - r11.s64;
	// srawi r9,r10,31
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFFFFFF) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 31;
	// and r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ctx.r10.u64;
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + r11.u64;
	// b 0x8258c6a8
	goto loc_8258C6A8;
loc_8258C698:
	// subf r10,r8,r11
	ctx.r10.s64 = r11.s64 - ctx.r8.s64;
	// srawi r9,r10,31
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFFFFFF) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 31;
	// and r8,r9,r10
	ctx.r8.u64 = ctx.r9.u64 & ctx.r10.u64;
	// subf r4,r8,r11
	ctx.r4.s64 = r11.s64 - ctx.r8.s64;
loc_8258C6A8:
	// stw r4,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r4.u32);
	// bl 0x8258c6c8
	sub_8258C6C8(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258C5C0) {
	__imp__sub_8258C5C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258C6C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82331308
	sub_82331308(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258c6f8
	if (!cr6.eq) goto loc_8258C6F8;
	// mr r11,r28
	r11.u64 = r28.u64;
	// b 0x8258c6fc
	goto loc_8258C6FC;
loc_8258C6F8:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_8258C6FC:
	// neg. r31,r11
	r31.s64 = -r11.s64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// addi r29,r11,28344
	r29.s64 = r11.s64 + 28344;
	// ble 0x8258c770
	if (!cr0.gt) goto loc_8258C770;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r30,r11,-10856
	r30.s64 = r11.s64 + -10856;
loc_8258C714:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821ec668
	sub_821EC668(ctx, base);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_8258C748:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x8258c748
	if (!cr0.eq) goto loc_8258C748;
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
	// bne 0x8258c714
	if (!cr0.eq) goto loc_8258C714;
loc_8258C770:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82b39978
	sub_82B39978(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c7ac
	if (cr6.eq) goto loc_8258C7AC;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// bgt cr6,0x8258c7b0
	if (cr6.gt) goto loc_8258C7B0;
loc_8258C7AC:
	// twi 31,r0,22
loc_8258C7B0:
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r4,12(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(12) );
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(24) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// addi r8,r11,28340
	ctx.r8.s64 = r11.s64 + 28340;
loc_8258C7D0:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8258c7d0
	if (!cr0.eq) goto loc_8258C7D0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
loc_8258C7F4:
	// mfmsr r6
	// mtmsrd r13,1
	// lwarx r7,0,r29
	reserved.u32 = *(uint32_t*)(base + r29.u32);
	ctx.r7.u64 = __builtin_bswap32(reserved.u32);
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
	// stwcx. r7,0,r29
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + r29.u32), reserved.s32, __builtin_bswap32(ctx.r7.s32));
	cr0.so = xer.so;
	// mtmsrd r6,1
	// bne 0x8258c7f4
	if (!cr0.eq) goto loc_8258C7F4;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8258C6C8) {
	__imp__sub_8258C6C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258C818) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r31,0
	r31.s64 = 0;
	// addi r10,r11,2516
	ctx.r10.s64 = r11.s64 + 2516;
	// lis r5,-32484
	ctx.r5.s64 = -2128871424;
	// stw r31,4(r21)
	PPC_STORE_U32(r21.u32 + 4, r31.u32);
	// lis r9,-31927
	ctx.r9.s64 = -2092367872;
	// stw r31,12(r21)
	PPC_STORE_U32(r21.u32 + 12, r31.u32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// stw r31,16(r21)
	PPC_STORE_U32(r21.u32 + 16, r31.u32);
	// lis r7,-31926
	ctx.r7.s64 = -2092302336;
	// stw r31,20(r21)
	PPC_STORE_U32(r21.u32 + 20, r31.u32);
	// lis r11,-31926
	r11.s64 = -2092302336;
	// stw r10,0(r21)
	PPC_STORE_U32(r21.u32 + 0, ctx.r10.u32);
	// lis r10,-32247
	ctx.r10.s64 = -2113339392;
	// stw r31,28(r21)
	PPC_STORE_U32(r21.u32 + 28, r31.u32);
	// addi r28,r21,24
	r28.s64 = r21.s64 + 24;
	// stw r31,32(r21)
	PPC_STORE_U32(r21.u32 + 32, r31.u32);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// stw r31,36(r21)
	PPC_STORE_U32(r21.u32 + 36, r31.u32);
	// ori r26,r5,40389
	r26.u64 = ctx.r5.u64 | 40389;
	// stb r31,40(r21)
	PPC_STORE_U8(r21.u32 + 40, r31.u8);
	// li r22,20
	r22.s64 = 20;
	// addi r20,r10,63
	r20.s64 = ctx.r10.s64 + 63;
	// addi r29,r9,28344
	r29.s64 = ctx.r9.s64 + 28344;
	// addi r25,r8,2864
	r25.s64 = ctx.r8.s64 + 2864;
	// addi r24,r7,-29852
	r24.s64 = ctx.r7.s64 + -29852;
	// addi r23,r11,-29856
	r23.s64 = r11.s64 + -29856;
loc_8258C894:
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// stw r31,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r31.u32);
loc_8258C89C:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x8258c89c
	if (!cr0.eq) goto loc_8258C89C;
	// addi r27,r6,1
	r27.s64 = ctx.r6.s64 + 1;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x821e3a10
	sub_821E3A10(ctx, base);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x821e2cc8
	sub_821E2CC8(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c8f0
	if (cr6.eq) goto loc_8258C8F0;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_8258C8F0:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x821f3c28
	sub_821F3C28(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_8258C908:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x8258c908
	if (!cr0.eq) goto loc_8258C908;
	// stw r31,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r31.u32);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x821e2cc8
	sub_821E2CC8(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258c94c
	if (cr6.eq) goto loc_8258C94C;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_8258C94C:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x821f3c28
	sub_821F3C28(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_8258C964:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x8258c964
	if (!cr0.eq) goto loc_8258C964;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(4) );
	// stw r30,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r30.u32);
	// stw r31,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r31.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stb r31,144(r1)
	PPC_STORE_U8(ctx.r1.u32 + 144, r31.u8);
	// stw r31,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r31.u32);
	// stw r31,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r31.u32);
	// stw r19,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r19.u32);
	// bne cr6,0x8258c9ac
	if (!cr6.eq) goto loc_8258C9AC;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// b 0x8258c9b8
	goto loc_8258C9B8;
loc_8258C9AC:
	// lwz r10,12(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + int32_t(12) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// divw r10,r9,r22
	ctx.r10.s32 = ctx.r9.s32 / r22.s32;
loc_8258C9B8:
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + int32_t(8) );
	// subf r11,r11,r9
	r11.s64 = ctx.r9.s64 - r11.s64;
	// divw r8,r11,r22
	ctx.r8.s32 = r11.s32 / r22.s32;
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// bge cr6,0x8258ca04
	if (!cr6.lt) goto loc_8258CA04;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258c9f8
	if (cr6.eq) goto loc_8258C9F8;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// li r8,5
	ctx.r8.s64 = 5;
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
loc_8258C9E4:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x8258c9e4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8258C9E4;
loc_8258C9F8:
	// addi r11,r9,20
	r11.s64 = ctx.r9.s64 + 20;
	// stw r11,8(r28)
	PPC_STORE_U32(r28.u32 + 8, r11.u32);
	// b 0x8258ca20
	goto loc_8258CA20;
loc_8258CA04:
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// stw r9,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r9.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r31,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r31.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// ld r4,128(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// bl 0x82a52b00
	sub_82A52B00(ctx, base);
loc_8258CA20:
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_8258CA2C:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x8258ca2c
	if (!cr0.eq) goto loc_8258CA2C;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// cmpwi cr6,r27,5
	cr6.compare<int32_t>(r27.s32, 5, xer);
	// blt cr6,0x8258c894
	if (cr6.lt) goto loc_8258C894;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// b 0x82ca2c14
	return;
}

PPC_WEAK_FUNC(sub_8258C818) {
	__imp__sub_8258C818(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258CA60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r31,r30,24
	r31.s64 = r30.s64 + 24;
	// lwz r3,28(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(28) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258ca88
	if (cr6.eq) goto loc_8258CA88;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_8258CA88:
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// li r11,0
	r11.s64 = 0;
	// addi r9,r10,23084
	ctx.r9.s64 = ctx.r10.s64 + 23084;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// addi r3,r30,8
	ctx.r3.s64 = r30.s64 + 8;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// stw r9,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r9.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// clrlwi r8,r29,31
	ctx.r8.u64 = r29.u32 & 0x1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x8258cac4
	if (cr6.eq) goto loc_8258CAC4;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8258CAC4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8258CA60) {
	__imp__sub_8258CA60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258CAD0) {
	PPC_FUNC_PROLOGUE();
	// b 0x8258ce48
	sub_8258CE48(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_8258CAD0) {
	__imp__sub_8258CAD0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258CAD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x82583560
	sub_82583560(ctx, base);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(32) );
	// lwz r31,28(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + int32_t(28) );
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x8258cb28
	if (cr6.eq) goto loc_8258CB28;
loc_8258CB04:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8258c5c0
	sub_8258C5C0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258cb28
	if (!cr6.eq) goto loc_8258CB28;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(32) );
	// addi r31,r31,20
	r31.s64 = r31.s64 + 20;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bne cr6,0x8258cb04
	if (!cr6.eq) goto loc_8258CB04;
loc_8258CB28:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258CAD8) {
	__imp__sub_8258CAD8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258CB40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,6
	cr6.compare<int32_t>(ctx.r4.s32, 6, xer);
	// bne cr6,0x8258cbdc
	if (!cr6.eq) goto loc_8258CBDC;
	// lwz r31,28(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + int32_t(28) );
	// li r30,0
	r30.s64 = 0;
	// lwz r11,32(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(32) );
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x8258cbc8
	if (cr6.eq) goto loc_8258CBC8;
loc_8258CB6C:
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmpw cr6,r11,r4
	cr6.compare<int32_t>(r11.s32, ctx.r4.s32, xer);
	// bge cr6,0x8258cb90
	if (!cr6.lt) goto loc_8258CB90;
	// stw r4,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r4.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8258c6c8
	sub_8258C6C8(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// b 0x8258cb94
	goto loc_8258CB94;
loc_8258CB90:
	// li r11,0
	r11.s64 = 0;
loc_8258CB94:
	// clrlwi r10,r30,24
	ctx.r10.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258cbb0
	if (!cr6.eq) goto loc_8258CBB0;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// beq cr6,0x8258cbb4
	if (cr6.eq) goto loc_8258CBB4;
loc_8258CBB0:
	// li r11,1
	r11.s64 = 1;
loc_8258CBB4:
	// lwz r10,32(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + int32_t(32) );
	// addi r31,r31,20
	r31.s64 = r31.s64 + 20;
	// clrlwi r30,r11,24
	r30.u64 = r11.u32 & 0xFF;
	// cmplw cr6,r31,r10
	cr6.compare<uint32_t>(r31.u32, ctx.r10.u32, xer);
	// bne cr6,0x8258cb6c
	if (!cr6.eq) goto loc_8258CB6C;
loc_8258CBC8:
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258cbdc
	if (!cr6.eq) goto loc_8258CBDC;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8258ce48
	sub_8258CE48(ctx, base);
loc_8258CBDC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8258CB40) {
	__imp__sub_8258CB40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258CBE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,1
	r11.s64 = 1;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// stb r11,40(r3)
	PPC_STORE_U8(ctx.r3.u32 + 40, r11.u8);
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r4,11
	ctx.r4.s64 = 11;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,56(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// bl 0x823fe6f0
	sub_823FE6F0(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r4,56(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(56) );
	// lwz r3,32(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(32) );
	// bl 0x827ce238
	sub_827CE238(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,11
	ctx.r4.s64 = 11;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336838
	sub_82336838(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336d70
	sub_82336D70(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r8,32(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258cc7c
	if (cr6.eq) goto loc_8258CC7C;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// bgt cr6,0x8258cc80
	if (cr6.gt) goto loc_8258CC80;
loc_8258CC7C:
	// twi 31,r0,22
loc_8258CC80:
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(24) );
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r4,-29864(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(-29864) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ccc0
	if (cr6.eq) goto loc_8258CCC0;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// bgt cr6,0x8258ccc4
	if (cr6.gt) goto loc_8258CCC4;
loc_8258CCC0:
	// twi 31,r0,22
loc_8258CCC4:
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(24) );
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,-29860(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(-29860) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8258CBE8) {
	__imp__sub_8258CBE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258CCF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,28(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(28) );
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// lwz r11,32(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(32) );
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// li r25,0
	r25.s64 = 0;
	// addi r27,r10,28340
	r27.s64 = ctx.r10.s64 + 28340;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x8258ce14
	if (cr6.eq) goto loc_8258CE14;
loc_8258CD20:
	// lbz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258cd3c
	if (cr6.eq) goto loc_8258CD3C;
	// addi r31,r31,20
	r31.s64 = r31.s64 + 20;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bne cr6,0x8258cd20
	if (!cr6.eq) goto loc_8258CD20;
	// b 0x8258ce14
	goto loc_8258CE14;
loc_8258CD3C:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82287710
	sub_82287710(ctx, base);
	// lis r30,-31927
	r30.s64 = -2092367872;
	// li r11,1
	r11.s64 = 1;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258cd84
	if (cr6.eq) goto loc_8258CD84;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,9
	cr6.compare<uint32_t>(ctx.r10.u32, 9, xer);
	// bgt cr6,0x8258cd88
	if (cr6.gt) goto loc_8258CD88;
loc_8258CD84:
	// twi 31,r0,22
loc_8258CD88:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(12) );
	// lwz r3,36(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// bl 0x8257b408
	sub_8257B408(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258cdc4
	if (cr6.eq) goto loc_8258CDC4;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// bgt cr6,0x8258cdc8
	if (cr6.gt) goto loc_8258CDC8;
loc_8258CDC4:
	// twi 31,r0,22
loc_8258CDC8:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(16) );
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(24) );
	// bl 0x8257c720
	sub_8257C720(ctx, base);
	// stw r26,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r26.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8258c6c8
	sub_8258C6C8(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
loc_8258CDF4:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r9
	reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r9
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x8258cdf4
	if (!cr0.eq) goto loc_8258CDF4;
	// stw r25,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r25.u32);
loc_8258CE14:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
loc_8258CE1C:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r27
	reserved.u32 = *(uint32_t*)(base + r27.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stwcx. r11,0,r27
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + r27.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x8258ce1c
	if (!cr0.eq) goto loc_8258CE1C;
	// stw r25,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r25.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_8258CCF0) {
	__imp__sub_8258CCF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258CE48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lbz r11,40(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258cf00
	if (cr6.eq) goto loc_8258CF00;
	// lwz r31,28(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + int32_t(28) );
	// li r30,0
	r30.s64 = 0;
	// lwz r11,32(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(32) );
	// lis r29,-31927
	r29.s64 = -2092367872;
	// stb r30,40(r28)
	PPC_STORE_U8(r28.u32 + 40, r30.u8);
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x8258ced8
	if (cr6.eq) goto loc_8258CED8;
loc_8258CE80:
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// stb r30,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r30.u8);
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ceb4
	if (cr6.eq) goto loc_8258CEB4;
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(32) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r10,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r10,9
	cr6.compare<uint32_t>(ctx.r10.u32, 9, xer);
	// bgt cr6,0x8258ceb8
	if (cr6.gt) goto loc_8258CEB8;
loc_8258CEB4:
	// twi 31,r0,22
loc_8258CEB8:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(12) );
	// lwz r3,36(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// bl 0x8257b408
	sub_8257B408(ctx, base);
	// lwz r11,32(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(32) );
	// addi r31,r31,20
	r31.s64 = r31.s64 + 20;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bne cr6,0x8258ce80
	if (!cr6.eq) goto loc_8258CE80;
loc_8258CED8:
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r4,56(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(56) );
	// lwz r3,32(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(32) );
	// bl 0x827ce400
	sub_827CE400(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336f98
	sub_82336F98(ctx, base);
loc_8258CF00:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8258CE48) {
	__imp__sub_8258CE48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258CF08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r8,-32246
	ctx.r8.s64 = -2113273856;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// li r10,-1
	ctx.r10.s64 = -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// lfs f0,-27468(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -27468);
	f0.f64 = double(temp.f32);
	// lis r7,-32245
	ctx.r7.s64 = -2113208320;
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stb r11,4(r31)
	PPC_STORE_U8(r31.u32 + 4, r11.u8);
	// lis r4,-32244
	ctx.r4.s64 = -2113142784;
	// stb r9,12(r31)
	PPC_STORE_U8(r31.u32 + 12, ctx.r9.u8);
	// lis r3,-32244
	ctx.r3.s64 = -2113142784;
	// stb r11,13(r31)
	PPC_STORE_U8(r31.u32 + 13, r11.u8);
	// addi r5,r7,-8392
	ctx.r5.s64 = ctx.r7.s64 + -8392;
	// stw r10,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r10.u32);
	// addi r7,r4,2996
	ctx.r7.s64 = ctx.r4.s64 + 2996;
	// stw r10,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r10.u32);
	// addi r4,r3,3024
	ctx.r4.s64 = ctx.r3.s64 + 3024;
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// stb r11,28(r31)
	PPC_STORE_U8(r31.u32 + 28, r11.u8);
	// li r8,1
	ctx.r8.s64 = 1;
	// stb r9,29(r31)
	PPC_STORE_U8(r31.u32 + 29, ctx.r9.u8);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stb r11,30(r31)
	PPC_STORE_U8(r31.u32 + 30, r11.u8);
	// addi r30,r31,32
	r30.s64 = r31.s64 + 32;
	// stb r11,31(r31)
	PPC_STORE_U8(r31.u32 + 31, r11.u8);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// stw r11,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r11.u32);
	// stw r11,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r11.u32);
	// bl 0x82590b38
	sub_82590B38(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590ba0
	sub_82590BA0(ctx, base);
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r8,-32244
	ctx.r8.s64 = -2113142784;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// addi r4,r8,3112
	ctx.r4.s64 = ctx.r8.s64 + 3112;
	// addi r7,r11,3056
	ctx.r7.s64 = r11.s64 + 3056;
	// addi r6,r10,3080
	ctx.r6.s64 = ctx.r10.s64 + 3080;
	// addi r5,r9,-8452
	ctx.r5.s64 = ctx.r9.s64 + -8452;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82590b38
	sub_82590B38(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590ba0
	sub_82590BA0(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r7,-32245
	ctx.r7.s64 = -2113208320;
	// lis r5,-32244
	ctx.r5.s64 = -2113142784;
	// addi r4,r7,-8420
	ctx.r4.s64 = ctx.r7.s64 + -8420;
	// lis r3,-32244
	ctx.r3.s64 = -2113142784;
	// addi r7,r5,3148
	ctx.r7.s64 = ctx.r5.s64 + 3148;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// addi r4,r3,3168
	ctx.r4.s64 = ctx.r3.s64 + 3168;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82590b38
	sub_82590B38(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590ba0
	sub_82590BA0(ctx, base);
	// addi r3,r1,156
	ctx.r3.s64 = ctx.r1.s64 + 156;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,148
	ctx.r3.s64 = ctx.r1.s64 + 148;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r5,r11,-8544
	ctx.r5.s64 = r11.s64 + -8544;
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r7,r10,3196
	ctx.r7.s64 = ctx.r10.s64 + 3196;
	// addi r4,r9,3220
	ctx.r4.s64 = ctx.r9.s64 + 3220;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// bl 0x82590b38
	sub_82590B38(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590ba0
	sub_82590BA0(ctx, base);
	// addi r3,r1,188
	ctx.r3.s64 = ctx.r1.s64 + 188;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,184
	ctx.r3.s64 = ctx.r1.s64 + 184;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,180
	ctx.r3.s64 = ctx.r1.s64 + 180;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r8,-32245
	ctx.r8.s64 = -2113208320;
	// lis r7,-32244
	ctx.r7.s64 = -2113142784;
	// addi r5,r8,-8484
	ctx.r5.s64 = ctx.r8.s64 + -8484;
	// lis r4,-32244
	ctx.r4.s64 = -2113142784;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r7,r7,3260
	ctx.r7.s64 = ctx.r7.s64 + 3260;
	// addi r4,r4,3280
	ctx.r4.s64 = ctx.r4.s64 + 3280;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x82590b38
	sub_82590B38(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590ba0
	sub_82590BA0(ctx, base);
	// addi r3,r1,220
	ctx.r3.s64 = ctx.r1.s64 + 220;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,216
	ctx.r3.s64 = ctx.r1.s64 + 216;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,212
	ctx.r3.s64 = ctx.r1.s64 + 212;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r3,-32245
	ctx.r3.s64 = -2113208320;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r5,r3,-8512
	ctx.r5.s64 = ctx.r3.s64 + -8512;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r7,r11,3320
	ctx.r7.s64 = r11.s64 + 3320;
	// addi r4,r10,3340
	ctx.r4.s64 = ctx.r10.s64 + 3340;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// bl 0x82590b38
	sub_82590B38(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590ba0
	sub_82590BA0(ctx, base);
	// addi r3,r1,252
	ctx.r3.s64 = ctx.r1.s64 + 252;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,248
	ctx.r3.s64 = ctx.r1.s64 + 248;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,244
	ctx.r3.s64 = ctx.r1.s64 + 244;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258CF08) {
	__imp__sub_8258CF08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258D1A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r27,-31927
	r27.s64 = -2092367872;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r29,0
	r29.s64 = 0;
	// li r28,1
	r28.s64 = 1;
	// lwz r10,26912(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26912) );
	// stw r4,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r4.u32);
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(12) );
	// lwz r9,88(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258d2a4
	if (cr6.eq) goto loc_8258D2A4;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258d29c
	if (cr6.eq) goto loc_8258D29C;
	// rotlwi r31,r9,0
	r31.u64 = rotl32(ctx.r9.u32, 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8258d210
	if (cr6.eq) goto loc_8258D210;
	// lbz r11,144(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 144);
	// rlwinm r9,r11,0,25,25
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// mr r11,r28
	r11.u64 = r28.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8258d214
	if (!cr6.eq) goto loc_8258D214;
loc_8258D210:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8258D214:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258d4a0
	if (cr6.eq) goto loc_8258D4A0;
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(12) );
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(88) );
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// bl 0x8235f3d8
	sub_8235F3D8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258d250
	if (cr6.eq) goto loc_8258D250;
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// mr r11,r28
	r11.u64 = r28.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258d254
	if (!cr6.eq) goto loc_8258D254;
loc_8258D250:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8258D254:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258d37c
	if (cr6.eq) goto loc_8258D37C;
	// lwz r10,48(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// mr r11,r29
	r11.u64 = r29.u64;
	// rlwinm r9,r10,31,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258d368
	if (cr6.eq) goto loc_8258D368;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258d2ac
	if (cr6.eq) goto loc_8258D2AC;
	// lbz r10,97(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 97);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8258d36c
	goto loc_8258D36C;
loc_8258D29C:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// lwz r10,26912(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26912) );
loc_8258D2A4:
	// mr r31,r29
	r31.u64 = r29.u64;
	// b 0x8258d210
	goto loc_8258D210;
loc_8258D2AC:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258d318
	if (!cr0.gt) goto loc_8258D318;
loc_8258D2C8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,97
	cr6.compare<int32_t>(ctx.r7.s32, 97, xer);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// blt cr6,0x8258d2e8
	if (cr6.lt) goto loc_8258D2E8;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_8258D2E8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258d304
	if (cr6.eq) goto loc_8258D304;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258d30c
	goto loc_8258D30C;
loc_8258D304:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258D30C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258d2c8
	if (cr6.gt) goto loc_8258D2C8;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258D318:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258d358
	if (cr6.eq) goto loc_8258D358;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,97
	cr6.compare<int32_t>(r11.s32, 97, xer);
	// mr r11,r28
	r11.u64 = r28.u64;
	// bgt cr6,0x8258d334
	if (cr6.gt) goto loc_8258D334;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8258D334:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258d358
	if (!cr6.eq) goto loc_8258D358;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258d36c
	goto loc_8258D36C;
loc_8258D358:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258d36c
	goto loc_8258D36C;
loc_8258D368:
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_8258D36C:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258d37c
	if (cr6.eq) goto loc_8258D37C;
	// stb r28,33(r11)
	PPC_STORE_U8(r11.u32 + 33, r28.u8);
loc_8258D37C:
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(48) );
	// mr r11,r29
	r11.u64 = r29.u64;
	// rlwinm r9,r10,6,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258d474
	if (cr6.eq) goto loc_8258D474;
	// lwz r11,140(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258d3b8
	if (cr6.eq) goto loc_8258D3B8;
	// lbz r10,122(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 122);
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8258d478
	goto loc_8258D478;
loc_8258D3B8:
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(72) );
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258d424
	if (!cr0.gt) goto loc_8258D424;
loc_8258D3D4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,122
	cr6.compare<int32_t>(ctx.r7.s32, 122, xer);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// blt cr6,0x8258d3f4
	if (cr6.lt) goto loc_8258D3F4;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_8258D3F4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258d410
	if (cr6.eq) goto loc_8258D410;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258d418
	goto loc_8258D418;
loc_8258D410:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258D418:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258d3d4
	if (cr6.gt) goto loc_8258D3D4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258D424:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258d464
	if (cr6.eq) goto loc_8258D464;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,122
	cr6.compare<int32_t>(r11.s32, 122, xer);
	// mr r11,r28
	r11.u64 = r28.u64;
	// bgt cr6,0x8258d440
	if (cr6.gt) goto loc_8258D440;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8258D440:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258d464
	if (!cr6.eq) goto loc_8258D464;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258d478
	goto loc_8258D478;
loc_8258D464:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258d478
	goto loc_8258D478;
loc_8258D474:
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_8258D478:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258d49c
	if (cr6.eq) goto loc_8258D49C;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x821c2c18
	sub_821C2C18(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bge cr6,0x8258d49c
	if (!cr6.lt) goto loc_8258D49C;
	// stb r28,31(r30)
	PPC_STORE_U8(r30.u32 + 31, r28.u8);
	// b 0x8258d4a0
	goto loc_8258D4A0;
loc_8258D49C:
	// stb r29,31(r30)
	PPC_STORE_U8(r30.u32 + 31, r29.u8);
loc_8258D4A0:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8258ff68
	sub_8258FF68(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8258d4c0
	if (!cr6.eq) goto loc_8258D4C0;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x8258d4cc
	goto loc_8258D4CC;
loc_8258D4C0:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8258d4e0
	if (!cr6.eq) goto loc_8258D4E0;
	// li r4,4
	ctx.r4.s64 = 4;
loc_8258D4CC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lfs f0,-8648(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -8648);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 8, temp.u32);
	// bl 0x8258fe70
	sub_8258FE70(ctx, base);
loc_8258D4E0:
	// li r11,-1
	r11.s64 = -1;
	// stw r28,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r28.u32);
	// stb r29,13(r30)
	PPC_STORE_U8(r30.u32 + 13, r29.u8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
	// bl 0x8258e938
	sub_8258E938(ctx, base);
	// addi r3,r30,48
	ctx.r3.s64 = r30.s64 + 48;
	// bl 0x82590c60
	sub_82590C60(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590080
	sub_82590080(ctx, base);
	// stb r28,30(r30)
	PPC_STORE_U8(r30.u32 + 30, r28.u8);
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590998
	sub_82590998(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,-30720
	ctx.r5.s64 = ctx.r10.s64 + -30720;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r4,26788(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// lwz r3,92(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258d558
	if (cr6.eq) goto loc_8258D558;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_8258D558:
	// lwz r11,26912(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26912) );
	// li r4,186
	ctx.r4.s64 = 186;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r29.u32);
	// stw r29,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r29.u32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r7,168(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(168) );
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x824fda50
	sub_824FDA50(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258d58c
	if (cr6.eq) goto loc_8258D58C;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x824fdaf8
	sub_824FDAF8(ctx, base);
loc_8258D58C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8258D1A0) {
	__imp__sub_8258D1A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258D598) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8258d784
	if (cr6.eq) goto loc_8258D784;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r4,1
	ctx.r4.s64 = 1;
	// lfs f0,-27456(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -27456);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 8, temp.u32);
	// bl 0x8258fe70
	sub_8258FE70(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x8258d5e8
	if (!cr6.eq) goto loc_8258D5E8;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8258ff68
	sub_8258FF68(ctx, base);
loc_8258D5E8:
	// li r31,0
	r31.s64 = 0;
	// addi r3,r30,48
	ctx.r3.s64 = r30.s64 + 48;
	// stw r31,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r31.u32);
	// bl 0x82590c60
	sub_82590C60(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590080
	sub_82590080(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r3,0(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// bl 0x8235f3d8
	sub_8235F3D8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258d63c
	if (cr6.eq) goto loc_8258D63C;
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258d640
	if (!cr6.eq) goto loc_8258D640;
loc_8258D63C:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258D640:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258d758
	if (cr6.eq) goto loc_8258D758;
	// lwz r10,48(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// mr r11,r31
	r11.u64 = r31.u64;
	// rlwinm r9,r10,31,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258d744
	if (cr6.eq) goto loc_8258D744;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258d688
	if (cr6.eq) goto loc_8258D688;
	// lbz r10,97(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 97);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8258d748
	goto loc_8258D748;
loc_8258D688:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258d6f4
	if (!cr0.gt) goto loc_8258D6F4;
loc_8258D6A4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,97
	cr6.compare<int32_t>(ctx.r7.s32, 97, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258d6c4
	if (cr6.lt) goto loc_8258D6C4;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258D6C4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258d6e0
	if (cr6.eq) goto loc_8258D6E0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258d6e8
	goto loc_8258D6E8;
loc_8258D6E0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258D6E8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258d6a4
	if (cr6.gt) goto loc_8258D6A4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258D6F4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258d734
	if (cr6.eq) goto loc_8258D734;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,97
	cr6.compare<int32_t>(r11.s32, 97, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258d710
	if (cr6.gt) goto loc_8258D710;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258D710:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258d734
	if (!cr6.eq) goto loc_8258D734;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258d748
	goto loc_8258D748;
loc_8258D734:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258d748
	goto loc_8258D748;
loc_8258D744:
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_8258D748:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258d758
	if (cr6.eq) goto loc_8258D758;
	// stb r31,33(r11)
	PPC_STORE_U8(r11.u32 + 33, r31.u8);
loc_8258D758:
	// li r11,-1
	r11.s64 = -1;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// stw r11,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r11.u32);
	// lis r9,-31926
	ctx.r9.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r9,-30716
	ctx.r5.s64 = ctx.r9.s64 + -30716;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,26788(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_8258D784:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258D598) {
	__imp__sub_8258D598(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258D7A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82ca74f8
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// std r4,232(r1)
	PPC_STORE_U64(ctx.r1.u32 + 232, ctx.r4.u64);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(0) );
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8258d95c
	if (!cr6.eq) goto loc_8258D95C;
	// lfs f0,232(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	f0.f64 = double(temp.f32);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// fmuls f11,f0,f0
	ctx.f11.f64 = double(float(f0.f64 * f0.f64));
	// lfs f13,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f13.f64 = double(temp.f32);
	// addi r30,r11,-27468
	r30.s64 = r11.s64 + -27468;
	// lfs f12,8604(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8604);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f10,f13,f13,f11
	ctx.f10.f64 = double(std::fma(float(ctx.f13.f64), float(ctx.f13.f64), float(ctx.f11.f64)));
	// fcmpu cr6,f10,f12
	cr6.compare(ctx.f10.f64, ctx.f12.f64);
	// blt cr6,0x8258d95c
	if (cr6.lt) goto loc_8258D95C;
	// fneg f13,f13
	ctx.f13.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lis r28,-32246
	r28.s64 = -2113273856;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f1,-25888(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + -25888);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x822a8ef8
	sub_822A8EF8(ctx, base);
	// lis r11,-32240
	r11.s64 = -2112880640;
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// lfs f31,18768(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 18768);
	f31.f64 = double(temp.f32);
	// lfs f28,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f28.f64 = double(temp.f32);
	// li r29,0
	r29.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// lfs f29,2252(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2252);
	f29.f64 = double(temp.f32);
	// lfs f30,360(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 360);
	f30.f64 = double(temp.f32);
	// lfs f27,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f27.f64 = double(temp.f32);
	// lfs f26,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f26.f64 = double(temp.f32);
loc_8258D830:
	// extsw r11,r31
	r11.s64 = r31.s32;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f0
	ctx.f13.f64 = double(f0.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// fnmsubs f25,f12,f30,f29
	f25.f64 = -double(std::fma(float(ctx.f12.f64), float(f30.f64), -float(f29.f64)));
	// fmr f1,f25
	ctx.f1.f64 = f25.f64;
	// bl 0x82239e88
	sub_82239E88(ctx, base);
	// frsp f24,f1
	ctx.fpscr.disableFlushMode();
	f24.f64 = double(float(ctx.f1.f64));
	// fmr f1,f25
	ctx.f1.f64 = f25.f64;
	// bl 0x82239f68
	sub_82239F68(ctx, base);
	// frsp f11,f1
	ctx.fpscr.disableFlushMode();
	ctx.f11.f64 = double(float(ctx.f1.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f24,84(r1)
	temp.f32 = float(f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f1,-25888(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + -25888);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x822a8ef8
	sub_822A8EF8(ctx, base);
	// lfs f10,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f9,f26,f10
	ctx.f9.f64 = static_cast<float>(f26.f64 - ctx.f10.f64);
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f7,f27,f8
	ctx.f7.f64 = static_cast<float>(f27.f64 - ctx.f8.f64);
	// fcmpu cr6,f31,f28
	cr6.compare(f31.f64, f28.f64);
	// fmuls f6,f9,f9
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f9.f64));
	// fmadds f5,f7,f7,f6
	ctx.f5.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f7.f64), float(ctx.f6.f64)));
	// fsqrts f0,f5
	f0.f64 = double(simd::sqrt_f32(float(ctx.f5.f64)));
	// blt cr6,0x8258d8a0
	if (cr6.lt) goto loc_8258D8A0;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x8258d8a8
	if (!cr6.lt) goto loc_8258D8A8;
loc_8258D8A0:
	// fmr f31,f0
	ctx.fpscr.disableFlushMode();
	f31.f64 = f0.f64;
	// mr r29,r31
	r29.u64 = r31.u64;
loc_8258D8A8:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmpwi cr6,r31,8
	cr6.compare<int32_t>(r31.s32, 8, xer);
	// blt cr6,0x8258d830
	if (cr6.lt) goto loc_8258D830;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8258e890
	sub_8258E890(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258d95c
	if (cr6.eq) goto loc_8258D95C;
	// lbz r11,13(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 13);
	// addi r31,r27,20
	r31.s64 = r27.s64 + 20;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258d8e0
	if (!cr6.eq) goto loc_8258D8E0;
	// addi r31,r27,16
	r31.s64 = r27.s64 + 16;
loc_8258D8E0:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmpw cr6,r29,r10
	cr6.compare<int32_t>(r29.s32, ctx.r10.s32, xer);
	// beq cr6,0x8258d950
	if (cr6.eq) goto loc_8258D950;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// rlwinm r5,r11,27,31,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82590478
	sub_82590478(ctx, base);
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x8258d928
	if (cr6.eq) goto loc_8258D928;
	// lbz r11,13(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 13);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r5,r10,27,31,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// bl 0x82590478
	sub_82590478(ctx, base);
loc_8258D928:
	// stw r29,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r29.u32);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,-30712
	ctx.r5.s64 = ctx.r10.s64 + -30712;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r4,26788(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_8258D950:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82590998
	sub_82590998(ctx, base);
loc_8258D95C:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82ca7544
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8258D7A0) {
	__imp__sub_8258D7A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258D970) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8258dc34
	if (!cr6.eq) goto loc_8258DC34;
	// lbz r11,13(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 13);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258d9cc
	if (cr6.eq) goto loc_8258D9CC;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(20) );
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8258dc34
	if (cr6.eq) goto loc_8258DC34;
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// bne cr6,0x8258d9c0
	if (!cr6.eq) goto loc_8258D9C0;
	// bl 0x8258dc50
	sub_8258DC50(ctx, base);
	// b 0x8258dc34
	goto loc_8258DC34;
loc_8258D9C0:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8258ded0
	sub_8258DED0(ctx, base);
	// b 0x8258dc20
	goto loc_8258DC20;
loc_8258D9CC:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(16) );
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8258dc34
	if (cr6.eq) goto loc_8258DC34;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x8258da84
	if (cr6.eq) goto loc_8258DA84;
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// beq cr6,0x8258dc20
	if (cr6.eq) goto loc_8258DC20;
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(36) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258da0c
	if (cr6.eq) goto loc_8258DA0C;
	// lwz r9,40(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(40) );
	// li r8,20
	ctx.r8.s64 = 20;
	// subf r7,r10,r9
	ctx.r7.s64 = ctx.r9.s64 - ctx.r10.s64;
	// divw r6,r7,r8
	ctx.r6.s32 = ctx.r7.s32 / ctx.r8.s32;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// blt cr6,0x8258da10
	if (cr6.lt) goto loc_8258DA10;
loc_8258DA0C:
	// twi 31,r0,22
loc_8258DA10:
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lbz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 16);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258dc20
	if (cr6.eq) goto loc_8258DC20;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8258fef0
	sub_8258FEF0(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(16) );
	// bl 0x8258f410
	sub_8258F410(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// stb r11,13(r31)
	PPC_STORE_U8(r31.u32 + 13, r11.u8);
	// lis r9,-31926
	ctx.r9.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r9,-30708
	ctx.r5.s64 = ctx.r9.s64 + -30708;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r4,26788(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82590998
	sub_82590998(ctx, base);
	// b 0x8258dc34
	goto loc_8258DC34;
loc_8258DA84:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r3,0(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// bl 0x8222c210
	sub_8222C210(ctx, base);
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258dac0
	if (cr6.eq) goto loc_8258DAC0;
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258dac4
	if (!cr6.eq) goto loc_8258DAC4;
loc_8258DAC0:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258DAC4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258dc20
	if (cr6.eq) goto loc_8258DC20;
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258dc20
	if (cr6.eq) goto loc_8258DC20;
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258dbdc
	if (cr6.eq) goto loc_8258DBDC;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258db18
	if (cr6.eq) goto loc_8258DB18;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258dbe0
	goto loc_8258DBE0;
loc_8258DB18:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258db84
	if (!cr0.gt) goto loc_8258DB84;
loc_8258DB34:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258db54
	if (cr6.lt) goto loc_8258DB54;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258DB54:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258db70
	if (cr6.eq) goto loc_8258DB70;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258db78
	goto loc_8258DB78;
loc_8258DB70:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258DB78:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258db34
	if (cr6.gt) goto loc_8258DB34;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258DB84:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258dbc8
	if (cr6.eq) goto loc_8258DBC8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258dba0
	if (cr6.gt) goto loc_8258DBA0;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258DBA0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258dbc8
	if (!cr6.eq) goto loc_8258DBC8;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258dbe0
	goto loc_8258DBE0;
loc_8258DBC8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258dbe0
	goto loc_8258DBE0;
loc_8258DBDC:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258DBE0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258dc20
	if (cr6.eq) goto loc_8258DC20;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823bf518
	sub_823BF518(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258dc20
	if (cr6.eq) goto loc_8258DC20;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821ee210
	sub_821EE210(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// clrlwi r10,r11,24
	ctx.r10.u64 = r11.u32 & 0xFF;
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r4,r9,27,31,31
	ctx.r4.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// bl 0x823bf150
	sub_823BF150(ctx, base);
loc_8258DC20:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82337540
	sub_82337540(ctx, base);
loc_8258DC34:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258D970) {
	__imp__sub_8258D970(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258DC50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8258dd00
	if (!cr6.eq) goto loc_8258DD00;
	// lbz r11,13(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 13);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258dcec
	if (cr6.eq) goto loc_8258DCEC;
	// li r11,0
	r11.s64 = 0;
	// addi r3,r31,48
	ctx.r3.s64 = r31.s64 + 48;
	// stb r11,13(r31)
	PPC_STORE_U8(r31.u32 + 13, r11.u8);
	// bl 0x82590c60
	sub_82590C60(ctx, base);
	// li r10,-1
	ctx.r10.s64 = -1;
	// li r4,3
	ctx.r4.s64 = 3;
	// stw r10,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8258fef0
	sub_8258FEF0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8258e938
	sub_8258E938(ctx, base);
	// lis r9,-31927
	ctx.r9.s64 = -2092367872;
	// lis r8,-31926
	ctx.r8.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r8,-30704
	ctx.r5.s64 = ctx.r8.s64 + -30704;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,26788(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82590998
	sub_82590998(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_8258DCEC:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82337540
	sub_82337540(ctx, base);
loc_8258DD00:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258DC50) {
	__imp__sub_8258DC50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258DD18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(16) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ddb8
	if (cr6.eq) goto loc_8258DDB8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258ddb4
	if (cr6.eq) goto loc_8258DDB4;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258dd70
	if (cr6.eq) goto loc_8258DD70;
	// lbz r10,144(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 144);
	// rlwinm r9,r10,0,25,25
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// li r10,1
	ctx.r10.s64 = 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8258dd74
	if (!cr6.eq) goto loc_8258DD74;
loc_8258DD70:
	// li r10,0
	ctx.r10.s64 = 0;
loc_8258DD74:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258deb4
	if (cr6.eq) goto loc_8258DEB4;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// rlwinm r9,r10,6,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258de7c
	if (cr6.eq) goto loc_8258DE7C;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258ddc0
	if (cr6.eq) goto loc_8258DDC0;
	// lbz r10,154(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 154);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r3,4(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8258de70
	goto loc_8258DE70;
loc_8258DDB4:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8258DDB8:
	// li r11,0
	r11.s64 = 0;
	// b 0x8258dd70
	goto loc_8258DD70;
loc_8258DDC0:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// subf r8,r10,r6
	ctx.r8.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r8,3
	xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x7) != 0);
	r11.s64 = ctx.r8.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258de30
	if (!cr0.gt) goto loc_8258DE30;
loc_8258DDE0:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,154
	cr6.compare<int32_t>(ctx.r7.s32, 154, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258de00
	if (cr6.lt) goto loc_8258DE00;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8258DE00:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258de1c
	if (cr6.eq) goto loc_8258DE1C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258de24
	goto loc_8258DE24;
loc_8258DE1C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258DE24:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258dde0
	if (cr6.gt) goto loc_8258DDE0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258DE30:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258de68
	if (cr6.eq) goto loc_8258DE68;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,154
	cr6.compare<int32_t>(r11.s32, 154, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258de4c
	if (cr6.gt) goto loc_8258DE4C;
	// li r11,0
	r11.s64 = 0;
loc_8258DE4C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258de68
	if (!cr6.eq) goto loc_8258DE68;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// b 0x8258de6c
	goto loc_8258DE6C;
loc_8258DE68:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_8258DE6C:
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_8258DE70:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258de7c
	if (cr6.eq) goto loc_8258DE7C;
	// bl 0x823e6e88
	sub_823E6E88(ctx, base);
loc_8258DE7C:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(36) );
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8258deb4
	if (!cr6.eq) goto loc_8258DEB4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8258deb4
	if (!cr6.eq) goto loc_8258DEB4;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lfs f0,-8648(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -8648);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 8, temp.u32);
	// bl 0x8258fe70
	sub_8258FE70(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
loc_8258DEB4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258DD18) {
	__imp__sub_8258DD18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258DED0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// lwz r4,20(r24)
	ctx.r4.u64 = PPC_LOAD_U32(r24.u32 + int32_t(20) );
	// bl 0x8258e890
	sub_8258E890(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e4c0
	if (cr6.eq) goto loc_8258E4C0;
	// lwz r10,52(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + int32_t(52) );
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + int32_t(20) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258df20
	if (cr6.eq) goto loc_8258DF20;
	// lwz r9,56(r24)
	ctx.r9.u64 = PPC_LOAD_U32(r24.u32 + int32_t(56) );
	// li r8,12
	ctx.r8.s64 = 12;
	// subf r7,r10,r9
	ctx.r7.s64 = ctx.r9.s64 - ctx.r10.s64;
	// divw r6,r7,r8
	ctx.r6.s32 = ctx.r7.s32 / ctx.r8.s32;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// blt cr6,0x8258df24
	if (cr6.lt) goto loc_8258DF24;
loc_8258DF20:
	// twi 31,r0,22
loc_8258DF24:
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r27,r11,r10
	r27.u64 = r11.u64 + ctx.r10.u64;
	// lbz r10,5(r27)
	ctx.r10.u64 = PPC_LOAD_U8(r27.u32 + 5);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258e4c0
	if (cr6.eq) goto loc_8258E4C0;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// lwz r11,26912(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26912) );
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(88) );
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// bl 0x8222c210
	sub_8222C210(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8258df80
	if (cr6.eq) goto loc_8258DF80;
	// lbz r11,144(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258df84
	if (!cr6.eq) goto loc_8258DF84;
loc_8258DF80:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8258DF84:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e4c0
	if (cr6.eq) goto loc_8258E4C0;
	// clrlwi r26,r25,24
	r26.u64 = r25.u32 & 0xFF;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x8258dfb8
	if (!cr6.eq) goto loc_8258DFB8;
	// lwz r11,26912(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26912) );
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(88) );
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// bl 0x828beec0
	sub_828BEEC0(ctx, base);
loc_8258DFB8:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258dfd4
	if (cr6.eq) goto loc_8258DFD4;
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258dfd8
	if (!cr6.eq) goto loc_8258DFD8;
loc_8258DFD4:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8258DFD8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e114
	if (cr6.eq) goto loc_8258E114;
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// mr r11,r28
	r11.u64 = r28.u64;
	// rlwinm r9,r10,31,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258e0dc
	if (cr6.eq) goto loc_8258E0DC;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e020
	if (cr6.eq) goto loc_8258E020;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8258e0e0
	goto loc_8258E0E0;
loc_8258E020:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258e08c
	if (!cr0.gt) goto loc_8258E08C;
loc_8258E03C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258e05c
	if (cr6.lt) goto loc_8258E05C;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_8258E05C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258e078
	if (cr6.eq) goto loc_8258E078;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258e080
	goto loc_8258E080;
loc_8258E078:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258E080:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258e03c
	if (cr6.gt) goto loc_8258E03C;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_8258E08C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258e0cc
	if (cr6.eq) goto loc_8258E0CC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258e0a8
	if (cr6.gt) goto loc_8258E0A8;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8258E0A8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258e0cc
	if (!cr6.eq) goto loc_8258E0CC;
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258e0e0
	goto loc_8258E0E0;
loc_8258E0CC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258e0e0
	goto loc_8258E0E0;
loc_8258E0DC:
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
loc_8258E0E0:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258e114
	if (cr6.eq) goto loc_8258E114;
	// lwz r3,20(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(20) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e104
	if (cr6.eq) goto loc_8258E104;
	// li r4,15
	ctx.r4.s64 = 15;
	// bl 0x821e8870
	sub_821E8870(ctx, base);
	// b 0x8258e108
	goto loc_8258E108;
loc_8258E104:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_8258E108:
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258e4c0
	if (!cr6.eq) goto loc_8258E4C0;
loc_8258E114:
	// lwz r11,36(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(36) );
	// mr r31,r28
	r31.u64 = r28.u64;
	// rlwinm r10,r11,19,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258e20c
	if (cr6.eq) goto loc_8258E20C;
	// lwz r11,140(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e150
	if (cr6.eq) goto loc_8258E150;
	// lbz r10,13(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 13);
	// lwz r11,72(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r11,1
	r11.s64 = 1;
	// lwz r31,4(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8258e210
	goto loc_8258E210;
loc_8258E150:
	// lwz r10,72(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + int32_t(72) );
	// lwz r6,76(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + int32_t(76) );
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r28.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258e1bc
	if (!cr0.gt) goto loc_8258E1BC;
loc_8258E16C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,13
	cr6.compare<int32_t>(ctx.r7.s32, 13, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258e18c
	if (cr6.lt) goto loc_8258E18C;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
loc_8258E18C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258e1a8
	if (cr6.eq) goto loc_8258E1A8;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258e1b0
	goto loc_8258E1B0;
loc_8258E1A8:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258E1B0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258e16c
	if (cr6.gt) goto loc_8258E16C;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_8258E1BC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258e1fc
	if (cr6.eq) goto loc_8258E1FC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,13
	cr6.compare<int32_t>(r11.s32, 13, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258e1d8
	if (cr6.gt) goto loc_8258E1D8;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8258E1D8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258e1fc
	if (!cr6.eq) goto loc_8258E1FC;
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x8258e210
	goto loc_8258E210;
loc_8258E1FC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// li r11,1
	r11.s64 = 1;
	// b 0x8258e210
	goto loc_8258E210;
loc_8258E20C:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8258E210:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e4c0
	if (cr6.eq) goto loc_8258E4C0;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(0) );
	// bl 0x821d9ed8
	sub_821D9ED8(ctx, base);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// addi r7,r11,-8708
	ctx.r7.s64 = r11.s64 + -8708;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// bl 0x823eab78
	sub_823EAB78(ctx, base);
	// lbz r6,7(r27)
	ctx.r6.u64 = PPC_LOAD_U8(r27.u32 + 7);
	// lis r30,-31927
	r30.s64 = -2092367872;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x8258e29c
	if (cr6.eq) goto loc_8258E29C;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r5,r11,-29756
	ctx.r5.s64 = r11.s64 + -29756;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8261b900
	sub_8261B900(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r3,52(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// bl 0x825a5a40
	sub_825A5A40(ctx, base);
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e294
	if (cr6.eq) goto loc_8258E294;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8258E294:
	// stw r28,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r28.u32);
	// b 0x8258e4a0
	goto loc_8258E4A0;
loc_8258E29C:
	// lbz r11,8(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e2ec
	if (cr6.eq) goto loc_8258E2EC;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r5,r11,-29752
	ctx.r5.s64 = r11.s64 + -29752;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8261b900
	sub_8261B900(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lwz r3,52(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// bl 0x825a5a40
	sub_825A5A40(ctx, base);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e2e4
	if (cr6.eq) goto loc_8258E2E4;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8258E2E4:
	// stw r28,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r28.u32);
	// b 0x8258e4a0
	goto loc_8258E4A0;
loc_8258E2EC:
	// lbz r11,9(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 9);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e33c
	if (cr6.eq) goto loc_8258E33C;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r5,r11,-29748
	ctx.r5.s64 = r11.s64 + -29748;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8261b900
	sub_8261B900(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r3,52(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// bl 0x825a5a40
	sub_825A5A40(ctx, base);
	// lwz r3,128(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(128) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e334
	if (cr6.eq) goto loc_8258E334;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8258E334:
	// stw r28,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r28.u32);
	// b 0x8258e4a0
	goto loc_8258E4A0;
loc_8258E33C:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8258e490
	if (!cr6.eq) goto loc_8258E490;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8258e490
	if (cr6.eq) goto loc_8258E490;
	// bl 0x82302d28
	sub_82302D28(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e414
	if (cr6.eq) goto loc_8258E414;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82337540
	sub_82337540(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82302ff8
	sub_82302FF8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// beq cr6,0x8258e398
	if (cr6.eq) goto loc_8258E398;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,48(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(48) );
	// bl 0x824f9a98
	sub_824F9A98(ctx, base);
	// b 0x8258e4a0
	goto loc_8258E4A0;
loc_8258E398:
	// lwz r9,28(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,3372
	ctx.r4.s64 = ctx.r10.s64 + 3372;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r31,52(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(52) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e408
	if (cr6.eq) goto loc_8258E408;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r4,r11,-29848
	ctx.r4.s64 = r11.s64 + -29848;
	// li r6,-1
	ctx.r6.s64 = -1;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// bl 0x823bd140
	sub_823BD140(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e408
	if (cr6.eq) goto loc_8258E408;
	// stw r3,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r3.u32);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x8240d440
	sub_8240D440(ctx, base);
loc_8258E408:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// b 0x8258e4a0
	goto loc_8258E4A0;
loc_8258E414:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r11,-29788
	ctx.r4.s64 = r11.s64 + -29788;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// li r3,48
	ctx.r3.s64 = 48;
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r31,52(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(52) );
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e484
	if (cr6.eq) goto loc_8258E484;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r4,r11,-29848
	ctx.r4.s64 = r11.s64 + -29848;
	// li r6,-1
	ctx.r6.s64 = -1;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// bl 0x823bd140
	sub_823BD140(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e484
	if (cr6.eq) goto loc_8258E484;
	// stw r3,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r3.u32);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x8240d440
	sub_8240D440(ctx, base);
loc_8258E484:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// b 0x8258e4a0
	goto loc_8258E4A0;
loc_8258E490:
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8258e4c8
	sub_8258E4C8(ctx, base);
loc_8258E4A0:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lwz r4,26788(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-30700
	ctx.r5.s64 = r11.s64 + -30700;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_8258E4C0:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_8258DED0) {
	__imp__sub_8258DED0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258E4C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,26912(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r11,140(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(140) );
	// lbz r9,52(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 52);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258e508
	if (cr6.eq) goto loc_8258E508;
	// lbz r11,53(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 53);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x8258e50c
	if (!cr6.eq) goto loc_8258E50C;
loc_8258E508:
	// li r11,0
	r11.s64 = 0;
loc_8258E50C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// lwz r3,156(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(156) );
	// li r4,1
	ctx.r4.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258e524
	if (!cr6.eq) goto loc_8258E524;
	// li r4,2
	ctx.r4.s64 = 2;
loc_8258E524:
	// bl 0x822641f0
	sub_822641F0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e6cc
	if (cr6.eq) goto loc_8258E6CC;
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e6cc
	if (cr6.eq) goto loc_8258E6CC;
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258e58c
	if (!cr6.eq) goto loc_8258E58C;
	// lwz r11,26912(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26912) );
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(88) );
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// bl 0x828beec0
	sub_828BEEC0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e57c
	if (cr6.eq) goto loc_8258E57C;
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258e580
	if (!cr6.eq) goto loc_8258E580;
loc_8258E57C:
	// li r11,0
	r11.s64 = 0;
loc_8258E580:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e6cc
	if (cr6.eq) goto loc_8258E6CC;
loc_8258E58C:
	// lwz r11,52(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(52) );
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r10,r11,6,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258e690
	if (cr6.eq) goto loc_8258E690;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e5cc
	if (cr6.eq) goto loc_8258E5CC;
	// lbz r11,154(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 154);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258e694
	goto loc_8258E694;
loc_8258E5CC:
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// li r11,0
	r11.s64 = 0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258e638
	if (!cr0.gt) goto loc_8258E638;
loc_8258E5E8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,154
	cr6.compare<int32_t>(ctx.r7.s32, 154, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258e608
	if (cr6.lt) goto loc_8258E608;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8258E608:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258e624
	if (cr6.eq) goto loc_8258E624;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258e62c
	goto loc_8258E62C;
loc_8258E624:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258E62C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258e5e8
	if (cr6.gt) goto loc_8258E5E8;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258E638:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258e67c
	if (cr6.eq) goto loc_8258E67C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,154
	cr6.compare<int32_t>(r11.s32, 154, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258e654
	if (cr6.gt) goto loc_8258E654;
	// li r11,0
	r11.s64 = 0;
loc_8258E654:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258e67c
	if (!cr6.eq) goto loc_8258E67C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258e694
	goto loc_8258E694;
loc_8258E67C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258e694
	goto loc_8258E694;
loc_8258E690:
	// li r11,0
	r11.s64 = 0;
loc_8258E694:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e6cc
	if (cr6.eq) goto loc_8258E6CC;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + int32_t(0) );
	// bl 0x821d9ed8
	sub_821D9ED8(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// bl 0x823e5ad0
	sub_823E5AD0(ctx, base);
loc_8258E6CC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8258E4C8) {
	__imp__sub_8258E4C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258E6D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r31,0
	r31.s64 = 0;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r11,140(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(140) );
	// lbz r9,52(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 52);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258e718
	if (cr6.eq) goto loc_8258E718;
	// lbz r11,53(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 53);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x8258e71c
	if (!cr6.eq) goto loc_8258E71C;
loc_8258E718:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258E71C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// lwz r3,156(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(156) );
	// li r4,1
	ctx.r4.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258e734
	if (!cr6.eq) goto loc_8258E734;
	// li r4,2
	ctx.r4.s64 = 2;
loc_8258E734:
	// bl 0x822641f0
	sub_822641F0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e874
	if (cr6.eq) goto loc_8258E874;
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258e874
	if (cr6.eq) goto loc_8258E874;
	// lwz r11,52(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(52) );
	// rlwinm r10,r11,6,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258e84c
	if (cr6.eq) goto loc_8258E84C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e788
	if (cr6.eq) goto loc_8258E788;
	// lbz r10,154(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 154);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258e850
	goto loc_8258E850;
loc_8258E788:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258e7f4
	if (!cr0.gt) goto loc_8258E7F4;
loc_8258E7A4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,154
	cr6.compare<int32_t>(ctx.r7.s32, 154, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258e7c4
	if (cr6.lt) goto loc_8258E7C4;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258E7C4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258e7e0
	if (cr6.eq) goto loc_8258E7E0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258e7e8
	goto loc_8258E7E8;
loc_8258E7E0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258E7E8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258e7a4
	if (cr6.gt) goto loc_8258E7A4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258E7F4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258e838
	if (cr6.eq) goto loc_8258E838;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,154
	cr6.compare<int32_t>(r11.s32, 154, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258e810
	if (cr6.gt) goto loc_8258E810;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258E810:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258e838
	if (!cr6.eq) goto loc_8258E838;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258e850
	goto loc_8258E850;
loc_8258E838:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258e850
	goto loc_8258E850;
loc_8258E84C:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8258E850:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e874
	if (cr6.eq) goto loc_8258E874;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x822bdc48
	sub_822BDC48(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// li r3,1
	ctx.r3.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258e878
	if (!cr6.eq) goto loc_8258E878;
loc_8258E874:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8258E878:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258E6D8) {
	__imp__sub_8258E6D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258E890) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,13(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 13);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e918
	if (cr6.eq) goto loc_8258E918;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// blt cr6,0x8258e908
	if (cr6.lt) goto loc_8258E908;
	// lwz r11,52(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(52) );
	// li r10,12
	ctx.r10.s64 = 12;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e8c0
	if (cr6.eq) goto loc_8258E8C0;
	// lwz r9,56(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(56) );
	// subf r8,r11,r9
	ctx.r8.s64 = ctx.r9.s64 - r11.s64;
	// divw r11,r8,r10
	r11.s32 = ctx.r8.s32 / ctx.r10.s32;
loc_8258E8C0:
	// cmpw cr6,r4,r11
	cr6.compare<int32_t>(ctx.r4.s32, r11.s32, xer);
	// bge cr6,0x8258e908
	if (!cr6.lt) goto loc_8258E908;
	// lwz r11,52(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(52) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258e8e8
	if (cr6.eq) goto loc_8258E8E8;
	// lwz r9,56(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(56) );
	// subf r8,r11,r9
	ctx.r8.s64 = ctx.r9.s64 - r11.s64;
	// divw r7,r8,r10
	ctx.r7.s32 = ctx.r8.s32 / ctx.r10.s32;
	// cmplw cr6,r4,r7
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r7.u32, xer);
	// blt cr6,0x8258e8ec
	if (cr6.lt) goto loc_8258E8EC;
loc_8258E8E8:
	// twi 31,r0,22
loc_8258E8EC:
	// rlwinm r10,r4,1,0,30
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r4,r10
	ctx.r10.u64 = ctx.r4.u64 + ctx.r10.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lbz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 4);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x8258e910
	if (!cr6.eq) goto loc_8258E910;
loc_8258E908:
	// cmpwi cr6,r4,7
	cr6.compare<int32_t>(ctx.r4.s32, 7, xer);
	// bne cr6,0x8258e92c
	if (!cr6.eq) goto loc_8258E92C;
loc_8258E910:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_8258E918:
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// blt cr6,0x8258e92c
	if (cr6.lt) goto loc_8258E92C;
	// cmpwi cr6,r4,8
	cr6.compare<int32_t>(ctx.r4.s32, 8, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bltlr cr6
	if (cr6.lt) return;
loc_8258E92C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258E890) {
	__imp__sub_8258E890(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258E938) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bbc
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r23,-31927
	r23.s64 = -2092367872;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r19,0
	r19.s64 = 0;
	// li r18,1
	r18.s64 = 1;
	// lwz r11,26912(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + int32_t(26912) );
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(88) );
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ea00
	if (cr6.eq) goto loc_8258EA00;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258e9fc
	if (cr6.eq) goto loc_8258E9FC;
	// rotlwi r25,r10,0
	r25.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8258e9a4
	if (cr6.eq) goto loc_8258E9A4;
	// lbz r11,144(r25)
	r11.u64 = PPC_LOAD_U8(r25.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// mr r11,r18
	r11.u64 = r18.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258e9a8
	if (!cr6.eq) goto loc_8258E9A8;
loc_8258E9A4:
	// mr r11,r19
	r11.u64 = r19.u64;
loc_8258E9A8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ef90
	if (cr6.eq) goto loc_8258EF90;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8258ef98
	sub_8258EF98(ctx, base);
	// lis r11,-32247
	r11.s64 = -2113339392;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-31926
	ctx.r9.s64 = -2092302336;
	// lis r8,-32244
	ctx.r8.s64 = -2113142784;
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r29,r19
	r29.u64 = r19.u64;
	// li r27,20
	r27.s64 = 20;
	// addi r26,r11,63
	r26.s64 = r11.s64 + 63;
	// addi r21,r10,1080
	r21.s64 = ctx.r10.s64 + 1080;
	// addi r20,r9,-29836
	r20.s64 = ctx.r9.s64 + -29836;
	// addi r24,r8,3404
	r24.s64 = ctx.r8.s64 + 3404;
loc_8258E9E8:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(36) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258ea08
	if (!cr6.eq) goto loc_8258EA08;
	// mr r11,r19
	r11.u64 = r19.u64;
	// b 0x8258ea14
	goto loc_8258EA14;
loc_8258E9FC:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8258EA00:
	// mr r25,r19
	r25.u64 = r19.u64;
	// b 0x8258e9a4
	goto loc_8258E9A4;
loc_8258EA08:
	// lwz r10,40(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(40) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// divw r11,r9,r27
	r11.s32 = ctx.r9.s32 / r27.s32;
loc_8258EA14:
	// cmpw cr6,r29,r11
	cr6.compare<int32_t>(r29.s32, r11.s32, xer);
	// bge cr6,0x8258ed30
	if (!cr6.lt) goto loc_8258ED30;
	// cmpwi cr6,r29,8
	cr6.compare<int32_t>(r29.s32, 8, xer);
	// bge cr6,0x8258ed30
	if (!cr6.lt) goto loc_8258ED30;
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(36) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ea44
	if (cr6.eq) goto loc_8258EA44;
	// lwz r10,40(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(40) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// divw r8,r9,r27
	ctx.r8.s32 = ctx.r9.s32 / r27.s32;
	// cmplw cr6,r29,r8
	cr6.compare<uint32_t>(r29.u32, ctx.r8.u32, xer);
	// blt cr6,0x8258ea48
	if (cr6.lt) goto loc_8258EA48;
loc_8258EA44:
	// twi 31,r0,22
loc_8258EA48:
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// add r10,r29,r10
	ctx.r10.u64 = r29.u64 + ctx.r10.u64;
	// rlwinm r28,r10,2,0,29
	r28.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r28,r11
	r31.u64 = r28.u64 + r11.u64;
	// addi r4,r31,4
	ctx.r4.s64 = r31.s64 + 4;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// lbz r9,31(r30)
	ctx.r9.u64 = PPC_LOAD_U8(r30.u32 + 31);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258ea80
	if (cr6.eq) goto loc_8258EA80;
	// addi r4,r31,8
	ctx.r4.s64 = r31.s64 + 8;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// b 0x8258ebb4
	goto loc_8258EBB4;
loc_8258EA80:
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258eaa4
	if (cr6.eq) goto loc_8258EAA4;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_8258EAA4:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258eab8
	if (cr6.eq) goto loc_8258EAB8;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_8258EAB8:
	// bl 0x821e6388
	sub_821E6388(ctx, base);
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// rlwinm r10,r11,27,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r17,r10,1
	r17.u64 = ctx.r10.u64 ^ 1;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// clrlwi r9,r17,24
	ctx.r9.u64 = r17.u32 & 0xFF;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258ebb4
	if (cr6.eq) goto loc_8258EBB4;
	// clrlwi r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258eb88
	if (cr6.eq) goto loc_8258EB88;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821da550
	sub_821DA550(ctx, base);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8258fd30
	sub_8258FD30(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x8258eb4c
	if (cr6.eq) goto loc_8258EB4C;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590338
	sub_82590338(ctx, base);
loc_8258EB4C:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(36) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258eb6c
	if (cr6.eq) goto loc_8258EB6C;
	// lwz r10,40(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(40) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// divw r8,r9,r27
	ctx.r8.s32 = ctx.r9.s32 / r27.s32;
	// cmplw cr6,r29,r8
	cr6.compare<uint32_t>(r29.u32, ctx.r8.u32, xer);
	// blt cr6,0x8258eb70
	if (cr6.lt) goto loc_8258EB70;
loc_8258EB6C:
	// twi 31,r0,22
loc_8258EB70:
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stb r19,16(r11)
	PPC_STORE_U8(r11.u32 + 16, r19.u8);
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// b 0x8258e9e8
	goto loc_8258E9E8;
loc_8258EB88:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(36) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258eba8
	if (cr6.eq) goto loc_8258EBA8;
	// lwz r10,40(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(40) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// divw r8,r9,r27
	ctx.r8.s32 = ctx.r9.s32 / r27.s32;
	// cmplw cr6,r29,r8
	cr6.compare<uint32_t>(r29.u32, ctx.r8.u32, xer);
	// blt cr6,0x8258ebac
	if (cr6.lt) goto loc_8258EBAC;
loc_8258EBA8:
	// twi 31,r0,22
loc_8258EBAC:
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// stb r18,16(r11)
	PPC_STORE_U8(r11.u32 + 16, r18.u8);
loc_8258EBB4:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821da550
	sub_821DA550(ctx, base);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8258fd30
	sub_8258FD30(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x8258ecf4
	if (!cr6.eq) goto loc_8258ECF4;
	// lwz r11,26912(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + int32_t(26912) );
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(88) );
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(0) );
	// bl 0x8235f3d8
	sub_8235F3D8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258ec28
	if (cr6.eq) goto loc_8258EC28;
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// mr r11,r18
	r11.u64 = r18.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258ec2c
	if (!cr6.eq) goto loc_8258EC2C;
loc_8258EC28:
	// mr r11,r19
	r11.u64 = r19.u64;
loc_8258EC2C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ec9c
	if (cr6.eq) goto loc_8258EC9C;
	// lbz r11,31(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 31);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258ec9c
	if (!cr6.eq) goto loc_8258EC9C;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590338
	sub_82590338(ctx, base);
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(36) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ec84
	if (cr6.eq) goto loc_8258EC84;
	// lwz r10,40(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(40) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// divw. r8,r9,r27
	ctx.r8.s32 = ctx.r9.s32 / r27.s32;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8258ec88
	if (!cr0.eq) goto loc_8258EC88;
loc_8258EC84:
	// twi 31,r0,22
loc_8258EC88:
	// stb r18,16(r11)
	PPC_STORE_U8(r11.u32 + 16, r18.u8);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// b 0x8258e9e8
	goto loc_8258E9E8;
loc_8258EC9C:
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590338
	sub_82590338(ctx, base);
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(36) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ecdc
	if (cr6.eq) goto loc_8258ECDC;
	// lwz r10,40(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(40) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// divw. r8,r9,r27
	ctx.r8.s32 = ctx.r9.s32 / r27.s32;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8258ece0
	if (!cr0.eq) goto loc_8258ECE0;
loc_8258ECDC:
	// twi 31,r0,22
loc_8258ECE0:
	// stb r19,16(r11)
	PPC_STORE_U8(r11.u32 + 16, r19.u8);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// b 0x8258e9e8
	goto loc_8258E9E8;
loc_8258ECF4:
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x8258ed20
	if (cr6.eq) goto loc_8258ED20;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590338
	sub_82590338(ctx, base);
loc_8258ED20:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// b 0x8258e9e8
	goto loc_8258E9E8;
loc_8258ED30:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825905e8
	sub_825905E8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821da550
	sub_821DA550(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825907c0
	sub_825907C0(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r7,6
	ctx.r7.s64 = 6;
	// bl 0x8258fd30
	sub_8258FD30(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// addi r31,r11,28344
	r31.s64 = r11.s64 + 28344;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
loc_8258ED84:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8258ed84
	if (!cr0.eq) goto loc_8258ED84;
	// lwz r6,40(r25)
	ctx.r6.u64 = PPC_LOAD_U32(r25.u32 + int32_t(40) );
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
	// mr r11,r19
	r11.u64 = r19.u64;
	// rlwinm r5,r6,31,31,31
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x8258ee9c
	if (cr6.eq) goto loc_8258EE9C;
	// lwz r11,140(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258ede0
	if (cr6.eq) goto loc_8258EDE0;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// mr r10,r18
	ctx.r10.u64 = r18.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8258eea0
	goto loc_8258EEA0;
loc_8258EDE0:
	// lwz r10,72(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + int32_t(72) );
	// lwz r5,76(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + int32_t(76) );
	// stw r19,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r19.u32);
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258ee4c
	if (!cr0.gt) goto loc_8258EE4C;
loc_8258EDFC:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r6,33
	cr6.compare<int32_t>(ctx.r6.s32, 33, xer);
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// blt cr6,0x8258ee1c
	if (cr6.lt) goto loc_8258EE1C;
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
loc_8258EE1C:
	// clrlwi r6,r6,24
	ctx.r6.u64 = ctx.r6.u32 & 0xFF;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x8258ee38
	if (cr6.eq) goto loc_8258EE38;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258ee40
	goto loc_8258EE40;
loc_8258EE38:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258EE40:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258edfc
	if (cr6.gt) goto loc_8258EDFC;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_8258EE4C:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x8258ee8c
	if (cr6.eq) goto loc_8258EE8C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// mr r11,r18
	r11.u64 = r18.u64;
	// bgt cr6,0x8258ee68
	if (cr6.gt) goto loc_8258EE68;
	// mr r11,r19
	r11.u64 = r19.u64;
loc_8258EE68:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258ee8c
	if (!cr6.eq) goto loc_8258EE8C;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// mr r10,r18
	ctx.r10.u64 = r18.u64;
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258eea0
	goto loc_8258EEA0;
loc_8258EE8C:
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// mr r10,r18
	ctx.r10.u64 = r18.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8258eea0
	goto loc_8258EEA0;
loc_8258EE9C:
	// mr r10,r19
	ctx.r10.u64 = r19.u64;
loc_8258EEA0:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258eeb8
	if (cr6.eq) goto loc_8258EEB8;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x823bf518
	sub_823BF518(ctx, base);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
loc_8258EEB8:
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,6
	ctx.r4.s64 = 6;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590338
	sub_82590338(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,1736
	ctx.r4.s64 = r11.s64 + 1736;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r10,-29812
	ctx.r4.s64 = ctx.r10.s64 + -29812;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821da550
	sub_821DA550(ctx, base);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// li r7,7
	ctx.r7.s64 = 7;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8258fd30
	sub_8258FD30(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8258EF2C:
	// mfmsr r8
	// mtmsrd r13,1
	// lwarx r9,0,r7
	reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r9.u64 = __builtin_bswap32(reserved.u32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// stwcx. r9,0,r7
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), reserved.s32, __builtin_bswap32(ctx.r9.s32));
	cr0.so = xer.so;
	// mtmsrd r8,1
	// bne 0x8258ef2c
	if (!cr0.eq) goto loc_8258EF2C;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x821c67d8
	sub_821C67D8(ctx, base);
loc_8258EF50:
	// mfmsr r5
	// mtmsrd r13,1
	// lwarx r6,0,r31
	reserved.u32 = *(uint32_t*)(base + r31.u32);
	ctx.r6.u64 = __builtin_bswap32(reserved.u32);
	// addi r6,r6,-1
	ctx.r6.s64 = ctx.r6.s64 + -1;
	// stwcx. r6,0,r31
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + r31.u32), reserved.s32, __builtin_bswap32(ctx.r6.s32));
	cr0.so = xer.so;
	// mtmsrd r5,1
	// bne 0x8258ef50
	if (!cr0.eq) goto loc_8258EF50;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,7
	ctx.r4.s64 = 7;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82590338
	sub_82590338(ctx, base);
loc_8258EF90:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c0c
	return;
}

PPC_WEAK_FUNC(sub_8258E938) {
	__imp__sub_8258E938(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258EF98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(24) );
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x8258f3f4
	if (cr6.eq) goto loc_8258F3F4;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,156(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(156) );
	// bl 0x822641f0
	sub_822641F0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258f3f4
	if (cr6.eq) goto loc_8258F3F4;
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258effc
	if (cr6.eq) goto loc_8258EFFC;
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258f000
	if (!cr6.eq) goto loc_8258F000;
loc_8258EFFC:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258F000:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258f3f4
	if (cr6.eq) goto loc_8258F3F4;
	// lbz r11,31(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 31);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258f3f4
	if (!cr6.eq) goto loc_8258F3F4;
	// lwz r11,44(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(44) );
	// mr r31,r30
	r31.u64 = r30.u64;
	// rlwinm r10,r11,19,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258f11c
	if (cr6.eq) goto loc_8258F11C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258f058
	if (cr6.eq) goto loc_8258F058;
	// lbz r10,77(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 77);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f120
	goto loc_8258F120;
loc_8258F058:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258f0c4
	if (!cr0.gt) goto loc_8258F0C4;
loc_8258F074:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,77
	cr6.compare<int32_t>(ctx.r7.s32, 77, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258f094
	if (cr6.lt) goto loc_8258F094;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_8258F094:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258f0b0
	if (cr6.eq) goto loc_8258F0B0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258f0b8
	goto loc_8258F0B8;
loc_8258F0B0:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258F0B8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258f074
	if (cr6.gt) goto loc_8258F074;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258F0C4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258f108
	if (cr6.eq) goto loc_8258F108;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,77
	cr6.compare<int32_t>(r11.s32, 77, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258f0e0
	if (cr6.gt) goto loc_8258F0E0;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258F0E0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258f108
	if (!cr6.eq) goto loc_8258F108;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f120
	goto loc_8258F120;
loc_8258F108:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f120
	goto loc_8258F120;
loc_8258F11C:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258F120:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258f3f4
	if (cr6.eq) goto loc_8258F3F4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8277a5a0
	sub_8277A5A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258f154
	if (cr6.eq) goto loc_8258F154;
	// lbz r10,144(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 144);
	// rlwinm r9,r10,0,25,25
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// li r10,1
	ctx.r10.s64 = 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8258f158
	if (!cr6.eq) goto loc_8258F158;
loc_8258F154:
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_8258F158:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258f28c
	if (cr6.eq) goto loc_8258F28C;
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(48) );
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r9,r10,6,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258f268
	if (cr6.eq) goto loc_8258F268;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258f1a4
	if (cr6.eq) goto loc_8258F1A4;
	// lbz r9,122(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 122);
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r11,r9,3
	r11.u64 = rotl32(ctx.r9.u32, 3);
	// add r8,r11,r10
	ctx.r8.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f26c
	goto loc_8258F26C;
loc_8258F1A4:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258f210
	if (!cr0.gt) goto loc_8258F210;
loc_8258F1C0:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,122
	cr6.compare<int32_t>(ctx.r7.s32, 122, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258f1e0
	if (cr6.lt) goto loc_8258F1E0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_8258F1E0:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258f1fc
	if (cr6.eq) goto loc_8258F1FC;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258f204
	goto loc_8258F204;
loc_8258F1FC:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258F204:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258f1c0
	if (cr6.gt) goto loc_8258F1C0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258F210:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258f254
	if (cr6.eq) goto loc_8258F254;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,122
	cr6.compare<int32_t>(r11.s32, 122, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258f22c
	if (cr6.gt) goto loc_8258F22C;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258F22C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258f254
	if (!cr6.eq) goto loc_8258F254;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f26c
	goto loc_8258F26C;
loc_8258F254:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f26c
	goto loc_8258F26C;
loc_8258F268:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258F26C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258f28c
	if (cr6.eq) goto loc_8258F28C;
	// bl 0x821c2c18
	sub_821C2C18(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bge cr6,0x8258f28c
	if (!cr6.lt) goto loc_8258F28C;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x8258f3f8
	goto loc_8258F3F8;
loc_8258F28C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(68) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258f2c0
	if (cr6.eq) goto loc_8258F2C0;
	// lbz r10,144(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 144);
	// rlwinm r9,r10,0,25,25
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// li r10,1
	ctx.r10.s64 = 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8258f2c4
	if (!cr6.eq) goto loc_8258F2C4;
loc_8258F2C0:
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_8258F2C4:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258f3f4
	if (cr6.eq) goto loc_8258F3F4;
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(48) );
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r9,r10,6,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258f3d4
	if (cr6.eq) goto loc_8258F3D4;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258f310
	if (cr6.eq) goto loc_8258F310;
	// lbz r9,122(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 122);
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r11,r9,3
	r11.u64 = rotl32(ctx.r9.u32, 3);
	// add r8,r11,r10
	ctx.r8.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f3d8
	goto loc_8258F3D8;
loc_8258F310:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258f37c
	if (!cr0.gt) goto loc_8258F37C;
loc_8258F32C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,122
	cr6.compare<int32_t>(ctx.r7.s32, 122, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258f34c
	if (cr6.lt) goto loc_8258F34C;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_8258F34C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258f368
	if (cr6.eq) goto loc_8258F368;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258f370
	goto loc_8258F370;
loc_8258F368:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258F370:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258f32c
	if (cr6.gt) goto loc_8258F32C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8258F37C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258f3c0
	if (cr6.eq) goto loc_8258F3C0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,122
	cr6.compare<int32_t>(r11.s32, 122, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258f398
	if (cr6.gt) goto loc_8258F398;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258F398:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258f3c0
	if (!cr6.eq) goto loc_8258F3C0;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f3d8
	goto loc_8258F3D8;
loc_8258F3C0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f3d8
	goto loc_8258F3D8;
loc_8258F3D4:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8258F3D8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258f3f4
	if (cr6.eq) goto loc_8258F3F4;
	// bl 0x821c2c18
	sub_821C2C18(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// blt cr6,0x8258f3f8
	if (cr6.lt) goto loc_8258F3F8;
loc_8258F3F4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8258F3F8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8258EF98) {
	__imp__sub_8258EF98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258F410) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-416(r1)
	ea = -416 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// stb r5,455(r1)
	PPC_STORE_U8(ctx.r1.u32 + 455, ctx.r5.u8);
	// stw r27,436(r1)
	PPC_STORE_U32(ctx.r1.u32 + 436, r27.u32);
	// bl 0x8258e890
	sub_8258E890(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258fd28
	if (cr6.eq) goto loc_8258FD28;
	// lwz r11,36(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(36) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258f45c
	if (cr6.eq) goto loc_8258F45C;
	// lwz r10,40(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + int32_t(40) );
	// li r9,20
	ctx.r9.s64 = 20;
	// subf r8,r11,r10
	ctx.r8.s64 = ctx.r10.s64 - r11.s64;
	// divw r7,r8,r9
	ctx.r7.s32 = ctx.r8.s32 / ctx.r9.s32;
	// cmplw cr6,r4,r7
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r7.u32, xer);
	// blt cr6,0x8258f460
	if (cr6.lt) goto loc_8258F460;
loc_8258F45C:
	// twi 31,r0,22
loc_8258F460:
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// add r10,r4,r10
	ctx.r10.u64 = ctx.r4.u64 + ctx.r10.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x8219c690
	sub_8219C690(ctx, base);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(88) );
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8258fd28
	if (cr6.eq) goto loc_8258FD28;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,3412
	ctx.r4.s64 = r11.s64 + 3412;
	// bl 0x822a97a8
	sub_822A97A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8258fd28
	if (cr6.eq) goto loc_8258FD28;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r3,0(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// bl 0x8222c210
	sub_8222C210(ctx, base);
	// li r19,0
	r19.s64 = 0;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258f4e4
	if (cr6.eq) goto loc_8258F4E4;
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258f4e8
	if (!cr6.eq) goto loc_8258F4E8;
loc_8258F4E4:
	// mr r11,r19
	r11.u64 = r19.u64;
loc_8258F4E8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258fd28
	if (cr6.eq) goto loc_8258FD28;
	// lwz r11,52(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(52) );
	// mr r28,r19
	r28.u64 = r19.u64;
	// addi r5,r3,36
	ctx.r5.s64 = ctx.r3.s64 + 36;
	// rlwinm r10,r11,6,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	// stw r28,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r28.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258f60c
	if (cr6.eq) goto loc_8258F60C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258f540
	if (cr6.eq) goto loc_8258F540;
	// lbz r10,154(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 154);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r28,r11
	r28.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// stw r28,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r28.u32);
	// b 0x8258f610
	goto loc_8258F610;
loc_8258F540:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r19,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r19.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258f5ac
	if (!cr0.gt) goto loc_8258F5AC;
loc_8258F55C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,154
	cr6.compare<int32_t>(ctx.r7.s32, 154, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258f57c
	if (cr6.lt) goto loc_8258F57C;
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
loc_8258F57C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258f598
	if (cr6.eq) goto loc_8258F598;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258f5a0
	goto loc_8258F5A0;
loc_8258F598:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258F5A0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258f55c
	if (cr6.gt) goto loc_8258F55C;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_8258F5AC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258f5f4
	if (cr6.eq) goto loc_8258F5F4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,154
	cr6.compare<int32_t>(r11.s32, 154, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258f5c8
	if (cr6.gt) goto loc_8258F5C8;
	// mr r11,r19
	r11.u64 = r19.u64;
loc_8258F5C8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258f5f4
	if (!cr6.eq) goto loc_8258F5F4;
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r28,r11
	r28.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// stw r28,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r28.u32);
	// b 0x8258f610
	goto loc_8258F610;
loc_8258F5F4:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r28,r11
	r28.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// stw r28,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r28.u32);
	// b 0x8258f610
	goto loc_8258F610;
loc_8258F60C:
	// mr r11,r19
	r11.u64 = r19.u64;
loc_8258F610:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258fd28
	if (cr6.eq) goto loc_8258FD28;
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + int32_t(0) );
	// stw r19,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r19.u32);
	// rlwinm r10,r11,19,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8258f720
	if (cr6.eq) goto loc_8258F720;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258f65c
	if (cr6.eq) goto loc_8258F65C;
	// lbz r10,13(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 13);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f724
	goto loc_8258F724;
loc_8258F65C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r19,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r19.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8258f6c8
	if (!cr0.gt) goto loc_8258F6C8;
loc_8258F678:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,13
	cr6.compare<int32_t>(ctx.r7.s32, 13, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8258f698
	if (cr6.lt) goto loc_8258F698;
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
loc_8258F698:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8258f6b4
	if (cr6.eq) goto loc_8258F6B4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8258f6bc
	goto loc_8258F6BC;
loc_8258F6B4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8258F6BC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8258f678
	if (cr6.gt) goto loc_8258F678;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_8258F6C8:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8258f70c
	if (cr6.eq) goto loc_8258F70C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,13
	cr6.compare<int32_t>(r11.s32, 13, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8258f6e4
	if (cr6.gt) goto loc_8258F6E4;
	// mr r11,r19
	r11.u64 = r19.u64;
loc_8258F6E4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258f70c
	if (!cr6.eq) goto loc_8258F70C;
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f724
	goto loc_8258F724;
loc_8258F70C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x8258f724
	goto loc_8258F724;
loc_8258F720:
	// mr r11,r19
	r11.u64 = r19.u64;
loc_8258F724:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258fd28
	if (cr6.eq) goto loc_8258FD28;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// bl 0x829fbc40
	sub_829FBC40(ctx, base);
	// lis r5,-32245
	ctx.r5.s64 = -2113208320;
	// lis r4,-32245
	ctx.r4.s64 = -2113208320;
	// lis r3,-32245
	ctx.r3.s64 = -2113208320;
	// addi r5,r5,-4560
	ctx.r5.s64 = ctx.r5.s64 + -4560;
	// addi r4,r4,-8608
	ctx.r4.s64 = ctx.r4.s64 + -8608;
	// addi r3,r3,-8652
	ctx.r3.s64 = ctx.r3.s64 + -8652;
	// stw r5,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r5.u32);
	// lis r31,-32245
	r31.s64 = -2113208320;
	// stw r4,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r4.u32);
	// lis r30,-31926
	r30.s64 = -2092302336;
	// stw r3,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r3.u32);
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-31926
	ctx.r8.s64 = -2092302336;
	// lis r7,-32246
	ctx.r7.s64 = -2113273856;
	// lis r6,-31926
	ctx.r6.s64 = -2092302336;
	// lis r29,-31926
	r29.s64 = -2092302336;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// addi r5,r31,-8708
	ctx.r5.s64 = r31.s64 + -8708;
	// addi r4,r30,-29748
	ctx.r4.s64 = r30.s64 + -29748;
	// addi r3,r11,-29760
	ctx.r3.s64 = r11.s64 + -29760;
	// stw r5,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r5.u32);
	// lis r21,-31927
	r21.s64 = -2092367872;
	// stw r4,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r4.u32);
	// addi r17,r9,3224
	r17.s64 = ctx.r9.s64 + 3224;
	// stw r3,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r3.u32);
	// addi r16,r8,-29844
	r16.s64 = ctx.r8.s64 + -29844;
	// addi r18,r7,1080
	r18.s64 = ctx.r7.s64 + 1080;
	// addi r20,r6,-29832
	r20.s64 = ctx.r6.s64 + -29832;
	// addi r15,r29,-29752
	r15.s64 = r29.s64 + -29752;
	// addi r14,r10,-29756
	r14.s64 = ctx.r10.s64 + -29756;
loc_8258F7B8:
	// lwz r11,156(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(156) );
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(160) );
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8258f848
	if (!cr6.eq) goto loc_8258F848;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821da550
	sub_821DA550(ctx, base);
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,140
	ctx.r3.s64 = ctx.r1.s64 + 140;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
	// addi r6,r1,140
	ctx.r6.s64 = ctx.r1.s64 + 140;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8258fd30
	sub_8258FD30(ctx, base);
	// addi r3,r1,140
	ctx.r3.s64 = ctx.r1.s64 + 140;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// cmpwi cr6,r19,-1
	cr6.compare<int32_t>(r19.s32, -1, xer);
	// beq cr6,0x8258f83c
	if (cr6.eq) goto loc_8258F83C;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82590338
	sub_82590338(ctx, base);
loc_8258F83C:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// b 0x8258fcb0
	goto loc_8258FCB0;
loc_8258F848:
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// bl 0x829fc0d0
	sub_829FC0D0(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x821d9ed8
	sub_821D9ED8(ctx, base);
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// li r23,1
	r23.s64 = 1;
	// bl 0x823e7208
	sub_823E7208(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823e8020
	sub_823E8020(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823e8348
	sub_823E8348(ctx, base);
	// lwz r11,26788(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + int32_t(26788) );
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// addi r31,r11,4
	r31.s64 = r11.s64 + 4;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// lwz r29,8(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// ble cr6,0x8258f8b8
	if (!cr6.gt) goto loc_8258F8B8;
	// twi 31,r0,22
loc_8258F8B8:
	// lwz r27,4(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// lwz r28,8(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
loc_8258F8C4:
	// cmplw cr6,r27,r28
	cr6.compare<uint32_t>(r27.u32, r28.u32, xer);
	// ble cr6,0x8258f8d0
	if (!cr6.gt) goto loc_8258F8D0;
	// twi 31,r0,22
loc_8258F8D0:
	// cmplw cr6,r31,r31
	cr6.compare<uint32_t>(r31.u32, r31.u32, xer);
	// beq cr6,0x8258f8dc
	if (cr6.eq) goto loc_8258F8DC;
	// twi 31,r0,22
loc_8258F8DC:
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// beq cr6,0x8258f934
	if (cr6.eq) goto loc_8258F934;
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// blt cr6,0x8258f8f0
	if (cr6.lt) goto loc_8258F8F0;
	// twi 31,r0,22
loc_8258F8F0:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8258f918
	if (!cr6.eq) goto loc_8258F918;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x827e3ca0
	sub_827E3CA0(ctx, base);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// cmplw cr6,r7,r3
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r3.u32, xer);
	// beq cr6,0x8258f92c
	if (cr6.eq) goto loc_8258F92C;
loc_8258F918:
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// blt cr6,0x8258f924
	if (cr6.lt) goto loc_8258F924;
	// twi 31,r0,22
loc_8258F924:
	// addi r30,r30,28
	r30.s64 = r30.s64 + 28;
	// b 0x8258f8c4
	goto loc_8258F8C4;
loc_8258F92C:
	// li r27,1
	r27.s64 = 1;
	// b 0x8258f938
	goto loc_8258F938;
loc_8258F934:
	// li r27,0
	r27.s64 = 0;
loc_8258F938:
	// lwz r3,436(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(436) );
	// li r29,0
	r29.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// bl 0x8258ef98
	sub_8258EF98(ctx, base);
	// lis r10,8965
	ctx.r10.s64 = 587530240;
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(104) );
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// ori r9,r10,64732
	ctx.r9.u64 = ctx.r10.u64 | 64732;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x8258f978
	if (!cr6.eq) goto loc_8258F978;
	// li r23,0
	r23.s64 = 0;
	// li r24,0
	r24.s64 = 0;
	// li r22,0
	r22.s64 = 0;
	// li r27,0
	r27.s64 = 0;
	// b 0x8258faf8
	goto loc_8258FAF8;
loc_8258F978:
	// lis r10,17610
	ctx.r10.s64 = 1154088960;
	// ori r9,r10,32357
	ctx.r9.u64 = ctx.r10.u64 | 32357;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x8258f9c8
	if (!cr6.eq) goto loc_8258F9C8;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(176) );
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// bl 0x8261b900
	sub_8261B900(ctx, base);
	// lwz r3,192(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(192) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8258f9b4
	if (!cr6.eq) goto loc_8258F9B4;
	// li r11,0
	r11.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// stw r11,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r11.u32);
	// b 0x8258fafc
	goto loc_8258FAFC;
loc_8258F9B4:
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r11.u32);
	// b 0x8258fafc
	goto loc_8258FAFC;
loc_8258F9C8:
	// lis r10,-10718
	ctx.r10.s64 = -702414848;
	// ori r9,r10,40965
	ctx.r9.u64 = ctx.r10.u64 | 40965;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x8258fa18
	if (!cr6.eq) goto loc_8258FA18;
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x8261b900
	sub_8261B900(ctx, base);
	// lwz r3,208(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(208) );
	// li r29,1
	r29.s64 = 1;
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// rlwinm r10,r11,27,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r26,r10,1
	r26.u64 = ctx.r10.u64 ^ 1;
	// beq cr6,0x8258fa0c
	if (cr6.eq) goto loc_8258FA0C;
	// addi r4,r1,208
	ctx.r4.s64 = ctx.r1.s64 + 208;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8258FA0C:
	// li r11,0
	r11.s64 = 0;
	// stw r11,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, r11.u32);
	// b 0x8258fafc
	goto loc_8258FAFC;
loc_8258FA18:
	// lis r10,11474
	ctx.r10.s64 = 751960064;
	// ori r9,r10,6347
	ctx.r9.u64 = ctx.r10.u64 | 6347;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x8258fa68
	if (!cr6.eq) goto loc_8258FA68;
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8261b900
	sub_8261B900(ctx, base);
	// lwz r3,224(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(224) );
	// li r30,1
	r30.s64 = 1;
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// rlwinm r10,r11,27,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r26,r10,1
	r26.u64 = ctx.r10.u64 ^ 1;
	// beq cr6,0x8258fa5c
	if (cr6.eq) goto loc_8258FA5C;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8258FA5C:
	// li r11,0
	r11.s64 = 0;
	// stw r11,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, r11.u32);
	// b 0x8258fafc
	goto loc_8258FAFC;
loc_8258FA68:
	// lis r10,-16232
	ctx.r10.s64 = -1063780352;
	// ori r9,r10,17909
	ctx.r9.u64 = ctx.r10.u64 | 17909;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x8258fac4
	if (!cr6.eq) goto loc_8258FAC4;
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// lwz r5,168(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(168) );
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// bl 0x8261b900
	sub_8261B900(ctx, base);
	// lwz r3,240(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(240) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258faa0
	if (cr6.eq) goto loc_8258FAA0;
	// lbz r10,455(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 455);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258faa4
	if (!cr6.eq) goto loc_8258FAA4;
loc_8258FAA0:
	// li r26,0
	r26.s64 = 0;
loc_8258FAA4:
	// li r31,1
	r31.s64 = 1;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258fab8
	if (cr6.eq) goto loc_8258FAB8;
	// addi r4,r1,240
	ctx.r4.s64 = ctx.r1.s64 + 240;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_8258FAB8:
	// li r11,0
	r11.s64 = 0;
	// stw r11,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, r11.u32);
	// b 0x8258fafc
	goto loc_8258FAFC;
loc_8258FAC4:
	// lbz r10,455(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 455);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8258fafc
	if (!cr6.eq) goto loc_8258FAFC;
	// li r11,0
	r11.s64 = 0;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r11.u32);
	// addi r5,r1,148
	ctx.r5.s64 = ctx.r1.s64 + 148;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// lwz r4,172(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(172) );
	// bl 0x823eab78
	sub_823EAB78(ctx, base);
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(148) );
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x8258fafc
	if (!cr6.eq) goto loc_8258FAFC;
loc_8258FAF8:
	// li r26,0
	r26.s64 = 0;
loc_8258FAFC:
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258fc70
	if (cr6.eq) goto loc_8258FC70;
	// lwz r4,164(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(164) );
	// bl 0x82303f38
	sub_82303F38(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258fb30
	if (cr6.eq) goto loc_8258FB30;
	// clrlwi r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x8258fb34
	if (!cr6.eq) goto loc_8258FB34;
loc_8258FB30:
	// li r11,0
	r11.s64 = 0;
loc_8258FB34:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258fb48
	if (cr6.eq) goto loc_8258FB48;
	// li r26,0
	r26.s64 = 0;
	// li r24,0
	r24.s64 = 0;
loc_8258FB48:
	// lwz r11,436(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(436) );
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// stb r23,124(r1)
	PPC_STORE_U8(ctx.r1.u32 + 124, r23.u8);
	// addi r4,r11,48
	ctx.r4.s64 = r11.s64 + 48;
	// stw r9,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r9.u32);
	// stb r26,125(r1)
	PPC_STORE_U8(ctx.r1.u32 + 125, r26.u8);
	// stb r24,126(r1)
	PPC_STORE_U8(ctx.r1.u32 + 126, r24.u8);
	// stb r29,127(r1)
	PPC_STORE_U8(ctx.r1.u32 + 127, r29.u8);
	// stb r30,128(r1)
	PPC_STORE_U8(ctx.r1.u32 + 128, r30.u8);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(4) );
	// stb r31,129(r1)
	PPC_STORE_U8(ctx.r1.u32 + 129, r31.u8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8258fb84
	if (!cr6.eq) goto loc_8258FB84;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x8258fb94
	goto loc_8258FB94;
loc_8258FB84:
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(8) );
	// li r8,12
	ctx.r8.s64 = 12;
	// subf r7,r11,r10
	ctx.r7.s64 = ctx.r10.s64 - r11.s64;
	// divw r10,r7,r8
	ctx.r10.s32 = ctx.r7.s32 / ctx.r8.s32;
loc_8258FB94:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258fbe0
	if (cr6.eq) goto loc_8258FBE0;
	// lwz r8,12(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(12) );
	// li r7,12
	ctx.r7.s64 = 12;
	// subf r6,r11,r8
	ctx.r6.s64 = ctx.r8.s64 - r11.s64;
	// divw r5,r6,r7
	ctx.r5.s32 = ctx.r6.s32 / ctx.r7.s32;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bge cr6,0x8258fbe0
	if (!cr6.lt) goto loc_8258FBE0;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(8) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258fbd4
	if (cr6.eq) goto loc_8258FBD4;
	// lwz r10,124(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(124) );
	// lwz r8,128(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(128) );
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
loc_8258FBD4:
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// b 0x8258fc08
	goto loc_8258FC08;
loc_8258FBE0:
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(8) );
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8258fbf0
	if (!cr6.gt) goto loc_8258FBF0;
	// twi 31,r0,22
loc_8258FBF0:
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// stw r4,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r4.u32);
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// stw r10,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r10.u32);
	// ld r5,112(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// bl 0x8272e828
	sub_8272E828(ctx, base);
loc_8258FC08:
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(180) );
	// bl 0x82345978
	sub_82345978(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,132
	ctx.r3.s64 = ctx.r1.s64 + 132;
	// li r5,-1
	ctx.r5.s64 = -1;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(88) );
	// bl 0x82345978
	sub_82345978(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// li r5,-1
	ctx.r5.s64 = -1;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
	// lwz r3,436(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(436) );
	// addi r6,r1,132
	ctx.r6.s64 = ctx.r1.s64 + 132;
	// addi r5,r1,136
	ctx.r5.s64 = ctx.r1.s64 + 136;
	// bl 0x8258fd30
	sub_8258FD30(ctx, base);
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,132
	ctx.r3.s64 = ctx.r1.s64 + 132;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_8258FC70:
	// cmpwi cr6,r19,-1
	cr6.compare<int32_t>(r19.s32, -1, xer);
	// beq cr6,0x8258fc9c
	if (cr6.eq) goto loc_8258FC9C;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// lwz r3,436(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(436) );
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// bl 0x82590338
	sub_82590338(ctx, base);
loc_8258FC9C:
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(160) );
	// lwz r27,436(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(436) );
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// lwz r28,144(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(144) );
	// stw r10,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r10.u32);
loc_8258FCB0:
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// cmpwi cr6,r19,7
	cr6.compare<int32_t>(r19.s32, 7, xer);
	// blt cr6,0x8258f7b8
	if (cr6.lt) goto loc_8258F7B8;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-29816
	ctx.r4.s64 = r11.s64 + -29816;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821da550
	sub_821DA550(ctx, base);
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// addi r6,r10,-29792
	ctx.r6.s64 = ctx.r10.s64 + -29792;
	// li r7,7
	ctx.r7.s64 = 7;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8258fd30
	sub_8258FD30(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,7
	ctx.r4.s64 = 7;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82590338
	sub_82590338(ctx, base);
	// lwz r3,152(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(152) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_8258FD28:
	// addi r1,r1,416
	ctx.r1.s64 = ctx.r1.s64 + 416;
	// b 0x82ca2c00
	return;
}

PPC_WEAK_FUNC(sub_8258F410) {
	__imp__sub_8258F410(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258FD30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// bl 0x82331308
	sub_82331308(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821e2cc8
	sub_821E2CC8(ctx, base);
	// lis r31,-31927
	r31.s64 = -2092367872;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r27,4(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x823f8a38
	sub_823F8A38(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,3436
	ctx.r4.s64 = ctx.r10.s64 + 3436;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r29,4(r9)
	r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823f8a38
	sub_823F8A38(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r8,-32244
	ctx.r8.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r8,3448
	ctx.r4.s64 = ctx.r8.s64 + 3448;
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r7,32(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r31,4(r7)
	r31.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(4) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x823f8a38
	sub_823F8A38(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8258fe48
	if (cr6.eq) goto loc_8258FE48;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f83d8
	sub_823F83D8(ctx, base);
loc_8258FE48:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8258fe68
	if (cr6.eq) goto loc_8258FE68;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8258fe68
	if (cr6.eq) goto loc_8258FE68;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82814d30
	sub_82814D30(ctx, base);
loc_8258FE68:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_8258FD30) {
	__imp__sub_8258FD30(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258FE70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,3456
	ctx.r4.s64 = r11.s64 + 3456;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r30,-31927
	r30.s64 = -2092367872;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r28,4(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f8a38
	sub_823F8A38(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r4,4(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// bl 0x823f9040
	sub_823F9040(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8258FE70) {
	__imp__sub_8258FE70(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258FEF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-29840
	ctx.r4.s64 = r11.s64 + -29840;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// lis r30,-31927
	r30.s64 = -2092367872;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r28,4(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f8a38
	sub_823F8A38(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r4,4(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// bl 0x823f9040
	sub_823F9040(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8258FEF0) {
	__imp__sub_8258FEF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8258FF68) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,3456
	ctx.r4.s64 = r11.s64 + 3456;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r30,-31927
	r30.s64 = -2092367872;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r31,4(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x823f8a38
	sub_823F8A38(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r4,4(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// bl 0x82283d80
	sub_82283D80(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82590074
	if (cr6.eq) goto loc_82590074;
	// clrlwi r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590074
	if (cr6.eq) goto loc_82590074;
	// lbz r11,4(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590074
	if (cr6.eq) goto loc_82590074;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r11,344
	ctx.r9.s64 = r11.s64 + 344;
	// stb r10,4(r28)
	PPC_STORE_U8(r28.u32 + 4, ctx.r10.u8);
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(12) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82590074
	if (cr6.eq) goto loc_82590074;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r11,23768(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(23768) );
	// addi r10,r11,-960
	ctx.r10.s64 = r11.s64 + -960;
	// srawi r9,r10,1
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 1;
	// addze r29,r9
	temp.s64 = ctx.r9.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r9.u32;
	r29.s64 = temp.s64;
	// bl 0x823f7780
	sub_823F7780(ctx, base);
	// extsw r8,r29
	ctx.r8.s64 = r29.s32;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// std r8,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r8.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f0
	ctx.f13.f64 = double(f0.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lwz r7,32(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lfs f11,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// lfs f3,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f2.f64 = double(temp.f32);
	// lwz r4,4(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(4) );
	// fsubs f1,f11,f12
	ctx.f1.f64 = static_cast<float>(ctx.f11.f64 - ctx.f12.f64);
	// bl 0x823f7678
	sub_823F7678(ctx, base);
loc_82590074:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8258FF68) {
	__imp__sub_8258FF68(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82590080) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// clrlwi r28,r23,24
	r28.u64 = r23.u32 & 0xFF;
	// lbz r11,28(r24)
	r11.u64 = PPC_LOAD_U8(r24.u32 + 28);
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x8259032c
	if (cr6.eq) goto loc_8259032C;
	// lis r30,-31927
	r30.s64 = -2092367872;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,26912(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r5,156(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(156) );
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// bl 0x822641f0
	sub_822641F0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// bl 0x822641f0
	sub_822641F0(ctx, base);
	// lwz r11,24(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + int32_t(24) );
	// li r25,0
	r25.s64 = 0;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r31,r25
	r31.u64 = r25.u64;
	// mr r27,r25
	r27.u64 = r25.u64;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82590188
	if (cr6.eq) goto loc_82590188;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82590138
	if (cr6.eq) goto loc_82590138;
	// lwz r10,36(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + int32_t(36) );
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// bne cr6,0x82590138
	if (!cr6.eq) goto loc_82590138;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82590124
	if (cr6.eq) goto loc_82590124;
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82590128
	if (!cr6.eq) goto loc_82590128;
loc_82590124:
	// mr r11,r25
	r11.u64 = r25.u64;
loc_82590128:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590138
	if (cr6.eq) goto loc_82590138;
	// li r31,1
	r31.s64 = 1;
loc_82590138:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x82590188
	if (cr6.eq) goto loc_82590188;
	// lwz r11,36(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(36) );
	// lwz r10,24(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + int32_t(24) );
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82590188
	if (!cr6.eq) goto loc_82590188;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82590174
	if (cr6.eq) goto loc_82590174;
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82590178
	if (!cr6.eq) goto loc_82590178;
loc_82590174:
	// mr r11,r25
	r11.u64 = r25.u64;
loc_82590178:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590188
	if (cr6.eq) goto loc_82590188;
	// li r27,1
	r27.s64 = 1;
loc_82590188:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82590294
	if (cr6.eq) goto loc_82590294;
	// clrlwi r10,r31,24
	ctx.r10.u64 = r31.u32 & 0xFF;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// addi r30,r11,23272
	r30.s64 = r11.s64 + 23272;
	// beq cr6,0x82590208
	if (cr6.eq) goto loc_82590208;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x825901d8
	if (cr6.eq) goto loc_825901D8;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82335168
	sub_82335168(ctx, base);
	// mr r11,r31
	r11.u64 = r31.u64;
	// stw r30,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r30.u32);
	// b 0x825901dc
	goto loc_825901DC;
loc_825901D8:
	// mr r11,r25
	r11.u64 = r25.u64;
loc_825901DC:
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825901f8
	if (cr6.eq) goto loc_825901F8;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x82590200
	goto loc_82590200;
loc_825901F8:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
loc_82590200:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8238f350
	sub_8238F350(ctx, base);
loc_82590208:
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590328
	if (cr6.eq) goto loc_82590328;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82590248
	if (cr6.eq) goto loc_82590248;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82335168
	sub_82335168(ctx, base);
	// mr r11,r31
	r11.u64 = r31.u64;
	// stw r30,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r30.u32);
	// b 0x8259024c
	goto loc_8259024C;
loc_82590248:
	// mr r11,r25
	r11.u64 = r25.u64;
loc_8259024C:
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590278
	if (cr6.eq) goto loc_82590278;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8238f350
	sub_8238F350(ctx, base);
	// stb r23,28(r24)
	PPC_STORE_U8(r24.u32 + 28, r23.u8);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	return;
loc_82590278:
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8238f350
	sub_8238F350(ctx, base);
	// stb r23,28(r24)
	PPC_STORE_U8(r24.u32 + 28, r23.u8);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	return;
loc_82590294:
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825902e0
	if (cr6.eq) goto loc_825902E0;
	// lwz r11,26912(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26912) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825902b8
	if (cr6.eq) goto loc_825902B8;
	// lbz r11,26821(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 26821);
	// b 0x825902bc
	goto loc_825902BC;
loc_825902B8:
	// mr r11,r25
	r11.u64 = r25.u64;
loc_825902BC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825902e0
	if (cr6.eq) goto loc_825902E0;
	// lwz r11,26912(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26912) );
	// li r5,5
	ctx.r5.s64 = 5;
	// lwz r4,36(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + int32_t(36) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,128(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(128) );
	// bl 0x8233a810
	sub_8233A810(ctx, base);
loc_825902E0:
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590328
	if (cr6.eq) goto loc_82590328;
	// lwz r11,26912(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26912) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590300
	if (cr6.eq) goto loc_82590300;
	// lbz r11,26821(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 26821);
	// b 0x82590304
	goto loc_82590304;
loc_82590300:
	// mr r11,r25
	r11.u64 = r25.u64;
loc_82590304:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590328
	if (cr6.eq) goto loc_82590328;
	// lwz r11,26912(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26912) );
	// li r5,5
	ctx.r5.s64 = 5;
	// lwz r4,36(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + int32_t(36) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,128(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(128) );
	// bl 0x8233a810
	sub_8233A810(ctx, base);
loc_82590328:
	// stb r23,28(r24)
	PPC_STORE_U8(r24.u32 + 28, r23.u8);
loc_8259032C:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_82590080) {
	__imp__sub_82590080(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82590338) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// mr r30,r8
	r30.u64 = ctx.r8.u64;
	// mr r29,r9
	r29.u64 = ctx.r9.u64;
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
	// bl 0x82590568
	sub_82590568(ctx, base);
	// clrlwi r11,r26,24
	r11.u64 = r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825903a8
	if (cr6.eq) goto loc_825903A8;
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825903a0
	if (cr6.eq) goto loc_825903A0;
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r11,r9,1
	r11.u64 = ctx.r9.u64 ^ 1;
	// addi r5,r11,2
	ctx.r5.s64 = r11.s64 + 2;
	// b 0x825903ac
	goto loc_825903AC;
loc_825903A0:
	// li r5,1
	ctx.r5.s64 = 1;
	// b 0x825903ac
	goto loc_825903AC;
loc_825903A8:
	// li r5,4
	ctx.r5.s64 = 4;
loc_825903AC:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825904f8
	sub_825904F8(ctx, base);
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r5,r11,-29828
	ctx.r5.s64 = r11.s64 + -29828;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821e2cc8
	sub_821E2CC8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x825904f8
	sub_825904F8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// clrlwi r10,r29,24
	ctx.r10.u64 = r29.u32 & 0xFF;
	// lis r9,-31926
	ctx.r9.s64 = -2092302336;
	// cntlzw r8,r10
	ctx.r8.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// addi r5,r9,-29824
	ctx.r5.s64 = ctx.r9.s64 + -29824;
	// rlwinm r7,r8,27,31,31
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// xori r11,r7,1
	r11.u64 = ctx.r7.u64 ^ 1;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
	// bl 0x821e2cc8
	sub_821E2CC8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x825904f8
	sub_825904F8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// clrlwi r6,r28,24
	ctx.r6.u64 = r28.u32 & 0xFF;
	// lis r5,-31926
	ctx.r5.s64 = -2092302336;
	// cntlzw r4,r6
	ctx.r4.u64 = ctx.r6.u32 == 0 ? 32 : __builtin_clz(ctx.r6.u32);
	// addi r5,r5,-29820
	ctx.r5.s64 = ctx.r5.s64 + -29820;
	// rlwinm r3,r4,27,31,31
	ctx.r3.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// xori r11,r3,1
	r11.u64 = ctx.r3.u64 ^ 1;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
	// bl 0x821e2cc8
	sub_821E2CC8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x825904f8
	sub_825904F8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82590338) {
	__imp__sub_82590338(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82590478) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// clrlwi r9,r6,24
	ctx.r9.u64 = ctx.r6.u32 & 0xFF;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cntlzw r8,r9
	ctx.r8.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// rlwinm r7,r8,27,31,31
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// lis r9,-31926
	ctx.r9.s64 = -2092302336;
	// xori r11,r7,1
	r11.u64 = ctx.r7.u64 ^ 1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// addi r29,r9,-29828
	r29.s64 = ctx.r9.s64 + -29828;
	// addi r31,r11,1
	r31.s64 = r11.s64 + 1;
	// bl 0x82590568
	sub_82590568(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x821e2cc8
	sub_821E2CC8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x825904f8
	sub_825904F8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82590478) {
	__imp__sub_82590478(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825904F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// lis r30,-31927
	r30.s64 = -2092367872;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r28,4(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f8a38
	sub_823F8A38(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r4,4(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// bl 0x823f9040
	sub_823F9040(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_825904F8) {
	__imp__sub_825904F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82590568) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// clrlwi r11,r6,24
	r11.u64 = ctx.r6.u32 & 0xFF;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259059c
	if (cr6.eq) goto loc_8259059C;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r4,r11,-29836
	ctx.r4.s64 = r11.s64 + -29836;
	// b 0x825905a4
	goto loc_825905A4;
loc_8259059C:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r4,r11,-29832
	ctx.r4.s64 = r11.s64 + -29832;
loc_825905A4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82331308
	sub_82331308(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821ec668
	sub_821EC668(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82590568) {
	__imp__sub_82590568(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825905E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259069c
	if (cr6.eq) goto loc_8259069C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82590698
	if (cr6.eq) goto loc_82590698;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590648
	if (cr6.eq) goto loc_82590648;
	// lbz r10,144(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 144);
	// rlwinm r9,r10,0,25,25
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// li r10,1
	ctx.r10.s64 = 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8259064c
	if (!cr6.eq) goto loc_8259064C;
loc_82590648:
	// li r10,0
	ctx.r10.s64 = 0;
loc_8259064C:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825907a4
	if (cr6.eq) goto loc_825907A4;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// li r3,0
	ctx.r3.s64 = 0;
	// rlwinm r9,r10,31,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8259076c
	if (cr6.eq) goto loc_8259076C;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825906a4
	if (cr6.eq) goto loc_825906A4;
	// lbz r10,33(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 33);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82590770
	goto loc_82590770;
loc_82590698:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_8259069C:
	// li r11,0
	r11.s64 = 0;
	// b 0x82590648
	goto loc_82590648;
loc_825906A4:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// subf r8,r10,r6
	ctx.r8.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r8,3
	xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x7) != 0);
	r11.s64 = ctx.r8.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82590714
	if (!cr0.gt) goto loc_82590714;
loc_825906C4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825906e4
	if (cr6.lt) goto loc_825906E4;
	// li r7,0
	ctx.r7.s64 = 0;
loc_825906E4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82590700
	if (cr6.eq) goto loc_82590700;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82590708
	goto loc_82590708;
loc_82590700:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82590708:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825906c4
	if (cr6.gt) goto loc_825906C4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82590714:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82590758
	if (cr6.eq) goto loc_82590758;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82590730
	if (cr6.gt) goto loc_82590730;
	// li r11,0
	r11.s64 = 0;
loc_82590730:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82590758
	if (!cr6.eq) goto loc_82590758;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82590770
	goto loc_82590770;
loc_82590758:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82590770
	goto loc_82590770;
loc_8259076C:
	// li r11,0
	r11.s64 = 0;
loc_82590770:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825907a4
	if (cr6.eq) goto loc_825907A4;
	// bl 0x821ee210
	sub_821EE210(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825907a4
	if (cr6.eq) goto loc_825907A4;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r3,r11,-29804
	ctx.r3.s64 = r11.s64 + -29804;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
loc_825907A4:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r3,r11,-29808
	ctx.r3.s64 = r11.s64 + -29808;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825905E8) {
	__imp__sub_825905E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825907C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590874
	if (cr6.eq) goto loc_82590874;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82590870
	if (cr6.eq) goto loc_82590870;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590820
	if (cr6.eq) goto loc_82590820;
	// lbz r10,144(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 144);
	// rlwinm r9,r10,0,25,25
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// li r10,1
	ctx.r10.s64 = 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82590824
	if (!cr6.eq) goto loc_82590824;
loc_82590820:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82590824:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8259097c
	if (cr6.eq) goto loc_8259097C;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// li r3,0
	ctx.r3.s64 = 0;
	// rlwinm r9,r10,31,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82590944
	if (cr6.eq) goto loc_82590944;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8259087c
	if (cr6.eq) goto loc_8259087C;
	// lbz r10,33(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 33);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82590948
	goto loc_82590948;
loc_82590870:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82590874:
	// li r11,0
	r11.s64 = 0;
	// b 0x82590820
	goto loc_82590820;
loc_8259087C:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// subf r8,r10,r6
	ctx.r8.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r8,3
	xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x7) != 0);
	r11.s64 = ctx.r8.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825908ec
	if (!cr0.gt) goto loc_825908EC;
loc_8259089C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825908bc
	if (cr6.lt) goto loc_825908BC;
	// li r7,0
	ctx.r7.s64 = 0;
loc_825908BC:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825908d8
	if (cr6.eq) goto loc_825908D8;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825908e0
	goto loc_825908E0;
loc_825908D8:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825908E0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8259089c
	if (cr6.gt) goto loc_8259089C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_825908EC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82590930
	if (cr6.eq) goto loc_82590930;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82590908
	if (cr6.gt) goto loc_82590908;
	// li r11,0
	r11.s64 = 0;
loc_82590908:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82590930
	if (!cr6.eq) goto loc_82590930;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82590948
	goto loc_82590948;
loc_82590930:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82590948
	goto loc_82590948;
loc_82590944:
	// li r11,0
	r11.s64 = 0;
loc_82590948:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259097c
	if (cr6.eq) goto loc_8259097C;
	// bl 0x821ee210
	sub_821EE210(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259097c
	if (cr6.eq) goto loc_8259097C;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r3,r11,-29796
	ctx.r3.s64 = r11.s64 + -29796;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
loc_8259097C:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r3,r11,-29800
	ctx.r3.s64 = r11.s64 + -29800;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825907C0) {
	__imp__sub_825907C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82590998) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-29768
	ctx.r4.s64 = r11.s64 + -29768;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// lis r28,-31927
	r28.s64 = -2092367872;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r29,4(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823f8a38
	sub_823F8A38(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r9,-31926
	ctx.r9.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r9,-29764
	ctx.r4.s64 = ctx.r9.s64 + -29764;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r8,32(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r28,4(r8)
	r28.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(4) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f8a38
	sub_823F8A38(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lbz r7,13(r31)
	ctx.r7.u64 = PPC_LOAD_U8(r31.u32 + 13);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82590afc
	if (cr6.eq) goto loc_82590AFC;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x82590ac4
	if (cr6.lt) goto loc_82590AC4;
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(52) );
	// li r10,12
	ctx.r10.s64 = 12;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590a68
	if (cr6.eq) goto loc_82590A68;
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(56) );
	// subf r8,r11,r9
	ctx.r8.s64 = ctx.r9.s64 - r11.s64;
	// divw r11,r8,r10
	r11.s32 = ctx.r8.s32 / ctx.r10.s32;
loc_82590A68:
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// bge cr6,0x82590ac4
	if (!cr6.lt) goto loc_82590AC4;
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(52) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590a90
	if (cr6.eq) goto loc_82590A90;
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(56) );
	// subf r8,r11,r9
	ctx.r8.s64 = ctx.r9.s64 - r11.s64;
	// divw r7,r8,r10
	ctx.r7.s32 = ctx.r8.s32 / ctx.r10.s32;
	// cmplw cr6,r30,r7
	cr6.compare<uint32_t>(r30.u32, ctx.r7.u32, xer);
	// blt cr6,0x82590a94
	if (cr6.lt) goto loc_82590A94;
loc_82590A90:
	// twi 31,r0,22
loc_82590A94:
	// rlwinm r10,r30,1,0,30
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r30,r10
	ctx.r10.u64 = r30.u64 + ctx.r10.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lbz r8,6(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 6);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82590ac4
	if (cr6.eq) goto loc_82590AC4;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82590adc
	if (cr6.eq) goto loc_82590ADC;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r4,r11,-29780
	ctx.r4.s64 = r11.s64 + -29780;
	// b 0x82590ad4
	goto loc_82590AD4;
loc_82590AC4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82590adc
	if (cr6.eq) goto loc_82590ADC;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// addi r4,r11,-29784
	ctx.r4.s64 = r11.s64 + -29784;
loc_82590AD4:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823f83d8
	sub_823F83D8(ctx, base);
loc_82590ADC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82590b2c
	if (cr6.eq) goto loc_82590B2C;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r4,r11,-29772
	ctx.r4.s64 = r11.s64 + -29772;
	// bl 0x823f83d8
	sub_823F83D8(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
loc_82590AFC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82590b14
	if (cr6.eq) goto loc_82590B14;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r4,r11,-29784
	ctx.r4.s64 = r11.s64 + -29784;
	// bl 0x823f83d8
	sub_823F83D8(ctx, base);
loc_82590B14:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82590b2c
	if (cr6.eq) goto loc_82590B2C;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r4,r11,-29776
	ctx.r4.s64 = r11.s64 + -29776;
	// bl 0x823f83d8
	sub_823F83D8(ctx, base);
loc_82590B2C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82590998) {
	__imp__sub_82590998(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82590B38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// li r5,-1
	ctx.r5.s64 = -1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// li r5,-1
	ctx.r5.s64 = -1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// li r5,-1
	ctx.r5.s64 = -1;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stb r11,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r11.u8);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82590B38) {
	__imp__sub_82590B38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82590BA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r9,20
	ctx.r9.s64 = 20;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82590bd0
	if (!cr6.eq) goto loc_82590BD0;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82590bdc
	goto loc_82590BDC;
loc_82590BD0:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// subf r8,r11,r10
	ctx.r8.s64 = ctx.r10.s64 - r11.s64;
	// divw r10,r8,r9
	ctx.r10.s32 = ctx.r8.s32 / ctx.r9.s32;
loc_82590BDC:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590c18
	if (cr6.eq) goto loc_82590C18;
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + int32_t(12) );
	// subf r7,r11,r8
	ctx.r7.s64 = ctx.r8.s64 - r11.s64;
	// divw r6,r7,r9
	ctx.r6.s32 = ctx.r7.s32 / ctx.r9.s32;
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// bge cr6,0x82590c18
	if (!cr6.lt) goto loc_82590C18;
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82590c0c
	if (cr6.eq) goto loc_82590C0C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82591170
	sub_82591170(ctx, base);
loc_82590C0C:
	// addi r11,r30,20
	r11.s64 = r30.s64 + 20;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// b 0x82590c44
	goto loc_82590C44;
loc_82590C18:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x82590c28
	if (!cr6.gt) goto loc_82590C28;
	// twi 31,r0,22
loc_82590C28:
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// ld r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// bl 0x82590ce0
	sub_82590CE0(ctx, base);
loc_82590C44:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82590BA0) {
	__imp__sub_82590BA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82590C60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r8,4(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(4) );
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(8) );
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// ble cr6,0x82590c7c
	if (!cr6.gt) goto loc_82590C7C;
	// twi 31,r0,22
	// twi 31,r0,22
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
loc_82590C7C:
	// beqlr cr6
	if (cr6.eq) return;
	// li r7,12
	ctx.r7.s64 = 12;
	// subf r9,r11,r11
	ctx.r9.s64 = r11.s64 - r11.s64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// divw r9,r9,r7
	ctx.r9.s32 = ctx.r9.s32 / ctx.r7.s32;
	// cmplw cr6,r11,r11
	cr6.compare<uint32_t>(r11.u32, r11.u32, xer);
	// rlwinm r7,r9,1,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// add r6,r9,r7
	ctx.r6.u64 = ctx.r9.u64 + ctx.r7.u64;
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r9,r8
	ctx.r7.u64 = ctx.r9.u64 + ctx.r8.u64;
	// beq cr6,0x82590cd4
	if (cr6.eq) goto loc_82590CD4;
	// subf r9,r11,r8
	ctx.r9.s64 = ctx.r8.s64 - r11.s64;
loc_82590CAC:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// add r6,r9,r10
	ctx.r6.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stwx r8,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r8.u32);
	// lwz r5,4(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// stw r5,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r5.u32);
	// lwz r4,8(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(8) );
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r4,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r4.u32);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82590cac
	if (!cr6.eq) goto loc_82590CAC;
loc_82590CD4:
	// stw r7,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r7.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82590C60) {
	__imp__sub_82590C60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82590CE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// std r4,160(r1)
	PPC_STORE_U64(ctx.r1.u32 + 160, ctx.r4.u64);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590d1c
	if (cr6.eq) goto loc_82590D1C;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// li r9,20
	ctx.r9.s64 = 20;
	// subf r8,r11,r10
	ctx.r8.s64 = ctx.r10.s64 - r11.s64;
	// divw. r7,r8,r9
	ctx.r7.s32 = ctx.r8.s32 / ctx.r9.s32;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82590d24
	if (!cr0.eq) goto loc_82590D24;
loc_82590D1C:
	// li r30,0
	r30.s64 = 0;
	// b 0x82590d54
	goto loc_82590D54;
loc_82590D24:
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x82590d30
	if (!cr6.gt) goto loc_82590D30;
	// twi 31,r0,22
loc_82590D30:
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(160) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82590d44
	if (cr6.eq) goto loc_82590D44;
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// beq cr6,0x82590d48
	if (cr6.eq) goto loc_82590D48;
loc_82590D44:
	// twi 31,r0,22
loc_82590D48:
	// lwz r10,164(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(164) );
	// subf r8,r11,r10
	ctx.r8.s64 = ctx.r10.s64 - r11.s64;
	// divw r30,r8,r9
	r30.s32 = ctx.r8.s32 / ctx.r9.s32;
loc_82590D54:
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82590e28
	sub_82590E28(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x82590d74
	if (!cr6.gt) goto loc_82590D74;
	// twi 31,r0,22
loc_82590D74:
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// add r8,r30,r10
	ctx.r8.u64 = r30.u64 + ctx.r10.u64;
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// ld r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// std r7,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r7.u64);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x82590dac
	if (cr6.gt) goto loc_82590DAC;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x82590db0
	if (!cr6.lt) goto loc_82590DB0;
loc_82590DAC:
	// twi 31,r0,22
loc_82590DB0:
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,0(r29)
	PPC_STORE_U64(r29.u32 + 0, r11.u64);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82590CE0) {
	__imp__sub_82590CE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82590DC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r29,r30
	r29.u64 = r30.u64;
	// mr r31,r28
	r31.u64 = r28.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82590e10
	if (cr6.eq) goto loc_82590E10;
loc_82590DF0:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82590e04
	if (cr6.eq) goto loc_82590E04;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82591170
	sub_82591170(ctx, base);
loc_82590E04:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r31,r31,20
	r31.s64 = r31.s64 + 20;
	// bne 0x82590df0
	if (!cr0.eq) goto loc_82590DF0;
loc_82590E10:
	// rlwinm r11,r30,2,0,29
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r28
	ctx.r3.u64 = r11.u64 + r28.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82590DC8) {
	__imp__sub_82590DC8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82590E28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// std r4,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.r4.u64);
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82591170
	sub_82591170(ctx, base);
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(4) );
	// li r24,20
	r24.s64 = 20;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82590e60
	if (!cr6.eq) goto loc_82590E60;
	// li r9,0
	ctx.r9.s64 = 0;
	// b 0x82590e6c
	goto loc_82590E6C;
loc_82590E60:
	// lwz r10,12(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + int32_t(12) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// divw r9,r9,r24
	ctx.r9.s32 = ctx.r9.s32 / r24.s32;
loc_82590E6C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82590e7c
	if (!cr6.eq) goto loc_82590E7C;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82590e88
	goto loc_82590E88;
loc_82590E7C:
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// subf r8,r11,r10
	ctx.r8.s64 = ctx.r10.s64 - r11.s64;
	// divw r10,r8,r24
	ctx.r10.s32 = ctx.r8.s32 / r24.s32;
loc_82590E88:
	// lis r8,3276
	ctx.r8.s64 = 214695936;
	// ori r8,r8,52428
	ctx.r8.u64 = ctx.r8.u64 | 52428;
	// subf r7,r10,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r10.s64;
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// bge cr6,0x82590ea4
	if (!cr6.lt) goto loc_82590EA4;
	// bl 0x82684b38
	sub_82684B38(ctx, base);
	// b 0x82591144
	goto loc_82591144;
loc_82590EA4:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82590eb4
	if (!cr6.eq) goto loc_82590EB4;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82590ec0
	goto loc_82590EC0;
loc_82590EB4:
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// subf r7,r11,r10
	ctx.r7.s64 = ctx.r10.s64 - r11.s64;
	// divw r10,r7,r24
	ctx.r10.s32 = ctx.r7.s32 / r24.s32;
loc_82590EC0:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bge cr6,0x82591028
	if (!cr6.lt) goto loc_82591028;
	// rlwinm r10,r9,31,1,31
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x7FFFFFFF;
	// li r25,0
	r25.s64 = 0;
	// subf r8,r10,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r10.s64;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x82590ee4
	if (cr6.lt) goto loc_82590EE4;
	// add r25,r10,r9
	r25.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_82590EE4:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82590ef4
	if (!cr6.eq) goto loc_82590EF4;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82590f00
	goto loc_82590F00;
loc_82590EF4:
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// divw r10,r9,r24
	ctx.r10.s32 = ctx.r9.s32 / r24.s32;
loc_82590F00:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r25,r10
	cr6.compare<uint32_t>(r25.u32, ctx.r10.u32, xer);
	// bge cr6,0x82590f24
	if (!cr6.lt) goto loc_82590F24;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82590f20
	if (cr6.eq) goto loc_82590F20;
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// divw r11,r9,r24
	r11.s32 = ctx.r9.s32 / r24.s32;
loc_82590F20:
	// addi r25,r11,1
	r25.s64 = r11.s64 + 1;
loc_82590F24:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8273fa80
	sub_8273FA80(ctx, base);
	// lwz r31,4(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + int32_t(4) );
	// lwz r29,204(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(204) );
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// mr r30,r26
	r30.u64 = r26.u64;
	// beq cr6,0x82590f6c
	if (cr6.eq) goto loc_82590F6C;
loc_82590F48:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82590f5c
	if (cr6.eq) goto loc_82590F5C;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82591170
	sub_82591170(ctx, base);
loc_82590F5C:
	// addi r31,r31,20
	r31.s64 = r31.s64 + 20;
	// addi r30,r30,20
	r30.s64 = r30.s64 + 20;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bne cr6,0x82590f48
	if (!cr6.eq) goto loc_82590F48;
loc_82590F6C:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82590dc8
	sub_82590DC8(ctx, base);
	// lwz r28,8(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplw cr6,r29,r28
	cr6.compare<uint32_t>(r29.u32, r28.u32, xer);
	// beq cr6,0x82590fb8
	if (cr6.eq) goto loc_82590FB8;
	// subf r30,r31,r29
	r30.s64 = r29.s64 - r31.s64;
loc_82590F94:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82590fa8
	if (cr6.eq) goto loc_82590FA8;
	// add r4,r31,r30
	ctx.r4.u64 = r31.u64 + r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82591170
	sub_82591170(ctx, base);
loc_82590FA8:
	// addi r31,r31,20
	r31.s64 = r31.s64 + 20;
	// add r11,r31,r30
	r11.u64 = r31.u64 + r30.u64;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x82590f94
	if (!cr6.eq) goto loc_82590F94;
loc_82590FB8:
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + int32_t(4) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82590fcc
	if (!cr6.eq) goto loc_82590FCC;
	// li r11,0
	r11.s64 = 0;
	// b 0x82590fd8
	goto loc_82590FD8;
loc_82590FCC:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// subf r10,r3,r11
	ctx.r10.s64 = r11.s64 - ctx.r3.s64;
	// divw r11,r10,r24
	r11.s32 = ctx.r10.s32 / r24.s32;
loc_82590FD8:
	// addi r31,r11,1
	r31.s64 = r11.s64 + 1;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82590ff8
	if (cr6.eq) goto loc_82590FF8;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r4,8(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// bl 0x823fb420
	sub_823FB420(ctx, base);
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + int32_t(4) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_82590FF8:
	// rlwinm r11,r25,2,0,29
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r26,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r26.u32);
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r25,r11
	r11.u64 = r25.u64 + r11.u64;
	// add r9,r31,r10
	ctx.r9.u64 = r31.u64 + ctx.r10.u64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r9,2,0,29
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r10,r26
	ctx.r8.u64 = ctx.r10.u64 + r26.u64;
	// add r7,r11,r26
	ctx.r7.u64 = r11.u64 + r26.u64;
	// stw r8,12(r27)
	PPC_STORE_U32(r27.u32 + 12, ctx.r8.u32);
	// stw r7,8(r27)
	PPC_STORE_U32(r27.u32 + 8, ctx.r7.u32);
	// b 0x82591144
	goto loc_82591144;
loc_82591028:
	// lwz r26,204(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(204) );
	// lwz r28,8(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// subf r11,r26,r28
	r11.s64 = r28.s64 - r26.s64;
	// divw r10,r11,r24
	ctx.r10.s32 = r11.s32 / r24.s32;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bge cr6,0x825910a4
	if (!cr6.lt) goto loc_825910A4;
	// addi r31,r26,20
	r31.s64 = r26.s64 + 20;
	// cmplw cr6,r26,r28
	cr6.compare<uint32_t>(r26.u32, r28.u32, xer);
	// beq cr6,0x82591074
	if (cr6.eq) goto loc_82591074;
	// addi r30,r31,-20
	r30.s64 = r31.s64 + -20;
loc_82591050:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82591064
	if (cr6.eq) goto loc_82591064;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82591170
	sub_82591170(ctx, base);
loc_82591064:
	// addi r30,r30,20
	r30.s64 = r30.s64 + 20;
	// addi r31,r31,20
	r31.s64 = r31.s64 + 20;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// bne cr6,0x82591050
	if (!cr6.eq) goto loc_82591050;
loc_82591074:
	// lwz r4,8(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// subf r11,r26,r4
	r11.s64 = ctx.r4.s64 - r26.s64;
	// divw r10,r11,r24
	ctx.r10.s32 = r11.s32 / r24.s32;
	// subfic r5,r10,1
	xer.ca = ctx.r10.u32 <= 1;
	ctx.r5.s64 = 1 - ctx.r10.s64;
	// bl 0x82590dc8
	sub_82590DC8(ctx, base);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(8) );
	// addi r11,r11,20
	r11.s64 = r11.s64 + 20;
	// stw r11,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r11.u32);
	// addi r4,r11,-20
	ctx.r4.s64 = r11.s64 + -20;
	// b 0x82591138
	goto loc_82591138;
loc_825910A4:
	// addi r30,r28,-20
	r30.s64 = r28.s64 + -20;
	// mr r31,r28
	r31.u64 = r28.u64;
	// mr r29,r30
	r29.u64 = r30.u64;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// beq cr6,0x825910dc
	if (cr6.eq) goto loc_825910DC;
loc_825910B8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x825910cc
	if (cr6.eq) goto loc_825910CC;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82591170
	sub_82591170(ctx, base);
loc_825910CC:
	// addi r29,r29,20
	r29.s64 = r29.s64 + 20;
	// addi r31,r31,20
	r31.s64 = r31.s64 + 20;
	// cmplw cr6,r29,r28
	cr6.compare<uint32_t>(r29.u32, r28.u32, xer);
	// bne cr6,0x825910b8
	if (!cr6.eq) goto loc_825910B8;
loc_825910DC:
	// stw r31,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r31.u32);
	// cmplw cr6,r26,r30
	cr6.compare<uint32_t>(r26.u32, r30.u32, xer);
	// beq cr6,0x82591134
	if (cr6.eq) goto loc_82591134;
	// addi r31,r30,28
	r31.s64 = r30.s64 + 28;
loc_825910EC:
	// addi r30,r30,-20
	r30.s64 = r30.s64 + -20;
	// addi r31,r31,-20
	r31.s64 = r31.s64 + -20;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,-8
	ctx.r3.s64 = r31.s64 + -8;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// addi r4,r31,-24
	ctx.r4.s64 = r31.s64 + -24;
	// addi r3,r31,-4
	ctx.r3.s64 = r31.s64 + -4;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// addi r4,r31,-20
	ctx.r4.s64 = r31.s64 + -20;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = r31.s64 + -16;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// lbz r11,-12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + -12);
	// cmplw cr6,r30,r26
	cr6.compare<uint32_t>(r30.u32, r26.u32, xer);
	// stb r11,8(r31)
	PPC_STORE_U8(r31.u32 + 8, r11.u8);
	// bne cr6,0x825910ec
	if (!cr6.eq) goto loc_825910EC;
loc_82591134:
	// addi r4,r26,20
	ctx.r4.s64 = r26.s64 + 20;
loc_82591138:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x825911d8
	sub_825911D8(ctx, base);
loc_82591144:
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_82590E28) {
	__imp__sub_82590E28(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82591170) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// addi r4,r30,4
	ctx.r4.s64 = r30.s64 + 4;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r4,r30,8
	ctx.r4.s64 = r30.s64 + 8;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// addi r4,r30,12
	ctx.r4.s64 = r30.s64 + 12;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// lbz r11,16(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stb r11,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r11.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82591170) {
	__imp__sub_82591170(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825911D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// cmplw cr6,r3,r26
	cr6.compare<uint32_t>(ctx.r3.u32, r26.u32, xer);
	// beq cr6,0x8259124c
	if (cr6.eq) goto loc_8259124C;
	// addi r29,r30,4
	r29.s64 = r30.s64 + 4;
	// addi r28,r30,8
	r28.s64 = r30.s64 + 8;
	// addi r27,r30,12
	r27.s64 = r30.s64 + 12;
	// addi r31,r3,8
	r31.s64 = ctx.r3.s64 + 8;
loc_82591204:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,-8
	ctx.r3.s64 = r31.s64 + -8;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r31,-4
	ctx.r3.s64 = r31.s64 + -4;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// lbz r11,16(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 16);
	// stb r11,8(r31)
	PPC_STORE_U8(r31.u32 + 8, r11.u8);
	// addi r31,r31,20
	r31.s64 = r31.s64 + 20;
	// addi r10,r31,-8
	ctx.r10.s64 = r31.s64 + -8;
	// cmplw cr6,r10,r26
	cr6.compare<uint32_t>(ctx.r10.u32, r26.u32, xer);
	// bne cr6,0x82591204
	if (!cr6.eq) goto loc_82591204;
loc_8259124C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_825911D8) {
	__imp__sub_825911D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82591258) {
	PPC_FUNC_PROLOGUE();
	// addi r3,r3,48
	ctx.r3.s64 = ctx.r3.s64 + 48;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82591258) {
	__imp__sub_82591258(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82591260) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r30,0
	r30.s64 = 0;
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// addi r9,r11,3880
	ctx.r9.s64 = r11.s64 + 3880;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// addi r8,r10,5732
	ctx.r8.s64 = ctx.r10.s64 + 5732;
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// stw r8,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r8.u32);
	// stw r30,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r30.u32);
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// lis r7,-31927
	ctx.r7.s64 = -2092367872;
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// addi r4,r7,28340
	ctx.r4.s64 = ctx.r7.s64 + 28340;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
loc_825912C0:
	// mfmsr r5
	// mtmsrd r13,1
	// lwarx r6,0,r3
	reserved.u32 = *(uint32_t*)(base + ctx.r3.u32);
	ctx.r6.u64 = __builtin_bswap32(reserved.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// stwcx. r6,0,r3
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r3.u32), reserved.s32, __builtin_bswap32(ctx.r6.s32));
	cr0.so = xer.so;
	// mtmsrd r5,1
	// bne 0x825912c0
	if (!cr0.eq) goto loc_825912C0;
	// stw r30,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r30.u32);
loc_825912E0:
	// mfmsr r10
	// mtmsrd r13,1
	// lwarx r11,0,r4
	reserved.u32 = *(uint32_t*)(base + ctx.r4.u32);
	r11.u64 = __builtin_bswap32(reserved.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwcx. r11,0,r4
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r4.u32), reserved.s32, __builtin_bswap32(r11.s32));
	cr0.so = xer.so;
	// mtmsrd r10,1
	// bne 0x825912e0
	if (!cr0.eq) goto loc_825912E0;
	// lis r9,-32242
	ctx.r9.s64 = -2113011712;
	// stb r30,44(r31)
	PPC_STORE_U8(r31.u32 + 44, r30.u8);
	// lis r8,-32246
	ctx.r8.s64 = -2113273856;
	// stb r30,45(r31)
	PPC_STORE_U8(r31.u32 + 45, r30.u8);
	// li r7,-100
	ctx.r7.s64 = -100;
	// stb r30,46(r31)
	PPC_STORE_U8(r31.u32 + 46, r30.u8);
	// addi r6,r9,18492
	ctx.r6.s64 = ctx.r9.s64 + 18492;
	// stw r7,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r7.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r30,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r30.u32);
	// addi r3,r31,112
	ctx.r3.s64 = r31.s64 + 112;
	// stw r30,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r30.u32);
	// lfs f0,-27468(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -27468);
	f0.f64 = double(temp.f32);
	// stw r30,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r30.u32);
	// addi r11,r31,68
	r11.s64 = r31.s64 + 68;
	// stw r6,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r6.u32);
	// stfs f0,68(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 68, temp.u32);
	// stw r30,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r30.u32);
	// addi r11,r31,48
	r11.s64 = r31.s64 + 48;
	// stw r30,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r30.u32);
	// stw r30,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r30.u32);
	// stw r30,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r30.u32);
	// stw r30,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r30.u32);
	// stw r30,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r30.u32);
	// stw r30,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r30.u32);
	// stb r30,108(r31)
	PPC_STORE_U8(r31.u32 + 108, r30.u8);
	// stb r5,109(r31)
	PPC_STORE_U8(r31.u32 + 109, ctx.r5.u8);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r4,-32242
	ctx.r4.s64 = -2113011712;
	// addi r3,r31,140
	ctx.r3.s64 = r31.s64 + 140;
	// addi r11,r4,18636
	r11.s64 = ctx.r4.s64 + 18636;
	// stw r11,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r11.u32);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r10,-32242
	ctx.r10.s64 = -2113011712;
	// addi r3,r31,168
	ctx.r3.s64 = r31.s64 + 168;
	// addi r9,r10,18716
	ctx.r9.s64 = ctx.r10.s64 + 18716;
	// stw r9,140(r31)
	PPC_STORE_U32(r31.u32 + 140, ctx.r9.u32);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r8,-32242
	ctx.r8.s64 = -2113011712;
	// lis r7,152
	ctx.r7.s64 = 9961472;
	// addi r6,r8,18888
	ctx.r6.s64 = ctx.r8.s64 + 18888;
	// ori r5,r7,38527
	ctx.r5.u64 = ctx.r7.u64 | 38527;
	// stw r6,168(r31)
	PPC_STORE_U32(r31.u32 + 168, ctx.r6.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r5,196(r31)
	PPC_STORE_U32(r31.u32 + 196, ctx.r5.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82591260) {
	__imp__sub_82591260(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825913C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82591418
	sub_82591418(ctx, base);
	// clrlwi r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82591400
	if (cr6.eq) goto loc_82591400;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82591400:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825913C8) {
	__imp__sub_825913C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82591418) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// addi r11,r31,168
	r11.s64 = r31.s64 + 168;
	// addi r29,r10,-4548
	r29.s64 = ctx.r10.s64 + -4548;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// stw r29,168(r31)
	PPC_STORE_U32(r31.u32 + 168, r29.u32);
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,180(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(180) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// addi r11,r31,140
	r11.s64 = r31.s64 + 140;
	// stw r30,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r30.u32);
	// stw r29,140(r31)
	PPC_STORE_U32(r31.u32 + 140, r29.u32);
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,152(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(152) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,152(r31)
	PPC_STORE_U32(r31.u32 + 152, r30.u32);
	// stw r29,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r29.u32);
	// addi r11,r31,112
	r11.s64 = r31.s64 + 112;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,124(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(124) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,124(r31)
	PPC_STORE_U32(r31.u32 + 124, r30.u32);
	// addi r3,r31,68
	ctx.r3.s64 = r31.s64 + 68;
	// bl 0x8257cc98
	sub_8257CC98(ctx, base);
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r11,r31,48
	r11.s64 = r31.s64 + 48;
	// addi r8,r9,12052
	ctx.r8.s64 = ctx.r9.s64 + 12052;
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// stw r8,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r8.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// addi r3,r31,36
	ctx.r3.s64 = r31.s64 + 36;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r31,32
	ctx.r3.s64 = r31.s64 + 32;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r7,-32241
	ctx.r7.s64 = -2112946176;
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// addi r6,r7,5732
	ctx.r6.s64 = ctx.r7.s64 + 5732;
	// stw r6,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r6.u32);
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// lis r5,-32246
	ctx.r5.s64 = -2113273856;
	// stw r30,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r30.u32);
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r4,r5,23084
	ctx.r4.s64 = ctx.r5.s64 + 23084;
	// stw r4,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r4.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82591418) {
	__imp__sub_82591418(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825914F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,-776
	ctx.r4.s64 = ctx.r9.s64 + -776;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r28,-31927
	r28.s64 = -2092367872;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// lwz r8,56(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r7,-32245
	ctx.r7.s64 = -2113208320;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r7,-732
	ctx.r4.s64 = ctx.r7.s64 + -732;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r6,56(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r4,-32244
	ctx.r4.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r4,3716
	ctx.r4.s64 = ctx.r4.s64 + 3716;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lbz r11,44(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 44);
	// li r6,0
	ctx.r6.s64 = 0;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,20
	ctx.r3.s64 = 20;
	// rlwinm r5,r10,27,31,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// bl 0x8283f948
	sub_8283F948(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,3724
	ctx.r4.s64 = ctx.r9.s64 + 3724;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lbz r8,45(r31)
	ctx.r8.u64 = PPC_LOAD_U8(r31.u32 + 45);
	// li r6,0
	ctx.r6.s64 = 0;
	// cntlzw r7,r8
	ctx.r7.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,20
	ctx.r3.s64 = 20;
	// rlwinm r5,r7,27,31,31
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x1;
	// bl 0x8283f948
	sub_8283F948(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// addi r6,r31,112
	ctx.r6.s64 = r31.s64 + 112;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r6,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r6.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r5,r31,140
	ctx.r5.s64 = r31.s64 + 140;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r5,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r5.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r3,r31,168
	ctx.r3.s64 = r31.s64 + 168;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r3,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r3.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r29,r31,68
	r29.s64 = r31.s64 + 68;
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// addi r5,r10,-29660
	ctx.r5.s64 = ctx.r10.s64 + -29660;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r6,152(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x828ce060
	sub_828CE060(ctx, base);
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r8,56(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(152) );
	// bl 0x828ce4e8
	sub_828CE4E8(ctx, base);
	// lis r7,152
	ctx.r7.s64 = 9961472;
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// li r6,1
	ctx.r6.s64 = 1;
	// stb r30,109(r31)
	PPC_STORE_U8(r31.u32 + 109, r30.u8);
	// ori r5,r7,38527
	ctx.r5.u64 = ctx.r7.u64 | 38527;
	// stb r6,46(r31)
	PPC_STORE_U8(r31.u32 + 46, ctx.r6.u8);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r5,196(r31)
	PPC_STORE_U32(r31.u32 + 196, ctx.r5.u32);
	// beq cr6,0x82591698
	if (cr6.eq) goto loc_82591698;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_82591698:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_825914F0) {
	__imp__sub_825914F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825916A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82583560
	sub_82583560(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r29,0
	r29.s64 = 0;
	// addi r8,r11,28344
	ctx.r8.s64 = r11.s64 + 28344;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// stw r29,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r29.u32);
loc_825916D0:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r7
	reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r7
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x825916d0
	if (!cr0.eq) goto loc_825916D0;
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
loc_825916F0:
	// mfmsr r5
	// mtmsrd r13,1
	// lwarx r6,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r6.u64 = __builtin_bswap32(reserved.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// stwcx. r6,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r6.s32));
	cr0.so = xer.so;
	// mtmsrd r5,1
	// bne 0x825916f0
	if (!cr0.eq) goto loc_825916F0;
	// lis r28,-31927
	r28.s64 = -2092367872;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(60) );
	// bl 0x8259db00
	sub_8259DB00(ctx, base);
	// lwz r11,196(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(196) );
	// lwz r30,96(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// beq cr6,0x82591740
	if (cr6.eq) goto loc_82591740;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82591950
	sub_82591950(ctx, base);
	// stw r30,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r30.u32);
loc_82591740:
	// addi r3,r31,68
	ctx.r3.s64 = r31.s64 + 68;
	// bl 0x828ce180
	sub_828CE180(ctx, base);
	// lbz r11,46(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 46);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82591918
	if (cr6.eq) goto loc_82591918;
	// stb r29,46(r31)
	PPC_STORE_U8(r31.u32 + 46, r29.u8);
	// addi r30,r31,24
	r30.s64 = r31.s64 + 24;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(28) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259179c
	if (cr6.eq) goto loc_8259179C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825917f0
	if (cr6.eq) goto loc_825917F0;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259179c
	if (cr6.eq) goto loc_8259179C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x825917a0
	if (!cr6.eq) goto loc_825917A0;
loc_8259179C:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_825917A0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82591918
	if (cr6.eq) goto loc_82591918;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,28,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825918c0
	if (cr6.eq) goto loc_825918C0;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825917fc
	if (cr6.eq) goto loc_825917FC;
	// lbz r10,100(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 100);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825918c4
	goto loc_825918C4;
loc_825917F0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8259179c
	goto loc_8259179C;
loc_825917FC:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82591868
	if (!cr0.gt) goto loc_82591868;
loc_82591818:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,100
	cr6.compare<int32_t>(ctx.r7.s32, 100, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82591838
	if (cr6.lt) goto loc_82591838;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_82591838:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82591854
	if (cr6.eq) goto loc_82591854;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8259185c
	goto loc_8259185C;
loc_82591854:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8259185C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82591818
	if (cr6.gt) goto loc_82591818;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82591868:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825918ac
	if (cr6.eq) goto loc_825918AC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,100
	cr6.compare<int32_t>(r11.s32, 100, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82591884
	if (cr6.gt) goto loc_82591884;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82591884:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825918ac
	if (!cr6.eq) goto loc_825918AC;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825918c4
	goto loc_825918C4;
loc_825918AC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825918c4
	goto loc_825918C4;
loc_825918C0:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_825918C4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82591918
	if (cr6.eq) goto loc_82591918;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// li r10,-1
	ctx.r10.s64 = -1;
	// addi r4,r11,-29636
	ctx.r4.s64 = r11.s64 + -29636;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82448530
	sub_82448530(ctx, base);
	// lwz r3,56(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + int32_t(56) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82591918
	if (cr6.eq) goto loc_82591918;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(20) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82591918:
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r10,-29656
	ctx.r4.s64 = ctx.r10.s64 + -29656;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r3,152(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x82837218
	sub_82837218(ctx, base);
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_825916A0) {
	__imp__sub_825916A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82591950) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// li r11,0
	r11.s64 = 0;
	// addi r7,r10,28344
	ctx.r7.s64 = ctx.r10.s64 + 28344;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
loc_8259197C:
	// mfmsr r8
	// mtmsrd r13,1
	// lwarx r9,0,r6
	reserved.u32 = *(uint32_t*)(base + ctx.r6.u32);
	ctx.r9.u64 = __builtin_bswap32(reserved.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwcx. r9,0,r6
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r6.u32), reserved.s32, __builtin_bswap32(ctx.r9.s32));
	cr0.so = xer.so;
	// mtmsrd r8,1
	// bne 0x8259197c
	if (!cr0.eq) goto loc_8259197C;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
loc_8259199C:
	// mfmsr r4
	// mtmsrd r13,1
	// lwarx r5,0,r7
	reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r5.u64 = __builtin_bswap32(reserved.u32);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// stwcx. r5,0,r7
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), reserved.s32, __builtin_bswap32(ctx.r5.s32));
	cr0.so = xer.so;
	// mtmsrd r4,1
	// bne 0x8259199c
	if (!cr0.eq) goto loc_8259199C;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(60) );
	// bl 0x8259db00
	sub_8259DB00(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,3744
	ctx.r4.s64 = ctx.r10.s64 + 3744;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r31,152(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// lis r8,-32244
	ctx.r8.s64 = -2113142784;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r4,r8,3772
	ctx.r4.s64 = ctx.r8.s64 + 3772;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f8c30
	sub_823F8C30(ctx, base);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cmpwi cr6,r11,50
	cr6.compare<int32_t>(r11.s32, 50, xer);
	// beq cr6,0x82591ab8
	if (cr6.eq) goto loc_82591AB8;
	// cmpwi cr6,r11,51
	cr6.compare<int32_t>(r11.s32, 51, xer);
	// beq cr6,0x82591aa0
	if (cr6.eq) goto loc_82591AA0;
	// cmpwi cr6,r11,52
	cr6.compare<int32_t>(r11.s32, 52, xer);
	// bne cr6,0x82591b10
	if (!cr6.eq) goto loc_82591B10;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lbz r5,45(r30)
	ctx.r5.u64 = PPC_LOAD_U8(r30.u32 + 45);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r11,-29644
	ctx.r3.s64 = r11.s64 + -29644;
	// bl 0x823f87c0
	sub_823F87C0(ctx, base);
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lbz r5,45(r30)
	ctx.r5.u64 = PPC_LOAD_U8(r30.u32 + 45);
	// addi r3,r10,-29640
	ctx.r3.s64 = ctx.r10.s64 + -29640;
	// bl 0x823f87c0
	sub_823F87C0(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r30,68
	ctx.r3.s64 = r30.s64 + 68;
	// bl 0x828ce580
	sub_828CE580(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823f86f8
	sub_823F86F8(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// b 0x82591b04
	goto loc_82591B04;
loc_82591AA0:
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r30,68
	ctx.r3.s64 = r30.s64 + 68;
	// bl 0x828ce580
	sub_828CE580(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// b 0x82591af4
	goto loc_82591AF4;
loc_82591AB8:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lbz r5,44(r30)
	ctx.r5.u64 = PPC_LOAD_U8(r30.u32 + 44);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r11,-29652
	ctx.r3.s64 = r11.s64 + -29652;
	// bl 0x823f87c0
	sub_823F87C0(ctx, base);
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lbz r5,44(r30)
	ctx.r5.u64 = PPC_LOAD_U8(r30.u32 + 44);
	// addi r3,r10,-29648
	ctx.r3.s64 = ctx.r10.s64 + -29648;
	// bl 0x823f87c0
	sub_823F87C0(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r30,68
	ctx.r3.s64 = r30.s64 + 68;
	// bl 0x828ce580
	sub_828CE580(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
loc_82591AF4:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823f86f8
	sub_823F86F8(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
loc_82591B04:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823f86f8
	sub_823F86F8(ctx, base);
loc_82591B10:
	// addi r3,r30,112
	ctx.r3.s64 = r30.s64 + 112;
	// bl 0x82833d40
	sub_82833D40(ctx, base);
	// addi r3,r30,140
	ctx.r3.s64 = r30.s64 + 140;
	// bl 0x82833d40
	sub_82833D40(ctx, base);
	// addi r3,r30,168
	ctx.r3.s64 = r30.s64 + 168;
	// bl 0x82833d40
	sub_82833D40(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82591950) {
	__imp__sub_82591950(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82591B50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r25{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(4) );
	// lis r29,-31927
	r29.s64 = -2092367872;
	// addi r11,r11,-50
	r11.s64 = r11.s64 + -50;
	// cmplwi cr6,r11,91
	cr6.compare<uint32_t>(r11.u32, 91, xer);
	// bgt cr6,0x82591d78
	if (cr6.gt) goto loc_82591D78;
	// lis r12,-32167
	r12.s64 = -2108096512;
	// addi r12,r12,7048
	r12.s64 = r12.s64 + 7048;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82591CF8;
	case 1:
		goto loc_82591D90;
	case 2:
		goto loc_82591D98;
	case 3:
		goto loc_82591D78;
	case 4:
		goto loc_82591D78;
	case 5:
		goto loc_82591D78;
	case 6:
		goto loc_82591D78;
	case 7:
		goto loc_82591D78;
	case 8:
		goto loc_82591D78;
	case 9:
		goto loc_82591D78;
	case 10:
		goto loc_82591D78;
	case 11:
		goto loc_82591D78;
	case 12:
		goto loc_82591D78;
	case 13:
		goto loc_82591D78;
	case 14:
		goto loc_82591D78;
	case 15:
		goto loc_82591D78;
	case 16:
		goto loc_82591D78;
	case 17:
		goto loc_82591D78;
	case 18:
		goto loc_82591D78;
	case 19:
		goto loc_82591D78;
	case 20:
		goto loc_82591D78;
	case 21:
		goto loc_82591D78;
	case 22:
		goto loc_82591D78;
	case 23:
		goto loc_82591D78;
	case 24:
		goto loc_82591D78;
	case 25:
		goto loc_82591D78;
	case 26:
		goto loc_82591D78;
	case 27:
		goto loc_82591D78;
	case 28:
		goto loc_82591D78;
	case 29:
		goto loc_82591D78;
	case 30:
		goto loc_82591D78;
	case 31:
		goto loc_82591D78;
	case 32:
		goto loc_82591D78;
	case 33:
		goto loc_82591D78;
	case 34:
		goto loc_82591D78;
	case 35:
		goto loc_82591D78;
	case 36:
		goto loc_82591D78;
	case 37:
		goto loc_82591D78;
	case 38:
		goto loc_82591D78;
	case 39:
		goto loc_82591D78;
	case 40:
		goto loc_82591D78;
	case 41:
		goto loc_82591D78;
	case 42:
		goto loc_82591D78;
	case 43:
		goto loc_82591D78;
	case 44:
		goto loc_82591D78;
	case 45:
		goto loc_82591D78;
	case 46:
		goto loc_82591D78;
	case 47:
		goto loc_82591D78;
	case 48:
		goto loc_82591D78;
	case 49:
		goto loc_82591D78;
	case 50:
		goto loc_82591D78;
	case 51:
		goto loc_82591D78;
	case 52:
		goto loc_82591D78;
	case 53:
		goto loc_82591D78;
	case 54:
		goto loc_82591D78;
	case 55:
		goto loc_82591D78;
	case 56:
		goto loc_82591D78;
	case 57:
		goto loc_82591D78;
	case 58:
		goto loc_82591D78;
	case 59:
		goto loc_82591D78;
	case 60:
		goto loc_82591D78;
	case 61:
		goto loc_82591D78;
	case 62:
		goto loc_82591D78;
	case 63:
		goto loc_82591D78;
	case 64:
		goto loc_82591D78;
	case 65:
		goto loc_82591D78;
	case 66:
		goto loc_82591D78;
	case 67:
		goto loc_82591D78;
	case 68:
		goto loc_82591D78;
	case 69:
		goto loc_82591D78;
	case 70:
		goto loc_82591D78;
	case 71:
		goto loc_82591D78;
	case 72:
		goto loc_82591D78;
	case 73:
		goto loc_82591D78;
	case 74:
		goto loc_82591D78;
	case 75:
		goto loc_82591D78;
	case 76:
		goto loc_82591D78;
	case 77:
		goto loc_82591D78;
	case 78:
		goto loc_82591D78;
	case 79:
		goto loc_82591D78;
	case 80:
		goto loc_82591D78;
	case 81:
		goto loc_82591D78;
	case 82:
		goto loc_82591D78;
	case 83:
		goto loc_82591D78;
	case 84:
		goto loc_82591D78;
	case 85:
		goto loc_82591D78;
	case 86:
		goto loc_82591D78;
	case 87:
		goto loc_82591D78;
	case 88:
		goto loc_82591D78;
	case 89:
		goto loc_82591D78;
	case 90:
		goto loc_82591F04;
	case 91:
		goto loc_82591ED8;
	default:
		__builtin_unreachable();
	}
	// lwz r18,7416(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7416) );
	// lwz r18,7568(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7568) );
	// lwz r18,7576(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7576) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7544(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7544) );
	// lwz r18,7940(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7940) );
	// lwz r18,7896(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(7896) );
loc_82591CF8:
	// lbz r11,44(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82591d88
	if (cr6.eq) goto loc_82591D88;
	// li r30,42
	r30.s64 = 42;
loc_82591D08:
	// lwz r31,26788(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821c7d38
	sub_821C7D38(ctx, base);
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// lwz r4,124(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(124) );
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(0) );
	// lwz r9,64(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(64) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r8,-31927
	ctx.r8.s64 = -2092367872;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,26912(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(26912) );
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r6,88(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(88) );
	// lwz r5,4(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(4) );
	// lwz r31,16(r5)
	r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + int32_t(16) );
	// bl 0x821c7d38
	sub_821C7D38(ctx, base);
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r8,101
	ctx.r8.s64 = 101;
	// li r9,0
	ctx.r9.s64 = 0;
	// bl 0x82279a40
	sub_82279A40(ctx, base);
loc_82591D78:
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336f98
	sub_82336F98(ctx, base);
loc_82591D88:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c3c
	return;
loc_82591D90:
	// li r30,43
	r30.s64 = 43;
	// b 0x82591d08
	goto loc_82591D08;
loc_82591D98:
	// lbz r11,45(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 45);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82591d88
	if (cr6.eq) goto loc_82591D88;
	// lwz r3,26788(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// li r31,0
	r31.s64 = 0;
	// li r30,44
	r30.s64 = 44;
	// bl 0x821c7d38
	sub_821C7D38(ctx, base);
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// rlwinm r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82591eb8
	if (cr6.eq) goto loc_82591EB8;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82591df4
	if (cr6.eq) goto loc_82591DF4;
	// lbz r10,33(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 33);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82591ebc
	goto loc_82591EBC;
loc_82591DF4:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82591e60
	if (!cr0.gt) goto loc_82591E60;
loc_82591E10:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,33
	cr6.compare<int32_t>(ctx.r7.s32, 33, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82591e30
	if (cr6.lt) goto loc_82591E30;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82591E30:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82591e4c
	if (cr6.eq) goto loc_82591E4C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82591e54
	goto loc_82591E54;
loc_82591E4C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82591E54:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82591e10
	if (cr6.gt) goto loc_82591E10;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82591E60:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82591ea4
	if (cr6.eq) goto loc_82591EA4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82591e7c
	if (cr6.gt) goto loc_82591E7C;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82591E7C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82591ea4
	if (!cr6.eq) goto loc_82591EA4;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82591ebc
	goto loc_82591EBC;
loc_82591EA4:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82591ebc
	goto loc_82591EBC;
loc_82591EB8:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82591EBC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82591d08
	if (cr6.eq) goto loc_82591D08;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823bf150
	sub_823BF150(ctx, base);
	// b 0x82591d08
	goto loc_82591D08;
loc_82591ED8:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,-30944
	ctx.r5.s64 = ctx.r10.s64 + -30944;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r4,26788(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c3c
	return;
loc_82591F04:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,-30948
	ctx.r5.s64 = ctx.r10.s64 + -30948;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r4,26788(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82591B50) {
	__imp__sub_82591B50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82591F30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmpwi cr6,r4,26
	cr6.compare<int32_t>(ctx.r4.s32, 26, xer);
	// bltlr cr6
	if (cr6.lt) return;
	// cmpwi cr6,r4,27
	cr6.compare<int32_t>(ctx.r4.s32, 27, xer);
	// ble cr6,0x82591f4c
	if (!cr6.gt) goto loc_82591F4C;
	// cmpwi cr6,r4,36
	cr6.compare<int32_t>(ctx.r4.s32, 36, xer);
	// bnelr cr6
	if (!cr6.eq) return;
	// b 0x82583140
	sub_82583140(ctx, base);
	return;
loc_82591F4C:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// addi r3,r3,68
	ctx.r3.s64 = ctx.r3.s64 + 68;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r6,152(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// b 0x828ce240
	sub_828CE240(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82591F30) {
	__imp__sub_82591F30(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82591F64) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82591F64) {
	__imp__sub_82591F64(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82591F68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,3844
	ctx.r4.s64 = r11.s64 + 3844;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82287710
	sub_82287710(ctx, base);
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r10,19816
	ctx.r4.s64 = ctx.r10.s64 + 19816;
	// bl 0x82b38f30
	sub_82B38F30(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82b39830
	sub_82B39830(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r31,36
	ctx.r3.s64 = r31.s64 + 36;
	// bl 0x822b85c8
	sub_822B85C8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82591F68) {
	__imp__sub_82591F68(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82592038) {
	PPC_FUNC_PROLOGUE();
	// addi r3,r3,68
	ctx.r3.s64 = ctx.r3.s64 + 68;
	// b 0x828ced00
	sub_828CED00(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82592038) {
	__imp__sub_82592038(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82592040) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r3,r3,400
	ctx.r3.s64 = ctx.r3.s64 + 400;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592080
	if (cr6.eq) goto loc_82592080;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8259207c
	if (cr6.eq) goto loc_8259207C;
	// rotlwi r3,r10,0
	ctx.r3.u64 = rotl32(ctx.r10.u32, 0);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
loc_8259207C:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82592080:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82592040) {
	__imp__sub_82592040(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82592098) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r26,-32246
	r26.s64 = -2113273856;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r30,0
	r30.s64 = 0;
	// lis r10,-32242
	ctx.r10.s64 = -2113011712;
	// addi r25,r26,-27456
	r25.s64 = r26.s64 + -27456;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// addi r9,r11,4600
	ctx.r9.s64 = r11.s64 + 4600;
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// addi r8,r10,19284
	ctx.r8.s64 = ctx.r10.s64 + 19284;
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// li r27,1
	r27.s64 = 1;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// addi r3,r31,88
	ctx.r3.s64 = r31.s64 + 88;
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// lfs f31,-12(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + -12);
	f31.f64 = double(temp.f32);
	// stw r30,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r30.u32);
	// addi r11,r31,44
	r11.s64 = r31.s64 + 44;
	// stw r30,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r30.u32);
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// stw r8,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r8.u32);
	// stfs f31,44(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 44, temp.u32);
	// stw r30,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r30.u32);
	// stw r30,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r30.u32);
	// stw r30,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r30.u32);
	// stw r30,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r30.u32);
	// stw r30,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r30.u32);
	// stw r30,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r30.u32);
	// stw r30,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r30.u32);
	// stb r30,84(r31)
	PPC_STORE_U8(r31.u32 + 84, r30.u8);
	// stb r27,85(r31)
	PPC_STORE_U8(r31.u32 + 85, r27.u8);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r7,-32242
	ctx.r7.s64 = -2113011712;
	// li r28,301
	r28.s64 = 301;
	// addi r6,r7,20816
	ctx.r6.s64 = ctx.r7.s64 + 20816;
	// stw r28,116(r31)
	PPC_STORE_U32(r31.u32 + 116, r28.u32);
	// addi r29,r31,128
	r29.s64 = r31.s64 + 128;
	// stw r6,88(r31)
	PPC_STORE_U32(r31.u32 + 88, ctx.r6.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r5,-32242
	ctx.r5.s64 = -2113011712;
	// addi r3,r29,32
	ctx.r3.s64 = r29.s64 + 32;
	// addi r4,r5,21280
	ctx.r4.s64 = ctx.r5.s64 + 21280;
	// stw r4,128(r31)
	PPC_STORE_U32(r31.u32 + 128, ctx.r4.u32);
	// bl 0x82402308
	sub_82402308(ctx, base);
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// stb r27,328(r31)
	PPC_STORE_U8(r31.u32 + 328, r27.u8);
	// stb r30,329(r31)
	PPC_STORE_U8(r31.u32 + 329, r30.u8);
	// lfs f13,24524(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r25.u32 + 24524);
	ctx.f13.f64 = double(temp.f32);
	// stb r30,340(r31)
	PPC_STORE_U8(r31.u32 + 340, r30.u8);
	// addi r3,r31,368
	ctx.r3.s64 = r31.s64 + 368;
	// stb r30,341(r31)
	PPC_STORE_U8(r31.u32 + 341, r30.u8);
	// addi r11,r29,160
	r11.s64 = r29.s64 + 160;
	// lfs f0,-30440(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30440);
	f0.f64 = double(temp.f32);
	// stfs f0,296(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 296, temp.u32);
	// stfs f0,300(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 300, temp.u32);
	// stfs f13,304(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 304, temp.u32);
	// stfs f13,308(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 308, temp.u32);
	// lfs f0,-27456(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + -27456);
	f0.f64 = double(temp.f32);
	// stfs f0,288(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 288, temp.u32);
	// stfs f31,292(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 292, temp.u32);
	// stfs f31,312(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 312, temp.u32);
	// stfs f31,316(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 316, temp.u32);
	// stfs f31,320(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 320, temp.u32);
	// stfs f31,324(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 324, temp.u32);
	// stfs f0,332(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 332, temp.u32);
	// stfs f31,336(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 336, temp.u32);
	// stw r28,352(r31)
	PPC_STORE_U32(r31.u32 + 352, r28.u32);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r9,-32242
	ctx.r9.s64 = -2113011712;
	// lis r8,-32241
	ctx.r8.s64 = -2112946176;
	// addi r7,r9,22152
	ctx.r7.s64 = ctx.r9.s64 + 22152;
	// addi r6,r8,5732
	ctx.r6.s64 = ctx.r8.s64 + 5732;
	// stw r7,368(r31)
	PPC_STORE_U32(r31.u32 + 368, ctx.r7.u32);
	// li r5,-1
	ctx.r5.s64 = -1;
	// stw r30,396(r31)
	PPC_STORE_U32(r31.u32 + 396, r30.u32);
	// addi r3,r31,444
	ctx.r3.s64 = r31.s64 + 444;
	// stw r6,400(r31)
	PPC_STORE_U32(r31.u32 + 400, ctx.r6.u32);
	// stw r30,404(r31)
	PPC_STORE_U32(r31.u32 + 404, r30.u32);
	// stw r5,408(r31)
	PPC_STORE_U32(r31.u32 + 408, ctx.r5.u32);
	// stb r30,412(r31)
	PPC_STORE_U8(r31.u32 + 412, r30.u8);
	// stb r30,413(r31)
	PPC_STORE_U8(r31.u32 + 413, r30.u8);
	// stb r30,424(r31)
	PPC_STORE_U8(r31.u32 + 424, r30.u8);
	// stb r30,425(r31)
	PPC_STORE_U8(r31.u32 + 425, r30.u8);
	// stw r30,436(r31)
	PPC_STORE_U32(r31.u32 + 436, r30.u32);
	// stb r30,440(r31)
	PPC_STORE_U8(r31.u32 + 440, r30.u8);
	// stb r30,441(r31)
	PPC_STORE_U8(r31.u32 + 441, r30.u8);
	// bl 0x823445b0
	sub_823445B0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_82592098) {
	__imp__sub_82592098(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82592220) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82592270
	sub_82592270(ctx, base);
	// clrlwi r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592258
	if (cr6.eq) goto loc_82592258;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82592258:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82592220) {
	__imp__sub_82592220(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82592270) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r31,444
	ctx.r3.s64 = r31.s64 + 444;
	// bl 0x823fb150
	sub_823FB150(ctx, base);
	// lis r11,-32241
	r11.s64 = -2112946176;
	// addi r3,r31,400
	ctx.r3.s64 = r31.s64 + 400;
	// addi r10,r11,5732
	ctx.r10.s64 = r11.s64 + 5732;
	// stw r10,400(r31)
	PPC_STORE_U32(r31.u32 + 400, ctx.r10.u32);
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// li r30,0
	r30.s64 = 0;
	// addi r29,r9,-4548
	r29.s64 = ctx.r9.s64 + -4548;
	// stw r30,404(r31)
	PPC_STORE_U32(r31.u32 + 404, r30.u32);
	// addi r11,r31,368
	r11.s64 = r31.s64 + 368;
	// stw r29,368(r31)
	PPC_STORE_U32(r31.u32 + 368, r29.u32);
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,380(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(380) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,380(r31)
	PPC_STORE_U32(r31.u32 + 380, r30.u32);
	// stw r29,128(r31)
	PPC_STORE_U32(r31.u32 + 128, r29.u32);
	// addi r11,r31,128
	r11.s64 = r31.s64 + 128;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,140(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(140) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,140(r31)
	PPC_STORE_U32(r31.u32 + 140, r30.u32);
	// stw r29,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r29.u32);
	// addi r11,r31,88
	r11.s64 = r31.s64 + 88;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,100(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(100) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r30.u32);
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// bl 0x8257cc98
	sub_8257CC98(ctx, base);
	// lis r8,-32246
	ctx.r8.s64 = -2113273856;
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// addi r7,r8,12052
	ctx.r7.s64 = ctx.r8.s64 + 12052;
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// stw r7,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r7.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// lis r6,-32246
	ctx.r6.s64 = -2113273856;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r5,r6,23084
	ctx.r5.s64 = ctx.r6.s64 + 23084;
	// stw r5,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r5.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82592270) {
	__imp__sub_82592270(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82592340) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(24) );
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// li r29,0
	r29.s64 = 0;
	// addi r3,r31,444
	ctx.r3.s64 = r31.s64 + 444;
	// stb r29,441(r31)
	PPC_STORE_U8(r31.u32 + 441, r29.u8);
	// lwz r7,448(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + int32_t(448) );
	// lwz r4,4(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(4) );
	// bl 0x82367ae8
	sub_82367AE8(ctx, base);
	// lwz r5,448(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + int32_t(448) );
	// stw r5,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, ctx.r5.u32);
	// addi r6,r31,128
	ctx.r6.s64 = r31.s64 + 128;
	// lwz r11,448(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(448) );
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r29,452(r31)
	PPC_STORE_U32(r31.u32 + 452, r29.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r11,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r11.u32);
	// lwz r10,448(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(448) );
	// stw r10,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r10.u32);
	// stw r6,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r6.u32);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// stw r29,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r29.u32);
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r30,r31,368
	r30.s64 = r31.s64 + 368;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,-308
	ctx.r4.s64 = ctx.r9.s64 + -308;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r28,-31927
	r28.s64 = -2092367872;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// lwz r8,56(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r6,152(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(152) );
	// bl 0x828ce060
	sub_828CE060(ctx, base);
	// lwz r7,88(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + int32_t(88) );
	// addi r3,r31,88
	ctx.r3.s64 = r31.s64 + 88;
	// lwz r6,4(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(4) );
	// mtctr r6
	ctr.u64 = ctx.r6.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r5,368(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + int32_t(368) );
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,4(r5)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r5.u32 + int32_t(4) );
	// mtctr r4
	ctr.u64 = ctx.r4.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// li r11,1
	r11.s64 = 1;
	// addi r3,r31,400
	ctx.r3.s64 = r31.s64 + 400;
	// stb r11,440(r31)
	PPC_STORE_U8(r31.u32 + 440, r11.u8);
	// mr r30,r29
	r30.u64 = r29.u64;
	// lwz r11,404(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(404) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592470
	if (cr6.eq) goto loc_82592470;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8259246c
	if (cr6.eq) goto loc_8259246C;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x82592474
	goto loc_82592474;
loc_8259246C:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82592470:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82592474:
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// rlwinm r9,r10,6,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82592574
	if (cr6.eq) goto loc_82592574;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825924b0
	if (cr6.eq) goto loc_825924B0;
	// lbz r10,26(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 26);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82592578
	goto loc_82592578;
loc_825924B0:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r29,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8259251c
	if (!cr0.gt) goto loc_8259251C;
loc_825924CC:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,26
	cr6.compare<int32_t>(ctx.r7.s32, 26, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825924ec
	if (cr6.lt) goto loc_825924EC;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_825924EC:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82592508
	if (cr6.eq) goto loc_82592508;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82592510
	goto loc_82592510;
loc_82592508:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82592510:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825924cc
	if (cr6.gt) goto loc_825924CC;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_8259251C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82592560
	if (cr6.eq) goto loc_82592560;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,26
	cr6.compare<int32_t>(r11.s32, 26, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82592538
	if (cr6.gt) goto loc_82592538;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82592538:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82592560
	if (!cr6.eq) goto loc_82592560;
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82592578
	goto loc_82592578;
loc_82592560:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82592578
	goto loc_82592578;
loc_82592574:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82592578:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825925d8
	if (cr6.eq) goto loc_825925D8;
	// lwz r11,156(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(156) );
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// bne cr6,0x825925d8
	if (!cr6.eq) goto loc_825925D8;
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,4004
	ctx.r4.s64 = ctx.r10.s64 + 4004;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r30,152(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r8,-31926
	ctx.r8.s64 = -2092302336;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r8,-29540
	ctx.r4.s64 = ctx.r8.s64 + -29540;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x828374b8
	sub_828374B8(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
loc_825925D8:
	// stw r29,396(r31)
	PPC_STORE_U32(r31.u32 + 396, r29.u32);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r3,r31,424
	ctx.r3.s64 = r31.s64 + 424;
	// lfs f1,-27468(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -27468);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82834498
	sub_82834498(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82592604
	if (cr6.eq) goto loc_82592604;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_82592604:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82592340) {
	__imp__sub_82592340(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82592610) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r31,160
	ctx.r3.s64 = r31.s64 + 160;
	// bl 0x82834da0
	sub_82834DA0(ctx, base);
	// addi r31,r31,400
	r31.s64 = r31.s64 + 400;
	// li r30,0
	r30.s64 = 0;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592678
	if (cr6.eq) goto loc_82592678;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825926cc
	if (cr6.eq) goto loc_825926CC;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592678
	if (cr6.eq) goto loc_82592678;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8259267c
	if (!cr6.eq) goto loc_8259267C;
loc_82592678:
	// li r11,0
	r11.s64 = 0;
loc_8259267C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825927b4
	if (cr6.eq) goto loc_825927B4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,5,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825927a0
	if (cr6.eq) goto loc_825927A0;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825926d8
	if (cr6.eq) goto loc_825926D8;
	// lbz r10,27(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 27);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825927a4
	goto loc_825927A4;
loc_825926CC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82592678
	goto loc_82592678;
loc_825926D8:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// li r11,0
	r11.s64 = 0;
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82592748
	if (!cr0.gt) goto loc_82592748;
loc_825926F8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,27
	cr6.compare<int32_t>(ctx.r7.s32, 27, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82592718
	if (cr6.lt) goto loc_82592718;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82592718:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82592734
	if (cr6.eq) goto loc_82592734;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8259273c
	goto loc_8259273C;
loc_82592734:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8259273C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825926f8
	if (cr6.gt) goto loc_825926F8;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82592748:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8259278c
	if (cr6.eq) goto loc_8259278C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82592764
	if (cr6.gt) goto loc_82592764;
	// li r11,0
	r11.s64 = 0;
loc_82592764:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8259278c
	if (!cr6.eq) goto loc_8259278C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825927a4
	goto loc_825927A4;
loc_8259278C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825927a4
	goto loc_825927A4;
loc_825927A0:
	// li r11,0
	r11.s64 = 0;
loc_825927A4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x825927b8
	if (!cr6.eq) goto loc_825927B8;
loc_825927B4:
	// li r11,0
	r11.s64 = 0;
loc_825927B8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825927d8
	if (cr6.eq) goto loc_825927D8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x827b0358
	sub_827B0358(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825927d8
	if (cr6.eq) goto loc_825927D8;
	// bl 0x828e7680
	sub_828E7680(ctx, base);
loc_825927D8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82592610) {
	__imp__sub_82592610(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825927F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x82583560
	sub_82583560(ctx, base);
	// lbz r11,440(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 440);
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259297c
	if (cr6.eq) goto loc_8259297C;
	// stb r27,440(r28)
	PPC_STORE_U8(r28.u32 + 440, r27.u8);
	// addi r3,r28,400
	ctx.r3.s64 = r28.s64 + 400;
	// mr r31,r27
	r31.u64 = r27.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,5,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82592924
	if (cr6.eq) goto loc_82592924;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592860
	if (cr6.eq) goto loc_82592860;
	// lbz r10,27(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 27);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82592928
	goto loc_82592928;
loc_82592860:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825928cc
	if (!cr0.gt) goto loc_825928CC;
loc_8259287C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,27
	cr6.compare<int32_t>(ctx.r7.s32, 27, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8259289c
	if (cr6.lt) goto loc_8259289C;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
loc_8259289C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825928b8
	if (cr6.eq) goto loc_825928B8;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825928c0
	goto loc_825928C0;
loc_825928B8:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825928C0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8259287c
	if (cr6.gt) goto loc_8259287C;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
loc_825928CC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82592910
	if (cr6.eq) goto loc_82592910;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825928e8
	if (cr6.gt) goto loc_825928E8;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_825928E8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82592910
	if (!cr6.eq) goto loc_82592910;
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82592928
	goto loc_82592928;
loc_82592910:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82592928
	goto loc_82592928;
loc_82592924:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82592928:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259297c
	if (cr6.eq) goto loc_8259297C;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x827aff90
	sub_827AFF90(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,3224
	ctx.r4.s64 = r11.s64 + 3224;
	// bl 0x8229ad78
	sub_8229AD78(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82592974
	if (cr6.eq) goto loc_82592974;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82595a58
	sub_82595A58(ctx, base);
loc_82592974:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_8259297C:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// stw r27,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r27.u32);
	// addi r8,r11,28344
	ctx.r8.s64 = r11.s64 + 28344;
	// stw r27,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r27.u32);
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
loc_82592994:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r7
	reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r7
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x82592994
	if (!cr0.eq) goto loc_82592994;
	// stw r27,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r27.u32);
loc_825929B4:
	// mfmsr r5
	// mtmsrd r13,1
	// lwarx r6,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r6.u64 = __builtin_bswap32(reserved.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// stwcx. r6,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r6.s32));
	cr0.so = xer.so;
	// mtmsrd r5,1
	// bne 0x825929b4
	if (!cr0.eq) goto loc_825929B4;
	// lis r30,-31927
	r30.s64 = -2092367872;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r3,60(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(60) );
	// bl 0x8259db00
	sub_8259DB00(ctx, base);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8257d1f0
	sub_8257D1F0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x825958b8
	sub_825958B8(ctx, base);
	// lwz r29,96(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmpwi cr6,r29,30
	cr6.compare<int32_t>(r29.s32, 30, xer);
	// blt cr6,0x82592a18
	if (cr6.lt) goto loc_82592A18;
	// cmpwi cr6,r29,31
	cr6.compare<int32_t>(r29.s32, 31, xer);
	// li r5,1
	ctx.r5.s64 = 1;
	// ble cr6,0x82592a1c
	if (!cr6.gt) goto loc_82592A1C;
loc_82592A18:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
loc_82592A1C:
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// addi r31,r28,44
	r31.s64 = r28.s64 + 44;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(152) );
	// bl 0x828ce4e8
	sub_828CE4E8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x828ce180
	sub_828CE180(ctx, base);
	// lwz r10,368(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + int32_t(368) );
	// addi r3,r28,368
	ctx.r3.s64 = r28.s64 + 368;
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(12) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lis r8,-31926
	ctx.r8.s64 = -2092302336;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r8,-29548
	ctx.r4.s64 = ctx.r8.s64 + -29548;
	// lwz r7,56(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r3,152(r7)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(152) );
	// bl 0x82837218
	sub_82837218(ctx, base);
	// lbz r6,441(r28)
	ctx.r6.u64 = PPC_LOAD_U8(r28.u32 + 441);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x82592a84
	if (cr6.eq) goto loc_82592A84;
	// cmpwi cr6,r29,301
	cr6.compare<int32_t>(r29.s32, 301, xer);
	// li r11,1
	r11.s64 = 1;
	// beq cr6,0x82592a88
	if (cr6.eq) goto loc_82592A88;
loc_82592A84:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82592A88:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592ac8
	if (cr6.eq) goto loc_82592AC8;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x82592ac8
	if (!cr6.eq) goto loc_82592AC8;
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(24) );
	// addi r3,r28,24
	ctx.r3.s64 = r28.s64 + 24;
	// stb r27,441(r28)
	PPC_STORE_U8(r28.u32 + 441, r27.u8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r28,444
	ctx.r3.s64 = r28.s64 + 444;
	// bl 0x82367a90
	sub_82367A90(ctx, base);
loc_82592AC8:
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_825927F0) {
	__imp__sub_825927F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82592AE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r28,-31927
	r28.s64 = -2092367872;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// addi r30,r11,80
	r30.s64 = r11.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82265160
	sub_82265160(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// stw r10,8(r30)
	PPC_STORE_U32(r30.u32 + 8, ctx.r10.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// cmpwi cr6,r11,141
	cr6.compare<int32_t>(r11.s32, 141, xer);
	// bgt cr6,0x82592bbc
	if (cr6.gt) goto loc_82592BBC;
	// beq cr6,0x82592b94
	if (cr6.eq) goto loc_82592B94;
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82592b80
	if (cr6.eq) goto loc_82592B80;
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// beq cr6,0x82592b6c
	if (cr6.eq) goto loc_82592B6C;
	// cmpwi cr6,r11,140
	cr6.compare<int32_t>(r11.s32, 140, xer);
	// bne cr6,0x82592c78
	if (!cr6.eq) goto loc_82592C78;
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lwz r4,26788(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-30948
	ctx.r5.s64 = r11.s64 + -30948;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
loc_82592B6C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82595218
	sub_82595218(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
loc_82592B80:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82594468
	sub_82594468(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
loc_82592B94:
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lwz r4,26788(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-30944
	ctx.r5.s64 = r11.s64 + -30944;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
loc_82592BBC:
	// cmpwi cr6,r11,201
	cr6.compare<int32_t>(r11.s32, 201, xer);
	// beq cr6,0x82592c04
	if (cr6.eq) goto loc_82592C04;
	// cmpwi cr6,r11,301
	cr6.compare<int32_t>(r11.s32, 301, xer);
	// bne cr6,0x82592c78
	if (!cr6.eq) goto loc_82592C78;
	// lbz r11,441(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 441);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592c78
	if (cr6.eq) goto loc_82592C78;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(24) );
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r3,r29,24
	ctx.r3.s64 = r29.s64 + 24;
	// stb r10,441(r29)
	PPC_STORE_U8(r29.u32 + 441, ctx.r10.u8);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r29,444
	ctx.r3.s64 = r29.s64 + 444;
	// bl 0x82367a90
	sub_82367A90(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
loc_82592C04:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,4028
	ctx.r4.s64 = r11.s64 + 4028;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r3,r11,63
	ctx.r3.s64 = r11.s64 + 63;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592c34
	if (cr6.eq) goto loc_82592C34;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_82592C34:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592c44
	if (cr6.eq) goto loc_82592C44;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_82592C44:
	// bl 0x821e6388
	sub_821E6388(ctx, base);
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rlwinm r10,r11,27,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r31,r10,1
	r31.u64 = ctx.r10.u64 ^ 1;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// clrlwi r9,r31,24
	ctx.r9.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82592c78
	if (cr6.eq) goto loc_82592C78;
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336f98
	sub_82336F98(ctx, base);
loc_82592C78:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82592AE0) {
	__imp__sub_82592AE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82592C80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r25{};
	// addi r11,r4,-26
	r11.s64 = ctx.r4.s64 + -26;
	// cmplwi cr6,r11,11
	cr6.compare<uint32_t>(r11.u32, 11, xer);
	// bgtlr cr6
	if (cr6.gt) return;
	// lis r12,-32167
	r12.s64 = -2108096512;
	// addi r12,r12,11428
	r12.s64 = r12.s64 + 11428;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82592CDC;
	case 1:
		goto loc_82592CDC;
	case 2:
		goto loc_82592D00;
	case 3:
		goto loc_82592D00;
	case 4:
		goto loc_82592D00;
	case 5:
		goto loc_82592D00;
	case 6:
		goto loc_82592D00;
	case 7:
		goto loc_82592D00;
	case 8:
		goto loc_82592D00;
	case 9:
		goto loc_82592D00;
	case 10:
		goto loc_82592CD4;
	case 11:
		goto loc_82592CD8;
	default:
		__builtin_unreachable();
	}
	// lwz r18,11484(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11484) );
	// lwz r18,11484(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11484) );
	// lwz r18,11520(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11520) );
	// lwz r18,11520(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11520) );
	// lwz r18,11520(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11520) );
	// lwz r18,11520(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11520) );
	// lwz r18,11520(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11520) );
	// lwz r18,11520(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11520) );
	// lwz r18,11520(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11520) );
	// lwz r18,11520(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11520) );
	// lwz r18,11476(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11476) );
	// lwz r18,11480(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(11480) );
loc_82592CD4:
	// b 0x82583140
	sub_82583140(ctx, base);
	return;
loc_82592CD8:
	// b 0x825832b0
	sub_825832B0(ctx, base);
	return;
loc_82592CDC:
	// lbz r11,84(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 84);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// addi r3,r3,44
	ctx.r3.s64 = ctx.r3.s64 + 44;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r6,152(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// b 0x828ce240
	sub_828CE240(ctx, base);
	return;
loc_82592D00:
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82592C80) {
	__imp__sub_82592C80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82592D08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// beq cr6,0x82592d9c
	if (cr6.eq) goto loc_82592D9C;
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x82592de0
	if (!cr6.eq) goto loc_82592DE0;
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(44) );
	// cmpwi cr6,r11,17
	cr6.compare<int32_t>(r11.s32, 17, xer);
	// beq cr6,0x82592d84
	if (cr6.eq) goto loc_82592D84;
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// beq cr6,0x82592d6c
	if (cr6.eq) goto loc_82592D6C;
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// bne cr6,0x82592de0
	if (!cr6.eq) goto loc_82592DE0;
	// bl 0x82593da8
	sub_82593DA8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82592D6C:
	// bl 0x825940b8
	sub_825940B8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82592D84:
	// bl 0x82593950
	sub_82593950(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82592D9C:
	// cmpwi cr6,r4,36
	cr6.compare<int32_t>(ctx.r4.s32, 36, xer);
	// bne cr6,0x82592de0
	if (!cr6.eq) goto loc_82592DE0;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x823380c0
	sub_823380C0(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,304
	ctx.r4.s64 = r11.s64 + 304;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_82592DE0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82592D08) {
	__imp__sub_82592D08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82592DF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,404(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(404) );
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r31,r3,400
	r31.s64 = ctx.r3.s64 + 400;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592e54
	if (cr6.eq) goto loc_82592E54;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82592ea8
	if (cr6.eq) goto loc_82592EA8;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592e54
	if (cr6.eq) goto loc_82592E54;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82592e58
	if (!cr6.eq) goto loc_82592E58;
loc_82592E54:
	// li r11,0
	r11.s64 = 0;
loc_82592E58:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593000
	if (cr6.eq) goto loc_82593000;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,5,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82592f7c
	if (cr6.eq) goto loc_82592F7C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82592eb4
	if (cr6.eq) goto loc_82592EB4;
	// lbz r10,27(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 27);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82592f80
	goto loc_82592F80;
loc_82592EA8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82592e54
	goto loc_82592E54;
loc_82592EB4:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// li r11,0
	r11.s64 = 0;
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82592f24
	if (!cr0.gt) goto loc_82592F24;
loc_82592ED4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,27
	cr6.compare<int32_t>(ctx.r7.s32, 27, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82592ef4
	if (cr6.lt) goto loc_82592EF4;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82592EF4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82592f10
	if (cr6.eq) goto loc_82592F10;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82592f18
	goto loc_82592F18;
loc_82592F10:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82592F18:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82592ed4
	if (cr6.gt) goto loc_82592ED4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82592F24:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82592f68
	if (cr6.eq) goto loc_82592F68;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82592f40
	if (cr6.gt) goto loc_82592F40;
	// li r11,0
	r11.s64 = 0;
loc_82592F40:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82592f68
	if (!cr6.eq) goto loc_82592F68;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82592f80
	goto loc_82592F80;
loc_82592F68:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82592f80
	goto loc_82592F80;
loc_82592F7C:
	// li r11,0
	r11.s64 = 0;
loc_82592F80:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593000
	if (cr6.eq) goto loc_82593000;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x827b0358
	sub_827B0358(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(0) );
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593000
	if (cr6.eq) goto loc_82593000;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x828e79f8
	sub_828E79F8(ctx, base);
	// extsw r11,r3
	r11.s64 = ctx.r3.s32;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f0
	ctx.f13.f64 = double(f0.s64);
	// frsp f31,f13
	f31.f64 = double(float(ctx.f13.f64));
	// bl 0x828e9100
	sub_828E9100(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmuls f31,f1,f31
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64 * f31.f64));
	// bl 0x828e8858
	sub_828E8858(ctx, base);
	// lbz r10,112(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 112);
	// fmuls f31,f1,f31
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64 * f31.f64));
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82593000
	if (cr6.eq) goto loc_82593000;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x828e7c58
	sub_828E7C58(ctx, base);
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f31.f64);
	// li r3,1
	ctx.r3.s64 = 1;
	// blt cr6,0x82593004
	if (cr6.lt) goto loc_82593004;
loc_82593000:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82593004:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82592DF8) {
	__imp__sub_82592DF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82593010) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,404(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(404) );
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r31,r3,400
	r31.s64 = ctx.r3.s64 + 400;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259306c
	if (cr6.eq) goto loc_8259306C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825930c0
	if (cr6.eq) goto loc_825930C0;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259306c
	if (cr6.eq) goto loc_8259306C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82593070
	if (!cr6.eq) goto loc_82593070;
loc_8259306C:
	// li r11,0
	r11.s64 = 0;
loc_82593070:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259320c
	if (cr6.eq) goto loc_8259320C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,5,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82593194
	if (cr6.eq) goto loc_82593194;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825930cc
	if (cr6.eq) goto loc_825930CC;
	// lbz r10,27(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 27);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593198
	goto loc_82593198;
loc_825930C0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8259306c
	goto loc_8259306C;
loc_825930CC:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// li r11,0
	r11.s64 = 0;
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8259313c
	if (!cr0.gt) goto loc_8259313C;
loc_825930EC:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,27
	cr6.compare<int32_t>(ctx.r7.s32, 27, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8259310c
	if (cr6.lt) goto loc_8259310C;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8259310C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82593128
	if (cr6.eq) goto loc_82593128;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82593130
	goto loc_82593130;
loc_82593128:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82593130:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825930ec
	if (cr6.gt) goto loc_825930EC;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8259313C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82593180
	if (cr6.eq) goto loc_82593180;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82593158
	if (cr6.gt) goto loc_82593158;
	// li r11,0
	r11.s64 = 0;
loc_82593158:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82593180
	if (!cr6.eq) goto loc_82593180;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593198
	goto loc_82593198;
loc_82593180:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593198
	goto loc_82593198;
loc_82593194:
	// li r11,0
	r11.s64 = 0;
loc_82593198:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259320c
	if (cr6.eq) goto loc_8259320C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x827b0358
	sub_827B0358(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x828e79f8
	sub_828E79F8(ctx, base);
	// extsw r11,r3
	r11.s64 = ctx.r3.s32;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f0
	ctx.f13.f64 = double(f0.s64);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// frsp f31,f13
	f31.f64 = double(float(ctx.f13.f64));
	// bl 0x828e9100
	sub_828E9100(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmuls f31,f1,f31
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64 * f31.f64));
	// bl 0x828e8858
	sub_828E8858(ctx, base);
	// lbz r10,112(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 112);
	// fmuls f31,f1,f31
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64 * f31.f64));
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8259320c
	if (cr6.eq) goto loc_8259320C;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x828e7c58
	sub_828E7C58(ctx, base);
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f31.f64);
	// li r3,1
	ctx.r3.s64 = 1;
	// bgt cr6,0x82593210
	if (cr6.gt) goto loc_82593210;
loc_8259320C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82593210:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82593010) {
	__imp__sub_82593010(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82593220) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,404(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(404) );
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r31,r3,400
	r31.s64 = ctx.r3.s64 + 400;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593278
	if (cr6.eq) goto loc_82593278;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825932cc
	if (cr6.eq) goto loc_825932CC;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593278
	if (cr6.eq) goto loc_82593278;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8259327c
	if (!cr6.eq) goto loc_8259327C;
loc_82593278:
	// li r11,0
	r11.s64 = 0;
loc_8259327C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825933dc
	if (cr6.eq) goto loc_825933DC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,5,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825933a0
	if (cr6.eq) goto loc_825933A0;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825932d8
	if (cr6.eq) goto loc_825932D8;
	// lbz r10,27(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 27);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825933a4
	goto loc_825933A4;
loc_825932CC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82593278
	goto loc_82593278;
loc_825932D8:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// li r11,0
	r11.s64 = 0;
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82593348
	if (!cr0.gt) goto loc_82593348;
loc_825932F8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,27
	cr6.compare<int32_t>(ctx.r7.s32, 27, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82593318
	if (cr6.lt) goto loc_82593318;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82593318:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82593334
	if (cr6.eq) goto loc_82593334;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8259333c
	goto loc_8259333C;
loc_82593334:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8259333C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825932f8
	if (cr6.gt) goto loc_825932F8;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82593348:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8259338c
	if (cr6.eq) goto loc_8259338C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82593364
	if (cr6.gt) goto loc_82593364;
	// li r11,0
	r11.s64 = 0;
loc_82593364:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8259338c
	if (!cr6.eq) goto loc_8259338C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825933a4
	goto loc_825933A4;
loc_8259338C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x825933a4
	goto loc_825933A4;
loc_825933A0:
	// li r11,0
	r11.s64 = 0;
loc_825933A4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825933dc
	if (cr6.eq) goto loc_825933DC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x827b0358
	sub_827B0358(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x828e86f8
	sub_828E86F8(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// li r11,1
	r11.s64 = 1;
	// blt cr6,0x825933d0
	if (cr6.lt) goto loc_825933D0;
	// li r11,0
	r11.s64 = 0;
loc_825933D0:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_825933DC:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82593220) {
	__imp__sub_82593220(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825933E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// stw r4,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r4.u32);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// addi r30,r31,444
	r30.s64 = r31.s64 + 444;
	// addi r5,r1,156
	ctx.r5.s64 = ctx.r1.s64 + 156;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x825cb448
	sub_825CB448(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// lwz r9,448(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + int32_t(448) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259342c
	if (cr6.eq) goto loc_8259342C;
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// beq cr6,0x82593430
	if (cr6.eq) goto loc_82593430;
loc_8259342C:
	// twi 31,r0,22
loc_82593430:
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x8259346c
	if (cr6.eq) goto loc_8259346C;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82593448
	if (!cr6.eq) goto loc_82593448;
	// twi 31,r0,22
loc_82593448:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82593458
	if (!cr6.eq) goto loc_82593458;
	// twi 31,r0,22
loc_82593458:
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(16) );
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_8259346C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_825933E8) {
	__imp__sub_825933E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82593478) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r31,0
	r31.s64 = 0;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593538
	if (cr6.eq) goto loc_82593538;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82593534
	if (cr6.eq) goto loc_82593534;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825934e8
	if (cr6.eq) goto loc_825934E8;
	// lbz r10,144(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 144);
	// rlwinm r9,r10,0,25,25
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// li r10,1
	ctx.r10.s64 = 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x825934ec
	if (!cr6.eq) goto loc_825934EC;
loc_825934E8:
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_825934EC:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82593678
	if (cr6.eq) goto loc_82593678;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// rlwinm r9,r10,19,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 19) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82593604
	if (cr6.eq) goto loc_82593604;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82593540
	if (cr6.eq) goto loc_82593540;
	// lbz r10,13(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 13);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593608
	goto loc_82593608;
loc_82593534:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82593538:
	// mr r11,r31
	r11.u64 = r31.u64;
	// b 0x825934e8
	goto loc_825934E8;
loc_82593540:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825935ac
	if (!cr0.gt) goto loc_825935AC;
loc_8259355C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,13
	cr6.compare<int32_t>(ctx.r7.s32, 13, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x8259357c
	if (cr6.lt) goto loc_8259357C;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_8259357C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82593598
	if (cr6.eq) goto loc_82593598;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x825935a0
	goto loc_825935A0;
loc_82593598:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_825935A0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x8259355c
	if (cr6.gt) goto loc_8259355C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_825935AC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825935f0
	if (cr6.eq) goto loc_825935F0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,13
	cr6.compare<int32_t>(r11.s32, 13, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825935c8
	if (cr6.gt) goto loc_825935C8;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_825935C8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825935f0
	if (!cr6.eq) goto loc_825935F0;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593608
	goto loc_82593608;
loc_825935F0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593608
	goto loc_82593608;
loc_82593604:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82593608:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593678
	if (cr6.eq) goto loc_82593678;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825933e8
	sub_825933E8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593678
	if (cr6.eq) goto loc_82593678;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8261b978
	sub_8261B978(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplw cr6,r28,r4
	cr6.compare<uint32_t>(r28.u32, ctx.r4.u32, xer);
	// beq cr6,0x82593654
	if (cr6.eq) goto loc_82593654;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8218df70
	sub_8218DF70(ctx, base);
loc_82593654:
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82593668
	if (cr6.eq) goto loc_82593668;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_82593668:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(0) );
	// li r3,1
	ctx.r3.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8259367c
	if (!cr6.eq) goto loc_8259367C;
loc_82593678:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8259367C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82593478) {
	__imp__sub_82593478(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82593688) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// addi r3,r30,400
	ctx.r3.s64 = r30.s64 + 400;
	// lwz r11,404(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(404) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593730
	if (cr6.eq) goto loc_82593730;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8259372c
	if (cr6.eq) goto loc_8259372C;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825936dc
	if (cr6.eq) goto loc_825936DC;
	// lbz r10,144(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 144);
	// rlwinm r9,r10,0,25,25
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// li r10,1
	ctx.r10.s64 = 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x825936e0
	if (!cr6.eq) goto loc_825936E0;
loc_825936DC:
	// li r10,0
	ctx.r10.s64 = 0;
loc_825936E0:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82593884
	if (cr6.eq) goto loc_82593884;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(36) );
	// li r3,0
	ctx.r3.s64 = 0;
	// rlwinm r9,r10,5,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82593800
	if (cr6.eq) goto loc_82593800;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82593738
	if (cr6.eq) goto loc_82593738;
	// lbz r9,27(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 27);
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r11,r9,3
	r11.u64 = rotl32(ctx.r9.u32, 3);
	// add r8,r11,r10
	ctx.r8.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593804
	goto loc_82593804;
loc_8259372C:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82593730:
	// li r11,0
	r11.s64 = 0;
	// b 0x825936dc
	goto loc_825936DC;
loc_82593738:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// subf r8,r10,r6
	ctx.r8.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r8,3
	xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x7) != 0);
	r11.s64 = ctx.r8.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x825937a8
	if (!cr0.gt) goto loc_825937A8;
loc_82593758:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,27
	cr6.compare<int32_t>(ctx.r7.s32, 27, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82593778
	if (cr6.lt) goto loc_82593778;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82593778:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82593794
	if (cr6.eq) goto loc_82593794;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8259379c
	goto loc_8259379C;
loc_82593794:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8259379C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82593758
	if (cr6.gt) goto loc_82593758;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_825937A8:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825937ec
	if (cr6.eq) goto loc_825937EC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825937c4
	if (cr6.gt) goto loc_825937C4;
	// li r11,0
	r11.s64 = 0;
loc_825937C4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825937ec
	if (!cr6.eq) goto loc_825937EC;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593804
	goto loc_82593804;
loc_825937EC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593804
	goto loc_82593804;
loc_82593800:
	// li r11,0
	r11.s64 = 0;
loc_82593804:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593884
	if (cr6.eq) goto loc_82593884;
	// bl 0x827b0358
	sub_827B0358(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82593884
	if (cr6.eq) goto loc_82593884;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x825933e8
	sub_825933E8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593884
	if (cr6.eq) goto loc_82593884;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x828e7888
	sub_828E7888(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplw cr6,r28,r4
	cr6.compare<uint32_t>(r28.u32, ctx.r4.u32, xer);
	// beq cr6,0x82593860
	if (cr6.eq) goto loc_82593860;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8218df70
	sub_8218DF70(ctx, base);
loc_82593860:
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82593874
	if (cr6.eq) goto loc_82593874;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_82593874:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(0) );
	// li r3,1
	ctx.r3.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82593888
	if (!cr6.eq) goto loc_82593888;
loc_82593884:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82593888:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82593688) {
	__imp__sub_82593688(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82593890) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r29,-31927
	r29.s64 = -2092367872;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825938d4
	if (cr6.eq) goto loc_825938D4;
loc_825938C8:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_825938D4:
	// li r28,21
	r28.s64 = 21;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// addi r3,r11,68
	ctx.r3.s64 = r11.s64 + 68;
	// bl 0x8247d010
	sub_8247D010(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// bl 0x82593478
	sub_82593478(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825938c8
	if (!cr6.eq) goto loc_825938C8;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// addi r3,r11,68
	ctx.r3.s64 = r11.s64 + 68;
	// bl 0x8247d010
	sub_8247D010(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// bl 0x82593688
	sub_82593688(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r3,r9,1
	ctx.r3.u64 = ctx.r9.u64 ^ 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82593890) {
	__imp__sub_82593890(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82593950) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,46
	cr6.compare<int32_t>(ctx.r4.s32, 46, xer);
	// beq cr6,0x825939c4
	if (cr6.eq) goto loc_825939C4;
	// cmpwi cr6,r4,47
	cr6.compare<int32_t>(ctx.r4.s32, 47, xer);
	// bne cr6,0x82593da0
	if (!cr6.eq) goto loc_82593DA0;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82338030
	sub_82338030(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,304
	ctx.r4.s64 = r11.s64 + 304;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r9,396(r27)
	PPC_STORE_U32(r27.u32 + 396, ctx.r9.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	return;
loc_825939C4:
	// lwz r4,396(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(396) );
	// li r29,0
	r29.s64 = 0;
	// lis r28,-31927
	r28.s64 = -2092367872;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82593d5c
	if (cr6.eq) goto loc_82593D5C;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// stw r29,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r29.u32);
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
	// lwz r11,404(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(404) );
	// addi r31,r27,400
	r31.s64 = r27.s64 + 400;
	// mr r30,r29
	r30.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593a48
	if (cr6.eq) goto loc_82593A48;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82593a9c
	if (cr6.eq) goto loc_82593A9C;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593a48
	if (cr6.eq) goto loc_82593A48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82593a4c
	if (!cr6.eq) goto loc_82593A4C;
loc_82593A48:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82593A4C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593d44
	if (cr6.eq) goto loc_82593D44;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,5,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82593b6c
	if (cr6.eq) goto loc_82593B6C;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593aa8
	if (cr6.eq) goto loc_82593AA8;
	// lbz r10,27(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 27);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593b70
	goto loc_82593B70;
loc_82593A9C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82593a48
	goto loc_82593A48;
loc_82593AA8:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82593b14
	if (!cr0.gt) goto loc_82593B14;
loc_82593AC4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,27
	cr6.compare<int32_t>(ctx.r7.s32, 27, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82593ae4
	if (cr6.lt) goto loc_82593AE4;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_82593AE4:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82593b00
	if (cr6.eq) goto loc_82593B00;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82593b08
	goto loc_82593B08;
loc_82593B00:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82593B08:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82593ac4
	if (cr6.gt) goto loc_82593AC4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82593B14:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82593b58
	if (cr6.eq) goto loc_82593B58;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82593b30
	if (cr6.gt) goto loc_82593B30;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82593B30:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82593b58
	if (!cr6.eq) goto loc_82593B58;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593b70
	goto loc_82593B70;
loc_82593B58:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593b70
	goto loc_82593B70;
loc_82593B6C:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82593B70:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593d44
	if (cr6.eq) goto loc_82593D44;
	// stw r29,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r29.u32);
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r29.u32);
	// lwz r3,26788(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// bl 0x821c7d38
	sub_821C7D38(ctx, base);
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x827af850
	sub_827AF850(ctx, base);
	// addi r3,r27,24
	ctx.r3.s64 = r27.s64 + 24;
	// bl 0x828e0070
	sub_828E0070(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// lis r4,-32484
	ctx.r4.s64 = -2128871424;
	// addi r3,r11,4044
	ctx.r3.s64 = r11.s64 + 4044;
	// ori r4,r4,40389
	ctx.r4.u64 = ctx.r4.u64 | 40389;
	// bl 0x821f3c28
	sub_821F3C28(ctx, base);
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r3,27600(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(27600) );
	// bl 0x829fb108
	sub_829FB108(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82593d2c
	if (cr6.eq) goto loc_82593D2C;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,4060
	ctx.r4.s64 = r11.s64 + 4060;
	// bl 0x823b12e8
	sub_823B12E8(ctx, base);
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// neg r30,r3
	r30.s64 = -ctx.r3.s64;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// mr r31,r29
	r31.u64 = r29.u64;
	// bl 0x821c7d38
	sub_821C7D38(ctx, base);
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// lwz r10,44(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(44) );
	// rlwinm r9,r10,15,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82593d04
	if (cr6.eq) goto loc_82593D04;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593c40
	if (cr6.eq) goto loc_82593C40;
	// lbz r10,81(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 81);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593d08
	goto loc_82593D08;
loc_82593C40:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82593cac
	if (!cr0.gt) goto loc_82593CAC;
loc_82593C5C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,81
	cr6.compare<int32_t>(ctx.r7.s32, 81, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82593c7c
	if (cr6.lt) goto loc_82593C7C;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_82593C7C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82593c98
	if (cr6.eq) goto loc_82593C98;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82593ca0
	goto loc_82593CA0;
loc_82593C98:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82593CA0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82593c5c
	if (cr6.gt) goto loc_82593C5C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82593CAC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82593cf0
	if (cr6.eq) goto loc_82593CF0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,81
	cr6.compare<int32_t>(r11.s32, 81, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82593cc8
	if (cr6.gt) goto loc_82593CC8;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82593CC8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82593cf0
	if (!cr6.eq) goto loc_82593CF0;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593d08
	goto loc_82593D08;
loc_82593CF0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82593d08
	goto loc_82593D08;
loc_82593D04:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82593D08:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593d2c
	if (cr6.eq) goto loc_82593D2C;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239e698
	sub_8239E698(ctx, base);
loc_82593D2C:
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82593d40
	if (cr6.eq) goto loc_82593D40;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_82593D40:
	// stw r29,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r29.u32);
loc_82593D44:
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82593d58
	if (cr6.eq) goto loc_82593D58;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_82593D58:
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
loc_82593D5C:
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x823380c0
	sub_823380C0(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,304
	ctx.r4.s64 = r11.s64 + 304;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// stw r29,396(r27)
	PPC_STORE_U32(r27.u32 + 396, r29.u32);
loc_82593DA0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82593950) {
	__imp__sub_82593950(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82593DA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r29,0
	r29.s64 = 0;
	// lis r27,-31927
	r27.s64 = -2092367872;
	// stw r29,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r29.u32);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r29.u32);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// lwz r4,396(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(396) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// mr r30,r29
	r30.u64 = r29.u64;
	// stw r29,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r29.u32);
	// cmpwi cr6,r31,36
	cr6.compare<int32_t>(r31.s32, 36, xer);
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// beq cr6,0x82593e7c
	if (cr6.eq) goto loc_82593E7C;
	// cmpwi cr6,r31,75
	cr6.compare<int32_t>(r31.s32, 75, xer);
	// bne cr6,0x82593e90
	if (!cr6.eq) goto loc_82593E90;
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// li r30,1
	r30.s64 = 1;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// addi r31,r11,80
	r31.s64 = r11.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// beq cr6,0x82593e70
	if (cr6.eq) goto loc_82593E70;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82594c70
	sub_82594C70(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r3,52(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// bl 0x825a5a40
	sub_825A5A40(ctx, base);
loc_82593E70:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// b 0x82593e90
	goto loc_82593E90;
loc_82593E7C:
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82594c70
	sub_82594C70(ctx, base);
	// li r30,1
	r30.s64 = 1;
loc_82593E90:
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594084
	if (cr6.eq) goto loc_82594084;
	// lwz r11,404(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(404) );
	// addi r31,r28,400
	r31.s64 = r28.s64 + 400;
	// mr r30,r29
	r30.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593ee4
	if (cr6.eq) goto loc_82593EE4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82593f38
	if (cr6.eq) goto loc_82593F38;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593ee4
	if (cr6.eq) goto loc_82593EE4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82593ee8
	if (!cr6.eq) goto loc_82593EE8;
loc_82593EE4:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82593EE8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594020
	if (cr6.eq) goto loc_82594020;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,5,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82594004
	if (cr6.eq) goto loc_82594004;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82593f44
	if (cr6.eq) goto loc_82593F44;
	// lbz r11,27(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 27);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82594008
	goto loc_82594008;
loc_82593F38:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82593ee4
	goto loc_82593EE4;
loc_82593F44:
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82593fac
	if (!cr0.gt) goto loc_82593FAC;
loc_82593F5C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,27
	cr6.compare<int32_t>(ctx.r7.s32, 27, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82593f7c
	if (cr6.lt) goto loc_82593F7C;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_82593F7C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82593f98
	if (cr6.eq) goto loc_82593F98;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82593fa0
	goto loc_82593FA0;
loc_82593F98:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82593FA0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82593f5c
	if (cr6.gt) goto loc_82593F5C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82593FAC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82593ff0
	if (cr6.eq) goto loc_82593FF0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82593fc8
	if (cr6.gt) goto loc_82593FC8;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82593FC8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82593ff0
	if (!cr6.eq) goto loc_82593FF0;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82594008
	goto loc_82594008;
loc_82593FF0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82594008
	goto loc_82594008;
loc_82594004:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82594008:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594020
	if (cr6.eq) goto loc_82594020;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r28,24
	ctx.r3.s64 = r28.s64 + 24;
	// bl 0x828df988
	sub_828DF988(ctx, base);
loc_82594020:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82594ea0
	sub_82594EA0(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// li r4,3
	ctx.r4.s64 = 3;
	// stb r10,441(r28)
	PPC_STORE_U8(r28.u32 + 441, ctx.r10.u8);
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x823380c0
	sub_823380C0(ctx, base);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,304
	ctx.r4.s64 = ctx.r9.s64 + 304;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r8,56(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_82594084:
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82594098
	if (cr6.eq) goto loc_82594098;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_82594098:
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825940b0
	if (cr6.eq) goto loc_825940B0;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_825940B0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82593DA8) {
	__imp__sub_82593DA8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825940B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,46
	cr6.compare<int32_t>(ctx.r4.s32, 46, xer);
	// beq cr6,0x8259412c
	if (cr6.eq) goto loc_8259412C;
	// cmpwi cr6,r4,47
	cr6.compare<int32_t>(ctx.r4.s32, 47, xer);
	// bne cr6,0x82594204
	if (!cr6.eq) goto loc_82594204;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82338030
	sub_82338030(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,304
	ctx.r4.s64 = r11.s64 + 304;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r9,396(r29)
	PPC_STORE_U32(r29.u32 + 396, ctx.r9.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c3c
	return;
loc_8259412C:
	// lwz r4,396(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + int32_t(396) );
	// li r31,0
	r31.s64 = 0;
	// lis r30,-31927
	r30.s64 = -2092367872;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x825941c0
	if (cr6.eq) goto loc_825941C0;
	// stw r31,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r31.u32);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// stw r31,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r31.u32);
	// stw r31,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r31.u32);
	// stw r31,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r31.u32);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259417c
	if (cr6.eq) goto loc_8259417C;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82594180
	goto loc_82594180;
loc_8259417C:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82594180:
	// lwz r10,396(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + int32_t(396) );
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// addi r4,r29,444
	ctx.r4.s64 = r29.s64 + 444;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x823660d0
	sub_823660D0(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82594210
	sub_82594210(ctx, base);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825941bc
	if (cr6.eq) goto loc_825941BC;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_825941BC:
	// stw r31,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r31.u32);
loc_825941C0:
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x823380c0
	sub_823380C0(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,304
	ctx.r4.s64 = r11.s64 + 304;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// stw r31,396(r29)
	PPC_STORE_U32(r29.u32 + 396, r31.u32);
loc_82594204:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_825940B8) {
	__imp__sub_825940B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82594210) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(0) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82594458
	if (cr6.eq) goto loc_82594458;
	// lwz r11,404(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(404) );
	// addi r31,r29,400
	r31.s64 = r29.s64 + 400;
	// li r27,1
	r27.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259427c
	if (cr6.eq) goto loc_8259427C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825942d0
	if (cr6.eq) goto loc_825942D0;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259427c
	if (cr6.eq) goto loc_8259427C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// mr r11,r27
	r11.u64 = r27.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82594280
	if (!cr6.eq) goto loc_82594280;
loc_8259427C:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82594280:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259444c
	if (cr6.eq) goto loc_8259444C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,5,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825943a0
	if (cr6.eq) goto loc_825943A0;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825942dc
	if (cr6.eq) goto loc_825942DC;
	// lbz r10,27(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 27);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// mr r11,r27
	r11.u64 = r27.u64;
	// b 0x825943a4
	goto loc_825943A4;
loc_825942D0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x8259427c
	goto loc_8259427C;
loc_825942DC:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82594348
	if (!cr0.gt) goto loc_82594348;
loc_825942F8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,27
	cr6.compare<int32_t>(ctx.r7.s32, 27, xer);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// blt cr6,0x82594318
	if (cr6.lt) goto loc_82594318;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_82594318:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82594334
	if (cr6.eq) goto loc_82594334;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8259433c
	goto loc_8259433C;
loc_82594334:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8259433C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825942f8
	if (cr6.gt) goto loc_825942F8;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_82594348:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8259438c
	if (cr6.eq) goto loc_8259438C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// mr r11,r27
	r11.u64 = r27.u64;
	// bgt cr6,0x82594364
	if (cr6.gt) goto loc_82594364;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82594364:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8259438c
	if (!cr6.eq) goto loc_8259438C;
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// mr r11,r27
	r11.u64 = r27.u64;
	// b 0x825943a4
	goto loc_825943A4;
loc_8259438C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// mr r11,r27
	r11.u64 = r27.u64;
	// b 0x825943a4
	goto loc_825943A4;
loc_825943A0:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_825943A4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259444c
	if (cr6.eq) goto loc_8259444C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(0) );
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// lis r31,-31927
	r31.s64 = -2092367872;
	// lwz r3,26788(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// bl 0x821c7d38
	sub_821C7D38(ctx, base);
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x827afb58
	sub_827AFB58(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r29,24
	ctx.r3.s64 = r29.s64 + 24;
	// bl 0x828df988
	sub_828DF988(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82594ea0
	sub_82594EA0(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,4084
	ctx.r4.s64 = r11.s64 + 4084;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82595a58
	sub_82595A58(ctx, base);
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,26788(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// addi r5,r10,-30592
	ctx.r5.s64 = ctx.r10.s64 + -30592;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_8259444C:
	// stb r27,441(r29)
	PPC_STORE_U8(r29.u32 + 441, r27.u8);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82594458:
	// li r11,1
	r11.s64 = 1;
	// stb r11,441(r29)
	PPC_STORE_U8(r29.u32 + 441, r11.u8);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82594210) {
	__imp__sub_82594210(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82594468) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r27,0
	r27.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r31,r26,400
	r31.s64 = r26.s64 + 400;
	// li r25,1
	r25.s64 = 1;
	// lwz r11,404(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + int32_t(404) );
	// mr r28,r27
	r28.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825944cc
	if (cr6.eq) goto loc_825944CC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82594520
	if (cr6.eq) goto loc_82594520;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825944cc
	if (cr6.eq) goto loc_825944CC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// mr r11,r25
	r11.u64 = r25.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x825944d0
	if (!cr6.eq) goto loc_825944D0;
loc_825944CC:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_825944D0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594c68
	if (cr6.eq) goto loc_82594C68;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,5,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825945f0
	if (cr6.eq) goto loc_825945F0;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259452c
	if (cr6.eq) goto loc_8259452C;
	// lbz r10,27(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 27);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r28,r11
	r28.u64 = r11.u64;
	// mr r11,r25
	r11.u64 = r25.u64;
	// b 0x825945f4
	goto loc_825945F4;
loc_82594520:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x825944cc
	goto loc_825944CC;
loc_8259452C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r27,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r27.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82594598
	if (!cr0.gt) goto loc_82594598;
loc_82594548:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,27
	cr6.compare<int32_t>(ctx.r7.s32, 27, xer);
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// blt cr6,0x82594568
	if (cr6.lt) goto loc_82594568;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
loc_82594568:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82594584
	if (cr6.eq) goto loc_82594584;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8259458c
	goto loc_8259458C;
loc_82594584:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8259458C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82594548
	if (cr6.gt) goto loc_82594548;
	// stw r10,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r10.u32);
loc_82594598:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825945dc
	if (cr6.eq) goto loc_825945DC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// mr r11,r25
	r11.u64 = r25.u64;
	// bgt cr6,0x825945b4
	if (cr6.gt) goto loc_825945B4;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_825945B4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825945dc
	if (!cr6.eq) goto loc_825945DC;
	// ld r11,128(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(132) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r28,r11
	r28.u64 = r11.u64;
	// mr r11,r25
	r11.u64 = r25.u64;
	// b 0x825945f4
	goto loc_825945F4;
loc_825945DC:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r28,r11
	r28.u64 = r11.u64;
	// mr r11,r25
	r11.u64 = r25.u64;
	// b 0x825945f4
	goto loc_825945F4;
loc_825945F0:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_825945F4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594c68
	if (cr6.eq) goto loc_82594C68;
	// lis r29,-31927
	r29.s64 = -2092367872;
	// lwz r31,8(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + int32_t(8) );
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r30,152(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// stw r27,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r27.u32);
	// stw r27,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r27.u32);
	// stw r27,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r27.u32);
	// stw r27,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r27.u32);
	// lwz r9,28(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,60(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(60) );
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
	// lwz r8,144(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(144) );
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82594c68
	if (cr6.eq) goto loc_82594C68;
	// stw r31,396(r26)
	PPC_STORE_U32(r26.u32 + 396, r31.u32);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// stb r25,113(r1)
	PPC_STORE_U8(ctx.r1.u32 + 113, r25.u8);
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// stw r27,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r27.u32);
	// addi r4,r1,113
	ctx.r4.s64 = ctx.r1.s64 + 113;
	// stb r27,112(r1)
	PPC_STORE_U8(ctx.r1.u32 + 112, r27.u8);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82839a70
	sub_82839A70(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594870
	if (cr6.eq) goto loc_82594870;
	// lbz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 112);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// addi r4,r11,1292
	ctx.r4.s64 = r11.s64 + 1292;
	// beq cr6,0x825946f4
	if (cr6.eq) goto loc_825946F4;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,4116
	ctx.r4.s64 = ctx.r10.s64 + 4116;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// b 0x82594c54
	goto loc_82594C54;
loc_825946F4:
	// lbz r10,113(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 113);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825947b8
	if (cr6.eq) goto loc_825947B8;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r10,-32242
	ctx.r10.s64 = -2113011712;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,6912
	ctx.r4.s64 = ctx.r10.s64 + 6912;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r9,-31927
	ctx.r9.s64 = -2092367872;
	// stw r27,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r27.u32);
	// addi r6,r9,28340
	ctx.r6.s64 = ctx.r9.s64 + 28340;
loc_82594748:
	// mfmsr r7
	// mtmsrd r13,1
	// lwarx r8,0,r6
	reserved.u32 = *(uint32_t*)(base + ctx.r6.u32);
	ctx.r8.u64 = __builtin_bswap32(reserved.u32);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stwcx. r8,0,r6
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r6.u32), reserved.s32, __builtin_bswap32(ctx.r8.s32));
	cr0.so = xer.so;
	// mtmsrd r7,1
	// bne 0x82594748
	if (!cr0.eq) goto loc_82594748;
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(120) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8259477c
	if (!cr6.eq) goto loc_8259477C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r4,r11,-28040
	ctx.r4.s64 = r11.s64 + -28040;
	// b 0x82594780
	goto loc_82594780;
loc_8259477C:
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_82594780:
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// lwz r5,116(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// bl 0x82b39260
	sub_82B39260(ctx, base);
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,17
	ctx.r6.s64 = 17;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// b 0x82594c54
	goto loc_82594C54;
loc_825947B8:
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r10,-32242
	ctx.r10.s64 = -2113011712;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,6948
	ctx.r4.s64 = ctx.r10.s64 + 6948;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r9,-31927
	ctx.r9.s64 = -2092367872;
	// stw r27,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r27.u32);
	// addi r6,r9,28340
	ctx.r6.s64 = ctx.r9.s64 + 28340;
loc_82594800:
	// mfmsr r7
	// mtmsrd r13,1
	// lwarx r8,0,r6
	reserved.u32 = *(uint32_t*)(base + ctx.r6.u32);
	ctx.r8.u64 = __builtin_bswap32(reserved.u32);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stwcx. r8,0,r6
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r6.u32), reserved.s32, __builtin_bswap32(ctx.r8.s32));
	cr0.so = xer.so;
	// mtmsrd r7,1
	// bne 0x82594800
	if (!cr0.eq) goto loc_82594800;
	// lwz r11,124(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(124) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82594834
	if (!cr6.eq) goto loc_82594834;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r4,r11,-28040
	ctx.r4.s64 = r11.s64 + -28040;
	// b 0x82594838
	goto loc_82594838;
loc_82594834:
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_82594838:
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// lwz r5,116(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(116) );
	// bl 0x82b39260
	sub_82B39260(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,18
	ctx.r6.s64 = 18;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// b 0x82594c54
	goto loc_82594C54;
loc_82594870:
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82839750
	sub_82839750(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594bcc
	if (cr6.eq) goto loc_82594BCC;
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(144) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825948a8
	if (cr6.eq) goto loc_825948A8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// stw r10,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r10.u32);
	// stw r9,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r9.u32);
	// b 0x825948b0
	goto loc_825948B0;
loc_825948A8:
	// stw r27,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r27.u32);
	// stw r27,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r27.u32);
loc_825948B0:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8283bfb0
	sub_8283BFB0(ctx, base);
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(144) );
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(16) );
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x82594914
	if (cr6.eq) goto loc_82594914;
	// cmpwi cr6,r11,17
	cr6.compare<int32_t>(r11.s32, 17, xer);
	// beq cr6,0x82594914
	if (cr6.eq) goto loc_82594914;
	// cmpwi cr6,r11,18
	cr6.compare<int32_t>(r11.s32, 18, xer);
	// beq cr6,0x82594914
	if (cr6.eq) goto loc_82594914;
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// beq cr6,0x82594914
	if (cr6.eq) goto loc_82594914;
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// beq cr6,0x82594914
	if (cr6.eq) goto loc_82594914;
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// beq cr6,0x82594914
	if (cr6.eq) goto loc_82594914;
	// cmpwi cr6,r11,22
	cr6.compare<int32_t>(r11.s32, 22, xer);
	// beq cr6,0x82594914
	if (cr6.eq) goto loc_82594914;
	// cmpwi cr6,r11,23
	cr6.compare<int32_t>(r11.s32, 23, xer);
	// beq cr6,0x82594914
	if (cr6.eq) goto loc_82594914;
	// cmpwi cr6,r11,24
	cr6.compare<int32_t>(r11.s32, 24, xer);
	// beq cr6,0x82594914
	if (cr6.eq) goto loc_82594914;
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// bne cr6,0x82594918
	if (!cr6.eq) goto loc_82594918;
loc_82594914:
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_82594918:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// li r5,-1
	ctx.r5.s64 = -1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// beq cr6,0x825949f0
	if (cr6.eq) goto loc_825949F0;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,4156
	ctx.r4.s64 = r11.s64 + 4156;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r4,144(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(144) );
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// addi r4,r10,11628
	ctx.r4.s64 = ctx.r10.s64 + 11628;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x82b38b78
	sub_82B38B78(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,1292
	ctx.r4.s64 = ctx.r9.s64 + 1292;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// addi r4,r1,116
	ctx.r4.s64 = ctx.r1.s64 + 116;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82287710
	sub_82287710(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r6,20
	ctx.r6.s64 = 20;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// b 0x82594b3c
	goto loc_82594B3C;
loc_825949F0:
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82594a04
	if (!cr6.eq) goto loc_82594A04;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,4176
	ctx.r4.s64 = r11.s64 + 4176;
	// b 0x82594a0c
	goto loc_82594A0C;
loc_82594A04:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,4156
	ctx.r4.s64 = r11.s64 + 4156;
loc_82594A0C:
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r4,144(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(144) );
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// addi r4,r10,11628
	ctx.r4.s64 = ctx.r10.s64 + 11628;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x82b38b78
	sub_82B38B78(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,1292
	ctx.r4.s64 = ctx.r9.s64 + 1292;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// addi r4,r1,116
	ctx.r4.s64 = ctx.r1.s64 + 116;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82287710
	sub_82287710(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,21
	ctx.r6.s64 = 21;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// stw r27,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r27.u32);
	// stw r27,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r27.u32);
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// stw r27,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, r27.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// stw r27,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, r27.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82594c70
	sub_82594C70(ctx, base);
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(160) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594b1c
	if (cr6.eq) goto loc_82594B1C;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r26,24
	ctx.r3.s64 = r26.s64 + 24;
	// bl 0x828df988
	sub_828DF988(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r4,160(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(160) );
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82594ea0
	sub_82594EA0(ctx, base);
	// stb r25,441(r26)
	PPC_STORE_U8(r26.u32 + 441, r25.u8);
loc_82594B1C:
	// addi r3,r26,24
	ctx.r3.s64 = r26.s64 + 24;
	// bl 0x828e0070
	sub_828E0070(ctx, base);
	// lwz r3,160(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(160) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82594b38
	if (cr6.eq) goto loc_82594B38;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_82594B38:
	// stw r27,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r27.u32);
loc_82594B3C:
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(144) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594b5c
	if (cr6.eq) goto loc_82594B5C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(8) );
	// stw r10,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r10.u32);
	// stw r9,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r9.u32);
	// b 0x82594b64
	goto loc_82594B64;
loc_82594B5C:
	// stw r27,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r27.u32);
	// stw r27,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r27.u32);
loc_82594B64:
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// addi r7,r11,-10668
	ctx.r7.s64 = r11.s64 + -10668;
	// bl 0x821b2710
	sub_821B2710(ctx, base);
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// bl 0x822a97a8
	sub_822A97A8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82594b9c
	if (cr6.eq) goto loc_82594B9C;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r4,r11,-10648
	ctx.r4.s64 = r11.s64 + -10648;
	// bl 0x823b12e8
	sub_823B12E8(ctx, base);
	// cmpwi cr6,r3,500
	cr6.compare<int32_t>(ctx.r3.s32, 500, xer);
	// mr r11,r25
	r11.u64 = r25.u64;
	// bge cr6,0x82594ba0
	if (!cr6.lt) goto loc_82594BA0;
loc_82594B9C:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82594BA0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// li r5,-1
	ctx.r5.s64 = -1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// beq cr6,0x82594bc0
	if (cr6.eq) goto loc_82594BC0;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,4196
	ctx.r4.s64 = r11.s64 + 4196;
	// b 0x82594c44
	goto loc_82594C44;
loc_82594BC0:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r11,4240
	ctx.r4.s64 = r11.s64 + 4240;
	// b 0x82594c44
	goto loc_82594C44;
loc_82594BCC:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,1292
	ctx.r4.s64 = r11.s64 + 1292;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r10,-32242
	ctx.r10.s64 = -2113011712;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,6864
	ctx.r4.s64 = ctx.r10.s64 + 6864;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,16
	ctx.r6.s64 = 16;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,4272
	ctx.r4.s64 = ctx.r9.s64 + 4272;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
loc_82594C44:
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82595a58
	sub_82595A58(ctx, base);
loc_82594C54:
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(144) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82594c68
	if (cr6.eq) goto loc_82594C68;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_82594C68:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_82594468) {
	__imp__sub_82594468(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82594C70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// li r30,0
	r30.s64 = 0;
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(0) );
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// lwz r11,404(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(404) );
	// addi r31,r29,400
	r31.s64 = r29.s64 + 400;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594cdc
	if (cr6.eq) goto loc_82594CDC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82594d30
	if (cr6.eq) goto loc_82594D30;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594cdc
	if (cr6.eq) goto loc_82594CDC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82594ce0
	if (!cr6.eq) goto loc_82594CE0;
loc_82594CDC:
	// li r11,0
	r11.s64 = 0;
loc_82594CE0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594e8c
	if (cr6.eq) goto loc_82594E8C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(36) );
	// rlwinm r10,r11,5,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82594e04
	if (cr6.eq) goto loc_82594E04;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594d3c
	if (cr6.eq) goto loc_82594D3C;
	// lbz r10,27(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 27);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82594e08
	goto loc_82594E08;
loc_82594D30:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82594cdc
	goto loc_82594CDC;
loc_82594D3C:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// li r11,0
	r11.s64 = 0;
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// srawi. r11,r9,3
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7) != 0);
	r11.s64 = ctx.r9.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82594dac
	if (!cr0.gt) goto loc_82594DAC;
loc_82594D5C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,27
	cr6.compare<int32_t>(ctx.r7.s32, 27, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82594d7c
	if (cr6.lt) goto loc_82594D7C;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82594D7C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82594d98
	if (cr6.eq) goto loc_82594D98;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82594da0
	goto loc_82594DA0;
loc_82594D98:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82594DA0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82594d5c
	if (cr6.gt) goto loc_82594D5C;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_82594DAC:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82594df0
	if (cr6.eq) goto loc_82594DF0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82594dc8
	if (cr6.gt) goto loc_82594DC8;
	// li r11,0
	r11.s64 = 0;
loc_82594DC8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82594df0
	if (!cr6.eq) goto loc_82594DF0;
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82594e08
	goto loc_82594E08;
loc_82594DF0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82594e08
	goto loc_82594E08;
loc_82594E04:
	// li r11,0
	r11.s64 = 0;
loc_82594E08:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594e8c
	if (cr6.eq) goto loc_82594E8C;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(0) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82594e28
	if (cr6.eq) goto loc_82594E28;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x82594e2c
	goto loc_82594E2C;
loc_82594E28:
	// li r11,0
	r11.s64 = 0;
loc_82594E2C:
	// lwz r10,396(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + int32_t(396) );
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// addi r4,r29,444
	ctx.r4.s64 = r29.s64 + 444;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// bl 0x823660d0
	sub_823660D0(ctx, base);
	// lis r31,-31927
	r31.s64 = -2092367872;
	// lwz r3,26788(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// bl 0x821c7d38
	sub_821C7D38(ctx, base);
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x827af850
	sub_827AF850(ctx, base);
	// lis r9,-31926
	ctx.r9.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,26788(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// addi r5,r9,-30592
	ctx.r5.s64 = ctx.r9.s64 + -30592;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
loc_82594E8C:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82594C70) {
	__imp__sub_82594C70(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82594EA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq cr6,0x82595078
	if (cr6.eq) goto loc_82595078;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(12) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82595078
	if (cr6.eq) goto loc_82595078;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x827414a0
	sub_827414A0(ctx, base);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// ble cr6,0x82594f34
	if (!cr6.gt) goto loc_82594F34;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-3448
	ctx.r4.s64 = r11.s64 + -3448;
	// bl 0x82b38f30
	sub_82B38F30(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// lwz r4,12(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(12) );
	// bl 0x82303f98
	sub_82303F98(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82b38e60
	sub_82B38E60(ctx, base);
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
loc_82594F34:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82594f4c
	if (!cr6.eq) goto loc_82594F4C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r4,r11,-28040
	ctx.r4.s64 = r11.s64 + -28040;
	// b 0x82594f50
	goto loc_82594F50;
loc_82594F4C:
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
loc_82594F50:
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82407a98
	sub_82407A98(ctx, base);
	// lis r27,-31927
	r27.s64 = -2092367872;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,23044
	ctx.r4.s64 = r11.s64 + 23044;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// lwz r26,40(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// bl 0x8259d6c8
	sub_8259D6C8(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r30,92(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// li r5,-1
	ctx.r5.s64 = -1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,-3356
	ctx.r4.s64 = ctx.r10.s64 + -3356;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8259d6c8
	sub_8259D6C8(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(26788) );
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,4312
	ctx.r4.s64 = ctx.r9.s64 + 4312;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// lwz r8,56(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r27,152(r8)
	r27.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(152) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// lwz r6,16(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(16) );
	// cmpwi cr6,r6,1
	cr6.compare<int32_t>(ctx.r6.s32, 1, xer);
	// bne cr6,0x82595048
	if (!cr6.eq) goto loc_82595048;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r29,24
	ctx.r3.s64 = r29.s64 + 24;
	// bl 0x828e0e38
	sub_828E0E38(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595048
	if (cr6.eq) goto loc_82595048;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82595098
	sub_82595098(ctx, base);
loc_82595048:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82595058
	if (cr6.eq) goto loc_82595058;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_82595058:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c30
	return;
loc_82595078:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82595098
	sub_82595098(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82594EA0) {
	__imp__sub_82594EA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82595098) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r30,r11,-17088
	r30.s64 = r11.s64 + -17088;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r29,40(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + int32_t(40) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r28,-32246
	r28.s64 = -2113273856;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r10,r28,-27468
	ctx.r10.s64 = r28.s64 + -27468;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,12(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8259d5f8
	sub_8259D5F8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,-3176
	ctx.r4.s64 = ctx.r9.s64 + -3176;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r8,56(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r31,152(r8)
	r31.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(152) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// lfs f1,-27468(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + -27468);
	ctx.f1.f64 = double(temp.f32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8259d5f8
	sub_8259D5F8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r7,-32244
	ctx.r7.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r7,4348
	ctx.r4.s64 = ctx.r7.s64 + 4348;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r6,-32244
	ctx.r6.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r6,4384
	ctx.r4.s64 = ctx.r6.s64 + 4384;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r4,-32244
	ctx.r4.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r4,4420
	ctx.r4.s64 = ctx.r4.s64 + 4420;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r3,-32246
	ctx.r3.s64 = -2113273856;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r3,23044
	ctx.r4.s64 = ctx.r3.s64 + 23044;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8259d6c8
	sub_8259D6C8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,4428
	ctx.r4.s64 = r11.s64 + 4428;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82595098) {
	__imp__sub_82595098(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82595218) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r30,0
	r30.s64 = 0;
	// lwz r27,8(r4)
	r27.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(8) );
	// lis r29,-31927
	r29.s64 = -2092367872;
	// stw r30,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r30.u32);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// stw r30,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r30.u32);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// stw r30,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r30.u32);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// stw r30,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r30.u32);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(60) );
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82595628
	if (cr6.eq) goto loc_82595628;
	// lwz r3,26788(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// mr r28,r30
	r28.u64 = r30.u64;
	// bl 0x821c7d38
	sub_821C7D38(ctx, base);
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(36) );
	// rlwinm r9,r10,17,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82595378
	if (cr6.eq) goto loc_82595378;
	// lwz r11,140(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825952bc
	if (cr6.eq) goto loc_825952BC;
	// lbz r10,15(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 15);
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x8259537c
	goto loc_8259537C;
loc_825952BC:
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(72) );
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + int32_t(76) );
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82595328
	if (!cr0.gt) goto loc_82595328;
loc_825952D8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,15
	cr6.compare<int32_t>(ctx.r7.s32, 15, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825952f8
	if (cr6.lt) goto loc_825952F8;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_825952F8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82595314
	if (cr6.eq) goto loc_82595314;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8259531c
	goto loc_8259531C;
loc_82595314:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8259531C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825952d8
	if (cr6.gt) goto loc_825952D8;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_82595328:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82595368
	if (cr6.eq) goto loc_82595368;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82595344
	if (cr6.gt) goto loc_82595344;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82595344:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82595368
	if (!cr6.eq) goto loc_82595368;
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8259537c
	goto loc_8259537C;
loc_82595368:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x8259537c
	goto loc_8259537C;
loc_82595378:
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_8259537C:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825953b4
	if (cr6.eq) goto loc_825953B4;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x82574e70
	sub_82574E70(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825953b4
	if (cr6.eq) goto loc_825953B4;
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bgt cr6,0x825953b4
	if (cr6.gt) goto loc_825953B4;
	// li r28,1
	r28.s64 = 1;
loc_825953B4:
	// clrlwi r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82595550
	if (!cr6.eq) goto loc_82595550;
	// lbz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 36);
	// mr r11,r30
	r11.u64 = r30.u64;
	// clrlwi r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x825954b8
	if (cr6.eq) goto loc_825954B8;
	// lwz r11,140(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825953fc
	if (cr6.eq) goto loc_825953FC;
	// lbz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 24);
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x825954bc
	goto loc_825954BC;
loc_825953FC:
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + int32_t(72) );
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + int32_t(76) );
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82595468
	if (!cr0.gt) goto loc_82595468;
loc_82595418:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,24
	cr6.compare<int32_t>(ctx.r7.s32, 24, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82595438
	if (cr6.lt) goto loc_82595438;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_82595438:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82595454
	if (cr6.eq) goto loc_82595454;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x8259545c
	goto loc_8259545C;
loc_82595454:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8259545C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82595418
	if (cr6.gt) goto loc_82595418;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_82595468:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825954a8
	if (cr6.eq) goto loc_825954A8;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,24
	cr6.compare<int32_t>(r11.s32, 24, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82595484
	if (cr6.gt) goto loc_82595484;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82595484:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825954a8
	if (!cr6.eq) goto loc_825954A8;
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(92) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x825954bc
	goto loc_825954BC;
loc_825954A8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x825954bc
	goto loc_825954BC;
loc_825954B8:
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_825954BC:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82595550
	if (cr6.eq) goto loc_82595550;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x824ffc00
	sub_824FFC00(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825954f0
	if (cr6.eq) goto loc_825954F0;
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x825954f4
	if (!cr6.eq) goto loc_825954F4;
loc_825954F0:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_825954F4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595550
	if (cr6.eq) goto loc_82595550;
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// li r31,1
	r31.s64 = 1;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(16) );
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x82595530
	if (!cr6.eq) goto loc_82595530;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r26,24
	ctx.r3.s64 = r26.s64 + 24;
	// bl 0x828e0e38
	sub_828E0E38(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82595530
	if (!cr6.eq) goto loc_82595530;
	// mr r31,r30
	r31.u64 = r30.u64;
loc_82595530:
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595550
	if (cr6.eq) goto loc_82595550;
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bgt cr6,0x82595550
	if (cr6.gt) goto loc_82595550;
	// li r28,1
	r28.s64 = 1;
loc_82595550:
	// clrlwi r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825955d8
	if (cr6.eq) goto loc_825955D8;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// stw r27,396(r26)
	PPC_STORE_U32(r26.u32 + 396, r27.u32);
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,1292
	ctx.r4.s64 = ctx.r10.s64 + 1292;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r31,152(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lis r8,-31926
	ctx.r8.s64 = -2092302336;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r8,-29544
	ctx.r4.s64 = ctx.r8.s64 + -29544;
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r6,19
	ctx.r6.s64 = 19;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// b 0x82595614
	goto loc_82595614;
loc_825955D8:
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825955ec
	if (cr6.eq) goto loc_825955EC;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x825955f0
	goto loc_825955F0;
loc_825955EC:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_825955F0:
	// stw r27,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r27.u32);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// addi r4,r26,444
	ctx.r4.s64 = r26.s64 + 444;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x823660d0
	sub_823660D0(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82594210
	sub_82594210(ctx, base);
loc_82595614:
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(112) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82595628
	if (cr6.eq) goto loc_82595628;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_82595628:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82595218) {
	__imp__sub_82595218(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82595630) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	// lis r11,-31927
	r11.s64 = -2092367872;
	// fsubs f0,f2,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = static_cast<float>(ctx.f2.f64 - ctx.f1.f64);
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// fctidz f13,f0
	ctx.f13.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f13,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.f13.u64);
	// lwz r11,-12(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-12) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r8,120(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(120) );
	// mulli r10,r8,9377
	ctx.r10.s64 = ctx.r8.s64 * 9377;
	// addi r7,r10,9439
	ctx.r7.s64 = ctx.r10.s64 + 9439;
	// rotlwi r10,r7,19
	ctx.r10.u64 = rotl32(ctx.r7.u32, 19);
	// stw r10,120(r9)
	PPC_STORE_U32(ctx.r9.u32 + 120, ctx.r10.u32);
	// beq cr6,0x82595680
	if (cr6.eq) goto loc_82595680;
	// divwu r9,r10,r11
	ctx.r9.u32 = ctx.r10.u32 / r11.u32;
	// mullw r8,r9,r11
	ctx.r8.s64 = int64_t(ctx.r9.s32) * int64_t(r11.s32);
	// subf r11,r8,r10
	r11.s64 = ctx.r10.s64 - ctx.r8.s64;
	// b 0x82595684
	goto loc_82595684;
loc_82595680:
	// li r11,0
	r11.s64 = 0;
loc_82595684:
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r11.u64);
	// lfd f0,-16(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// fcfid f13,f0
	ctx.f13.f64 = double(f0.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// fadds f1,f12,f1
	ctx.f1.f64 = double(float(ctx.f12.f64 + ctx.f1.f64));
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82595630) {
	__imp__sub_82595630(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825956A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82593220
	sub_82593220(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259570c
	if (cr6.eq) goto loc_8259570C;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,4460
	ctx.r4.s64 = r11.s64 + 4460;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825956f8
	if (cr6.eq) goto loc_825956F8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_825956F8:
	// li r11,0
	r11.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c38
	return;
loc_8259570C:
	// li r29,0
	r29.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r29,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r29.u32);
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// bl 0x82592df8
	sub_82592DF8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259574c
	if (cr6.eq) goto loc_8259574C;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r10,r11,4496
	ctx.r10.s64 = r11.s64 + 4496;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x8228a900
	sub_8228A900(ctx, base);
loc_8259574C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82593010
	sub_82593010(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259577c
	if (cr6.eq) goto loc_8259577C;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r10,r11,4528
	ctx.r10.s64 = r11.s64 + 4528;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x8228a900
	sub_8228A900(ctx, base);
loc_8259577C:
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8257ca28
	sub_8257CA28(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82835508
	sub_82835508(ctx, base);
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(180) );
	// li r31,1
	r31.s64 = 1;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x825957a4
	if (!cr6.lt) goto loc_825957A4;
	// mr r31,r29
	r31.u64 = r29.u64;
loc_825957A4:
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8257e830
	sub_8257E830(ctx, base);
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825957d0
	if (cr6.eq) goto loc_825957D0;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r10,r11,4564
	ctx.r10.s64 = r11.s64 + 4564;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x8228a900
	sub_8228A900(ctx, base);
loc_825957D0:
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595864
	if (cr6.eq) goto loc_82595864;
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(104) );
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// srawi r11,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	r11.s64 = ctx.r9.s32 >> 2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595864
	if (cr6.eq) goto loc_82595864;
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r10,26912(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(12) );
	// lwz r8,88(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(88) );
	// lwz r7,4(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(4) );
	// lwz r6,120(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + int32_t(120) );
	// mulli r10,r6,9377
	ctx.r10.s64 = ctx.r6.s64 * 9377;
	// addi r5,r10,9439
	ctx.r5.s64 = ctx.r10.s64 + 9439;
	// rotlwi r10,r5,19
	ctx.r10.u64 = rotl32(ctx.r5.u32, 19);
	// stw r10,120(r7)
	PPC_STORE_U32(ctx.r7.u32 + 120, ctx.r10.u32);
	// beq cr6,0x82595830
	if (cr6.eq) goto loc_82595830;
	// divwu r9,r10,r11
	ctx.r9.u32 = ctx.r10.u32 / r11.u32;
	// mullw r8,r9,r11
	ctx.r8.s64 = int64_t(ctx.r9.s32) * int64_t(r11.s32);
	// subf r11,r8,r10
	r11.s64 = ctx.r10.s64 - ctx.r8.s64;
	// b 0x82595834
	goto loc_82595834;
loc_82595830:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82595834:
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82595854
	if (cr6.eq) goto loc_82595854;
	// lwz r9,104(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(104) );
	// subf r8,r10,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r10.s64;
	// srawi r9,r8,2
	xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x3) != 0);
	ctx.r9.s64 = ctx.r8.s32 >> 2;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82595858
	if (cr6.lt) goto loc_82595858;
loc_82595854:
	// twi 31,r0,22
loc_82595858:
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x8259586c
	goto loc_8259586C;
loc_82595864:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r11,3224
	ctx.r4.s64 = r11.s64 + 3224;
loc_8259586C:
	// li r5,-1
	ctx.r5.s64 = -1;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82595888
	if (cr6.eq) goto loc_82595888;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_82595888:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(0) );
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r29,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r29.u32);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// beq cr6,0x825958a8
	if (cr6.eq) goto loc_825958A8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_825958A8:
	// stw r29,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r29.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_825956A0) {
	__imp__sub_825956A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825958B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// lwz r11,408(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(408) );
	// lwz r4,4(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + int32_t(4) );
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// beq cr6,0x82595918
	if (cr6.eq) goto loc_82595918;
	// stw r4,408(r30)
	PPC_STORE_U32(r30.u32 + 408, ctx.r4.u32);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-4364
	ctx.r10.s64 = r11.s64 + -4364;
	// lfs f2,-14888(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -14888);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,-14868(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -14868);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82595630
	sub_82595630(ctx, base);
	// addi r3,r30,412
	ctx.r3.s64 = r30.s64 + 412;
	// bl 0x82834498
	sub_82834498(ctx, base);
	// addi r3,r30,88
	ctx.r3.s64 = r30.s64 + 88;
	// bl 0x828e30d0
	sub_828E30D0(ctx, base);
	// addi r3,r30,128
	ctx.r3.s64 = r30.s64 + 128;
	// bl 0x828e4360
	sub_828E4360(ctx, base);
	// addi r3,r30,368
	ctx.r3.s64 = r30.s64 + 368;
	// bl 0x828e4dd8
	sub_828E4DD8(ctx, base);
	// b 0x82595a3c
	goto loc_82595A3C;
loc_82595918:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(0) );
	// cmpwi cr6,r11,301
	cr6.compare<int32_t>(r11.s32, 301, xer);
	// beq cr6,0x82595a3c
	if (cr6.eq) goto loc_82595A3C;
	// li r31,0
	r31.s64 = 0;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// stw r31,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r31.u32);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// stw r31,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r31.u32);
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,60(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(60) );
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// bl 0x827be1e8
	sub_827BE1E8(ctx, base);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82595a38
	if (cr6.eq) goto loc_82595A38;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + int32_t(0) );
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// beq cr6,0x82595a24
	if (cr6.eq) goto loc_82595A24;
	// addi r28,r30,412
	r28.s64 = r30.s64 + 412;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82834510
	sub_82834510(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595a24
	if (cr6.eq) goto loc_82595A24;
	// addi r29,r30,424
	r29.s64 = r30.s64 + 424;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82834510
	sub_82834510(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595a24
	if (cr6.eq) goto loc_82595A24;
	// stw r31,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r31.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// stw r31,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r31.u32);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// stw r31,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r31.u32);
	// stw r31,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r31.u32);
	// bl 0x8218df70
	sub_8218DF70(ctx, base);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x825956a0
	sub_825956A0(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595a14
	if (cr6.eq) goto loc_82595A14;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82595a14
	if (cr6.eq) goto loc_82595A14;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82595a58
	sub_82595A58(ctx, base);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// lfs f2,-4364(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -4364);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,27524(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 27524);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82595630
	sub_82595630(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82834498
	sub_82834498(ctx, base);
loc_82595A14:
	// stb r31,0(r28)
	PPC_STORE_U8(r28.u32 + 0, r31.u8);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stb r31,1(r28)
	PPC_STORE_U8(r28.u32 + 1, r31.u8);
	// bl 0x82214f08
	sub_82214F08(ctx, base);
loc_82595A24:
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(96) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82595a38
	if (cr6.eq) goto loc_82595A38;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82741bd8
	sub_82741BD8(ctx, base);
loc_82595A38:
	// stw r31,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r31.u32);
loc_82595A3C:
	// addi r3,r27,12
	ctx.r3.s64 = r27.s64 + 12;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r3,r27,8
	ctx.r3.s64 = r27.s64 + 8;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_825958B8) {
	__imp__sub_825958B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82595A58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,404(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(404) );
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r31,r3,400
	r31.s64 = ctx.r3.s64 + 400;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595ab0
	if (cr6.eq) goto loc_82595AB0;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82595b04
	if (cr6.eq) goto loc_82595B04;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595ab0
	if (cr6.eq) goto loc_82595AB0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82595ab4
	if (!cr6.eq) goto loc_82595AB4;
loc_82595AB0:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82595AB4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595c28
	if (cr6.eq) goto loc_82595C28;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(48) );
	// rlwinm r10,r11,28,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82595bd4
	if (cr6.eq) goto loc_82595BD4;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595b10
	if (cr6.eq) goto loc_82595B10;
	// lbz r10,100(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 100);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82595bd8
	goto loc_82595BD8;
loc_82595B04:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82595ab0
	goto loc_82595AB0;
loc_82595B10:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82595b7c
	if (!cr0.gt) goto loc_82595B7C;
loc_82595B2C:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,100
	cr6.compare<int32_t>(ctx.r7.s32, 100, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82595b4c
	if (cr6.lt) goto loc_82595B4C;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
loc_82595B4C:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82595b68
	if (cr6.eq) goto loc_82595B68;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82595b70
	goto loc_82595B70;
loc_82595B68:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82595B70:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82595b2c
	if (cr6.gt) goto loc_82595B2C;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82595B7C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82595bc0
	if (cr6.eq) goto loc_82595BC0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,100
	cr6.compare<int32_t>(r11.s32, 100, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82595b98
	if (cr6.gt) goto loc_82595B98;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82595B98:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82595bc0
	if (!cr6.eq) goto loc_82595BC0;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82595bd8
	goto loc_82595BD8;
loc_82595BC0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x82595bd8
	goto loc_82595BD8;
loc_82595BD4:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82595BD8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82595c28
	if (cr6.eq) goto loc_82595C28;
	// li r10,-1
	ctx.r10.s64 = -1;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82448530
	sub_82448530(ctx, base);
	// lwz r3,56(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(56) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82595c28
	if (cr6.eq) goto loc_82595C28;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(20) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82595C28:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82595A58) {
	__imp__sub_82595A58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82595C38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,48
	ctx.r3.s64 = 48;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82595ca8
	if (cr6.eq) goto loc_82595CA8;
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// li r11,16
	r11.s64 = 16;
	// addi r8,r10,-32248
	ctx.r8.s64 = ctx.r10.s64 + -32248;
	// addi r7,r9,21572
	ctx.r7.s64 = ctx.r9.s64 + 21572;
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// lis r6,-32244
	ctx.r6.s64 = -2113142784;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// stw r7,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r7.u32);
	// addi r4,r6,4644
	ctx.r4.s64 = ctx.r6.s64 + 4644;
	// stw r5,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r5.u32);
	// lvx128 v0,r31,r11
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r31.u32 + r11.u32) & ~0xF), VectorMaskL));
	// stvx128 v0,r3,r11
	ea = (ctx.r3.u32 + r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f0,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	f0.f64 = double(temp.f32);
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// stfs f0,32(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 32, temp.u32);
	// b 0x82595cac
	goto loc_82595CAC;
loc_82595CA8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82595CAC:
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// beq cr6,0x82595cc8
	if (cr6.eq) goto loc_82595CC8;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x82595cd0
	goto loc_82595CD0;
loc_82595CC8:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_82595CD0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82595C38) {
	__imp__sub_82595C38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82595CE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,8
	ctx.r3.s64 = 8;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82595d3c
	if (cr6.eq) goto loc_82595D3C;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r9,r11,-32248
	ctx.r9.s64 = r11.s64 + -32248;
	// addi r8,r10,4672
	ctx.r8.s64 = ctx.r10.s64 + 4672;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// stw r7,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r7.u32);
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// b 0x82595d40
	goto loc_82595D40;
loc_82595D3C:
	// li r11,0
	r11.s64 = 0;
loc_82595D40:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x82595d5c
	if (cr6.eq) goto loc_82595D5C;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x82595d64
	goto loc_82595D64;
loc_82595D5C:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_82595D64:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82595CE8) {
	__imp__sub_82595CE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82595D80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,8
	ctx.r3.s64 = 8;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82595dd4
	if (cr6.eq) goto loc_82595DD4;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r9,r11,-32248
	ctx.r9.s64 = r11.s64 + -32248;
	// addi r8,r10,4696
	ctx.r8.s64 = ctx.r10.s64 + 4696;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// stw r7,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r7.u32);
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// b 0x82595dd8
	goto loc_82595DD8;
loc_82595DD4:
	// li r11,0
	r11.s64 = 0;
loc_82595DD8:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x82595df4
	if (cr6.eq) goto loc_82595DF4;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x82595dfc
	goto loc_82595DFC;
loc_82595DF4:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_82595DFC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82595D80) {
	__imp__sub_82595D80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82595E18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,8
	ctx.r3.s64 = 8;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82595e6c
	if (cr6.eq) goto loc_82595E6C;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r9,r11,-32248
	ctx.r9.s64 = r11.s64 + -32248;
	// addi r8,r10,4720
	ctx.r8.s64 = ctx.r10.s64 + 4720;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// stw r7,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r7.u32);
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// b 0x82595e70
	goto loc_82595E70;
loc_82595E6C:
	// li r11,0
	r11.s64 = 0;
loc_82595E70:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x82595e8c
	if (cr6.eq) goto loc_82595E8C;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x82595e94
	goto loc_82595E94;
loc_82595E8C:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_82595E94:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82595E18) {
	__imp__sub_82595E18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82595EB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,48
	ctx.r3.s64 = 48;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82595f20
	if (cr6.eq) goto loc_82595F20;
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// li r11,16
	r11.s64 = 16;
	// addi r8,r10,-32248
	ctx.r8.s64 = ctx.r10.s64 + -32248;
	// addi r7,r9,21572
	ctx.r7.s64 = ctx.r9.s64 + 21572;
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// lis r6,-32244
	ctx.r6.s64 = -2113142784;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// stw r7,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r7.u32);
	// addi r4,r6,4744
	ctx.r4.s64 = ctx.r6.s64 + 4744;
	// stw r5,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r5.u32);
	// lvx128 v0,r31,r11
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r31.u32 + r11.u32) & ~0xF), VectorMaskL));
	// stvx128 v0,r3,r11
	ea = (ctx.r3.u32 + r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f0,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	f0.f64 = double(temp.f32);
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// stfs f0,32(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 32, temp.u32);
	// b 0x82595f24
	goto loc_82595F24;
loc_82595F20:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82595F24:
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// beq cr6,0x82595f40
	if (cr6.eq) goto loc_82595F40;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x82595f48
	goto loc_82595F48;
loc_82595F40:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_82595F48:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82595EB0) {
	__imp__sub_82595EB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82595F60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,48
	ctx.r3.s64 = 48;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82595fd0
	if (cr6.eq) goto loc_82595FD0;
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// li r11,16
	r11.s64 = 16;
	// addi r8,r10,-32248
	ctx.r8.s64 = ctx.r10.s64 + -32248;
	// addi r7,r9,21572
	ctx.r7.s64 = ctx.r9.s64 + 21572;
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// lis r6,-32244
	ctx.r6.s64 = -2113142784;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// stw r7,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r7.u32);
	// addi r4,r6,4772
	ctx.r4.s64 = ctx.r6.s64 + 4772;
	// stw r5,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r5.u32);
	// lvx128 v0,r31,r11
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r31.u32 + r11.u32) & ~0xF), VectorMaskL));
	// stvx128 v0,r3,r11
	ea = (ctx.r3.u32 + r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f0,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	f0.f64 = double(temp.f32);
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// stfs f0,32(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 32, temp.u32);
	// b 0x82595fd4
	goto loc_82595FD4;
loc_82595FD0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82595FD4:
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// beq cr6,0x82595ff0
	if (cr6.eq) goto loc_82595FF0;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x82595ff8
	goto loc_82595FF8;
loc_82595FF0:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_82595FF8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82595F60) {
	__imp__sub_82595F60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82596010) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,8
	ctx.r3.s64 = 8;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82596064
	if (cr6.eq) goto loc_82596064;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r9,r11,-32248
	ctx.r9.s64 = r11.s64 + -32248;
	// addi r8,r10,4800
	ctx.r8.s64 = ctx.r10.s64 + 4800;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// stw r7,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r7.u32);
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// b 0x82596068
	goto loc_82596068;
loc_82596064:
	// li r11,0
	r11.s64 = 0;
loc_82596068:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x82596084
	if (cr6.eq) goto loc_82596084;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x8259608c
	goto loc_8259608C;
loc_82596084:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_8259608C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82596010) {
	__imp__sub_82596010(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825960A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,8
	ctx.r3.s64 = 8;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825960fc
	if (cr6.eq) goto loc_825960FC;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r9,r11,-32248
	ctx.r9.s64 = r11.s64 + -32248;
	// addi r8,r10,4824
	ctx.r8.s64 = ctx.r10.s64 + 4824;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + int32_t(4) );
	// stw r7,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r7.u32);
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// b 0x82596100
	goto loc_82596100;
loc_825960FC:
	// li r11,0
	r11.s64 = 0;
loc_82596100:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x8259611c
	if (cr6.eq) goto loc_8259611C;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x82596124
	goto loc_82596124;
loc_8259611C:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_82596124:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825960A8) {
	__imp__sub_825960A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82596140) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,48
	ctx.r3.s64 = 48;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x825961b0
	if (cr6.eq) goto loc_825961B0;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// li r10,16
	ctx.r10.s64 = 16;
	// addi r8,r11,-32248
	ctx.r8.s64 = r11.s64 + -32248;
	// addi r7,r9,4848
	ctx.r7.s64 = ctx.r9.s64 + 4848;
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// stw r6,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r6.u32);
	// stw r7,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r7.u32);
	// lvx128 v0,r31,r10
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r31.u32 + ctx.r10.u32) & ~0xF), VectorMaskL));
	// stvx128 v0,r3,r10
	ea = (ctx.r3.u32 + ctx.r10.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// lwz r5,32(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + int32_t(32) );
	// stw r5,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r5.u32);
	// lfs f0,36(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 36);
	f0.f64 = double(temp.f32);
	// stfs f0,36(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 36, temp.u32);
	// b 0x825961b4
	goto loc_825961B4;
loc_825961B0:
	// li r11,0
	r11.s64 = 0;
loc_825961B4:
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// beq cr6,0x825961d0
	if (cr6.eq) goto loc_825961D0;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x825961d8
	goto loc_825961D8;
loc_825961D0:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_825961D8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82596140) {
	__imp__sub_82596140(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825961F0) {
	PPC_FUNC_PROLOGUE();
	// li r3,15
	ctx.r3.s64 = 15;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825961F0) {
	__imp__sub_825961F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825961F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,48
	ctx.r3.s64 = 48;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82596268
	if (cr6.eq) goto loc_82596268;
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// li r11,16
	r11.s64 = 16;
	// addi r8,r10,-32248
	ctx.r8.s64 = ctx.r10.s64 + -32248;
	// addi r7,r9,21572
	ctx.r7.s64 = ctx.r9.s64 + 21572;
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// lis r6,-32244
	ctx.r6.s64 = -2113142784;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + int32_t(4) );
	// stw r7,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r7.u32);
	// addi r4,r6,4872
	ctx.r4.s64 = ctx.r6.s64 + 4872;
	// stw r5,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r5.u32);
	// lvx128 v0,r31,r11
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((r31.u32 + r11.u32) & ~0xF), VectorMaskL));
	// stvx128 v0,r3,r11
	ea = (ctx.r3.u32 + r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// lfs f0,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	f0.f64 = double(temp.f32);
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// stfs f0,32(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 32, temp.u32);
	// b 0x8259626c
	goto loc_8259626C;
loc_82596268:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8259626C:
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// beq cr6,0x82596288
	if (cr6.eq) goto loc_82596288;
	// bl 0x8254c780
	sub_8254C780(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x82596290
	goto loc_82596290;
loc_82596288:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_82596290:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825961F8) {
	__imp__sub_825961F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825962A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// addi r9,r11,23160
	ctx.r9.s64 = r11.s64 + 23160;
	// addi r8,r10,5732
	ctx.r8.s64 = ctx.r10.s64 + 5732;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// stw r8,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r8.u32);
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// lis r7,-32246
	ctx.r7.s64 = -2113273856;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r7,23128
	ctx.r5.s64 = ctx.r7.s64 + 23128;
	// stw r6,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r6.u32);
	// stw r5,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r5.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825962A8) {
	__imp__sub_825962A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82596308) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32241
	r11.s64 = -2112946176;
	// lfs f1,27524(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 27524);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82596308) {
	__imp__sub_82596308(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82596318) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lfs f1,-27400(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -27400);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82596318) {
	__imp__sub_82596318(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82596328) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// li r11,1
	r11.s64 = 1;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// stb r11,16(r3)
	PPC_STORE_U8(ctx.r3.u32 + 16, r11.u8);
	// lwz r11,26912(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26912) );
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r3,124(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(124) );
	// b 0x825bb2c0
	sub_825BB2C0(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82596328) {
	__imp__sub_82596328(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82596348) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31950
	r11.s64 = -2093875200;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,-27380(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(-27380) );
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + int32_t(0) );
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(16) );
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi r8,r3,24
	ctx.r8.u64 = ctx.r3.u32 & 0xFF;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x825964bc
	if (cr6.eq) goto loc_825964BC;
	// addi r3,r30,4
	ctx.r3.s64 = r30.s64 + 4;
	// mr r31,r29
	r31.u64 = r29.u64;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lwz r11,44(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(44) );
	// rlwinm r10,r11,19,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82596498
	if (cr6.eq) goto loc_82596498;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825963d4
	if (cr6.eq) goto loc_825963D4;
	// lbz r10,77(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 77);
	// lwz r11,72(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8259649c
	goto loc_8259649C;
loc_825963D4:
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82596440
	if (!cr0.gt) goto loc_82596440;
loc_825963F0:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,77
	cr6.compare<int32_t>(ctx.r7.s32, 77, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82596410
	if (cr6.lt) goto loc_82596410;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_82596410:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8259642c
	if (cr6.eq) goto loc_8259642C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82596434
	goto loc_82596434;
loc_8259642C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82596434:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825963f0
	if (cr6.gt) goto loc_825963F0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82596440:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82596484
	if (cr6.eq) goto loc_82596484;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,77
	cr6.compare<int32_t>(r11.s32, 77, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8259645c
	if (cr6.gt) goto loc_8259645C;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8259645C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82596484
	if (!cr6.eq) goto loc_82596484;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8259649c
	goto loc_8259649C;
loc_82596484:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r11,1
	r11.s64 = 1;
	// b 0x8259649c
	goto loc_8259649C;
loc_82596498:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8259649C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825964bc
	if (cr6.eq) goto loc_825964BC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_825964BC:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(8) );
	// addi r31,r30,4
	r31.s64 = r30.s64 + 4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825964e8
	if (cr6.eq) goto loc_825964E8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825964e0
	if (cr6.eq) goto loc_825964E0;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x825964ec
	goto loc_825964EC;
loc_825964E0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_825964E8:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_825964EC:
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(48) );
	// rlwinm r9,r10,30,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x825965e0
	if (cr6.eq) goto loc_825965E0;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82596524
	if (cr6.eq) goto loc_82596524;
	// lbz r9,98(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 98);
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r11,r9,3
	r11.u64 = rotl32(ctx.r9.u32, 3);
	// add r8,r11,r10
	ctx.r8.u64 = r11.u64 + ctx.r10.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(4) );
	// b 0x825965e8
	goto loc_825965E8;
loc_82596524:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82596590
	if (!cr0.gt) goto loc_82596590;
loc_82596540:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,98
	cr6.compare<int32_t>(ctx.r7.s32, 98, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82596560
	if (cr6.lt) goto loc_82596560;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_82596560:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8259657c
	if (cr6.eq) goto loc_8259657C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82596584
	goto loc_82596584;
loc_8259657C:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82596584:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82596540
	if (cr6.gt) goto loc_82596540;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82596590:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x825965d0
	if (cr6.eq) goto loc_825965D0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,98
	cr6.compare<int32_t>(r11.s32, 98, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x825965ac
	if (cr6.gt) goto loc_825965AC;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_825965AC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x825965d0
	if (!cr6.eq) goto loc_825965D0;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x825965e8
	goto loc_825965E8;
loc_825965D0:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// b 0x825965e8
	goto loc_825965E8;
loc_825965E0:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(80) );
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_825965E8:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8259660c
	if (cr6.eq) goto loc_8259660C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r31,r11,20
	r31.s64 = r11.s64 + 20;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8273da00
	sub_8273DA00(ctx, base);
loc_8259660C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82596348) {
	__imp__sub_82596348(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82596618) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r25{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-448(r1)
	ea = -448 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// li r30,0
	r30.s64 = 0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(8) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82596670
	if (cr6.eq) goto loc_82596670;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825967a4
	if (cr6.eq) goto loc_825967A4;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82596670
	if (cr6.eq) goto loc_82596670;
	// bl 0x825575c8
	sub_825575C8(ctx, base);
	// lbz r11,144(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82596674
	if (!cr6.eq) goto loc_82596674;
loc_82596670:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82596674:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825969e0
	if (cr6.eq) goto loc_825969E0;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(0) );
	// addi r11,r11,-6
	r11.s64 = r11.s64 + -6;
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// bgt cr6,0x825969e0
	if (cr6.gt) goto loc_825969E0;
	// lis r12,-32167
	r12.s64 = -2108096512;
	// addi r12,r12,26280
	r12.s64 = r12.s64 + 26280;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_825969C4;
	case 1:
		goto loc_825969E0;
	case 2:
		goto loc_825969E0;
	case 3:
		goto loc_825969E0;
	case 4:
		goto loc_825969E0;
	case 5:
		goto loc_825969E0;
	case 6:
		goto loc_825969E0;
	case 7:
		goto loc_82596918;
	case 8:
		goto loc_8259693C;
	case 9:
		goto loc_82596978;
	case 10:
		goto loc_825969E0;
	case 11:
		goto loc_825967AC;
	case 12:
		goto loc_82596858;
	case 13:
		goto loc_825969E0;
	case 14:
		goto loc_825969E0;
	case 15:
		goto loc_825969E0;
	case 16:
		goto loc_825969E0;
	case 17:
		goto loc_825969E0;
	case 18:
		goto loc_825969E0;
	case 19:
		goto loc_825969E0;
	case 20:
		goto loc_825969E0;
	case 21:
		goto loc_825969E0;
	case 22:
		goto loc_825969E0;
	case 23:
		goto loc_825969E0;
	case 24:
		goto loc_825969E0;
	case 25:
		goto loc_825969E0;
	case 26:
		goto loc_825969E0;
	case 27:
		goto loc_825969E0;
	case 28:
		goto loc_825969E0;
	case 29:
		goto loc_825969E0;
	case 30:
		goto loc_825969E0;
	case 31:
		goto loc_825969E0;
	case 32:
		goto loc_825969E0;
	case 33:
		goto loc_825969E0;
	case 34:
		goto loc_825969E0;
	case 35:
		goto loc_825969E0;
	case 36:
		goto loc_825969E0;
	case 37:
		goto loc_825969E0;
	case 38:
		goto loc_825969E0;
	case 39:
		goto loc_825969E0;
	case 40:
		goto loc_825969E0;
	case 41:
		goto loc_825969E0;
	case 42:
		goto loc_825967E8;
	case 43:
		goto loc_825969E0;
	case 44:
		goto loc_825969E0;
	case 45:
		goto loc_825969E0;
	case 46:
		goto loc_825968B8;
	case 47:
		goto loc_825969E0;
	case 48:
		goto loc_825969E0;
	case 49:
		goto loc_825969E0;
	case 50:
		goto loc_825969E0;
	case 51:
		goto loc_825969E0;
	case 52:
		goto loc_825969E0;
	case 53:
		goto loc_825969E0;
	case 54:
		goto loc_825969E0;
	case 55:
		goto loc_825969E0;
	case 56:
		goto loc_825969E0;
	case 57:
		goto loc_82596824;
	case 58:
		goto loc_82596894;
	case 59:
		goto loc_825969E0;
	case 60:
		goto loc_825969E0;
	case 61:
		goto loc_825969E0;
	case 62:
		goto loc_825968DC;
	default:
		__builtin_unreachable();
	}
	// lwz r18,27076(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27076) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,26904(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(26904) );
	// lwz r18,26940(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(26940) );
	// lwz r18,27000(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27000) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,26540(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(26540) );
	// lwz r18,26712(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(26712) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,26600(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(26600) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,26808(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(26808) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,26660(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(26660) );
	// lwz r18,26772(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(26772) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,27104(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(27104) );
	// lwz r18,26844(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(26844) );
loc_825967A4:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
	// b 0x82596670
	goto loc_82596670;
loc_825967AC:
	// vspltisw v0,0
	simd::store_i32(ctx.v0.u32, simd::set1_i32(int32_t(0x0)));
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r8,r9,4744
	ctx.r8.s64 = ctx.r9.s64 + 4744;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f0,-17752(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -17752);
	f0.f64 = double(temp.f32);
	// stvx128 v0,r0,r11
	ea = (r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r30.u32);
	// stfs f0,160(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// stw r8,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r8.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// b 0x82ca2c3c
	return;
loc_825967E8:
	// vspltisw v0,0
	simd::store_i32(ctx.v0.u32, simd::set1_i32(int32_t(0x0)));
	// addi r11,r1,240
	r11.s64 = ctx.r1.s64 + 240;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r8,r9,4772
	ctx.r8.s64 = ctx.r9.s64 + 4772;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f0,-17752(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -17752);
	f0.f64 = double(temp.f32);
	// stvx128 v0,r0,r11
	ea = (r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// stw r30,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, r30.u32);
	// stfs f0,256(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stw r8,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, ctx.r8.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// b 0x82ca2c3c
	return;
loc_82596824:
	// vspltisw v0,0
	simd::store_i32(ctx.v0.u32, simd::set1_i32(int32_t(0x0)));
	// addi r11,r1,336
	r11.s64 = ctx.r1.s64 + 336;
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r4,r1,320
	ctx.r4.s64 = ctx.r1.s64 + 320;
	// addi r9,r10,4848
	ctx.r9.s64 = ctx.r10.s64 + 4848;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stvx128 v0,r0,r11
	ea = (r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// stw r30,324(r1)
	PPC_STORE_U32(ctx.r1.u32 + 324, r30.u32);
	// stw r9,320(r1)
	PPC_STORE_U32(ctx.r1.u32 + 320, ctx.r9.u32);
	// stw r30,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, r30.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// b 0x82ca2c3c
	return;
loc_82596858:
	// vspltisw v0,0
	simd::store_i32(ctx.v0.u32, simd::set1_i32(int32_t(0x0)));
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// addi r8,r9,4872
	ctx.r8.s64 = ctx.r9.s64 + 4872;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f0,-17752(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -17752);
	f0.f64 = double(temp.f32);
	// stvx128 v0,r0,r11
	ea = (r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// stw r30,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r30.u32);
	// stfs f0,208(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// stw r8,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r8.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// b 0x82ca2c3c
	return;
loc_82596894:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// stw r30,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r30.u32);
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// addi r10,r11,4824
	ctx.r10.s64 = r11.s64 + 4824;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r10.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// b 0x82ca2c3c
	return;
loc_825968B8:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// stw r30,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r30.u32);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r10,r11,4800
	ctx.r10.s64 = r11.s64 + 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// b 0x82ca2c3c
	return;
loc_825968DC:
	// vspltisw v0,0
	simd::store_i32(ctx.v0.u32, simd::set1_i32(int32_t(0x0)));
	// addi r11,r1,288
	r11.s64 = ctx.r1.s64 + 288;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// addi r4,r1,272
	ctx.r4.s64 = ctx.r1.s64 + 272;
	// addi r8,r9,21600
	ctx.r8.s64 = ctx.r9.s64 + 21600;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f0,-17752(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -17752);
	f0.f64 = double(temp.f32);
	// stvx128 v0,r0,r11
	ea = (r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// stw r30,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, r30.u32);
	// stfs f0,304(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// stw r8,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r8.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// b 0x82ca2c3c
	return;
loc_82596918:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r10,r11,4672
	ctx.r10.s64 = r11.s64 + 4672;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// b 0x82ca2c3c
	return;
loc_8259693C:
	// vspltisw v0,0
	simd::store_i32(ctx.v0.u32, simd::set1_i32(int32_t(0x0)));
	// addi r11,r1,384
	r11.s64 = ctx.r1.s64 + 384;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// addi r4,r1,368
	ctx.r4.s64 = ctx.r1.s64 + 368;
	// addi r8,r9,4644
	ctx.r8.s64 = ctx.r9.s64 + 4644;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f0,-17752(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -17752);
	f0.f64 = double(temp.f32);
	// stvx128 v0,r0,r11
	ea = (r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// stw r30,372(r1)
	PPC_STORE_U32(ctx.r1.u32 + 372, r30.u32);
	// stfs f0,400(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// stw r8,368(r1)
	PPC_STORE_U32(ctx.r1.u32 + 368, ctx.r8.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// b 0x82ca2c3c
	return;
loc_82596978:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r10,r11,4696
	ctx.r10.s64 = r11.s64 + 4696;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// lis r8,-32244
	ctx.r8.s64 = -2113142784;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// addi r7,r9,-32248
	ctx.r7.s64 = ctx.r9.s64 + -32248;
	// addi r6,r8,4720
	ctx.r6.s64 = ctx.r8.s64 + 4720;
	// stw r7,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r7.u32);
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// stw r6,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r6.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82596348
	sub_82596348(ctx, base);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// b 0x82ca2c3c
	return;
loc_825969C4:
	// lis r11,-32245
	r11.s64 = -2113208320;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// addi r10,r11,-32224
	ctx.r10.s64 = r11.s64 + -32224;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// bl 0x82596348
	sub_82596348(ctx, base);
loc_825969E0:
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82596618) {
	__imp__sub_82596618(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825969E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r30,0
	r30.s64 = 0;
	// lis r10,-32242
	ctx.r10.s64 = -2113011712;
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r8,r11,5716
	ctx.r8.s64 = r11.s64 + 5716;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// addi r7,r10,23848
	ctx.r7.s64 = ctx.r10.s64 + 23848;
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// addi r3,r31,88
	ctx.r3.s64 = r31.s64 + 88;
	// stw r8,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r8.u32);
	// lfs f0,-27468(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -27468);
	f0.f64 = double(temp.f32);
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// addi r11,r31,44
	r11.s64 = r31.s64 + 44;
	// stw r30,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r30.u32);
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// stw r30,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r30.u32);
	// stw r7,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r7.u32);
	// stfs f0,44(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 44, temp.u32);
	// stw r30,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r30.u32);
	// stw r30,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r30.u32);
	// stw r30,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r30.u32);
	// stw r30,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r30.u32);
	// stw r30,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r30.u32);
	// stw r30,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r30.u32);
	// stw r30,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r30.u32);
	// stb r30,84(r31)
	PPC_STORE_U8(r31.u32 + 84, r30.u8);
	// stb r6,85(r31)
	PPC_STORE_U8(r31.u32 + 85, ctx.r6.u8);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r5,-32242
	ctx.r5.s64 = -2113011712;
	// addi r3,r31,116
	ctx.r3.s64 = r31.s64 + 116;
	// addi r4,r5,25632
	ctx.r4.s64 = ctx.r5.s64 + 25632;
	// stw r4,88(r31)
	PPC_STORE_U32(r31.u32 + 88, ctx.r4.u32);
	// bl 0x828338a8
	sub_828338A8(ctx, base);
	// lis r3,-32242
	ctx.r3.s64 = -2113011712;
	// addi r11,r3,25948
	r11.s64 = ctx.r3.s64 + 25948;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,116(r31)
	PPC_STORE_U32(r31.u32 + 116, r11.u32);
	// stw r30,144(r31)
	PPC_STORE_U32(r31.u32 + 144, r30.u32);
	// stw r30,152(r31)
	PPC_STORE_U32(r31.u32 + 152, r30.u32);
	// stw r30,156(r31)
	PPC_STORE_U32(r31.u32 + 156, r30.u32);
	// stw r30,160(r31)
	PPC_STORE_U32(r31.u32 + 160, r30.u32);
	// stw r30,164(r31)
	PPC_STORE_U32(r31.u32 + 164, r30.u32);
	// stw r30,168(r31)
	PPC_STORE_U32(r31.u32 + 168, r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825969E8) {
	__imp__sub_825969E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82596AD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// addi r11,r31,116
	r11.s64 = r31.s64 + 116;
	// addi r28,r10,-4548
	r28.s64 = ctx.r10.s64 + -4548;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// stw r28,116(r31)
	PPC_STORE_U32(r31.u32 + 116, r28.u32);
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,128(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(128) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// addi r11,r31,88
	r11.s64 = r31.s64 + 88;
	// stw r30,128(r31)
	PPC_STORE_U32(r31.u32 + 128, r30.u32);
	// stw r28,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r28.u32);
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// bl 0x828581b0
	sub_828581B0(ctx, base);
	// lwz r3,100(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(100) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// stw r30,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r30.u32);
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// bl 0x8257cc98
	sub_8257CC98(ctx, base);
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// addi r8,r9,12052
	ctx.r8.s64 = ctx.r9.s64 + 12052;
	// addi r3,r11,4
	ctx.r3.s64 = r11.s64 + 4;
	// stw r8,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r8.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// lis r7,-32246
	ctx.r7.s64 = -2113273856;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// addi r6,r7,23084
	ctx.r6.s64 = ctx.r7.s64 + 23084;
	// stw r6,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r6.u32);
	// bl 0x82356698
	sub_82356698(ctx, base);
	// clrlwi r5,r29,31
	ctx.r5.u64 = r29.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x82596b74
	if (cr6.eq) goto loc_82596B74;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82596B74:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82596AD0) {
	__imp__sub_82596AD0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82596B80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-31927
	r30.s64 = -2092367872;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,26788(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x823381b8
	sub_823381B8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82596bc0
	if (cr6.eq) goto loc_82596BC0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82596BC0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(0) );
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r10,26788(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(26788) );
	// li r11,0
	r11.s64 = 0;
	// addi r9,r31,88
	ctx.r9.s64 = r31.s64 + 88;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r8,56(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(56) );
	// lwz r29,152(r8)
	r29.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(152) );
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r7,r31,116
	ctx.r7.s64 = r31.s64 + 116;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r7,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r7.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8228a900
	sub_8228A900(ctx, base);
	// addi r30,r31,44
	r30.s64 = r31.s64 + 44;
	// lis r5,-31926
	ctx.r5.s64 = -2092302336;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r5,r5,-29452
	ctx.r5.s64 = ctx.r5.s64 + -29452;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x828ce060
	sub_828CE060(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x828ce4e8
	sub_828CE4E8(ctx, base);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(24) );
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(4) );
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82596cb8
	sub_82596CB8(ctx, base);
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(100) );
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82596c74
	if (cr6.eq) goto loc_82596C74;
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
loc_82596C74:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82596B80) {
	__imp__sub_82596B80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82596C80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82583490
	sub_82583490(ctx, base);
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// bl 0x828ced00
	sub_828CED00(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82596C80) {
	__imp__sub_82596C80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82596CB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31927
	r11.s64 = -2092367872;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// lwz r11,26912(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26912) );
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(12) );
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(88) );
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(0) );
	// addi r3,r11,104
	ctx.r3.s64 = r11.s64 + 104;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(108) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82596d14
	if (cr6.eq) goto loc_82596D14;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(0) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82596d10
	if (cr6.eq) goto loc_82596D10;
	// rotlwi r6,r10,0
	ctx.r6.u64 = rotl32(ctx.r10.u32, 0);
	// b 0x82596d18
	goto loc_82596D18;
loc_82596D10:
	// bl 0x821940c8
	sub_821940C8(ctx, base);
loc_82596D14:
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_82596D18:
	// addi r11,r30,144
	r11.s64 = r30.s64 + 144;
	// stw r6,144(r30)
	PPC_STORE_U32(r30.u32 + 144, ctx.r6.u32);
	// rotlwi r11,r6,0
	r11.u64 = rotl32(ctx.r6.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82596d40
	if (cr6.eq) goto loc_82596D40;
	// lbz r11,144(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 144);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82596d44
	if (!cr6.eq) goto loc_82596D44;
loc_82596D40:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82596D44:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82597188
	if (cr6.eq) goto loc_82597188;
	// lwz r11,44(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(44) );
	// rlwinm r10,r11,19,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82596e50
	if (cr6.eq) goto loc_82596E50;
	// lwz r11,140(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82596d8c
	if (cr6.eq) goto loc_82596D8C;
	// lbz r10,77(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 77);
	// lwz r11,72(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// stw r11,152(r30)
	PPC_STORE_U32(r30.u32 + 152, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x82596e54
	goto loc_82596E54;
loc_82596D8C:
	// lwz r10,72(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(72) );
	// lwz r5,76(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82596df8
	if (!cr0.gt) goto loc_82596DF8;
loc_82596DA8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,77
	cr6.compare<int32_t>(ctx.r7.s32, 77, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82596dc8
	if (cr6.lt) goto loc_82596DC8;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82596DC8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82596de4
	if (cr6.eq) goto loc_82596DE4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82596dec
	goto loc_82596DEC;
loc_82596DE4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82596DEC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82596da8
	if (cr6.gt) goto loc_82596DA8;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82596DF8:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82596e3c
	if (cr6.eq) goto loc_82596E3C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,77
	cr6.compare<int32_t>(r11.s32, 77, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82596e14
	if (cr6.gt) goto loc_82596E14;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82596E14:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82596e3c
	if (!cr6.eq) goto loc_82596E3C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// stw r11,152(r30)
	PPC_STORE_U32(r30.u32 + 152, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x82596e54
	goto loc_82596E54;
loc_82596E3C:
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// stw r11,152(r30)
	PPC_STORE_U32(r30.u32 + 152, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x82596e54
	goto loc_82596E54;
loc_82596E50:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82596E54:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82597188
	if (cr6.eq) goto loc_82597188;
	// lwz r11,44(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(44) );
	// rlwinm r10,r11,27,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82596f60
	if (cr6.eq) goto loc_82596F60;
	// lwz r11,140(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(140) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82596e9c
	if (cr6.eq) goto loc_82596E9C;
	// lbz r10,69(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 69);
	// lwz r11,72(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// stw r11,148(r30)
	PPC_STORE_U32(r30.u32 + 148, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x82596f64
	goto loc_82596F64;
loc_82596E9C:
	// lwz r10,72(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(72) );
	// lwz r6,76(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82596f08
	if (!cr0.gt) goto loc_82596F08;
loc_82596EB8:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,69
	cr6.compare<int32_t>(ctx.r7.s32, 69, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82596ed8
	if (cr6.lt) goto loc_82596ED8;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82596ED8:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82596ef4
	if (cr6.eq) goto loc_82596EF4;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82596efc
	goto loc_82596EFC;
loc_82596EF4:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82596EFC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82596eb8
	if (cr6.gt) goto loc_82596EB8;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82596F08:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82596f4c
	if (cr6.eq) goto loc_82596F4C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,69
	cr6.compare<int32_t>(r11.s32, 69, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82596f24
	if (cr6.gt) goto loc_82596F24;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82596F24:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82596f4c
	if (!cr6.eq) goto loc_82596F4C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// stw r11,148(r30)
	PPC_STORE_U32(r30.u32 + 148, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x82596f64
	goto loc_82596F64;
loc_82596F4C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// stw r11,148(r30)
	PPC_STORE_U32(r30.u32 + 148, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x82596f64
	goto loc_82596F64;
loc_82596F60:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82596F64:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82597188
	if (cr6.eq) goto loc_82597188;
	// lwz r3,152(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(152) );
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(0) );
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(68) );
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,156(r30)
	PPC_STORE_U32(r30.u32 + 156, ctx.r3.u32);
	// lwz r9,52(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(52) );
	// rlwinm r8,r9,18,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 18) & 0x1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82597084
	if (cr6.eq) goto loc_82597084;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82596fc4
	if (cr6.eq) goto loc_82596FC4;
	// lbz r11,142(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 142);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// stw r11,160(r30)
	PPC_STORE_U32(r30.u32 + 160, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x82597088
	goto loc_82597088;
loc_82596FC4:
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8259702c
	if (!cr0.gt) goto loc_8259702C;
loc_82596FDC:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,142
	cr6.compare<int32_t>(ctx.r7.s32, 142, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82596ffc
	if (cr6.lt) goto loc_82596FFC;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82596FFC:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82597018
	if (cr6.eq) goto loc_82597018;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82597020
	goto loc_82597020;
loc_82597018:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82597020:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x82596fdc
	if (cr6.gt) goto loc_82596FDC;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8259702C:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82597070
	if (cr6.eq) goto loc_82597070;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,142
	cr6.compare<int32_t>(r11.s32, 142, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82597048
	if (cr6.gt) goto loc_82597048;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82597048:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82597070
	if (!cr6.eq) goto loc_82597070;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// stw r11,160(r30)
	PPC_STORE_U32(r30.u32 + 160, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x82597088
	goto loc_82597088;
loc_82597070:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
	// stw r11,160(r30)
	PPC_STORE_U32(r30.u32 + 160, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// b 0x82597088
	goto loc_82597088;
loc_82597084:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82597088:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82597188
	if (cr6.eq) goto loc_82597188;
	// lwz r3,160(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + int32_t(160) );
	// bl 0x82455f20
	sub_82455F20(ctx, base);
	// stw r3,164(r30)
	PPC_STORE_U32(r30.u32 + 164, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82597188
	if (cr6.eq) goto loc_82597188;
	// lwz r11,44(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(44) );
	// rlwinm r10,r11,29,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82597188
	if (cr6.eq) goto loc_82597188;
	// lwz r11,140(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(140) );
	// lwz r10,72(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(72) );
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825970dc
	if (cr6.eq) goto loc_825970DC;
	// lbz r11,67(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 67);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(4) );
	// b 0x82597184
	goto loc_82597184;
loc_825970DC:
	// lwz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(76) );
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82597144
	if (!cr0.gt) goto loc_82597144;
loc_825970F4:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,67
	cr6.compare<int32_t>(ctx.r7.s32, 67, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x82597114
	if (cr6.lt) goto loc_82597114;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_82597114:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82597130
	if (cr6.eq) goto loc_82597130;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82597138
	goto loc_82597138;
loc_82597130:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82597138:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825970f4
	if (cr6.gt) goto loc_825970F4;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_82597144:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8259717c
	if (cr6.eq) goto loc_8259717C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,67
	cr6.compare<int32_t>(r11.s32, 67, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x82597160
	if (cr6.gt) goto loc_82597160;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82597160:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8259717c
	if (!cr6.eq) goto loc_8259717C;
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(84) );
	// b 0x82597180
	goto loc_82597180;
loc_8259717C:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_82597180:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_82597184:
	// stw r11,168(r30)
	PPC_STORE_U32(r30.u32 + 168, r11.u32);
loc_82597188:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82596CB8) {
	__imp__sub_82596CB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825971A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82583560
	sub_82583560(ctx, base);
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// bl 0x828ce180
	sub_828CE180(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r10,-29448
	ctx.r4.s64 = ctx.r10.s64 + -29448;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r3,152(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(152) );
	// bl 0x82837218
	sub_82837218(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825971A0) {
	__imp__sub_825971A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825971F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x821f0108
	sub_821F0108(ctx, base);
	// lis r11,-31926
	r11.s64 = -2092302336;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r4,-29444(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(-29444) );
	// lfs f1,-19068(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -19068);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x823319a0
	sub_823319A0(ctx, base);
	// lis r9,-31927
	ctx.r9.s64 = -2092367872;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,10
	ctx.r4.s64 = 10;
	// lwz r11,26788(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(26788) );
	// lwz r8,32(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(32) );
	// lwz r3,88(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(88) );
	// bl 0x82332d48
	sub_82332D48(ctx, base);
	// lwz r3,104(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(104) );
	// bl 0x8221be68
	sub_8221BE68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825971F8) {
	__imp__sub_825971F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82597278) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,1292
	ctx.r4.s64 = r11.s64 + 1292;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lis r29,-31927
	r29.s64 = -2092367872;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// cmpwi cr6,r31,115
	cr6.compare<int32_t>(r31.s32, 115, xer);
	// beq cr6,0x82597368
	if (cr6.eq) goto loc_82597368;
	// cmpwi cr6,r31,117
	cr6.compare<int32_t>(r31.s32, 117, xer);
	// beq cr6,0x82597320
	if (cr6.eq) goto loc_82597320;
	// cmpwi cr6,r31,118
	cr6.compare<int32_t>(r31.s32, 118, xer);
	// bne cr6,0x825974b8
	if (!cr6.eq) goto loc_825974B8;
	// lwz r10,168(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(168) );
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,4996
	ctx.r4.s64 = ctx.r9.s64 + 4996;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r31,92(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(92) );
	// lwz r30,28(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// li r5,37
	ctx.r5.s64 = 37;
	// li r7,-60
	ctx.r7.s64 = -60;
	// li r8,100
	ctx.r8.s64 = 100;
	// li r9,20
	ctx.r9.s64 = 20;
	// li r10,6
	ctx.r10.s64 = 6;
	// b 0x825974a8
	goto loc_825974A8;
loc_82597320:
	// lwz r10,168(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + int32_t(168) );
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r9,4956
	ctx.r4.s64 = ctx.r9.s64 + 4956;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r31,92(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(92) );
	// lwz r30,28(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// li r5,36
	ctx.r5.s64 = 36;
	// li r7,-100
	ctx.r7.s64 = -100;
	// li r8,100
	ctx.r8.s64 = 100;
	// li r9,25
	ctx.r9.s64 = 25;
	// li r10,6
	ctx.r10.s64 = 6;
	// b 0x825974a8
	goto loc_825974A8;
loc_82597368:
	// lwz r11,144(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + int32_t(144) );
	// li r31,0
	r31.s64 = 0;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(52) );
	// rlwinm r9,r10,24,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82597450
	if (cr6.eq) goto loc_82597450;
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(140) );
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x825973a4
	if (cr6.eq) goto loc_825973A4;
	// lbz r10,136(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 136);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// rotlwi r10,r10,3
	ctx.r10.u64 = rotl32(ctx.r10.u32, 3);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r31,4(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(4) );
	// b 0x82597450
	goto loc_82597450;
loc_825973A4:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(72) );
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + int32_t(76) );
	// stw r31,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r31.u32);
	// subf r11,r10,r6
	r11.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r10,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r10.u32);
	// srawi. r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82597410
	if (!cr0.gt) goto loc_82597410;
loc_825973C0:
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r7,136
	cr6.compare<int32_t>(ctx.r7.s32, 136, xer);
	// li r7,1
	ctx.r7.s64 = 1;
	// blt cr6,0x825973e0
	if (cr6.lt) goto loc_825973E0;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
loc_825973E0:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x825973fc
	if (cr6.eq) goto loc_825973FC;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82597404
	goto loc_82597404;
loc_825973FC:
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82597404:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x825973c0
	if (cr6.gt) goto loc_825973C0;
	// stw r10,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r10.u32);
loc_82597410:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x82597448
	if (cr6.eq) goto loc_82597448;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(0) );
	// cmpwi cr6,r11,136
	cr6.compare<int32_t>(r11.s32, 136, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x8259742c
	if (cr6.gt) goto loc_8259742C;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_8259742C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82597448
	if (!cr6.eq) goto loc_82597448;
	// ld r11,104(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lwz r11,108(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(108) );
	// b 0x8259744c
	goto loc_8259744C;
loc_82597448:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_8259744C:
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(4) );
loc_82597450:
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// lwz r4,168(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + int32_t(168) );
	// bl 0x8274e218
	sub_8274E218(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8282bce0
	sub_8282BCE0(ctx, base);
	// lwz r11,26788(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + int32_t(26788) );
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r4,r10,4916
	ctx.r4.s64 = ctx.r10.s64 + 4916;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r30,28(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// li r5,35
	ctx.r5.s64 = 35;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r8,10000
	ctx.r8.s64 = 10000;
	// li r9,5
	ctx.r9.s64 = 5;
	// li r10,1
	ctx.r10.s64 = 1;
loc_825974A8:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82337ea0
	sub_82337EA0(ctx, base);
loc_825974B8:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82597278) {
	__imp__sub_82597278(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_825974C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r25{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r4,4(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + int32_t(4) );
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r4,-110
	r11.s64 = ctx.r4.s64 + -110;
	// cmplwi cr6,r11,31
	cr6.compare<uint32_t>(r11.u32, 31, xer);
	// bgt cr6,0x82597868
	if (cr6.gt) goto loc_82597868;
	// lis r12,-32167
	r12.s64 = -2108096512;
	// addi r12,r12,29952
	r12.s64 = r12.s64 + 29952;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82597580;
	case 1:
		goto loc_82597670;
	case 2:
		goto loc_82597680;
	case 3:
		goto loc_82597708;
	case 4:
		goto loc_82597708;
	case 5:
		goto loc_82597798;
	case 6:
		goto loc_8259772C;
	case 7:
		goto loc_82597798;
	case 8:
		goto loc_82597798;
	case 9:
		goto loc_825977A4;
	case 10:
		goto loc_82597854;
	case 11:
		goto loc_82597868;
	case 12:
		goto loc_82597868;
	case 13:
		goto loc_82597868;
	case 14:
		goto loc_82597868;
	case 15:
		goto loc_82597868;
	case 16:
		goto loc_82597868;
	case 17:
		goto loc_82597868;
	case 18:
		goto loc_82597868;
	case 19:
		goto loc_82597868;
	case 20:
		goto loc_82597868;
	case 21:
		goto loc_82597868;
	case 22:
		goto loc_82597868;
	case 23:
		goto loc_82597868;
	case 24:
		goto loc_82597868;
	case 25:
		goto loc_82597868;
	case 26:
		goto loc_82597868;
	case 27:
		goto loc_82597868;
	case 28:
		goto loc_82597868;
	case 29:
		goto loc_82597868;
	case 30:
		goto loc_8259782C;
	case 31:
		goto loc_82597804;
	default:
		__builtin_unreachable();
	}
	// lwz r18,30080(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30080) );
	// lwz r18,30320(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30320) );
	// lwz r18,30336(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30336) );
	// lwz r18,30472(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30472) );
	// lwz r18,30472(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30472) );
	// lwz r18,30616(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30616) );
	// lwz r18,30508(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30508) );
	// lwz r18,30616(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30616) );
	// lwz r18,30616(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30616) );
	// lwz r18,30628(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30628) );
	// lwz r18,30804(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30804) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30824(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30824) );
	// lwz r18,30764(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30764) );
	// lwz r18,30724(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(30724) );
loc_82597580:
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(168) );
	// bl 0x8274dfd0
	sub_8274DFD0(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r4,r11,5040
	ctx.r4.s64 = r11.s64 + 5040;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// addi r4,r10,5076
	ctx.r4.s64 = ctx.r10.s64 + 5076;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// lwz r4,168(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(168) );
	// bl 0x8274d188
	sub_8274D188(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82b38b78
	sub_82B38B78(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// addi r4,r9,5108
	ctx.r4.s64 = ctx.r9.s64 + 5108;
	// bl 0x822d6b40
	sub_822D6B40(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x82303f98
	sub_82303F98(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82b38b78
	sub_82B38B78(ctx, base);
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// lis r8,-31927
	ctx.r8.s64 = -2092367872;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// lwz r11,26788(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(26788) );
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82287710
	sub_82287710(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r6,29
	ctx.r6.s64 = 29;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// b 0x82597868
	goto loc_82597868;
loc_82597670:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825981c0
	sub_825981C0(ctx, base);
	// b 0x82597868
	goto loc_82597868;
loc_82597680:
	// lwz r4,164(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(164) );
	// lwz r3,148(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(148) );
	// bl 0x828b0b38
	sub_828B0B38(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x825976f8
	if (cr6.eq) goto loc_825976F8;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,5128
	ctx.r4.s64 = r11.s64 + 5128;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// lwz r11,26788(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26788) );
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82287710
	sub_82287710(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r6,33
	ctx.r6.s64 = 33;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// b 0x82597868
	goto loc_82597868;
loc_825976F8:
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825981c0
	sub_825981C0(ctx, base);
	// b 0x82597868
	goto loc_82597868;
loc_82597708:
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(168) );
	// lbz r11,85(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 85);
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r4,r10,27,31,31
	ctx.r4.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// stb r4,85(r3)
	PPC_STORE_U8(ctx.r3.u32 + 85, ctx.r4.u8);
	// bl 0x827502f0
	sub_827502F0(ctx, base);
	// lis r9,-31927
	ctx.r9.s64 = -2092367872;
	// lwz r11,26788(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(26788) );
	// b 0x8259785c
	goto loc_8259785C;
loc_8259772C:
	// lwz r4,164(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + int32_t(164) );
	// lwz r3,148(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + int32_t(148) );
	// bl 0x828b0b38
	sub_828B0B38(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8259778c
	if (cr6.eq) goto loc_8259778C;
	// bl 0x825984f0
	sub_825984F0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82598850
	sub_82598850(ctx, base);
	// lis r11,-31927
	r11.s64 = -2092367872;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336f98
	sub_82336F98(ctx, base);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r10,5484
	ctx.r4.s64 = ctx.r10.s64 + 5484;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x825971f8
	sub_825971F8(ctx, base);
	// b 0x82597868
	goto loc_82597868;
loc_8259778C:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x825981c0
	sub_825981C0(ctx, base);
	// b 0x82597868
	goto loc_82597868;
loc_82597798:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82597278
	sub_82597278(ctx, base);
	// b 0x82597868
	goto loc_82597868;
loc_825977A4:
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,5168
	ctx.r4.s64 = r11.s64 + 5168;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82301d40
	sub_82301D40(ctx, base);
	// lis r10,-31927
	ctx.r10.s64 = -2092367872;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// lwz r11,26788(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(26788) );
	// lwz r31,28(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82287710
	sub_82287710(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r6,34
	ctx.r6.s64 = 34;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x82337c68
	sub_82337C68(ctx, base);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x821c6868
	sub_821C6868(ctx, base);
	// b 0x82597868
	goto loc_82597868;
loc_82597804:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,-30944
	ctx.r5.s64 = ctx.r10.s64 + -30944;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r4,26788(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// b 0x82597868
	goto loc_82597868;
loc_8259782C:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,-30948
	ctx.r5.s64 = ctx.r10.s64 + -30948;
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// lwz r4,26788(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// b 0x82597868
	goto loc_82597868;
loc_82597854:
	// lis r11,-31927
	r11.s64 = -2092367872;
	// lwz r11,26788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(26788) );
loc_8259785C:
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336f98
	sub_82336F98(ctx, base);
loc_82597868:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + int32_t(-8) );
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_825974C0) {
	__imp__sub_825974C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82597880) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r25{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lis r31,-31927
	r31.s64 = -2092367872;
	// addi r11,r30,-46
	r11.s64 = r30.s64 + -46;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// rlwinm r27,r10,27,31,31
	r27.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// lwz r9,28(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r10,40(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(40) );
	// lwz r29,44(r9)
	r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(44) );
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x8259793c
	if (!cr6.eq) goto loc_8259793C;
	// rotlwi r11,r9,0
	r11.u64 = rotl32(ctx.r9.u32, 0);
	// lwz r3,64(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(64) );
	// bl 0x8240cd98
	sub_8240CD98(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82597cac
	if (!cr6.eq) goto loc_82597CAC;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,304
	ctx.r4.s64 = r11.s64 + 304;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + int32_t(56) );
	// lwz r4,152(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + int32_t(152) );
	// bl 0x823f8908
	sub_823F8908(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82214f08
	sub_82214F08(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
loc_82597908:
	// cmpwi cr6,r30,46
	cr6.compare<int32_t>(r30.s32, 46, xer);
	// blt cr6,0x82597cac
	if (cr6.lt) goto loc_82597CAC;
	// cmpwi cr6,r30,47
	cr6.compare<int32_t>(r30.s32, 47, xer);
	// bgt cr6,0x82597cac
	if (cr6.gt) goto loc_82597CAC;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// bne cr6,0x82597968
	if (!cr6.eq) goto loc_82597968;
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r5,r10,-30832
	ctx.r5.s64 = ctx.r10.s64 + -30832;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// b 0x8259797c
	goto loc_8259797C;
loc_8259793C:
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// beq cr6,0x82597908
	if (cr6.eq) goto loc_82597908;
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x82597cac
	if (!cr6.eq) goto loc_82597CAC;
	// cmpwi cr6,r30,46
	cr6.compare<int32_t>(r30.s32, 46, xer);
	// bne cr6,0x82597cac
	if (!cr6.eq) goto loc_82597CAC;
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x823380c0
	sub_823380C0(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82597968:
	// lis r10,-31926
	ctx.r10.s64 = -2092302336;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// addi r5,r10,-30828
	ctx.r5.s64 = ctx.r10.s64 + -30828;
	// bl 0x82306098
	sub_82306098(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
loc_8259797C:
	// bl 0x822ade08
	sub_822ADE08(ctx, base);
	// addi r11,r29,-29
	r11.s64 = r29.s64 + -29;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bgt cr6,0x82597cac
	if (cr6.gt) goto loc_82597CAC;
	// lis r12,-32167
	r12.s64 = -2108096512;
	// addi r12,r12,31140
	r12.s64 = r12.s64 + 31140;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_825979C8;
	case 1:
		goto loc_825979FC;
	case 2:
		goto loc_82597A7C;
	case 3:
		goto loc_82597AC8;
	case 4:
		goto loc_82597B14;
	case 5:
		goto loc_82597B80;
	case 6:
		goto loc_82597BE4;
	case 7:
		goto loc_82597C30;
	case 8:
		goto loc_82597C30;
	default:
		__builtin_unreachable();
	}
	// lwz r18,31176(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(31176) );
	// lwz r18,31228(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(31228) );
	// lwz r18,31356(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(31356) );
	// lwz r18,31432(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(31432) );
	// lwz r18,31508(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(31508) );
	// lwz r18,31616(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(31616) );
	// lwz r18,31716(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(31716) );
	// lwz r18,31792(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(31792) );
	// lwz r18,31792(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + int32_t(31792) );
loc_825979C8:
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x825979e0
	if (!cr6.eq) goto loc_825979E0;
	// bl 0x82338150
	sub_82338150(ctx, base);
loc_825979E0:
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82597cac
	if (cr6.eq) goto loc_82597CAC;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x825986e0
	sub_825986E0(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_825979FC:
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x82597a14
	if (!cr6.eq) goto loc_82597A14;
	// bl 0x82338150
	sub_82338150(ctx, base);
loc_82597A14:
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82597cac
	if (cr6.eq) goto loc_82597CAC;
	// lwz r11,168(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + int32_t(168) );
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// rlwinm r10,r11,0,20,30
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFE;
	// rlwinm r10,r10,0,24,22
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82597a5c
	if (cr6.eq) goto loc_82597A5C;
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82597a5c
	if (!cr6.eq) goto loc_82597A5C;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82598548
	sub_82598548(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82598680
	sub_82598680(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82597A5C:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82598548
	sub_82598548(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x825984f0
	sub_825984F0(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82598680
	sub_82598680(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82597A7C:
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x82597a94
	if (!cr6.eq) goto loc_82597A94;
	// bl 0x82338150
	sub_82338150(ctx, base);
loc_82597A94:
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82597cac
	if (cr6.eq) goto loc_82597CAC;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82598548
	sub_82598548(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x825984f0
	sub_825984F0(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82598850
	sub_82598850(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82598680
	sub_82598680(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82597AC8:
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x82597ae0
	if (!cr6.eq) goto loc_82597AE0;
	// bl 0x82338150
	sub_82338150(ctx, base);
loc_82597AE0:
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82597cac
	if (cr6.eq) goto loc_82597CAC;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82598548
	sub_82598548(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,164(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(164) );
	// lwz r3,148(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + int32_t(148) );
	// bl 0x828b1f28
	sub_828B1F28(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82598680
	sub_82598680(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82597B14:
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x82597b2c
	if (!cr6.eq) goto loc_82597B2C;
	// bl 0x82338150
	sub_82338150(ctx, base);
loc_82597B2C:
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82597cac
	if (cr6.eq) goto loc_82597CAC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,164(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + int32_t(164) );
	// lwz r3,148(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + int32_t(148) );
	// bl 0x828b1f28
	sub_828B1F28(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336f98
	sub_82336F98(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,5360
	ctx.r4.s64 = r11.s64 + 5360;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x825971f8
	sub_825971F8(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82597B80:
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x82597b98
	if (!cr6.eq) goto loc_82597B98;
	// bl 0x82338150
	sub_82338150(ctx, base);
loc_82597B98:
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82597cac
	if (cr6.eq) goto loc_82597CAC;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x825984f0
	sub_825984F0(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// bl 0x82336f98
	sub_82336F98(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r4,r11,5320
	ctx.r4.s64 = r11.s64 + 5320;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8222cf18
	sub_8222CF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x825971f8
	sub_825971F8(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82597BE4:
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x82597c00
	if (!cr6.eq) goto loc_82597C00;
	// bl 0x82338150
	sub_82338150(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
loc_82597C00:
	// clrlwi r10,r27,24
	ctx.r10.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82597cac
	if (cr6.eq) goto loc_82597CAC;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r9,64(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + int32_t(64) );
	// stb r10,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r10.u8);
	// lwz r4,44(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(44) );
	// bl 0x82597dc0
	sub_82597DC0(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_82597C30:
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + int32_t(40) );
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x82597c4c
	if (!cr6.eq) goto loc_82597C4C;
	// bl 0x82338150
	sub_82338150(ctx, base);
	// lwz r11,26788(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + int32_t(26788) );
loc_82597C4C:
	// clrlwi r10,r27,24
	ctx.r10.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82597cac
	if (cr6.eq) goto loc_82597CAC;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + int32_t(28) );
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r8,64(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + int32_t(64) );
	// stb r10,0(r8)
	PPC_STORE_U8(ctx.r8.u32 + 0, ctx.r10.u8);
	// lwz r9,168(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + int32_t(168) );
	// lwz r11,44(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + int32_t(44) );
	// addi r10,r11,60
	ctx.r10.s64 = r11.s64 + 60;
	// lwz r7,28(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + int32_t(28) );
	// rlwinm r6,r7,0,20,30
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFE;
	// rlwinm r6,r6,0,24,22
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x82597c8c
	if (!cr6.eq) goto loc_82597C8C;
	// addi r10,r11,100
	ctx.r10.s64 = r11.s64 + 100;
loc_82597C8C:
	// srawi r8,r10,31
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFFFFFF) != 0);
	ctx.r8.s64 = ctx.r10.s32 >> 31;
	// and r7,r8,r10
	ctx.r7.u64 = ctx.r8.u64 & ctx.r10.u64;
	// subf r10,r7,r11
	ctx.r10.s64 = r11.s64 - ctx.r7.s64;
	// subfic r11,r10,100
	xer.ca = ctx.r10.u32 <= 100;
	r11.s64 = 100 - ctx.r10.s64;
	// srawi r6,r11,31
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7FFFFFFF) != 0);
	ctx.r6.s64 = r11.s32 >> 31;
	// and r11,r6,r11
	r11.u64 = ctx.r6.u64 & r11.u64;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r11,92(r9)
	PPC_STORE_U32(ctx.r9.u32 + 92, r11.u32);
loc_82597CAC:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82597880) {
	__imp__sub_82597880(ctx, base);
}

