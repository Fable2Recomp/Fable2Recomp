#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_8309E970"))) PPC_WEAK_FUNC(sub_8309E970);
PPC_FUNC_IMPL(__imp__sub_8309E970) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r23,0
	r23.s64 = 0;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// stw r23,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r23.u32);
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8309e9d4
	if (cr6.eq) goto loc_8309E9D4;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8309e9d4
	if (!cr6.eq) goto loc_8309E9D4;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lwz r8,20(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r23.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r30,16
	ctx.r5.s64 = r30.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8309d768
	sub_8309D768(ctx, base);
	// lwz r30,128(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_8309E9D4:
	// addi r25,r29,40
	r25.s64 = r29.s64 + 40;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x8309ea40
	if (cr6.eq) goto loc_8309EA40;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8309ea30
	if (cr6.eq) goto loc_8309EA30;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309ea30
	if (!cr6.eq) goto loc_8309EA30;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830979c8
	sub_830979C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8309ea30
	if (cr0.eq) goto loc_8309EA30;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8309ea1c
	if (cr6.eq) goto loc_8309EA1C;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8309ec68
	if (!cr6.eq) goto loc_8309EC68;
loc_8309EA1C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// b 0x8309eac8
	goto loc_8309EAC8;
loc_8309EA30:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3037
	ctx.r5.s64 = 3037;
	// addi r6,r11,19372
	ctx.r6.s64 = r11.s64 + 19372;
	// b 0x8309ec5c
	goto loc_8309EC5C;
loc_8309EA40:
	// mr r31,r23
	r31.u64 = r23.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8309ea60
	if (cr6.eq) goto loc_8309EA60;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8309ec68
	if (!cr6.eq) goto loc_8309EC68;
	// lwz r31,16(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// addi r25,r27,48
	r25.s64 = r27.s64 + 48;
loc_8309EA60:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bne 0x8309ea9c
	if (!cr0.eq) goto loc_8309EA9C;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x8309ae98
	sub_8309AE98(ctx, base);
	// b 0x8309ec68
	goto loc_8309EC68;
loc_8309EA9C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8309eac4
	if (!cr0.eq) goto loc_8309EAC4;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// beq 0x8309eac8
	if (cr0.eq) goto loc_8309EAC8;
loc_8309EAC4:
	// li r10,1
	ctx.r10.s64 = 1;
loc_8309EAC8:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83095fc0
	sub_83095FC0(ctx, base);
	// or r26,r3,r10
	r26.u64 = ctx.r3.u64 | ctx.r10.u64;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309eb0c
	if (cr0.eq) goto loc_8309EB0C;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x8309eb10
	goto loc_8309EB10;
loc_8309EB0C:
	// mr r28,r23
	r28.u64 = r23.u64;
loc_8309EB10:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8309ec68
	if (cr6.eq) goto loc_8309EC68;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8309eb40
	if (cr6.eq) goto loc_8309EB40;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r28)
	PPC_STORE_U32(r28.u32 + 16, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309ec68
	if (cr0.eq) goto loc_8309EC68;
loc_8309EB40:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8309eb68
	if (cr6.eq) goto loc_8309EB68;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,32(r28)
	PPC_STORE_U32(r28.u32 + 32, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309ec68
	if (cr0.eq) goto loc_8309EC68;
loc_8309EB68:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x8309ebcc
	if (cr6.eq) goto loc_8309EBCC;
	// lwz r31,32(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// b 0x8309ebc4
	goto loc_8309EBC4;
loc_8309EB78:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309ebc0
	if (cr6.eq) goto loc_8309EBC0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x8309ebc0
	if (!cr6.eq) goto loc_8309EBC0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x830979c8
	sub_830979C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8309ebf8
	if (cr0.eq) goto loc_8309EBF8;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// bne cr6,0x8309ebc0
	if (!cr6.eq) goto loc_8309EBC0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
loc_8309EBC0:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_8309EBC4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8309eb78
	if (!cr6.eq) goto loc_8309EB78;
loc_8309EBCC:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x8309ebe4
	if (cr6.eq) goto loc_8309EBE4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,16(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83097810
	sub_83097810(ctx, base);
loc_8309EBE4:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x8309ec70
	if (cr6.eq) goto loc_8309EC70;
	// lwz r31,32(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// mr r30,r23
	r30.u64 = r23.u64;
	// b 0x8309ec34
	goto loc_8309EC34;
loc_8309EBF8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3017
	ctx.r5.s64 = 3017;
	// addi r6,r11,19320
	ctx.r6.s64 = r11.s64 + 19320;
	// b 0x8309ec5c
	goto loc_8309EC5C;
loc_8309EC08:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309ec30
	if (cr6.eq) goto loc_8309EC30;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x8309ec30
	if (!cr6.eq) goto loc_8309EC30;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x83097a98
	sub_83097A98(ctx, base);
	// add r30,r3,r30
	r30.u64 = ctx.r3.u64 + r30.u64;
loc_8309EC30:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_8309EC34:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8309ec08
	if (!cr6.eq) goto loc_8309EC08;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,16(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// bl 0x83097a98
	sub_83097A98(ctx, base);
	// cmplw cr6,r30,r3
	cr6.compare<uint32_t>(r30.u32, ctx.r3.u32, xer);
	// beq cr6,0x8309ec70
	if (cr6.eq) goto loc_8309EC70;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3014
	ctx.r5.s64 = 3014;
	// addi r6,r11,19260
	ctx.r6.s64 = r11.s64 + 19260;
loc_8309EC5C:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_8309EC68:
	// mr r28,r23
	r28.u64 = r23.u64;
	// b 0x8309ec7c
	goto loc_8309EC7C;
loc_8309EC70:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83099758
	sub_83099758(ctx, base);
loc_8309EC7C:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c24
	return;
}

__attribute__((alias("__imp__sub_8309EC88"))) PPC_WEAK_FUNC(sub_8309EC88);
PPC_FUNC_IMPL(__imp__sub_8309EC88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb8
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// mr r17,r5
	r17.u64 = ctx.r5.u64;
	// mr r16,r6
	r16.u64 = ctx.r6.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x8309ecc0
	if (cr6.eq) goto loc_8309ECC0;
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x8309ecc0
	if (cr6.eq) goto loc_8309ECC0;
loc_8309ECB8:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8309f2b0
	goto loc_8309F2B0;
loc_8309ECC0:
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x8309ecd4
	if (cr6.eq) goto loc_8309ECD4;
	// lwz r11,4(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8309ecb8
	if (!cr6.eq) goto loc_8309ECB8;
loc_8309ECD4:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x8309ece8
	if (cr6.eq) goto loc_8309ECE8;
	// lwz r11,4(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8309ecb8
	if (!cr6.eq) goto loc_8309ECB8;
loc_8309ECE8:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// addi r22,r23,48
	r22.s64 = r23.s64 + 48;
	// bne cr6,0x8309ecfc
	if (!cr6.eq) goto loc_8309ECFC;
	// addi r22,r21,40
	r22.s64 = r21.s64 + 40;
	// beq cr6,0x8309ed04
	if (cr6.eq) goto loc_8309ED04;
loc_8309ECFC:
	// lwz r25,16(r23)
	r25.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// b 0x8309ed08
	goto loc_8309ED08;
loc_8309ED04:
	// li r25,0
	r25.s64 = 0;
loc_8309ED08:
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x8309ed18
	if (cr6.eq) goto loc_8309ED18;
	// lwz r20,16(r17)
	r20.u64 = PPC_LOAD_U32(r17.u32 + 16);
	// b 0x8309ed1c
	goto loc_8309ED1C;
loc_8309ED18:
	// li r20,0
	r20.s64 = 0;
loc_8309ED1C:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x8309ed2c
	if (cr6.eq) goto loc_8309ED2C;
	// lwz r19,16(r16)
	r19.u64 = PPC_LOAD_U32(r16.u32 + 16);
	// b 0x8309ed30
	goto loc_8309ED30;
loc_8309ED2C:
	// li r19,0
	r19.s64 = 0;
loc_8309ED30:
	// li r3,80
	ctx.r3.s64 = 80;
	// stw r20,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r20.u32);
	// stw r19,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r19.u32);
	// li r27,0
	r27.s64 = 0;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309ed70
	if (cr0.eq) goto loc_8309ED70;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,30
	ctx.r5.s64 = 30;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// b 0x8309ed74
	goto loc_8309ED74;
loc_8309ED70:
	// li r18,0
	r18.s64 = 0;
loc_8309ED74:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x8309f000
	if (cr6.eq) goto loc_8309F000;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x830979c8
	sub_830979C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bne 0x8309eda0
	if (!cr0.eq) goto loc_8309EDA0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,19516
	ctx.r6.s64 = r11.s64 + 19516;
	// b 0x8309eff4
	goto loc_8309EFF4;
loc_8309EDA0:
	// addi r28,r18,16
	r28.s64 = r18.s64 + 16;
	// addi r7,r1,116
	ctx.r7.s64 = ctx.r1.s64 + 116;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// bl 0x8309b2c8
	sub_8309B2C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x8309edd0
	if (!cr0.lt) goto loc_8309EDD0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,19472
	ctx.r6.s64 = r11.s64 + 19472;
	// b 0x8309eff0
	goto loc_8309EFF0;
loc_8309EDD0:
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// lwz r30,116(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r24,r30
	r24.u64 = r30.u64;
	// beq cr6,0x8309ef48
	if (cr6.eq) goto loc_8309EF48;
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309ef48
	if (!cr6.eq) goto loc_8309EF48;
	// lwz r31,28(r25)
	r31.u64 = PPC_LOAD_U32(r25.u32 + 28);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// lwz r29,32(r25)
	r29.u64 = PPC_LOAD_U32(r25.u32 + 32);
	// beq cr6,0x8309ee78
	if (cr6.eq) goto loc_8309EE78;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309ee78
	if (!cr6.eq) goto loc_8309EE78;
	// lwz r11,28(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// blt cr6,0x8309ee28
	if (cr6.lt) goto loc_8309EE28;
	// lwz r11,32(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bge cr6,0x8309ee78
	if (!cr6.lt) goto loc_8309EE78;
loc_8309EE28:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// lwz r11,28(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 28);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bge cr6,0x8309ee4c
	if (!cr6.lt) goto loc_8309EE4C;
	// stw r31,28(r26)
	PPC_STORE_U32(r26.u32 + 28, r31.u32);
loc_8309EE4C:
	// lwz r11,32(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 32);
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bge cr6,0x8309ee5c
	if (!cr6.lt) goto loc_8309EE5C;
	// stw r29,32(r26)
	PPC_STORE_U32(r26.u32 + 32, r29.u32);
loc_8309EE5C:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8309efe8
	if (cr0.eq) goto loc_8309EFE8;
loc_8309EE78:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8309eef8
	if (cr6.eq) goto loc_8309EEF8;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309eef8
	if (!cr6.eq) goto loc_8309EEF8;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// blt cr6,0x8309eea4
	if (cr6.lt) goto loc_8309EEA4;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bge cr6,0x8309eef8
	if (!cr6.lt) goto loc_8309EEF8;
loc_8309EEA4:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// lwz r11,28(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 28);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bge cr6,0x8309eecc
	if (!cr6.lt) goto loc_8309EECC;
	// stw r31,28(r24)
	PPC_STORE_U32(r24.u32 + 28, r31.u32);
loc_8309EECC:
	// lwz r11,32(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 32);
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bge cr6,0x8309eedc
	if (!cr6.lt) goto loc_8309EEDC;
	// stw r29,32(r24)
	PPC_STORE_U32(r24.u32 + 32, r29.u32);
loc_8309EEDC:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8309efe8
	if (cr0.eq) goto loc_8309EFE8;
loc_8309EEF8:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309ef48
	if (cr6.eq) goto loc_8309EF48;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x8309ef48
	if (!cr6.eq) goto loc_8309EF48;
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// blt cr6,0x8309ef30
	if (cr6.lt) goto loc_8309EF30;
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplw cr6,r9,r29
	cr6.compare<uint32_t>(ctx.r9.u32, r29.u32, xer);
	// bge cr6,0x8309ef48
	if (!cr6.lt) goto loc_8309EF48;
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bge cr6,0x8309ef34
	if (!cr6.lt) goto loc_8309EF34;
loc_8309EF30:
	// stw r31,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r31.u32);
loc_8309EF34:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// bge cr6,0x8309ef48
	if (!cr6.lt) goto loc_8309EF48;
	// stw r29,32(r11)
	PPC_STORE_U32(r11.u32 + 32, r29.u32);
loc_8309EF48:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309f008
	if (cr6.eq) goto loc_8309F008;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r3,40
	ctx.r3.s64 = 40;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309ef80
	if (!cr6.eq) goto loc_8309EF80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309efc0
	if (cr0.eq) goto loc_8309EFC0;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwz r8,32(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r7,28(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// b 0x8309efa4
	goto loc_8309EFA4;
loc_8309EF80:
	// bl 0x83046708
	sub_83046708(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x8309efc0
	if (cr0.eq) goto loc_8309EFC0;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// bl 0x83097a98
	sub_83097A98(ctx, base);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8309EFA4:
	// li r9,512
	ctx.r9.s64 = 512;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x8309efc4
	goto loc_8309EFC4;
loc_8309EFC0:
	// li r27,0
	r27.s64 = 0;
loc_8309EFC4:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8309f000
	if (cr6.eq) goto loc_8309F000;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8309f008
	if (!cr0.eq) goto loc_8309F008;
loc_8309EFE8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,19424
	ctx.r6.s64 = r11.s64 + 19424;
loc_8309EFF0:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
loc_8309EFF4:
	// li r5,3020
	ctx.r5.s64 = 3020;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_8309F000:
	// li r18,0
	r18.s64 = 0;
	// b 0x8309f2ac
	goto loc_8309F2AC;
loc_8309F008:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x8309f034
	if (cr6.eq) goto loc_8309F034;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// stw r3,32(r18)
	PPC_STORE_U32(r18.u32 + 32, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f000
	if (cr0.eq) goto loc_8309F000;
loc_8309F034:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f068
	if (cr0.eq) goto loc_8309F068;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8309f06c
	goto loc_8309F06C;
loc_8309F068:
	// li r31,0
	r31.s64 = 0;
loc_8309F06C:
	// stw r31,36(r18)
	PPC_STORE_U32(r18.u32 + 36, r31.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8309f000
	if (cr6.eq) goto loc_8309F000;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// addi r29,r11,18280
	r29.s64 = r11.s64 + 18280;
	// beq 0x8309f0a4
	if (cr0.eq) goto loc_8309F0A4;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x8309f0a8
	goto loc_8309F0A8;
loc_8309F0A4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8309F0A8:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq cr6,0x8309f000
	if (cr6.eq) goto loc_8309F000;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8309f0e8
	if (cr6.eq) goto loc_8309F0E8;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309f000
	if (cr6.eq) goto loc_8309F000;
loc_8309F0E8:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// lis r11,-32245
	r11.s64 = -2113208320;
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// addi r30,r11,25560
	r30.s64 = r11.s64 + 25560;
	// beq 0x8309f114
	if (cr0.eq) goto loc_8309F114;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x8309f118
	goto loc_8309F118;
loc_8309F114:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8309F118:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq cr6,0x8309f000
	if (cr6.eq) goto loc_8309F000;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x8309f188
	if (cr6.eq) goto loc_8309F188;
	// cmplw cr6,r20,r26
	cr6.compare<uint32_t>(r20.u32, r26.u32, xer);
	// beq cr6,0x8309f168
	if (cr6.eq) goto loc_8309F168;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83095a00
	sub_83095A00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8309f168
	if (!cr0.eq) goto loc_8309F168;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// b 0x8309f170
	goto loc_8309F170;
loc_8309F168:
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
loc_8309F170:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309f000
	if (cr6.eq) goto loc_8309F000;
loc_8309F188:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f1ac
	if (cr0.eq) goto loc_8309F1AC;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x8309f1b0
	goto loc_8309F1B0;
loc_8309F1AC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8309F1B0:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r3.u32);
	// beq cr6,0x8309f000
	if (cr6.eq) goto loc_8309F000;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8309f1fc
	if (cr6.eq) goto loc_8309F1FC;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309f000
	if (cr6.eq) goto loc_8309F000;
loc_8309F1FC:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f220
	if (cr0.eq) goto loc_8309F220;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x8309f224
	goto loc_8309F224;
loc_8309F220:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8309F224:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r3.u32);
	// beq cr6,0x8309f000
	if (cr6.eq) goto loc_8309F000;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x8309f294
	if (cr6.eq) goto loc_8309F294;
	// cmplw cr6,r19,r24
	cr6.compare<uint32_t>(r19.u32, r24.u32, xer);
	// beq cr6,0x8309f2b8
	if (cr6.eq) goto loc_8309F2B8;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83095a00
	sub_83095A00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8309f2b8
	if (!cr0.eq) goto loc_8309F2B8;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
loc_8309F274:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309f000
	if (cr6.eq) goto loc_8309F000;
loc_8309F294:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83099758
	sub_83099758(ctx, base);
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83099758
	sub_83099758(ctx, base);
loc_8309F2AC:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
loc_8309F2B0:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82ca2c08
	return;
loc_8309F2B8:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// b 0x8309f274
	goto loc_8309F274;
}

__attribute__((alias("__imp__sub_8309F2C8"))) PPC_WEAK_FUNC(sub_8309F2C8);
PPC_FUNC_IMPL(__imp__sub_8309F2C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8309f580
	if (cr6.eq) goto loc_8309F580;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8309f580
	if (!cr6.eq) goto loc_8309F580;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8309f580
	if (cr6.eq) goto loc_8309F580;
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8309f580
	if (!cr6.eq) goto loc_8309F580;
	// li r3,80
	ctx.r3.s64 = 80;
	// addi r27,r26,48
	r27.s64 = r26.s64 + 48;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f340
	if (cr0.eq) goto loc_8309F340;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,28
	ctx.r5.s64 = 28;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8309f344
	goto loc_8309F344;
loc_8309F340:
	// li r30,0
	r30.s64 = 0;
loc_8309F344:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8309f580
	if (cr6.eq) goto loc_8309F580;
	// lwz r31,16(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r29,16(r26)
	r29.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8309f568
	if (cr6.eq) goto loc_8309F568;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x8309f398
	if (!cr6.eq) goto loc_8309F398;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309f45c
	if (cr6.eq) goto loc_8309F45C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f580
	if (cr0.eq) goto loc_8309F580;
	// b 0x8309f45c
	goto loc_8309F45C;
loc_8309F398:
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309f568
	if (!cr6.eq) goto loc_8309F568;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x8309f3c8
	if (!cr6.eq) goto loc_8309F3C8;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f44c
	if (cr0.eq) goto loc_8309F44C;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// rlwinm r9,r11,0,22,22
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	// b 0x8309f430
	goto loc_8309F430;
loc_8309F3C8:
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309f568
	if (!cr6.eq) goto loc_8309F568;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x8309f400
	if (!cr6.eq) goto loc_8309F400;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f44c
	if (cr0.eq) goto loc_8309F44C;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// rlwinm r9,r11,0,22,22
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	// b 0x8309f438
	goto loc_8309F438;
loc_8309F400:
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309f568
	if (!cr6.eq) goto loc_8309F568;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// rlwinm. r11,r11,0,10,10
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8309f568
	if (cr0.eq) goto loc_8309F568;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f44c
	if (cr0.eq) goto loc_8309F44C;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// rlwinm r9,r11,0,10,22
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x3FFE00;
	// rlwinm r9,r9,0,22,10
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFE003FF;
loc_8309F430:
	// li r8,1
	ctx.r8.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
loc_8309F438:
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r6,0
	ctx.r6.s64 = 0;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// b 0x8309f450
	goto loc_8309F450;
loc_8309F44C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8309F450:
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8309f580
	if (cr6.eq) goto loc_8309F580;
loc_8309F45C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8309f47c
	if (cr6.eq) goto loc_8309F47C;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309f47c
	if (!cr6.eq) goto loc_8309F47C;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8309f48c
	if (cr6.eq) goto loc_8309F48C;
loc_8309F47C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3051
	ctx.r5.s64 = 3051;
	// addi r6,r11,19560
	ctx.r6.s64 = r11.s64 + 19560;
	// b 0x8309f574
	goto loc_8309F574;
loc_8309F48C:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f580
	if (cr0.eq) goto loc_8309F580;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f4e0
	if (cr0.eq) goto loc_8309F4E0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,6
	ctx.r5.s64 = 6;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8309f4e4
	goto loc_8309F4E4;
loc_8309F4E0:
	// li r31,0
	r31.s64 = 0;
loc_8309F4E4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8309f580
	if (cr6.eq) goto loc_8309F580;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bne 0x8309f528
	if (!cr0.eq) goto loc_8309F528;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r5,8(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x8309ae98
	sub_8309AE98(ctx, base);
	// b 0x8309f580
	goto loc_8309F580;
loc_8309F528:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// oris r11,r11,64
	r11.u64 = r11.u64 | 4194304;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f580
	if (cr0.eq) goto loc_8309F580;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83099758
	sub_83099758(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x8309f584
	goto loc_8309F584;
loc_8309F568:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3021
	ctx.r5.s64 = 3021;
	// addi r6,r11,19544
	ctx.r6.s64 = r11.s64 + 19544;
loc_8309F574:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_8309F580:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8309F584:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_8309F590"))) PPC_WEAK_FUNC(sub_8309F590);
PPC_FUNC_IMPL(__imp__sub_8309F590) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r20,0
	r20.s64 = 0;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r24,r20
	r24.u64 = r20.u64;
	// mr r21,r20
	r21.u64 = r20.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// stw r24,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r24.u32);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// stw r21,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r21.u32);
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// mr r25,r8
	r25.u64 = ctx.r8.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// mr r27,r20
	r27.u64 = r20.u64;
	// mr r22,r20
	r22.u64 = r20.u64;
	// beq cr6,0x8309f5ec
	if (cr6.eq) goto loc_8309F5EC;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x8309f5ec
	if (cr6.eq) goto loc_8309F5EC;
loc_8309F5E4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8309fe44
	goto loc_8309FE44;
loc_8309F5EC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8309f608
	if (cr6.eq) goto loc_8309F608;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8309f5e4
	if (!cr6.eq) goto loc_8309F5E4;
	// addi r23,r28,48
	r23.s64 = r28.s64 + 48;
	// b 0x8309f618
	goto loc_8309F618;
loc_8309F608:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// addi r23,r29,48
	r23.s64 = r29.s64 + 48;
	// bne cr6,0x8309f618
	if (!cr6.eq) goto loc_8309F618;
	// addi r23,r26,40
	r23.s64 = r26.s64 + 40;
loc_8309F618:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309f64c
	if (cr0.eq) goto loc_8309F64C;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8309f650
	goto loc_8309F650;
loc_8309F64C:
	// mr r30,r20
	r30.u64 = r20.u64;
loc_8309F650:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8309f5e4
	if (cr6.eq) goto loc_8309F5E4;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8309f680
	if (cr6.eq) goto loc_8309F680;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309fe3c
	if (cr0.eq) goto loc_8309FE3C;
loc_8309F680:
	// cmpwi cr6,r31,35
	cr6.compare<int32_t>(r31.s32, 35, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmpwi cr6,r31,36
	cr6.compare<int32_t>(r31.s32, 36, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmpwi cr6,r31,37
	cr6.compare<int32_t>(r31.s32, 37, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmpwi cr6,r31,38
	cr6.compare<int32_t>(r31.s32, 38, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmpwi cr6,r31,39
	cr6.compare<int32_t>(r31.s32, 39, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmpwi cr6,r31,45
	cr6.compare<int32_t>(r31.s32, 45, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmpwi cr6,r31,46
	cr6.compare<int32_t>(r31.s32, 46, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmpwi cr6,r31,40
	cr6.compare<int32_t>(r31.s32, 40, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmpwi cr6,r31,41
	cr6.compare<int32_t>(r31.s32, 41, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmpwi cr6,r31,42
	cr6.compare<int32_t>(r31.s32, 42, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmpwi cr6,r31,43
	cr6.compare<int32_t>(r31.s32, 43, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmpwi cr6,r31,44
	cr6.compare<int32_t>(r31.s32, 44, xer);
	// beq cr6,0x8309f70c
	if (cr6.eq) goto loc_8309F70C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8309f7d4
	if (cr6.eq) goto loc_8309F7D4;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x8309f7d4
	if (!cr0.eq) goto loc_8309F7D4;
	// b 0x8309fe3c
	goto loc_8309FE3C;
loc_8309F70C:
	// addi r11,r31,-35
	r11.s64 = r31.s64 + -35;
	// li r4,8
	ctx.r4.s64 = 8;
	// cmplwi cr6,r11,11
	cr6.compare<uint32_t>(r11.u32, 11, xer);
	// bgt cr6,0x8309f7ac
	if (cr6.gt) goto loc_8309F7AC;
	// lis r12,-32249
	r12.s64 = -2113470464;
	// addi r12,r12,14720
	r12.s64 = r12.s64 + 14720;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// lis r12,-31990
	r12.s64 = -2096496640;
	// addi r12,r12,-2236
	r12.s64 = r12.s64 + -2236;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_8309F744;
	case 1:
		goto loc_8309F74C;
	case 2:
		goto loc_8309F754;
	case 3:
		goto loc_8309F75C;
	case 4:
		goto loc_8309F764;
	case 5:
		goto loc_8309F784;
	case 6:
		goto loc_8309F78C;
	case 7:
		goto loc_8309F794;
	case 8:
		goto loc_8309F79C;
	case 9:
		goto loc_8309F7A4;
	case 10:
		goto loc_8309F76C;
	case 11:
		goto loc_8309F778;
	default:
		__builtin_unreachable();
	}
loc_8309F744:
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x8309f7a8
	goto loc_8309F7A8;
loc_8309F74C:
	// li r4,9
	ctx.r4.s64 = 9;
	// b 0x8309f7a8
	goto loc_8309F7A8;
loc_8309F754:
	// li r4,10
	ctx.r4.s64 = 10;
	// b 0x8309f7a8
	goto loc_8309F7A8;
loc_8309F75C:
	// li r4,11
	ctx.r4.s64 = 11;
	// b 0x8309f7a8
	goto loc_8309F7A8;
loc_8309F764:
	// li r4,12
	ctx.r4.s64 = 12;
	// b 0x8309f7a8
	goto loc_8309F7A8;
loc_8309F76C:
	// li r31,1
	r31.s64 = 1;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x8309f7ac
	goto loc_8309F7AC;
loc_8309F778:
	// li r31,1
	r31.s64 = 1;
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x8309f7ac
	goto loc_8309F7AC;
loc_8309F784:
	// li r4,13
	ctx.r4.s64 = 13;
	// b 0x8309f7a8
	goto loc_8309F7A8;
loc_8309F78C:
	// li r4,14
	ctx.r4.s64 = 14;
	// b 0x8309f7a8
	goto loc_8309F7A8;
loc_8309F794:
	// li r4,21
	ctx.r4.s64 = 21;
	// b 0x8309f7a8
	goto loc_8309F7A8;
loc_8309F79C:
	// li r4,22
	ctx.r4.s64 = 22;
	// b 0x8309f7a8
	goto loc_8309F7A8;
loc_8309F7A4:
	// li r4,23
	ctx.r4.s64 = 23;
loc_8309F7A8:
	// li r31,27
	r31.s64 = 27;
loc_8309F7AC:
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309f590
	sub_8309F590(ctx, base);
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309fe3c
	if (cr0.eq) goto loc_8309FE3C;
	// stw r31,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r31.u32);
loc_8309F7D4:
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309f7f0
	if (cr6.eq) goto loc_8309F7F0;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r24,r11
	r24.u64 = r11.u64;
	// mr r27,r11
	r27.u64 = r11.u64;
	// stw r24,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r24.u32);
loc_8309F7F0:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// beq cr6,0x8309f8f0
	if (cr6.eq) goto loc_8309F8F0;
	// cmpwi cr6,r31,1
	cr6.compare<int32_t>(r31.s32, 1, xer);
	// beq cr6,0x8309f8f0
	if (cr6.eq) goto loc_8309F8F0;
	// cmpwi cr6,r31,26
	cr6.compare<int32_t>(r31.s32, 26, xer);
	// beq cr6,0x8309f8f0
	if (cr6.eq) goto loc_8309F8F0;
	// cmpwi cr6,r31,27
	cr6.compare<int32_t>(r31.s32, 27, xer);
	// beq cr6,0x8309f8f0
	if (cr6.eq) goto loc_8309F8F0;
	// cmpwi cr6,r31,19
	cr6.compare<int32_t>(r31.s32, 19, xer);
	// beq cr6,0x8309f8f0
	if (cr6.eq) goto loc_8309F8F0;
	// cmpwi cr6,r31,20
	cr6.compare<int32_t>(r31.s32, 20, xer);
	// beq cr6,0x8309f8f0
	if (cr6.eq) goto loc_8309F8F0;
	// cmpwi cr6,r31,7
	cr6.compare<int32_t>(r31.s32, 7, xer);
	// bne cr6,0x8309f858
	if (!cr6.eq) goto loc_8309F858;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8309f848
	if (cr6.eq) goto loc_8309F848;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309f848
	if (!cr6.eq) goto loc_8309F848;
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// blt cr6,0x8309f97c
	if (cr6.lt) goto loc_8309F97C;
loc_8309F848:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3082
	ctx.r5.s64 = 3082;
	// addi r6,r11,19836
	ctx.r6.s64 = r11.s64 + 19836;
	// b 0x8309fe30
	goto loc_8309FE30;
loc_8309F858:
	// cmpwi cr6,r31,13
	cr6.compare<int32_t>(r31.s32, 13, xer);
	// beq cr6,0x8309f8b8
	if (cr6.eq) goto loc_8309F8B8;
	// cmpwi cr6,r31,14
	cr6.compare<int32_t>(r31.s32, 14, xer);
	// beq cr6,0x8309f8b8
	if (cr6.eq) goto loc_8309F8B8;
	// cmpwi cr6,r31,21
	cr6.compare<int32_t>(r31.s32, 21, xer);
	// beq cr6,0x8309f8b8
	if (cr6.eq) goto loc_8309F8B8;
	// cmpwi cr6,r31,22
	cr6.compare<int32_t>(r31.s32, 22, xer);
	// beq cr6,0x8309f8b8
	if (cr6.eq) goto loc_8309F8B8;
	// cmpwi cr6,r31,23
	cr6.compare<int32_t>(r31.s32, 23, xer);
	// beq cr6,0x8309f8b8
	if (cr6.eq) goto loc_8309F8B8;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8309f8a8
	if (cr6.eq) goto loc_8309F8A8;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309f8a8
	if (!cr6.eq) goto loc_8309F8A8;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830979c8
	sub_830979C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8309f8f0
	if (!cr0.eq) goto loc_8309F8F0;
loc_8309F8A8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3022
	ctx.r5.s64 = 3022;
	// addi r6,r11,19800
	ctx.r6.s64 = r11.s64 + 19800;
	// b 0x8309fe30
	goto loc_8309FE30;
loc_8309F8B8:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8309f848
	if (cr6.eq) goto loc_8309F848;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309f848
	if (!cr6.eq) goto loc_8309F848;
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bge cr6,0x8309f848
	if (!cr6.lt) goto loc_8309F848;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
loc_8309F8F0:
	// cmpwi cr6,r31,2
	cr6.compare<int32_t>(r31.s32, 2, xer);
	// beq cr6,0x8309f910
	if (cr6.eq) goto loc_8309F910;
	// cmpwi cr6,r31,3
	cr6.compare<int32_t>(r31.s32, 3, xer);
	// beq cr6,0x8309f910
	if (cr6.eq) goto loc_8309F910;
	// cmpwi cr6,r31,26
	cr6.compare<int32_t>(r31.s32, 26, xer);
	// beq cr6,0x8309f910
	if (cr6.eq) goto loc_8309F910;
	// cmpwi cr6,r31,27
	cr6.compare<int32_t>(r31.s32, 27, xer);
	// bne cr6,0x8309f97c
	if (!cr6.eq) goto loc_8309F97C;
loc_8309F910:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8309fe24
	if (!cr0.eq) goto loc_8309FE24;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r4,32(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// bl 0x83095fc0
	sub_83095FC0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8309fe24
	if (!cr0.eq) goto loc_8309FE24;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x8309f950
	if (cr6.eq) goto loc_8309F950;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x8309f97c
	if (!cr6.eq) goto loc_8309F97C;
loc_8309F950:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x8309f97c
	if (!cr6.eq) goto loc_8309F97C;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830979c8
	sub_830979C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8309f97c
	if (!cr0.eq) goto loc_8309F97C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3065
	ctx.r5.s64 = 3065;
	// addi r6,r11,19748
	ctx.r6.s64 = r11.s64 + 19748;
	// b 0x8309fe30
	goto loc_8309FE30;
loc_8309F97C:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309f998
	if (cr6.eq) goto loc_8309F998;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r21,r11
	r21.u64 = r11.u64;
	// mr r22,r11
	r22.u64 = r11.u64;
	// stw r21,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r21.u32);
loc_8309F998:
	// cmpwi cr6,r31,26
	cr6.compare<int32_t>(r31.s32, 26, xer);
	// beq cr6,0x8309fdd8
	if (cr6.eq) goto loc_8309FDD8;
	// cmpwi cr6,r31,27
	cr6.compare<int32_t>(r31.s32, 27, xer);
	// beq cr6,0x8309fdd8
	if (cr6.eq) goto loc_8309FDD8;
	// cmpwi cr6,r31,13
	cr6.compare<int32_t>(r31.s32, 13, xer);
	// beq cr6,0x8309fd7c
	if (cr6.eq) goto loc_8309FD7C;
	// cmpwi cr6,r31,14
	cr6.compare<int32_t>(r31.s32, 14, xer);
	// beq cr6,0x8309fd7c
	if (cr6.eq) goto loc_8309FD7C;
	// cmpwi cr6,r31,21
	cr6.compare<int32_t>(r31.s32, 21, xer);
	// beq cr6,0x8309fd58
	if (cr6.eq) goto loc_8309FD58;
	// cmpwi cr6,r31,22
	cr6.compare<int32_t>(r31.s32, 22, xer);
	// beq cr6,0x8309fd58
	if (cr6.eq) goto loc_8309FD58;
	// cmpwi cr6,r31,23
	cr6.compare<int32_t>(r31.s32, 23, xer);
	// beq cr6,0x8309fd58
	if (cr6.eq) goto loc_8309FD58;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x8309fa04
	if (!cr6.eq) goto loc_8309FA04;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8309fb74
	if (cr6.eq) goto loc_8309FB74;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309fe3c
	if (cr0.eq) goto loc_8309FE3C;
	// b 0x8309fb74
	goto loc_8309FB74;
loc_8309FA04:
	// cmpwi cr6,r31,7
	cr6.compare<int32_t>(r31.s32, 7, xer);
	// beq cr6,0x8309fd2c
	if (cr6.eq) goto loc_8309FD2C;
	// cmpwi cr6,r31,5
	cr6.compare<int32_t>(r31.s32, 5, xer);
	// beq cr6,0x8309fd2c
	if (cr6.eq) goto loc_8309FD2C;
	// cmpwi cr6,r31,6
	cr6.compare<int32_t>(r31.s32, 6, xer);
	// beq cr6,0x8309fd2c
	if (cr6.eq) goto loc_8309FD2C;
	// cmpwi cr6,r31,2
	cr6.compare<int32_t>(r31.s32, 2, xer);
	// beq cr6,0x8309fd2c
	if (cr6.eq) goto loc_8309FD2C;
	// cmpwi cr6,r31,3
	cr6.compare<int32_t>(r31.s32, 3, xer);
	// beq cr6,0x8309fd2c
	if (cr6.eq) goto loc_8309FD2C;
	// cmpwi cr6,r31,1
	cr6.compare<int32_t>(r31.s32, 1, xer);
	// beq cr6,0x8309fd2c
	if (cr6.eq) goto loc_8309FD2C;
	// cmpwi cr6,r31,4
	cr6.compare<int32_t>(r31.s32, 4, xer);
	// bne cr6,0x8309fac8
	if (!cr6.eq) goto loc_8309FAC8;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8309fe3c
	if (cr6.eq) goto loc_8309FE3C;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309fa78
	if (cr0.eq) goto loc_8309FA78;
	// li r9,512
	ctx.r9.s64 = 512;
	// lwz r8,32(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r7,28(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,16(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// b 0x8309fa7c
	goto loc_8309FA7C;
loc_8309FA78:
	// mr r24,r20
	r24.u64 = r20.u64;
loc_8309FA7C:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8309fe3c
	if (cr6.eq) goto loc_8309FE3C;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8309fabc
	if (cr0.eq) goto loc_8309FABC;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// b 0x8309fd18
	goto loc_8309FD18;
loc_8309FABC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,19684
	ctx.r6.s64 = r11.s64 + 19684;
	// b 0x8309fd04
	goto loc_8309FD04;
loc_8309FAC8:
	// cmpwi cr6,r31,24
	cr6.compare<int32_t>(r31.s32, 24, xer);
	// beq cr6,0x8309fc64
	if (cr6.eq) goto loc_8309FC64;
	// cmpwi cr6,r31,25
	cr6.compare<int32_t>(r31.s32, 25, xer);
	// beq cr6,0x8309fc64
	if (cr6.eq) goto loc_8309FC64;
	// cmpwi cr6,r31,15
	cr6.compare<int32_t>(r31.s32, 15, xer);
	// beq cr6,0x8309fb3c
	if (cr6.eq) goto loc_8309FB3C;
	// cmpwi cr6,r31,16
	cr6.compare<int32_t>(r31.s32, 16, xer);
	// beq cr6,0x8309fb3c
	if (cr6.eq) goto loc_8309FB3C;
	// cmpwi cr6,r31,17
	cr6.compare<int32_t>(r31.s32, 17, xer);
	// beq cr6,0x8309fb3c
	if (cr6.eq) goto loc_8309FB3C;
	// cmpwi cr6,r31,18
	cr6.compare<int32_t>(r31.s32, 18, xer);
	// beq cr6,0x8309fb3c
	if (cr6.eq) goto loc_8309FB3C;
	// cmpwi cr6,r31,19
	cr6.compare<int32_t>(r31.s32, 19, xer);
	// beq cr6,0x8309fb3c
	if (cr6.eq) goto loc_8309FB3C;
	// cmpwi cr6,r31,20
	cr6.compare<int32_t>(r31.s32, 20, xer);
	// beq cr6,0x8309fb3c
	if (cr6.eq) goto loc_8309FB3C;
loc_8309FB08:
	// addi r8,r30,16
	ctx.r8.s64 = r30.s64 + 16;
	// addi r7,r1,132
	ctx.r7.s64 = ctx.r1.s64 + 132;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309b2c8
	sub_8309B2C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x8309fb6c
	if (!cr0.lt) goto loc_8309FB6C;
loc_8309FB2C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r6,r11,19668
	ctx.r6.s64 = r11.s64 + 19668;
	// b 0x8309fe30
	goto loc_8309FE30;
loc_8309FB3C:
	// addi r31,r30,16
	r31.s64 = r30.s64 + 16;
	// addi r7,r1,132
	ctx.r7.s64 = ctx.r1.s64 + 132;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309b2c8
	sub_8309B2C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8309fb2c
	if (cr0.lt) goto loc_8309FB2C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r20,20(r11)
	PPC_STORE_U32(r11.u32 + 20, r20.u32);
loc_8309FB6C:
	// lwz r21,132(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r24,128(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_8309FB74:
	// lwz r9,32(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8309fbc4
	if (cr6.eq) goto loc_8309FBC4;
	// cmplw cr6,r27,r24
	cr6.compare<uint32_t>(r27.u32, r24.u32, xer);
	// beq cr6,0x8309fbc4
	if (cr6.eq) goto loc_8309FBC4;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83095a00
	sub_83095A00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8309fbc4
	if (!cr0.eq) goto loc_8309FBC4;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309fe3c
	if (cr0.eq) goto loc_8309FE3C;
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
loc_8309FBC4:
	// lwz r9,36(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8309fc14
	if (cr6.eq) goto loc_8309FC14;
	// cmplw cr6,r22,r21
	cr6.compare<uint32_t>(r22.u32, r21.u32, xer);
	// beq cr6,0x8309fc14
	if (cr6.eq) goto loc_8309FC14;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83095a00
	sub_83095A00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8309fc14
	if (!cr0.eq) goto loc_8309FC14;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309fe3c
	if (cr0.eq) goto loc_8309FE3C;
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
loc_8309FC14:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8309fc24
	if (!cr6.eq) goto loc_8309FC24;
	// stw r20,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r20.u32);
loc_8309FC24:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83099758
	sub_83099758(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830960a8
	sub_830960A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8309fe40
	if (cr0.eq) goto loc_8309FE40;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309cff8
	sub_8309CFF8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309fe40
	if (cr0.eq) goto loc_8309FE40;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8309fe40
	goto loc_8309FE40;
loc_8309FC64:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309fc98
	if (cr0.eq) goto loc_8309FC98;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// b 0x8309fc9c
	goto loc_8309FC9C;
loc_8309FC98:
	// mr r24,r20
	r24.u64 = r20.u64;
loc_8309FC9C:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8309fe3c
	if (cr6.eq) goto loc_8309FE3C;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8309fcfc
	if (cr0.eq) goto loc_8309FCFC;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8309fcfc
	if (cr0.eq) goto loc_8309FCFC;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// mr r21,r24
	r21.u64 = r24.u64;
	// b 0x8309fd18
	goto loc_8309FD18;
loc_8309FCFC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,19608
	ctx.r6.s64 = r11.s64 + 19608;
loc_8309FD04:
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r4,r30,48
	ctx.r4.s64 = r30.s64 + 48;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// stw r20,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r20.u32);
loc_8309FD18:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83097810
	sub_83097810(ctx, base);
	// b 0x8309fb74
	goto loc_8309FB74;
loc_8309FD2C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8309fd18
	if (cr6.eq) goto loc_8309FD18;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309fe3c
	if (cr0.eq) goto loc_8309FE3C;
	// b 0x8309fd18
	goto loc_8309FD18;
loc_8309FD58:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x8309fb08
	if (cr6.eq) goto loc_8309FB08;
	// lwz r11,4(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309f848
	if (!cr6.eq) goto loc_8309F848;
	// lwz r11,20(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// blt cr6,0x8309fb08
	if (cr6.lt) goto loc_8309FB08;
	// b 0x8309f848
	goto loc_8309F848;
loc_8309FD7C:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x8309fd9c
	if (cr6.eq) goto loc_8309FD9C;
	// lwz r11,4(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8309f848
	if (!cr6.eq) goto loc_8309F848;
	// lwz r11,20(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bge cr6,0x8309f848
	if (!cr6.lt) goto loc_8309F848;
loc_8309FD9C:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8309fe1c
	if (!cr0.eq) goto loc_8309FE1C;
loc_8309FDB8:
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309ae98
	sub_8309AE98(ctx, base);
	// b 0x8309fe3c
	goto loc_8309FE3C;
loc_8309FDD8:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8309fdb8
	if (cr0.eq) goto loc_8309FDB8;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8309fe1c
	if (cr6.eq) goto loc_8309FE1C;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309fe3c
	if (cr0.eq) goto loc_8309FE3C;
loc_8309FE1C:
	// mr r21,r27
	r21.u64 = r27.u64;
	// b 0x8309fb74
	goto loc_8309FB74;
loc_8309FE24:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3025
	ctx.r5.s64 = 3025;
	// addi r6,r11,19576
	ctx.r6.s64 = r11.s64 + 19576;
loc_8309FE30:
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_8309FE3C:
	// mr r30,r20
	r30.u64 = r20.u64;
loc_8309FE40:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8309FE44:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c18
	return;
}

__attribute__((alias("__imp__sub_8309FE50"))) PPC_WEAK_FUNC(sub_8309FE50);
PPC_FUNC_IMPL(__imp__sub_8309FE50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309ffa0
	if (cr6.eq) goto loc_8309FFA0;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309fe8c
	if (cr0.eq) goto loc_8309FE8C;
	// bl 0x83048e80
	sub_83048E80(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8309fe90
	goto loc_8309FE90;
loc_8309FE8C:
	// li r30,0
	r30.s64 = 0;
loc_8309FE90:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8309ffa0
	if (cr6.eq) goto loc_8309FFA0;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r11.u32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// beq cr6,0x8309fedc
	if (cr6.eq) goto loc_8309FEDC;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8309ff0c
	if (!cr6.eq) goto loc_8309FF0C;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,3079
	ctx.r5.s64 = 3079;
	// addi r6,r10,19896
	ctx.r6.s64 = ctx.r10.s64 + 19896;
	// b 0x8309fef4
	goto loc_8309FEF4;
loc_8309FEDC:
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8309ff2c
	if (cr6.eq) goto loc_8309FF2C;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// li r5,3080
	ctx.r5.s64 = 3080;
	// addi r6,r10,20780
	ctx.r6.s64 = ctx.r10.s64 + 20780;
loc_8309FEF4:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r7,20(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x8309ff2c
	goto loc_8309FF2C;
loc_8309FF0C:
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r5,52(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8309f590
	sub_8309F590(ctx, base);
	// stw r3,20(r30)
	PPC_STORE_U32(r30.u32 + 20, ctx.r3.u32);
loc_8309FF2C:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309ff5c
	if (cr0.eq) goto loc_8309FF5C;
	// addi r9,r31,40
	ctx.r9.s64 = r31.s64 + 40;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// b 0x8309ff60
	goto loc_8309FF60;
loc_8309FF5C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8309FF60:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8309ffa0
	if (cr6.eq) goto loc_8309FFA0;
	// stw r3,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r3.u32);
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8309ff94
	if (cr0.eq) goto loc_8309FF94;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,20620
	ctx.r6.s64 = r11.s64 + 20620;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x8309ff98
	goto loc_8309FF98;
loc_8309FF94:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8309FF98:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8309ffa4
	if (!cr6.eq) goto loc_8309FFA4;
loc_8309FFA0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8309FFA4:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_8309FFB0"))) PPC_WEAK_FUNC(sub_8309FFB0);
PPC_FUNC_IMPL(__imp__sub_8309FFB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830a0210
	if (cr6.eq) goto loc_830A0210;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x830a01f8
	if (!cr6.eq) goto loc_830A01F8;
	// lwz r4,16(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// bl 0x830979c8
	sub_830979C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a01f8
	if (cr0.eq) goto loc_830A01F8;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0030
	if (cr0.eq) goto loc_830A0030;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x830a0034
	goto loc_830A0034;
loc_830A0030:
	// li r28,0
	r28.s64 = 0;
loc_830A0034:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830a0210
	if (cr6.eq) goto loc_830A0210;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,16(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a0070
	if (!cr0.eq) goto loc_830A0070;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r6,r11,20004
	ctx.r6.s64 = r11.s64 + 20004;
	// addi r4,r29,48
	ctx.r4.s64 = r29.s64 + 48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A0070:
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830960a8
	sub_830960A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a00e0
	if (cr0.eq) goto loc_830A00E0;
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8309c488
	sub_8309C488(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a00e0
	if (cr0.lt) goto loc_830A00E0;
	// addi r6,r29,48
	ctx.r6.s64 = r29.s64 + 48;
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83095f40
	sub_83095F40(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a00e0
	if (cr0.lt) goto loc_830A00E0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,128(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lfd f0,3376(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x830a00d8
	if (!cr6.eq) goto loc_830A00D8;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_830A00D8:
	// bl 0x83046848
	sub_83046848(ctx, base);
	// b 0x830a0214
	goto loc_830A0214;
loc_830A00E0:
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a00fc
	if (cr0.eq) goto loc_830A00FC;
	// bl 0x83048e80
	sub_83048E80(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830a0100
	goto loc_830A0100;
loc_830A00FC:
	// li r30,0
	r30.s64 = 0;
loc_830A0100:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830a0210
	if (cr6.eq) goto loc_830A0210;
	// li r11,2
	r11.s64 = 2;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// stw r3,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0210
	if (cr0.eq) goto loc_830A0210;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830a0170
	if (cr6.eq) goto loc_830A0170;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,28(r30)
	PPC_STORE_U32(r30.u32 + 28, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0210
	if (cr0.eq) goto loc_830A0210;
loc_830A0170:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830a0198
	if (cr6.eq) goto loc_830A0198;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0210
	if (cr0.eq) goto loc_830A0210;
loc_830A0198:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830a01c0
	if (cr6.eq) goto loc_830A01C0;
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0210
	if (cr0.eq) goto loc_830A0210;
loc_830A01C0:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a01e8
	if (cr0.eq) goto loc_830A01E8;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,20620
	ctx.r6.s64 = r11.s64 + 20620;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a01ec
	goto loc_830A01EC;
loc_830A01E8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A01EC:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a0210
	if (cr6.eq) goto loc_830A0210;
	// b 0x830a0214
	goto loc_830A0214;
loc_830A01F8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3019
	ctx.r5.s64 = 3019;
	// addi r6,r11,19940
	ctx.r6.s64 = r11.s64 + 19940;
	// addi r4,r29,48
	ctx.r4.s64 = r29.s64 + 48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A0210:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A0214:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830A0220"))) PPC_WEAK_FUNC(sub_830A0220);
PPC_FUNC_IMPL(__imp__sub_830A0220) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// lwz r11,120(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
	// beq cr6,0x830a0308
	if (cr6.eq) goto loc_830A0308;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x830a02ec
	if (!cr6.eq) goto loc_830A02EC;
	// lwz r4,16(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// bl 0x830979c8
	sub_830979C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a02ec
	if (cr0.eq) goto loc_830A02EC;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a02a8
	if (cr0.eq) goto loc_830A02A8;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,9
	ctx.r5.s64 = 9;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x830a02ac
	goto loc_830A02AC;
loc_830A02A8:
	// li r28,0
	r28.s64 = 0;
loc_830A02AC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830a0408
	if (cr6.eq) goto loc_830A0408;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,16(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a030c
	if (!cr0.eq) goto loc_830A030C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r6,r11,20064
	ctx.r6.s64 = r11.s64 + 20064;
	// addi r4,r29,48
	ctx.r4.s64 = r29.s64 + 48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a030c
	goto loc_830A030C;
loc_830A02EC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3019
	ctx.r5.s64 = 3019;
	// addi r6,r11,20040
	ctx.r6.s64 = r11.s64 + 20040;
	// addi r4,r29,48
	ctx.r4.s64 = r29.s64 + 48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a0408
	goto loc_830A0408;
loc_830A0308:
	// lwz r28,112(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_830A030C:
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0328
	if (cr0.eq) goto loc_830A0328;
	// bl 0x83048e80
	sub_83048E80(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830a032c
	goto loc_830A032C;
loc_830A0328:
	// li r30,0
	r30.s64 = 0;
loc_830A032C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830a0408
	if (cr6.eq) goto loc_830A0408;
	// li r11,12
	r11.s64 = 12;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r11.u32);
	// beq cr6,0x830a0384
	if (cr6.eq) goto loc_830A0384;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830a0408
	if (cr6.eq) goto loc_830A0408;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// stw r3,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0408
	if (cr0.eq) goto loc_830A0408;
loc_830A0384:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830a03ac
	if (cr6.eq) goto loc_830A03AC;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0408
	if (cr0.eq) goto loc_830A0408;
loc_830A03AC:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830a03d4
	if (cr6.eq) goto loc_830A03D4;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,28(r30)
	PPC_STORE_U32(r30.u32 + 28, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0408
	if (cr0.eq) goto loc_830A0408;
loc_830A03D4:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a03fc
	if (cr0.eq) goto loc_830A03FC;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,20620
	ctx.r6.s64 = r11.s64 + 20620;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a0400
	goto loc_830A0400;
loc_830A03FC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A0400:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830a040c
	if (!cr6.eq) goto loc_830A040C;
loc_830A0408:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A040C:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c30
	return;
}

__attribute__((alias("__imp__sub_830A0418"))) PPC_WEAK_FUNC(sub_830A0418);
PPC_FUNC_IMPL(__imp__sub_830A0418) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830a04e0
	if (cr6.eq) goto loc_830A04E0;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x830a04fc
	if (!cr6.eq) goto loc_830A04FC;
	// lwz r4,16(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// bl 0x830979c8
	sub_830979C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a04fc
	if (cr0.eq) goto loc_830A04FC;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a04a0
	if (cr0.eq) goto loc_830A04A0;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x830a04a4
	goto loc_830A04A4;
loc_830A04A0:
	// li r28,0
	r28.s64 = 0;
loc_830A04A4:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830a0624
	if (cr6.eq) goto loc_830A0624;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,16(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a04e0
	if (!cr0.eq) goto loc_830A04E0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r6,r11,20004
	ctx.r6.s64 = r11.s64 + 20004;
	// addi r4,r29,48
	ctx.r4.s64 = r29.s64 + 48;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A04E0:
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0518
	if (cr0.eq) goto loc_830A0518;
	// bl 0x83048e80
	sub_83048E80(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a051c
	goto loc_830A051C;
loc_830A04FC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3019
	ctx.r5.s64 = 3019;
	// addi r6,r11,20040
	ctx.r6.s64 = r11.s64 + 20040;
	// addi r4,r29,48
	ctx.r4.s64 = r29.s64 + 48;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a0624
	goto loc_830A0624;
loc_830A0518:
	// li r31,0
	r31.s64 = 0;
loc_830A051C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830a0624
	if (cr6.eq) goto loc_830A0624;
	// li r11,3
	r11.s64 = 3;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,112(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 112);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,112(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 112);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,112(r30)
	PPC_STORE_U32(r30.u32 + 112, r11.u32);
	// bne cr6,0x830a056c
	if (!cr6.eq) goto loc_830A056C;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x830a0558
	if (!cr6.eq) goto loc_830A0558;
	// li r11,4
	r11.s64 = 4;
	// b 0x830a0568
	goto loc_830A0568;
loc_830A0558:
	// cmplw cr6,r27,r24
	cr6.compare<uint32_t>(r27.u32, r24.u32, xer);
	// bne cr6,0x830a056c
	if (!cr6.eq) goto loc_830A056C;
	// li r11,5
	r11.s64 = 5;
	// li r27,0
	r27.s64 = 0;
loc_830A0568:
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
loc_830A056C:
	// stw r27,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r27.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830a05a4
	if (cr6.eq) goto loc_830A05A4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830a0624
	if (cr6.eq) goto loc_830A0624;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0624
	if (cr0.eq) goto loc_830A0624;
loc_830A05A4:
	// stw r24,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r24.u32);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830a05d0
	if (cr6.eq) goto loc_830A05D0;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0624
	if (cr0.eq) goto loc_830A0624;
loc_830A05D0:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830a05f0
	if (cr6.eq) goto loc_830A05F0;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830967a0
	sub_830967A0(ctx, base);
	// stw r3,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0624
	if (cr0.eq) goto loc_830A0624;
loc_830A05F0:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a0618
	if (cr0.eq) goto loc_830A0618;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,20620
	ctx.r6.s64 = r11.s64 + 20620;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a061c
	goto loc_830A061C;
loc_830A0618:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A061C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830a0628
	if (!cr6.eq) goto loc_830A0628;
loc_830A0624:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A0628:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c28
	return;
}

__attribute__((alias("__imp__sub_830A0630"))) PPC_WEAK_FUNC(sub_830A0630);
PPC_FUNC_IMPL(__imp__sub_830A0630) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r29,r30,40
	r29.s64 = r30.s64 + 40;
loc_830A0644:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x83022310
	sub_83022310(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830a0670
	if (!cr0.lt) goto loc_830A0670;
	// li r11,1
	r11.s64 = 1;
	// stw r3,80(r30)
	PPC_STORE_U32(r30.u32 + 80, ctx.r3.u32);
	// stw r11,72(r30)
	PPC_STORE_U32(r30.u32 + 72, r11.u32);
loc_830A0664:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_830A0668:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
loc_830A0670:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,13
	cr6.compare<uint32_t>(r11.u32, 13, xer);
	// bgt cr6,0x830a0644
	if (cr6.gt) goto loc_830A0644;
	// lis r12,-32249
	r12.s64 = -2113470464;
	// addi r12,r12,14848
	r12.s64 = r12.s64 + 14848;
	// rlwinm r0,r11,1,0,30
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31990
	r12.s64 = -2096496640;
	// addi r12,r12,1604
	r12.s64 = r12.s64 + 1604;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_830A06A4;
	case 1:
		goto loc_830A06AC;
	case 2:
		goto loc_830A0850;
	case 3:
		goto loc_830A0858;
	case 4:
		goto loc_830A0860;
	case 5:
		goto loc_830A0868;
	case 6:
		goto loc_830A0870;
	case 7:
		goto loc_830A0878;
	case 8:
		goto loc_830A0880;
	case 9:
		goto loc_830A0888;
	case 10:
		goto loc_830A2CEC;
	case 11:
		goto loc_830A0644;
	case 12:
		goto loc_830A0644;
	case 13:
		goto loc_830A0664;
	default:
		__builtin_unreachable();
	}
loc_830A06A4:
	// li r3,386
	ctx.r3.s64 = 386;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A06AC:
	// lbz r11,49(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 49);
	// extsb. r10,r11
	ctx.r10.s64 = r11.s8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830a06c4
	if (!cr0.eq) goto loc_830A06C4;
	// lbz r11,48(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 48);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A06C4:
	// lbz r11,50(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 50);
	// extsb. r11,r11
	r11.s64 = r11.s8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a080c
	if (!cr0.eq) goto loc_830A080C;
	// lbz r11,48(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 48);
	// cmpwi cr6,r10,61
	cr6.compare<int32_t>(ctx.r10.s32, 61, xer);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// bne cr6,0x830a07a4
	if (!cr6.eq) goto loc_830A07A4;
	// cmpwi cr6,r11,47
	cr6.compare<int32_t>(r11.s32, 47, xer);
	// bgt cr6,0x830a0754
	if (cr6.gt) goto loc_830A0754;
	// beq cr6,0x830a074c
	if (cr6.eq) goto loc_830A074C;
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// beq cr6,0x830a0744
	if (cr6.eq) goto loc_830A0744;
	// cmpwi cr6,r11,37
	cr6.compare<int32_t>(r11.s32, 37, xer);
	// beq cr6,0x830a073c
	if (cr6.eq) goto loc_830A073C;
	// cmpwi cr6,r11,38
	cr6.compare<int32_t>(r11.s32, 38, xer);
	// beq cr6,0x830a0734
	if (cr6.eq) goto loc_830A0734;
	// cmpwi cr6,r11,42
	cr6.compare<int32_t>(r11.s32, 42, xer);
	// beq cr6,0x830a072c
	if (cr6.eq) goto loc_830A072C;
	// cmpwi cr6,r11,43
	cr6.compare<int32_t>(r11.s32, 43, xer);
	// beq cr6,0x830a0724
	if (cr6.eq) goto loc_830A0724;
	// cmpwi cr6,r11,45
	cr6.compare<int32_t>(r11.s32, 45, xer);
	// bne cr6,0x830a06a4
	if (!cr6.eq) goto loc_830A06A4;
	// li r3,368
	ctx.r3.s64 = 368;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0724:
	// li r3,367
	ctx.r3.s64 = 367;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A072C:
	// li r3,364
	ctx.r3.s64 = 364;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0734:
	// li r3,373
	ctx.r3.s64 = 373;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A073C:
	// li r3,366
	ctx.r3.s64 = 366;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0744:
	// li r3,361
	ctx.r3.s64 = 361;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A074C:
	// li r3,365
	ctx.r3.s64 = 365;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0754:
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// beq cr6,0x830a079c
	if (cr6.eq) goto loc_830A079C;
	// cmpwi cr6,r11,61
	cr6.compare<int32_t>(r11.s32, 61, xer);
	// beq cr6,0x830a0794
	if (cr6.eq) goto loc_830A0794;
	// cmpwi cr6,r11,62
	cr6.compare<int32_t>(r11.s32, 62, xer);
	// beq cr6,0x830a078c
	if (cr6.eq) goto loc_830A078C;
	// cmpwi cr6,r11,94
	cr6.compare<int32_t>(r11.s32, 94, xer);
	// beq cr6,0x830a0784
	if (cr6.eq) goto loc_830A0784;
	// cmpwi cr6,r11,124
	cr6.compare<int32_t>(r11.s32, 124, xer);
	// bne cr6,0x830a06a4
	if (!cr6.eq) goto loc_830A06A4;
	// li r3,374
	ctx.r3.s64 = 374;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0784:
	// li r3,375
	ctx.r3.s64 = 375;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A078C:
	// li r3,359
	ctx.r3.s64 = 359;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0794:
	// li r3,360
	ctx.r3.s64 = 360;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A079C:
	// li r3,358
	ctx.r3.s64 = 358;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A07A4:
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x830a06a4
	if (!cr6.eq) goto loc_830A06A4;
	// cmpwi cr6,r11,38
	cr6.compare<int32_t>(r11.s32, 38, xer);
	// beq cr6,0x830a0804
	if (cr6.eq) goto loc_830A0804;
	// cmpwi cr6,r11,43
	cr6.compare<int32_t>(r11.s32, 43, xer);
	// beq cr6,0x830a07fc
	if (cr6.eq) goto loc_830A07FC;
	// cmpwi cr6,r11,45
	cr6.compare<int32_t>(r11.s32, 45, xer);
	// beq cr6,0x830a07f4
	if (cr6.eq) goto loc_830A07F4;
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// beq cr6,0x830a07ec
	if (cr6.eq) goto loc_830A07EC;
	// cmpwi cr6,r11,62
	cr6.compare<int32_t>(r11.s32, 62, xer);
	// beq cr6,0x830a07e4
	if (cr6.eq) goto loc_830A07E4;
	// cmpwi cr6,r11,124
	cr6.compare<int32_t>(r11.s32, 124, xer);
	// bne cr6,0x830a06a4
	if (!cr6.eq) goto loc_830A06A4;
	// li r3,363
	ctx.r3.s64 = 363;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A07E4:
	// li r3,370
	ctx.r3.s64 = 370;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A07EC:
	// li r3,369
	ctx.r3.s64 = 369;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A07F4:
	// li r3,357
	ctx.r3.s64 = 357;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A07FC:
	// li r3,356
	ctx.r3.s64 = 356;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0804:
	// li r3,362
	ctx.r3.s64 = 362;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A080C:
	// lbz r9,51(r30)
	ctx.r9.u64 = PPC_LOAD_U8(r30.u32 + 51);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x830a06a4
	if (!cr6.eq) goto loc_830A06A4;
	// cmpwi cr6,r11,61
	cr6.compare<int32_t>(r11.s32, 61, xer);
	// bne cr6,0x830a06a4
	if (!cr6.eq) goto loc_830A06A4;
	// lbz r11,48(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 48);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x830a06a4
	if (!cr6.eq) goto loc_830A06A4;
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// beq cr6,0x830a0848
	if (cr6.eq) goto loc_830A0848;
	// cmpwi cr6,r11,62
	cr6.compare<int32_t>(r11.s32, 62, xer);
	// bne cr6,0x830a06a4
	if (!cr6.eq) goto loc_830A06A4;
	// li r3,372
	ctx.r3.s64 = 372;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0848:
	// li r3,371
	ctx.r3.s64 = 371;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0850:
	// li r3,376
	ctx.r3.s64 = 376;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0858:
	// li r3,377
	ctx.r3.s64 = 377;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0860:
	// li r3,378
	ctx.r3.s64 = 378;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0868:
	// li r3,379
	ctx.r3.s64 = 379;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0870:
	// li r3,380
	ctx.r3.s64 = 380;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0878:
	// li r3,381
	ctx.r3.s64 = 381;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0880:
	// li r3,382
	ctx.r3.s64 = 382;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0888:
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r28,r11,18620
	r28.s64 = r11.s64 + 18620;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r31,r10,18644
	r31.s64 = ctx.r10.s64 + 18644;
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r27,r9,21424
	r27.s64 = ctx.r9.s64 + 21424;
	// extsb r11,r11
	r11.s64 = r11.s8;
	// addi r11,r11,-66
	r11.s64 = r11.s64 + -66;
	// cmplwi cr6,r11,53
	cr6.compare<uint32_t>(r11.u32, 53, xer);
	// bgt cr6,0x830a0f00
	if (cr6.gt) goto loc_830A0F00;
	// lis r12,-32249
	r12.s64 = -2113470464;
	// addi r12,r12,14736
	r12.s64 = r12.s64 + 14736;
	// rlwinm r0,r11,1,0,30
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31990
	r12.s64 = -2096496640;
	// addi r12,r12,2272
	r12.s64 = r12.s64 + 2272;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_830A09F0;
	case 1:
		goto loc_830A0D50;
	case 2:
		goto loc_830A0F5C;
	case 3:
		goto loc_830A0F00;
	case 4:
		goto loc_830A0F00;
	case 5:
		goto loc_830A1234;
	case 6:
		goto loc_830A0F00;
	case 7:
		goto loc_830A0F00;
	case 8:
		goto loc_830A0F00;
	case 9:
		goto loc_830A0F00;
	case 10:
		goto loc_830A1504;
	case 11:
		goto loc_830A0F00;
	case 12:
		goto loc_830A16B0;
	case 13:
		goto loc_830A0F00;
	case 14:
		goto loc_830A1988;
	case 15:
		goto loc_830A0F00;
	case 16:
		goto loc_830A1B14;
	case 17:
		goto loc_830A2040;
	case 18:
		goto loc_830A2644;
	case 19:
		goto loc_830A0F00;
	case 20:
		goto loc_830A2B78;
	case 21:
		goto loc_830A0F00;
	case 22:
		goto loc_830A0F00;
	case 23:
		goto loc_830A0F00;
	case 24:
		goto loc_830A0F00;
	case 25:
		goto loc_830A0F00;
	case 26:
		goto loc_830A0F00;
	case 27:
		goto loc_830A0F00;
	case 28:
		goto loc_830A0F00;
	case 29:
		goto loc_830A0F00;
	case 30:
		goto loc_830A0F00;
	case 31:
		goto loc_830A08E0;
	case 32:
		goto loc_830A0970;
	case 33:
		goto loc_830A0A70;
	case 34:
		goto loc_830A0D90;
	case 35:
		goto loc_830A0FDC;
	case 36:
		goto loc_830A10CC;
	case 37:
		goto loc_830A1200;
	case 38:
		goto loc_830A1280;
	case 39:
		goto loc_830A12C0;
	case 40:
		goto loc_830A0F00;
	case 41:
		goto loc_830A0F00;
	case 42:
		goto loc_830A1400;
	case 43:
		goto loc_830A1544;
	case 44:
		goto loc_830A15B8;
	case 45:
		goto loc_830A16F0;
	case 46:
		goto loc_830A1764;
	case 47:
		goto loc_830A0F00;
	case 48:
		goto loc_830A1A1C;
	case 49:
		goto loc_830A1B94;
	case 50:
		goto loc_830A20F0;
	case 51:
		goto loc_830A2870;
	case 52:
		goto loc_830A29DC;
	case 53:
		goto loc_830A2BCC;
	default:
		__builtin_unreachable();
	}
loc_830A08E0:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21416
	ctx.r10.s64 = ctx.r10.s64 + 21416;
loc_830A08EC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0910
	if (cr0.eq) goto loc_830A0910;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a08ec
	if (cr6.eq) goto loc_830A08EC;
loc_830A0910:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21400
	ctx.r10.s64 = ctx.r10.s64 + 21400;
loc_830A0924:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0948
	if (cr0.eq) goto loc_830A0948;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0924
	if (cr6.eq) goto loc_830A0924;
loc_830A0948:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0958
	if (!cr0.eq) goto loc_830A0958;
	// li r3,258
	ctx.r3.s64 = 258;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0958:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
loc_830A0968:
	// li r3,257
	ctx.r3.s64 = 257;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0970:
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-11508
	ctx.r10.s64 = ctx.r10.s64 + -11508;
loc_830A097C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a09a0
	if (cr0.eq) goto loc_830A09A0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a097c
	if (cr6.eq) goto loc_830A097C;
loc_830A09A0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a09b0
	if (!cr0.eq) goto loc_830A09B0;
	// li r3,260
	ctx.r3.s64 = 260;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A09B0:
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,12820
	ctx.r10.s64 = ctx.r10.s64 + 12820;
loc_830A09BC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a09e0
	if (cr0.eq) goto loc_830A09E0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a09bc
	if (cr6.eq) goto loc_830A09BC;
loc_830A09E0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,261
	ctx.r3.s64 = 261;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A09F0:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21388
	ctx.r10.s64 = ctx.r10.s64 + 21388;
loc_830A09FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0a20
	if (cr0.eq) goto loc_830A0A20;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a09fc
	if (cr6.eq) goto loc_830A09FC;
loc_830A0A20:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0a30
	if (!cr0.eq) goto loc_830A0A30;
	// li r3,259
	ctx.r3.s64 = 259;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0A30:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17696
	ctx.r10.s64 = ctx.r10.s64 + 17696;
loc_830A0A3C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0a60
	if (cr0.eq) goto loc_830A0A60;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0a3c
	if (cr6.eq) goto loc_830A0A3C;
loc_830A0A60:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,262
	ctx.r3.s64 = 262;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0A70:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21380
	ctx.r10.s64 = ctx.r10.s64 + 21380;
loc_830A0A7C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0aa0
	if (cr0.eq) goto loc_830A0AA0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0a7c
	if (cr6.eq) goto loc_830A0A7C;
loc_830A0AA0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0ab0
	if (!cr0.eq) goto loc_830A0AB0;
	// li r3,263
	ctx.r3.s64 = 263;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0AB0:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21372
	ctx.r10.s64 = ctx.r10.s64 + 21372;
loc_830A0ABC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0ae0
	if (cr0.eq) goto loc_830A0AE0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0abc
	if (cr6.eq) goto loc_830A0ABC;
loc_830A0AE0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,18664
	ctx.r10.s64 = ctx.r10.s64 + 18664;
loc_830A0AF4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0b18
	if (cr0.eq) goto loc_830A0B18;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0af4
	if (cr6.eq) goto loc_830A0AF4;
loc_830A0B18:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0b28
	if (!cr0.eq) goto loc_830A0B28;
	// li r3,264
	ctx.r3.s64 = 264;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0B28:
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,9516
	ctx.r10.s64 = ctx.r10.s64 + 9516;
loc_830A0B34:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0b58
	if (cr0.eq) goto loc_830A0B58;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0b34
	if (cr6.eq) goto loc_830A0B34;
loc_830A0B58:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,18320
	ctx.r10.s64 = ctx.r10.s64 + 18320;
loc_830A0B6C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0b90
	if (cr0.eq) goto loc_830A0B90;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0b6c
	if (cr6.eq) goto loc_830A0B6C;
loc_830A0B90:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,16528
	ctx.r10.s64 = ctx.r10.s64 + 16528;
loc_830A0BA4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0bc8
	if (cr0.eq) goto loc_830A0BC8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0ba4
	if (cr6.eq) goto loc_830A0BA4;
loc_830A0BC8:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0bd8
	if (!cr0.eq) goto loc_830A0BD8;
	// li r3,265
	ctx.r3.s64 = 265;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0BD8:
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,1240
	ctx.r10.s64 = ctx.r10.s64 + 1240;
loc_830A0BE4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0c08
	if (cr0.eq) goto loc_830A0C08;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0be4
	if (cr6.eq) goto loc_830A0BE4;
loc_830A0C08:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0c18
	if (!cr0.eq) goto loc_830A0C18;
	// li r3,266
	ctx.r3.s64 = 266;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0C18:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21364
	ctx.r10.s64 = ctx.r10.s64 + 21364;
loc_830A0C24:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0c48
	if (cr0.eq) goto loc_830A0C48;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0c24
	if (cr6.eq) goto loc_830A0C24;
loc_830A0C48:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0c58
	if (!cr0.eq) goto loc_830A0C58;
	// li r3,267
	ctx.r3.s64 = 267;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0C58:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21344
	ctx.r10.s64 = ctx.r10.s64 + 21344;
loc_830A0C64:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0c88
	if (cr0.eq) goto loc_830A0C88;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0c64
	if (cr6.eq) goto loc_830A0C64;
loc_830A0C88:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0c98
	if (!cr0.eq) goto loc_830A0C98;
	// li r3,269
	ctx.r3.s64 = 269;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0C98:
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,10828
	ctx.r10.s64 = ctx.r10.s64 + 10828;
loc_830A0CA4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0cc8
	if (cr0.eq) goto loc_830A0CC8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0ca4
	if (cr6.eq) goto loc_830A0CA4;
loc_830A0CC8:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0cd8
	if (!cr0.eq) goto loc_830A0CD8;
	// li r3,270
	ctx.r3.s64 = 270;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0CD8:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21332
	ctx.r10.s64 = ctx.r10.s64 + 21332;
loc_830A0CE4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0d08
	if (cr0.eq) goto loc_830A0D08;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0ce4
	if (cr6.eq) goto loc_830A0CE4;
loc_830A0D08:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-27568
	ctx.r10.s64 = ctx.r10.s64 + -27568;
loc_830A0D1C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0d40
	if (cr0.eq) goto loc_830A0D40;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0d1c
	if (cr6.eq) goto loc_830A0D1C;
loc_830A0D40:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,272
	ctx.r3.s64 = 272;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0D50:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21316
	ctx.r10.s64 = ctx.r10.s64 + 21316;
loc_830A0D5C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0d80
	if (cr0.eq) goto loc_830A0D80;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0d5c
	if (cr6.eq) goto loc_830A0D5C;
loc_830A0D80:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,268
	ctx.r3.s64 = 268;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0D90:
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-22156
	ctx.r10.s64 = ctx.r10.s64 + -22156;
loc_830A0D9C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0dc0
	if (cr0.eq) goto loc_830A0DC0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0d9c
	if (cr6.eq) goto loc_830A0D9C;
loc_830A0DC0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0dd0
	if (!cr0.eq) goto loc_830A0DD0;
	// li r3,274
	ctx.r3.s64 = 274;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0DD0:
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-4448
	ctx.r10.s64 = ctx.r10.s64 + -4448;
loc_830A0DDC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0e00
	if (cr0.eq) goto loc_830A0E00;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0ddc
	if (cr6.eq) goto loc_830A0DDC;
loc_830A0E00:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21308
	ctx.r10.s64 = ctx.r10.s64 + 21308;
loc_830A0E14:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0e38
	if (cr0.eq) goto loc_830A0E38;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0e14
	if (cr6.eq) goto loc_830A0E14;
loc_830A0E38:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0e48
	if (!cr0.eq) goto loc_830A0E48;
	// li r3,277
	ctx.r3.s64 = 277;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0E48:
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,12816
	ctx.r10.s64 = ctx.r10.s64 + 12816;
loc_830A0E54:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0e78
	if (cr0.eq) goto loc_830A0E78;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0e54
	if (cr6.eq) goto loc_830A0E54;
loc_830A0E78:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0e88
	if (!cr0.eq) goto loc_830A0E88;
	// li r3,279
	ctx.r3.s64 = 279;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0E88:
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,10836
	ctx.r10.s64 = ctx.r10.s64 + 10836;
loc_830A0E94:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0eb8
	if (cr0.eq) goto loc_830A0EB8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0e94
	if (cr6.eq) goto loc_830A0E94;
loc_830A0EB8:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0ec8
	if (!cr0.eq) goto loc_830A0EC8;
	// li r3,278
	ctx.r3.s64 = 278;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0EC8:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21292
	ctx.r10.s64 = ctx.r10.s64 + 21292;
loc_830A0ED4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0ef8
	if (cr0.eq) goto loc_830A0EF8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0ed4
	if (cr6.eq) goto loc_830A0ED4;
loc_830A0EF8:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
loc_830A0F00:
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lbz r11,0(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x821ee9e8
	sub_821EE9E8(ctx, base);
	// cmpwi cr6,r3,97
	cr6.compare<int32_t>(ctx.r3.s32, 97, xer);
	// beq cr6,0x830a2c70
	if (cr6.eq) goto loc_830A2C70;
	// cmpwi cr6,r3,100
	cr6.compare<int32_t>(ctx.r3.s32, 100, xer);
	// beq cr6,0x830a2c38
	if (cr6.eq) goto loc_830A2C38;
	// cmpwi cr6,r3,112
	cr6.compare<int32_t>(ctx.r3.s32, 112, xer);
	// beq cr6,0x830a2c0c
	if (cr6.eq) goto loc_830A2C0C;
	// cmpwi cr6,r3,116
	cr6.compare<int32_t>(ctx.r3.s32, 116, xer);
	// bne cr6,0x830a2ca8
	if (!cr6.eq) goto loc_830A2CA8;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a2ca8
	if (!cr0.eq) goto loc_830A2CA8;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a237c
	if (cr0.eq) goto loc_830A237C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,21228
	ctx.r6.s64 = r11.s64 + 21228;
	// b 0x830a2c98
	goto loc_830A2C98;
loc_830A0F5C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21208
	ctx.r10.s64 = ctx.r10.s64 + 21208;
loc_830A0F68:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0f8c
	if (cr0.eq) goto loc_830A0F8C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0f68
	if (cr6.eq) goto loc_830A0F68;
loc_830A0F8C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f9c
	if (!cr0.eq) goto loc_830A0F9C;
	// li r3,275
	ctx.r3.s64 = 275;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0F9C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21188
	ctx.r10.s64 = ctx.r10.s64 + 21188;
loc_830A0FA8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0fcc
	if (cr0.eq) goto loc_830A0FCC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0fa8
	if (cr6.eq) goto loc_830A0FA8;
loc_830A0FCC:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,276
	ctx.r3.s64 = 276;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A0FDC:
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,12808
	ctx.r10.s64 = ctx.r10.s64 + 12808;
loc_830A0FE8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a100c
	if (cr0.eq) goto loc_830A100C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a0fe8
	if (cr6.eq) goto loc_830A0FE8;
loc_830A100C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a101c
	if (!cr0.eq) goto loc_830A101C;
	// li r3,280
	ctx.r3.s64 = 280;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A101C:
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,18312
	ctx.r10.s64 = ctx.r10.s64 + 18312;
loc_830A1028:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a104c
	if (cr0.eq) goto loc_830A104C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1028
	if (cr6.eq) goto loc_830A1028;
loc_830A104C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21176
	ctx.r10.s64 = ctx.r10.s64 + 21176;
loc_830A1060:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1084
	if (cr0.eq) goto loc_830A1084;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1060
	if (cr6.eq) goto loc_830A1060;
loc_830A1084:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21168
	ctx.r10.s64 = ctx.r10.s64 + 21168;
loc_830A1098:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a10bc
	if (cr0.eq) goto loc_830A10BC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1098
	if (cr6.eq) goto loc_830A1098;
loc_830A10BC:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,281
	ctx.r3.s64 = 281;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A10CC:
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,5664
	ctx.r10.s64 = ctx.r10.s64 + 5664;
loc_830A10D8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a10fc
	if (cr0.eq) goto loc_830A10FC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a10d8
	if (cr6.eq) goto loc_830A10D8;
loc_830A10FC:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a110c
	if (!cr0.eq) goto loc_830A110C;
	// li r3,282
	ctx.r3.s64 = 282;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A110C:
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-11548
	ctx.r10.s64 = ctx.r10.s64 + -11548;
loc_830A1118:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a113c
	if (cr0.eq) goto loc_830A113C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1118
	if (cr6.eq) goto loc_830A1118;
loc_830A113C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a114c
	if (!cr0.eq) goto loc_830A114C;
	// li r3,283
	ctx.r3.s64 = 283;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A114C:
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,12792
	ctx.r10.s64 = ctx.r10.s64 + 12792;
loc_830A1158:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a117c
	if (cr0.eq) goto loc_830A117C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1158
	if (cr6.eq) goto loc_830A1158;
loc_830A117C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a118c
	if (!cr0.eq) goto loc_830A118C;
	// li r3,284
	ctx.r3.s64 = 284;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A118C:
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,9492
	ctx.r10.s64 = ctx.r10.s64 + 9492;
loc_830A1198:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a11bc
	if (cr0.eq) goto loc_830A11BC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1198
	if (cr6.eq) goto loc_830A1198;
loc_830A11BC:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a11cc
	if (!cr0.eq) goto loc_830A11CC;
	// li r3,285
	ctx.r3.s64 = 285;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A11CC:
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,12900
	ctx.r10.s64 = ctx.r10.s64 + 12900;
loc_830A11D8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0ef8
	if (cr0.eq) goto loc_830A0EF8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a11d8
	if (cr6.eq) goto loc_830A11D8;
	// b 0x830a0ef8
	goto loc_830A0EF8;
loc_830A1200:
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-4008
	ctx.r10.s64 = ctx.r10.s64 + -4008;
loc_830A120C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0ef8
	if (cr0.eq) goto loc_830A0EF8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a120c
	if (cr6.eq) goto loc_830A120C;
	// b 0x830a0ef8
	goto loc_830A0EF8;
loc_830A1234:
	// lwz r11,84(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a0f00
	if (cr6.eq) goto loc_830A0F00;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21152
	ctx.r10.s64 = ctx.r10.s64 + 21152;
loc_830A124C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1270
	if (cr0.eq) goto loc_830A1270;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a124c
	if (cr6.eq) goto loc_830A124C;
loc_830A1270:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,286
	ctx.r3.s64 = 286;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1280:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17896
	ctx.r10.s64 = ctx.r10.s64 + 17896;
loc_830A128C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a12b0
	if (cr0.eq) goto loc_830A12B0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a128c
	if (cr6.eq) goto loc_830A128C;
loc_830A12B0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,287
	ctx.r3.s64 = 287;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A12C0:
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,12788
	ctx.r10.s64 = ctx.r10.s64 + 12788;
loc_830A12CC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a12f0
	if (cr0.eq) goto loc_830A12F0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a12cc
	if (cr6.eq) goto loc_830A12CC;
loc_830A12F0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1300
	if (!cr0.eq) goto loc_830A1300;
	// li r3,288
	ctx.r3.s64 = 288;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1300:
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,12784
	ctx.r10.s64 = ctx.r10.s64 + 12784;
loc_830A130C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1330
	if (cr0.eq) goto loc_830A1330;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a130c
	if (cr6.eq) goto loc_830A130C;
loc_830A1330:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1340
	if (!cr0.eq) goto loc_830A1340;
	// li r3,289
	ctx.r3.s64 = 289;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1340:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21144
	ctx.r10.s64 = ctx.r10.s64 + 21144;
loc_830A134C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1370
	if (cr0.eq) goto loc_830A1370;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a134c
	if (cr6.eq) goto loc_830A134C;
loc_830A1370:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1380
	if (!cr0.eq) goto loc_830A1380;
	// li r3,290
	ctx.r3.s64 = 290;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1380:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21136
	ctx.r10.s64 = ctx.r10.s64 + 21136;
loc_830A138C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a13b0
	if (cr0.eq) goto loc_830A13B0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a138c
	if (cr6.eq) goto loc_830A138C;
loc_830A13B0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a13c0
	if (!cr0.eq) goto loc_830A13C0;
	// li r3,291
	ctx.r3.s64 = 291;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A13C0:
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-5360
	ctx.r10.s64 = ctx.r10.s64 + -5360;
loc_830A13CC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a13f0
	if (cr0.eq) goto loc_830A13F0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a13cc
	if (cr6.eq) goto loc_830A13CC;
loc_830A13F0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,292
	ctx.r3.s64 = 292;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1400:
	// lis r10,-32243
	ctx.r10.s64 = -2113077248;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,12908
	ctx.r10.s64 = ctx.r10.s64 + 12908;
loc_830A140C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1430
	if (cr0.eq) goto loc_830A1430;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a140c
	if (cr6.eq) goto loc_830A140C;
loc_830A1430:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1440
	if (!cr0.eq) goto loc_830A1440;
	// li r3,293
	ctx.r3.s64 = 293;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1440:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21128
	ctx.r10.s64 = ctx.r10.s64 + 21128;
loc_830A144C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1470
	if (cr0.eq) goto loc_830A1470;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a144c
	if (cr6.eq) goto loc_830A144C;
loc_830A1470:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1480
	if (!cr0.eq) goto loc_830A1480;
	// li r3,294
	ctx.r3.s64 = 294;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1480:
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-11528
	ctx.r10.s64 = ctx.r10.s64 + -11528;
loc_830A148C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a14b0
	if (cr0.eq) goto loc_830A14B0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a148c
	if (cr6.eq) goto loc_830A148C;
loc_830A14B0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lwz r11,84(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a0f00
	if (cr6.eq) goto loc_830A0F00;
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-10252
	ctx.r10.s64 = ctx.r10.s64 + -10252;
loc_830A14D0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a14f4
	if (cr0.eq) goto loc_830A14F4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a14d0
	if (cr6.eq) goto loc_830A14D0;
loc_830A14F4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,295
	ctx.r3.s64 = 295;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1504:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17580
	ctx.r10.s64 = ctx.r10.s64 + 17580;
loc_830A1510:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1534
	if (cr0.eq) goto loc_830A1534;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1510
	if (cr6.eq) goto loc_830A1510;
loc_830A1534:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,296
	ctx.r3.s64 = 296;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1544:
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,23944
	ctx.r10.s64 = ctx.r10.s64 + 23944;
loc_830A1550:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1574
	if (cr0.eq) goto loc_830A1574;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1550
	if (cr6.eq) goto loc_830A1550;
loc_830A1574:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1584
	if (!cr0.eq) goto loc_830A1584;
	// li r3,297
	ctx.r3.s64 = 297;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1584:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21120
	ctx.r10.s64 = ctx.r10.s64 + 21120;
loc_830A1590:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0ef8
	if (cr0.eq) goto loc_830A0EF8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1590
	if (cr6.eq) goto loc_830A1590;
	// b 0x830a0ef8
	goto loc_830A0EF8;
loc_830A15B8:
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,32732
	ctx.r10.s64 = ctx.r10.s64 + 32732;
loc_830A15C4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a15e8
	if (cr0.eq) goto loc_830A15E8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a15c4
	if (cr6.eq) goto loc_830A15C4;
loc_830A15E8:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a15f8
	if (!cr0.eq) goto loc_830A15F8;
	// li r3,271
	ctx.r3.s64 = 271;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A15F8:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,18652
	ctx.r10.s64 = ctx.r10.s64 + 18652;
loc_830A1604:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1628
	if (cr0.eq) goto loc_830A1628;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1604
	if (cr6.eq) goto loc_830A1604;
loc_830A1628:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1638
	if (!cr0.eq) goto loc_830A1638;
	// li r3,298
	ctx.r3.s64 = 298;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1638:
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-10096
	ctx.r10.s64 = ctx.r10.s64 + -10096;
loc_830A1644:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1668
	if (cr0.eq) goto loc_830A1668;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1644
	if (cr6.eq) goto loc_830A1644;
loc_830A1668:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21104
	ctx.r10.s64 = ctx.r10.s64 + 21104;
loc_830A167C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a16a0
	if (cr0.eq) goto loc_830A16A0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a167c
	if (cr6.eq) goto loc_830A167C;
loc_830A16A0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,299
	ctx.r3.s64 = 299;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A16B0:
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,30216
	ctx.r10.s64 = ctx.r10.s64 + 30216;
loc_830A16BC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a16e0
	if (cr0.eq) goto loc_830A16E0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a16bc
	if (cr6.eq) goto loc_830A16BC;
loc_830A16E0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,300
	ctx.r3.s64 = 300;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A16F0:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21100
	ctx.r10.s64 = ctx.r10.s64 + 21100;
loc_830A16FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1720
	if (cr0.eq) goto loc_830A1720;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a16fc
	if (cr6.eq) goto loc_830A16FC;
loc_830A1720:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1730
	if (!cr0.eq) goto loc_830A1730;
	// li r3,301
	ctx.r3.s64 = 301;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1730:
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,10168
	ctx.r10.s64 = ctx.r10.s64 + 10168;
loc_830A173C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0ef8
	if (cr0.eq) goto loc_830A0EF8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a173c
	if (cr6.eq) goto loc_830A173C;
	// b 0x830a0ef8
	goto loc_830A0EF8;
loc_830A1764:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21088
	ctx.r10.s64 = ctx.r10.s64 + 21088;
loc_830A1770:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1794
	if (cr0.eq) goto loc_830A1794;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1770
	if (cr6.eq) goto loc_830A1770;
loc_830A1794:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a17a4
	if (!cr0.eq) goto loc_830A17A4;
	// li r3,302
	ctx.r3.s64 = 302;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A17A4:
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_830A17AC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a17d0
	if (cr0.eq) goto loc_830A17D0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a17ac
	if (cr6.eq) goto loc_830A17AC;
loc_830A17D0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a17e0
	if (!cr0.eq) goto loc_830A17E0;
loc_830A17D8:
	// li r3,303
	ctx.r3.s64 = 303;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A17E0:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17616
	ctx.r10.s64 = ctx.r10.s64 + 17616;
loc_830A17EC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1810
	if (cr0.eq) goto loc_830A1810;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a17ec
	if (cr6.eq) goto loc_830A17EC;
loc_830A1810:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1820
	if (!cr0.eq) goto loc_830A1820;
	// li r3,304
	ctx.r3.s64 = 304;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1820:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21080
	ctx.r10.s64 = ctx.r10.s64 + 21080;
loc_830A182C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1850
	if (cr0.eq) goto loc_830A1850;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a182c
	if (cr6.eq) goto loc_830A182C;
loc_830A1850:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21068
	ctx.r10.s64 = ctx.r10.s64 + 21068;
loc_830A1864:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1888
	if (cr0.eq) goto loc_830A1888;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1864
	if (cr6.eq) goto loc_830A1864;
loc_830A1888:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,21060
	ctx.r10.s64 = ctx.r10.s64 + 21060;
loc_830A189C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a18c0
	if (cr0.eq) goto loc_830A18C0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a189c
	if (cr6.eq) goto loc_830A189C;
loc_830A18C0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lwz r11,84(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a0f00
	if (cr6.eq) goto loc_830A0F00;
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-1784
	ctx.r10.s64 = ctx.r10.s64 + -1784;
loc_830A18E0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1904
	if (cr0.eq) goto loc_830A1904;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a18e0
	if (cr6.eq) goto loc_830A18E0;
loc_830A1904:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1920
	if (!cr0.eq) goto loc_830A1920;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a1920
	if (!cr0.eq) goto loc_830A1920;
	// li r3,306
	ctx.r3.s64 = 306;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1920:
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,22700
	ctx.r10.s64 = ctx.r10.s64 + 22700;
loc_830A192C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1950
	if (cr0.eq) goto loc_830A1950;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a192c
	if (cr6.eq) goto loc_830A192C;
loc_830A1950:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a196c
	if (!cr0.eq) goto loc_830A196C;
loc_830A1964:
	// li r3,305
	ctx.r3.s64 = 305;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A196C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,20992
	ctx.r6.s64 = r11.s64 + 20992;
loc_830A1974:
	// li r5,3086
	ctx.r5.s64 = 3086;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a0f00
	goto loc_830A0F00;
loc_830A1988:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17592
	ctx.r10.s64 = ctx.r10.s64 + 17592;
loc_830A1994:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a19b8
	if (cr0.eq) goto loc_830A19B8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1994
	if (cr6.eq) goto loc_830A1994;
loc_830A19B8:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a19c8
	if (!cr0.eq) goto loc_830A19C8;
	// li r3,307
	ctx.r3.s64 = 307;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A19C8:
	// lwz r11,84(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a0f00
	if (cr6.eq) goto loc_830A0F00;
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-22448
	ctx.r10.s64 = ctx.r10.s64 + -22448;
loc_830A19E0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1a04
	if (cr0.eq) goto loc_830A1A04;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a19e0
	if (cr6.eq) goto loc_830A19E0;
loc_830A1A04:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// b 0x830a1964
	goto loc_830A1964;
loc_830A1A1C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20976
	ctx.r10.s64 = ctx.r10.s64 + 20976;
loc_830A1A28:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1a4c
	if (cr0.eq) goto loc_830A1A4C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1a28
	if (cr6.eq) goto loc_830A1A28;
loc_830A1A4C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1a5c
	if (!cr0.eq) goto loc_830A1A5C;
	// li r3,309
	ctx.r3.s64 = 309;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1A5C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20956
	ctx.r10.s64 = ctx.r10.s64 + 20956;
loc_830A1A68:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1a8c
	if (cr0.eq) goto loc_830A1A8C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1a68
	if (cr6.eq) goto loc_830A1A68;
loc_830A1A8C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,1256
	ctx.r10.s64 = ctx.r10.s64 + 1256;
loc_830A1AA0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1ac4
	if (cr0.eq) goto loc_830A1AC4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1aa0
	if (cr6.eq) goto loc_830A1AA0;
loc_830A1AC4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1ad4
	if (!cr0.eq) goto loc_830A1AD4;
	// li r3,312
	ctx.r3.s64 = 312;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1AD4:
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,11108
	ctx.r10.s64 = ctx.r10.s64 + 11108;
loc_830A1AE0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1b04
	if (cr0.eq) goto loc_830A1B04;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1ae0
	if (cr6.eq) goto loc_830A1AE0;
loc_830A1B04:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,311
	ctx.r3.s64 = 311;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1B14:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20940
	ctx.r10.s64 = ctx.r10.s64 + 20940;
loc_830A1B20:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1b44
	if (cr0.eq) goto loc_830A1B44;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1b20
	if (cr6.eq) goto loc_830A1B20;
loc_830A1B44:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1b54
	if (!cr0.eq) goto loc_830A1B54;
	// li r3,308
	ctx.r3.s64 = 308;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1B54:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20920
	ctx.r10.s64 = ctx.r10.s64 + 20920;
loc_830A1B60:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1b84
	if (cr0.eq) goto loc_830A1B84;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1b60
	if (cr6.eq) goto loc_830A1B60;
loc_830A1B84:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,310
	ctx.r3.s64 = 310;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1B94:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17684
	ctx.r10.s64 = ctx.r10.s64 + 17684;
loc_830A1BA0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1bc4
	if (cr0.eq) goto loc_830A1BC4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1ba0
	if (cr6.eq) goto loc_830A1BA0;
loc_830A1BC4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1bd4
	if (!cr0.eq) goto loc_830A1BD4;
	// li r3,315
	ctx.r3.s64 = 315;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1BD4:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17672
	ctx.r10.s64 = ctx.r10.s64 + 17672;
loc_830A1BE0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1c04
	if (cr0.eq) goto loc_830A1C04;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1be0
	if (cr6.eq) goto loc_830A1BE0;
loc_830A1C04:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1c14
	if (!cr0.eq) goto loc_830A1C14;
	// li r3,316
	ctx.r3.s64 = 316;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1C14:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17660
	ctx.r10.s64 = ctx.r10.s64 + 17660;
loc_830A1C20:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1c44
	if (cr0.eq) goto loc_830A1C44;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1c20
	if (cr6.eq) goto loc_830A1C20;
loc_830A1C44:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1c54
	if (!cr0.eq) goto loc_830A1C54;
	// li r3,317
	ctx.r3.s64 = 317;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1C54:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17648
	ctx.r10.s64 = ctx.r10.s64 + 17648;
loc_830A1C60:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1c84
	if (cr0.eq) goto loc_830A1C84;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1c60
	if (cr6.eq) goto loc_830A1C60;
loc_830A1C84:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1c94
	if (!cr0.eq) goto loc_830A1C94;
	// li r3,318
	ctx.r3.s64 = 318;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1C94:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20904
	ctx.r10.s64 = ctx.r10.s64 + 20904;
loc_830A1CA0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1cc4
	if (cr0.eq) goto loc_830A1CC4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1ca0
	if (cr6.eq) goto loc_830A1CA0;
loc_830A1CC4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1cd4
	if (!cr0.eq) goto loc_830A1CD4;
	// li r3,319
	ctx.r3.s64 = 319;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1CD4:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20896
	ctx.r10.s64 = ctx.r10.s64 + 20896;
loc_830A1CE0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1d04
	if (cr0.eq) goto loc_830A1D04;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1ce0
	if (cr6.eq) goto loc_830A1CE0;
loc_830A1D04:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1d14
	if (!cr0.eq) goto loc_830A1D14;
	// li r3,320
	ctx.r3.s64 = 320;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1D14:
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,10844
	ctx.r10.s64 = ctx.r10.s64 + 10844;
loc_830A1D20:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1d44
	if (cr0.eq) goto loc_830A1D44;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1d20
	if (cr6.eq) goto loc_830A1D20;
loc_830A1D44:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20888
	ctx.r10.s64 = ctx.r10.s64 + 20888;
loc_830A1D58:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1d7c
	if (cr0.eq) goto loc_830A1D7C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1d58
	if (cr6.eq) goto loc_830A1D58;
loc_830A1D7C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20880
	ctx.r10.s64 = ctx.r10.s64 + 20880;
loc_830A1D90:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1db4
	if (cr0.eq) goto loc_830A1DB4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1d90
	if (cr6.eq) goto loc_830A1D90;
loc_830A1DB4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20872
	ctx.r10.s64 = ctx.r10.s64 + 20872;
loc_830A1DC8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1dec
	if (cr0.eq) goto loc_830A1DEC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1dc8
	if (cr6.eq) goto loc_830A1DC8;
loc_830A1DEC:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1dfc
	if (!cr0.eq) goto loc_830A1DFC;
	// li r3,321
	ctx.r3.s64 = 321;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1DFC:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20852
	ctx.r10.s64 = ctx.r10.s64 + 20852;
loc_830A1E08:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1e2c
	if (cr0.eq) goto loc_830A1E2C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1e08
	if (cr6.eq) goto loc_830A1E08;
loc_830A1E2C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1e3c
	if (!cr0.eq) goto loc_830A1E3C;
	// li r3,323
	ctx.r3.s64 = 323;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1E3C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20844
	ctx.r10.s64 = ctx.r10.s64 + 20844;
loc_830A1E48:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1e6c
	if (cr0.eq) goto loc_830A1E6C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1e48
	if (cr6.eq) goto loc_830A1E48;
loc_830A1E6C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1e7c
	if (!cr0.eq) goto loc_830A1E7C;
	// li r3,324
	ctx.r3.s64 = 324;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1E7C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20832
	ctx.r10.s64 = ctx.r10.s64 + 20832;
loc_830A1E88:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1eac
	if (cr0.eq) goto loc_830A1EAC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1e88
	if (cr6.eq) goto loc_830A1E88;
loc_830A1EAC:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,8492
	ctx.r10.s64 = ctx.r10.s64 + 8492;
loc_830A1EC0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1ee4
	if (cr0.eq) goto loc_830A1EE4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1ec0
	if (cr6.eq) goto loc_830A1EC0;
loc_830A1EE4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1ef4
	if (!cr0.eq) goto loc_830A1EF4;
	// li r3,325
	ctx.r3.s64 = 325;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1EF4:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,3336
	ctx.r10.s64 = ctx.r10.s64 + 3336;
loc_830A1F00:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1f24
	if (cr0.eq) goto loc_830A1F24;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1f00
	if (cr6.eq) goto loc_830A1F00;
loc_830A1F24:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1f34
	if (!cr0.eq) goto loc_830A1F34;
loc_830A1F2C:
	// li r3,326
	ctx.r3.s64 = 326;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1F34:
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,22808
	ctx.r10.s64 = ctx.r10.s64 + 22808;
loc_830A1F40:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1f64
	if (cr0.eq) goto loc_830A1F64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1f40
	if (cr6.eq) goto loc_830A1F40;
loc_830A1F64:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1f74
	if (!cr0.eq) goto loc_830A1F74;
	// li r3,327
	ctx.r3.s64 = 327;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1F74:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20824
	ctx.r10.s64 = ctx.r10.s64 + 20824;
loc_830A1F80:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1fa4
	if (cr0.eq) goto loc_830A1FA4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1f80
	if (cr6.eq) goto loc_830A1F80;
loc_830A1FA4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a1fb4
	if (!cr0.eq) goto loc_830A1FB4;
	// li r3,328
	ctx.r3.s64 = 328;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A1FB4:
	// lwz r11,84(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a0f00
	if (cr6.eq) goto loc_830A0F00;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,22860
	ctx.r10.s64 = ctx.r10.s64 + 22860;
loc_830A1FCC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a1ff0
	if (cr0.eq) goto loc_830A1FF0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a1fcc
	if (cr6.eq) goto loc_830A1FCC;
loc_830A1FF0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2000
	if (!cr0.eq) goto loc_830A2000;
loc_830A1FF8:
	// li r3,313
	ctx.r3.s64 = 313;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2000:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17604
	ctx.r10.s64 = ctx.r10.s64 + 17604;
loc_830A200C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2030
	if (cr0.eq) goto loc_830A2030;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a200c
	if (cr6.eq) goto loc_830A200C;
loc_830A2030:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,322
	ctx.r3.s64 = 322;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2040:
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-7288
	ctx.r10.s64 = ctx.r10.s64 + -7288;
loc_830A204C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2070
	if (cr0.eq) goto loc_830A2070;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a204c
	if (cr6.eq) goto loc_830A204C;
loc_830A2070:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a1f2c
	if (cr0.eq) goto loc_830A1F2C;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20808
	ctx.r10.s64 = ctx.r10.s64 + 20808;
loc_830A2084:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a20a8
	if (cr0.eq) goto loc_830A20A8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2084
	if (cr6.eq) goto loc_830A2084;
loc_830A20A8:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a1ff8
	if (cr0.eq) goto loc_830A1FF8;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20784
	ctx.r10.s64 = ctx.r10.s64 + 20784;
loc_830A20BC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a20e0
	if (cr0.eq) goto loc_830A20E0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a20bc
	if (cr6.eq) goto loc_830A20BC;
loc_830A20E0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,314
	ctx.r3.s64 = 314;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A20F0:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,18672
	ctx.r10.s64 = ctx.r10.s64 + 18672;
loc_830A20FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2120
	if (cr0.eq) goto loc_830A2120;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a20fc
	if (cr6.eq) goto loc_830A20FC;
loc_830A2120:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2130
	if (!cr0.eq) goto loc_830A2130;
	// li r3,329
	ctx.r3.s64 = 329;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2130:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20772
	ctx.r10.s64 = ctx.r10.s64 + 20772;
loc_830A213C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2160
	if (cr0.eq) goto loc_830A2160;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a213c
	if (cr6.eq) goto loc_830A213C;
loc_830A2160:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,18008
	ctx.r10.s64 = ctx.r10.s64 + 18008;
loc_830A2174:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2198
	if (cr0.eq) goto loc_830A2198;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2174
	if (cr6.eq) goto loc_830A2174;
loc_830A2198:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20760
	ctx.r10.s64 = ctx.r10.s64 + 20760;
loc_830A21AC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a21d0
	if (cr0.eq) goto loc_830A21D0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a21ac
	if (cr6.eq) goto loc_830A21AC;
loc_830A21D0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a21e0
	if (!cr0.eq) goto loc_830A21E0;
	// li r3,341
	ctx.r3.s64 = 341;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A21E0:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20748
	ctx.r10.s64 = ctx.r10.s64 + 20748;
loc_830A21EC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2210
	if (cr0.eq) goto loc_830A2210;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a21ec
	if (cr6.eq) goto loc_830A21EC;
loc_830A2210:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2220
	if (!cr0.eq) goto loc_830A2220;
	// li r3,342
	ctx.r3.s64 = 342;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2220:
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-4540
	ctx.r10.s64 = ctx.r10.s64 + -4540;
loc_830A222C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2250
	if (cr0.eq) goto loc_830A2250;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a222c
	if (cr6.eq) goto loc_830A222C;
loc_830A2250:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,3900
	ctx.r10.s64 = ctx.r10.s64 + 3900;
loc_830A2264:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2288
	if (cr0.eq) goto loc_830A2288;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2264
	if (cr6.eq) goto loc_830A2264;
loc_830A2288:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2298
	if (!cr0.eq) goto loc_830A2298;
	// li r3,344
	ctx.r3.s64 = 344;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2298:
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-4032
	ctx.r10.s64 = ctx.r10.s64 + -4032;
loc_830A22A4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a22c8
	if (cr0.eq) goto loc_830A22C8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a22a4
	if (cr6.eq) goto loc_830A22A4;
loc_830A22C8:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20740
	ctx.r10.s64 = ctx.r10.s64 + 20740;
loc_830A22DC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2300
	if (cr0.eq) goto loc_830A2300;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a22dc
	if (cr6.eq) goto loc_830A22DC;
loc_830A2300:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2310
	if (!cr0.eq) goto loc_830A2310;
	// li r3,345
	ctx.r3.s64 = 345;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2310:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20728
	ctx.r10.s64 = ctx.r10.s64 + 20728;
loc_830A231C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2340
	if (cr0.eq) goto loc_830A2340;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a231c
	if (cr6.eq) goto loc_830A231C;
loc_830A2340:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_830A2350:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2374
	if (cr0.eq) goto loc_830A2374;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2350
	if (cr6.eq) goto loc_830A2350;
loc_830A2374:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2384
	if (!cr0.eq) goto loc_830A2384;
loc_830A237C:
	// li r3,330
	ctx.r3.s64 = 330;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2384:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,18632
	ctx.r10.s64 = ctx.r10.s64 + 18632;
loc_830A2390:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a23b4
	if (cr0.eq) goto loc_830A23B4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2390
	if (cr6.eq) goto loc_830A2390;
loc_830A23B4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a23c4
	if (!cr0.eq) goto loc_830A23C4;
	// li r3,331
	ctx.r3.s64 = 331;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A23C4:
	// lwz r11,84(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a0f00
	if (cr6.eq) goto loc_830A0F00;
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-9600
	ctx.r10.s64 = ctx.r10.s64 + -9600;
loc_830A23DC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2400
	if (cr0.eq) goto loc_830A2400;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a23dc
	if (cr6.eq) goto loc_830A23DC;
loc_830A2400:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2410
	if (!cr0.eq) goto loc_830A2410;
	// li r3,332
	ctx.r3.s64 = 332;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2410:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20716
	ctx.r10.s64 = ctx.r10.s64 + 20716;
	// bne 0x830a251c
	if (!cr0.eq) goto loc_830A251C;
loc_830A2428:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a244c
	if (cr0.eq) goto loc_830A244C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2428
	if (cr6.eq) goto loc_830A2428;
loc_830A244C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a245c
	if (!cr0.eq) goto loc_830A245C;
loc_830A2454:
	// li r3,333
	ctx.r3.s64 = 333;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A245C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20704
	ctx.r10.s64 = ctx.r10.s64 + 20704;
loc_830A2468:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a248c
	if (cr0.eq) goto loc_830A248C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2468
	if (cr6.eq) goto loc_830A2468;
loc_830A248C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a249c
	if (!cr0.eq) goto loc_830A249C;
loc_830A2494:
	// li r3,335
	ctx.r3.s64 = 335;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A249C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20692
	ctx.r10.s64 = ctx.r10.s64 + 20692;
loc_830A24A8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a24cc
	if (cr0.eq) goto loc_830A24CC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a24a8
	if (cr6.eq) goto loc_830A24A8;
loc_830A24CC:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a24dc
	if (!cr0.eq) goto loc_830A24DC;
loc_830A24D4:
	// li r3,337
	ctx.r3.s64 = 337;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A24DC:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20680
	ctx.r10.s64 = ctx.r10.s64 + 20680;
loc_830A24E8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a250c
	if (cr0.eq) goto loc_830A250C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a24e8
	if (cr6.eq) goto loc_830A24E8;
loc_830A250C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
loc_830A2514:
	// li r3,338
	ctx.r3.s64 = 338;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A251C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2540
	if (cr0.eq) goto loc_830A2540;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a251c
	if (cr6.eq) goto loc_830A251C;
loc_830A2540:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2560
	if (!cr0.eq) goto loc_830A2560;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3086
	ctx.r5.s64 = 3086;
	// addi r6,r11,20616
	ctx.r6.s64 = r11.s64 + 20616;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A2560:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// addi r10,r10,20704
	ctx.r10.s64 = ctx.r10.s64 + 20704;
loc_830A256C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2590
	if (cr0.eq) goto loc_830A2590;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a256c
	if (cr6.eq) goto loc_830A256C;
loc_830A2590:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a25b0
	if (!cr0.eq) goto loc_830A25B0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3086
	ctx.r5.s64 = 3086;
	// addi r6,r11,20552
	ctx.r6.s64 = r11.s64 + 20552;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A25B0:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// addi r10,r10,20692
	ctx.r10.s64 = ctx.r10.s64 + 20692;
loc_830A25BC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a25e0
	if (cr0.eq) goto loc_830A25E0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a25bc
	if (cr6.eq) goto loc_830A25BC;
loc_830A25E0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2600
	if (!cr0.eq) goto loc_830A2600;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3086
	ctx.r5.s64 = 3086;
	// addi r6,r11,20488
	ctx.r6.s64 = r11.s64 + 20488;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A2600:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// addi r10,r10,20680
	ctx.r10.s64 = ctx.r10.s64 + 20680;
loc_830A260C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2630
	if (cr0.eq) goto loc_830A2630;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a260c
	if (cr6.eq) goto loc_830A260C;
loc_830A2630:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,20424
	ctx.r6.s64 = r11.s64 + 20424;
	// b 0x830a1974
	goto loc_830A1974;
loc_830A2644:
	// lwz r11,84(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a0f00
	if (cr6.eq) goto loc_830A0F00;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17804
	ctx.r10.s64 = ctx.r10.s64 + 17804;
loc_830A265C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2680
	if (cr0.eq) goto loc_830A2680;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a265c
	if (cr6.eq) goto loc_830A265C;
loc_830A2680:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a2454
	if (cr0.eq) goto loc_830A2454;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17752
	ctx.r10.s64 = ctx.r10.s64 + 17752;
loc_830A2694:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a26b8
	if (cr0.eq) goto loc_830A26B8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2694
	if (cr6.eq) goto loc_830A2694;
loc_830A26B8:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a26c8
	if (!cr0.eq) goto loc_830A26C8;
	// li r3,334
	ctx.r3.s64 = 334;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A26C8:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17792
	ctx.r10.s64 = ctx.r10.s64 + 17792;
loc_830A26D4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a26f8
	if (cr0.eq) goto loc_830A26F8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a26d4
	if (cr6.eq) goto loc_830A26D4;
loc_830A26F8:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a2494
	if (cr0.eq) goto loc_830A2494;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17736
	ctx.r10.s64 = ctx.r10.s64 + 17736;
loc_830A270C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2730
	if (cr0.eq) goto loc_830A2730;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a270c
	if (cr6.eq) goto loc_830A270C;
loc_830A2730:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2740
	if (!cr0.eq) goto loc_830A2740;
	// li r3,336
	ctx.r3.s64 = 336;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2740:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17780
	ctx.r10.s64 = ctx.r10.s64 + 17780;
loc_830A274C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2770
	if (cr0.eq) goto loc_830A2770;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a274c
	if (cr6.eq) goto loc_830A274C;
loc_830A2770:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a24d4
	if (cr0.eq) goto loc_830A24D4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17768
	ctx.r10.s64 = ctx.r10.s64 + 17768;
loc_830A2784:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a27a8
	if (cr0.eq) goto loc_830A27A8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2784
	if (cr6.eq) goto loc_830A2784;
loc_830A27A8:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a2514
	if (cr0.eq) goto loc_830A2514;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17564
	ctx.r10.s64 = ctx.r10.s64 + 17564;
loc_830A27BC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a27e0
	if (cr0.eq) goto loc_830A27E0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a27bc
	if (cr6.eq) goto loc_830A27BC;
loc_830A27E0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a27f0
	if (!cr0.eq) goto loc_830A27F0;
	// li r3,343
	ctx.r3.s64 = 343;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A27F0:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,17724
	ctx.r10.s64 = ctx.r10.s64 + 17724;
loc_830A27FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2820
	if (cr0.eq) goto loc_830A2820;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a27fc
	if (cr6.eq) goto loc_830A27FC;
loc_830A2820:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2830
	if (!cr0.eq) goto loc_830A2830;
	// li r3,339
	ctx.r3.s64 = 339;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2830:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20404
	ctx.r10.s64 = ctx.r10.s64 + 20404;
loc_830A283C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2860
	if (cr0.eq) goto loc_830A2860;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a283c
	if (cr6.eq) goto loc_830A283C;
loc_830A2860:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,340
	ctx.r3.s64 = 340;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2870:
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-5368
	ctx.r10.s64 = ctx.r10.s64 + -5368;
loc_830A287C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a28a0
	if (cr0.eq) goto loc_830A28A0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a287c
	if (cr6.eq) goto loc_830A287C;
loc_830A28A0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a28b0
	if (!cr0.eq) goto loc_830A28B0;
	// li r3,348
	ctx.r3.s64 = 348;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A28B0:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20396
	ctx.r10.s64 = ctx.r10.s64 + 20396;
loc_830A28BC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a28e0
	if (cr0.eq) goto loc_830A28E0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a28bc
	if (cr6.eq) goto loc_830A28BC;
loc_830A28E0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a28f0
	if (!cr0.eq) goto loc_830A28F0;
	// li r3,346
	ctx.r3.s64 = 346;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A28F0:
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,14776
	ctx.r10.s64 = ctx.r10.s64 + 14776;
loc_830A28FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2920
	if (cr0.eq) goto loc_830A2920;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a28fc
	if (cr6.eq) goto loc_830A28FC;
loc_830A2920:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20388
	ctx.r10.s64 = ctx.r10.s64 + 20388;
loc_830A2934:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2958
	if (cr0.eq) goto loc_830A2958;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2934
	if (cr6.eq) goto loc_830A2934;
loc_830A2958:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2968
	if (!cr0.eq) goto loc_830A2968;
	// li r3,349
	ctx.r3.s64 = 349;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2968:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20376
	ctx.r10.s64 = ctx.r10.s64 + 20376;
loc_830A2974:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2998
	if (cr0.eq) goto loc_830A2998;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2974
	if (cr6.eq) goto loc_830A2974;
loc_830A2998:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a29a8
	if (!cr0.eq) goto loc_830A29A8;
	// li r3,347
	ctx.r3.s64 = 347;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A29A8:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20368
	ctx.r10.s64 = ctx.r10.s64 + 20368;
loc_830A29B4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a0ef8
	if (cr0.eq) goto loc_830A0EF8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a29b4
	if (cr6.eq) goto loc_830A29B4;
	// b 0x830a0ef8
	goto loc_830A0EF8;
loc_830A29DC:
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,22844
	ctx.r10.s64 = ctx.r10.s64 + 22844;
loc_830A29E8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2a0c
	if (cr0.eq) goto loc_830A2A0C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a29e8
	if (cr6.eq) goto loc_830A29E8;
loc_830A2A0C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2a1c
	if (!cr0.eq) goto loc_830A2A1C;
	// li r3,350
	ctx.r3.s64 = 350;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2A1C:
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,22652
	ctx.r10.s64 = ctx.r10.s64 + 22652;
loc_830A2A28:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2a4c
	if (cr0.eq) goto loc_830A2A4C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2a28
	if (cr6.eq) goto loc_830A2A28;
loc_830A2A4C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2a5c
	if (!cr0.eq) goto loc_830A2A5C;
	// li r3,351
	ctx.r3.s64 = 351;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2A5C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,20360
	ctx.r10.s64 = ctx.r10.s64 + 20360;
loc_830A2A68:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2a8c
	if (cr0.eq) goto loc_830A2A8C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2a68
	if (cr6.eq) goto loc_830A2A68;
loc_830A2A8C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830a06a4
	if (cr0.eq) goto loc_830A06A4;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,10792
	ctx.r10.s64 = ctx.r10.s64 + 10792;
loc_830A2AA0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2ac4
	if (cr0.eq) goto loc_830A2AC4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2aa0
	if (cr6.eq) goto loc_830A2AA0;
loc_830A2AC4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2ad4
	if (!cr0.eq) goto loc_830A2AD4;
	// li r3,353
	ctx.r3.s64 = 353;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2AD4:
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,10816
	ctx.r10.s64 = ctx.r10.s64 + 10816;
loc_830A2AE0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2b04
	if (cr0.eq) goto loc_830A2B04;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2ae0
	if (cr6.eq) goto loc_830A2AE0;
loc_830A2B04:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a2b14
	if (!cr0.eq) goto loc_830A2B14;
	// li r3,354
	ctx.r3.s64 = 354;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2B14:
	// lwz r11,84(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a0f00
	if (cr6.eq) goto loc_830A0F00;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,22684
	ctx.r10.s64 = ctx.r10.s64 + 22684;
loc_830A2B2C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2b50
	if (cr0.eq) goto loc_830A2B50;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2b2c
	if (cr6.eq) goto loc_830A2B2C;
loc_830A2B50:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a2b6c
	if (!cr0.eq) goto loc_830A2B6C;
loc_830A2B64:
	// li r3,352
	ctx.r3.s64 = 352;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2B6C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,20288
	ctx.r6.s64 = r11.s64 + 20288;
	// b 0x830a1974
	goto loc_830A1974;
loc_830A2B78:
	// lwz r11,84(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a0f00
	if (cr6.eq) goto loc_830A0F00;
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,-22436
	ctx.r10.s64 = ctx.r10.s64 + -22436;
loc_830A2B90:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2bb4
	if (cr0.eq) goto loc_830A2BB4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2b90
	if (cr6.eq) goto loc_830A2B90;
loc_830A2BB4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// b 0x830a2b64
	goto loc_830A2B64;
loc_830A2BCC:
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,12744
	ctx.r10.s64 = ctx.r10.s64 + 12744;
loc_830A2BD8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x830a2bfc
	if (cr0.eq) goto loc_830A2BFC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830a2bd8
	if (cr6.eq) goto loc_830A2BD8;
loc_830A2BFC:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830a0f00
	if (!cr0.eq) goto loc_830A0F00;
	// li r3,355
	ctx.r3.s64 = 355;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2C0C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a2ca8
	if (!cr0.eq) goto loc_830A2CA8;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a17d8
	if (cr0.eq) goto loc_830A17D8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,20224
	ctx.r6.s64 = r11.s64 + 20224;
	// b 0x830a2c98
	goto loc_830A2C98;
loc_830A2C38:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// addi r4,r11,20216
	ctx.r4.s64 = r11.s64 + 20216;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a2ca8
	if (!cr0.eq) goto loc_830A2CA8;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a2c64
	if (!cr0.eq) goto loc_830A2C64;
	// li r3,273
	ctx.r3.s64 = 273;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2C64:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,20156
	ctx.r6.s64 = r11.s64 + 20156;
	// b 0x830a2c98
	goto loc_830A2C98;
loc_830A2C70:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a2ca8
	if (!cr0.eq) goto loc_830A2CA8;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a0968
	if (cr0.eq) goto loc_830A0968;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,20100
	ctx.r6.s64 = r11.s64 + 20100;
loc_830A2C98:
	// li r5,3086
	ctx.r5.s64 = 3086;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A2CA8:
	// li r31,0
	r31.s64 = 0;
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8309d768
	sub_8309D768(ctx, base);
	// subf r11,r31,r3
	r11.s64 = ctx.r3.s64 - r31.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// addi r3,r11,384
	ctx.r3.s64 = r11.s64 + 384;
	// b 0x830a0668
	goto loc_830A0668;
loc_830A2CEC:
	// li r3,383
	ctx.r3.s64 = 383;
	// b 0x830a0668
	goto loc_830A0668;
}

__attribute__((alias("__imp__sub_830A2CF8"))) PPC_WEAK_FUNC(sub_830A2CF8);
PPC_FUNC_IMPL(__imp__sub_830A2CF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-416(r1)
	ea = -416 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lis r5,-32241
	ctx.r5.s64 = -2112946176;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r18,r10,22556
	r18.s64 = ctx.r10.s64 + 22556;
	// addi r10,r5,13568
	ctx.r10.s64 = ctx.r5.s64 + 13568;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// stw r18,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r18.u32);
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// stw r10,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r10.u32);
	// mr r19,r4
	r19.u64 = ctx.r4.u64;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r21,r7
	r21.u64 = ctx.r7.u64;
	// lis r6,-32249
	ctx.r6.s64 = -2113470464;
	// lis r4,-32249
	ctx.r4.s64 = -2113470464;
	// lis r3,-32249
	ctx.r3.s64 = -2113470464;
	// lis r28,-32256
	r28.s64 = -2113929216;
	// lis r27,-32249
	r27.s64 = -2113470464;
	// lis r8,-32249
	ctx.r8.s64 = -2113470464;
	// lis r7,-32249
	ctx.r7.s64 = -2113470464;
	// lis r26,-32243
	r26.s64 = -2113077248;
	// addi r16,r9,22536
	r16.s64 = ctx.r9.s64 + 22536;
	// addi r28,r28,3224
	r28.s64 = r28.s64 + 3224;
	// addi r27,r27,22456
	r27.s64 = r27.s64 + 22456;
	// stw r16,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r16.u32);
	// addi r6,r6,22516
	ctx.r6.s64 = ctx.r6.s64 + 22516;
	// stw r28,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, r28.u32);
	// addi r9,r4,22492
	ctx.r9.s64 = ctx.r4.s64 + 22492;
	// stw r28,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, r28.u32);
	// addi r5,r3,22472
	ctx.r5.s64 = ctx.r3.s64 + 22472;
	// stw r6,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r6.u32);
	// addi r17,r8,22444
	r17.s64 = ctx.r8.s64 + 22444;
	// stw r9,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r9.u32);
	// addi r15,r7,22428
	r15.s64 = ctx.r7.s64 + 22428;
	// stw r5,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r5.u32);
	// addi r10,r26,11916
	ctx.r10.s64 = r26.s64 + 11916;
	// stw r6,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r6.u32);
	// stw r27,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, r27.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r17,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, r17.u32);
	// stw r15,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, r15.u32);
	// stw r27,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, r27.u32);
	// stw r27,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, r27.u32);
	// stw r10,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r10.u32);
	// stw r28,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, r28.u32);
	// stw r28,252(r1)
	PPC_STORE_U32(ctx.r1.u32 + 252, r28.u32);
	// stw r27,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, r27.u32);
	// beq cr6,0x830a3ac8
	if (cr6.eq) goto loc_830A3AC8;
	// lwz r22,8(r11)
	r22.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x830a3ac8
	if (cr6.eq) goto loc_830A3AC8;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a3ac8
	if (cr6.eq) goto loc_830A3AC8;
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x830a3ac8
	if (cr6.eq) goto loc_830A3AC8;
	// li r3,20
	ctx.r3.s64 = 20;
	// lwz r23,24(r22)
	r23.u64 = PPC_LOAD_U32(r22.u32 + 24);
	// bl 0x83046708
	sub_83046708(ctx, base);
	// li r20,0
	r20.s64 = 0;
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a2e1c
	if (cr0.eq) goto loc_830A2E1C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,22412
	ctx.r6.s64 = r11.s64 + 22412;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// stw r28,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r28.u32);
	// b 0x830a2e24
	goto loc_830A2E24;
loc_830A2E1C:
	// stw r20,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r20.u32);
	// rotlwi r28,r20,0
	r28.u64 = __builtin_rotateleft32(r20.u32, 0);
loc_830A2E24:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830a3ac8
	if (cr6.eq) goto loc_830A3AC8;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a2e5c
	if (cr0.eq) goto loc_830A2E5C;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83047398
	sub_83047398(ctx, base);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// b 0x830a2e60
	goto loc_830A2E60;
loc_830A2E5C:
	// mr r14,r20
	r14.u64 = r20.u64;
loc_830A2E60:
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x830a3ac8
	if (cr6.eq) goto loc_830A3AC8;
	// stw r14,8(r28)
	PPC_STORE_U32(r28.u32 + 8, r14.u32);
	// li r3,88
	ctx.r3.s64 = 88;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a2e88
	if (cr0.eq) goto loc_830A2E88;
	// bl 0x830488a8
	sub_830488A8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x830a2e8c
	goto loc_830A2E8C;
loc_830A2E88:
	// mr r27,r20
	r27.u64 = r20.u64;
loc_830A2E8C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830a3ac8
	if (cr6.eq) goto loc_830A3AC8;
	// stw r27,24(r14)
	PPC_STORE_U32(r14.u32 + 24, r27.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830a2eb4
	if (cr6.eq) goto loc_830A2EB4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,28(r14)
	PPC_STORE_U32(r14.u32 + 28, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3ac8
	if (cr0.eq) goto loc_830A3AC8;
loc_830A2EB4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830a2f04
	if (cr6.eq) goto loc_830A2F04;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,64(r27)
	PPC_STORE_U32(r27.u32 + 64, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3ac8
	if (cr0.eq) goto loc_830A3AC8;
loc_830A2ED0:
	// lwz r3,8(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a2ef8
	if (cr6.eq) goto loc_830A2EF8;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x830a2ef8
	if (!cr6.eq) goto loc_830A2EF8;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,60(r27)
	PPC_STORE_U32(r27.u32 + 60, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3ac8
	if (cr0.eq) goto loc_830A3AC8;
loc_830A2EF8:
	// lwz r29,12(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x830a2ed0
	if (!cr6.eq) goto loc_830A2ED0;
loc_830A2F04:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830a2f2c
	if (cr6.eq) goto loc_830A2F2C;
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x830a2f2c
	if (cr6.eq) goto loc_830A2F2C;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8309b960
	sub_8309B960(ctx, base);
	// stw r3,52(r27)
	PPC_STORE_U32(r27.u32 + 52, ctx.r3.u32);
loc_830A2F2C:
	// li r25,1
	r25.s64 = 1;
	// mr r24,r20
	r24.u64 = r20.u64;
	// mr r26,r25
	r26.u64 = r25.u64;
	// mr r28,r20
	r28.u64 = r20.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830a2fe0
	if (cr6.eq) goto loc_830A2FE0;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,48(r27)
	PPC_STORE_U32(r27.u32 + 48, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3ac8
	if (cr0.eq) goto loc_830A3AC8;
	// b 0x830a2fe0
	goto loc_830A2FE0;
loc_830A2F5C:
	// li r3,24
	ctx.r3.s64 = 24;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a2f78
	if (cr0.eq) goto loc_830A2F78;
	// bl 0x83047f08
	sub_83047F08(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x830a2f7c
	goto loc_830A2F7C;
loc_830A2F78:
	// mr r29,r20
	r29.u64 = r20.u64;
loc_830A2F7C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830a3ac8
	if (cr6.eq) goto loc_830A3AC8;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830a2f90
	if (cr6.eq) goto loc_830A2F90;
	// li r28,3073
	r28.s64 = 3073;
loc_830A2F90:
	// lwz r11,48(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// addi r30,r29,20
	r30.s64 = r29.s64 + 20;
	// stw r11,16(r29)
	PPC_STORE_U32(r29.u32 + 16, r11.u32);
	// lwz r4,12(r19)
	ctx.r4.u64 = PPC_LOAD_U32(r19.u32 + 12);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830a2fc8
	if (cr6.eq) goto loc_830A2FC8;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8309d198
	sub_8309D198(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830a2fd0
	if (!cr0.lt) goto loc_830A2FD0;
	// li r28,3058
	r28.s64 = 3058;
	// stw r25,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r25.u32);
	// b 0x830a2fd0
	goto loc_830A2FD0;
loc_830A2FC8:
	// stw r25,20(r29)
	PPC_STORE_U32(r29.u32 + 20, r25.u32);
	// mr r24,r30
	r24.u64 = r30.u64;
loc_830A2FD0:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// stw r29,48(r27)
	PPC_STORE_U32(r27.u32 + 48, r29.u32);
	// mullw r26,r11,r26
	r26.s64 = int64_t(r11.s32) * int64_t(r26.s32);
	// lwz r19,8(r19)
	r19.u64 = PPC_LOAD_U32(r19.u32 + 8);
loc_830A2FE0:
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x830a2f5c
	if (!cr6.eq) goto loc_830A2F5C;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,20(r14)
	PPC_STORE_U32(r14.u32 + 20, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3ac8
	if (cr0.eq) goto loc_830A3AC8;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r29,r19,16
	r29.s64 = r19.s64 + 16;
	// cmplwi cr6,r28,3058
	cr6.compare<uint32_t>(r28.u32, 3058, xer);
	// lwz r25,16(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// beq cr6,0x830a3aac
	if (cr6.eq) goto loc_830A3AAC;
	// cmplwi cr6,r28,3073
	cr6.compare<uint32_t>(r28.u32, 3073, xer);
	// beq cr6,0x830a3a9c
	if (cr6.eq) goto loc_830A3A9C;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830a3104
	if (cr6.eq) goto loc_830A3104;
	// cmpwi cr6,r25,9
	cr6.compare<int32_t>(r25.s32, 9, xer);
	// beq cr6,0x830a3060
	if (cr6.eq) goto loc_830A3060;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830a3060
	if (cr6.eq) goto loc_830A3060;
	// cmpwi cr6,r25,3
	cr6.compare<int32_t>(r25.s32, 3, xer);
	// beq cr6,0x830a3060
	if (cr6.eq) goto loc_830A3060;
	// cmpwi cr6,r25,4
	cr6.compare<int32_t>(r25.s32, 4, xer);
	// beq cr6,0x830a3060
	if (cr6.eq) goto loc_830A3060;
	// cmpwi cr6,r25,5
	cr6.compare<int32_t>(r25.s32, 5, xer);
	// beq cr6,0x830a3060
	if (cr6.eq) goto loc_830A3060;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// li r5,3072
	ctx.r5.s64 = 3072;
	// addi r6,r9,22364
	ctx.r6.s64 = ctx.r9.s64 + 22364;
	// b 0x830a30bc
	goto loc_830A30BC;
loc_830A3060:
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83097a98
	sub_83097A98(ctx, base);
	// mullw. r30,r3,r26
	r30.s64 = int64_t(ctx.r3.s32) * int64_t(r26.s32);
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x830a30fc
	if (cr0.eq) goto loc_830A30FC;
	// lwz r11,52(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 52);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a30ec
	if (cr6.eq) goto loc_830A30EC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x830a30ec
	if (!cr6.eq) goto loc_830A30EC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x83097a98
	sub_83097A98(ctx, base);
	// divwu r11,r3,r30
	r11.u32 = ctx.r3.u32 / r30.u32;
	// twllei r30,0
	// mullw r11,r11,r30
	r11.s64 = int64_t(r11.s32) * int64_t(r30.s32);
	// subf. r11,r11,r3
	r11.s64 = ctx.r3.s64 - r11.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a30d8
	if (cr0.eq) goto loc_830A30D8;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3075
	ctx.r5.s64 = 3075;
	// addi r6,r9,22320
	ctx.r6.s64 = ctx.r9.s64 + 22320;
loc_830A30B8:
	// addi r10,r1,224
	ctx.r10.s64 = ctx.r1.s64 + 224;
loc_830A30BC:
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a3ac8
	goto loc_830A3AC8;
loc_830A30D8:
	// divwu r11,r3,r30
	r11.u32 = ctx.r3.u32 / r30.u32;
	// twllei r30,0
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
	// mullw r26,r11,r26
	r26.s64 = int64_t(r11.s32) * int64_t(r26.s32);
	// b 0x830a3104
	goto loc_830A3104;
loc_830A30EC:
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3074
	ctx.r5.s64 = 3074;
	// addi r6,r9,22288
	ctx.r6.s64 = ctx.r9.s64 + 22288;
	// b 0x830a30b8
	goto loc_830A30B8;
loc_830A30FC:
	// mr r26,r20
	r26.u64 = r20.u64;
	// stw r20,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r20.u32);
loc_830A3104:
	// cmplwi cr6,r26,1
	cr6.compare<uint32_t>(r26.u32, 1, xer);
	// blt cr6,0x830a3a8c
	if (cr6.lt) goto loc_830A3A8C;
	// lis r11,1
	r11.s64 = 65536;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// bgt cr6,0x830a3a8c
	if (cr6.gt) goto loc_830A3A8C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// bl 0x83097a98
	sub_83097A98(ctx, base);
	// stw r3,20(r27)
	PPC_STORE_U32(r27.u32 + 20, ctx.r3.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// stw r11,40(r27)
	PPC_STORE_U32(r27.u32 + 40, r11.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x830a31a8
	if (cr6.eq) goto loc_830A31A8;
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// stw r11,16(r27)
	PPC_STORE_U32(r27.u32 + 16, r11.u32);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// stw r11,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r11.u32);
	// stw r11,24(r27)
	PPC_STORE_U32(r27.u32 + 24, r11.u32);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r11.u32);
	// stw r11,28(r27)
	PPC_STORE_U32(r27.u32 + 28, r11.u32);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r11.u32);
	// lwz r10,16(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830a31b0
	if (cr0.eq) goto loc_830A31B0;
	// stw r11,32(r27)
	PPC_STORE_U32(r27.u32 + 32, r11.u32);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r11.u32);
	// stw r11,36(r27)
	PPC_STORE_U32(r27.u32 + 36, r11.u32);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r11.u32);
	// b 0x830a31b0
	goto loc_830A31B0;
loc_830A31A8:
	// li r11,-1
	r11.s64 = -1;
	// stw r11,16(r27)
	PPC_STORE_U32(r27.u32 + 16, r11.u32);
loc_830A31B0:
	// lwz r11,20(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// lwz r26,16(r22)
	r26.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a3224
	if (cr6.eq) goto loc_830A3224;
	// addi r5,r1,152
	ctx.r5.s64 = ctx.r1.s64 + 152;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8301d1e0
	sub_8301D1E0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bge 0x830a3200
	if (!cr0.lt) goto loc_830A3200;
	// lwz r11,20(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// rlwinm r10,r25,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r8,-32249
	ctx.r8.s64 = -2113470464;
	// li r5,3089
	ctx.r5.s64 = 3089;
	// addi r6,r8,22252
	ctx.r6.s64 = ctx.r8.s64 + 22252;
	// lwz r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// b 0x830a321c
	goto loc_830A321C;
loc_830A3200:
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3039
	ctx.r5.s64 = 3039;
	// addi r6,r9,22216
	ctx.r6.s64 = ctx.r9.s64 + 22216;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
loc_830A321C:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A3224:
	// rlwinm. r11,r26,0,23,23
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a3254
	if (cr0.eq) goto loc_830A3254;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3055
	ctx.r5.s64 = 3055;
	// addi r6,r9,22176
	ctx.r6.s64 = ctx.r9.s64 + 22176;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A3254:
	// cmpwi cr6,r25,1
	cr6.compare<int32_t>(r25.s32, 1, xer);
	// bne cr6,0x830a3290
	if (!cr6.eq) goto loc_830A3290;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a332c
	if (cr0.eq) goto loc_830A332C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r8,r18
	ctx.r8.u64 = r18.u64;
	// addi r6,r11,22140
	ctx.r6.s64 = r11.s64 + 22140;
	// li r5,3035
	ctx.r5.s64 = 3035;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A3290:
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// bne cr6,0x830a32d0
	if (!cr6.eq) goto loc_830A32D0;
	// rlwinm. r11,r26,0,27,27
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a332c
	if (!cr0.eq) goto loc_830A332C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a332c
	if (cr0.eq) goto loc_830A332C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// li r5,3046
	ctx.r5.s64 = 3046;
	// addi r6,r11,22088
	ctx.r6.s64 = r11.s64 + 22088;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A32D0:
	// cmpwi cr6,r25,3
	cr6.compare<int32_t>(r25.s32, 3, xer);
	// beq cr6,0x830a32e0
	if (cr6.eq) goto loc_830A32E0;
	// cmpwi cr6,r25,4
	cr6.compare<int32_t>(r25.s32, 4, xer);
	// bne cr6,0x830a331c
	if (!cr6.eq) goto loc_830A331C;
loc_830A32E0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// bl 0x830979c8
	sub_830979C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a331c
	if (!cr0.eq) goto loc_830A331C;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3038
	ctx.r5.s64 = 3038;
	// addi r6,r9,22060
	ctx.r6.s64 = ctx.r9.s64 + 22060;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A331C:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830a3454
	if (cr6.eq) goto loc_830A3454;
	// cmpwi cr6,r25,9
	cr6.compare<int32_t>(r25.s32, 9, xer);
	// beq cr6,0x830a3454
	if (cr6.eq) goto loc_830A3454;
loc_830A332C:
	// rlwinm. r11,r26,0,30,30
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a3370
	if (cr0.eq) goto loc_830A3370;
	// cmpwi cr6,r25,3
	cr6.compare<int32_t>(r25.s32, 3, xer);
	// beq cr6,0x830a3370
	if (cr6.eq) goto loc_830A3370;
	// cmpwi cr6,r25,4
	cr6.compare<int32_t>(r25.s32, 4, xer);
	// beq cr6,0x830a3370
	if (cr6.eq) goto loc_830A3370;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3007
	ctx.r5.s64 = 3007;
	// addi r6,r9,22020
	ctx.r6.s64 = ctx.r9.s64 + 22020;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// rlwinm r26,r26,0,31,29
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
loc_830A3370:
	// rlwinm. r11,r26,0,25,25
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a33ac
	if (cr0.eq) goto loc_830A33AC;
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// beq cr6,0x830a33ac
	if (cr6.eq) goto loc_830A33AC;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3047
	ctx.r5.s64 = 3047;
	// addi r6,r9,21980
	ctx.r6.s64 = ctx.r9.s64 + 21980;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// rlwinm r26,r26,0,26,24
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFFFFFFFFFFFBF;
loc_830A33AC:
	// rlwinm. r11,r26,0,25,25
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a33e8
	if (cr0.eq) goto loc_830A33E8;
	// rlwinm. r11,r26,0,26,26
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a33e8
	if (cr0.eq) goto loc_830A33E8;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3062
	ctx.r5.s64 = 3062;
	// addi r6,r9,21936
	ctx.r6.s64 = ctx.r9.s64 + 21936;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// rlwinm r26,r26,0,26,24
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFFFFFFFFFFFBF;
loc_830A33E8:
	// clrlwi. r11,r26,31
	r11.u64 = r26.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a341c
	if (cr0.eq) goto loc_830A341C;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3006
	ctx.r5.s64 = 3006;
	// addi r6,r9,21896
	ctx.r6.s64 = ctx.r9.s64 + 21896;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// rlwinm r26,r26,0,0,30
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFFFFE;
loc_830A341C:
	// rlwinm. r11,r26,0,28,28
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a34d8
	if (cr0.eq) goto loc_830A34D8;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3054
	ctx.r5.s64 = 3054;
	// addi r6,r9,21856
	ctx.r6.s64 = ctx.r9.s64 + 21856;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// rlwinm r26,r26,0,29,27
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// b 0x830a34d8
	goto loc_830A34D8;
loc_830A3454:
	// rlwinm. r11,r26,0,30,30
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a3490
	if (cr0.eq) goto loc_830A3490;
	// clrlwi. r11,r26,31
	r11.u64 = r26.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a3490
	if (cr0.eq) goto loc_830A3490;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3007
	ctx.r5.s64 = 3007;
	// addi r6,r9,21812
	ctx.r6.s64 = ctx.r9.s64 + 21812;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// rlwinm r26,r26,0,31,29
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
loc_830A3490:
	// rlwinm. r11,r26,0,30,30
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a34cc
	if (cr0.eq) goto loc_830A34CC;
	// rlwinm. r11,r26,0,25,25
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a34cc
	if (cr0.eq) goto loc_830A34CC;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3007
	ctx.r5.s64 = 3007;
	// addi r6,r9,21764
	ctx.r6.s64 = ctx.r9.s64 + 21764;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// rlwinm r26,r26,0,31,29
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
loc_830A34CC:
	// rlwinm. r11,r26,0,30,30
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a34d8
	if (!cr0.eq) goto loc_830A34D8;
	// ori r26,r26,65
	r26.u64 = r26.u64 | 65;
loc_830A34D8:
	// rlwinm. r11,r26,0,29,29
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a3524
	if (cr0.eq) goto loc_830A3524;
	// cmpwi cr6,r25,3
	cr6.compare<int32_t>(r25.s32, 3, xer);
	// beq cr6,0x830a3524
	if (cr6.eq) goto loc_830A3524;
	// cmpwi cr6,r25,4
	cr6.compare<int32_t>(r25.s32, 4, xer);
	// beq cr6,0x830a3524
	if (cr6.eq) goto loc_830A3524;
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// beq cr6,0x830a3524
	if (cr6.eq) goto loc_830A3524;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3008
	ctx.r5.s64 = 3008;
	// addi r6,r9,21724
	ctx.r6.s64 = ctx.r9.s64 + 21724;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// rlwinm r26,r26,0,30,28
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
loc_830A3524:
	// cmpwi cr6,r25,5
	cr6.compare<int32_t>(r25.s32, 5, xer);
	// bne cr6,0x830a3540
	if (!cr6.eq) goto loc_830A3540;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,48(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83097810
	sub_83097810(ctx, base);
	// ori r26,r26,64
	r26.u64 = r26.u64 | 64;
loc_830A3540:
	// stw r26,44(r27)
	PPC_STORE_U32(r27.u32 + 44, r26.u32);
	// lwz r3,28(r22)
	ctx.r3.u64 = PPC_LOAD_U32(r22.u32 + 28);
	// bl 0x83046848
	sub_83046848(ctx, base);
	// rlwinm. r24,r26,0,25,25
	r24.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// stw r3,72(r27)
	PPC_STORE_U32(r27.u32 + 72, ctx.r3.u32);
	// beq 0x830a3570
	if (cr0.eq) goto loc_830A3570;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a3570
	if (cr6.eq) goto loc_830A3570;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,68(r27)
	PPC_STORE_U32(r27.u32 + 68, r11.u32);
	// b 0x830a3574
	goto loc_830A3574;
loc_830A3570:
	// stw r20,68(r27)
	PPC_STORE_U32(r27.u32 + 68, r20.u32);
loc_830A3574:
	// mr r23,r20
	r23.u64 = r20.u64;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830a35f8
	if (cr6.eq) goto loc_830A35F8;
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x830a3598
	if (!cr6.eq) goto loc_830A3598;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// b 0x830a3728
	goto loc_830A3728;
loc_830A3598:
	// lwz r28,52(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + 52);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830a35ac
	if (cr6.eq) goto loc_830A35AC;
	// lwz r30,16(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// b 0x830a35b0
	goto loc_830A35B0;
loc_830A35AC:
	// mr r30,r20
	r30.u64 = r20.u64;
loc_830A35B0:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83097a98
	sub_83097A98(ctx, base);
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x830a35d8
	if (!cr6.eq) goto loc_830A35D8;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// b 0x830a372c
	goto loc_830A372C;
loc_830A35D8:
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r6,48(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r5,8(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8309ae98
	sub_8309AE98(ctx, base);
	// stw r20,52(r27)
	PPC_STORE_U32(r27.u32 + 52, r20.u32);
	// b 0x830a373c
	goto loc_830A373C;
loc_830A35F8:
	// cmpwi cr6,r25,9
	cr6.compare<int32_t>(r25.s32, 9, xer);
	// beq cr6,0x830a3618
	if (cr6.eq) goto loc_830A3618;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830a3618
	if (cr6.eq) goto loc_830A3618;
	// cmpwi cr6,r25,3
	cr6.compare<int32_t>(r25.s32, 3, xer);
	// beq cr6,0x830a3618
	if (cr6.eq) goto loc_830A3618;
	// cmpwi cr6,r25,4
	cr6.compare<int32_t>(r25.s32, 4, xer);
	// bne cr6,0x830a373c
	if (!cr6.eq) goto loc_830A373C;
loc_830A3618:
	// rlwinm. r11,r26,0,30,30
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a373c
	if (cr0.eq) goto loc_830A373C;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3654
	if (cr0.eq) goto loc_830A3654;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830a3658
	goto loc_830A3658;
loc_830A3654:
	// mr r30,r20
	r30.u64 = r20.u64;
loc_830A3658:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x830a3668
	if (!cr6.eq) goto loc_830A3668;
loc_830A3660:
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// b 0x830a3724
	goto loc_830A3724;
loc_830A3668:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3698
	if (cr0.eq) goto loc_830A3698;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,6
	ctx.r5.s64 = 6;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// b 0x830a369c
	goto loc_830A369C;
loc_830A3698:
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
loc_830A369C:
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a3660
	if (cr6.eq) goto loc_830A3660;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a36cc
	if (cr0.eq) goto loc_830A36CC;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x83049848
	sub_83049848(ctx, base);
	// b 0x830a36d0
	goto loc_830A36D0;
loc_830A36CC:
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
loc_830A36D0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// beq cr6,0x830a3660
	if (cr6.eq) goto loc_830A3660;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3704
	if (cr0.eq) goto loc_830A3704;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// lwz r4,32(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,25560
	ctx.r6.s64 = r11.s64 + 25560;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a3708
	goto loc_830A3708;
loc_830A3704:
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
loc_830A3708:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a3660
	if (cr6.eq) goto loc_830A3660;
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83099758
	sub_83099758(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
loc_830A3724:
	// li r7,1
	ctx.r7.s64 = 1;
loc_830A3728:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_830A372C:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,48(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// stw r3,52(r27)
	PPC_STORE_U32(r27.u32 + 52, ctx.r3.u32);
loc_830A373C:
	// lwz r11,52(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 52);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a3920
	if (cr6.eq) goto loc_830A3920;
	// cmpwi cr6,r25,1
	cr6.compare<int32_t>(r25.s32, 1, xer);
	// bne cr6,0x830a3778
	if (!cr6.eq) goto loc_830A3778;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// mr r8,r18
	ctx.r8.u64 = r18.u64;
	// addi r6,r11,21696
	ctx.r6.s64 = r11.s64 + 21696;
loc_830A3760:
	// li r5,3009
	ctx.r5.s64 = 3009;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a39f4
	goto loc_830A39F4;
loc_830A3778:
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// bne cr6,0x830a37a8
	if (!cr6.eq) goto loc_830A37A8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// bl 0x830979c8
	sub_830979C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a37a8
	if (!cr0.eq) goto loc_830A37A8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r9,r15
	ctx.r9.u64 = r15.u64;
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
	// addi r6,r11,21648
	ctx.r6.s64 = r11.s64 + 21648;
	// b 0x830a3760
	goto loc_830A3760;
loc_830A37A8:
	// rlwinm. r28,r26,0,27,27
	r28.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// bne 0x830a37ec
	if (!cr0.eq) goto loc_830A37EC;
	// rlwinm. r11,r26,0,26,26
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a37ec
	if (cr0.eq) goto loc_830A37EC;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,224
	ctx.r10.s64 = ctx.r1.s64 + 224;
	// addi r8,r1,176
	ctx.r8.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3045
	ctx.r5.s64 = 3045;
	// addi r6,r9,21608
	ctx.r6.s64 = ctx.r9.s64 + 21608;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a387c
	goto loc_830A387C;
loc_830A37EC:
	// andi. r30,r26,80
	r30.u64 = r26.u64 & 80;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x830a383c
	if (cr0.eq) goto loc_830A383C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,52(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 52);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830960a8
	sub_830960A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a383c
	if (!cr0.eq) goto loc_830A383C;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,224
	ctx.r10.s64 = ctx.r1.s64 + 224;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3011
	ctx.r5.s64 = 3011;
	// addi r6,r9,21568
	ctx.r6.s64 = ctx.r9.s64 + 21568;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a387c
	goto loc_830A387C;
loc_830A383C:
	// lwz r11,52(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 52);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a3884
	if (!cr0.eq) goto loc_830A3884;
	// lwz r11,52(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 52);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r6,48(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,8(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x8309ae98
	sub_8309AE98(ctx, base);
loc_830A387C:
	// stw r20,52(r27)
	PPC_STORE_U32(r27.u32 + 52, r20.u32);
	// b 0x830a39a0
	goto loc_830A39A0;
loc_830A3884:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830a389c
	if (cr6.eq) goto loc_830A389C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,52(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 52);
	// bl 0x8309cff8
	sub_8309CFF8(ctx, base);
	// stw r3,56(r27)
	PPC_STORE_U32(r27.u32 + 56, ctx.r3.u32);
loc_830A389C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x830a38d4
	if (!cr6.eq) goto loc_830A38D4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a38d4
	if (cr0.eq) goto loc_830A38D4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,52(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 52);
	// bl 0x8309cff8
	sub_8309CFF8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a38d4
	if (cr0.eq) goto loc_830A38D4;
	// stw r3,52(r27)
	PPC_STORE_U32(r27.u32 + 52, ctx.r3.u32);
	// b 0x830a39a0
	goto loc_830A39A0;
loc_830A38D4:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x830a38e4
	if (!cr6.eq) goto loc_830A38E4;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x830a387c
	if (!cr6.eq) goto loc_830A387C;
loc_830A38E4:
	// lwz r30,52(r27)
	r30.u64 = PPC_LOAD_U32(r27.u32 + 52);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// stw r20,52(r27)
	PPC_STORE_U32(r27.u32 + 52, r20.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8309e720
	sub_8309E720(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r4,26
	ctx.r4.s64 = 26;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8309f590
	sub_8309F590(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// b 0x830a39a0
	goto loc_830A39A0;
loc_830A3920:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830a3930
	if (cr6.eq) goto loc_830A3930;
	// cmpwi cr6,r25,9
	cr6.compare<int32_t>(r25.s32, 9, xer);
	// bne cr6,0x830a394c
	if (!cr6.eq) goto loc_830A394C;
loc_830A3930:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a394c
	if (cr0.eq) goto loc_830A394C;
	// rlwinm. r11,r26,0,30,30
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a3978
	if (!cr0.eq) goto loc_830A3978;
loc_830A394C:
	// cmpwi cr6,r25,3
	cr6.compare<int32_t>(r25.s32, 3, xer);
	// beq cr6,0x830a395c
	if (cr6.eq) goto loc_830A395C;
	// cmpwi cr6,r25,4
	cr6.compare<int32_t>(r25.s32, 4, xer);
	// bne cr6,0x830a3970
	if (!cr6.eq) goto loc_830A3970;
loc_830A395C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a3978
	if (!cr0.eq) goto loc_830A3978;
loc_830A3970:
	// cmpwi cr6,r25,5
	cr6.compare<int32_t>(r25.s32, 5, xer);
	// bne cr6,0x830a39a0
	if (!cr6.eq) goto loc_830A39A0;
loc_830A3978:
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,224
	ctx.r10.s64 = ctx.r1.s64 + 224;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3012
	ctx.r5.s64 = 3012;
	// addi r6,r9,21548
	ctx.r6.s64 = ctx.r9.s64 + 21548;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A39A0:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830a39f8
	if (cr6.eq) goto loc_830A39F8;
	// cmpwi cr6,r25,9
	cr6.compare<int32_t>(r25.s32, 9, xer);
	// beq cr6,0x830a39f8
	if (cr6.eq) goto loc_830A39F8;
	// cmpwi cr6,r25,1
	cr6.compare<int32_t>(r25.s32, 1, xer);
	// beq cr6,0x830a39f8
	if (cr6.eq) goto loc_830A39F8;
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// beq cr6,0x830a39f8
	if (cr6.eq) goto loc_830A39F8;
	// lwz r11,60(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a39f8
	if (cr6.eq) goto loc_830A39F8;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3043
	ctx.r5.s64 = 3043;
	// addi r6,r9,21516
	ctx.r6.s64 = ctx.r9.s64 + 21516;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A39F4:
	// stw r20,52(r27)
	PPC_STORE_U32(r27.u32 + 52, r20.u32);
loc_830A39F8:
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a3a48
	if (cr6.eq) goto loc_830A3A48;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830a3a48
	if (cr6.eq) goto loc_830A3A48;
	// cmpwi cr6,r25,9
	cr6.compare<int32_t>(r25.s32, 9, xer);
	// beq cr6,0x830a3a48
	if (cr6.eq) goto loc_830A3A48;
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// beq cr6,0x830a3a48
	if (cr6.eq) goto loc_830A3A48;
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,3040
	ctx.r5.s64 = 3040;
	// addi r6,r9,21480
	ctx.r6.s64 = ctx.r9.s64 + 21480;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// stw r20,28(r14)
	PPC_STORE_U32(r14.u32 + 28, r20.u32);
loc_830A3A48:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830973b0
	sub_830973B0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a3ac8
	if (cr0.lt) goto loc_830A3AC8;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830a3a84
	if (cr6.eq) goto loc_830A3A84;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830967a0
	sub_830967A0(ctx, base);
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r3.u32);
	// beq 0x830a3ac8
	if (cr0.eq) goto loc_830A3AC8;
loc_830A3A84:
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// b 0x830a3acc
	goto loc_830A3ACC;
loc_830A3A8C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3059
	ctx.r5.s64 = 3059;
	// addi r6,r11,18940
	ctx.r6.s64 = r11.s64 + 18940;
	// b 0x830a3ab8
	goto loc_830A3AB8;
loc_830A3A9C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3073
	ctx.r5.s64 = 3073;
	// addi r6,r11,21428
	ctx.r6.s64 = r11.s64 + 21428;
	// b 0x830a3ab8
	goto loc_830A3AB8;
loc_830A3AAC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3058
	ctx.r5.s64 = 3058;
	// addi r6,r11,18832
	ctx.r6.s64 = r11.s64 + 18832;
loc_830A3AB8:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A3AC8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A3ACC:
	// addi r1,r1,416
	ctx.r1.s64 = ctx.r1.s64 + 416;
	// b 0x82ca2c00
	return;
}

__attribute__((alias("__imp__sub_830A3AD8"))) PPC_WEAK_FUNC(sub_830A3AD8);
PPC_FUNC_IMPL(__imp__sub_830A3AD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bbc
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// li r18,0
	r18.s64 = 0;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r17,r5
	r17.u64 = ctx.r5.u64;
	// stw r18,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r18.u32);
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// lwz r11,24(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 24);
	// mr r19,r7
	r19.u64 = ctx.r7.u64;
	// mr r28,r18
	r28.u64 = r18.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a3b14
	if (cr6.eq) goto loc_830A3B14;
	// lwz r28,8(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_830A3B14:
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x830488a8
	sub_830488A8(ctx, base);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830a3e98
	if (cr6.eq) goto loc_830A3E98;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x830a3e98
	if (cr6.eq) goto loc_830A3E98;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// addi r21,r17,16
	r21.s64 = r17.s64 + 16;
	// lwz r27,24(r28)
	r27.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a3b5c
	if (cr0.eq) goto loc_830A3B5C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,8(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// li r5,3047
	ctx.r5.s64 = 3047;
	// addi r6,r11,22872
	ctx.r6.s64 = r11.s64 + 22872;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A3B5C:
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a3b84
	if (cr0.eq) goto loc_830A3B84;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,8(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// li r5,3006
	ctx.r5.s64 = 3006;
	// addi r6,r11,22828
	ctx.r6.s64 = r11.s64 + 22828;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A3B84:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x830979c8
	sub_830979C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a3bb4
	if (!cr0.eq) goto loc_830A3BB4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,8(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// li r5,3038
	ctx.r5.s64 = 3038;
	// addi r6,r11,22784
	ctx.r6.s64 = r11.s64 + 22784;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A3BB4:
	// mr r30,r18
	r30.u64 = r18.u64;
	// mr r31,r25
	r31.u64 = r25.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830a3c40
	if (cr6.eq) goto loc_830A3C40;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r29,r11,22736
	r29.s64 = r11.s64 + 22736;
loc_830A3BCC:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830a3c34
	if (cr6.eq) goto loc_830A3C34;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x830a3c34
	if (!cr6.eq) goto loc_830A3C34;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a3c0c
	if (cr6.eq) goto loc_830A3C0C;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r9,12
	cr6.compare<int32_t>(ctx.r9.s32, 12, xer);
	// bne cr6,0x830a3c0c
	if (!cr6.eq) goto loc_830A3C0C;
	// li r30,1
	r30.s64 = 1;
	// mr r31,r11
	r31.u64 = r11.u64;
	// b 0x830a3c34
	goto loc_830A3C34;
loc_830A3C0C:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x830a3c34
	if (cr6.eq) goto loc_830A3C34;
	// lwz r11,20(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r5,3044
	ctx.r5.s64 = 3044;
	// lwz r7,8(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A3C34:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x830a3bcc
	if (!cr6.eq) goto loc_830A3BCC;
loc_830A3C40:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3c6c
	if (cr0.eq) goto loc_830A3C6C;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,20620
	ctx.r6.s64 = r11.s64 + 20620;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// b 0x830a3c70
	goto loc_830A3C70;
loc_830A3C6C:
	// mr r20,r18
	r20.u64 = r18.u64;
loc_830A3C70:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x830a3e98
	if (cr6.eq) goto loc_830A3E98;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3ca8
	if (cr0.eq) goto loc_830A3CA8;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x83047398
	sub_83047398(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// b 0x830a3cac
	goto loc_830A3CAC;
loc_830A3CA8:
	// mr r22,r18
	r22.u64 = r18.u64;
loc_830A3CAC:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x830a3e98
	if (cr6.eq) goto loc_830A3E98;
	// stw r22,8(r20)
	PPC_STORE_U32(r20.u32 + 8, r22.u32);
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,20(r22)
	PPC_STORE_U32(r22.u32 + 20, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3e98
	if (cr0.eq) goto loc_830A3E98;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3ce8
	if (cr0.eq) goto loc_830A3CE8;
	// bl 0x83048308
	sub_83048308(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a3cec
	goto loc_830A3CEC;
loc_830A3CE8:
	// mr r31,r18
	r31.u64 = r18.u64;
loc_830A3CEC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830a3e98
	if (cr6.eq) goto loc_830A3E98;
	// stw r31,24(r22)
	PPC_STORE_U32(r22.u32 + 24, r31.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// lwz r3,20(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a3d1c
	if (cr6.eq) goto loc_830A3D1C;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3e98
	if (cr0.eq) goto loc_830A3E98;
loc_830A3D1C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830a3d38
	if (cr6.eq) goto loc_830A3D38;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3e98
	if (cr0.eq) goto loc_830A3E98;
loc_830A3D38:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830a3d54
	if (cr6.eq) goto loc_830A3D54;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,68(r31)
	PPC_STORE_U32(r31.u32 + 68, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3e98
	if (cr0.eq) goto loc_830A3E98;
loc_830A3D54:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83097810
	sub_83097810(ctx, base);
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x830a3de8
	if (cr6.eq) goto loc_830A3DE8;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830a3d98
	if (!cr6.eq) goto loc_830A3D98;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,8(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// li r5,3076
	ctx.r5.s64 = 3076;
	// addi r6,r11,22692
	ctx.r6.s64 = r11.s64 + 22692;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// mr r19,r18
	r19.u64 = r18.u64;
loc_830A3D98:
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x830a3de8
	if (cr6.eq) goto loc_830A3DE8;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,60(r31)
	PPC_STORE_U32(r31.u32 + 60, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3e98
	if (cr0.eq) goto loc_830A3E98;
loc_830A3DB4:
	// lwz r3,8(r19)
	ctx.r3.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a3ddc
	if (cr6.eq) goto loc_830A3DDC;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x830a3ddc
	if (!cr6.eq) goto loc_830A3DDC;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,56(r31)
	PPC_STORE_U32(r31.u32 + 56, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3e98
	if (cr0.eq) goto loc_830A3E98;
loc_830A3DDC:
	// lwz r19,12(r19)
	r19.u64 = PPC_LOAD_U32(r19.u32 + 12);
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// bne cr6,0x830a3db4
	if (!cr6.eq) goto loc_830A3DB4;
loc_830A3DE8:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830a3e10
	if (cr6.eq) goto loc_830A3E10;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a3e10
	if (cr6.eq) goto loc_830A3E10;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3e98
	if (cr0.eq) goto loc_830A3E98;
loc_830A3E10:
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// addi r10,r1,132
	ctx.r10.s64 = ctx.r1.s64 + 132;
	// lwz r6,36(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// li r9,10
	ctx.r9.s64 = 10;
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// lwz r7,44(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r8,32(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bl 0x8309d768
	sub_8309D768(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830a3e58
	if (!cr0.lt) goto loc_830A3E58;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3003
	ctx.r5.s64 = 3003;
	// addi r6,r11,17316
	ctx.r6.s64 = r11.s64 + 17316;
	// b 0x830a3e88
	goto loc_830A3E88;
loc_830A3E58:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lwz r23,132(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bne cr6,0x830a40b8
	if (!cr6.eq) goto loc_830A40B8;
	// lwz r5,40(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 40);
	// bl 0x83095a00
	sub_83095A00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a3ea4
	if (!cr0.eq) goto loc_830A3EA4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3068
	ctx.r5.s64 = 3068;
	// addi r6,r11,22640
	ctx.r6.s64 = r11.s64 + 22640;
loc_830A3E88:
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// lwz r7,8(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A3E98:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A3E9C:
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// b 0x82ca2c0c
	return;
loc_830A3EA4:
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// mr r26,r18
	r26.u64 = r18.u64;
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r25,r18
	r25.u64 = r18.u64;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r11,40(r22)
	PPC_STORE_U32(r22.u32 + 40, r11.u32);
	// lwz r29,44(r23)
	r29.u64 = PPC_LOAD_U32(r23.u32 + 44);
	// lwz r30,44(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// b 0x830a4044
	goto loc_830A4044;
loc_830A3ED8:
	// lwz r27,8(r29)
	r27.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830a40ac
	if (cr6.eq) goto loc_830A40AC;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// bne cr6,0x830a3f84
	if (!cr6.eq) goto loc_830A3F84;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830a3f10
	if (cr6.eq) goto loc_830A3F10;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a3f10
	if (cr6.eq) goto loc_830A3F10;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// beq cr6,0x830a3f64
	if (cr6.eq) goto loc_830A3F64;
loc_830A3F10:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x830a3e98
	if (cr0.eq) goto loc_830A3E98;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3f50
	if (cr0.eq) goto loc_830A3F50;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r6,16(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a3f54
	goto loc_830A3F54;
loc_830A3F50:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
loc_830A3F54:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a3e98
	if (cr6.eq) goto loc_830A3E98;
	// stw r3,12(r25)
	PPC_STORE_U32(r25.u32 + 12, ctx.r3.u32);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_830A3F64:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r3,36(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	// lwz r4,36(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// bl 0x83046820
	sub_83046820(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a4050
	if (cr0.eq) goto loc_830A4050;
loc_830A3F84:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830a3e98
	if (cr6.eq) goto loc_830A3E98;
	// lwz r28,8(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830a3e98
	if (cr6.eq) goto loc_830A3E98;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// bne cr6,0x830a3fdc
	if (!cr6.eq) goto loc_830A3FDC;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// beq cr6,0x830a403c
	if (cr6.eq) goto loc_830A403C;
	// mr r29,r26
	r29.u64 = r26.u64;
	// b 0x830a403c
	goto loc_830A403C;
loc_830A3FDC:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r5,20(r24)
	ctx.r5.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// bl 0x83095820
	sub_83095820(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3e98
	if (cr0.eq) goto loc_830A3E98;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a3e98
	if (cr6.eq) goto loc_830A3E98;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r26,r29
	r26.u64 = r29.u64;
	// lwz r9,24(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// mr r25,r30
	r25.u64 = r30.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// stw r8,16(r9)
	PPC_STORE_U32(ctx.r9.u32 + 16, ctx.r8.u32);
	// stw r8,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r8.u32);
	// lwz r8,24(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// stw r8,24(r9)
	PPC_STORE_U32(ctx.r9.u32 + 24, ctx.r8.u32);
	// stw r8,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r8.u32);
	// lwz r10,28(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// stw r10,28(r9)
	PPC_STORE_U32(ctx.r9.u32 + 28, ctx.r10.u32);
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
loc_830A403C:
	// lwz r29,12(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
loc_830A4044:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x830a3ed8
	if (!cr6.eq) goto loc_830A3ED8;
	// b 0x830a40ac
	goto loc_830A40AC;
loc_830A4050:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,3068
	ctx.r5.s64 = 3068;
	// lwz r7,8(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r6,r10,22576
	ctx.r6.s64 = ctx.r10.s64 + 22576;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a3e98
	goto loc_830A3E98;
loc_830A407C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a40d4
	if (cr6.eq) goto loc_830A40D4;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
loc_830A40AC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x830a407c
	if (!cr6.eq) goto loc_830A407C;
	// b 0x830a40d4
	goto loc_830A40D4;
loc_830A40B8:
	// lwz r11,104(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 104);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// bl 0x83097a98
	sub_83097A98(ctx, base);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// lwz r11,104(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 104);
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// stw r11,104(r24)
	PPC_STORE_U32(r24.u32 + 104, r11.u32);
loc_830A40D4:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r10,3
	ctx.r10.s64 = 3;
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r10,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r10.u32);
	// stw r18,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, r18.u32);
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r11.u32);
	// lwz r3,40(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r3.u32);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r3.u32);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r4,192(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// beq cr6,0x830a4120
	if (cr6.eq) goto loc_830A4120;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830a3e98
	if (cr6.eq) goto loc_830A3E98;
loc_830A4120:
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x830a4130
	if (cr6.eq) goto loc_830A4130;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a3e98
	if (cr6.eq) goto loc_830A3E98;
loc_830A4130:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83097810
	sub_83097810(ctx, base);
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8309e720
	sub_8309E720(ctx, base);
	// stw r3,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a3e98
	if (cr0.eq) goto loc_830A3E98;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// bne cr6,0x830a4194
	if (!cr6.eq) goto loc_830A4194;
	// lwz r30,20(r24)
	r30.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// stw r11,20(r24)
	PPC_STORE_U32(r24.u32 + 20, r11.u32);
	// bl 0x830973b0
	sub_830973B0(ctx, base);
	// stw r30,20(r24)
	PPC_STORE_U32(r24.u32 + 20, r30.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a3e98
	if (cr0.lt) goto loc_830A3E98;
	// lwz r11,100(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 100);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,100(r24)
	PPC_STORE_U32(r24.u32 + 100, r11.u32);
loc_830A4194:
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// lwz r10,20(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// stw r11,20(r10)
	PPC_STORE_U32(ctx.r10.u32 + 20, r11.u32);
	// stw r31,32(r24)
	PPC_STORE_U32(r24.u32 + 32, r31.u32);
	// b 0x830a3e9c
	goto loc_830A3E9C;
}

__attribute__((alias("__imp__sub_830A41B0"))) PPC_WEAK_FUNC(sub_830A41B0);
PPC_FUNC_IMPL(__imp__sub_830A41B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r14,0
	r14.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r16,r14
	r16.u64 = r14.u64;
	// stw r14,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r14.u32);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// stw r14,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r14.u32);
	// mr r17,r5
	r17.u64 = ctx.r5.u64;
	// stw r16,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r16.u32);
	// mr r15,r6
	r15.u64 = ctx.r6.u64;
	// stw r14,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r14.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r14,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r14.u32);
	// stw r14,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r14.u32);
	// beq cr6,0x830a47f0
	if (cr6.eq) goto loc_830A47F0;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x830a47f0
	if (!cr6.eq) goto loc_830A47F0;
	// lwz r11,32(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 32);
	// addi r18,r29,16
	r18.s64 = r29.s64 + 16;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a4218
	if (cr6.eq) goto loc_830A4218;
	// lwz r6,36(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// b 0x830a421c
	goto loc_830A421C;
loc_830A4218:
	// mr r6,r14
	ctx.r6.u64 = r14.u64;
loc_830A421C:
	// li r9,6
	ctx.r9.s64 = 6;
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x830a422c
	if (cr6.eq) goto loc_830A422C;
	// li r9,22
	ctx.r9.s64 = 22;
loc_830A422C:
	// addi r11,r1,148
	r11.s64 = ctx.r1.s64 + 148;
	// lwz r8,20(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// addi r10,r1,152
	ctx.r10.s64 = ctx.r1.s64 + 152;
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mr r31,r14
	r31.u64 = r14.u64;
	// bl 0x8309d768
	sub_8309D768(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a47d8
	if (cr0.lt) goto loc_830A47D8;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830a4268
	if (!cr6.eq) goto loc_830A4268;
	// li r31,1
	r31.s64 = 1;
loc_830A4268:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// addi r30,r11,-3408
	r30.s64 = r11.s64 + -3408;
	// bne cr6,0x830a42bc
	if (!cr6.eq) goto loc_830A42BC;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x830a43a8
	if (!cr6.eq) goto loc_830A43A8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r10,r1,148
	ctx.r10.s64 = ctx.r1.s64 + 148;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,101
	ctx.r5.s64 = 101;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83099af0
	sub_83099AF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a47d8
	if (cr0.lt) goto loc_830A47D8;
	// lwz r16,144(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830a42c4
	if (!cr6.eq) goto loc_830A42C4;
	// li r31,1
	r31.s64 = 1;
loc_830A42BC:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x830a4304
	if (!cr6.eq) goto loc_830A4304;
loc_830A42C4:
	// addi r11,r1,148
	r11.s64 = ctx.r1.s64 + 148;
	// lwz r8,20(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// addi r10,r1,152
	ctx.r10.s64 = ctx.r1.s64 + 152;
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309d768
	sub_8309D768(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a47d8
	if (cr0.lt) goto loc_830A47D8;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830a4304
	if (!cr6.eq) goto loc_830A4304;
	// li r31,1
	r31.s64 = 1;
loc_830A4304:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// bne cr6,0x830a4350
	if (!cr6.eq) goto loc_830A4350;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x830a439c
	if (!cr6.eq) goto loc_830A439C;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r10,r1,148
	ctx.r10.s64 = ctx.r1.s64 + 148;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,101
	ctx.r5.s64 = 101;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83099af0
	sub_83099AF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a47d8
	if (cr0.lt) goto loc_830A47D8;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830a4358
	if (!cr6.eq) goto loc_830A4358;
	// lwz r16,144(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r31,1
	r31.s64 = 1;
loc_830A4350:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x830a439c
	if (!cr6.eq) goto loc_830A439C;
loc_830A4358:
	// addi r6,r1,164
	ctx.r6.s64 = ctx.r1.s64 + 164;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830c2f60
	sub_830C2F60(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a47d8
	if (cr0.lt) goto loc_830A47D8;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x830a47e8
	if (cr6.eq) goto loc_830A47E8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,8(r18)
	ctx.r7.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// li r5,3004
	ctx.r5.s64 = 3004;
	// addi r6,r11,18688
	ctx.r6.s64 = r11.s64 + 18688;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a47d8
	goto loc_830A47D8;
loc_830A439C:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// mr r19,r16
	r19.u64 = r16.u64;
	// bne cr6,0x830a43ac
	if (!cr6.eq) goto loc_830A43AC;
loc_830A43A8:
	// lwz r19,152(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
loc_830A43AC:
	// lwz r24,44(r19)
	r24.u64 = PPC_LOAD_U32(r19.u32 + 44);
	// addi r23,r1,156
	r23.s64 = ctx.r1.s64 + 156;
	// addi r22,r1,160
	r22.s64 = ctx.r1.s64 + 160;
	// mr r25,r17
	r25.u64 = r17.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830a4608
	if (cr6.eq) goto loc_830A4608;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// addi r21,r11,23020
	r21.s64 = r11.s64 + 23020;
	// addi r20,r10,-23184
	r20.s64 = ctx.r10.s64 + -23184;
loc_830A43D4:
	// lwz r11,12(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
	// lwz r27,8(r24)
	r27.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a4400
	if (cr6.eq) goto loc_830A4400;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r9,12
	cr6.compare<int32_t>(ctx.r9.s32, 12, xer);
	// bne cr6,0x830a4400
	if (!cr6.eq) goto loc_830A4400;
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r24,r11
	r24.u64 = r11.u64;
loc_830A4400:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x830a4418
	if (cr6.eq) goto loc_830A4418;
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a45fc
	if (cr0.eq) goto loc_830A45FC;
loc_830A4418:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830a45f4
	if (cr6.eq) goto loc_830A45F4;
	// lwz r28,24(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r30,48(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// beq cr6,0x830a443c
	if (cr6.eq) goto loc_830A443C;
	// lwz r29,16(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// b 0x830a4440
	goto loc_830A4440;
loc_830A443C:
	// mr r29,r14
	r29.u64 = r14.u64;
loc_830A4440:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4464
	if (cr0.eq) goto loc_830A4464;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a4468
	goto loc_830A4468;
loc_830A4464:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
loc_830A4468:
	// stw r3,0(r23)
	PPC_STORE_U32(r23.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a47d8
	if (cr6.eq) goto loc_830A47D8;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4498
	if (cr0.eq) goto loc_830A4498;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a449c
	goto loc_830A449C;
loc_830A4498:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
loc_830A449C:
	// stw r3,0(r22)
	PPC_STORE_U32(r22.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a47d8
	if (cr6.eq) goto loc_830A47D8;
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a4544
	if (cr0.eq) goto loc_830A4544;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// beq 0x830a4658
	if (cr0.eq) goto loc_830A4658;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,8(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x830a47d8
	if (cr0.eq) goto loc_830A47D8;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x830a4504
	if (cr6.eq) goto loc_830A4504;
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// stw r31,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r31.u32);
	// b 0x830a4544
	goto loc_830A4544;
loc_830A4504:
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r4,20(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309e720
	sub_8309E720(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x830a47d8
	if (cr0.eq) goto loc_830A47D8;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309f590
	sub_8309F590(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a47d8
	if (cr0.eq) goto loc_830A47D8;
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
loc_830A4544:
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a45dc
	if (cr0.eq) goto loc_830A45DC;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a4664
	if (!cr0.eq) goto loc_830A4664;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a4664
	if (cr0.eq) goto loc_830A4664;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r4,20(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309e720
	sub_8309E720(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x830a47d8
	if (cr0.eq) goto loc_830A47D8;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// mr. r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x830a47d8
	if (cr0.eq) goto loc_830A47D8;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r5,8(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309f590
	sub_8309F590(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a47d8
	if (cr0.eq) goto loc_830A47D8;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
loc_830A45DC:
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// lwz r10,0(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// lwz r25,12(r25)
	r25.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r23,r11,12
	r23.s64 = r11.s64 + 12;
	// addi r22,r10,12
	r22.s64 = ctx.r10.s64 + 12;
	// b 0x830a45fc
	goto loc_830A45FC;
loc_830A45F4:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x830a4610
	if (cr6.eq) goto loc_830A4610;
loc_830A45FC:
	// lwz r24,12(r24)
	r24.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x830a43d4
	if (!cr6.eq) goto loc_830A43D4;
loc_830A4608:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x830a4750
	if (!cr6.eq) goto loc_830A4750;
loc_830A4610:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x830a4750
	if (!cr6.eq) goto loc_830A4750;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4684
	if (cr0.eq) goto loc_830A4684;
	// cntlzw r11,r16
	r11.u64 = r16.u32 == 0 ? 32 : __builtin_clz(r16.u32);
	// mr r9,r18
	ctx.r9.u64 = r18.u64;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r8,1
	ctx.r8.s64 = 1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,31
	ctx.r5.s64 = r11.s64 + 31;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a4688
	goto loc_830A4688;
loc_830A4658:
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// b 0x830a4670
	goto loc_830A4670;
loc_830A4664:
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_830A4670:
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// lwz r5,8(r18)
	ctx.r5.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x8309ae98
	sub_8309AE98(ctx, base);
	// b 0x830a47d8
	goto loc_830A47D8;
loc_830A4684:
	// mr r31,r14
	r31.u64 = r14.u64;
loc_830A4688:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830a47d8
	if (cr6.eq) goto loc_830A47D8;
	// lwz r11,40(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a46bc
	if (cr6.eq) goto loc_830A46BC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a47d8
	if (cr0.eq) goto loc_830A47D8;
loc_830A46BC:
	// lwz r11,148(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a46ec
	if (cr0.eq) goto loc_830A46EC;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,6548
	ctx.r6.s64 = r11.s64 + 6548;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a46f0
	goto loc_830A46F0;
loc_830A46EC:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
loc_830A46F0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r3.u32);
	// beq cr6,0x830a47d8
	if (cr6.eq) goto loc_830A47D8;
	// lwz r11,156(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// bl 0x83099758
	sub_83099758(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830960a8
	sub_830960A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a47dc
	if (cr0.eq) goto loc_830A47DC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8309cff8
	sub_8309CFF8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a47dc
	if (cr0.eq) goto loc_830A47DC;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a47dc
	goto loc_830A47DC;
loc_830A4750:
	// mr r8,r14
	ctx.r8.u64 = r14.u64;
	// mr r11,r17
	r11.u64 = r17.u64;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x830a4770
	if (cr6.eq) goto loc_830A4770;
loc_830A4760:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830a4760
	if (!cr6.eq) goto loc_830A4760;
loc_830A4770:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x830a47a0
	if (!cr6.eq) goto loc_830A47A0;
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// beq cr6,0x830a478c
	if (cr6.eq) goto loc_830A478C;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r9,r11,3044
	ctx.r9.s64 = r11.s64 + 3044;
	// b 0x830a4794
	goto loc_830A4794;
loc_830A478C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r9,r11,3224
	ctx.r9.s64 = r11.s64 + 3224;
loc_830A4794:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,22976
	ctx.r6.s64 = r11.s64 + 22976;
	// b 0x830a47c4
	goto loc_830A47C4;
loc_830A47A0:
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// beq cr6,0x830a47b4
	if (cr6.eq) goto loc_830A47B4;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r9,r11,3044
	ctx.r9.s64 = r11.s64 + 3044;
	// b 0x830a47bc
	goto loc_830A47BC;
loc_830A47B4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r9,r11,3224
	ctx.r9.s64 = r11.s64 + 3224;
loc_830A47BC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,22920
	ctx.r6.s64 = r11.s64 + 22920;
loc_830A47C4:
	// li r5,3013
	ctx.r5.s64 = 3013;
	// lwz r7,8(r18)
	ctx.r7.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A47D8:
	// mr r31,r14
	r31.u64 = r14.u64;
loc_830A47DC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x830a47f4
	if (!cr6.eq) goto loc_830A47F4;
loc_830A47E8:
	// lwz r3,164(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// b 0x830a47f4
	goto loc_830A47F4;
loc_830A47F0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A47F4:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// b 0x82ca2c00
	return;
}

__attribute__((alias("__imp__sub_830A4800"))) PPC_WEAK_FUNC(sub_830A4800);
PPC_FUNC_IMPL(__imp__sub_830A4800) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb8
	// stwu r1,-560(r1)
	ea = -560 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// mr r16,r4
	r16.u64 = ctx.r4.u64;
	// mr r18,r6
	r18.u64 = ctx.r6.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830a4e08
	if (cr6.eq) goto loc_830A4E08;
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x830a4e08
	if (!cr6.eq) goto loc_830A4E08;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x830a4e08
	if (cr6.eq) goto loc_830A4E08;
	// lwz r11,4(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x830a4e08
	if (!cr6.eq) goto loc_830A4E08;
	// lwz r29,16(r16)
	r29.u64 = PPC_LOAD_U32(r16.u32 + 16);
	// li r17,0
	r17.s64 = 0;
	// addi r20,r5,16
	r20.s64 = ctx.r5.s64 + 16;
	// stw r17,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r17.u32);
	// mr r31,r17
	r31.u64 = r17.u64;
	// stw r17,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r17.u32);
	// mr r30,r17
	r30.u64 = r17.u64;
	// stw r17,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r17.u32);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// stw r17,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r17.u32);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// bgt cr6,0x830a4914
	if (cr6.gt) goto loc_830A4914;
	// beq cr6,0x830a4900
	if (cr6.eq) goto loc_830A4900;
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// beq cr6,0x830a48ec
	if (cr6.eq) goto loc_830A48EC;
	// cmpwi cr6,r11,26
	cr6.compare<int32_t>(r11.s32, 26, xer);
	// beq cr6,0x830a48d8
	if (cr6.eq) goto loc_830A48D8;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// beq cr6,0x830a48c4
	if (cr6.eq) goto loc_830A48C4;
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// beq cr6,0x830a48b0
	if (cr6.eq) goto loc_830A48B0;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x830a4980
	if (!cr6.eq) goto loc_830A4980;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r30,14
	r30.s64 = 14;
	// addi r11,r11,19624
	r11.s64 = r11.s64 + 19624;
	// addi r31,r11,15048
	r31.s64 = r11.s64 + 15048;
	// b 0x830a4980
	goto loc_830A4980;
loc_830A48B0:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r30,14
	r30.s64 = 14;
	// addi r11,r11,19624
	r11.s64 = r11.s64 + 19624;
	// addi r31,r11,11856
	r31.s64 = r11.s64 + 11856;
	// b 0x830a4980
	goto loc_830A4980;
loc_830A48C4:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r30,18
	r30.s64 = 18;
	// addi r11,r11,19624
	r11.s64 = r11.s64 + 19624;
	// addi r31,r11,7752
	r31.s64 = r11.s64 + 7752;
	// b 0x830a4980
	goto loc_830A4980;
loc_830A48D8:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r30,14
	r30.s64 = 14;
	// addi r11,r11,19624
	r11.s64 = r11.s64 + 19624;
	// addi r31,r11,4560
	r31.s64 = r11.s64 + 4560;
	// b 0x830a4980
	goto loc_830A4980;
loc_830A48EC:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r30,18
	r30.s64 = 18;
	// addi r11,r11,19624
	r11.s64 = r11.s64 + 19624;
	// addi r31,r11,456
	r31.s64 = r11.s64 + 456;
	// b 0x830a4980
	goto loc_830A4980;
loc_830A4900:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r30,12
	r30.s64 = 12;
	// addi r11,r11,19624
	r11.s64 = r11.s64 + 19624;
	// addi r31,r11,18240
	r31.s64 = r11.s64 + 18240;
	// b 0x830a4980
	goto loc_830A4980;
loc_830A4914:
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// beq cr6,0x830a4970
	if (cr6.eq) goto loc_830A4970;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// beq cr6,0x830a4960
	if (cr6.eq) goto loc_830A4960;
	// cmpwi cr6,r11,39
	cr6.compare<int32_t>(r11.s32, 39, xer);
	// beq cr6,0x830a494c
	if (cr6.eq) goto loc_830A494C;
	// cmpwi cr6,r11,50
	cr6.compare<int32_t>(r11.s32, 50, xer);
	// ble cr6,0x830a4980
	if (!cr6.gt) goto loc_830A4980;
	// cmpwi cr6,r11,53
	cr6.compare<int32_t>(r11.s32, 53, xer);
	// bgt cr6,0x830a4980
	if (cr6.gt) goto loc_830A4980;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r30,2
	r30.s64 = 2;
	// addi r31,r11,19624
	r31.s64 = r11.s64 + 19624;
	// b 0x830a4980
	goto loc_830A4980;
loc_830A494C:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r30,1
	r30.s64 = 1;
	// addi r11,r11,19624
	r11.s64 = r11.s64 + 19624;
	// addi r31,r11,20976
	r31.s64 = r11.s64 + 20976;
	// b 0x830a4980
	goto loc_830A4980;
loc_830A4960:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r11,r11,19624
	r11.s64 = r11.s64 + 19624;
	// addi r31,r11,22120
	r31.s64 = r11.s64 + 22120;
	// b 0x830a497c
	goto loc_830A497C;
loc_830A4970:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r11,r11,19624
	r11.s64 = r11.s64 + 19624;
	// addi r31,r11,21208
	r31.s64 = r11.s64 + 21208;
loc_830A497C:
	// li r30,4
	r30.s64 = 4;
loc_830A4980:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r5,255
	ctx.r5.s64 = 255;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83097b80
	sub_83097B80(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bne cr6,0x830a49b0
	if (!cr6.eq) goto loc_830A49B0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3087
	ctx.r5.s64 = 3087;
	// addi r6,r11,23188
	ctx.r6.s64 = r11.s64 + 23188;
	// b 0x830a4a38
	goto loc_830A4A38;
loc_830A49B0:
	// addi r10,r1,148
	ctx.r10.s64 = ctx.r1.s64 + 148;
	// lwz r6,24(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r8,r18
	ctx.r8.u64 = r18.u64;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x83099af0
	sub_83099AF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a4e08
	if (cr0.lt) goto loc_830A4E08;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x830a4a4c
	if (cr6.eq) goto loc_830A4A4C;
	// addi r10,r1,148
	ctx.r10.s64 = ctx.r1.s64 + 148;
	// lwz r6,24(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83099af0
	sub_83099AF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a4e08
	if (cr0.lt) goto loc_830A4E08;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r5,3088
	ctx.r5.s64 = 3088;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bne cr6,0x830a4a30
	if (!cr6.eq) goto loc_830A4A30;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,8(r20)
	ctx.r7.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// addi r6,r11,23132
	ctx.r6.s64 = r11.s64 + 23132;
	// b 0x830a4a40
	goto loc_830A4A40;
loc_830A4A30:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23096
	ctx.r6.s64 = r11.s64 + 23096;
loc_830A4A38:
	// lwz r8,8(r20)
	ctx.r8.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
loc_830A4A40:
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a4e08
	goto loc_830A4E08;
loc_830A4A4C:
	// lwz r21,144(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addi r25,r1,152
	r25.s64 = ctx.r1.s64 + 152;
	// addi r24,r1,156
	r24.s64 = ctx.r1.s64 + 156;
	// mr r28,r18
	r28.u64 = r18.u64;
	// lwz r26,44(r21)
	r26.u64 = PPC_LOAD_U32(r21.u32 + 44);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830a4c40
	if (cr6.eq) goto loc_830A4C40;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// addi r23,r11,23020
	r23.s64 = r11.s64 + 23020;
	// addi r22,r10,-23184
	r22.s64 = ctx.r10.s64 + -23184;
loc_830A4A78:
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// lwz r27,8(r26)
	r27.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a4aa4
	if (cr6.eq) goto loc_830A4AA4;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r9,12
	cr6.compare<int32_t>(ctx.r9.s32, 12, xer);
	// bne cr6,0x830a4aa4
	if (!cr6.eq) goto loc_830A4AA4;
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r26,r11
	r26.u64 = r11.u64;
loc_830A4AA4:
	// lwz r29,24(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830a4c2c
	if (cr6.eq) goto loc_830A4C2C;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r30,48(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a4ac8
	if (cr6.eq) goto loc_830A4AC8;
	// lwz r31,16(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// b 0x830a4acc
	goto loc_830A4ACC;
loc_830A4AC8:
	// mr r31,r17
	r31.u64 = r17.u64;
loc_830A4ACC:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4af0
	if (cr0.eq) goto loc_830A4AF0;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a4af4
	goto loc_830A4AF4;
loc_830A4AF0:
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
loc_830A4AF4:
	// stw r3,0(r25)
	PPC_STORE_U32(r25.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a4e08
	if (cr6.eq) goto loc_830A4E08;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4b24
	if (cr0.eq) goto loc_830A4B24;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a4b28
	goto loc_830A4B28;
loc_830A4B24:
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
loc_830A4B28:
	// stw r3,0(r24)
	PPC_STORE_U32(r24.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a4e08
	if (cr6.eq) goto loc_830A4E08;
	// lwz r11,44(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a4b7c
	if (cr0.eq) goto loc_830A4B7C;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// beq 0x830a4c84
	if (cr0.eq) goto loc_830A4C84;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,8(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
loc_830A4B7C:
	// lwz r11,44(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a4c14
	if (cr0.eq) goto loc_830A4C14;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x830978f8
	sub_830978F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a4c90
	if (!cr0.eq) goto loc_830A4C90;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8309aa48
	sub_8309AA48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a4c90
	if (cr0.eq) goto loc_830A4C90;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,20(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8309e720
	sub_8309E720(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x830a4e08
	if (cr0.eq) goto loc_830A4E08;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// mr. r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x830a4e08
	if (cr0.eq) goto loc_830A4E08;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r5,8(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8309f590
	sub_8309F590(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4e08
	if (cr0.eq) goto loc_830A4E08;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
loc_830A4C14:
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// lwz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// lwz r28,12(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// addi r25,r11,12
	r25.s64 = r11.s64 + 12;
	// addi r24,r10,12
	r24.s64 = ctx.r10.s64 + 12;
	// b 0x830a4c34
	goto loc_830A4C34;
loc_830A4C2C:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x830a4c48
	if (cr6.eq) goto loc_830A4C48;
loc_830A4C34:
	// lwz r26,12(r26)
	r26.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x830a4a78
	if (!cr6.eq) goto loc_830A4A78;
loc_830A4C40:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x830a4db0
	if (!cr6.eq) goto loc_830A4DB0;
loc_830A4C48:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x830a4db0
	if (!cr6.eq) goto loc_830A4DB0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4cb0
	if (cr0.eq) goto loc_830A4CB0;
	// mr r9,r20
	ctx.r9.u64 = r20.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,33
	ctx.r5.s64 = 33;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830a4cb4
	goto loc_830A4CB4;
loc_830A4C84:
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// b 0x830a4c9c
	goto loc_830A4C9C;
loc_830A4C90:
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
loc_830A4C9C:
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// lwz r5,8(r20)
	ctx.r5.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x8309ae98
	sub_8309AE98(ctx, base);
	// b 0x830a4e08
	goto loc_830A4E08;
loc_830A4CB0:
	// mr r30,r17
	r30.u64 = r17.u64;
loc_830A4CB4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830a4e08
	if (cr6.eq) goto loc_830A4E08;
	// lwz r11,40(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a4ce8
	if (cr6.eq) goto loc_830A4CE8;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4e08
	if (cr0.eq) goto loc_830A4E08;
loc_830A4CE8:
	// lwz r11,0(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 0);
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4e08
	if (cr0.eq) goto loc_830A4E08;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4d34
	if (cr0.eq) goto loc_830A4D34;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,6548
	ctx.r6.s64 = r11.s64 + 6548;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a4d38
	goto loc_830A4D38;
loc_830A4D34:
	// mr r31,r17
	r31.u64 = r17.u64;
loc_830A4D38:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830a4e08
	if (cr6.eq) goto loc_830A4E08;
	// lwz r11,152(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// li r3,20
	ctx.r3.s64 = 20;
	// lwz r10,156(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r10,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r10.u32);
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4d7c
	if (cr0.eq) goto loc_830A4D7C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,23072
	ctx.r6.s64 = r11.s64 + 23072;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x830a4d80
	goto loc_830A4D80;
loc_830A4D7C:
	// mr r11,r17
	r11.u64 = r17.u64;
loc_830A4D80:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,36(r30)
	PPC_STORE_U32(r30.u32 + 36, r11.u32);
	// beq cr6,0x830a4e08
	if (cr6.eq) goto loc_830A4E08;
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// stw r31,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r31.u32);
	// bl 0x83099758
	sub_83099758(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x830a4e0c
	goto loc_830A4E0C;
loc_830A4DB0:
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
	// mr r11,r18
	r11.u64 = r18.u64;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x830a4dd8
	if (cr6.eq) goto loc_830A4DD8;
loc_830A4DC0:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830a4dc0
	if (!cr6.eq) goto loc_830A4DC0;
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// beq cr6,0x830a4de4
	if (cr6.eq) goto loc_830A4DE4;
loc_830A4DD8:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r9,r11,3044
	ctx.r9.s64 = r11.s64 + 3044;
	// b 0x830a4dec
	goto loc_830A4DEC;
loc_830A4DE4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r9,r11,3224
	ctx.r9.s64 = r11.s64 + 3224;
loc_830A4DEC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,8(r20)
	ctx.r7.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// li r5,3013
	ctx.r5.s64 = 3013;
	// addi r6,r11,23028
	ctx.r6.s64 = r11.s64 + 23028;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A4E08:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A4E0C:
	// addi r1,r1,560
	ctx.r1.s64 = ctx.r1.s64 + 560;
	// b 0x82ca2c08
	return;
}

__attribute__((alias("__imp__sub_830A4E18"))) PPC_WEAK_FUNC(sub_830A4E18);
PPC_FUNC_IMPL(__imp__sub_830A4E18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r31,r8
	r31.u64 = ctx.r8.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830a4e84
	if (cr6.eq) goto loc_830A4E84;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830a4e84
	if (cr6.eq) goto loc_830A4E84;
	// addi r5,r1,136
	ctx.r5.s64 = ctx.r1.s64 + 136;
	// lwz r3,24(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// li r4,2
	ctx.r4.s64 = 2;
	// addi r24,r29,16
	r24.s64 = r29.s64 + 16;
	// bl 0x8301d1e0
	sub_8301D1E0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830a4e90
	if (!cr0.lt) goto loc_830A4E90;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,8(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// li r5,3041
	ctx.r5.s64 = 3041;
	// addi r6,r11,23220
	ctx.r6.s64 = r11.s64 + 23220;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A4E84:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A4E88:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c24
	return;
loc_830A4E90:
	// lwz r11,140(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// rlwinm r11,r11,0,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830a4ec4
	if (cr6.eq) goto loc_830A4EC4;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830a4ed8
	if (!cr6.eq) goto loc_830A4ED8;
	// subfic r11,r31,0
	xer.ca = r31.u32 <= 0;
	r11.s64 = 0 - r31.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// addi r28,r11,42
	r28.s64 = r11.s64 + 42;
	// b 0x830a4edc
	goto loc_830A4EDC;
loc_830A4EC4:
	// subfic r11,r31,0
	xer.ca = r31.u32 <= 0;
	r11.s64 = 0 - r31.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// addi r28,r11,43
	r28.s64 = r11.s64 + 43;
	// b 0x830a4edc
	goto loc_830A4EDC;
loc_830A4ED8:
	// lwz r28,128(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_830A4EDC:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4f10
	if (cr0.eq) goto loc_830A4F10;
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,34
	ctx.r5.s64 = 34;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830a4f14
	goto loc_830A4F14;
loc_830A4F10:
	// li r30,0
	r30.s64 = 0;
loc_830A4F14:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830a4e84
	if (cr6.eq) goto loc_830A4E84;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4f4c
	if (cr0.eq) goto loc_830A4F4C;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// b 0x830a4f50
	goto loc_830A4F50;
loc_830A4F4C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A4F50:
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a4e84
	if (cr6.eq) goto loc_830A4E84;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83046848
	sub_83046848(ctx, base);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4e84
	if (cr0.eq) goto loc_830A4E84;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x830a41b0
	sub_830A41B0(ctx, base);
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4e84
	if (cr0.eq) goto loc_830A4E84;
	// stw r25,44(r30)
	PPC_STORE_U32(r30.u32 + 44, r25.u32);
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a4fc8
	if (cr0.eq) goto loc_830A4FC8;
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a4fcc
	goto loc_830A4FCC;
loc_830A4FC8:
	// li r31,0
	r31.s64 = 0;
loc_830A4FCC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830a4e84
	if (cr6.eq) goto loc_830A4E84;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5004
	if (cr0.eq) goto loc_830A5004;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// b 0x830a5008
	goto loc_830A5008;
loc_830A5004:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A5008:
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a4e84
	if (cr6.eq) goto loc_830A4E84;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a503c
	if (cr0.eq) goto loc_830A503C;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,25560
	ctx.r6.s64 = r11.s64 + 25560;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a5040
	goto loc_830A5040;
loc_830A503C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A5040:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq cr6,0x830a4e84
	if (cr6.eq) goto loc_830A4E84;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5070
	if (cr0.eq) goto loc_830A5070;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x83049848
	sub_83049848(ctx, base);
	// b 0x830a5074
	goto loc_830A5074;
loc_830A5070:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A5074:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// beq cr6,0x830a4e84
	if (cr6.eq) goto loc_830A4E84;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x83099758
	sub_83099758(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x830a4e88
	goto loc_830A4E88;
}

__attribute__((alias("__imp__sub_830A5098"))) PPC_WEAK_FUNC(sub_830A5098);
PPC_FUNC_IMPL(__imp__sub_830A5098) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r5
	ctx.r9.u64 = ctx.r5.u64;
	// lwz r8,20(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r11,0
	r11.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8309d768
	sub_8309D768(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830A50E0"))) PPC_WEAK_FUNC(sub_830A50E0);
PPC_FUNC_IMPL(__imp__sub_830A50E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r28,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r28.u32);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// b 0x830a5128
	goto loc_830A5128;
loc_830A5108:
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// beq cr6,0x830a5134
	if (cr6.eq) goto loc_830A5134;
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// beq cr6,0x830a5134
	if (cr6.eq) goto loc_830A5134;
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// beq cr6,0x830a5134
	if (cr6.eq) goto loc_830A5134;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
loc_830A5128:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830a5108
	if (!cr6.eq) goto loc_830A5108;
	// b 0x830a5138
	goto loc_830A5138;
loc_830A5134:
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
loc_830A5138:
	// clrlwi. r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a51a0
	if (!cr0.eq) goto loc_830A51A0;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// beq cr6,0x830a5164
	if (cr6.eq) goto loc_830A5164;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3064
	ctx.r5.s64 = 3064;
	// addi r6,r11,23304
	ctx.r6.s64 = r11.s64 + 23304;
	// addi r4,r29,40
	ctx.r4.s64 = r29.s64 + 40;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a52b0
	goto loc_830A52B0;
loc_830A5164:
	// stw r28,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r28.u32);
	// lis r12,26
	r12.s64 = 1703936;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lis r11,-31990
	r11.s64 = -2096496640;
	// ori r12,r12,3
	r12.u64 = r12.u64 | 3;
	// lwz r3,4(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r7,r11,20632
	ctx.r7.s64 = r11.s64 + 20632;
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// and r4,r10,r12
	ctx.r4.u64 = ctx.r10.u64 & r12.u64;
	// bl 0x83055cf8
	sub_83055CF8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a52b0
	if (cr0.lt) goto loc_830A52B0;
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// b 0x830a52e8
	goto loc_830A52E8;
loc_830A51A0:
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x83025aa0
	sub_83025AA0(ctx, base);
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x830a5254
	if (!cr6.eq) goto loc_830A5254;
	// lis r12,26
	r12.s64 = 1703936;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,4(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// ori r12,r12,3
	r12.u64 = r12.u64 | 3;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// li r6,0
	ctx.r6.s64 = 0;
	// and r5,r11,r12
	ctx.r5.u64 = r11.u64 & r12.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8302ab48
	sub_8302AB48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a52a8
	if (cr0.lt) goto loc_830A52A8;
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x830466c0
	sub_830466C0(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x830a52a8
	if (cr0.eq) goto loc_830A52A8;
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a5274
	if (cr6.eq) goto loc_830A5274;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r28,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r28.u32);
	// b 0x830a5274
	goto loc_830A5274;
loc_830A5254:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3201
	ctx.r5.s64 = 3201;
	// addi r6,r11,23256
	ctx.r6.s64 = r11.s64 + 23256;
	// addi r4,r29,40
	ctx.r4.s64 = r29.s64 + 40;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83096ff0
	sub_83096FF0(ctx, base);
	// mr r31,r28
	r31.u64 = r28.u64;
	// mr r30,r28
	r30.u64 = r28.u64;
loc_830A5274:
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a529c
	if (cr0.eq) goto loc_830A529C;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r29,40
	ctx.r4.s64 = r29.s64 + 40;
	// bl 0x83049d18
	sub_83049D18(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a52a0
	goto loc_830A52A0;
loc_830A529C:
	// mr r31,r28
	r31.u64 = r28.u64;
loc_830A52A0:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x830a52dc
	if (!cr6.eq) goto loc_830A52DC;
loc_830A52A8:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x830287f8
	sub_830287F8(ctx, base);
loc_830A52B0:
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r11,72(r29)
	PPC_STORE_U32(r29.u32 + 72, r11.u32);
	// beq cr6,0x830a52d4
	if (cr6.eq) goto loc_830A52D4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_830A52D4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830a52e8
	goto loc_830A52E8;
loc_830A52DC:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x830287f8
	sub_830287F8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_830A52E8:
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830A52F0"))) PPC_WEAK_FUNC(sub_830A52F0);
PPC_FUNC_IMPL(__imp__sub_830A52F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r25,0
	r25.s64 = 0;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r31,r25
	r31.u64 = r25.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// stw r31,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r31.u32);
	// li r26,1
	r26.s64 = 1;
	// cmplwi cr6,r30,16
	cr6.compare<uint32_t>(r30.u32, 16, xer);
	// ble cr6,0x830a5324
	if (!cr6.gt) goto loc_830A5324;
	// stw r26,72(r27)
	PPC_STORE_U32(r27.u32 + 72, r26.u32);
loc_830A5324:
	// lwz r11,72(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 72);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830a5a1c
	if (!cr6.eq) goto loc_830A5A1C;
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r1,176
	r11.s64 = ctx.r1.s64 + 176;
	// subfic r9,r30,16
	xer.ca = r30.u32 <= 16;
	ctx.r9.s64 = 16 - r30.s64;
	// add r29,r10,r11
	r29.u64 = ctx.r10.u64 + r11.u64;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// mtctr r30
	ctr.u64 = r30.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830a5394
	if (cr6.eq) goto loc_830A5394;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_830A5360:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a53c4
	if (cr6.eq) goto loc_830A53C4;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r9,8(r27)
	PPC_STORE_U32(r27.u32 + 8, ctx.r9.u32);
	// stw r25,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r25.u32);
	// lwz r9,12(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// stw r9,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r9.u32);
	// stw r11,12(r27)
	PPC_STORE_U32(r27.u32 + 12, r11.u32);
	// bdnz 0x830a5360
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_830A5360;
loc_830A5394:
	// cmplwi cr6,r28,439
	cr6.compare<uint32_t>(r28.u32, 439, xer);
	// bgt cr6,0x830a7770
	if (cr6.gt) goto loc_830A7770;
	// lis r12,-32249
	r12.s64 = -2113470464;
	// addi r12,r12,14880
	r12.s64 = r12.s64 + 14880;
	// rlwinm r0,r28,1,0,30
	r0.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31990
	r12.s64 = -2096496640;
	// addi r12,r12,21444
	r12.s64 = r12.s64 + 21444;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r28.u64) {
	case 0:
		goto loc_830A53E0;
	case 1:
		goto loc_830A542C;
	case 2:
		goto loc_830A56B0;
	case 3:
		goto loc_830A5484;
	case 4:
		goto loc_830A6220;
	case 5:
		goto loc_830A56B0;
	case 6:
		goto loc_830A56B0;
	case 7:
		goto loc_830A56B0;
	case 8:
		goto loc_830A56B0;
	case 9:
		goto loc_830A56B0;
	case 10:
		goto loc_830A56B0;
	case 11:
		goto loc_830A56B0;
	case 12:
		goto loc_830A56B0;
	case 13:
		goto loc_830A56B0;
	case 14:
		goto loc_830A54A0;
	case 15:
		goto loc_830A54C8;
	case 16:
		goto loc_830A5508;
	case 17:
		goto loc_830A646C;
	case 18:
		goto loc_830A54F8;
	case 19:
		goto loc_830A5520;
	case 20:
		goto loc_830A5554;
	case 21:
		goto loc_830A56B0;
	case 22:
		goto loc_830A5588;
	case 23:
		goto loc_830A7770;
	case 24:
		goto loc_830A55FC;
	case 25:
		goto loc_830A5618;
	case 26:
		goto loc_830A5644;
	case 27:
		goto loc_830A5664;
	case 28:
		goto loc_830A5694;
	case 29:
		goto loc_830A7770;
	case 30:
		goto loc_830A55FC;
	case 31:
		goto loc_830A5618;
	case 32:
		goto loc_830A5644;
	case 33:
		goto loc_830A56B0;
	case 34:
		goto loc_830A56A0;
	case 35:
		goto loc_830A6220;
	case 36:
		goto loc_830A56B0;
	case 37:
		goto loc_830A56B8;
	case 38:
		goto loc_830A56E0;
	case 39:
		goto loc_830A56F8;
	case 40:
		goto loc_830A5710;
	case 41:
		goto loc_830A5728;
	case 42:
		goto loc_830A5740;
	case 43:
		goto loc_830A5758;
	case 44:
		goto loc_830A5770;
	case 45:
		goto loc_830A5788;
	case 46:
		goto loc_830A57A0;
	case 47:
		goto loc_830A56B0;
	case 48:
		goto loc_830A57B8;
	case 49:
		goto loc_830A7770;
	case 50:
		goto loc_830A7770;
	case 51:
		goto loc_830A7770;
	case 52:
		goto loc_830A56B0;
	case 53:
		goto loc_830A56A0;
	case 54:
		goto loc_830A57E0;
	case 55:
		goto loc_830A57F8;
	case 56:
		goto loc_830A5810;
	case 57:
		goto loc_830A5828;
	case 58:
		goto loc_830A5880;
	case 59:
		goto loc_830A7770;
	case 60:
		goto loc_830A7770;
	case 61:
		goto loc_830A5898;
	case 62:
		goto loc_830A58C8;
	case 63:
		goto loc_830A58F8;
	case 64:
		goto loc_830A590C;
	case 65:
		goto loc_830A56B0;
	case 66:
		goto loc_830A5948;
	case 67:
		goto loc_830A5970;
	case 68:
		goto loc_830A56B0;
	case 69:
		goto loc_830A56B0;
	case 70:
		goto loc_830A59B8;
	case 71:
		goto loc_830A5A24;
	case 72:
		goto loc_830A5A94;
	case 73:
		goto loc_830A5AC4;
	case 74:
		goto loc_830A5AF4;
	case 75:
		goto loc_830A56B0;
	case 76:
		goto loc_830A5B24;
	case 77:
		goto loc_830A56B0;
	case 78:
		goto loc_830A5B38;
	case 79:
		goto loc_830A6220;
	case 80:
		goto loc_830A56B0;
	case 81:
		goto loc_830A56B0;
	case 82:
		goto loc_830A56B0;
	case 83:
		goto loc_830A56B0;
	case 84:
		goto loc_830A5B4C;
	case 85:
		goto loc_830A5B7C;
	case 86:
		goto loc_830A5B94;
	case 87:
		goto loc_830A5BAC;
	case 88:
		goto loc_830A5BC4;
	case 89:
		goto loc_830A5BDC;
	case 90:
		goto loc_830A5BDC;
	case 91:
		goto loc_830A5BF4;
	case 92:
		goto loc_830A5C0C;
	case 93:
		goto loc_830A5C24;
	case 94:
		goto loc_830A5C44;
	case 95:
		goto loc_830A5C58;
	case 96:
		goto loc_830A5C7C;
	case 97:
		goto loc_830A5C94;
	case 98:
		goto loc_830A5CBC;
	case 99:
		goto loc_830A5CFC;
	case 100:
		goto loc_830A5D5C;
	case 101:
		goto loc_830A5DBC;
	case 102:
		goto loc_830A5E1C;
	case 103:
		goto loc_830A5E7C;
	case 104:
		goto loc_830A5EDC;
	case 105:
		goto loc_830A5F3C;
	case 106:
		goto loc_830A5F54;
	case 107:
		goto loc_830A5F6C;
	case 108:
		goto loc_830A5F84;
	case 109:
		goto loc_830A5F9C;
	case 110:
		goto loc_830A5FB4;
	case 111:
		goto loc_830A5FFC;
	case 112:
		goto loc_830A602C;
	case 113:
		goto loc_830A605C;
	case 114:
		goto loc_830A608C;
	case 115:
		goto loc_830A60BC;
	case 116:
		goto loc_830A60D4;
	case 117:
		goto loc_830A6104;
	case 118:
		goto loc_830A611C;
	case 119:
		goto loc_830A6164;
	case 120:
		goto loc_830A61C4;
	case 121:
		goto loc_830A61DC;
	case 122:
		goto loc_830A6248;
	case 123:
		goto loc_830A5FCC;
	case 124:
		goto loc_830A5FE4;
	case 125:
		goto loc_830A6134;
	case 126:
		goto loc_830A629C;
	case 127:
		goto loc_830A6284;
	case 128:
		goto loc_830A62B4;
	case 129:
		goto loc_830A60EC;
	case 130:
		goto loc_830A62CC;
	case 131:
		goto loc_830A62E8;
	case 132:
		goto loc_830A6304;
	case 133:
		goto loc_830A6320;
	case 134:
		goto loc_830A6338;
	case 135:
		goto loc_830A7770;
	case 136:
		goto loc_830A7770;
	case 137:
		goto loc_830A7770;
	case 138:
		goto loc_830A6220;
	case 139:
		goto loc_830A58F0;
	case 140:
		goto loc_830A6350;
	case 141:
		goto loc_830A6364;
	case 142:
		goto loc_830A56B0;
	case 143:
		goto loc_830A636C;
	case 144:
		goto loc_830A637C;
	case 145:
		goto loc_830A56B0;
	case 146:
		goto loc_830A5484;
	case 147:
		goto loc_830A638C;
	case 148:
		goto loc_830A63F0;
	case 149:
		goto loc_830A6468;
	case 150:
		goto loc_830A6478;
	case 151:
		goto loc_830A6478;
	case 152:
		goto loc_830A6478;
	case 153:
		goto loc_830A6478;
	case 154:
		goto loc_830A56B0;
	case 155:
		goto loc_830A6494;
	case 156:
		goto loc_830A6220;
	case 157:
		goto loc_830A56B0;
	case 158:
		goto loc_830A64A4;
	case 159:
		goto loc_830A64CC;
	case 160:
		goto loc_830A64F4;
	case 161:
		goto loc_830A650C;
	case 162:
		goto loc_830A6524;
	case 163:
		goto loc_830A6540;
	case 164:
		goto loc_830A655C;
	case 165:
		goto loc_830A6580;
	case 166:
		goto loc_830A6220;
	case 167:
		goto loc_830A58F0;
	case 168:
		goto loc_830A6220;
	case 169:
		goto loc_830A56B0;
	case 170:
		goto loc_830A65C8;
	case 171:
		goto loc_830A56B0;
	case 172:
		goto loc_830A5484;
	case 173:
		goto loc_830A6468;
	case 174:
		goto loc_830A65D0;
	case 175:
		goto loc_830A56B0;
	case 176:
		goto loc_830A5484;
	case 177:
		goto loc_830A56B0;
	case 178:
		goto loc_830A56B0;
	case 179:
		goto loc_830A56B0;
	case 180:
		goto loc_830A56B0;
	case 181:
		goto loc_830A56B0;
	case 182:
		goto loc_830A6220;
	case 183:
		goto loc_830A56B0;
	case 184:
		goto loc_830A6614;
	case 185:
		goto loc_830A6634;
	case 186:
		goto loc_830A56B0;
	case 187:
		goto loc_830A5484;
	case 188:
		goto loc_830A664C;
	case 189:
		goto loc_830A56B0;
	case 190:
		goto loc_830A6668;
	case 191:
		goto loc_830A6684;
	case 192:
		goto loc_830A56B0;
	case 193:
		goto loc_830A5484;
	case 194:
		goto loc_830A66A0;
	case 195:
		goto loc_830A66B4;
	case 196:
		goto loc_830A66C8;
	case 197:
		goto loc_830A6818;
	case 198:
		goto loc_830A66EC;
	case 199:
		goto loc_830A686C;
	case 200:
		goto loc_830A6898;
	case 201:
		goto loc_830A6220;
	case 202:
		goto loc_830A6220;
	case 203:
		goto loc_830A58F0;
	case 204:
		goto loc_830A68AC;
	case 205:
		goto loc_830A6220;
	case 206:
		goto loc_830A56B0;
	case 207:
		goto loc_830A5484;
	case 208:
		goto loc_830A6614;
	case 209:
		goto loc_830A68B8;
	case 210:
		goto loc_830A68D0;
	case 211:
		goto loc_830A7770;
	case 212:
		goto loc_830A7770;
	case 213:
		goto loc_830A56B0;
	case 214:
		goto loc_830A56A0;
	case 215:
		goto loc_830A6904;
	case 216:
		goto loc_830A6954;
	case 217:
		goto loc_830A69A8;
	case 218:
		goto loc_830A69C0;
	case 219:
		goto loc_830A69D8;
	case 220:
		goto loc_830A69F0;
	case 221:
		goto loc_830A6A08;
	case 222:
		goto loc_830A6A20;
	case 223:
		goto loc_830A6A38;
	case 224:
		goto loc_830A6A50;
	case 225:
		goto loc_830A6A6C;
	case 226:
		goto loc_830A5758;
	case 227:
		goto loc_830A5770;
	case 228:
		goto loc_830A5788;
	case 229:
		goto loc_830A57A0;
	case 230:
		goto loc_830A56B0;
	case 231:
		goto loc_830A6A84;
	case 232:
		goto loc_830A6B2C;
	case 233:
		goto loc_830A6220;
	case 234:
		goto loc_830A58F0;
	case 235:
		goto loc_830A6C04;
	case 236:
		goto loc_830A6468;
	case 237:
		goto loc_830A56B0;
	case 238:
		goto loc_830A5484;
	case 239:
		goto loc_830A6C18;
	case 240:
		goto loc_830A6220;
	case 241:
		goto loc_830A58F0;
	case 242:
		goto loc_830A6C98;
	case 243:
		goto loc_830A6CB4;
	case 244:
		goto loc_830A56B0;
	case 245:
		goto loc_830A5484;
	case 246:
		goto loc_830A6D08;
	case 247:
		goto loc_830A7770;
	case 248:
		goto loc_830A6CE0;
	case 249:
		goto loc_830A6CF0;
	case 250:
		goto loc_830A6220;
	case 251:
		goto loc_830A6D98;
	case 252:
		goto loc_830A59E8;
	case 253:
		goto loc_830A59E8;
	case 254:
		goto loc_830A6220;
	case 255:
		goto loc_830A58F0;
	case 256:
		goto loc_830A6DD8;
	case 257:
		goto loc_830A6468;
	case 258:
		goto loc_830A56B0;
	case 259:
		goto loc_830A5484;
	case 260:
		goto loc_830A6220;
	case 261:
		goto loc_830A6DE0;
	case 262:
		goto loc_830A6DF4;
	case 263:
		goto loc_830A6E04;
	case 264:
		goto loc_830A6E0C;
	case 265:
		goto loc_830A6E2C;
	case 266:
		goto loc_830A6E48;
	case 267:
		goto loc_830A56B0;
	case 268:
		goto loc_830A56B0;
	case 269:
		goto loc_830A56B0;
	case 270:
		goto loc_830A6E54;
	case 271:
		goto loc_830A6E60;
	case 272:
		goto loc_830A6E6C;
	case 273:
		goto loc_830A56B0;
	case 274:
		goto loc_830A6E78;
	case 275:
		goto loc_830A6E98;
	case 276:
		goto loc_830A6ECC;
	case 277:
		goto loc_830A6EE8;
	case 278:
		goto loc_830A6F08;
	case 279:
		goto loc_830A56B0;
	case 280:
		goto loc_830A6E78;
	case 281:
		goto loc_830A6E98;
	case 282:
		goto loc_830A6F20;
	case 283:
		goto loc_830A6F3C;
	case 284:
		goto loc_830A6F44;
	case 285:
		goto loc_830A6ECC;
	case 286:
		goto loc_830A6EE8;
	case 287:
		goto loc_830A6F5C;
	case 288:
		goto loc_830A6F90;
	case 289:
		goto loc_830A6FA4;
	case 290:
		goto loc_830A6FAC;
	case 291:
		goto loc_830A6FBC;
	case 292:
		goto loc_830A6FCC;
	case 293:
		goto loc_830A6FE8;
	case 294:
		goto loc_830A7004;
	case 295:
		goto loc_830A7050;
	case 296:
		goto loc_830A56B0;
	case 297:
		goto loc_830A5484;
	case 298:
		goto loc_830A7064;
	case 299:
		goto loc_830A6220;
	case 300:
		goto loc_830A6DE0;
	case 301:
		goto loc_830A56B0;
	case 302:
		goto loc_830A6220;
	case 303:
		goto loc_830A56B0;
	case 304:
		goto loc_830A6220;
	case 305:
		goto loc_830A56B0;
	case 306:
		goto loc_830A706C;
	case 307:
		goto loc_830A7088;
	case 308:
		goto loc_830A56B0;
	case 309:
		goto loc_830A56B0;
	case 310:
		goto loc_830A56B0;
	case 311:
		goto loc_830A56B0;
	case 312:
		goto loc_830A56B0;
	case 313:
		goto loc_830A70A4;
	case 314:
		goto loc_830A7164;
	case 315:
		goto loc_830A7254;
	case 316:
		goto loc_830A7254;
	case 317:
		goto loc_830A7264;
	case 318:
		goto loc_830A7274;
	case 319:
		goto loc_830A7288;
	case 320:
		goto loc_830A56B0;
	case 321:
		goto loc_830A7298;
	case 322:
		goto loc_830A7298;
	case 323:
		goto loc_830A72B4;
	case 324:
		goto loc_830A72CC;
	case 325:
		goto loc_830A72E0;
	case 326:
		goto loc_830A7320;
	case 327:
		goto loc_830A56B0;
	case 328:
		goto loc_830A6220;
	case 329:
		goto loc_830A7354;
	case 330:
		goto loc_830A7364;
	case 331:
		goto loc_830A7364;
	case 332:
		goto loc_830A736C;
	case 333:
		goto loc_830A7384;
	case 334:
		goto loc_830A73A4;
	case 335:
		goto loc_830A73BC;
	case 336:
		goto loc_830A73E4;
	case 337:
		goto loc_830A73EC;
	case 338:
		goto loc_830A56B0;
	case 339:
		goto loc_830A56B0;
	case 340:
		goto loc_830A56B0;
	case 341:
		goto loc_830A73FC;
	case 342:
		goto loc_830A7410;
	case 343:
		goto loc_830A7424;
	case 344:
		goto loc_830A7444;
	case 345:
		goto loc_830A744C;
	case 346:
		goto loc_830A56B0;
	case 347:
		goto loc_830A7464;
	case 348:
		goto loc_830A746C;
	case 349:
		goto loc_830A7474;
	case 350:
		goto loc_830A747C;
	case 351:
		goto loc_830A7484;
	case 352:
		goto loc_830A748C;
	case 353:
		goto loc_830A56B0;
	case 354:
		goto loc_830A7494;
	case 355:
		goto loc_830A56B0;
	case 356:
		goto loc_830A749C;
	case 357:
		goto loc_830A74A8;
	case 358:
		goto loc_830A74B4;
	case 359:
		goto loc_830A56B0;
	case 360:
		goto loc_830A74C0;
	case 361:
		goto loc_830A74CC;
	case 362:
		goto loc_830A56B0;
	case 363:
		goto loc_830A74D8;
	case 364:
		goto loc_830A74E4;
	case 365:
		goto loc_830A56B0;
	case 366:
		goto loc_830A74F0;
	case 367:
		goto loc_830A74FC;
	case 368:
		goto loc_830A7508;
	case 369:
		goto loc_830A7514;
	case 370:
		goto loc_830A56B0;
	case 371:
		goto loc_830A7520;
	case 372:
		goto loc_830A752C;
	case 373:
		goto loc_830A56B0;
	case 374:
		goto loc_830A7538;
	case 375:
		goto loc_830A56B0;
	case 376:
		goto loc_830A7544;
	case 377:
		goto loc_830A56B0;
	case 378:
		goto loc_830A7550;
	case 379:
		goto loc_830A56B0;
	case 380:
		goto loc_830A755C;
	case 381:
		goto loc_830A56B0;
	case 382:
		goto loc_830A7568;
	case 383:
		goto loc_830A56B0;
	case 384:
		goto loc_830A758C;
	case 385:
		goto loc_830A7598;
	case 386:
		goto loc_830A75A4;
	case 387:
		goto loc_830A75B0;
	case 388:
		goto loc_830A75BC;
	case 389:
		goto loc_830A75C8;
	case 390:
		goto loc_830A75D4;
	case 391:
		goto loc_830A75E0;
	case 392:
		goto loc_830A75EC;
	case 393:
		goto loc_830A75F8;
	case 394:
		goto loc_830A7604;
	case 395:
		goto loc_830A56B0;
	case 396:
		goto loc_830A7574;
	case 397:
		goto loc_830A7610;
	case 398:
		goto loc_830A762C;
	case 399:
		goto loc_830A6220;
	case 400:
		goto loc_830A56B0;
	case 401:
		goto loc_830A7648;
	case 402:
		goto loc_830A56B0;
	case 403:
		goto loc_830A56B0;
	case 404:
		goto loc_830A56B0;
	case 405:
		goto loc_830A5484;
	case 406:
		goto loc_830A56B0;
	case 407:
		goto loc_830A56B0;
	case 408:
		goto loc_830A7664;
	case 409:
		goto loc_830A56B0;
	case 410:
		goto loc_830A76B8;
	case 411:
		goto loc_830A56B0;
	case 412:
		goto loc_830A76D0;
	case 413:
		goto loc_830A56B0;
	case 414:
		goto loc_830A76E8;
	case 415:
		goto loc_830A56B0;
	case 416:
		goto loc_830A76FC;
	case 417:
		goto loc_830A76FC;
	case 418:
		goto loc_830A76FC;
	case 419:
		goto loc_830A76FC;
	case 420:
		goto loc_830A7718;
	case 421:
		goto loc_830A7718;
	case 422:
		goto loc_830A6220;
	case 423:
		goto loc_830A56B0;
	case 424:
		goto loc_830A56B0;
	case 425:
		goto loc_830A76FC;
	case 426:
		goto loc_830A76FC;
	case 427:
		goto loc_830A76FC;
	case 428:
		goto loc_830A76FC;
	case 429:
		goto loc_830A76FC;
	case 430:
		goto loc_830A76FC;
	case 431:
		goto loc_830A76FC;
	case 432:
		goto loc_830A56B0;
	case 433:
		goto loc_830A772C;
	case 434:
		goto loc_830A76FC;
	case 435:
		goto loc_830A76FC;
	case 436:
		goto loc_830A76FC;
	case 437:
		goto loc_830A7740;
	case 438:
		goto loc_830A7758;
	case 439:
		goto loc_830A7768;
	default:
		__builtin_unreachable();
	}
loc_830A53C4:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r6,r11,2012
	ctx.r6.s64 = r11.s64 + 2012;
loc_830A53CC:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83097060
	sub_83097060(ctx, base);
	// b 0x830a5a1c
	goto loc_830A5A1C;
loc_830A53E0:
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83046ea8
	sub_83046EA8(ctx, base);
loc_830A5410:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a541c
	goto loc_830A541C;
loc_830A5418:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A541C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
loc_830A5420:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A542C:
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r9,112(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 112);
	// lwz r8,108(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 108);
	// lwz r7,104(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 104);
	// lwz r6,100(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 100);
	// lwz r5,96(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 96);
	// lwz r4,92(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 92);
	// bl 0x83046ea8
	sub_83046EA8(ctx, base);
loc_830A545C:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a5468
	goto loc_830A5468;
loc_830A5464:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A5468:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
loc_830A5478:
	// beq 0x830a59e8
	if (cr0.eq) goto loc_830A59E8;
loc_830A547C:
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A5484:
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_830A5488:
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83046868
	sub_83046868(ctx, base);
loc_830A5490:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_830A5494:
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
loc_830A5498:
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A54A0:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830976c0
	sub_830976C0(ctx, base);
loc_830A54B4:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// b 0x830a547c
	goto loc_830A547C;
loc_830A54C8:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,184(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830976c0
	sub_830976C0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
loc_830A54F0:
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A54F8:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// stw r31,28(r27)
	PPC_STORE_U32(r27.u32 + 28, r31.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A5508:
	// lwz r11,28(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// li r4,9
	ctx.r4.s64 = 9;
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
loc_830A5514:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83097148
	sub_83097148(ctx, base);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A5520:
	// li r8,0
	ctx.r8.s64 = 0;
	// li r4,7
	ctx.r4.s64 = 7;
loc_830A5528:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83097598
	sub_83097598(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
loc_830A554C:
	// stw r25,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, r25.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A5554:
	// li r4,7
	ctx.r4.s64 = 7;
	// lwz r8,188(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83097598
	sub_83097598(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// stw r25,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r25.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A5588:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a55b4
	if (cr0.eq) goto loc_830A55B4;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83047cb0
	sub_83047CB0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a55b8
	goto loc_830A55B8;
loc_830A55B4:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A55B8:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a55dc
	if (cr0.eq) goto loc_830A55DC;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// stw r31,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r31.u32);
	// b 0x830a55e0
	goto loc_830A55E0;
loc_830A55DC:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
loc_830A55E0:
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830a547c
	if (cr6.eq) goto loc_830A547C;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309a858
	sub_8309A858(ctx, base);
	// b 0x830a58f0
	goto loc_830A58F0;
loc_830A55FC:
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a59e8
	if (cr6.eq) goto loc_830A59E8;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r10,16(r27)
	PPC_STORE_U32(r27.u32 + 16, ctx.r10.u32);
loc_830A5610:
	// stw r25,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r25.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A5618:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830959a0
	sub_830959A0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x830a5634
	if (cr0.eq) goto loc_830A5634;
loc_830A5630:
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
loc_830A5634:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83097780
	sub_83097780(ctx, base);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A5644:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830959a0
	sub_830959A0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x830a5634
	if (cr0.eq) goto loc_830A5634;
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// b 0x830a5630
	goto loc_830A5630;
loc_830A5664:
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// li r4,8
	ctx.r4.s64 = 8;
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83097598
	sub_83097598(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// b 0x830a54f0
	goto loc_830A54F0;
loc_830A5694:
	// lwz r8,188(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x830a5528
	goto loc_830A5528;
loc_830A56A0:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309a858
	sub_8309A858(ctx, base);
loc_830A56B0:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a547c
	goto loc_830A547C;
loc_830A56B8:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,2
	ctx.r4.s64 = 2;
loc_830A56CC:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// bl 0x83047cb0
	sub_83047CB0(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A56E0:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,64
	ctx.r4.s64 = 64;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A56F8:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A5710:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A5728:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,256
	ctx.r4.s64 = 256;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A5740:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A5758:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lis r4,2
	ctx.r4.s64 = 131072;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A5770:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lis r4,4
	ctx.r4.s64 = 262144;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A5788:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lis r4,8
	ctx.r4.s64 = 524288;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A57A0:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lis r4,16
	ctx.r4.s64 = 1048576;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A57B8:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83047cb0
	sub_83047CB0(ctx, base);
	// b 0x830a545c
	goto loc_830A545C;
loc_830A57E0:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,512
	ctx.r4.s64 = 512;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A57F8:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,1024
	ctx.r4.s64 = 1024;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A5810:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,2048
	ctx.r4.s64 = 2048;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A5828:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5854
	if (cr0.eq) goto loc_830A5854;
	// li r4,0
	ctx.r4.s64 = 0;
loc_830A583C:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r7,0
	ctx.r7.s64 = 0;
	// bl 0x83047cb0
	sub_83047CB0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a5858
	goto loc_830A5858;
loc_830A5854:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A5858:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5870
	if (cr0.eq) goto loc_830A5870;
loc_830A586C:
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
loc_830A5870:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8309cf40
	sub_8309CF40(ctx, base);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A5880:
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r11,24(r10)
	PPC_STORE_U32(ctx.r10.u32 + 24, r11.u32);
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// b 0x830a586c
	goto loc_830A586C;
loc_830A5898:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x83047cb0
	sub_83047CB0(ctx, base);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309cf40
	sub_8309CF40(ctx, base);
	// b 0x830a56b0
	goto loc_830A56B0;
loc_830A58C8:
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r11,24(r10)
	PPC_STORE_U32(ctx.r10.u32 + 24, r11.u32);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309cf40
	sub_8309CF40(ctx, base);
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r25.u32);
loc_830A58F0:
	// lwz r31,180(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// b 0x830a5498
	goto loc_830A5498;
loc_830A58F8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309e1f0
	sub_8309E1F0(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A590C:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x8309e1f0
	sub_8309E1F0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83046868
	sub_83046868(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a547c
	goto loc_830A547C;
loc_830A5948:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,24248
	ctx.r6.s64 = r11.s64 + 24248;
loc_830A5960:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a545c
	goto loc_830A545C;
loc_830A5970:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a599c
	if (cr0.eq) goto loc_830A599C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,24248
	ctx.r6.s64 = r11.s64 + 24248;
loc_830A5988:
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830468d0
	sub_830468D0(ctx, base);
loc_830A5994:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a59a0
	goto loc_830A59A0;
loc_830A599C:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A59A0:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a59e8
	if (cr0.eq) goto loc_830A59E8;
	// b 0x830a5494
	goto loc_830A5494;
loc_830A59B8:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309d768
	sub_8309D768(ctx, base);
loc_830A59E4:
	// lwz r31,128(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_830A59E8:
	// lwz r11,76(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 76);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830a5a1c
	if (!cr6.eq) goto loc_830A5A1C;
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a778c
	if (cr6.eq) goto loc_830A778C;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// stw r10,12(r27)
	PPC_STORE_U32(r27.u32 + 12, ctx.r10.u32);
	// stw r31,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r31.u32);
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
loc_830A5A18:
	// stw r3,8(r27)
	PPC_STORE_U32(r27.u32 + 8, ctx.r3.u32);
loc_830A5A1C:
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c2c
	return;
loc_830A5A24:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309d768
	sub_8309D768(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830a59e4
	if (!cr0.eq) goto loc_830A59E4;
	// lwz r31,128(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830a59e8
	if (cr6.eq) goto loc_830A59E8;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x830a59e8
	if (cr6.eq) goto loc_830A59E8;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,3005
	ctx.r5.s64 = 3005;
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// addi r6,r10,24228
	ctx.r6.s64 = ctx.r10.s64 + 24228;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A5A94:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// li r9,32
	ctx.r9.s64 = 32;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309d768
	sub_8309D768(ctx, base);
	// b 0x830a59e4
	goto loc_830A59E4;
loc_830A5AC4:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// li r9,128
	ctx.r9.s64 = 128;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309d768
	sub_8309D768(ctx, base);
	// b 0x830a59e4
	goto loc_830A59E4;
loc_830A5AF4:
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r9,64
	ctx.r9.s64 = 64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309d768
	sub_8309D768(ctx, base);
	// b 0x830a59e4
	goto loc_830A59E4;
loc_830A5B24:
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
loc_830A5B2C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309a768
	sub_8309A768(ctx, base);
	// b 0x830a58f0
	goto loc_830A58F0;
loc_830A5B38:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309e648
	sub_8309E648(ctx, base);
	// b 0x830a545c
	goto loc_830A545C;
loc_830A5B4C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,0
	ctx.r5.s64 = 0;
loc_830A5B60:
	// li r8,1
	ctx.r8.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
loc_830A5B68:
	// li r7,1
	ctx.r7.s64 = 1;
loc_830A5B6C:
	// li r6,0
	ctx.r6.s64 = 0;
loc_830A5B70:
	// li r9,0
	ctx.r9.s64 = 0;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A5B7C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,5
	ctx.r5.s64 = 5;
	// b 0x830a5b60
	goto loc_830A5B60;
loc_830A5B94:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,11
	ctx.r5.s64 = 11;
	// b 0x830a5b60
	goto loc_830A5B60;
loc_830A5BAC:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,12
	ctx.r5.s64 = 12;
	// b 0x830a5b60
	goto loc_830A5B60;
loc_830A5BC4:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,13
	ctx.r5.s64 = 13;
	// b 0x830a5b60
	goto loc_830A5B60;
loc_830A5BDC:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,9
	ctx.r5.s64 = 9;
	// b 0x830a5b60
	goto loc_830A5B60;
loc_830A5BF4:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,16
	ctx.r5.s64 = 16;
	// b 0x830a5b60
	goto loc_830A5B60;
loc_830A5C0C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,20
	ctx.r5.s64 = 20;
	// b 0x830a5b60
	goto loc_830A5B60;
loc_830A5C24:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x830a5b68
	goto loc_830A5B68;
loc_830A5C44:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309e4a8
	sub_8309E4A8(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A5C58:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,4
	ctx.r7.s64 = 4;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x830a5b6c
	goto loc_830A5B6C;
loc_830A5C7C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309e560
	sub_8309E560(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A5C94:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,23
	ctx.r5.s64 = 23;
loc_830A5CA8:
	// li r6,0
	ctx.r6.s64 = 0;
loc_830A5CAC:
	// li r7,1
	ctx.r7.s64 = 1;
loc_830A5CB0:
	// li r8,1
	ctx.r8.s64 = 1;
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x830a5b70
	goto loc_830A5B70;
loc_830A5CBC:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a5ce0
	if (!cr0.eq) goto loc_830A5CE0;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,24
	ctx.r5.s64 = 24;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A5CE0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,24180
	ctx.r6.s64 = r11.s64 + 24180;
loc_830A5CE8:
	// li r5,3086
	ctx.r5.s64 = 3086;
	// addi r4,r27,40
	ctx.r4.s64 = r27.s64 + 40;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A5CFC:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5d30
	if (cr0.eq) goto loc_830A5D30;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a5d34
	goto loc_830A5D34;
loc_830A5D30:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A5D34:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_830A5D54:
	// li r5,25
	ctx.r5.s64 = 25;
	// b 0x830a5cac
	goto loc_830A5CAC;
loc_830A5D5C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5d90
	if (cr0.eq) goto loc_830A5D90;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a5d94
	goto loc_830A5D94;
loc_830A5D90:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A5D94:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_830A5DB4:
	// li r5,26
	ctx.r5.s64 = 26;
	// b 0x830a5cac
	goto loc_830A5CAC;
loc_830A5DBC:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5df0
	if (cr0.eq) goto loc_830A5DF0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a5df4
	goto loc_830A5DF4;
loc_830A5DF0:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A5DF4:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_830A5E14:
	// li r5,27
	ctx.r5.s64 = 27;
	// b 0x830a5cac
	goto loc_830A5CAC;
loc_830A5E1C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5e50
	if (cr0.eq) goto loc_830A5E50;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a5e54
	goto loc_830A5E54;
loc_830A5E50:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A5E54:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_830A5E74:
	// li r5,28
	ctx.r5.s64 = 28;
	// b 0x830a5cac
	goto loc_830A5CAC;
loc_830A5E7C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5eb0
	if (cr0.eq) goto loc_830A5EB0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a5eb4
	goto loc_830A5EB4;
loc_830A5EB0:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A5EB4:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_830A5ED4:
	// li r5,29
	ctx.r5.s64 = 29;
	// b 0x830a5cac
	goto loc_830A5CAC;
loc_830A5EDC:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5f10
	if (cr0.eq) goto loc_830A5F10;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a5f14
	goto loc_830A5F14;
loc_830A5F10:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A5F14:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_830A5F34:
	// li r5,30
	ctx.r5.s64 = 30;
	// b 0x830a5cac
	goto loc_830A5CAC;
loc_830A5F3C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a5d54
	goto loc_830A5D54;
loc_830A5F54:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a5db4
	goto loc_830A5DB4;
loc_830A5F6C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a5e14
	goto loc_830A5E14;
loc_830A5F84:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a5e74
	goto loc_830A5E74;
loc_830A5F9C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a5ed4
	goto loc_830A5ED4;
loc_830A5FB4:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a5f34
	goto loc_830A5F34;
loc_830A5FCC:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,33
	ctx.r5.s64 = 33;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A5FE4:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,38
	ctx.r5.s64 = 38;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A5FFC:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a6020
	if (!cr0.eq) goto loc_830A6020;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,34
	ctx.r5.s64 = 34;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A6020:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,24096
	ctx.r6.s64 = r11.s64 + 24096;
	// b 0x830a5ce8
	goto loc_830A5CE8;
loc_830A602C:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a6050
	if (!cr0.eq) goto loc_830A6050;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,35
	ctx.r5.s64 = 35;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A6050:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,24008
	ctx.r6.s64 = r11.s64 + 24008;
	// b 0x830a5ce8
	goto loc_830A5CE8;
loc_830A605C:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a6080
	if (!cr0.eq) goto loc_830A6080;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,36
	ctx.r5.s64 = 36;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A6080:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23920
	ctx.r6.s64 = r11.s64 + 23920;
	// b 0x830a5ce8
	goto loc_830A5CE8;
loc_830A608C:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a60b0
	if (!cr0.eq) goto loc_830A60B0;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,37
	ctx.r5.s64 = 37;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A60B0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23832
	ctx.r6.s64 = r11.s64 + 23832;
	// b 0x830a5ce8
	goto loc_830A5CE8;
loc_830A60BC:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,42
	ctx.r5.s64 = 42;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A60D4:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,43
	ctx.r5.s64 = 43;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A60EC:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,44
	ctx.r5.s64 = 44;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A6104:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,45
	ctx.r5.s64 = 45;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A611C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,46
	ctx.r5.s64 = 46;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A6134:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a6158
	if (!cr0.eq) goto loc_830A6158;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,47
	ctx.r5.s64 = 47;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A6158:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23772
	ctx.r6.s64 = r11.s64 + 23772;
	// b 0x830a5ce8
	goto loc_830A5CE8;
loc_830A6164:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6198
	if (cr0.eq) goto loc_830A6198;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a619c
	goto loc_830A619C;
loc_830A6198:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A619C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_830A61BC:
	// li r5,39
	ctx.r5.s64 = 39;
	// b 0x830a5cac
	goto loc_830A5CAC;
loc_830A61C4:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a61bc
	goto loc_830A61BC;
loc_830A61DC:
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r25,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r25.u32);
	// bl 0x8309d198
	sub_8309D198(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830a6228
	if (!cr0.lt) goto loc_830A6228;
loc_830A61F8:
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// addi r4,r11,48
	ctx.r4.s64 = r11.s64 + 48;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830a620c
	if (!cr6.eq) goto loc_830A620C;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_830A620C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r6,r11,23744
	ctx.r6.s64 = r11.s64 + 23744;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A6220:
	// mr r31,r25
	r31.u64 = r25.u64;
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A6228:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r7,128(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// li r5,31
	ctx.r5.s64 = 31;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a5cb0
	goto loc_830A5CB0;
loc_830A6248:
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r25,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r25.u32);
	// bl 0x8309d198
	sub_8309D198(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a61f8
	if (cr0.lt) goto loc_830A61F8;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r7,128(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// li r5,32
	ctx.r5.s64 = 32;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a5cb0
	goto loc_830A5CB0;
loc_830A6284:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,48
	ctx.r5.s64 = 48;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A629C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,49
	ctx.r5.s64 = 49;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A62B4:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,50
	ctx.r5.s64 = 50;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A62CC:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r5,51
	ctx.r5.s64 = 51;
	// b 0x830a5cac
	goto loc_830A5CAC;
loc_830A62E8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r5,52
	ctx.r5.s64 = 52;
	// b 0x830a5cac
	goto loc_830A5CAC;
loc_830A6304:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r5,53
	ctx.r5.s64 = 53;
	// b 0x830a5cac
	goto loc_830A5CAC;
loc_830A6320:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,40
	ctx.r5.s64 = 40;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A6338:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r5,41
	ctx.r5.s64 = 41;
	// b 0x830a5ca8
	goto loc_830A5CA8;
loc_830A6350:
	// li r4,0
	ctx.r4.s64 = 0;
loc_830A6354:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309e430
	sub_8309E430(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A6364:
	// lwz r4,184(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// b 0x830a6354
	goto loc_830A6354;
loc_830A636C:
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// b 0x830a5b2c
	goto loc_830A5B2C;
loc_830A637C:
	// li r4,1
	ctx.r4.s64 = 1;
loc_830A6380:
	// li r5,0
	ctx.r5.s64 = 0;
loc_830A6384:
	// mr r31,r25
	r31.u64 = r25.u64;
	// b 0x830a5514
	goto loc_830A5514;
loc_830A638C:
	// lwz r31,180(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r30,r31
	r30.u64 = r31.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830a5498
	if (cr6.eq) goto loc_830A5498;
loc_830A639C:
	// lwz r31,8(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x830a63e0
	if (!cr6.eq) goto loc_830A63E0;
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r3,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r3.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r4,72(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a58f0
	if (cr0.eq) goto loc_830A58F0;
loc_830A63E0:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x830a639c
	if (!cr6.eq) goto loc_830A639C;
	// b 0x830a58f0
	goto loc_830A58F0;
loc_830A63F0:
	// lwz r3,180(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a6454
	if (cr6.eq) goto loc_830A6454;
loc_830A6400:
	// lwz r31,8(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x830a6444
	if (!cr6.eq) goto loc_830A6444;
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r3,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r3.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r4,72(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6450
	if (cr0.eq) goto loc_830A6450;
loc_830A6444:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x830a6400
	if (!cr6.eq) goto loc_830A6400;
loc_830A6450:
	// lwz r3,180(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_830A6454:
	// lwz r4,184(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// bl 0x83046868
	sub_83046868(ctx, base);
loc_830A645C:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_830A6460:
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// b 0x830a54f0
	goto loc_830A54F0;
loc_830A6468:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A646C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830972b8
	sub_830972B8(ctx, base);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A6478:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23732
	ctx.r6.s64 = r11.s64 + 23732;
	// b 0x830a5960
	goto loc_830A5960;
loc_830A6494:
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83046868
	sub_83046868(ctx, base);
	// b 0x830a5994
	goto loc_830A5994;
loc_830A64A4:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// li r4,0
	ctx.r4.s64 = 0;
loc_830A64B8:
	// li r7,0
	ctx.r7.s64 = 0;
loc_830A64BC:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83049ed8
	sub_83049ED8(ctx, base);
	// b 0x830a545c
	goto loc_830A545C;
loc_830A64CC:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a599c
	if (cr0.eq) goto loc_830A599C;
	// li r4,0
	ctx.r4.s64 = 0;
loc_830A64E0:
	// li r7,0
	ctx.r7.s64 = 0;
loc_830A64E4:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83049ed8
	sub_83049ED8(ctx, base);
	// b 0x830a5994
	goto loc_830A5994;
loc_830A64F4:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x830a64b8
	goto loc_830A64B8;
loc_830A650C:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a599c
	if (cr0.eq) goto loc_830A599C;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x830a64e0
	goto loc_830A64E0;
loc_830A6524:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// lwz r7,180(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x830a64bc
	goto loc_830A64BC;
loc_830A6540:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a599c
	if (cr0.eq) goto loc_830A599C;
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x830a64e4
	goto loc_830A64E4;
loc_830A655C:
	// li r3,28
	ctx.r3.s64 = 28;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x8304a138
	sub_8304A138(ctx, base);
	// b 0x830a545c
	goto loc_830A545C;
loc_830A6580:
	// li r3,28
	ctx.r3.s64 = 28;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a65a8
	if (cr0.eq) goto loc_830A65A8;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8304a138
	sub_8304A138(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a65ac
	goto loc_830A65AC;
loc_830A65A8:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A65AC:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
loc_830A65B0:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a59e8
	if (cr0.eq) goto loc_830A59E8;
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// b 0x830a6460
	goto loc_830A6460;
loc_830A65C8:
	// li r4,5
	ctx.r4.s64 = 5;
	// b 0x830a6380
	goto loc_830A6380;
loc_830A65D0:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309c348
	sub_8309C348(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,25560
	ctx.r6.s64 = r11.s64 + 25560;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A6614:
	// lwz r31,180(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_830A6618:
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
loc_830A661C:
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a59e8
	if (cr6.eq) goto loc_830A59E8;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r10,24(r27)
	PPC_STORE_U32(r27.u32 + 24, ctx.r10.u32);
	// b 0x830a5610
	goto loc_830A5610;
loc_830A6634:
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83046868
	sub_83046868(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// b 0x830a6618
	goto loc_830A6618;
loc_830A664C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r7,188(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830a2cf8
	sub_830A2CF8(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A6668:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23720
	ctx.r6.s64 = r11.s64 + 23720;
	// b 0x830a5960
	goto loc_830A5960;
loc_830A6684:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a599c
	if (cr0.eq) goto loc_830A599C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23720
	ctx.r6.s64 = r11.s64 + 23720;
	// b 0x830a5988
	goto loc_830A5988;
loc_830A66A0:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83096408
	sub_83096408(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A66B4:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83096408
	sub_83096408(ctx, base);
	// b 0x830a54b4
	goto loc_830A54B4;
loc_830A66C8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83096408
	sub_83096408(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// b 0x830a5494
	goto loc_830A5494;
loc_830A66EC:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a6818
	if (cr6.eq) goto loc_830A6818;
	// lwz r29,8(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830a6818
	if (cr6.eq) goto loc_830A6818;
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r3,52
	ctx.r3.s64 = 52;
	// lwz r30,24(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// stw r11,28(r29)
	PPC_STORE_U32(r29.u32 + 28, r11.u32);
	// lwz r11,184(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// stw r26,76(r30)
	PPC_STORE_U32(r30.u32 + 76, r26.u32);
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6738
	if (cr0.eq) goto loc_830A6738;
	// bl 0x83048e80
	sub_83048E80(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a673c
	goto loc_830A673C;
loc_830A6738:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A673C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// stw r3,64(r30)
	PPC_STORE_U32(r30.u32 + 64, ctx.r3.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830a67b0
	if (cr6.eq) goto loc_830A67B0;
	// stw r26,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r26.u32);
	// li r3,80
	ctx.r3.s64 = 80;
	// lwz r11,112(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 112);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,112(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 112);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,112(r27)
	PPC_STORE_U32(r27.u32 + 112, r11.u32);
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a67a0
	if (cr0.eq) goto loc_830A67A0;
	// addi r9,r27,40
	ctx.r9.s64 = r27.s64 + 40;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x830a67a4
	goto loc_830A67A4;
loc_830A67A0:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_830A67A4:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
loc_830A67B0:
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// lwz r5,20(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// b 0x830a6810
	goto loc_830A6810;
loc_830A67C8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83095820
	sub_83095820(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x830a680c
	if (cr0.eq) goto loc_830A680C;
loc_830A67D8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a6800
	if (cr6.eq) goto loc_830A6800;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x830a6800
	if (!cr6.eq) goto loc_830A6800;
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// lwz r10,40(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 40);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830a6830
	if (cr6.eq) goto loc_830A6830;
loc_830A6800:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x830a67d8
	if (!cr6.eq) goto loc_830A67D8;
loc_830A680C:
	// lwz r5,32(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 32);
loc_830A6810:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x830a67c8
	if (!cr6.eq) goto loc_830A67C8;
loc_830A6818:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// bl 0x830972b8
	sub_830972B8(ctx, base);
	// stw r25,32(r27)
	PPC_STORE_U32(r27.u32 + 32, r25.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A6830:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r11,76(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 76);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a685c
	if (cr6.eq) goto loc_830A685C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,8(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// li r5,3069
	ctx.r5.s64 = 3069;
	// addi r6,r11,23696
	ctx.r6.s64 = r11.s64 + 23696;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830A685C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r26,76(r11)
	PPC_STORE_U32(r11.u32 + 76, r26.u32);
	// b 0x830a6818
	goto loc_830A6818;
loc_830A686C:
	// lwz r7,188(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_830A687C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830a3ad8
	sub_830A3AD8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// b 0x830a661c
	goto loc_830A661C;
loc_830A6898:
	// lwz r7,192(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lwz r6,188(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r5,184(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a687c
	goto loc_830A687C;
loc_830A68AC:
	// lwz r5,36(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 36);
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x830a6384
	goto loc_830A6384;
loc_830A68B8:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5854
	if (cr0.eq) goto loc_830A5854;
	// li r4,16
	ctx.r4.s64 = 16;
	// b 0x830a583c
	goto loc_830A583C;
loc_830A68D0:
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r11,24(r10)
	PPC_STORE_U32(ctx.r10.u32 + 24, r11.u32);
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm. r11,r11,0,25,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x70;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a5870
	if (!cr0.eq) goto loc_830A5870;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// ori r11,r11,16
	r11.u64 = r11.u64 | 16;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// b 0x830a5870
	goto loc_830A5870;
loc_830A6904:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6930
	if (cr0.eq) goto loc_830A6930;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83047cb0
	sub_83047CB0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a6934
	goto loc_830A6934;
loc_830A6930:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A6934:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a59e8
	if (cr0.eq) goto loc_830A59E8;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// b 0x830a547c
	goto loc_830A547C;
loc_830A6954:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6980
	if (cr0.eq) goto loc_830A6980;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83047cb0
	sub_83047CB0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a6984
	goto loc_830A6984;
loc_830A6980:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A6984:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a56a0
	if (cr0.eq) goto loc_830A56A0;
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// stw r31,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r31.u32);
	// b 0x830a56a0
	goto loc_830A56A0;
loc_830A69A8:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,16
	ctx.r4.s64 = 16;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A69C0:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,32
	ctx.r4.s64 = 32;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A69D8:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,48
	ctx.r4.s64 = 48;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A69F0:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,80
	ctx.r4.s64 = 80;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A6A08:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A6A20:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,8192
	ctx.r4.s64 = 8192;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A6A38:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,16384
	ctx.r4.s64 = 16384;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A6A50:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lis r4,0
	ctx.r4.s64 = 0;
	// ori r4,r4,32768
	ctx.r4.u64 = ctx.r4.u64 | 32768;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A6A6C:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lis r4,1
	ctx.r4.s64 = 65536;
	// b 0x830a56cc
	goto loc_830A56CC;
loc_830A6A84:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6ab0
	if (cr0.eq) goto loc_830A6AB0;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,20620
	ctx.r6.s64 = r11.s64 + 20620;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a6ab4
	goto loc_830A6AB4;
loc_830A6AB0:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A6AB4:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6b1c
	if (cr0.eq) goto loc_830A6B1C;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6af8
	if (cr0.eq) goto loc_830A6AF8;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r7,180(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83047398
	sub_83047398(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x830a6afc
	goto loc_830A6AFC;
loc_830A6AF8:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_830A6AFC:
	// stw r4,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r4.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6b1c
	if (cr0.eq) goto loc_830A6B1C;
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
loc_830A6B1C:
	// lwz r11,92(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 92);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,92(r27)
	PPC_STORE_U32(r27.u32 + 92, r11.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A6B2C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6b58
	if (cr0.eq) goto loc_830A6B58;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,20620
	ctx.r6.s64 = r11.s64 + 20620;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a6b5c
	goto loc_830A6B5C;
loc_830A6B58:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A6B5C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6bf4
	if (cr0.eq) goto loc_830A6BF4;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6ba0
	if (cr0.eq) goto loc_830A6BA0;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r7,180(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83047398
	sub_83047398(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x830a6ba4
	goto loc_830A6BA4;
loc_830A6BA0:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_830A6BA4:
	// stw r4,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r4.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6bf4
	if (cr0.eq) goto loc_830A6BF4;
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,20(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a6bf4
	if (cr6.eq) goto loc_830A6BF4;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830973b0
	sub_830973B0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830a6bf4
	if (!cr0.lt) goto loc_830A6BF4;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
loc_830A6BF4:
	// lwz r11,96(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 96);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,96(r27)
	PPC_STORE_U32(r27.u32 + 96, r11.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A6C04:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,6
	ctx.r4.s64 = 6;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83097148
	sub_83097148(ctx, base);
	// b 0x830a6220
	goto loc_830A6220;
loc_830A6C18:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6c44
	if (cr0.eq) goto loc_830A6C44;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,23688
	ctx.r6.s64 = r11.s64 + 23688;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a6c48
	goto loc_830A6C48;
loc_830A6C44:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A6C48:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a59e8
	if (cr0.eq) goto loc_830A59E8;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6c8c
	if (cr0.eq) goto loc_830A6C8C;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r7,180(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,5
	ctx.r4.s64 = 5;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83047398
	sub_83047398(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x830a6c90
	goto loc_830A6C90;
loc_830A6C8C:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_830A6C90:
	// stw r4,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r4.u32);
	// b 0x830a65b0
	goto loc_830A65B0;
loc_830A6C98:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83097148
	sub_83097148(ctx, base);
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A6CAC:
	// stw r25,84(r27)
	PPC_STORE_U32(r27.u32 + 84, r25.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A6CB4:
	// stw r26,84(r27)
	PPC_STORE_U32(r27.u32 + 84, r26.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r31,r25
	r31.u64 = r25.u64;
	// bl 0x830972b8
	sub_830972B8(ctx, base);
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a59e8
	if (cr6.eq) goto loc_830A59E8;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x830a59e8
	if (!cr6.eq) goto loc_830A59E8;
	// b 0x830a6cac
	goto loc_830A6CAC;
loc_830A6CE0:
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830c2e68
	sub_830C2E68(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A6CF0:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a6d08
	if (cr0.eq) goto loc_830A6D08;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23628
	ctx.r6.s64 = r11.s64 + 23628;
	// b 0x830a5ce8
	goto loc_830A5CE8;
loc_830A6D08:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6d34
	if (cr0.eq) goto loc_830A6D34;
	// lis r11,-32243
	r11.s64 = -2113077248;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,25408
	ctx.r6.s64 = r11.s64 + 25408;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a6d38
	goto loc_830A6D38;
loc_830A6D34:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A6D38:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a59e8
	if (cr0.eq) goto loc_830A59E8;
	// li r3,28
	ctx.r3.s64 = 28;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a6d74
	if (cr0.eq) goto loc_830A6D74;
	// lwz r6,188(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83049ae0
	sub_83049AE0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x830a6d78
	goto loc_830A6D78;
loc_830A6D74:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_830A6D78:
	// stw r4,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r4.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a59e8
	if (cr0.eq) goto loc_830A59E8;
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// b 0x830a554c
	goto loc_830A554C;
loc_830A6D98:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x830a59e8
	if (cr0.eq) goto loc_830A59E8;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x830a59e8
	if (!cr6.eq) goto loc_830A59E8;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x830a59e8
	if (!cr6.eq) goto loc_830A59E8;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830a59e8
	if (!cr6.eq) goto loc_830A59E8;
	// li r11,2
	r11.s64 = 2;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A6DD8:
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x830a6380
	goto loc_830A6380;
loc_830A6DE0:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830967a0
	sub_830967A0(ctx, base);
loc_830A6DEC:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A6DF4:
	// li r4,0
	ctx.r4.s64 = 0;
loc_830A6DF8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309fe50
	sub_8309FE50(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A6E04:
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a6df8
	goto loc_830A6DF8;
loc_830A6E0C:
	// lwz r8,176(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r5,r8
	ctx.r5.u64 = ctx.r8.u64;
	// bl 0x830a0418
	sub_830A0418(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A6E2C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r6,r11,20620
	ctx.r6.s64 = r11.s64 + 20620;
	// b 0x830a5960
	goto loc_830A5960;
loc_830A6E48:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83096b78
	sub_83096B78(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A6E54:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83096a70
	sub_83096A70(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A6E60:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83096860
	sub_83096860(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A6E6C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83096968
	sub_83096968(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A6E78:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r8,180(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830a0418
	sub_830A0418(ctx, base);
	// b 0x830a5490
	goto loc_830A5490;
loc_830A6E98:
	// lwz r8,192(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r7,188(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_830A6EAC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830a0418
	sub_830A0418(ctx, base);
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
	// stw r25,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, r25.u32);
	// stw r25,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r25.u32);
	// b 0x830a646c
	goto loc_830A646C;
loc_830A6ECC:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a599c
	if (cr0.eq) goto loc_830A599C;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r6,r11,20620
	ctx.r6.s64 = r11.s64 + 20620;
	// b 0x830a5988
	goto loc_830A5988;
loc_830A6EE8:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r8,184(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830a0418
	sub_830A0418(ctx, base);
	// b 0x830a645c
	goto loc_830A645C;
loc_830A6F08:
	// lwz r8,196(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lwz r7,192(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lwz r6,188(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r5,184(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a6eac
	goto loc_830A6EAC;
loc_830A6F20:
	// li r7,0
	ctx.r7.s64 = 0;
loc_830A6F24:
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_830A6F30:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309ffb0
	sub_8309FFB0(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A6F3C:
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// b 0x830a6f24
	goto loc_830A6F24;
loc_830A6F44:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
loc_830A6F50:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830a0220
	sub_830A0220(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A6F5C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r8,196(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lwz r7,192(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lwz r6,188(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r5,184(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830a0418
	sub_830A0418(ctx, base);
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r25,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, r25.u32);
	// stw r25,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r25.u32);
	// stw r25,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, r25.u32);
	// b 0x830a646c
	goto loc_830A646C;
loc_830A6F90:
	// li r7,0
	ctx.r7.s64 = 0;
loc_830A6F94:
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a6f30
	goto loc_830A6F30;
loc_830A6FA4:
	// lwz r7,188(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// b 0x830a6f94
	goto loc_830A6F94;
loc_830A6FAC:
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a6f50
	goto loc_830A6F50;
loc_830A6FBC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309d240
	sub_8309D240(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A6FCC:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83047b50
	sub_83047B50(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A6FE8:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23612
	ctx.r6.s64 = r11.s64 + 23612;
	// b 0x830a5960
	goto loc_830A5960;
loc_830A7004:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a7030
	if (cr0.eq) goto loc_830A7030;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23612
	ctx.r6.s64 = r11.s64 + 23612;
loc_830A701C:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a7034
	goto loc_830A7034;
loc_830A7030:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A7034:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830970e0
	sub_830970E0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a59e8
	if (cr0.eq) goto loc_830A59E8;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// b 0x830a5488
	goto loc_830A5488;
loc_830A7050:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83096c70
	sub_83096C70(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A7064:
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x830a6380
	goto loc_830A6380;
loc_830A706C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23600
	ctx.r6.s64 = r11.s64 + 23600;
	// b 0x830a5960
	goto loc_830A5960;
loc_830A7088:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a599c
	if (cr0.eq) goto loc_830A599C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23600
	ctx.r6.s64 = r11.s64 + 23600;
	// b 0x830a5988
	goto loc_830A5988;
loc_830A70A4:
	// li r3,80
	ctx.r3.s64 = 80;
	// addi r30,r27,40
	r30.s64 = r27.s64 + 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a70dc
	if (cr0.eq) goto loc_830A70DC;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a70e0
	goto loc_830A70E0;
loc_830A70DC:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A70E0:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x830a70f0
	if (!cr6.eq) goto loc_830A70F0;
loc_830A70E8:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// b 0x830a715c
	goto loc_830A715C;
loc_830A70F0:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a7120
	if (cr0.eq) goto loc_830A7120;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// b 0x830a7124
	goto loc_830A7124;
loc_830A7120:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_830A7124:
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a70e8
	if (cr6.eq) goto loc_830A70E8;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a720c
	if (cr0.eq) goto loc_830A720C;
	// li r5,1
	ctx.r5.s64 = 1;
	// b 0x830a71fc
	goto loc_830A71FC;
loc_830A7148:
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83099758
	sub_83099758(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
loc_830A715C:
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// b 0x830a5420
	goto loc_830A5420;
loc_830A7164:
	// li r3,80
	ctx.r3.s64 = 80;
	// addi r30,r27,40
	r30.s64 = r27.s64 + 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a719c
	if (cr0.eq) goto loc_830A719C;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830a71a0
	goto loc_830A71A0;
loc_830A719C:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_830A71A0:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830a70e8
	if (cr6.eq) goto loc_830A70E8;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a71d8
	if (cr0.eq) goto loc_830A71D8;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// b 0x830a71dc
	goto loc_830A71DC;
loc_830A71D8:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_830A71DC:
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830a70e8
	if (cr6.eq) goto loc_830A70E8;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a720c
	if (cr0.eq) goto loc_830A720C;
	// li r5,0
	ctx.r5.s64 = 0;
loc_830A71FC:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83049848
	sub_83049848(ctx, base);
	// b 0x830a7210
	goto loc_830A7210;
loc_830A720C:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_830A7210:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq cr6,0x830a70e8
	if (cr6.eq) goto loc_830A70E8;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a7244
	if (cr0.eq) goto loc_830A7244;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,25560
	ctx.r6.s64 = r11.s64 + 25560;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a7248
	goto loc_830A7248;
loc_830A7244:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_830A7248:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830a7148
	if (!cr6.eq) goto loc_830A7148;
	// b 0x830a70e8
	goto loc_830A70E8;
loc_830A7254:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309b620
	sub_8309B620(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A7264:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309b6e8
	sub_8309B6E8(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A7274:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309e720
	sub_8309E720(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A7288:
	// addi r4,r27,40
	ctx.r4.s64 = r27.s64 + 40;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309b838
	sub_8309B838(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A7298:
	// li r6,1
	ctx.r6.s64 = 1;
loc_830A729C:
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309e970
	sub_8309E970(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A72B4:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830a41b0
	sub_830A41B0(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A72CC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830980d8
	sub_830980D8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// b 0x830a5478
	goto loc_830A5478;
loc_830A72E0:
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830c2d48
	sub_830C2D48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a59e8
	if (cr0.lt) goto loc_830A59E8;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r5,128(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r6,r11,16
	ctx.r6.s64 = r11.s64 + 16;
	// bl 0x83049848
	sub_83049848(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A7320:
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830c2d48
	sub_830C2D48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a59e8
	if (cr0.lt) goto loc_830A59E8;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A7354:
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_830A7358:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309c048
	sub_8309C048(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A7364:
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x830a7358
	goto loc_830A7358;
loc_830A736C:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a7384
	if (cr0.eq) goto loc_830A7384;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23544
	ctx.r6.s64 = r11.s64 + 23544;
	// b 0x830a5ce8
	goto loc_830A5CE8;
loc_830A7384:
	// li r8,0
	ctx.r8.s64 = 0;
loc_830A7388:
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_830A7394:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830a4e18
	sub_830A4E18(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A73A4:
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r6,188(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r5,184(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// b 0x830a7394
	goto loc_830A7394;
loc_830A73BC:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a73d8
	if (!cr0.eq) goto loc_830A73D8;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309c208
	sub_8309C208(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A73D8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23480
	ctx.r6.s64 = r11.s64 + 23480;
	// b 0x830a5ce8
	goto loc_830A5CE8;
loc_830A73E4:
	// li r8,1
	ctx.r8.s64 = 1;
	// b 0x830a7388
	goto loc_830A7388;
loc_830A73EC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309c348
	sub_8309C348(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A73FC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309f2c8
	sub_8309F2C8(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A7410:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309bab8
	sub_8309BAB8(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A7424:
	// li r4,45
	ctx.r4.s64 = 45;
loc_830A7428:
	// li r6,0
	ctx.r6.s64 = 0;
loc_830A742C:
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r7,1
	ctx.r7.s64 = 1;
loc_830A7434:
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8309f590
	sub_8309F590(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A7444:
	// li r4,46
	ctx.r4.s64 = 46;
	// b 0x830a7428
	goto loc_830A7428;
loc_830A744C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830a4800
	sub_830A4800(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A7464:
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x830a7428
	goto loc_830A7428;
loc_830A746C:
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x830a7428
	goto loc_830A7428;
loc_830A7474:
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x830a7428
	goto loc_830A7428;
loc_830A747C:
	// li r4,5
	ctx.r4.s64 = 5;
	// b 0x830a7428
	goto loc_830A7428;
loc_830A7484:
	// li r4,6
	ctx.r4.s64 = 6;
	// b 0x830a7428
	goto loc_830A7428;
loc_830A748C:
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x830a7428
	goto loc_830A7428;
loc_830A7494:
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x830a729c
	goto loc_830A729C;
loc_830A749C:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A74A8:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,9
	ctx.r4.s64 = 9;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A74B4:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,10
	ctx.r4.s64 = 10;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A74C0:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,11
	ctx.r4.s64 = 11;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A74CC:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,12
	ctx.r4.s64 = 12;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A74D8:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,13
	ctx.r4.s64 = 13;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A74E4:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,14
	ctx.r4.s64 = 14;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A74F0:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,15
	ctx.r4.s64 = 15;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A74FC:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,16
	ctx.r4.s64 = 16;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A7508:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,17
	ctx.r4.s64 = 17;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A7514:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,18
	ctx.r4.s64 = 18;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A7520:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,19
	ctx.r4.s64 = 19;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A752C:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,20
	ctx.r4.s64 = 20;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A7538:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,21
	ctx.r4.s64 = 21;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A7544:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,22
	ctx.r4.s64 = 22;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A7550:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,23
	ctx.r4.s64 = 23;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A755C:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,24
	ctx.r4.s64 = 24;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A7568:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,25
	ctx.r4.s64 = 25;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A7574:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8309ec88
	sub_8309EC88(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A758C:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,27
	ctx.r4.s64 = 27;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A7598:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,35
	ctx.r4.s64 = 35;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A75A4:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,36
	ctx.r4.s64 = 36;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A75B0:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,37
	ctx.r4.s64 = 37;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A75BC:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,38
	ctx.r4.s64 = 38;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A75C8:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,39
	ctx.r4.s64 = 39;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A75D4:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,40
	ctx.r4.s64 = 40;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A75E0:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,41
	ctx.r4.s64 = 41;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A75EC:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,42
	ctx.r4.s64 = 42;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A75F8:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,43
	ctx.r4.s64 = 43;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A7604:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,44
	ctx.r4.s64 = 44;
	// b 0x830a742c
	goto loc_830A742C;
loc_830A7610:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23464
	ctx.r6.s64 = r11.s64 + 23464;
	// b 0x830a5960
	goto loc_830A5960;
loc_830A762C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a7030
	if (cr0.eq) goto loc_830A7030;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,23464
	ctx.r6.s64 = r11.s64 + 23464;
	// b 0x830a701c
	goto loc_830A701C;
loc_830A7648:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5464
	if (cr0.eq) goto loc_830A5464;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// addi r6,r11,25560
	ctx.r6.s64 = r11.s64 + 25560;
	// b 0x830a5960
	goto loc_830A5960;
loc_830A7664:
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a76a4
	if (cr6.eq) goto loc_830A76A4;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x830a76a4
	if (!cr6.eq) goto loc_830A76A4;
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830a768c
	if (!cr6.eq) goto loc_830A768C;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
loc_830A768C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,3081
	ctx.r5.s64 = 3081;
	// addi r6,r10,23392
	ctx.r6.s64 = ctx.r10.s64 + 23392;
	// addi r4,r11,48
	ctx.r4.s64 = r11.s64 + 48;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83096ff0
	sub_83096FF0(ctx, base);
loc_830A76A4:
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x830a7434
	goto loc_830A7434;
loc_830A76B8:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// neg r11,r11
	r11.s64 = -r11.s64;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A76D0:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// lfd f0,24(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 24);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfd f0,24(r31)
	PPC_STORE_U64(r31.u32 + 24, f0.u64);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A76E8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x830997e0
	sub_830997E0(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A76FC:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a5418
	if (cr0.eq) goto loc_830A5418;
	// addi r4,r27,40
	ctx.r4.s64 = r27.s64 + 40;
	// bl 0x83046d28
	sub_83046D28(ctx, base);
	// b 0x830a5410
	goto loc_830A5410;
loc_830A7718:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// stw r11,36(r27)
	PPC_STORE_U32(r27.u32 + 36, r11.u32);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A772C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83099928
	sub_83099928(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A7740:
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// bl 0x8301f740
	sub_8301F740(ctx, base);
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// bl 0x83022810
	sub_83022810(ctx, base);
	// b 0x830a6220
	goto loc_830A6220;
loc_830A7758:
	// li r4,0
	ctx.r4.s64 = 0;
loc_830A775C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830a50e0
	sub_830A50E0(ctx, base);
	// b 0x830a6dec
	goto loc_830A6DEC;
loc_830A7768:
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x830a775c
	goto loc_830A775C;
loc_830A7770:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,23352
	ctx.r6.s64 = r11.s64 + 23352;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83097060
	sub_83097060(ctx, base);
	// b 0x830a59e8
	goto loc_830A59E8;
loc_830A778C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830a77b4
	if (cr0.eq) goto loc_830A77B4;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lwz r5,8(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r6,r11,1960
	ctx.r6.s64 = r11.s64 + 1960;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830a77b8
	goto loc_830A77B8;
loc_830A77B4:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_830A77B8:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830a5a18
	if (!cr6.eq) goto loc_830A5A18;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r6,r11,1928
	ctx.r6.s64 = r11.s64 + 1928;
	// b 0x830a53cc
	goto loc_830A53CC;
}

__attribute__((alias("__imp__sub_830A77D0"))) PPC_WEAK_FUNC(sub_830A77D0);
PPC_FUNC_IMPL(__imp__sub_830A77D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r24,0
	r24.s64 = 0;
	// addi r11,r31,1032
	r11.s64 = r31.s64 + 1032;
	// li r25,-1
	r25.s64 = -1;
	// addi r22,r31,32
	r22.s64 = r31.s64 + 32;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// stw r24,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r24.u32);
	// lis r9,-32241
	ctx.r9.s64 = -2112946176;
	// stw r24,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r24.u32);
	// stw r25,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r25.u32);
	// mr r30,r24
	r30.u64 = r24.u64;
	// stw r22,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r22.u32);
	// addi r26,r11,-784
	r26.s64 = r11.s64 + -784;
	// sth r24,32(r31)
	PPC_STORE_U16(r31.u32 + 32, r24.u16);
	// addi r27,r10,-19584
	r27.s64 = ctx.r10.s64 + -19584;
	// addi r23,r9,13852
	r23.s64 = ctx.r9.s64 + 13852;
loc_830A7824:
	// addi r11,r26,-20384
	r11.s64 = r26.s64 + -20384;
	// rlwinm r29,r30,1,0,30
	r29.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// lhax r11,r29,r11
	r11.s64 = int16_t(PPC_LOAD_U16(r29.u32 + r11.u32));
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a7920
	if (!cr0.eq) goto loc_830A7920;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x830a785c
	if (!cr6.lt) goto loc_830A785C;
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 3032);
	// bl 0x830a0630
	sub_830A0630(ctx, base);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830a785c
	if (!cr0.lt) goto loc_830A785C;
	// stw r24,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r24.u32);
loc_830A785C:
	// addi r11,r26,-18512
	r11.s64 = r26.s64 + -18512;
	// lhax r11,r29,r11
	r11.s64 = int16_t(PPC_LOAD_U16(r29.u32 + r11.u32));
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a78e4
	if (cr0.eq) goto loc_830A78E4;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add. r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// blt 0x830a78e4
	if (cr0.lt) goto loc_830A78E4;
	// cmpwi cr6,r11,7525
	cr6.compare<int32_t>(r11.s32, 7525, xer);
	// bgt cr6,0x830a78e4
	if (cr6.gt) goto loc_830A78E4;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhax r11,r10,r26
	r11.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + r26.u32));
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x830a78e4
	if (!cr6.eq) goto loc_830A78E4;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r9,r31,1030
	ctx.r9.s64 = r31.s64 + 1030;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x830a8d78
	if (!cr6.lt) goto loc_830A8D78;
	// addi r9,r27,3744
	ctx.r9.s64 = r27.s64 + 3744;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// lhax r30,r10,r9
	r30.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r9.u32));
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// sth r30,0(r11)
	PPC_STORE_U16(r11.u32 + 0, r30.u16);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// stw r25,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r25.u32);
	// ble cr6,0x830a7824
	if (!cr6.gt) goto loc_830A7824;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// b 0x830a7824
	goto loc_830A7824;
loc_830A78E4:
	// addi r11,r27,1872
	r11.s64 = r27.s64 + 1872;
	// lhax r11,r29,r11
	r11.s64 = int16_t(PPC_LOAD_U16(r29.u32 + r11.u32));
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a8c9c
	if (cr0.eq) goto loc_830A8C9C;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add. r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// blt 0x830a8c9c
	if (cr0.lt) goto loc_830A8C9C;
	// cmpwi cr6,r11,7525
	cr6.compare<int32_t>(r11.s32, 7525, xer);
	// bgt cr6,0x830a8c9c
	if (cr6.gt) goto loc_830A8C9C;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhax r9,r11,r26
	ctx.r9.s64 = int16_t(PPC_LOAD_U16(r11.u32 + r26.u32));
	// cmpw cr6,r9,r10
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, xer);
	// bne cr6,0x830a8c9c
	if (!cr6.eq) goto loc_830A8C9C;
	// addi r10,r27,3744
	ctx.r10.s64 = r27.s64 + 3744;
	// lhax r11,r11,r10
	r11.s64 = int16_t(PPC_LOAD_U16(r11.u32 + ctx.r10.u32));
loc_830A7920:
	// rlwinm r30,r11,1,0,30
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r9,r27,-2440
	ctx.r9.s64 = r27.s64 + -2440;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplwi cr6,r11,425
	cr6.compare<uint32_t>(r11.u32, 425, xer);
	// lhax r29,r30,r9
	r29.s64 = int16_t(PPC_LOAD_U16(r30.u32 + ctx.r9.u32));
	// rlwinm r28,r29,2,0,29
	r28.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r28,r10
	ctx.r10.s64 = ctx.r10.s64 - r28.s64;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// bgt cr6,0x830a8b88
	if (cr6.gt) goto loc_830A8B88;
	// lis r12,-32249
	r12.s64 = -2113470464;
	// addi r12,r12,15760
	r12.s64 = r12.s64 + 15760;
	// rlwinm r0,r11,1,0,30
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31990
	r12.s64 = -2096496640;
	// addi r12,r12,31092
	r12.s64 = r12.s64 + 31092;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_830A7974;
	case 1:
		goto loc_830A797C;
	case 2:
		goto loc_830A7988;
	case 3:
		goto loc_830A7994;
	case 4:
		goto loc_830A79A0;
	case 5:
		goto loc_830A79A8;
	case 6:
		goto loc_830A79B4;
	case 7:
		goto loc_830A79C0;
	case 8:
		goto loc_830A79CC;
	case 9:
		goto loc_830A79D8;
	case 10:
		goto loc_830A79E4;
	case 11:
		goto loc_830A79F0;
	case 12:
		goto loc_830A79FC;
	case 13:
		goto loc_830A7A08;
	case 14:
		goto loc_830A7A14;
	case 15:
		goto loc_830A7A20;
	case 16:
		goto loc_830A7A2C;
	case 17:
		goto loc_830A7A38;
	case 18:
		goto loc_830A7A40;
	case 19:
		goto loc_830A7A48;
	case 20:
		goto loc_830A7A54;
	case 21:
		goto loc_830A7A60;
	case 22:
		goto loc_830A7A6C;
	case 23:
		goto loc_830A7A78;
	case 24:
		goto loc_830A7A84;
	case 25:
		goto loc_830A7A90;
	case 26:
		goto loc_830A7A98;
	case 27:
		goto loc_830A7AA4;
	case 28:
		goto loc_830A7AB0;
	case 29:
		goto loc_830A7ABC;
	case 30:
		goto loc_830A7AC8;
	case 31:
		goto loc_830A7AD0;
	case 32:
		goto loc_830A7AD8;
	case 33:
		goto loc_830A7AE4;
	case 34:
		goto loc_830A7AF0;
	case 35:
		goto loc_830A7AFC;
	case 36:
		goto loc_830A7B04;
	case 37:
		goto loc_830A7B0C;
	case 38:
		goto loc_830A7B14;
	case 39:
		goto loc_830A7B1C;
	case 40:
		goto loc_830A7B24;
	case 41:
		goto loc_830A7B2C;
	case 42:
		goto loc_830A7B34;
	case 43:
		goto loc_830A7B3C;
	case 44:
		goto loc_830A7B44;
	case 45:
		goto loc_830A7B4C;
	case 46:
		goto loc_830A7B58;
	case 47:
		goto loc_830A7B64;
	case 48:
		goto loc_830A7B70;
	case 49:
		goto loc_830A7B7C;
	case 50:
		goto loc_830A7B84;
	case 51:
		goto loc_830A7B8C;
	case 52:
		goto loc_830A7B94;
	case 53:
		goto loc_830A7BA0;
	case 54:
		goto loc_830A7BAC;
	case 55:
		goto loc_830A7BB8;
	case 56:
		goto loc_830A7BC4;
	case 57:
		goto loc_830A7BD0;
	case 58:
		goto loc_830A7BDC;
	case 59:
		goto loc_830A7BE8;
	case 60:
		goto loc_830A7BF4;
	case 61:
		goto loc_830A7C00;
	case 62:
		goto loc_830A7C0C;
	case 63:
		goto loc_830A7C18;
	case 64:
		goto loc_830A7C24;
	case 65:
		goto loc_830A7C30;
	case 66:
		goto loc_830A7C3C;
	case 67:
		goto loc_830A7C48;
	case 68:
		goto loc_830A7C54;
	case 69:
		goto loc_830A7C60;
	case 70:
		goto loc_830A7C6C;
	case 71:
		goto loc_830A7C78;
	case 72:
		goto loc_830A7C84;
	case 73:
		goto loc_830A7C8C;
	case 74:
		goto loc_830A7C98;
	case 75:
		goto loc_830A7CA4;
	case 76:
		goto loc_830A7CB0;
	case 77:
		goto loc_830A7CBC;
	case 78:
		goto loc_830A7CC4;
	case 79:
		goto loc_830A7CCC;
	case 80:
		goto loc_830A7CD4;
	case 81:
		goto loc_830A7CDC;
	case 82:
		goto loc_830A7CE4;
	case 83:
		goto loc_830A7CEC;
	case 84:
		goto loc_830A7CF4;
	case 85:
		goto loc_830A7CFC;
	case 86:
		goto loc_830A7D04;
	case 87:
		goto loc_830A7D0C;
	case 88:
		goto loc_830A7D18;
	case 89:
		goto loc_830A7D20;
	case 90:
		goto loc_830A7D2C;
	case 91:
		goto loc_830A7D34;
	case 92:
		goto loc_830A7D3C;
	case 93:
		goto loc_830A7D44;
	case 94:
		goto loc_830A7D4C;
	case 95:
		goto loc_830A7D54;
	case 96:
		goto loc_830A7D5C;
	case 97:
		goto loc_830A7D64;
	case 98:
		goto loc_830A7D6C;
	case 99:
		goto loc_830A7D78;
	case 100:
		goto loc_830A7D84;
	case 101:
		goto loc_830A7D90;
	case 102:
		goto loc_830A7D9C;
	case 103:
		goto loc_830A7DA8;
	case 104:
		goto loc_830A7DB4;
	case 105:
		goto loc_830A7DBC;
	case 106:
		goto loc_830A7DC4;
	case 107:
		goto loc_830A7DCC;
	case 108:
		goto loc_830A7DD4;
	case 109:
		goto loc_830A7DDC;
	case 110:
		goto loc_830A7DE4;
	case 111:
		goto loc_830A7DEC;
	case 112:
		goto loc_830A7DF4;
	case 113:
		goto loc_830A7DFC;
	case 114:
		goto loc_830A7E04;
	case 115:
		goto loc_830A7E0C;
	case 116:
		goto loc_830A7E14;
	case 117:
		goto loc_830A7E1C;
	case 118:
		goto loc_830A7E28;
	case 119:
		goto loc_830A7E30;
	case 120:
		goto loc_830A7E38;
	case 121:
		goto loc_830A7E40;
	case 122:
		goto loc_830A7E4C;
	case 123:
		goto loc_830A7E58;
	case 124:
		goto loc_830A7E64;
	case 125:
		goto loc_830A7E70;
	case 126:
		goto loc_830A7E7C;
	case 127:
		goto loc_830A7E84;
	case 128:
		goto loc_830A7E8C;
	case 129:
		goto loc_830A7E98;
	case 130:
		goto loc_830A7EA4;
	case 131:
		goto loc_830A7EB0;
	case 132:
		goto loc_830A7EBC;
	case 133:
		goto loc_830A7EC8;
	case 134:
		goto loc_830A7ED4;
	case 135:
		goto loc_830A7EDC;
	case 136:
		goto loc_830A7EE8;
	case 137:
		goto loc_830A7EF4;
	case 138:
		goto loc_830A7F00;
	case 139:
		goto loc_830A7F0C;
	case 140:
		goto loc_830A7F14;
	case 141:
		goto loc_830A7F20;
	case 142:
		goto loc_830A7F2C;
	case 143:
		goto loc_830A7F38;
	case 144:
		goto loc_830A7F44;
	case 145:
		goto loc_830A7F50;
	case 146:
		goto loc_830A7F5C;
	case 147:
		goto loc_830A7F64;
	case 148:
		goto loc_830A7F70;
	case 149:
		goto loc_830A7F7C;
	case 150:
		goto loc_830A7F88;
	case 151:
		goto loc_830A7F94;
	case 152:
		goto loc_830A7FA0;
	case 153:
		goto loc_830A7FAC;
	case 154:
		goto loc_830A7FB8;
	case 155:
		goto loc_830A7FC4;
	case 156:
		goto loc_830A7FD0;
	case 157:
		goto loc_830A7FDC;
	case 158:
		goto loc_830A7FE8;
	case 159:
		goto loc_830A7FF0;
	case 160:
		goto loc_830A7FFC;
	case 161:
		goto loc_830A8004;
	case 162:
		goto loc_830A8010;
	case 163:
		goto loc_830A801C;
	case 164:
		goto loc_830A8024;
	case 165:
		goto loc_830A8030;
	case 166:
		goto loc_830A803C;
	case 167:
		goto loc_830A8048;
	case 168:
		goto loc_830A8054;
	case 169:
		goto loc_830A8060;
	case 170:
		goto loc_830A806C;
	case 171:
		goto loc_830A8078;
	case 172:
		goto loc_830A8084;
	case 173:
		goto loc_830A808C;
	case 174:
		goto loc_830A8098;
	case 175:
		goto loc_830A80A4;
	case 176:
		goto loc_830A80B0;
	case 177:
		goto loc_830A80BC;
	case 178:
		goto loc_830A80C8;
	case 179:
		goto loc_830A80D4;
	case 180:
		goto loc_830A80E0;
	case 181:
		goto loc_830A80EC;
	case 182:
		goto loc_830A80F8;
	case 183:
		goto loc_830A8104;
	case 184:
		goto loc_830A8110;
	case 185:
		goto loc_830A8118;
	case 186:
		goto loc_830A8124;
	case 187:
		goto loc_830A8130;
	case 188:
		goto loc_830A813C;
	case 189:
		goto loc_830A8148;
	case 190:
		goto loc_830A8154;
	case 191:
		goto loc_830A8160;
	case 192:
		goto loc_830A816C;
	case 193:
		goto loc_830A8178;
	case 194:
		goto loc_830A8184;
	case 195:
		goto loc_830A818C;
	case 196:
		goto loc_830A8194;
	case 197:
		goto loc_830A81A0;
	case 198:
		goto loc_830A81AC;
	case 199:
		goto loc_830A81B8;
	case 200:
		goto loc_830A81C4;
	case 201:
		goto loc_830A81D0;
	case 202:
		goto loc_830A81DC;
	case 203:
		goto loc_830A81E8;
	case 204:
		goto loc_830A81F4;
	case 205:
		goto loc_830A8200;
	case 206:
		goto loc_830A8208;
	case 207:
		goto loc_830A8210;
	case 208:
		goto loc_830A8218;
	case 209:
		goto loc_830A8220;
	case 210:
		goto loc_830A8228;
	case 211:
		goto loc_830A8230;
	case 212:
		goto loc_830A8238;
	case 213:
		goto loc_830A8240;
	case 214:
		goto loc_830A8248;
	case 215:
		goto loc_830A8250;
	case 216:
		goto loc_830A8258;
	case 217:
		goto loc_830A8260;
	case 218:
		goto loc_830A8268;
	case 219:
		goto loc_830A8274;
	case 220:
		goto loc_830A8280;
	case 221:
		goto loc_830A828C;
	case 222:
		goto loc_830A8298;
	case 223:
		goto loc_830A82A4;
	case 224:
		goto loc_830A82AC;
	case 225:
		goto loc_830A82B4;
	case 226:
		goto loc_830A82C0;
	case 227:
		goto loc_830A82CC;
	case 228:
		goto loc_830A82D8;
	case 229:
		goto loc_830A82E4;
	case 230:
		goto loc_830A82F0;
	case 231:
		goto loc_830A82F8;
	case 232:
		goto loc_830A8300;
	case 233:
		goto loc_830A830C;
	case 234:
		goto loc_830A8318;
	case 235:
		goto loc_830A8324;
	case 236:
		goto loc_830A8330;
	case 237:
		goto loc_830A8338;
	case 238:
		goto loc_830A8344;
	case 239:
		goto loc_830A834C;
	case 240:
		goto loc_830A8354;
	case 241:
		goto loc_830A8360;
	case 242:
		goto loc_830A836C;
	case 243:
		goto loc_830A8378;
	case 244:
		goto loc_830A8384;
	case 245:
		goto loc_830A8390;
	case 246:
		goto loc_830A839C;
	case 247:
		goto loc_830A83A8;
	case 248:
		goto loc_830A83B0;
	case 249:
		goto loc_830A83B8;
	case 250:
		goto loc_830A83C0;
	case 251:
		goto loc_830A83C8;
	case 252:
		goto loc_830A83D4;
	case 253:
		goto loc_830A83E0;
	case 254:
		goto loc_830A83EC;
	case 255:
		goto loc_830A83F8;
	case 256:
		goto loc_830A8404;
	case 257:
		goto loc_830A8410;
	case 258:
		goto loc_830A841C;
	case 259:
		goto loc_830A8428;
	case 260:
		goto loc_830A8434;
	case 261:
		goto loc_830A843C;
	case 262:
		goto loc_830A8444;
	case 263:
		goto loc_830A8450;
	case 264:
		goto loc_830A845C;
	case 265:
		goto loc_830A8464;
	case 266:
		goto loc_830A8470;
	case 267:
		goto loc_830A8478;
	case 268:
		goto loc_830A8484;
	case 269:
		goto loc_830A8490;
	case 270:
		goto loc_830A849C;
	case 271:
		goto loc_830A84A4;
	case 272:
		goto loc_830A84B0;
	case 273:
		goto loc_830A84BC;
	case 274:
		goto loc_830A84C8;
	case 275:
		goto loc_830A84D0;
	case 276:
		goto loc_830A84D8;
	case 277:
		goto loc_830A84E0;
	case 278:
		goto loc_830A84EC;
	case 279:
		goto loc_830A84F8;
	case 280:
		goto loc_830A8504;
	case 281:
		goto loc_830A8510;
	case 282:
		goto loc_830A851C;
	case 283:
		goto loc_830A8528;
	case 284:
		goto loc_830A8534;
	case 285:
		goto loc_830A8540;
	case 286:
		goto loc_830A854C;
	case 287:
		goto loc_830A8558;
	case 288:
		goto loc_830A8564;
	case 289:
		goto loc_830A8570;
	case 290:
		goto loc_830A857C;
	case 291:
		goto loc_830A8588;
	case 292:
		goto loc_830A8594;
	case 293:
		goto loc_830A85A0;
	case 294:
		goto loc_830A85AC;
	case 295:
		goto loc_830A85B8;
	case 296:
		goto loc_830A85C4;
	case 297:
		goto loc_830A85CC;
	case 298:
		goto loc_830A85D8;
	case 299:
		goto loc_830A85E4;
	case 300:
		goto loc_830A85F0;
	case 301:
		goto loc_830A85FC;
	case 302:
		goto loc_830A8608;
	case 303:
		goto loc_830A8610;
	case 304:
		goto loc_830A8618;
	case 305:
		goto loc_830A8624;
	case 306:
		goto loc_830A8630;
	case 307:
		goto loc_830A8638;
	case 308:
		goto loc_830A8644;
	case 309:
		goto loc_830A864C;
	case 310:
		goto loc_830A8658;
	case 311:
		goto loc_830A8660;
	case 312:
		goto loc_830A8668;
	case 313:
		goto loc_830A8674;
	case 314:
		goto loc_830A8680;
	case 315:
		goto loc_830A868C;
	case 316:
		goto loc_830A8698;
	case 317:
		goto loc_830A86A0;
	case 318:
		goto loc_830A86AC;
	case 319:
		goto loc_830A86B8;
	case 320:
		goto loc_830A86C4;
	case 321:
		goto loc_830A86D0;
	case 322:
		goto loc_830A86DC;
	case 323:
		goto loc_830A86E8;
	case 324:
		goto loc_830A86F4;
	case 325:
		goto loc_830A8700;
	case 326:
		goto loc_830A870C;
	case 327:
		goto loc_830A8718;
	case 328:
		goto loc_830A8724;
	case 329:
		goto loc_830A8730;
	case 330:
		goto loc_830A873C;
	case 331:
		goto loc_830A8748;
	case 332:
		goto loc_830A8754;
	case 333:
		goto loc_830A8760;
	case 334:
		goto loc_830A876C;
	case 335:
		goto loc_830A8778;
	case 336:
		goto loc_830A8784;
	case 337:
		goto loc_830A8790;
	case 338:
		goto loc_830A879C;
	case 339:
		goto loc_830A87A8;
	case 340:
		goto loc_830A87B4;
	case 341:
		goto loc_830A87C0;
	case 342:
		goto loc_830A87CC;
	case 343:
		goto loc_830A87D8;
	case 344:
		goto loc_830A87E4;
	case 345:
		goto loc_830A87F0;
	case 346:
		goto loc_830A87FC;
	case 347:
		goto loc_830A8808;
	case 348:
		goto loc_830A8814;
	case 349:
		goto loc_830A8820;
	case 350:
		goto loc_830A882C;
	case 351:
		goto loc_830A8838;
	case 352:
		goto loc_830A8844;
	case 353:
		goto loc_830A8850;
	case 354:
		goto loc_830A885C;
	case 355:
		goto loc_830A8868;
	case 356:
		goto loc_830A8874;
	case 357:
		goto loc_830A8880;
	case 358:
		goto loc_830A888C;
	case 359:
		goto loc_830A8898;
	case 360:
		goto loc_830A88A4;
	case 361:
		goto loc_830A88B0;
	case 362:
		goto loc_830A88BC;
	case 363:
		goto loc_830A88C8;
	case 364:
		goto loc_830A88D4;
	case 365:
		goto loc_830A88E0;
	case 366:
		goto loc_830A88EC;
	case 367:
		goto loc_830A88F8;
	case 368:
		goto loc_830A8904;
	case 369:
		goto loc_830A8910;
	case 370:
		goto loc_830A891C;
	case 371:
		goto loc_830A8928;
	case 372:
		goto loc_830A8934;
	case 373:
		goto loc_830A8940;
	case 374:
		goto loc_830A894C;
	case 375:
		goto loc_830A8958;
	case 376:
		goto loc_830A8964;
	case 377:
		goto loc_830A8970;
	case 378:
		goto loc_830A897C;
	case 379:
		goto loc_830A8988;
	case 380:
		goto loc_830A8994;
	case 381:
		goto loc_830A89A0;
	case 382:
		goto loc_830A89AC;
	case 383:
		goto loc_830A89B8;
	case 384:
		goto loc_830A89C4;
	case 385:
		goto loc_830A89D0;
	case 386:
		goto loc_830A89DC;
	case 387:
		goto loc_830A89E8;
	case 388:
		goto loc_830A89F4;
	case 389:
		goto loc_830A8A00;
	case 390:
		goto loc_830A8A0C;
	case 391:
		goto loc_830A8A18;
	case 392:
		goto loc_830A8A24;
	case 393:
		goto loc_830A8A30;
	case 394:
		goto loc_830A8A3C;
	case 395:
		goto loc_830A8A48;
	case 396:
		goto loc_830A8A54;
	case 397:
		goto loc_830A8A5C;
	case 398:
		goto loc_830A8A68;
	case 399:
		goto loc_830A8A74;
	case 400:
		goto loc_830A8A80;
	case 401:
		goto loc_830A8A8C;
	case 402:
		goto loc_830A8A98;
	case 403:
		goto loc_830A8AA4;
	case 404:
		goto loc_830A8AB0;
	case 405:
		goto loc_830A8ABC;
	case 406:
		goto loc_830A8AC8;
	case 407:
		goto loc_830A8AD4;
	case 408:
		goto loc_830A8AE0;
	case 409:
		goto loc_830A8AE8;
	case 410:
		goto loc_830A8AF4;
	case 411:
		goto loc_830A8B00;
	case 412:
		goto loc_830A8B08;
	case 413:
		goto loc_830A8B10;
	case 414:
		goto loc_830A8B18;
	case 415:
		goto loc_830A8B20;
	case 416:
		goto loc_830A8B28;
	case 417:
		goto loc_830A8B30;
	case 418:
		goto loc_830A8B38;
	case 419:
		goto loc_830A8B44;
	case 420:
		goto loc_830A8B50;
	case 421:
		goto loc_830A8B58;
	case 422:
		goto loc_830A8B60;
	case 423:
		goto loc_830A8B68;
	case 424:
		goto loc_830A8B70;
	case 425:
		goto loc_830A8B78;
	default:
		__builtin_unreachable();
	}
loc_830A7974:
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A797C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7988:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7994:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A79A0:
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A79A8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,5
	ctx.r4.s64 = 5;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A79B4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,6
	ctx.r4.s64 = 6;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A79C0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A79CC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A79D8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,12
	ctx.r4.s64 = 12;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A79E4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,9
	ctx.r4.s64 = 9;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A79F0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,10
	ctx.r4.s64 = 10;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A79FC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,11
	ctx.r4.s64 = 11;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7A08:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,13
	ctx.r4.s64 = 13;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7A14:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,14
	ctx.r4.s64 = 14;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7A20:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,15
	ctx.r4.s64 = 15;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7A2C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,18
	ctx.r4.s64 = 18;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7A38:
	// li r4,16
	ctx.r4.s64 = 16;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7A40:
	// li r4,17
	ctx.r4.s64 = 17;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7A48:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,19
	ctx.r4.s64 = 19;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7A54:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,20
	ctx.r4.s64 = 20;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7A60:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,21
	ctx.r4.s64 = 21;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7A6C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,22
	ctx.r4.s64 = 22;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7A78:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,25
	ctx.r4.s64 = 25;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7A84:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,26
	ctx.r4.s64 = 26;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7A90:
	// li r4,24
	ctx.r4.s64 = 24;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7A98:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,27
	ctx.r4.s64 = 27;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7AA4:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,28
	ctx.r4.s64 = 28;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7AB0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,31
	ctx.r4.s64 = 31;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7ABC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,32
	ctx.r4.s64 = 32;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7AC8:
	// li r4,30
	ctx.r4.s64 = 30;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7AD0:
	// li r4,35
	ctx.r4.s64 = 35;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7AD8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,36
	ctx.r4.s64 = 36;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7AE4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,33
	ctx.r4.s64 = 33;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7AF0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,34
	ctx.r4.s64 = 34;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7AFC:
	// li r4,37
	ctx.r4.s64 = 37;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B04:
	// li r4,38
	ctx.r4.s64 = 38;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B0C:
	// li r4,39
	ctx.r4.s64 = 39;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B14:
	// li r4,40
	ctx.r4.s64 = 40;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B1C:
	// li r4,41
	ctx.r4.s64 = 41;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B24:
	// li r4,42
	ctx.r4.s64 = 42;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B2C:
	// li r4,43
	ctx.r4.s64 = 43;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B34:
	// li r4,44
	ctx.r4.s64 = 44;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B3C:
	// li r4,45
	ctx.r4.s64 = 45;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B44:
	// li r4,46
	ctx.r4.s64 = 46;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B4C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,47
	ctx.r4.s64 = 47;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7B58:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,48
	ctx.r4.s64 = 48;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7B64:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,52
	ctx.r4.s64 = 52;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7B70:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,53
	ctx.r4.s64 = 53;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7B7C:
	// li r4,54
	ctx.r4.s64 = 54;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B84:
	// li r4,55
	ctx.r4.s64 = 55;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B8C:
	// li r4,56
	ctx.r4.s64 = 56;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7B94:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,57
	ctx.r4.s64 = 57;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7BA0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,58
	ctx.r4.s64 = 58;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7BAC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,61
	ctx.r4.s64 = 61;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7BB8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,62
	ctx.r4.s64 = 62;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7BC4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,63
	ctx.r4.s64 = 63;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7BD0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,64
	ctx.r4.s64 = 64;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7BDC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,65
	ctx.r4.s64 = 65;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7BE8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,66
	ctx.r4.s64 = 66;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7BF4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,67
	ctx.r4.s64 = 67;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C00:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,68
	ctx.r4.s64 = 68;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C0C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,69
	ctx.r4.s64 = 69;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C18:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,70
	ctx.r4.s64 = 70;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C24:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,71
	ctx.r4.s64 = 71;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C30:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,72
	ctx.r4.s64 = 72;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C3C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,73
	ctx.r4.s64 = 73;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C48:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,74
	ctx.r4.s64 = 74;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C54:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,75
	ctx.r4.s64 = 75;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C60:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,76
	ctx.r4.s64 = 76;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C6C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,77
	ctx.r4.s64 = 77;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C78:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,78
	ctx.r4.s64 = 78;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C84:
	// li r4,79
	ctx.r4.s64 = 79;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7C8C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,80
	ctx.r4.s64 = 80;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7C98:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,81
	ctx.r4.s64 = 81;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7CA4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,82
	ctx.r4.s64 = 82;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7CB0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,83
	ctx.r4.s64 = 83;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7CBC:
	// li r4,84
	ctx.r4.s64 = 84;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7CC4:
	// li r4,85
	ctx.r4.s64 = 85;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7CCC:
	// li r4,86
	ctx.r4.s64 = 86;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7CD4:
	// li r4,87
	ctx.r4.s64 = 87;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7CDC:
	// li r4,88
	ctx.r4.s64 = 88;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7CE4:
	// li r4,89
	ctx.r4.s64 = 89;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7CEC:
	// li r4,90
	ctx.r4.s64 = 90;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7CF4:
	// li r4,91
	ctx.r4.s64 = 91;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7CFC:
	// li r4,92
	ctx.r4.s64 = 92;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7D04:
	// li r4,93
	ctx.r4.s64 = 93;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7D0C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,94
	ctx.r4.s64 = 94;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7D18:
	// li r4,95
	ctx.r4.s64 = 95;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7D20:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,96
	ctx.r4.s64 = 96;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7D2C:
	// li r4,97
	ctx.r4.s64 = 97;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7D34:
	// li r4,98
	ctx.r4.s64 = 98;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7D3C:
	// li r4,99
	ctx.r4.s64 = 99;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7D44:
	// li r4,100
	ctx.r4.s64 = 100;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7D4C:
	// li r4,101
	ctx.r4.s64 = 101;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7D54:
	// li r4,102
	ctx.r4.s64 = 102;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7D5C:
	// li r4,103
	ctx.r4.s64 = 103;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7D64:
	// li r4,104
	ctx.r4.s64 = 104;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7D6C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,105
	ctx.r4.s64 = 105;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7D78:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,106
	ctx.r4.s64 = 106;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7D84:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,107
	ctx.r4.s64 = 107;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7D90:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,108
	ctx.r4.s64 = 108;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7D9C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,109
	ctx.r4.s64 = 109;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7DA8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,110
	ctx.r4.s64 = 110;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7DB4:
	// li r4,123
	ctx.r4.s64 = 123;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7DBC:
	// li r4,124
	ctx.r4.s64 = 124;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7DC4:
	// li r4,111
	ctx.r4.s64 = 111;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7DCC:
	// li r4,112
	ctx.r4.s64 = 112;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7DD4:
	// li r4,113
	ctx.r4.s64 = 113;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7DDC:
	// li r4,114
	ctx.r4.s64 = 114;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7DE4:
	// li r4,115
	ctx.r4.s64 = 115;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7DEC:
	// li r4,116
	ctx.r4.s64 = 116;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7DF4:
	// li r4,129
	ctx.r4.s64 = 129;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7DFC:
	// li r4,117
	ctx.r4.s64 = 117;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7E04:
	// li r4,118
	ctx.r4.s64 = 118;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7E0C:
	// li r4,125
	ctx.r4.s64 = 125;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7E14:
	// li r4,119
	ctx.r4.s64 = 119;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7E1C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,120
	ctx.r4.s64 = 120;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7E28:
	// li r4,126
	ctx.r4.s64 = 126;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7E30:
	// li r4,127
	ctx.r4.s64 = 127;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7E38:
	// li r4,128
	ctx.r4.s64 = 128;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7E40:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,130
	ctx.r4.s64 = 130;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7E4C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,131
	ctx.r4.s64 = 131;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7E58:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,132
	ctx.r4.s64 = 132;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7E64:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,121
	ctx.r4.s64 = 121;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7E70:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,122
	ctx.r4.s64 = 122;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7E7C:
	// li r4,134
	ctx.r4.s64 = 134;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7E84:
	// li r4,133
	ctx.r4.s64 = 133;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7E8C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,138
	ctx.r4.s64 = 138;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7E98:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,139
	ctx.r4.s64 = 139;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7EA4:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,140
	ctx.r4.s64 = 140;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7EB0:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,141
	ctx.r4.s64 = 141;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7EBC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,142
	ctx.r4.s64 = 142;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7EC8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,143
	ctx.r4.s64 = 143;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7ED4:
	// li r4,144
	ctx.r4.s64 = 144;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7EDC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,145
	ctx.r4.s64 = 145;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7EE8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,146
	ctx.r4.s64 = 146;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7EF4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,147
	ctx.r4.s64 = 147;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F00:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,148
	ctx.r4.s64 = 148;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F0C:
	// li r4,149
	ctx.r4.s64 = 149;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7F14:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,150
	ctx.r4.s64 = 150;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F20:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,151
	ctx.r4.s64 = 151;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F2C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,152
	ctx.r4.s64 = 152;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F38:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,153
	ctx.r4.s64 = 153;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F44:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,154
	ctx.r4.s64 = 154;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F50:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,155
	ctx.r4.s64 = 155;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F5C:
	// li r4,156
	ctx.r4.s64 = 156;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7F64:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,157
	ctx.r4.s64 = 157;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F70:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,158
	ctx.r4.s64 = 158;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F7C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,159
	ctx.r4.s64 = 159;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F88:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,160
	ctx.r4.s64 = 160;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7F94:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,161
	ctx.r4.s64 = 161;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7FA0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,162
	ctx.r4.s64 = 162;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7FAC:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,163
	ctx.r4.s64 = 163;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7FB8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,164
	ctx.r4.s64 = 164;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7FC4:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,165
	ctx.r4.s64 = 165;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7FD0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,166
	ctx.r4.s64 = 166;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7FDC:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,167
	ctx.r4.s64 = 167;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7FE8:
	// li r4,168
	ctx.r4.s64 = 168;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A7FF0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,169
	ctx.r4.s64 = 169;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A7FFC:
	// li r4,170
	ctx.r4.s64 = 170;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8004:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,171
	ctx.r4.s64 = 171;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8010:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,172
	ctx.r4.s64 = 172;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A801C:
	// li r4,173
	ctx.r4.s64 = 173;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8024:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,174
	ctx.r4.s64 = 174;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8030:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,175
	ctx.r4.s64 = 175;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A803C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,176
	ctx.r4.s64 = 176;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8048:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,177
	ctx.r4.s64 = 177;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8054:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,178
	ctx.r4.s64 = 178;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8060:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,179
	ctx.r4.s64 = 179;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A806C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,180
	ctx.r4.s64 = 180;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8078:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,181
	ctx.r4.s64 = 181;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8084:
	// li r4,182
	ctx.r4.s64 = 182;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A808C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,183
	ctx.r4.s64 = 183;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8098:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,184
	ctx.r4.s64 = 184;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A80A4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,185
	ctx.r4.s64 = 185;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A80B0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,186
	ctx.r4.s64 = 186;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A80BC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,187
	ctx.r4.s64 = 187;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A80C8:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,188
	ctx.r4.s64 = 188;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A80D4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,189
	ctx.r4.s64 = 189;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A80E0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,190
	ctx.r4.s64 = 190;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A80EC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,191
	ctx.r4.s64 = 191;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A80F8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,192
	ctx.r4.s64 = 192;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8104:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,193
	ctx.r4.s64 = 193;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8110:
	// li r4,194
	ctx.r4.s64 = 194;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8118:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,195
	ctx.r4.s64 = 195;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8124:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,196
	ctx.r4.s64 = 196;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8130:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,197
	ctx.r4.s64 = 197;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A813C:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,198
	ctx.r4.s64 = 198;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8148:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,199
	ctx.r4.s64 = 199;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8154:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,200
	ctx.r4.s64 = 200;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8160:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,201
	ctx.r4.s64 = 201;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A816C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,202
	ctx.r4.s64 = 202;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8178:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,203
	ctx.r4.s64 = 203;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8184:
	// li r4,204
	ctx.r4.s64 = 204;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A818C:
	// li r4,205
	ctx.r4.s64 = 205;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8194:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,206
	ctx.r4.s64 = 206;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A81A0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,207
	ctx.r4.s64 = 207;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A81AC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,208
	ctx.r4.s64 = 208;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A81B8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,209
	ctx.r4.s64 = 209;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A81C4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,210
	ctx.r4.s64 = 210;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A81D0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,213
	ctx.r4.s64 = 213;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A81DC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,214
	ctx.r4.s64 = 214;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A81E8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,215
	ctx.r4.s64 = 215;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A81F4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,216
	ctx.r4.s64 = 216;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8200:
	// li r4,217
	ctx.r4.s64 = 217;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8208:
	// li r4,218
	ctx.r4.s64 = 218;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8210:
	// li r4,219
	ctx.r4.s64 = 219;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8218:
	// li r4,220
	ctx.r4.s64 = 220;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8220:
	// li r4,221
	ctx.r4.s64 = 221;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8228:
	// li r4,222
	ctx.r4.s64 = 222;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8230:
	// li r4,223
	ctx.r4.s64 = 223;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8238:
	// li r4,224
	ctx.r4.s64 = 224;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8240:
	// li r4,225
	ctx.r4.s64 = 225;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8248:
	// li r4,226
	ctx.r4.s64 = 226;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8250:
	// li r4,227
	ctx.r4.s64 = 227;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8258:
	// li r4,228
	ctx.r4.s64 = 228;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8260:
	// li r4,229
	ctx.r4.s64 = 229;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8268:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,230
	ctx.r4.s64 = 230;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8274:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,231
	ctx.r4.s64 = 231;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8280:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,232
	ctx.r4.s64 = 232;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A828C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,233
	ctx.r4.s64 = 233;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8298:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,234
	ctx.r4.s64 = 234;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A82A4:
	// li r4,235
	ctx.r4.s64 = 235;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A82AC:
	// li r4,236
	ctx.r4.s64 = 236;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A82B4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,237
	ctx.r4.s64 = 237;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A82C0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,238
	ctx.r4.s64 = 238;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A82CC:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,239
	ctx.r4.s64 = 239;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A82D8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,240
	ctx.r4.s64 = 240;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A82E4:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,241
	ctx.r4.s64 = 241;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A82F0:
	// li r4,242
	ctx.r4.s64 = 242;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A82F8:
	// li r4,243
	ctx.r4.s64 = 243;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8300:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,244
	ctx.r4.s64 = 244;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A830C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,245
	ctx.r4.s64 = 245;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8318:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,246
	ctx.r4.s64 = 246;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8324:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,248
	ctx.r4.s64 = 248;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8330:
	// li r4,250
	ctx.r4.s64 = 250;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8338:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,251
	ctx.r4.s64 = 251;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8344:
	// li r4,252
	ctx.r4.s64 = 252;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A834C:
	// li r4,253
	ctx.r4.s64 = 253;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8354:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,409
	ctx.r4.s64 = 409;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8360:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,410
	ctx.r4.s64 = 410;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A836C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,411
	ctx.r4.s64 = 411;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8378:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,412
	ctx.r4.s64 = 412;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8384:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,413
	ctx.r4.s64 = 413;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8390:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,414
	ctx.r4.s64 = 414;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A839C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,415
	ctx.r4.s64 = 415;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A83A8:
	// li r4,416
	ctx.r4.s64 = 416;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A83B0:
	// li r4,417
	ctx.r4.s64 = 417;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A83B8:
	// li r4,418
	ctx.r4.s64 = 418;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A83C0:
	// li r4,419
	ctx.r4.s64 = 419;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A83C8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,306
	ctx.r4.s64 = 306;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A83D4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,307
	ctx.r4.s64 = 307;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A83E0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,308
	ctx.r4.s64 = 308;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A83EC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,309
	ctx.r4.s64 = 309;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A83F8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,310
	ctx.r4.s64 = 310;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8404:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,311
	ctx.r4.s64 = 311;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8410:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,312
	ctx.r4.s64 = 312;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A841C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,254
	ctx.r4.s64 = 254;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8428:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,255
	ctx.r4.s64 = 255;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8434:
	// li r4,256
	ctx.r4.s64 = 256;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A843C:
	// li r4,257
	ctx.r4.s64 = 257;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8444:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,258
	ctx.r4.s64 = 258;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8450:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,259
	ctx.r4.s64 = 259;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A845C:
	// li r4,260
	ctx.r4.s64 = 260;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8464:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,261
	ctx.r4.s64 = 261;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8470:
	// li r4,262
	ctx.r4.s64 = 262;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8478:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,263
	ctx.r4.s64 = 263;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8484:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,264
	ctx.r4.s64 = 264;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8490:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,265
	ctx.r4.s64 = 265;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A849C:
	// li r4,266
	ctx.r4.s64 = 266;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A84A4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,267
	ctx.r4.s64 = 267;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A84B0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,268
	ctx.r4.s64 = 268;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A84BC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,269
	ctx.r4.s64 = 269;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A84C8:
	// li r4,270
	ctx.r4.s64 = 270;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A84D0:
	// li r4,271
	ctx.r4.s64 = 271;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A84D8:
	// li r4,272
	ctx.r4.s64 = 272;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A84E0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,273
	ctx.r4.s64 = 273;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A84EC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,274
	ctx.r4.s64 = 274;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A84F8:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,275
	ctx.r4.s64 = 275;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8504:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,276
	ctx.r4.s64 = 276;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8510:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,277
	ctx.r4.s64 = 277;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A851C:
	// li r5,6
	ctx.r5.s64 = 6;
	// li r4,278
	ctx.r4.s64 = 278;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8528:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,279
	ctx.r4.s64 = 279;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8534:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,280
	ctx.r4.s64 = 280;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8540:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,281
	ctx.r4.s64 = 281;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A854C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,282
	ctx.r4.s64 = 282;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8558:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,283
	ctx.r4.s64 = 283;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8564:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,284
	ctx.r4.s64 = 284;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8570:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,285
	ctx.r4.s64 = 285;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A857C:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,286
	ctx.r4.s64 = 286;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8588:
	// li r5,6
	ctx.r5.s64 = 6;
	// li r4,287
	ctx.r4.s64 = 287;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8594:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,288
	ctx.r4.s64 = 288;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A85A0:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,289
	ctx.r4.s64 = 289;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A85AC:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,290
	ctx.r4.s64 = 290;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A85B8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,291
	ctx.r4.s64 = 291;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A85C4:
	// li r4,292
	ctx.r4.s64 = 292;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A85CC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,293
	ctx.r4.s64 = 293;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A85D8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,294
	ctx.r4.s64 = 294;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A85E4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,295
	ctx.r4.s64 = 295;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A85F0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,296
	ctx.r4.s64 = 296;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A85FC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,297
	ctx.r4.s64 = 297;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8608:
	// li r4,298
	ctx.r4.s64 = 298;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8610:
	// li r4,299
	ctx.r4.s64 = 299;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8618:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,300
	ctx.r4.s64 = 300;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8624:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,301
	ctx.r4.s64 = 301;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8630:
	// li r4,302
	ctx.r4.s64 = 302;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8638:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,303
	ctx.r4.s64 = 303;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8644:
	// li r4,304
	ctx.r4.s64 = 304;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A864C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,305
	ctx.r4.s64 = 305;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8658:
	// li r4,313
	ctx.r4.s64 = 313;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8660:
	// li r4,314
	ctx.r4.s64 = 314;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8668:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,315
	ctx.r4.s64 = 315;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8674:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,316
	ctx.r4.s64 = 316;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8680:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,317
	ctx.r4.s64 = 317;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A868C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,318
	ctx.r4.s64 = 318;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8698:
	// li r4,319
	ctx.r4.s64 = 319;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A86A0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,320
	ctx.r4.s64 = 320;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A86AC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,321
	ctx.r4.s64 = 321;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A86B8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,322
	ctx.r4.s64 = 322;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A86C4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,323
	ctx.r4.s64 = 323;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A86D0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,324
	ctx.r4.s64 = 324;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A86DC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,325
	ctx.r4.s64 = 325;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A86E8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,326
	ctx.r4.s64 = 326;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A86F4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,327
	ctx.r4.s64 = 327;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8700:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,328
	ctx.r4.s64 = 328;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A870C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,329
	ctx.r4.s64 = 329;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8718:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,330
	ctx.r4.s64 = 330;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8724:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,331
	ctx.r4.s64 = 331;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8730:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,332
	ctx.r4.s64 = 332;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A873C:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,333
	ctx.r4.s64 = 333;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8748:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,334
	ctx.r4.s64 = 334;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8754:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,335
	ctx.r4.s64 = 335;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8760:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,336
	ctx.r4.s64 = 336;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A876C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,337
	ctx.r4.s64 = 337;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8778:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,338
	ctx.r4.s64 = 338;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8784:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,339
	ctx.r4.s64 = 339;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8790:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,340
	ctx.r4.s64 = 340;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A879C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,341
	ctx.r4.s64 = 341;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A87A8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,342
	ctx.r4.s64 = 342;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A87B4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,343
	ctx.r4.s64 = 343;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A87C0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,344
	ctx.r4.s64 = 344;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A87CC:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,345
	ctx.r4.s64 = 345;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A87D8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,346
	ctx.r4.s64 = 346;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A87E4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,347
	ctx.r4.s64 = 347;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A87F0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,348
	ctx.r4.s64 = 348;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A87FC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,349
	ctx.r4.s64 = 349;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8808:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,350
	ctx.r4.s64 = 350;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8814:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,351
	ctx.r4.s64 = 351;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8820:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,352
	ctx.r4.s64 = 352;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A882C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,353
	ctx.r4.s64 = 353;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8838:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,354
	ctx.r4.s64 = 354;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8844:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,355
	ctx.r4.s64 = 355;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8850:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,356
	ctx.r4.s64 = 356;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A885C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,357
	ctx.r4.s64 = 357;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8868:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,358
	ctx.r4.s64 = 358;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8874:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,359
	ctx.r4.s64 = 359;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8880:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,360
	ctx.r4.s64 = 360;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A888C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,361
	ctx.r4.s64 = 361;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8898:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,362
	ctx.r4.s64 = 362;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A88A4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,363
	ctx.r4.s64 = 363;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A88B0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,364
	ctx.r4.s64 = 364;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A88BC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,365
	ctx.r4.s64 = 365;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A88C8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,366
	ctx.r4.s64 = 366;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A88D4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,367
	ctx.r4.s64 = 367;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A88E0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,368
	ctx.r4.s64 = 368;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A88EC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,369
	ctx.r4.s64 = 369;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A88F8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,370
	ctx.r4.s64 = 370;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8904:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,371
	ctx.r4.s64 = 371;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8910:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,372
	ctx.r4.s64 = 372;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A891C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,373
	ctx.r4.s64 = 373;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8928:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,374
	ctx.r4.s64 = 374;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8934:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,375
	ctx.r4.s64 = 375;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8940:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,376
	ctx.r4.s64 = 376;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A894C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,377
	ctx.r4.s64 = 377;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8958:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,378
	ctx.r4.s64 = 378;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8964:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,379
	ctx.r4.s64 = 379;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8970:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,380
	ctx.r4.s64 = 380;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A897C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,381
	ctx.r4.s64 = 381;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8988:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,382
	ctx.r4.s64 = 382;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8994:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,395
	ctx.r4.s64 = 395;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A89A0:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,396
	ctx.r4.s64 = 396;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A89AC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,383
	ctx.r4.s64 = 383;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A89B8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,384
	ctx.r4.s64 = 384;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A89C4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,385
	ctx.r4.s64 = 385;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A89D0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,386
	ctx.r4.s64 = 386;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A89DC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,387
	ctx.r4.s64 = 387;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A89E8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,388
	ctx.r4.s64 = 388;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A89F4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,389
	ctx.r4.s64 = 389;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A00:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,390
	ctx.r4.s64 = 390;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A0C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,391
	ctx.r4.s64 = 391;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A18:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,392
	ctx.r4.s64 = 392;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A24:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,393
	ctx.r4.s64 = 393;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A30:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,394
	ctx.r4.s64 = 394;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A3C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,397
	ctx.r4.s64 = 397;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A48:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,398
	ctx.r4.s64 = 398;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A54:
	// li r4,399
	ctx.r4.s64 = 399;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8A5C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,400
	ctx.r4.s64 = 400;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A68:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,401
	ctx.r4.s64 = 401;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A74:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,402
	ctx.r4.s64 = 402;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A80:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,403
	ctx.r4.s64 = 403;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A8C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,404
	ctx.r4.s64 = 404;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8A98:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,405
	ctx.r4.s64 = 405;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8AA4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,406
	ctx.r4.s64 = 406;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8AB0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,407
	ctx.r4.s64 = 407;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8ABC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,408
	ctx.r4.s64 = 408;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8AC8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,420
	ctx.r4.s64 = 420;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8AD4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,421
	ctx.r4.s64 = 421;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8AE0:
	// li r4,422
	ctx.r4.s64 = 422;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8AE8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,423
	ctx.r4.s64 = 423;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8AF4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,424
	ctx.r4.s64 = 424;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8B00:
	// li r4,425
	ctx.r4.s64 = 425;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B08:
	// li r4,426
	ctx.r4.s64 = 426;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B10:
	// li r4,427
	ctx.r4.s64 = 427;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B18:
	// li r4,428
	ctx.r4.s64 = 428;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B20:
	// li r4,429
	ctx.r4.s64 = 429;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B28:
	// li r4,430
	ctx.r4.s64 = 430;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B30:
	// li r4,431
	ctx.r4.s64 = 431;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B38:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,432
	ctx.r4.s64 = 432;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8B44:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,433
	ctx.r4.s64 = 433;
	// b 0x830a8b80
	goto loc_830A8B80;
loc_830A8B50:
	// li r4,434
	ctx.r4.s64 = 434;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B58:
	// li r4,435
	ctx.r4.s64 = 435;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B60:
	// li r4,436
	ctx.r4.s64 = 436;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B68:
	// li r4,437
	ctx.r4.s64 = 437;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B70:
	// li r4,438
	ctx.r4.s64 = 438;
	// b 0x830a8b7c
	goto loc_830A8B7C;
loc_830A8B78:
	// li r4,439
	ctx.r4.s64 = 439;
loc_830A8B7C:
	// li r5,0
	ctx.r5.s64 = 0;
loc_830A8B80:
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 3032);
	// bl 0x830a52f0
	sub_830A52F0(ctx, base);
loc_830A8B88:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r10,r29,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r8,r27,-3296
	ctx.r8.s64 = r27.s64 + -3296;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// subf r10,r28,r9
	ctx.r10.s64 = ctx.r9.s64 - r28.s64;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lha r11,0(r11)
	r11.s64 = int16_t(PPC_LOAD_U16(r11.u32 + 0));
	// stw r10,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r10.u32);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lhax r10,r30,r8
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(r30.u32 + ctx.r8.u32));
	// bne 0x830a8c24
	if (!cr0.eq) goto loc_830A8C24;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x830a8c24
	if (!cr6.eq) goto loc_830A8C24;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r10,66
	ctx.r10.s64 = 66;
	// li r30,66
	r30.s64 = 66;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// sth r10,0(r11)
	PPC_STORE_U16(r11.u32 + 0, ctx.r10.u16);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x830a8c10
	if (!cr6.lt) goto loc_830A8C10;
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 3032);
	// bl 0x830a0630
	sub_830A0630(ctx, base);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830a8c10
	if (!cr0.lt) goto loc_830A8C10;
	// stw r24,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r24.u32);
loc_830A8C10:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830a7824
	if (!cr6.eq) goto loc_830A7824;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830a8d8c
	goto loc_830A8D8C;
loc_830A8C24:
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r27,3456
	ctx.r10.s64 = r27.s64 + 3456;
	// lhax r10,r9,r10
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + ctx.r10.u32));
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830a8c64
	if (cr0.eq) goto loc_830A8C64;
	// add. r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt 0x830a8c64
	if (cr0.lt) goto loc_830A8C64;
	// cmpwi cr6,r10,7525
	cr6.compare<int32_t>(ctx.r10.s32, 7525, xer);
	// bgt cr6,0x830a8c64
	if (cr6.gt) goto loc_830A8C64;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhax r8,r10,r26
	ctx.r8.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + r26.u32));
	// cmpw cr6,r8,r11
	cr6.compare<int32_t>(ctx.r8.s32, r11.s32, xer);
	// bne cr6,0x830a8c64
	if (!cr6.eq) goto loc_830A8C64;
	// addi r11,r27,3744
	r11.s64 = r27.s64 + 3744;
	// lhax r30,r10,r11
	r30.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + r11.u32));
	// b 0x830a8c68
	goto loc_830A8C68;
loc_830A8C64:
	// lhax r30,r9,r27
	r30.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + r27.u32));
loc_830A8C68:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r10,r31,1030
	ctx.r10.s64 = r31.s64 + 1030;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x830a8d78
	if (!cr6.lt) goto loc_830A8D78;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// sth r30,0(r11)
	PPC_STORE_U16(r11.u32 + 0, r30.u16);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
loc_830A8C88:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x830a7824
	goto loc_830A7824;
loc_830A8C9C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830a8cc0
	if (!cr6.eq) goto loc_830A8CC0;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83099a58
	sub_83099A58(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_830A8CC0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x830a8d64
	if (!cr6.lt) goto loc_830A8D64;
	// li r11,3
	r11.s64 = 3;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
loc_830A8CD4:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r11,r26,-18512
	r11.s64 = r26.s64 + -18512;
	// lha r9,0(r10)
	ctx.r9.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + 0));
	// rlwinm r9,r9,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// lhax r11,r9,r11
	r11.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + r11.u32));
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a8d10
	if (cr0.eq) goto loc_830A8D10;
	// addic. r11,r11,256
	xer.ca = r11.u32 > 4294967039;
	r11.s64 = r11.s64 + 256;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// blt 0x830a8d10
	if (cr0.lt) goto loc_830A8D10;
	// cmpwi cr6,r11,7525
	cr6.compare<int32_t>(r11.s32, 7525, xer);
	// bgt cr6,0x830a8d10
	if (cr6.gt) goto loc_830A8D10;
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r9,r9,r26
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r9.u32 + r26.u32);
	// cmplwi cr6,r9,256
	cr6.compare<uint32_t>(ctx.r9.u32, 256, xer);
	// beq cr6,0x830a8d30
	if (cr6.eq) goto loc_830A8D30;
loc_830A8D10:
	// cmplw cr6,r10,r22
	cr6.compare<uint32_t>(ctx.r10.u32, r22.u32, xer);
	// ble cr6,0x830a8d88
	if (!cr6.gt) goto loc_830A8D88;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// stw r10,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r10.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// b 0x830a8cd4
	goto loc_830A8CD4;
loc_830A8D30:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r9,r31,1030
	ctx.r9.s64 = r31.s64 + 1030;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830a8d78
	if (!cr6.lt) goto loc_830A8D78;
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r8,r27,3744
	ctx.r8.s64 = r27.s64 + 3744;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// lhzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r9.u32 + ctx.r8.u32);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// extsh r30,r9
	r30.s64 = ctx.r9.s16;
	// sth r30,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, r30.u16);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// b 0x830a8c88
	goto loc_830A8C88;
loc_830A8D64:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a8d88
	if (cr6.eq) goto loc_830A8D88;
	// stw r25,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r25.u32);
	// b 0x830a7824
	goto loc_830A7824;
loc_830A8D78:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,2044
	ctx.r4.s64 = r11.s64 + 2044;
	// bl 0x83099a58
	sub_83099A58(ctx, base);
loc_830A8D88:
	// li r3,1
	ctx.r3.s64 = 1;
loc_830A8D8C:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	return;
}

__attribute__((alias("__imp__sub_830A8D98"))) PPC_WEAK_FUNC(sub_830A8D98);
PPC_FUNC_IMPL(__imp__sub_830A8D98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-3200(r1)
	ea = -3200 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// bl 0x82cb8290
	sub_82CB8290(ctx, base);
	// lis r4,8
	ctx.r4.s64 = 524288;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// ori r4,r4,31
	ctx.r4.u64 = ctx.r4.u64 | 31;
	// li r3,-1
	ctx.r3.s64 = -1;
	// bl 0x82cb8290
	sub_82CB8290(ctx, base);
	// lis r4,3
	ctx.r4.s64 = 196608;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82cb8290
	sub_82CB8290(ctx, base);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x830a8df8
	if (!cr6.eq) goto loc_830A8DF8;
	// lis r29,-30602
	r29.s64 = -2005532672;
	// ori r29,r29,2156
	r29.u64 = r29.u64 | 2156;
	// b 0x830a8ed4
	goto loc_830A8ED4;
loc_830A8DF8:
	// li r30,0
	r30.s64 = 0;
	// li r25,1
	r25.s64 = 1;
	// stw r30,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r30.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r27,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r27.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r29,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r29.u32);
	// stw r26,120(r31)
	PPC_STORE_U32(r31.u32 + 120, r26.u32);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// stw r30,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r30.u32);
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// stw r30,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r30.u32);
	// stw r30,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r30.u32);
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// stw r30,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r30.u32);
	// stw r30,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r30.u32);
	// stw r30,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r30.u32);
	// stw r25,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r25.u32);
	// stw r30,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r30.u32);
	// stw r30,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r30.u32);
	// stw r30,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r30.u32);
	// stw r30,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r30.u32);
	// stw r30,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r30.u32);
	// stw r30,108(r31)
	PPC_STORE_U32(r31.u32 + 108, r30.u32);
	// stw r30,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r30.u32);
	// bl 0x8301f740
	sub_8301F740(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830a8ed4
	if (cr0.lt) goto loc_830A8ED4;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83097148
	sub_83097148(ctx, base);
	// li r5,3036
	ctx.r5.s64 = 3036;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// stw r31,3112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 3112, r31.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x830a77d0
	sub_830A77D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830a8ea4
	if (cr0.eq) goto loc_830A8EA4;
	// stw r25,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r25.u32);
loc_830A8EA4:
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x83022810
	sub_83022810(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830a8ed4
	if (cr0.lt) goto loc_830A8ED4;
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830a8ed4
	if (!cr6.eq) goto loc_830A8ED4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r30,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r30.u32);
loc_830A8ED4:
	// bl 0x82cb83f8
	sub_82CB83F8(ctx, base);
	// lis r4,11
	ctx.r4.s64 = 720896;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// ori r4,r4,31
	ctx.r4.u64 = ctx.r4.u64 | 31;
	// bl 0x82cb8290
	sub_82CB8290(ctx, base);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bge cr6,0x830a8ef8
	if (!cr6.lt) goto loc_830A8EF8;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x830a8f20
	goto loc_830A8F20;
loc_830A8EF8:
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a8f1c
	if (cr6.eq) goto loc_830A8F1C;
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x830a8f20
	if (cr6.lt) goto loc_830A8F20;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830a8f20
	goto loc_830A8F20;
loc_830A8F1C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830A8F20:
	// addi r1,r1,3200
	ctx.r1.s64 = ctx.r1.s64 + 3200;
	// b 0x82ca2c28
	return;
}

__attribute__((alias("__imp__sub_830A8F28"))) PPC_WEAK_FUNC(sub_830A8F28);
PPC_FUNC_IMPL(__imp__sub_830A8F28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8306ae98
	sub_8306AE98(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lis r10,-31952
	ctx.r10.s64 = -2094006272;
	// stw r30,348(r31)
	PPC_STORE_U32(r31.u32 + 348, r30.u32);
	// addi r11,r11,24272
	r11.s64 = r11.s64 + 24272;
	// lis r9,-31952
	ctx.r9.s64 = -2094006272;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r10,r10,3456
	ctx.r10.s64 = ctx.r10.s64 + 3456;
	// addi r9,r9,3744
	ctx.r9.s64 = ctx.r9.s64 + 3744;
	// li r11,0
	r11.s64 = 0;
	// stw r10,248(r31)
	PPC_STORE_U32(r31.u32 + 248, ctx.r10.u32);
	// stw r9,252(r31)
	PPC_STORE_U32(r31.u32 + 252, ctx.r9.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,556(r31)
	PPC_STORE_U32(r31.u32 + 556, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830A8F98"))) PPC_WEAK_FUNC(sub_830A8F98);
PPC_FUNC_IMPL(__imp__sub_830A8F98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r3,r31,508
	ctx.r3.s64 = r31.s64 + 508;
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r11,540(r31)
	PPC_STORE_U32(r31.u32 + 540, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,544(r31)
	PPC_STORE_U32(r31.u32 + 544, r11.u32);
	// bl 0x83071ec8
	sub_83071EC8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830A8FF8"))) PPC_WEAK_FUNC(sub_830A8FF8);
PPC_FUNC_IMPL(__imp__sub_830A8FF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// li r8,32
	ctx.r8.s64 = 32;
	// ori r9,r10,512
	ctx.r9.u64 = ctx.r10.u64 | 512;
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r6,200(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 200);
	// stw r8,56(r11)
	PPC_STORE_U32(r11.u32 + 56, ctx.r8.u32);
	// subf. r10,r9,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r9.s64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r6,268(r11)
	PPC_STORE_U32(r11.u32 + 268, ctx.r6.u32);
	// beq 0x830a90f4
	if (cr0.eq) goto loc_830A90F4;
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// beq cr6,0x830a90bc
	if (cr6.eq) goto loc_830A90BC;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// beq cr6,0x830a9098
	if (cr6.eq) goto loc_830A9098;
	// cmplwi cr6,r10,100
	cr6.compare<uint32_t>(ctx.r10.u32, 100, xer);
	// beq cr6,0x830a90a0
	if (cr6.eq) goto loc_830A90A0;
	// cmplwi cr6,r10,255
	cr6.compare<uint32_t>(ctx.r10.u32, 255, xer);
	// beq cr6,0x830a906c
	if (cr6.eq) goto loc_830A906C;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r10,24648
	ctx.r6.s64 = ctx.r10.s64 + 24648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830a9158
	goto loc_830A9158;
loc_830A906C:
	// lwz r10,108(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// li r9,2048
	ctx.r9.s64 = 2048;
	// lwz r6,112(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// oris r10,r10,64
	ctx.r10.u64 = ctx.r10.u64 | 4194304;
	// stw r8,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r8.u32);
	// rlwimi r6,r7,26,5,6
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r7.u32, 26) & 0x6000000) | (ctx.r6.u64 & 0xFFFFFFFFF9FFFFFF);
	// stw r9,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r9.u32);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r6,112(r11)
	PPC_STORE_U32(r11.u32 + 112, ctx.r6.u32);
	// stw r10,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r10.u32);
	// b 0x830a9118
	goto loc_830A9118;
loc_830A9098:
	// lis r9,-1
	ctx.r9.s64 = -65536;
	// ori r9,r9,513
	ctx.r9.u64 = ctx.r9.u64 | 513;
loc_830A90A0:
	// lwz r6,108(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// stw r8,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r8.u32);
	// oris r8,r6,8256
	ctx.r8.u64 = ctx.r6.u64 | 541065216;
	// stw r9,200(r11)
	PPC_STORE_U32(r11.u32 + 200, ctx.r9.u32);
	// ori r8,r8,16
	ctx.r8.u64 = ctx.r8.u64 | 16;
	// stw r8,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r8.u32);
	// b 0x830a910c
	goto loc_830A910C;
loc_830A90BC:
	// lwz r8,108(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// li r9,17
	ctx.r9.s64 = 17;
	// lwz r10,112(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// lis r6,-1
	ctx.r6.s64 = -65536;
	// oris r8,r8,64
	ctx.r8.u64 = ctx.r8.u64 | 4194304;
	// rlwimi r10,r9,26,5,6
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 26) & 0x6000000) | (ctx.r10.u64 & 0xFFFFFFFFF9FFFFFF);
	// li r5,22
	ctx.r5.s64 = 22;
	// ori r6,r6,513
	ctx.r6.u64 = ctx.r6.u64 | 513;
	// ori r8,r8,9
	ctx.r8.u64 = ctx.r8.u64 | 9;
	// stw r5,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r5.u32);
	// rlwimi r10,r9,26,1,1
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 26) & 0x40000000) | (ctx.r10.u64 & 0xFFFFFFFFBFFFFFFF);
	// stw r6,200(r11)
	PPC_STORE_U32(r11.u32 + 200, ctx.r6.u32);
	// stw r8,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r8.u32);
	// b 0x830a9114
	goto loc_830A9114;
loc_830A90F4:
	// li r9,12
	ctx.r9.s64 = 12;
	// lwz r8,108(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// stw r9,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r9.u32);
	// oris r9,r8,8256
	ctx.r9.u64 = ctx.r8.u64 | 541065216;
	// ori r9,r9,16
	ctx.r9.u64 = ctx.r9.u64 | 16;
	// stw r9,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r9.u32);
loc_830A910C:
	// lwz r10,112(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// oris r10,r10,10240
	ctx.r10.u64 = ctx.r10.u64 | 671088640;
loc_830A9114:
	// stw r10,112(r11)
	PPC_STORE_U32(r11.u32 + 112, ctx.r10.u32);
loc_830A9118:
	// lwz r10,108(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// li r9,2
	ctx.r9.s64 = 2;
	// lwz r8,44(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// li r6,10
	ctx.r6.s64 = 10;
	// oris r10,r10,17024
	ctx.r10.u64 = ctx.r10.u64 | 1115684864;
	// stw r9,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r9.u32);
	// li r5,4
	ctx.r5.s64 = 4;
	// stw r6,68(r11)
	PPC_STORE_U32(r11.u32 + 68, ctx.r6.u32);
	// li r9,16
	ctx.r9.s64 = 16;
	// stw r7,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r7.u32);
	// ori r10,r10,512
	ctx.r10.u64 = ctx.r10.u64 | 512;
	// stw r5,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r5.u32);
	// stw r9,76(r11)
	PPC_STORE_U32(r11.u32 + 76, ctx.r9.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r10.u32);
	// stw r8,468(r11)
	PPC_STORE_U32(r11.u32 + 468, ctx.r8.u32);
loc_830A9158:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830A9168"))) PPC_WEAK_FUNC(sub_830A9168);
PPC_FUNC_IMPL(__imp__sub_830A9168) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a91e8
	if (cr0.eq) goto loc_830A91E8;
	// bl 0x8307ecc0
	sub_8307ECC0(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830a91e0
	if (!cr6.gt) goto loc_830A91E0;
	// li r28,0
	r28.s64 = 0;
loc_830A91A0:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830a91cc
	if (!cr6.eq) goto loc_830A91CC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83062ab0
	sub_83062AB0(ctx, base);
loc_830A91CC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830a91a0
	if (cr6.lt) goto loc_830A91A0;
loc_830A91E0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83083b38
	sub_83083B38(ctx, base);
loc_830A91E8:
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a9654
	if (!cr0.eq) goto loc_830A9654;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r27,8192
	r27.s64 = 536870912;
	// lis r25,12288
	r25.s64 = 805306368;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830a929c
	if (!cr6.gt) goto loc_830A929C;
	// li r28,0
	r28.s64 = 0;
loc_830A9210:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lis r10,4112
	ctx.r10.s64 = 269484032;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830a9270
	if (cr6.eq) goto loc_830A9270;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// beq cr6,0x830a9258
	if (cr6.eq) goto loc_830A9258;
	// lis r10,8208
	ctx.r10.s64 = 537919488;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830a9258
	if (cr6.eq) goto loc_830A9258;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// beq cr6,0x830a9258
	if (cr6.eq) goto loc_830A9258;
	// li r30,1
	r30.s64 = 1;
	// b 0x830a9288
	goto loc_830A9288;
loc_830A9258:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306c5b0
	sub_8306C5B0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// b 0x830a9280
	goto loc_830A9280;
loc_830A9270:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306fa98
	sub_8306FA98(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_830A9280:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x830a96fc
	if (cr6.lt) goto loc_830A96FC;
loc_830A9288:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830a9210
	if (cr6.lt) goto loc_830A9210;
loc_830A929C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830a932c
	if (!cr6.gt) goto loc_830A932C;
	// li r28,0
	r28.s64 = 0;
loc_830A92B0:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// beq cr6,0x830a92d8
	if (cr6.eq) goto loc_830A92D8;
	// li r30,1
	r30.s64 = 1;
	// b 0x830a9318
	goto loc_830A9318;
loc_830A92D8:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x830a96fc
	if (cr6.lt) goto loc_830A96FC;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83062b60
	sub_83062B60(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830a96fc
	if (cr0.lt) goto loc_830A96FC;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830631e0
	sub_830631E0(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830a96fc
	if (cr0.lt) goto loc_830A96FC;
loc_830A9318:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830a92b0
	if (cr6.lt) goto loc_830A92B0;
loc_830A932C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084778
	sub_83084778(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830a96fc
	if (cr0.lt) goto loc_830A96FC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830a93b4
	if (!cr6.gt) goto loc_830A93B4;
	// li r28,0
	r28.s64 = 0;
loc_830A9358:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// beq cr6,0x830a9384
	if (cr6.eq) goto loc_830A9384;
	// lis r10,28848
	ctx.r10.s64 = 1890582528;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830a93a0
	if (!cr6.eq) goto loc_830A93A0;
loc_830A9384:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306c5b0
	sub_8306C5B0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x830a96fc
	if (cr6.lt) goto loc_830A96FC;
loc_830A93A0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830a9358
	if (cr6.lt) goto loc_830A9358;
loc_830A93B4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r29,0
	r29.s64 = 0;
	// lis r26,8272
	r26.s64 = 542113792;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830a9494
	if (!cr6.gt) goto loc_830A9494;
	// li r28,0
	r28.s64 = 0;
loc_830A93CC:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lis r10,4176
	ctx.r10.s64 = 273678336;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830a946c
	if (cr6.eq) goto loc_830A946C;
	// lis r10,4336
	ctx.r10.s64 = 284164096;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830a9460
	if (cr6.eq) goto loc_830A9460;
	// lis r10,8256
	ctx.r10.s64 = 541065216;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830a9440
	if (cr6.eq) goto loc_830A9440;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// beq cr6,0x830a9434
	if (cr6.eq) goto loc_830A9434;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x830a9480
	if (!cr6.eq) goto loc_830A9480;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83067080
	sub_83067080(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x830a9478
	if (cr0.eq) goto loc_830A9478;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83067168
	sub_83067168(ctx, base);
	// b 0x830a9474
	goto loc_830A9474;
loc_830A9434:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83066318
	sub_83066318(ctx, base);
	// b 0x830a9474
	goto loc_830A9474;
loc_830A9440:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830667a0
	sub_830667A0(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x830a9478
	if (cr0.eq) goto loc_830A9478;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306d3f0
	sub_8306D3F0(ctx, base);
	// b 0x830a9474
	goto loc_830A9474;
loc_830A9460:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83063ea0
	sub_83063EA0(ctx, base);
	// b 0x830a9474
	goto loc_830A9474;
loc_830A946C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83062918
	sub_83062918(ctx, base);
loc_830A9474:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_830A9478:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x830a96fc
	if (cr6.lt) goto loc_830A96FC;
loc_830A9480:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830a93cc
	if (cr6.lt) goto loc_830A93CC;
loc_830A9494:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084778
	sub_83084778(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830a96fc
	if (cr0.lt) goto loc_830A96FC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r29,0
	r29.s64 = 0;
	// lis r27,28720
	r27.s64 = 1882193920;
	// lis r24,29520
	r24.s64 = 1934622720;
	// lis r25,29536
	r25.s64 = 1935671296;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830a9560
	if (!cr6.gt) goto loc_830A9560;
	// li r28,0
	r28.s64 = 0;
loc_830A94CC:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// beq cr6,0x830a9538
	if (cr6.eq) goto loc_830A9538;
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830a952c
	if (cr6.eq) goto loc_830A952C;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// beq cr6,0x830a951c
	if (cr6.eq) goto loc_830A951C;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// beq cr6,0x830a9510
	if (cr6.eq) goto loc_830A9510;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x830a954c
	if (!cr6.eq) goto loc_830A954C;
loc_830A9510:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83064258
	sub_83064258(ctx, base);
	// b 0x830a9540
	goto loc_830A9540;
loc_830A951C:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83067818
	sub_83067818(ctx, base);
	// b 0x830a9540
	goto loc_830A9540;
loc_830A952C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83066ad8
	sub_83066AD8(ctx, base);
	// b 0x830a9540
	goto loc_830A9540;
loc_830A9538:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830664b8
	sub_830664B8(ctx, base);
loc_830A9540:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x830a96fc
	if (cr6.lt) goto loc_830A96FC;
loc_830A954C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830a94cc
	if (cr6.lt) goto loc_830A94CC;
loc_830A9560:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830a95b8
	if (!cr6.gt) goto loc_830A95B8;
	// li r29,0
	r29.s64 = 0;
loc_830A957C:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x830a95a4
	if (!cr6.eq) goto loc_830A95A4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306da58
	sub_8306DA58(ctx, base);
loc_830A95A4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830a957c
	if (cr6.lt) goto loc_830A957C;
loc_830A95B8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830a9654
	if (!cr6.gt) goto loc_830A9654;
	// li r28,0
	r28.s64 = 0;
loc_830A95D4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// beq cr6,0x830a9628
	if (cr6.eq) goto loc_830A9628;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// beq cr6,0x830a961c
	if (cr6.eq) goto loc_830A961C;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// beq cr6,0x830a961c
	if (cr6.eq) goto loc_830A961C;
	// lis r10,29552
	ctx.r10.s64 = 1936719872;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830a961c
	if (cr6.eq) goto loc_830A961C;
	// lis r10,29568
	ctx.r10.s64 = 1937768448;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830a9640
	if (!cr6.eq) goto loc_830A9640;
loc_830A961C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83064598
	sub_83064598(ctx, base);
	// b 0x830a9634
	goto loc_830A9634;
loc_830A9628:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83067818
	sub_83067818(ctx, base);
loc_830A9634:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x830a96fc
	if (cr6.lt) goto loc_830A96FC;
loc_830A9640:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830a95d4
	if (cr6.lt) goto loc_830A95D4;
loc_830A9654:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830a96b0
	if (!cr6.gt) goto loc_830A96B0;
	// li r28,0
	r28.s64 = 0;
loc_830A9668:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lis r11,20528
	r11.s64 = 1345323008;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r28,r10
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + ctx.r10.u32);
	// stw r10,260(r31)
	PPC_STORE_U32(r31.u32 + 260, ctx.r10.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830a969c
	if (!cr6.eq) goto loc_830A969C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830620a8
	sub_830620A8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830a96fc
	if (cr0.lt) goto loc_830A96FC;
loc_830A969C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830a9668
	if (cr6.lt) goto loc_830A9668;
loc_830A96B0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084778
	sub_83084778(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830a96fc
	if (cr0.lt) goto loc_830A96FC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084e68
	sub_83084E68(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830a96fc
	if (cr0.lt) goto loc_830A96FC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307f3a8
	sub_8307F3A8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830a96fc
	if (cr0.lt) goto loc_830A96FC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830878b8
	sub_830878B8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830a96fc
	if (cr0.lt) goto loc_830A96FC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// li r30,0
	r30.s64 = 0;
loc_830A96FC:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
}

__attribute__((alias("__imp__sub_830A9708"))) PPC_WEAK_FUNC(sub_830A9708);
PPC_FUNC_IMPL(__imp__sub_830A9708) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, f30.u64);
	// stfd f31,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,-1
	r11.s64 = -1;
	// li r27,0
	r27.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// stw r11,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r11.u32);
	// stw r11,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830a980c
	if (!cr6.gt) goto loc_830A980C;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// li r29,0
	r29.s64 = 0;
	// addi r28,r11,936
	r28.s64 = r11.s64 + 936;
	// lfd f30,3248(r10)
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3248);
	// lfd f31,3376(r9)
	f31.u64 = PPC_LOAD_U64(ctx.r9.u32 + 3376);
loc_830A975C:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lis r10,8240
	ctx.r10.s64 = 540016640;
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r9,r11,r29
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stw r9,260(r31)
	PPC_STORE_U32(r31.u32 + 260, ctx.r9.u32);
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830a9798
	if (cr6.eq) goto loc_830A9798;
	// lis r10,8224
	ctx.r10.s64 = 538968064;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830a97f8
	if (!cr6.eq) goto loc_830A97F8;
loc_830A9798:
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830a97f8
	if (!cr6.eq) goto loc_830A97F8;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,4
	ctx.r7.s64 = 4;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,785
	ctx.r5.s64 = 785;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307a8d8
	sub_8307A8D8(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// stw r3,548(r31)
	PPC_STORE_U32(r31.u32 + 548, ctx.r3.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// stw r3,552(r31)
	PPC_STORE_U32(r31.u32 + 552, ctx.r3.u32);
loc_830A97F8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830a975c
	if (cr6.lt) goto loc_830A975C;
loc_830A980C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a98c4
	if (!cr0.eq) goto loc_830A98C4;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830a98c4
	if (!cr6.gt) goto loc_830A98C4;
	// li r29,0
	r29.s64 = 0;
loc_830A9834:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lis r9,4144
	ctx.r9.s64 = 271581184;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r10,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830a989c
	if (cr6.eq) goto loc_830A989C;
	// lis r9,4176
	ctx.r9.s64 = 273678336;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830a989c
	if (cr6.eq) goto loc_830A989C;
	// lis r9,4192
	ctx.r9.s64 = 274726912;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830a989c
	if (cr6.eq) goto loc_830A989C;
	// lis r9,4208
	ctx.r9.s64 = 275775488;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830a989c
	if (cr6.eq) goto loc_830A989C;
	// lis r9,20480
	ctx.r9.s64 = 1342177280;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830a9890
	if (cr6.eq) goto loc_830A9890;
	// li r27,1
	r27.s64 = 1;
	// b 0x830a98b0
	goto loc_830A98B0;
loc_830A9890:
	// clrlwi r11,r10,12
	r11.u64 = ctx.r10.u32 & 0xFFFFF;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// ble cr6,0x830a98a8
	if (!cr6.gt) goto loc_830A98A8;
loc_830A989C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83063678
	sub_83063678(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
loc_830A98A8:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// blt cr6,0x830a9948
	if (cr6.lt) goto loc_830A9948;
loc_830A98B0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830a9834
	if (cr6.lt) goto loc_830A9834;
loc_830A98C4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830a9944
	if (!cr6.gt) goto loc_830A9944;
	// li r9,0
	ctx.r9.s64 = 0;
loc_830A98E0:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r8,84(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// bne cr6,0x830a9930
	if (!cr6.eq) goto loc_830A9930;
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r7,16(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm. r8,r8,0,23,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x830a9930
	if (cr0.eq) goto loc_830A9930;
	// lwz r8,552(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// beq cr6,0x830a9930
	if (cr6.eq) goto loc_830A9930;
	// lwz r8,548(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// beq cr6,0x830a9930
	if (cr6.eq) goto loc_830A9930;
	// lwz r8,116(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
loc_830A9930:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x830a98e0
	if (cr6.lt) goto loc_830A98E0;
loc_830A9944:
	// li r27,0
	r27.s64 = 0;
loc_830A9948:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82ca2c30
	return;
}

__attribute__((alias("__imp__sub_830A9960"))) PPC_WEAK_FUNC(sub_830A9960);
PPC_FUNC_IMPL(__imp__sub_830A9960) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r23,r6
	r23.u64 = ctx.r6.u64;
	// li r24,0
	r24.s64 = 0;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x830a9990
	if (cr6.eq) goto loc_830A9990;
	// lis r24,15
	r24.s64 = 983040;
	// b 0x830a9a44
	goto loc_830A9A44;
loc_830A9990:
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a99b0
	if (cr0.eq) goto loc_830A99B0;
	// lis r24,16
	r24.s64 = 1048576;
loc_830A99B0:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830a9a44
	if (cr6.eq) goto loc_830A9A44;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// mr r30,r25
	r30.u64 = r25.u64;
	// mr r29,r26
	r29.u64 = r26.u64;
	// addi r27,r11,-22448
	r27.s64 = r11.s64 + -22448;
loc_830A99C8:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r31,0
	r31.s64 = 0;
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x830a9a10
	if (cr6.lt) goto loc_830A9A10;
	// beq cr6,0x830a9a08
	if (cr6.eq) goto loc_830A9A08;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x830a9a00
	if (cr6.lt) goto loc_830A9A00;
	// bne cr6,0x830a9a14
	if (!cr6.eq) goto loc_830A9A14;
	// lis r31,8
	r31.s64 = 524288;
	// b 0x830a9a14
	goto loc_830A9A14;
loc_830A9A00:
	// lis r31,4
	r31.s64 = 262144;
	// b 0x830a9a14
	goto loc_830A9A14;
loc_830A9A08:
	// lis r31,2
	r31.s64 = 131072;
	// b 0x830a9a14
	goto loc_830A9A14;
loc_830A9A10:
	// lis r31,1
	r31.s64 = 65536;
loc_830A9A14:
	// and. r11,r31,r24
	r11.u64 = r31.u64 & r24.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a9a34
	if (cr0.eq) goto loc_830A9A34;
	// lwz r11,260(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// li r5,4821
	ctx.r5.s64 = 4821;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830A9A34:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// or r24,r31,r24
	r24.u64 = r31.u64 | r24.u64;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x830a99c8
	if (!cr0.eq) goto loc_830A99C8;
loc_830A9A44:
	// lwz r7,204(r28)
	ctx.r7.u64 = PPC_LOAD_U32(r28.u32 + 204);
	// rlwinm. r11,r7,0,26,26
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a9ac8
	if (!cr0.eq) goto loc_830A9AC8;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830a9ac0
	if (cr6.eq) goto loc_830A9AC0;
	// lwz r8,20(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_830A9A64:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r6,r6,0,6,6
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x830a9ab0
	if (!cr0.eq) goto loc_830A9AB0;
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r5,16(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r5
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// lwz r6,4(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// clrlwi. r6,r6,31
	ctx.r6.u64 = ctx.r6.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x830a9ac0
	if (cr0.eq) goto loc_830A9AC0;
	// lwz r6,72(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r6,-1
	cr6.compare<int32_t>(ctx.r6.s32, -1, xer);
	// beq cr6,0x830a9ac0
	if (cr6.eq) goto loc_830A9AC0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830a9ac0
	if (!cr6.eq) goto loc_830A9AC0;
loc_830A9AB0:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r26
	cr6.compare<uint32_t>(ctx.r9.u32, r26.u32, xer);
	// blt cr6,0x830a9a64
	if (cr6.lt) goto loc_830A9A64;
loc_830A9AC0:
	// cmplw cr6,r9,r26
	cr6.compare<uint32_t>(ctx.r9.u32, r26.u32, xer);
	// bne cr6,0x830a9acc
	if (!cr6.eq) goto loc_830A9ACC;
loc_830A9AC8:
	// oris r24,r24,32
	r24.u64 = r24.u64 | 2097152;
loc_830A9ACC:
	// clrlwi. r11,r7,31
	r11.u64 = ctx.r7.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830a9b20
	if (cr0.eq) goto loc_830A9B20;
	// lwz r11,296(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 296);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a9b20
	if (cr6.eq) goto loc_830A9B20;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830a9b20
	if (cr6.eq) goto loc_830A9B20;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_830A9AF0:
	// lwz r9,300(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 300);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// mulli r9,r9,6
	ctx.r9.s64 = ctx.r9.s64 * 6;
	// lwz r7,296(r28)
	ctx.r7.u64 = PPC_LOAD_U32(r28.u32 + 296);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r8,r9,r7
	PPC_STORE_U32(ctx.r9.u32 + ctx.r7.u32, ctx.r8.u32);
	// blt cr6,0x830a9af0
	if (cr6.lt) goto loc_830A9AF0;
loc_830A9B20:
	// stw r24,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r24.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c24
	return;
}

__attribute__((alias("__imp__sub_830A9B30"))) PPC_WEAK_FUNC(sub_830A9B30);
PPC_FUNC_IMPL(__imp__sub_830A9B30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,348(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 348);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830a9b54
	if (cr6.eq) goto loc_830A9B54;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830a9e34
	goto loc_830A9E34;
loc_830A9B54:
	// li r23,0
	r23.s64 = 0;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// mr r24,r23
	r24.u64 = r23.u64;
	// mr r25,r23
	r25.u64 = r23.u64;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// li r10,8
	ctx.r10.s64 = 8;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_830A9B70:
	// std r9,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r9.u64);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// bdnz 0x830a9b70
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_830A9B70;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// stw r23,540(r30)
	PPC_STORE_U32(r30.u32 + 540, r23.u32);
	// li r5,32
	ctx.r5.s64 = 32;
	// stw r23,544(r30)
	PPC_STORE_U32(r30.u32 + 544, r23.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r30,508
	ctx.r3.s64 = r30.s64 + 508;
	// std r23,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r23.u64);
	// std r23,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r23.u64);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r26,r23
	r26.u64 = r23.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830a9d34
	if (!cr6.gt) goto loc_830A9D34;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// mr r28,r23
	r28.u64 = r23.u64;
	// addi r27,r11,-5376
	r27.s64 = r11.s64 + -5376;
loc_830A9BBC:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r31,r11,r28
	r31.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r10,r11,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830a9c94
	if (cr0.eq) goto loc_830A9C94;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,108(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r4,108(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,116(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r29,11
	cr6.compare<uint32_t>(r29.u32, 11, xer);
	// beq cr6,0x830a9c60
	if (cr6.eq) goto loc_830A9C60;
	// cmplwi cr6,r29,13
	cr6.compare<uint32_t>(r29.u32, 13, xer);
	// bne cr6,0x830a9d20
	if (!cr6.eq) goto loc_830A9D20;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830a9d20
	if (!cr6.eq) goto loc_830A9D20;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830a9d20
	if (cr6.eq) goto loc_830A9D20;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x830a9d20
	if (!cr6.eq) goto loc_830A9D20;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// lwz r4,96(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// li r5,4528
	ctx.r5.s64 = 4528;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r25,1
	r25.s64 = 1;
	// li r24,1
	r24.s64 = 1;
	// b 0x830a9d20
	goto loc_830A9D20;
loc_830A9C60:
	// cmplwi cr6,r3,4
	cr6.compare<uint32_t>(ctx.r3.u32, 4, xer);
	// bge cr6,0x830a9d20
	if (!cr6.lt) goto loc_830A9D20;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,96(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// li r6,1
	ctx.r6.s64 = 1;
	// stwx r9,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r9.u32);
	// stwx r6,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r6.u32);
	// b 0x830a9d20
	goto loc_830A9D20;
loc_830A9C94:
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830a9d20
	if (cr0.eq) goto loc_830A9D20;
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830a9d20
	if (!cr0.eq) goto loc_830A9D20;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,108(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r4,108(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,116(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r29,6
	cr6.compare<uint32_t>(r29.u32, 6, xer);
	// beq cr6,0x830a9cf8
	if (cr6.eq) goto loc_830A9CF8;
	// cmplwi cr6,r29,11
	cr6.compare<uint32_t>(r29.u32, 11, xer);
	// bne cr6,0x830a9d20
	if (!cr6.eq) goto loc_830A9D20;
	// cmplwi cr6,r3,2
	cr6.compare<uint32_t>(ctx.r3.u32, 2, xer);
	// bge cr6,0x830a9d20
	if (!cr6.lt) goto loc_830A9D20;
	// addi r10,r3,135
	ctx.r10.s64 = ctx.r3.s64 + 135;
	// b 0x830a9d04
	goto loc_830A9D04;
loc_830A9CF8:
	// cmplwi cr6,r3,8
	cr6.compare<uint32_t>(ctx.r3.u32, 8, xer);
	// bge cr6,0x830a9d20
	if (!cr6.lt) goto loc_830A9D20;
	// addi r10,r3,127
	ctx.r10.s64 = ctx.r3.s64 + 127;
loc_830A9D04:
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r9,r10,r30
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bge cr6,0x830a9d20
	if (!cr6.lt) goto loc_830A9D20;
	// stwx r11,r10,r30
	PPC_STORE_U32(ctx.r10.u32 + r30.u32, r11.u32);
loc_830A9D20:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x830a9bbc
	if (cr6.lt) goto loc_830A9BBC;
loc_830A9D34:
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// mr r27,r23
	r27.u64 = r23.u64;
	// li r26,1
	r26.s64 = 1;
	// mr r31,r23
	r31.u64 = r23.u64;
	// addi r29,r10,-5416
	r29.s64 = ctx.r10.s64 + -5416;
	// addi r28,r11,-5480
	r28.s64 = r11.s64 + -5480;
loc_830A9D50:
	// rlwinm r11,r31,4,0,27
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// li r11,4
	r11.s64 = 4;
loc_830A9D64:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// bne 0x830a9d64
	if (!cr0.eq) goto loc_830A9D64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x830a9df4
	if (!cr6.eq) goto loc_830A9DF4;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x830a9dac
	if (!cr6.eq) goto loc_830A9DAC;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r5,4530
	ctx.r5.s64 = 4530;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r24,1
	r24.s64 = 1;
loc_830A9DAC:
	// li r27,1
	r27.s64 = 1;
loc_830A9DB0:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplwi cr6,r31,4
	cr6.compare<uint32_t>(r31.u32, 4, xer);
	// blt cr6,0x830a9d50
	if (cr6.lt) goto loc_830A9D50;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// bne cr6,0x830a9de0
	if (!cr6.eq) goto loc_830A9DE0;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r5,4538
	ctx.r5.s64 = 4538;
	// addi r6,r11,-5540
	ctx.r6.s64 = r11.s64 + -5540;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r24,1
	r24.s64 = 1;
loc_830A9DE0:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x830a9e30
	if (cr6.eq) goto loc_830A9E30;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830a9e34
	goto loc_830A9E34;
loc_830A9DF4:
	// cmplwi cr6,r9,4
	cr6.compare<uint32_t>(ctx.r9.u32, 4, xer);
	// beq cr6,0x830a9e20
	if (cr6.eq) goto loc_830A9E20;
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r5,4529
	ctx.r5.s64 = 4529;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r24,1
	r24.s64 = 1;
loc_830A9E20:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x830a9db0
	if (cr6.eq) goto loc_830A9DB0;
	// mr r26,r23
	r26.u64 = r23.u64;
	// b 0x830a9db0
	goto loc_830A9DB0;
loc_830A9E30:
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
loc_830A9E34:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c24
	return;
}

__attribute__((alias("__imp__sub_830A9E40"))) PPC_WEAK_FUNC(sub_830A9E40);
PPC_FUNC_IMPL(__imp__sub_830A9E40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r4,256(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r27,8(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// clrlwi r28,r9,12
	r28.u64 = ctx.r9.u32 & 0xFFFFF;
	// lwz r29,12(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r26,16(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r11,r28,2,0,29
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,340(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 340);
	// add r25,r11,r27
	r25.u64 = r11.u64 + r27.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830a9f6c
	if (cr0.lt) goto loc_830A9F6C;
	// li r30,0
	r30.s64 = 0;
	// lwz r9,548(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// lwz r8,552(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_830A9EB0:
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// stwx r9,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r9.u32);
	// stwx r8,r11,r6
	PPC_STORE_U32(r11.u32 + ctx.r6.u32, ctx.r8.u32);
	// bge cr6,0x830a9ef0
	if (!cr6.lt) goto loc_830A9EF0;
	// lwzx r7,r11,r26
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r5
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// stwx r7,r11,r4
	PPC_STORE_U32(r11.u32 + ctx.r4.u32, ctx.r7.u32);
loc_830A9EF0:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830a9eb0
	if (cr6.lt) goto loc_830A9EB0;
	// lis r11,256
	r11.s64 = 16777216;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,88
	ctx.r4.s64 = 88;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
loc_830A9F6C:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830A9F78"))) PPC_WEAK_FUNC(sub_830A9F78);
PPC_FUNC_IMPL(__imp__sub_830A9F78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r4,256(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r27,8(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// clrlwi r28,r9,12
	r28.u64 = ctx.r9.u32 & 0xFFFFF;
	// lwz r29,12(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r26,16(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r11,r28,2,0,29
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,340(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 340);
	// add r25,r11,r27
	r25.u64 = r11.u64 + r27.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aa0a4
	if (cr0.lt) goto loc_830AA0A4;
	// li r30,0
	r30.s64 = 0;
	// lwz r9,548(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// lwz r8,552(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_830A9FE8:
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// stwx r9,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r9.u32);
	// stwx r8,r11,r6
	PPC_STORE_U32(r11.u32 + ctx.r6.u32, ctx.r8.u32);
	// bge cr6,0x830aa028
	if (!cr6.lt) goto loc_830AA028;
	// lwzx r7,r11,r26
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r5
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// stwx r7,r11,r4
	PPC_STORE_U32(r11.u32 + ctx.r4.u32, ctx.r7.u32);
loc_830AA028:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830a9fe8
	if (cr6.lt) goto loc_830A9FE8;
	// lis r11,256
	r11.s64 = 16777216;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,88
	ctx.r4.s64 = 88;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
loc_830AA0A4:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830AA0B0"))) PPC_WEAK_FUNC(sub_830AA0B0);
PPC_FUNC_IMPL(__imp__sub_830AA0B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r29,8(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r28,16(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r27,12(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// clrlwi r26,r10,12
	r26.u64 = ctx.r10.u32 & 0xFFFFF;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r26,2,0,29
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r25,r11,r29
	r25.u64 = r11.u64 + r29.u64;
	// lwzx r7,r11,r29
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// lwzx r11,r10,r8
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwzx r10,r9,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// bne cr6,0x830aa128
	if (!cr6.eq) goto loc_830AA128;
	// lwz r7,12(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// beq cr6,0x830aa144
	if (cr6.eq) goto loc_830AA144;
loc_830AA128:
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x830aa230
	if (!cr6.eq) goto loc_830AA230;
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830aa230
	if (!cr6.eq) goto loc_830AA230;
loc_830AA144:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aa268
	if (cr0.lt) goto loc_830AA268;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830aa1bc
	if (cr6.eq) goto loc_830AA1BC;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// subf r8,r10,r28
	ctx.r8.s64 = r28.s64 - ctx.r10.s64;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
loc_830AA190:
	// lwzx r7,r8,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830aa190
	if (!cr0.eq) goto loc_830AA190;
loc_830AA1BC:
	// li r31,0
	r31.s64 = 0;
	// lis r11,256
	r11.s64 = 16777216;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,88
	ctx.r4.s64 = 88;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// b 0x830aa268
	goto loc_830AA268;
loc_830AA230:
	// li r31,0
	r31.s64 = 0;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,11
	ctx.r4.s64 = 11;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
loc_830AA268:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830AA270"))) PPC_WEAK_FUNC(sub_830AA270);
PPC_FUNC_IMPL(__imp__sub_830AA270) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r29,8(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r28,16(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r27,12(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// clrlwi r26,r10,12
	r26.u64 = ctx.r10.u32 & 0xFFFFF;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r26,2,0,29
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r25,r11,r29
	r25.u64 = r11.u64 + r29.u64;
	// lwzx r7,r11,r29
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// lwzx r11,r10,r8
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwzx r10,r9,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// bne cr6,0x830aa2e8
	if (!cr6.eq) goto loc_830AA2E8;
	// lwz r7,12(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// beq cr6,0x830aa304
	if (cr6.eq) goto loc_830AA304;
loc_830AA2E8:
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x830aa3f0
	if (!cr6.eq) goto loc_830AA3F0;
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830aa3f0
	if (!cr6.eq) goto loc_830AA3F0;
loc_830AA304:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aa428
	if (cr0.lt) goto loc_830AA428;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830aa37c
	if (cr6.eq) goto loc_830AA37C;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// subf r8,r10,r28
	ctx.r8.s64 = r28.s64 - ctx.r10.s64;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
loc_830AA350:
	// lwzx r7,r8,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830aa350
	if (!cr0.eq) goto loc_830AA350;
loc_830AA37C:
	// li r31,0
	r31.s64 = 0;
	// lis r11,256
	r11.s64 = 16777216;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,88
	ctx.r4.s64 = 88;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// b 0x830aa428
	goto loc_830AA428;
loc_830AA3F0:
	// li r31,0
	r31.s64 = 0;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,10
	ctx.r4.s64 = 10;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
loc_830AA428:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830AA430"))) PPC_WEAK_FUNC(sub_830AA430);
PPC_FUNC_IMPL(__imp__sub_830AA430) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,348(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 348);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830aa490
	if (cr6.eq) goto loc_830AA490;
	// lwz r11,200(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// clrlwi r4,r11,1
	ctx.r4.u64 = r11.u32 & 0x7FFFFFFF;
loc_830AA458:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aa47c
	if (cr0.lt) goto loc_830AA47C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ab90
	sub_8306AB90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aa47c
	if (cr0.lt) goto loc_830AA47C;
	// li r3,0
	ctx.r3.s64 = 0;
loc_830AA47C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_830AA490:
	// lwz r4,200(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// b 0x830aa458
	goto loc_830AA458;
}

__attribute__((alias("__imp__sub_830AA498"))) PPC_WEAK_FUNC(sub_830AA498);
PPC_FUNC_IMPL(__imp__sub_830AA498) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r4,108(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r4,108(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,116(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,11
	cr6.compare<uint32_t>(r29.u32, 11, xer);
	// bne cr6,0x830aa50c
	if (!cr6.eq) goto loc_830AA50C;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// bge cr6,0x830aa734
	if (!cr6.lt) goto loc_830AA734;
	// addi r11,r27,135
	r11.s64 = r27.s64 + 135;
	// stw r27,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r27.u32);
	// li r25,1
	r25.s64 = 1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// b 0x830aa530
	goto loc_830AA530;
loc_830AA50C:
	// cmplwi cr6,r29,6
	cr6.compare<uint32_t>(r29.u32, 6, xer);
	// bne cr6,0x830aa734
	if (!cr6.eq) goto loc_830AA734;
	// cmplwi cr6,r27,8
	cr6.compare<uint32_t>(r27.u32, 8, xer);
	// bge cr6,0x830aa734
	if (!cr6.lt) goto loc_830AA734;
	// addi r11,r27,2
	r11.s64 = r27.s64 + 2;
	// addi r10,r27,127
	ctx.r10.s64 = r27.s64 + 127;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// li r25,3
	r25.s64 = 3;
	// rlwinm r11,r10,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_830AA530:
	// lwzx r10,r11,r31
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// li r26,0
	r26.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830aa584
	if (cr6.eq) goto loc_830AA584;
loc_830AA544:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x830aa574
	if (cr6.lt) goto loc_830AA574;
	// beq cr6,0x830aa56c
	if (cr6.eq) goto loc_830AA56C;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x830aa564
	if (cr6.lt) goto loc_830AA564;
	// bne cr6,0x830aa578
	if (!cr6.eq) goto loc_830AA578;
	// oris r26,r26,8
	r26.u64 = r26.u64 | 524288;
	// b 0x830aa578
	goto loc_830AA578;
loc_830AA564:
	// oris r26,r26,4
	r26.u64 = r26.u64 | 262144;
	// b 0x830aa578
	goto loc_830AA578;
loc_830AA56C:
	// oris r26,r26,2
	r26.u64 = r26.u64 | 131072;
	// b 0x830aa578
	goto loc_830AA578;
loc_830AA574:
	// oris r26,r26,1
	r26.u64 = r26.u64 | 65536;
loc_830AA578:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x830aa544
	if (cr6.lt) goto loc_830AA544;
loc_830AA584:
	// cmplwi cr6,r25,1
	cr6.compare<uint32_t>(r25.u32, 1, xer);
	// beq cr6,0x830aa5b0
	if (cr6.eq) goto loc_830AA5B0;
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830aa5ac
	if (!cr0.eq) goto loc_830AA5AC;
	// cmplwi cr6,r29,6
	cr6.compare<uint32_t>(r29.u32, 6, xer);
	// bne cr6,0x830aa5b0
	if (!cr6.eq) goto loc_830AA5B0;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm. r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830aa5b0
	if (cr0.eq) goto loc_830AA5B0;
loc_830AA5AC:
	// oris r26,r26,32
	r26.u64 = r26.u64 | 2097152;
loc_830AA5B0:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// li r30,0
	r30.s64 = 0;
	// rlwinm. r11,r11,0,7,7
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830aa5c4
	if (cr0.eq) goto loc_830AA5C4;
	// lis r30,64
	r30.s64 = 4194304;
loc_830AA5C4:
	// lis r4,512
	ctx.r4.s64 = 33554432;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r4,r4,31
	ctx.r4.u64 = ctx.r4.u64 | 31;
	// bl 0x83073378
	sub_83073378(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aa73c
	if (cr0.lt) goto loc_830AA73C;
	// lis r4,-32768
	ctx.r4.s64 = -2147483648;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aa73c
	if (cr0.lt) goto loc_830AA73C;
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830aa6d8
	if (cr0.eq) goto loc_830AA6D8;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r11,-1
	r11.s64 = -1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// stw r11,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r11.u32);
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r11.u32);
	// beq cr6,0x830aa680
	if (cr6.eq) goto loc_830AA680;
	// lwz r7,4(r28)
	ctx.r7.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
loc_830AA630:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// bne cr6,0x830aa670
	if (!cr6.eq) goto loc_830AA670;
	// lwz r6,8(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r6,r4
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, xer);
	// bne cr6,0x830aa670
	if (!cr6.eq) goto loc_830AA670;
	// lwz r6,12(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// lwz r4,12(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r6,r4
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, xer);
	// bne cr6,0x830aa670
	if (!cr6.eq) goto loc_830AA670;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r11,r6
	PPC_STORE_U32(r11.u32 + ctx.r6.u32, ctx.r9.u32);
loc_830AA670:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x830aa630
	if (cr6.lt) goto loc_830AA630;
loc_830AA680:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// li r8,4
	ctx.r8.s64 = 4;
loc_830AA68C:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830aa6a4
	if (cr6.eq) goto loc_830AA6A4;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
loc_830AA6A4:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830aa68c
	if (!cr0.eq) goto loc_830AA68C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,324(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 324);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aa73c
	if (cr0.lt) goto loc_830AA73C;
loc_830AA6D8:
	// lis r11,-128
	r11.s64 = -8388608;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r9,r25,0,27,28
	ctx.r9.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 0) & 0x18;
	// rlwimi r11,r25,20,9,11
	r11.u64 = (__builtin_rotateleft32(r25.u32, 20) & 0x700000) | (r11.u64 & 0xFFFFFFFFFF8FFFFF);
	// clrlwi r8,r27,21
	ctx.r8.u64 = r27.u32 & 0x7FF;
	// or r11,r11,r9
	r11.u64 = r11.u64 | ctx.r9.u64;
	// lwz r10,312(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 312);
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r11,r11,8,0,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 8) & 0xFFFFFF00;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// or r11,r11,r8
	r11.u64 = r11.u64 | ctx.r8.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// or r4,r11,r30
	ctx.r4.u64 = r11.u64 | r30.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aa73c
	if (cr0.lt) goto loc_830AA73C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ab90
	sub_8306AB90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aa73c
	if (cr0.lt) goto loc_830AA73C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830aa73c
	goto loc_830AA73C;
loc_830AA734:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_830AA73C:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830AA748"))) PPC_WEAK_FUNC(sub_830AA748);
PPC_FUNC_IMPL(__imp__sub_830AA748) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r4,108(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r4,108(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,116(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r30,11
	cr6.compare<uint32_t>(r30.u32, 11, xer);
	// stw r3,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r3.u32);
	// bne cr6,0x830aa7b4
	if (!cr6.eq) goto loc_830AA7B4;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// bge cr6,0x830aa7e4
	if (!cr6.lt) goto loc_830AA7E4;
	// li r11,1
	r11.s64 = 1;
	// b 0x830aa7d8
	goto loc_830AA7D8;
loc_830AA7B4:
	// cmplwi cr6,r30,6
	cr6.compare<uint32_t>(r30.u32, 6, xer);
	// bne cr6,0x830aa7cc
	if (!cr6.eq) goto loc_830AA7CC;
	// cmplwi cr6,r3,8
	cr6.compare<uint32_t>(ctx.r3.u32, 8, xer);
	// bge cr6,0x830aa7e4
	if (!cr6.lt) goto loc_830AA7E4;
	// li r11,3
	r11.s64 = 3;
	// b 0x830aa7d8
	goto loc_830AA7D8;
loc_830AA7CC:
	// cmplwi cr6,r30,65535
	cr6.compare<uint32_t>(r30.u32, 65535, xer);
	// bne cr6,0x830aa7e4
	if (!cr6.eq) goto loc_830AA7E4;
	// li r11,0
	r11.s64 = 0;
loc_830AA7D8:
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830aa7ec
	goto loc_830AA7EC;
loc_830AA7E4:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_830AA7EC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830AA7F8"))) PPC_WEAK_FUNC(sub_830AA7F8);
PPC_FUNC_IMPL(__imp__sub_830AA7F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// li r29,1
	r29.s64 = 1;
	// lwz r4,108(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r4,108(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,116(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r31,11
	cr6.compare<uint32_t>(r31.u32, 11, xer);
	// stw r3,0(r25)
	PPC_STORE_U32(r25.u32 + 0, ctx.r3.u32);
	// bne cr6,0x830aa868
	if (!cr6.eq) goto loc_830AA868;
	// cmplwi cr6,r3,4
	cr6.compare<uint32_t>(ctx.r3.u32, 4, xer);
	// bge cr6,0x830aa8a8
	if (!cr6.lt) goto loc_830AA8A8;
	// li r11,8
	r11.s64 = 8;
	// b 0x830aa87c
	goto loc_830AA87C;
loc_830AA868:
	// cmplwi cr6,r31,13
	cr6.compare<uint32_t>(r31.u32, 13, xer);
	// bne cr6,0x830aa884
	if (!cr6.eq) goto loc_830AA884;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830aa8a8
	if (!cr6.eq) goto loc_830AA8A8;
	// li r11,9
	r11.s64 = 9;
loc_830AA87C:
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// b 0x830aa894
	goto loc_830AA894;
loc_830AA884:
	// cmplwi cr6,r31,65535
	cr6.compare<uint32_t>(r31.u32, 65535, xer);
	// bne cr6,0x830aa8a8
	if (!cr6.eq) goto loc_830AA8A8;
	// li r29,0
	r29.s64 = 0;
	// stw r29,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r29.u32);
loc_830AA894:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830aa8a0
	if (cr6.eq) goto loc_830AA8A0;
	// stw r29,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r29.u32);
loc_830AA8A0:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830aa8b0
	goto loc_830AA8B0;
loc_830AA8A8:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_830AA8B0:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830AA8B8"))) PPC_WEAK_FUNC(sub_830AA8B8);
PPC_FUNC_IMPL(__imp__sub_830AA8B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-31952
	r11.s64 = -2094006272;
	// subf r6,r4,r3
	ctx.r6.s64 = ctx.r3.s64 - ctx.r4.s64;
	// addi r11,r11,3856
	r11.s64 = r11.s64 + 3856;
	// li r7,0
	ctx.r7.s64 = 0;
loc_830AA8C8:
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// li r9,4
	ctx.r9.s64 = 4;
loc_830AA8D4:
	// lwzx r5,r6,r10
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r5,r3
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r3.u32, xer);
	// beq cr6,0x830aa8f4
	if (cr6.eq) goto loc_830AA8F4;
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// beq cr6,0x830aa8f4
	if (cr6.eq) goto loc_830AA8F4;
	// li r8,0
	ctx.r8.s64 = 0;
loc_830AA8F4:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830aa8d4
	if (!cr0.eq) goto loc_830AA8D4;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x830aa920
	if (!cr6.eq) goto loc_830AA920;
	// addi r7,r7,16
	ctx.r7.s64 = ctx.r7.s64 + 16;
	// cmplwi cr6,r7,128
	cr6.compare<uint32_t>(ctx.r7.u32, 128, xer);
	// blt cr6,0x830aa8c8
	if (cr6.lt) goto loc_830AA8C8;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_830AA920:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830AA928"))) PPC_WEAK_FUNC(sub_830AA928);
PPC_FUNC_IMPL(__imp__sub_830AA928) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830aa9d4
	if (cr6.eq) goto loc_830AA9D4;
	// lwz r7,260(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r11,0
	r11.s64 = 0;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r8,r29,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r5,16(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// lwz r7,8(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lwz r5,0(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r5,r9
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
	// lwz r5,4(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
loc_830AA974:
	// lwzx r4,r11,r7
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r9
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r9.u32);
	// lwz r4,4(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// bne cr6,0x830aa9c4
	if (!cr6.eq) goto loc_830AA9C4;
	// lwz r4,260(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r30,8(r4)
	r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r4,16(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// lwzx r30,r30,r11
	r30.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r4,0(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r30,r30,2,0,29
	r30.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r30,r3
	r30.u64 = PPC_LOAD_U32(r30.u32 + ctx.r3.u32);
	// lwzx r4,r4,r3
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r3.u32);
	// lwz r3,12(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r4,12(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplw cr6,r4,r3
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r3.u32, xer);
	// beq cr6,0x830aa9d4
	if (cr6.eq) goto loc_830AA9D4;
loc_830AA9C4:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// add r11,r8,r11
	r11.u64 = ctx.r8.u64 + r11.u64;
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// blt cr6,0x830aa974
	if (cr6.lt) goto loc_830AA974;
loc_830AA9D4:
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x830aab94
	if (cr6.eq) goto loc_830AAB94;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mullw r10,r10,r29
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(r29.s32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r9,-1
	ctx.r9.s64 = -1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// std r9,0(r8)
	PPC_STORE_U64(ctx.r8.u32 + 0, ctx.r9.u64);
	// li r30,0
	r30.s64 = 0;
	// std r9,8(r8)
	PPC_STORE_U64(ctx.r8.u32 + 8, ctx.r9.u64);
	// add r28,r10,r11
	r28.u64 = ctx.r10.u64 + r11.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830aaa40
	if (cr6.eq) goto loc_830AAA40;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_830AAA18:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r6,r8,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwzx r6,r6,r9
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwz r6,16(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r8,r6,r7
	PPC_STORE_U32(ctx.r6.u32 + ctx.r7.u32, ctx.r8.u32);
	// bne 0x830aaa18
	if (!cr0.eq) goto loc_830AAA18;
loc_830AAA40:
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r11,4
	r11.s64 = 4;
loc_830AAA48:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// li r8,-1
	ctx.r8.s64 = -1;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// rlwinm r9,r9,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// xori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 ^ 1;
	// add r30,r9,r30
	r30.u64 = ctx.r9.u64 + r30.u64;
	// bne 0x830aaa48
	if (!cr0.eq) goto loc_830AAA48;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aab98
	if (cr0.lt) goto loc_830AAB98;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830aaab8
	if (cr0.eq) goto loc_830AAAB8;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// b 0x830aaabc
	goto loc_830AAABC;
loc_830AAAB8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830AAABC:
	// stw r3,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830aaad4
	if (!cr6.eq) goto loc_830AAAD4;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830aab98
	goto loc_830AAB98;
loc_830AAAD4:
	// li r11,1
	r11.s64 = 1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aab98
	if (cr0.lt) goto loc_830AAB98;
	// lwz r4,260(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830aab98
	if (cr0.lt) goto loc_830AAB98;
	// li r11,0
	r11.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
loc_830AAB14:
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x830aab48
	if (cr6.eq) goto loc_830AAB48;
	// lwz r8,0(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// lwzx r7,r10,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// stwx r7,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r7.u32);
	// lwz r8,0(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r8,8(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// stwx r9,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
loc_830AAB48:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r10,16
	cr6.compare<uint32_t>(ctx.r10.u32, 16, xer);
	// blt cr6,0x830aab14
	if (cr6.lt) goto loc_830AAB14;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830aab94
	if (cr6.eq) goto loc_830AAB94;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_830AAB64:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830aab64
	if (!cr0.eq) goto loc_830AAB64;
loc_830AAB94:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830AAB98:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830AABA0"))) PPC_WEAK_FUNC(sub_830AABA0);
PPC_FUNC_IMPL(__imp__sub_830AABA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// li r28,0
	r28.s64 = 0;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830aac00
	if (cr6.eq) goto loc_830AAC00;
	// lwz r8,136(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 136);
	// lwz r9,20(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 20);
loc_830AABD4:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x830aabf4
	if (!cr6.eq) goto loc_830AABF4;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r10,r28
	cr6.compare<uint32_t>(ctx.r10.u32, r28.u32, xer);
	// blt cr6,0x830aabf4
	if (cr6.lt) goto loc_830AABF4;
	// addi r28,r10,1
	r28.s64 = ctx.r10.s64 + 1;
loc_830AABF4:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830aabd4
	if (!cr0.eq) goto loc_830AABD4;
loc_830AAC00:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r31,0
	r31.s64 = 0;
	// addi r30,r1,80
	r30.s64 = ctx.r1.s64 + 80;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830AAC10:
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// lwz r4,136(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 136);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830aac5c
	if (cr6.eq) goto loc_830AAC5C;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r31,4
	cr6.compare<uint32_t>(r31.u32, 4, xer);
	// blt cr6,0x830aac10
	if (cr6.lt) goto loc_830AAC10;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830aac68
	if (cr0.eq) goto loc_830AAC68;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// b 0x830aac6c
	goto loc_830AAC6C;
loc_830AAC5C:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830aad2c
	goto loc_830AAD2C;
loc_830AAC68:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830AAC6C:
	// stw r3,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830aac5c
	if (cr6.eq) goto loc_830AAC5C;
	// li r11,1
	r11.s64 = 1;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bge 0x830aacc0
	if (!cr0.lt) goto loc_830AACC0;
loc_830AAC9C:
	// lwz r31,0(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830aacb8
	if (cr6.eq) goto loc_830AACB8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830AACB8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x830aad2c
	goto loc_830AAD2C;
loc_830AACC0:
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r4,260(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830aac9c
	if (cr0.lt) goto loc_830AAC9C;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830aad28
	if (cr6.eq) goto loc_830AAD28;
	// li r11,0
	r11.s64 = 0;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
loc_830AACE4:
	// lwz r9,0(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r9,8(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// stwx r8,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r8.u32);
	// lwz r9,260(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r7,0(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// stwx r9,r7,r11
	PPC_STORE_U32(ctx.r7.u32 + r11.u32, ctx.r9.u32);
	// lwz r9,260(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// stwx r8,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830aace4
	if (!cr0.eq) goto loc_830AACE4;
loc_830AAD28:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830AAD2C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82ca2c30
	return;
}

__attribute__((alias("__imp__sub_830AAD38"))) PPC_WEAK_FUNC(sub_830AAD38);
PPC_FUNC_IMPL(__imp__sub_830AAD38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-416(r1)
	ea = -416 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// li r17,0
	r17.s64 = 0;
	// mr r14,r17
	r14.u64 = r17.u64;
	// mr r15,r17
	r15.u64 = r17.u64;
	// lwz r4,260(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// stw r14,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r14.u32);
	// stw r15,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r15.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830aad78
	if (!cr0.eq) goto loc_830AAD78;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830abbdc
	goto loc_830ABBDC;
loc_830AAD78:
	// lwz r10,260(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// lis r7,20480
	ctx.r7.s64 = 1342177280;
	// lis r9,20512
	ctx.r9.s64 = 1344274432;
	// lis r8,28800
	ctx.r8.s64 = 1887436800;
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// clrlwi r16,r6,12
	r16.u64 = ctx.r6.u32 & 0xFFFFF;
	// rlwinm r6,r6,0,0,11
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFF00000;
	// divwu r18,r10,r16
	r18.u32 = ctx.r10.u32 / r16.u32;
	// twllei r16,0
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// beq cr6,0x830aadbc
	if (cr6.eq) goto loc_830AADBC;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830aadbc
	if (cr6.eq) goto loc_830AADBC;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// bne cr6,0x830aadc0
	if (!cr6.eq) goto loc_830AADC0;
loc_830AADBC:
	// li r10,1
	ctx.r10.s64 = 1;
loc_830AADC0:
	// lis r7,24656
	ctx.r7.s64 = 1615855616;
	// mr r28,r17
	r28.u64 = r17.u64;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// beq cr6,0x830abb90
	if (cr6.eq) goto loc_830ABB90;
	// lis r7,24736
	ctx.r7.s64 = 1621098496;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// beq cr6,0x830abb90
	if (cr6.eq) goto loc_830ABB90;
	// lis r7,24816
	ctx.r7.s64 = 1626341376;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// beq cr6,0x830abb90
	if (cr6.eq) goto loc_830ABB90;
	// lis r7,4352
	ctx.r7.s64 = 285212672;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// beq cr6,0x830abb90
	if (cr6.eq) goto loc_830ABB90;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x830ab784
	if (!cr6.eq) goto loc_830AB784;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// li r19,-1
	r19.s64 = -1;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x830aaea0
	if (cr6.eq) goto loc_830AAEA0;
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// addi r31,r1,192
	r31.s64 = ctx.r1.s64 + 192;
	// rlwinm r30,r16,2,0,29
	r30.u64 = __builtin_rotateleft64(r16.u32 | (r16.u64 << 32), 2) & 0xFFFFFFFC;
loc_830AAE18:
	// stw r19,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r19.u32);
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// stw r19,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r19.u32);
	// stw r19,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r19.u32);
	// stw r19,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r19.u32);
	// beq cr6,0x830aae8c
	if (cr6.eq) goto loc_830AAE8C;
	// lwz r9,260(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// rlwinm r6,r5,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,20(r21)
	ctx.r8.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// mr r11,r16
	r11.u64 = r16.u64;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
loc_830AAE4C:
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addi r29,r1,192
	r29.s64 = ctx.r1.s64 + 192;
	// lwz r27,0(r10)
	r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r27,2,0,29
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwzx r3,r3,r8
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r8.u32);
	// lwzx r27,r27,r8
	r27.u64 = PPC_LOAD_U32(r27.u32 + ctx.r8.u32);
	// lwz r3,16(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r27,16(r27)
	r27.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// add r3,r3,r6
	ctx.r3.u64 = ctx.r3.u64 + ctx.r6.u64;
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r27,r3,r29
	PPC_STORE_U32(ctx.r3.u32 + r29.u32, r27.u32);
	// bne 0x830aae4c
	if (!cr0.eq) goto loc_830AAE4C;
loc_830AAE8C:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// add r7,r30,r7
	ctx.r7.u64 = r30.u64 + ctx.r7.u64;
	// cmplw cr6,r5,r18
	cr6.compare<uint32_t>(ctx.r5.u32, r18.u32, xer);
	// blt cr6,0x830aae18
	if (cr6.lt) goto loc_830AAE18;
loc_830AAEA0:
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// lwz r10,20(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// lwz r9,16(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830ab084
	if (cr0.eq) goto loc_830AB084;
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r9,0(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,112(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 112);
	// lwz r8,0(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwzx r31,r11,r10
	r31.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r4,108(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 108);
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,65535
	cr6.compare<uint32_t>(r30.u32, 65535, xer);
	// beq cr6,0x830ab0fc
	if (cr6.eq) goto loc_830AB0FC;
	// cmplwi cr6,r30,11
	cr6.compare<uint32_t>(r30.u32, 11, xer);
	// bne cr6,0x830aaf70
	if (!cr6.eq) goto loc_830AAF70;
	// lis r10,-31952
	ctx.r10.s64 = -2094006272;
	// mr r11,r17
	r11.u64 = r17.u64;
	// addi r9,r10,3856
	ctx.r9.s64 = ctx.r10.s64 + 3856;
loc_830AAF30:
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830aaf50
	if (cr6.eq) goto loc_830AAF50;
	// addi r8,r9,64
	ctx.r8.s64 = ctx.r9.s64 + 64;
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x830aaf68
	if (!cr6.eq) goto loc_830AAF68;
loc_830AAF50:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830aaf30
	if (cr6.lt) goto loc_830AAF30;
	// li r11,1
	r11.s64 = 1;
loc_830AAF60:
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// b 0x830aafc8
	goto loc_830AAFC8;
loc_830AAF68:
	// mr r11,r17
	r11.u64 = r17.u64;
	// b 0x830aaf60
	goto loc_830AAF60;
loc_830AAF70:
	// cmplwi cr6,r30,13
	cr6.compare<uint32_t>(r30.u32, 13, xer);
	// bne cr6,0x830aafd4
	if (!cr6.eq) goto loc_830AAFD4;
	// lis r11,-31952
	r11.s64 = -2094006272;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
	// addi r7,r11,3856
	ctx.r7.s64 = r11.s64 + 3856;
loc_830AAF88:
	// mr r11,r17
	r11.u64 = r17.u64;
	// addi r9,r1,192
	ctx.r9.s64 = ctx.r1.s64 + 192;
loc_830AAF90:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830aafb0
	if (cr6.eq) goto loc_830AAFB0;
	// add r5,r11,r8
	ctx.r5.u64 = r11.u64 + ctx.r8.u64;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r5,r7
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r7.u32);
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x830ab074
	if (!cr6.eq) goto loc_830AB074;
loc_830AAFB0:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x830aaf90
	if (cr6.lt) goto loc_830AAF90;
	// li r6,1
	ctx.r6.s64 = 1;
loc_830AAFC4:
	// cntlzw r11,r6
	r11.u64 = ctx.r6.u32 == 0 ? 32 : __builtin_clz(ctx.r6.u32);
loc_830AAFC8:
	// rlwinm r28,r11,27,31,31
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x830aafe0
	if (!cr6.eq) goto loc_830AAFE0;
loc_830AAFD4:
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// rlwinm. r11,r11,0,11,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1F0000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830aaffc
	if (cr0.eq) goto loc_830AAFFC;
loc_830AAFE0:
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x830aaba0
	sub_830AABA0(ctx, base);
	// lwz r14,80(r1)
	r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
loc_830AAFFC:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// std r17,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r17.u64);
	// std r17,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r17.u64);
	// bl 0x830aa8b8
	sub_830AA8B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830ab030
	if (!cr0.eq) goto loc_830AB030;
	// cmplwi cr6,r30,13
	cr6.compare<uint32_t>(r30.u32, 13, xer);
	// bne cr6,0x830ab0fc
	if (!cr6.eq) goto loc_830AB0FC;
	// lwz r11,192(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830ab0fc
	if (!cr6.eq) goto loc_830AB0FC;
loc_830AB030:
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// stw r17,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r17.u32);
	// beq cr6,0x830abbd8
	if (cr6.eq) goto loc_830ABBD8;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// b 0x830abbd8
	goto loc_830ABBD8;
loc_830AB074:
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplwi cr6,r8,16
	cr6.compare<uint32_t>(ctx.r8.u32, 16, xer);
	// blt cr6,0x830aaf88
	if (cr6.lt) goto loc_830AAF88;
	// b 0x830aafc4
	goto loc_830AAFC4;
loc_830AB084:
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x830ab0fc
	if (cr6.eq) goto loc_830AB0FC;
	// lis r11,-31952
	r11.s64 = -2094006272;
	// addi r7,r1,192
	ctx.r7.s64 = ctx.r1.s64 + 192;
	// addi r5,r11,3856
	ctx.r5.s64 = r11.s64 + 3856;
loc_830AB09C:
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
loc_830AB0A0:
	// mr r11,r17
	r11.u64 = r17.u64;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_830AB0A8:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830ab0c8
	if (cr6.eq) goto loc_830AB0C8;
	// add r4,r11,r8
	ctx.r4.u64 = r11.u64 + ctx.r8.u64;
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r5
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r5.u32);
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// bne cr6,0x830ab0ec
	if (!cr6.eq) goto loc_830AB0EC;
loc_830AB0C8:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x830ab0a8
	if (cr6.lt) goto loc_830AB0A8;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,16
	ctx.r7.s64 = ctx.r7.s64 + 16;
	// cmplw cr6,r6,r18
	cr6.compare<uint32_t>(ctx.r6.u32, r18.u32, xer);
	// blt cr6,0x830ab09c
	if (cr6.lt) goto loc_830AB09C;
	// b 0x830ab0fc
	goto loc_830AB0FC;
loc_830AB0EC:
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplwi cr6,r8,32
	cr6.compare<uint32_t>(ctx.r8.u32, 32, xer);
	// blt cr6,0x830ab0a0
	if (cr6.lt) goto loc_830AB0A0;
	// li r28,1
	r28.s64 = 1;
loc_830AB0FC:
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// lis r9,4304
	ctx.r9.s64 = 282066944;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x830ab120
	if (cr6.eq) goto loc_830AB120;
	// lis r9,4320
	ctx.r9.s64 = 283115520;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830ab2c0
	if (!cr6.eq) goto loc_830AB2C0;
loc_830AB120:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830ab2c0
	if (cr6.eq) goto loc_830AB2C0;
	// lwz r9,20(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_830AB138:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,60(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 60);
	// rlwinm. r7,r7,0,11,15
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x1F0000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x830ab154
	if (cr0.eq) goto loc_830AB154;
	// li r8,1
	ctx.r8.s64 = 1;
loc_830AB154:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830ab138
	if (!cr0.eq) goto loc_830AB138;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x830ab2c0
	if (cr6.eq) goto loc_830AB2C0;
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// mr r29,r17
	r29.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830ab1a8
	if (cr6.eq) goto loc_830AB1A8;
	// lwz r8,136(r21)
	ctx.r8.u64 = PPC_LOAD_U32(r21.u32 + 136);
loc_830AB17C:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x830ab19c
	if (!cr6.eq) goto loc_830AB19C;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// blt cr6,0x830ab19c
	if (cr6.lt) goto loc_830AB19C;
	// addi r29,r10,1
	r29.s64 = ctx.r10.s64 + 1;
loc_830AB19C:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830ab17c
	if (!cr0.eq) goto loc_830AB17C;
loc_830AB1A8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r31,r17
	r31.u64 = r17.u64;
	// addi r30,r1,176
	r30.s64 = ctx.r1.s64 + 176;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830AB1B8:
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// lwz r4,136(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 136);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830ab214
	if (cr6.eq) goto loc_830AB214;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r31,4
	cr6.compare<uint32_t>(r31.u32, 4, xer);
	// blt cr6,0x830ab1b8
	if (cr6.lt) goto loc_830AB1B8;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830ab208
	if (cr0.eq) goto loc_830AB208;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r15,r3
	r15.u64 = ctx.r3.u64;
	// b 0x830ab20c
	goto loc_830AB20C;
loc_830AB208:
	// mr r15,r17
	r15.u64 = r17.u64;
loc_830AB20C:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// bne cr6,0x830ab220
	if (!cr6.eq) goto loc_830AB220;
loc_830AB214:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x830abba8
	goto loc_830ABBA8;
loc_830AB220:
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// rlwimi r4,r10,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r10.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// lwz r4,260(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// lwz r3,16(r15)
	ctx.r3.u64 = PPC_LOAD_U32(r15.u32 + 16);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// lwz r3,8(r15)
	ctx.r3.u64 = PPC_LOAD_U32(r15.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// mr r15,r17
	r15.u64 = r17.u64;
loc_830AB2C0:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x830ab76c
	if (cr6.eq) goto loc_830AB76C;
	// lwz r11,108(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 108);
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830ab76c
	if (cr0.eq) goto loc_830AB76C;
	// mr r20,r17
	r20.u64 = r17.u64;
	// mr r22,r17
	r22.u64 = r17.u64;
	// cmplwi cr6,r16,4
	cr6.compare<uint32_t>(r16.u32, 4, xer);
	// bne cr6,0x830ab574
	if (!cr6.eq) goto loc_830AB574;
	// li r27,1
	r27.s64 = 1;
	// mr r26,r17
	r26.u64 = r17.u64;
	// addi r30,r1,112
	r30.s64 = ctx.r1.s64 + 112;
	// li r31,-1
	r31.s64 = -1;
loc_830AB2F4:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x830ab374
	if (cr6.eq) goto loc_830AB374;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// mr r27,r17
	r27.u64 = r17.u64;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// std r17,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r17.u64);
	// std r17,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r17.u64);
	// stw r19,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r19.u32);
	// stw r19,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r19.u32);
	// stw r19,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r19.u32);
	// stw r19,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r19.u32);
	// stw r31,-16(r30)
	PPC_STORE_U32(r30.u32 + -16, r31.u32);
	// stw r17,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r17.u32);
	// beq cr6,0x830ab40c
	if (cr6.eq) goto loc_830AB40C;
	// addi r28,r1,192
	r28.s64 = ctx.r1.s64 + 192;
	// mr r29,r18
	r29.u64 = r18.u64;
loc_830AB338:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830aa8b8
	sub_830AA8B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830ab350
	if (!cr0.eq) goto loc_830AB350;
	// li r27,1
	r27.s64 = 1;
loc_830AB350:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r28,r28,16
	r28.s64 = r28.s64 + 16;
	// bne 0x830ab338
	if (!cr0.eq) goto loc_830AB338;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x830ab40c
	if (cr6.eq) goto loc_830AB40C;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r26,4
	cr6.compare<uint32_t>(r26.u32, 4, xer);
	// blt cr6,0x830ab2f4
	if (cr6.lt) goto loc_830AB2F4;
loc_830AB374:
	// li r25,1
	r25.s64 = 1;
	// mr r23,r17
	r23.u64 = r17.u64;
	// addi r29,r1,112
	r29.s64 = ctx.r1.s64 + 112;
loc_830AB380:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830ab4f8
	if (cr6.eq) goto loc_830AB4F8;
	// mr r24,r17
	r24.u64 = r17.u64;
	// addi r30,r1,112
	r30.s64 = ctx.r1.s64 + 112;
loc_830AB390:
	// cmplw cr6,r24,r23
	cr6.compare<uint32_t>(r24.u32, r23.u32, xer);
	// beq cr6,0x830ab4d0
	if (cr6.eq) goto loc_830AB4D0;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// mr r25,r17
	r25.u64 = r17.u64;
	// mr r26,r17
	r26.u64 = r17.u64;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// std r17,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r17.u64);
	// std r17,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r17.u64);
	// stw r19,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r19.u32);
	// stw r19,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r19.u32);
	// stw r19,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r19.u32);
	// stw r19,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r19.u32);
	// stw r31,-16(r29)
	PPC_STORE_U32(r29.u32 + -16, r31.u32);
	// stw r31,-16(r30)
	PPC_STORE_U32(r30.u32 + -16, r31.u32);
	// stw r17,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r17.u32);
	// stw r17,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r17.u32);
	// beq cr6,0x830ab4e4
	if (cr6.eq) goto loc_830AB4E4;
	// addi r28,r1,192
	r28.s64 = ctx.r1.s64 + 192;
	// mr r27,r18
	r27.u64 = r18.u64;
loc_830AB3E0:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830aa8b8
	sub_830AA8B8(ctx, base);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830aa8b8
	sub_830AA8B8(ctx, base);
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// bne cr6,0x830ab448
	if (!cr6.eq) goto loc_830AB448;
	// li r26,1
	r26.s64 = 1;
	// b 0x830ab450
	goto loc_830AB450;
loc_830AB40C:
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// b 0x830ab748
	goto loc_830AB748;
loc_830AB448:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830ab454
	if (!cr6.eq) goto loc_830AB454;
loc_830AB450:
	// li r25,1
	r25.s64 = 1;
loc_830AB454:
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// addi r28,r28,16
	r28.s64 = r28.s64 + 16;
	// bne 0x830ab3e0
	if (!cr0.eq) goto loc_830AB3E0;
	// lwz r14,80(r1)
	r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830ab4e4
	if (cr6.eq) goto loc_830AB4E4;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// bne cr6,0x830ab4d0
	if (!cr6.eq) goto loc_830AB4D0;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// li r22,1
	r22.s64 = 1;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r7,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r7.u32);
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// stw r5,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r5.u32);
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r11.u32);
	// stw r19,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r19.u32);
	// stw r19,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, r19.u32);
	// stw r19,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, r19.u32);
	// stw r19,12(r9)
	PPC_STORE_U32(ctx.r9.u32 + 12, r19.u32);
	// stw r19,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r19.u32);
	// stw r19,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, r19.u32);
	// stw r19,8(r8)
	PPC_STORE_U32(ctx.r8.u32 + 8, r19.u32);
	// stw r19,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, r19.u32);
	// stw r17,32(r29)
	PPC_STORE_U32(r29.u32 + 32, r17.u32);
	// stw r17,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r17.u32);
loc_830AB4D0:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r24,4
	cr6.compare<uint32_t>(r24.u32, 4, xer);
	// blt cr6,0x830ab390
	if (cr6.lt) goto loc_830AB390;
	// b 0x830ab4e8
	goto loc_830AB4E8;
loc_830AB4E4:
	// li r20,1
	r20.s64 = 1;
loc_830AB4E8:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplwi cr6,r23,4
	cr6.compare<uint32_t>(r23.u32, 4, xer);
	// blt cr6,0x830ab380
	if (cr6.lt) goto loc_830AB380;
loc_830AB4F8:
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// beq cr6,0x830ab524
	if (cr6.eq) goto loc_830AB524;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// li r6,4
	ctx.r6.s64 = 4;
	// b 0x830ab6b8
	goto loc_830AB6B8;
loc_830AB524:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x830ab6d8
	if (cr6.eq) goto loc_830AB6D8;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// li r20,1
	r20.s64 = 1;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// b 0x830ab6bc
	goto loc_830AB6BC;
loc_830AB574:
	// cmplwi cr6,r16,3
	cr6.compare<uint32_t>(r16.u32, 3, xer);
	// bne cr6,0x830ab6d8
	if (!cr6.eq) goto loc_830AB6D8;
	// li r31,-1
	r31.s64 = -1;
	// mr r11,r17
	r11.u64 = r17.u64;
	// mr r25,r31
	r25.u64 = r31.u64;
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
loc_830AB58C:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x830ab59c
	if (!cr6.eq) goto loc_830AB59C;
	// mr r25,r11
	r25.u64 = r11.u64;
loc_830AB59C:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x830ab58c
	if (cr6.lt) goto loc_830AB58C;
	// mr r23,r17
	r23.u64 = r17.u64;
	// addi r26,r1,112
	r26.s64 = ctx.r1.s64 + 112;
loc_830AB5B4:
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// bne cr6,0x830ab698
	if (!cr6.eq) goto loc_830AB698;
	// mr r24,r17
	r24.u64 = r17.u64;
	// addi r28,r1,112
	r28.s64 = ctx.r1.s64 + 112;
loc_830AB5C4:
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// bne cr6,0x830ab680
	if (!cr6.eq) goto loc_830AB680;
	// cmplw cr6,r24,r23
	cr6.compare<uint32_t>(r24.u32, r23.u32, xer);
	// beq cr6,0x830ab670
	if (cr6.eq) goto loc_830AB670;
	// cmplw cr6,r24,r25
	cr6.compare<uint32_t>(r24.u32, r25.u32, xer);
	// beq cr6,0x830ab670
	if (cr6.eq) goto loc_830AB670;
	// cmplw cr6,r23,r25
	cr6.compare<uint32_t>(r23.u32, r25.u32, xer);
	// beq cr6,0x830ab670
	if (cr6.eq) goto loc_830AB670;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// rlwinm r9,r25,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,112
	ctx.r8.s64 = ctx.r1.s64 + 112;
	// mr r29,r17
	r29.u64 = r17.u64;
	// std r19,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r19.u64);
	// mr r30,r17
	r30.u64 = r17.u64;
	// std r19,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r19.u64);
	// stw r17,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r17.u32);
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// stw r17,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r17.u32);
	// stw r17,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r17.u32);
	// stw r17,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r17.u32);
	// stw r17,-16(r26)
	PPC_STORE_U32(r26.u32 + -16, r17.u32);
	// stw r17,-16(r28)
	PPC_STORE_U32(r28.u32 + -16, r17.u32);
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// stw r31,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r31.u32);
	// stwx r31,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, r31.u32);
	// beq cr6,0x830ab66c
	if (cr6.eq) goto loc_830AB66C;
	// addi r27,r1,192
	r27.s64 = ctx.r1.s64 + 192;
loc_830AB634:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x830ab670
	if (!cr6.eq) goto loc_830AB670;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830aa8b8
	sub_830AA8B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830ab654
	if (!cr0.eq) goto loc_830AB654;
	// li r29,1
	r29.s64 = 1;
loc_830AB654:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r27,r27,16
	r27.s64 = r27.s64 + 16;
	// cmplw cr6,r30,r18
	cr6.compare<uint32_t>(r30.u32, r18.u32, xer);
	// blt cr6,0x830ab634
	if (cr6.lt) goto loc_830AB634;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x830ab670
	if (!cr6.eq) goto loc_830AB670;
loc_830AB66C:
	// li r20,1
	r20.s64 = 1;
loc_830AB670:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplwi cr6,r24,4
	cr6.compare<uint32_t>(r24.u32, 4, xer);
	// blt cr6,0x830ab5c4
	if (cr6.lt) goto loc_830AB5C4;
loc_830AB680:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplwi cr6,r23,4
	cr6.compare<uint32_t>(r23.u32, 4, xer);
	// blt cr6,0x830ab5b4
	if (cr6.lt) goto loc_830AB5B4;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// beq cr6,0x830ab6d8
	if (cr6.eq) goto loc_830AB6D8;
loc_830AB698:
	// li r6,3
	ctx.r6.s64 = 3;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// li r6,3
	ctx.r6.s64 = 3;
loc_830AB6B8:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
loc_830AB6BC:
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// bne cr6,0x830ab748
	if (!cr6.eq) goto loc_830AB748;
loc_830AB6D8:
	// mr r29,r17
	r29.u64 = r17.u64;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x830ab748
	if (cr6.eq) goto loc_830AB748;
	// mr r30,r17
	r30.u64 = r17.u64;
loc_830AB6E8:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lwz r10,260(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// lwz r9,20(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// std r19,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r19.u64);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// std r19,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r19.u64);
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r17,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, r17.u32);
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r16
	cr6.compare<uint32_t>(r29.u32, r16.u32, xer);
	// blt cr6,0x830ab6e8
	if (cr6.lt) goto loc_830AB6E8;
loc_830AB748:
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x830ab8ac
	if (cr6.eq) goto loc_830AB8AC;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// mr r14,r17
	r14.u64 = r17.u64;
	// b 0x830ab8ac
	goto loc_830AB8AC;
loc_830AB76C:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r4,260(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abba8
	if (cr0.lt) goto loc_830ABBA8;
	// b 0x830ab8ac
	goto loc_830AB8AC;
loc_830AB784:
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830abb74
	if (cr6.eq) goto loc_830ABB74;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x830abb74
	if (cr6.eq) goto loc_830ABB74;
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// lwz r31,20(r21)
	r31.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// lwz r10,132(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 132);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830ab7dc
	if (!cr6.eq) goto loc_830AB7DC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,60(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 60);
	// li r5,4817
	ctx.r5.s64 = 4817;
	// addi r6,r11,24712
	ctx.r6.s64 = r11.s64 + 24712;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
	// b 0x830abbd8
	goto loc_830ABBD8;
loc_830AB7DC:
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x830ab89c
	if (cr6.eq) goto loc_830AB89C;
	// lis r10,-31952
	ctx.r10.s64 = -2094006272;
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// rlwinm r26,r16,2,0,29
	r26.u64 = __builtin_rotateleft64(r16.u32 | (r16.u64 << 32), 2) & 0xFFFFFFFC;
	// li r19,-1
	r19.s64 = -1;
	// addi r3,r10,3856
	ctx.r3.s64 = ctx.r10.s64 + 3856;
loc_830AB800:
	// stw r19,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r19.u32);
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// stw r19,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r19.u32);
	// stw r19,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r19.u32);
	// stw r19,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r19.u32);
	// beq cr6,0x830ab84c
	if (cr6.eq) goto loc_830AB84C;
	// lwz r9,8(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// add r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 + ctx.r6.u64;
loc_830AB828:
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r31
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r31.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x830ab828
	if (!cr0.eq) goto loc_830AB828;
loc_830AB84C:
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
loc_830AB850:
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
loc_830AB858:
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x830ab878
	if (cr6.eq) goto loc_830AB878;
	// add r30,r7,r10
	r30.u64 = ctx.r7.u64 + ctx.r10.u64;
	// rlwinm r30,r30,2,0,29
	r30.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r30,r3
	r30.u64 = PPC_LOAD_U32(r30.u32 + ctx.r3.u32);
	// cmplw cr6,r9,r30
	cr6.compare<uint32_t>(ctx.r9.u32, r30.u32, xer);
	// bne cr6,0x830ab8bc
	if (!cr6.eq) goto loc_830AB8BC;
loc_830AB878:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// blt cr6,0x830ab858
	if (cr6.lt) goto loc_830AB858;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// add r6,r6,r26
	ctx.r6.u64 = ctx.r6.u64 + r26.u64;
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// cmplw cr6,r5,r18
	cr6.compare<uint32_t>(ctx.r5.u32, r18.u32, xer);
	// blt cr6,0x830ab800
	if (cr6.lt) goto loc_830AB800;
loc_830AB89C:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abbd8
	if (cr0.lt) goto loc_830ABBD8;
loc_830AB8AC:
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// mr r31,r17
	r31.u64 = r17.u64;
	// stw r17,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r17.u32);
	// b 0x830abba8
	goto loc_830ABBA8;
loc_830AB8BC:
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplwi cr6,r7,32
	cr6.compare<uint32_t>(ctx.r7.u32, 32, xer);
	// blt cr6,0x830ab850
	if (cr6.lt) goto loc_830AB850;
	// lwz r11,108(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 108);
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830ab89c
	if (cr0.eq) goto loc_830AB89C;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x830aa928
	sub_830AA928(ctx, base);
	// lwz r15,84(r1)
	r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abbc0
	if (cr0.lt) goto loc_830ABBC0;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x830ab914
	if (cr6.eq) goto loc_830AB914;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abbc0
	if (cr0.lt) goto loc_830ABBC0;
	// mr r15,r17
	r15.u64 = r17.u64;
loc_830AB914:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830ab930
	if (cr0.eq) goto loc_830AB930;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830ab934
	goto loc_830AB934;
loc_830AB930:
	// mr r30,r17
	r30.u64 = r17.u64;
loc_830AB934:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x830ab948
	if (!cr6.eq) goto loc_830AB948;
loc_830AB93C:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x830abbc0
	goto loc_830ABBC0;
loc_830AB948:
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// mr r28,r17
	r28.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830ab9a4
	if (cr6.eq) goto loc_830AB9A4;
	// lwz r7,16(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r8,20(r21)
	ctx.r8.u64 = PPC_LOAD_U32(r21.u32 + 20);
loc_830AB960:
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// clrlwi. r6,r9,31
	ctx.r6.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x830ab998
	if (cr0.eq) goto loc_830AB998;
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830ab998
	if (cr0.eq) goto loc_830AB998;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// bge cr6,0x830ab998
	if (!cr6.lt) goto loc_830AB998;
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
loc_830AB998:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x830ab960
	if (!cr0.eq) goto loc_830AB960;
loc_830AB9A4:
	// lis r4,8272
	ctx.r4.s64 = 542113792;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abbc0
	if (cr0.lt) goto loc_830ABBC0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,260(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abbc0
	if (cr0.lt) goto loc_830ABBC0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r4,136(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 136);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r25,r28,1
	r25.s64 = r28.s64 + 1;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x830ab93c
	if (cr6.eq) goto loc_830AB93C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abbc0
	if (cr0.lt) goto loc_830ABBC0;
	// li r28,1
	r28.s64 = 1;
	// cmplwi cr6,r16,1
	cr6.compare<uint32_t>(r16.u32, 1, xer);
	// ble cr6,0x830ab8ac
	if (!cr6.gt) goto loc_830AB8AC;
	// li r27,4
	r27.s64 = 4;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
loc_830ABA64:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830aba80
	if (cr0.eq) goto loc_830ABA80;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830aba84
	goto loc_830ABA84;
loc_830ABA80:
	// mr r30,r17
	r30.u64 = r17.u64;
loc_830ABA84:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830ab93c
	if (cr6.eq) goto loc_830AB93C;
	// lis r4,28720
	ctx.r4.s64 = 1882193920;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abbc0
	if (cr0.lt) goto loc_830ABBC0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,260(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abbc0
	if (cr0.lt) goto loc_830ABBC0;
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// addi r10,r16,-1
	ctx.r10.s64 = r16.s64 + -1;
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// lwz r10,260(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r10,r10,r26
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r26.u32);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r29,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r29.u32);
	// beq cr6,0x830abb34
	if (cr6.eq) goto loc_830ABB34;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,136(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 136);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x830ab93c
	if (cr6.eq) goto loc_830AB93C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// b 0x830abb48
	goto loc_830ABB48;
loc_830ABB34:
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
loc_830ABB48:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abbc0
	if (cr0.lt) goto loc_830ABBC0;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r28,r16
	cr6.compare<uint32_t>(r28.u32, r16.u32, xer);
	// blt cr6,0x830aba64
	if (cr6.lt) goto loc_830ABA64;
	// b 0x830ab8ac
	goto loc_830AB8AC;
loc_830ABB74:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abbd8
	if (cr0.lt) goto loc_830ABBD8;
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// stw r17,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r17.u32);
	// b 0x830abbd8
	goto loc_830ABBD8;
loc_830ABB90:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830abbd8
	if (cr0.lt) goto loc_830ABBD8;
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// stw r17,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r17.u32);
loc_830ABBA8:
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x830abbc0
	if (cr6.eq) goto loc_830ABBC0;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830ABBC0:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x830abbd8
	if (cr6.eq) goto loc_830ABBD8;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830ABBD8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_830ABBDC:
	// addi r1,r1,416
	ctx.r1.s64 = ctx.r1.s64 + 416;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82ca2c00
	return;
}

__attribute__((alias("__imp__sub_830ABBE8"))) PPC_WEAK_FUNC(sub_830ABBE8);
PPC_FUNC_IMPL(__imp__sub_830ABBE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// lwz r31,20(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// li r11,0
	r11.s64 = 0;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,16(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwzx r5,r31,r8
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + ctx.r8.u32);
	// lwz r30,4(r5)
	r30.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm r30,r30,2,0,29
	r30.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r30,r9
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,24,24
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830abc34
	if (cr0.eq) goto loc_830ABC34;
	// lis r11,228
	r11.s64 = 14942208;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r11.u32);
	// b 0x830abe50
	goto loc_830ABE50;
loc_830ABC34:
	// rlwinm. r9,r6,0,15,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x10000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830abc48
	if (cr0.eq) goto loc_830ABC48;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r11,1
	r11.s64 = 1;
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
loc_830ABC48:
	// rlwinm. r9,r6,0,14,14
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x20000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830abc64
	if (cr0.eq) goto loc_830ABC64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r1,80
	r30.s64 = ctx.r1.s64 + 80;
	// li r29,1
	r29.s64 = 1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwx r29,r9,r30
	PPC_STORE_U32(ctx.r9.u32 + r30.u32, r29.u32);
loc_830ABC64:
	// rlwinm. r9,r6,0,13,13
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830abc80
	if (cr0.eq) goto loc_830ABC80;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r1,80
	r30.s64 = ctx.r1.s64 + 80;
	// li r29,2
	r29.s64 = 2;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwx r29,r9,r30
	PPC_STORE_U32(ctx.r9.u32 + r30.u32, r29.u32);
loc_830ABC80:
	// rlwinm. r9,r6,0,12,12
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x80000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830abc9c
	if (cr0.eq) goto loc_830ABC9C;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r30,3
	r30.s64 = 3;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwx r30,r9,r6
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, r30.u32);
loc_830ABC9C:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// ble cr6,0x830abca8
	if (!cr6.gt) goto loc_830ABCA8;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_830ABCA8:
	// lwz r11,108(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 108);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// srawi. r30,r11,31
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7FFFFFFF) != 0);
	r30.s64 = r11.s32 >> 31;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x830abccc
	if (cr0.eq) goto loc_830ABCCC;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// li r11,-1
	r11.s64 = -1;
	// std r11,0(r9)
	PPC_STORE_U64(ctx.r9.u32 + 0, r11.u64);
	// std r11,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, r11.u64);
	// b 0x830abd50
	goto loc_830ABD50;
loc_830ABCCC:
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830abd38
	if (cr6.eq) goto loc_830ABD38;
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// lwzx r8,r9,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
loc_830ABCE8:
	// lwz r29,0(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r29,r29,2,0,29
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r29,r9
	r29.u64 = PPC_LOAD_U32(r29.u32 + ctx.r9.u32);
	// lwz r29,16(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplw cr6,r8,r29
	cr6.compare<uint32_t>(ctx.r8.u32, r29.u32, xer);
	// bne cr6,0x830abd10
	if (!cr6.eq) goto loc_830ABD10;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// blt cr6,0x830abce8
	if (cr6.lt) goto loc_830ABCE8;
loc_830ABD10:
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// bge cr6,0x830abd38
	if (!cr6.lt) goto loc_830ABD38;
	// li r11,0
	r11.s64 = 0;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
loc_830ABD20:
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x830abd20
	if (cr6.lt) goto loc_830ABD20;
	// b 0x830abd50
	goto loc_830ABD50;
loc_830ABD38:
	// lwz r11,16(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// stw r11,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, r11.u32);
	// stw r11,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, r11.u32);
	// stw r11,12(r9)
	PPC_STORE_U32(ctx.r9.u32 + 12, r11.u32);
loc_830ABD50:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830abd90
	if (cr6.eq) goto loc_830ABD90;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// subf r9,r9,r4
	ctx.r9.s64 = ctx.r4.s64 - ctx.r9.s64;
loc_830ABD64:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwzx r8,r8,r31
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r31.u32);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// stwx r8,r5,r6
	PPC_STORE_U32(ctx.r5.u32 + ctx.r6.u32, ctx.r8.u32);
	// bne 0x830abd64
	if (!cr0.eq) goto loc_830ABD64;
loc_830ABD90:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x830abe24
	if (cr6.eq) goto loc_830ABE24;
	// lis r11,-31952
	r11.s64 = -2094006272;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r6,r11,3856
	ctx.r6.s64 = r11.s64 + 3856;
loc_830ABDA8:
	// li r11,0
	r11.s64 = 0;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
loc_830ABDB0:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830abdd0
	if (cr6.eq) goto loc_830ABDD0;
	// add r4,r8,r11
	ctx.r4.u64 = ctx.r8.u64 + r11.u64;
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r6
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r6.u32);
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// bne cr6,0x830abe10
	if (!cr6.eq) goto loc_830ABE10;
loc_830ABDD0:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x830abdb0
	if (cr6.lt) goto loc_830ABDB0;
	// rlwinm r11,r5,4,0,27
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 4) & 0xFFFFFFF0;
	// add. r10,r11,r6
	ctx.r10.u64 = r11.u64 + ctx.r6.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830abe28
	if (!cr0.eq) goto loc_830ABE28;
loc_830ABDEC:
	// lwz r11,260(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 260);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,4818
	ctx.r5.s64 = 4818;
	// addi r6,r10,24776
	ctx.r6.s64 = ctx.r10.s64 + 24776;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830abe54
	goto loc_830ABE54;
loc_830ABE10:
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplwi cr6,r8,32
	cr6.compare<uint32_t>(ctx.r8.u32, 32, xer);
	// blt cr6,0x830abda8
	if (cr6.lt) goto loc_830ABDA8;
	// b 0x830abdec
	goto loc_830ABDEC;
loc_830ABE24:
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
loc_830ABE28:
	// li r9,0
	ctx.r9.s64 = 0;
	// li r11,16
	r11.s64 = 16;
loc_830ABE30:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// slw r8,r8,r11
	ctx.r8.u64 = r11.u8 & 0x20 ? 0 : (ctx.r8.u32 << (r11.u8 & 0x3F));
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// or r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 | ctx.r9.u64;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// blt cr6,0x830abe30
	if (cr6.lt) goto loc_830ABE30;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
loc_830ABE50:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830ABE54:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830ABE60"))) PPC_WEAK_FUNC(sub_830ABE60);
PPC_FUNC_IMPL(__imp__sub_830ABE60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r11,r11,24272
	r11.s64 = r11.s64 + 24272;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8306af88
	sub_8306AF88(ctx, base);
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830abea0
	if (cr0.eq) goto loc_830ABEA0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
loc_830ABEA0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830ABEC0"))) PPC_WEAK_FUNC(sub_830ABEC0);
PPC_FUNC_IMPL(__imp__sub_830ABEC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8306bb68
	sub_8306BB68(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830abf74
	if (cr0.lt) goto loc_830ABF74;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// lwz r28,12(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830abf38
	if (cr6.eq) goto loc_830ABF38;
	// li r29,0
	r29.s64 = 0;
loc_830ABEF8:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830abf28
	if (cr0.eq) goto loc_830ABF28;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830aad38
	sub_830AAD38(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830abf74
	if (cr0.lt) goto loc_830ABF74;
loc_830ABF28:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// blt cr6,0x830abef8
	if (cr6.lt) goto loc_830ABEF8;
loc_830ABF38:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084778
	sub_83084778(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830abf74
	if (cr0.lt) goto loc_830ABF74;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830878b8
	sub_830878B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830abf74
	if (cr0.lt) goto loc_830ABF74;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307f3a8
	sub_8307F3A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830abf74
	if (cr0.lt) goto loc_830ABF74;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_830ABF74:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830ABF80"))) PPC_WEAK_FUNC(sub_830ABF80);
PPC_FUNC_IMPL(__imp__sub_830ABF80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2bdc
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// clrlwi. r7,r11,12
	ctx.r7.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x830abf9c
	if (!cr0.eq) goto loc_830ABF9C;
loc_830ABF94:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830ac094
	goto loc_830AC094;
loc_830ABF9C:
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// li r31,0
	r31.s64 = 0;
	// twllei r7,0
	// divwu. r28,r11,r7
	r28.u32 = r11.u32 / ctx.r7.u32;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x830ac090
	if (cr0.eq) goto loc_830AC090;
	// lwz r11,108(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 108);
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r29,r7,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r27,-1
	r27.s64 = -1;
	// srawi r26,r11,31
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7FFFFFFF) != 0);
	r26.s64 = r11.s32 >> 31;
	// lis r11,-31952
	r11.s64 = -2094006272;
	// addi r30,r11,3856
	r30.s64 = r11.s64 + 3856;
loc_830ABFD0:
	// addi r11,r1,-80
	r11.s64 = ctx.r1.s64 + -80;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// std r27,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r27.u64);
	// std r27,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r27.u64);
	// beq cr6,0x830ac01c
	if (cr6.eq) goto loc_830AC01C;
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r9,r1,-80
	ctx.r9.s64 = ctx.r1.s64 + -80;
	// lwz r8,20(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r11,r7
	r11.u64 = ctx.r7.u64;
	// add r10,r10,r5
	ctx.r10.u64 = ctx.r10.u64 + ctx.r5.u64;
loc_830ABFF8:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r8
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r8.u32);
	// lwz r6,16(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// stw r6,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r6.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830abff8
	if (!cr0.eq) goto loc_830ABFF8;
loc_830AC01C:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x830ac080
	if (cr6.eq) goto loc_830AC080;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
loc_830AC02C:
	// li r11,0
	r11.s64 = 0;
	// addi r8,r1,-80
	ctx.r8.s64 = ctx.r1.s64 + -80;
loc_830AC034:
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830ac054
	if (cr6.eq) goto loc_830AC054;
	// add r25,r9,r11
	r25.u64 = ctx.r9.u64 + r11.u64;
	// rlwinm r25,r25,2,0,29
	r25.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r25,r25,r30
	r25.u64 = PPC_LOAD_U32(r25.u32 + r30.u32);
	// cmplw cr6,r10,r25
	cr6.compare<uint32_t>(ctx.r10.u32, r25.u32, xer);
	// bne cr6,0x830ac068
	if (!cr6.eq) goto loc_830AC068;
loc_830AC054:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x830ac034
	if (cr6.lt) goto loc_830AC034;
	// b 0x830ac078
	goto loc_830AC078;
loc_830AC068:
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// cmplwi cr6,r9,32
	cr6.compare<uint32_t>(ctx.r9.u32, 32, xer);
	// blt cr6,0x830ac02c
	if (cr6.lt) goto loc_830AC02C;
loc_830AC078:
	// cmplwi cr6,r6,8
	cr6.compare<uint32_t>(ctx.r6.u32, 8, xer);
	// beq cr6,0x830abf94
	if (cr6.eq) goto loc_830ABF94;
loc_830AC080:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// add r5,r29,r5
	ctx.r5.u64 = r29.u64 + ctx.r5.u64;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// blt cr6,0x830abfd0
	if (cr6.lt) goto loc_830ABFD0;
loc_830AC090:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830AC094:
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830AC098"))) PPC_WEAK_FUNC(sub_830AC098);
PPC_FUNC_IMPL(__imp__sub_830AC098) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// li r21,0
	r21.s64 = 0;
	// li r29,0
	r29.s64 = 0;
	// lwz r24,12(r31)
	r24.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830ac0f0
	if (cr6.eq) goto loc_830AC0F0;
	// li r28,0
	r28.s64 = 0;
loc_830AC0C4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// bl 0x83062368
	sub_83062368(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830ac0c4
	if (cr6.lt) goto loc_830AC0C4;
loc_830AC0F0:
	// li r26,0
	r26.s64 = 0;
	// lis r20,24656
	r20.s64 = 1615855616;
	// lis r17,24768
	r17.s64 = 1623195648;
	// lis r14,24704
	r14.s64 = 1619001344;
	// lis r15,24784
	r15.s64 = 1624244224;
	// lis r16,24864
	r16.s64 = 1629487104;
	// lis r18,24576
	r18.s64 = 1610612736;
	// lis r19,4352
	r19.s64 = 285212672;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830ac580
	if (cr6.eq) goto loc_830AC580;
	// li r25,0
	r25.s64 = 0;
loc_830AC11C:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r26,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r26.u32);
	// lwzx r4,r11,r25
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// stw r4,260(r31)
	PPC_STORE_U32(r31.u32 + 260, ctx.r4.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// lis r10,24816
	ctx.r10.s64 = 1626341376;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// lis r10,24736
	ctx.r10.s64 = 1621098496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// lis r10,24608
	ctx.r10.s64 = 1612709888;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// lis r10,24688
	ctx.r10.s64 = 1617952768;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// lis r10,24848
	ctx.r10.s64 = 1628438528;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// lis r10,24624
	ctx.r10.s64 = 1613758464;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// cmplw cr6,r11,r14
	cr6.compare<uint32_t>(r11.u32, r14.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// beq cr6,0x830ac1b4
	if (cr6.eq) goto loc_830AC1B4;
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// bne cr6,0x830ac554
	if (!cr6.eq) goto loc_830AC554;
loc_830AC1B4:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// clrlwi r28,r11,12
	r28.u64 = r11.u32 & 0xFFFFF;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// mr r27,r28
	r27.u64 = r28.u64;
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// bne cr6,0x830ac1d0
	if (!cr6.eq) goto loc_830AC1D0;
	// li r27,0
	r27.s64 = 0;
loc_830AC1D0:
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830ac25c
	if (cr6.eq) goto loc_830AC25C;
	// rlwinm r29,r27,2,0,29
	r29.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
loc_830AC1E0:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x830ac25c
	if (!cr6.eq) goto loc_830AC25C;
	// lwz r10,60(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// rlwinm. r10,r10,0,11,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1F0000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830ac25c
	if (!cr0.eq) goto loc_830AC25C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,128(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830ac240
	if (!cr6.eq) goto loc_830AC240;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,108(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// lwz r11,112(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r3,6
	cr6.compare<uint32_t>(ctx.r3.u32, 6, xer);
	// b 0x830ac248
	goto loc_830AC248;
loc_830AC240:
	// lwz r11,136(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
loc_830AC248:
	// bne cr6,0x830ac25c
	if (!cr6.eq) goto loc_830AC25C;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// blt cr6,0x830ac1e0
	if (cr6.lt) goto loc_830AC1E0;
loc_830AC25C:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// bne cr6,0x830ac440
	if (!cr6.eq) goto loc_830AC440;
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// bne cr6,0x830ac440
	if (!cr6.eq) goto loc_830AC440;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830acad0
	if (cr0.lt) goto loc_830ACAD0;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830ac2c4
	if (cr0.eq) goto loc_830AC2C4;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// b 0x830ac2c8
	goto loc_830AC2C8;
loc_830AC2C4:
	// li r21,0
	r21.s64 = 0;
loc_830AC2C8:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830ac6a4
	if (cr6.eq) goto loc_830AC6A4;
	// lis r4,4096
	ctx.r4.s64 = 268435456;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,2
	ctx.r5.s64 = 2;
	// ori r4,r4,2
	ctx.r4.u64 = ctx.r4.u64 | 2;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830acab8
	if (cr0.lt) goto loc_830ACAB8;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r4,260(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830acab8
	if (cr0.lt) goto loc_830ACAB8;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// lwz r10,8(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,8(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// lwz r11,16(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,16(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830acab8
	if (cr0.lt) goto loc_830ACAB8;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830ac378
	if (cr0.eq) goto loc_830AC378;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x830ac37c
	goto loc_830AC37C;
loc_830AC378:
	// li r29,0
	r29.s64 = 0;
loc_830AC37C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830ac6b0
	if (cr6.eq) goto loc_830AC6B0;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lis r4,24656
	ctx.r4.s64 = 1615855616;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,4
	ctx.r5.s64 = 4;
	// ori r4,r4,2
	ctx.r4.u64 = ctx.r4.u64 | 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// blt 0x830ac6c0
	if (cr0.lt) goto loc_830AC6C0;
	// lwz r4,260(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830ac6bc
	if (cr0.lt) goto loc_830AC6BC;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r11,8
	r11.s64 = 8;
	// addi r9,r10,-8
	ctx.r9.s64 = ctx.r10.s64 + -8;
loc_830AC3CC:
	// lwz r8,260(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// lwz r8,8(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwz r8,0(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stw r8,-8(r10)
	PPC_STORE_U32(ctx.r10.u32 + -8, ctx.r8.u32);
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// stwx r8,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830ac3cc
	if (cr6.lt) goto loc_830AC3CC;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r3,16(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r30,260(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830ac430
	if (cr6.eq) goto loc_830AC430;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830AC430:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stwx r29,r11,r25
	PPC_STORE_U32(r11.u32 + r25.u32, r29.u32);
	// stw r29,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r29.u32);
	// b 0x830ac54c
	goto loc_830AC54C;
loc_830AC440:
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// beq cr6,0x830ac550
	if (cr6.eq) goto loc_830AC550;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830acad0
	if (cr0.lt) goto loc_830ACAD0;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830ac494
	if (cr0.eq) goto loc_830AC494;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// b 0x830ac498
	goto loc_830AC498;
loc_830AC494:
	// li r21,0
	r21.s64 = 0;
loc_830AC498:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830ac6a4
	if (cr6.eq) goto loc_830AC6A4;
	// li r11,1
	r11.s64 = 1;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830acab8
	if (cr0.lt) goto loc_830ACAB8;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r4,260(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830acab8
	if (cr0.lt) goto loc_830ACAB8;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830ac538
	if (cr6.eq) goto loc_830AC538;
	// li r11,0
	r11.s64 = 0;
	// rlwinm r10,r27,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
loc_830AC4F0:
	// lwz r8,260(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// lwz r6,8(r21)
	ctx.r6.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// lwz r8,8(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// stwx r8,r11,r6
	PPC_STORE_U32(r11.u32 + ctx.r6.u32, ctx.r8.u32);
	// lwzx r8,r11,r7
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r7,16(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// stwx r8,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r8.u32);
	// lwz r8,16(r21)
	ctx.r8.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r7,260(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r7,8(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// stwx r8,r7,r10
	PPC_STORE_U32(ctx.r7.u32 + ctx.r10.u32, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830ac4f0
	if (!cr0.eq) goto loc_830AC4F0;
loc_830AC538:
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830acab8
	if (cr0.lt) goto loc_830ACAB8;
loc_830AC54C:
	// li r21,0
	r21.s64 = 0;
loc_830AC550:
	// lwz r4,260(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 260);
loc_830AC554:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830acad0
	if (cr0.lt) goto loc_830ACAD0;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r26,r24
	cr6.compare<uint32_t>(r26.u32, r24.u32, xer);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// blt cr6,0x830ac11c
	if (cr6.lt) goto loc_830AC11C;
loc_830AC580:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// li r28,0
	r28.s64 = 0;
	// lwz r22,12(r31)
	r22.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x830acad0
	if (cr6.eq) goto loc_830ACAD0;
	// lis r11,-32768
	r11.s64 = -2147483648;
	// lis r23,8208
	r23.s64 = 537919488;
	// lis r24,4192
	r24.s64 = 274726912;
	// ori r29,r11,16385
	r29.u64 = r11.u64 | 16385;
	// lis r25,20480
	r25.s64 = 1342177280;
	// lis r26,24880
	r26.s64 = 1630535680;
	// lis r27,28848
	r27.s64 = 1890582528;
loc_830AC5B4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r10,r28,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r28,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r28.u32);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830ac5e8
	if (cr6.eq) goto loc_830AC5E8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x830ac5e8
	if (!cr6.eq) goto loc_830AC5E8;
	// addi r11,r11,48
	r11.s64 = r11.s64 + 48;
	// stw r11,264(r31)
	PPC_STORE_U32(r31.u32 + 264, r11.u32);
loc_830AC5E8:
	// lwz r10,260(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830ac624
	if (cr0.eq) goto loc_830AC624;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830ac624
	if (cr6.eq) goto loc_830AC624;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x830acadc
	if (!cr6.eq) goto loc_830ACADC;
loc_830AC624:
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// bgt cr6,0x830ac8b8
	if (cr6.gt) goto loc_830AC8B8;
	// beq cr6,0x830ac978
	if (cr6.eq) goto loc_830AC978;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// bgt cr6,0x830ac7a8
	if (cr6.gt) goto loc_830AC7A8;
	// beq cr6,0x830aca74
	if (cr6.eq) goto loc_830ACA74;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bgt cr6,0x830ac708
	if (cr6.gt) goto loc_830AC708;
	// beq cr6,0x830ac6fc
	if (cr6.eq) goto loc_830AC6FC;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830aca80
	if (cr6.eq) goto loc_830ACA80;
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac6f0
	if (cr6.eq) goto loc_830AC6F0;
	// lis r10,4112
	ctx.r10.s64 = 269484032;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac6e4
	if (cr6.eq) goto loc_830AC6E4;
	// lis r10,4144
	ctx.r10.s64 = 271581184;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac6d8
	if (cr6.eq) goto loc_830AC6D8;
	// lis r10,4160
	ctx.r10.s64 = 272629760;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac6cc
	if (cr6.eq) goto loc_830AC6CC;
	// lis r10,4176
	ctx.r10.s64 = 273678336;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830aca98
	if (!cr6.eq) goto loc_830ACA98;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,140(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 140);
loc_830AC694:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x830aca7c
	goto loc_830ACA7C;
loc_830AC6A4:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830acad4
	goto loc_830ACAD4;
loc_830AC6B0:
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
	// b 0x830acad0
	goto loc_830ACAD0;
loc_830AC6BC:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_830AC6C0:
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x830acacc
	goto loc_830ACACC;
loc_830AC6CC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,136(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 136);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC6D8:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,132(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 132);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC6E4:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,128(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 128);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC6F0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,124(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 124);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC6FC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,144(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 144);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC708:
	// lis r10,4208
	ctx.r10.s64 = 275775488;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac79c
	if (cr6.eq) goto loc_830AC79C;
	// lis r10,4304
	ctx.r10.s64 = 282066944;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac77c
	if (cr6.eq) goto loc_830AC77C;
	// lis r10,4320
	ctx.r10.s64 = 283115520;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac764
	if (cr6.eq) goto loc_830AC764;
	// lis r10,4336
	ctx.r10.s64 = 284164096;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830aca5c
	if (cr6.eq) goto loc_830ACA5C;
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// beq cr6,0x830ac758
	if (cr6.eq) goto loc_830AC758;
	// lis r10,8192
	ctx.r10.s64 = 536870912;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830aca98
	if (!cr6.eq) goto loc_830ACA98;
loc_830AC74C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830aa270
	sub_830AA270(ctx, base);
	// b 0x830aca7c
	goto loc_830ACA7C;
loc_830AC758:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,220(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 220);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC764:
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// rlwinm. r11,r11,0,5,5
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830ac794
	if (cr0.eq) goto loc_830AC794;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,228(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 228);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC77C:
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// rlwinm. r11,r11,0,5,5
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830ac794
	if (cr0.eq) goto loc_830AC794;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,224(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 224);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC794:
	// mr r30,r29
	r30.u64 = r29.u64;
	// b 0x830aca80
	goto loc_830ACA80;
loc_830AC79C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,152(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 152);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC7A8:
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bgt cr6,0x830ac850
	if (cr6.gt) goto loc_830AC850;
	// beq cr6,0x830ac844
	if (cr6.eq) goto loc_830AC844;
	// lis r10,8224
	ctx.r10.s64 = 538968064;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac838
	if (cr6.eq) goto loc_830AC838;
	// lis r10,8240
	ctx.r10.s64 = 540016640;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac82c
	if (cr6.eq) goto loc_830AC82C;
	// lis r10,8256
	ctx.r10.s64 = 541065216;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac820
	if (cr6.eq) goto loc_830AC820;
	// lis r10,8272
	ctx.r10.s64 = 542113792;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac814
	if (cr6.eq) goto loc_830AC814;
	// lis r10,8304
	ctx.r10.s64 = 544210944;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac808
	if (cr6.eq) goto loc_830AC808;
	// lis r10,12288
	ctx.r10.s64 = 805306368;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830aca98
	if (!cr6.eq) goto loc_830ACA98;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,188(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 188);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC808:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,260(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 260);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC814:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,176(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 176);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC820:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,172(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 172);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC82C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830a9e40
	sub_830A9E40(ctx, base);
	// b 0x830aca7c
	goto loc_830ACA7C;
loc_830AC838:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830a9f78
	sub_830A9F78(ctx, base);
	// b 0x830aca7c
	goto loc_830ACA7C;
loc_830AC844:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,180(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 180);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC850:
	// lis r10,20528
	ctx.r10.s64 = 1345323008;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac8ac
	if (cr6.eq) goto loc_830AC8AC;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// beq cr6,0x830ac978
	if (cr6.eq) goto loc_830AC978;
	// lis r10,24592
	ctx.r10.s64 = 1611661312;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac914
	if (cr6.eq) goto loc_830AC914;
	// lis r10,24608
	ctx.r10.s64 = 1612709888;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac96c
	if (cr6.eq) goto loc_830AC96C;
	// lis r10,24624
	ctx.r10.s64 = 1613758464;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac960
	if (cr6.eq) goto loc_830AC960;
	// lis r10,24640
	ctx.r10.s64 = 1614807040;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830aca98
	if (!cr6.eq) goto loc_830ACA98;
loc_830AC894:
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// rlwinm. r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830acb04
	if (cr0.eq) goto loc_830ACB04;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,276(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 276);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC8AC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,232(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 232);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC8B8:
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bgt cr6,0x830ac984
	if (cr6.gt) goto loc_830AC984;
	// beq cr6,0x830ac894
	if (cr6.eq) goto loc_830AC894;
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// bgt cr6,0x830ac920
	if (cr6.gt) goto loc_830AC920;
	// beq cr6,0x830ac96c
	if (cr6.eq) goto loc_830AC96C;
	// lis r10,24672
	ctx.r10.s64 = 1616904192;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac914
	if (cr6.eq) goto loc_830AC914;
	// lis r10,24688
	ctx.r10.s64 = 1617952768;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac96c
	if (cr6.eq) goto loc_830AC96C;
	// cmplw cr6,r11,r14
	cr6.compare<uint32_t>(r11.u32, r14.u32, xer);
	// beq cr6,0x830ac960
	if (cr6.eq) goto loc_830AC960;
	// lis r10,24720
	ctx.r10.s64 = 1620049920;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac894
	if (cr6.eq) goto loc_830AC894;
	// lis r10,24736
	ctx.r10.s64 = 1621098496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac978
	if (cr6.eq) goto loc_830AC978;
	// lis r10,24752
	ctx.r10.s64 = 1622147072;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830aca98
	if (!cr6.eq) goto loc_830ACA98;
loc_830AC914:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,280(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 280);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC920:
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// beq cr6,0x830ac960
	if (cr6.eq) goto loc_830AC960;
	// lis r10,24800
	ctx.r10.s64 = 1625292800;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac894
	if (cr6.eq) goto loc_830AC894;
	// lis r10,24816
	ctx.r10.s64 = 1626341376;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac978
	if (cr6.eq) goto loc_830AC978;
	// lis r10,24832
	ctx.r10.s64 = 1627389952;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac914
	if (cr6.eq) goto loc_830AC914;
	// lis r10,24848
	ctx.r10.s64 = 1628438528;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac96c
	if (cr6.eq) goto loc_830AC96C;
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// bne cr6,0x830aca98
	if (!cr6.eq) goto loc_830ACA98;
loc_830AC960:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,272(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 272);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC96C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,268(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 268);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC978:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,264(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 264);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC984:
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bgt cr6,0x830aca14
	if (cr6.gt) goto loc_830ACA14;
	// beq cr6,0x830ac74c
	if (cr6.eq) goto loc_830AC74C;
	// lis r10,28672
	ctx.r10.s64 = 1879048192;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830aca08
	if (cr6.eq) goto loc_830ACA08;
	// lis r10,28688
	ctx.r10.s64 = 1880096768;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac9fc
	if (cr6.eq) goto loc_830AC9FC;
	// lis r10,28704
	ctx.r10.s64 = 1881145344;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac9f0
	if (cr6.eq) goto loc_830AC9F0;
	// lis r10,28720
	ctx.r10.s64 = 1882193920;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac9e4
	if (cr6.eq) goto loc_830AC9E4;
	// lis r10,28736
	ctx.r10.s64 = 1883242496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ac9e4
	if (cr6.eq) goto loc_830AC9E4;
	// lis r10,28800
	ctx.r10.s64 = 1887436800;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830aca98
	if (!cr6.eq) goto loc_830ACA98;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,284(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 284);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC9E4:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,208(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 208);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC9F0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,204(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 204);
	// b 0x830ac694
	goto loc_830AC694;
loc_830AC9FC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,200(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 200);
	// b 0x830ac694
	goto loc_830AC694;
loc_830ACA08:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,196(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 196);
	// b 0x830ac694
	goto loc_830AC694;
loc_830ACA14:
	// lis r10,28864
	ctx.r10.s64 = 1891631104;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830aca74
	if (cr6.eq) goto loc_830ACA74;
	// lis r10,28880
	ctx.r10.s64 = 1892679680;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830aca68
	if (cr6.eq) goto loc_830ACA68;
	// lis r10,29520
	ctx.r10.s64 = 1934622720;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830aca5c
	if (cr6.eq) goto loc_830ACA5C;
	// lis r10,29536
	ctx.r10.s64 = 1935671296;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830aca5c
	if (cr6.eq) goto loc_830ACA5C;
	// lis r10,29552
	ctx.r10.s64 = 1936719872;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830aca5c
	if (cr6.eq) goto loc_830ACA5C;
	// lis r10,29568
	ctx.r10.s64 = 1937768448;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830aca98
	if (!cr6.eq) goto loc_830ACA98;
loc_830ACA5C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,256(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 256);
	// b 0x830ac694
	goto loc_830AC694;
loc_830ACA68:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,148(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// b 0x830ac694
	goto loc_830AC694;
loc_830ACA74:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830aa0b0
	sub_830AA0B0(ctx, base);
loc_830ACA7C:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_830ACA80:
	// cmpw cr6,r30,r29
	cr6.compare<int32_t>(r30.s32, r29.s32, xer);
	// beq cr6,0x830aca9c
	if (cr6.eq) goto loc_830ACA9C;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplw cr6,r28,r22
	cr6.compare<uint32_t>(r28.u32, r22.u32, xer);
	// blt cr6,0x830ac5b4
	if (cr6.lt) goto loc_830AC5B4;
	// b 0x830acad0
	goto loc_830ACAD0;
loc_830ACA98:
	// mr r30,r29
	r30.u64 = r29.u64;
loc_830ACA9C:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r5,4532
	ctx.r5.s64 = 4532;
	// addi r6,r10,-22616
	ctx.r6.s64 = ctx.r10.s64 + -22616;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830ACAB8:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830acad0
	if (cr6.eq) goto loc_830ACAD0;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
loc_830ACACC:
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830ACAD0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_830ACAD4:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x82ca2c00
	return;
loc_830ACADC:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,4511
	ctx.r5.s64 = 4511;
	// addi r6,r10,24852
	ctx.r6.s64 = ctx.r10.s64 + 24852;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r30,-32768
	r30.s64 = -2147483648;
	// ori r30,r30,16389
	r30.u64 = r30.u64 | 16389;
	// b 0x830acad0
	goto loc_830ACAD0;
loc_830ACB04:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,4532
	ctx.r5.s64 = 4532;
	// addi r6,r10,24816
	ctx.r6.s64 = ctx.r10.s64 + 24816;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// mr r30,r29
	r30.u64 = r29.u64;
	// b 0x830acad0
	goto loc_830ACAD0;
}

__attribute__((alias("__imp__sub_830ACB28"))) PPC_WEAK_FUNC(sub_830ACB28);
PPC_FUNC_IMPL(__imp__sub_830ACB28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r6,4(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830acb90
	if (cr6.eq) goto loc_830ACB90;
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r8,136(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
loc_830ACB44:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r4
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r4.u32, xer);
	// bne cr6,0x830acb80
	if (!cr6.eq) goto loc_830ACB80;
	// lwz r11,80(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bge cr6,0x830acb80
	if (!cr6.lt) goto loc_830ACB80;
	// lwz r4,24(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r4
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830acb98
	if (!cr0.eq) goto loc_830ACB98;
loc_830ACB80:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// blt cr6,0x830acb44
	if (cr6.lt) goto loc_830ACB44;
loc_830ACB90:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_830ACB98:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830ACBA0"))) PPC_WEAK_FUNC(sub_830ACBA0);
PPC_FUNC_IMPL(__imp__sub_830ACBA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r21,r5
	r21.u64 = ctx.r5.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x830acbc8
	if (!cr6.eq) goto loc_830ACBC8;
loc_830ACBC0:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830acdc8
	goto loc_830ACDC8;
loc_830ACBC8:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830acdc4
	if (cr0.eq) goto loc_830ACDC4;
	// lis r9,8304
	ctx.r9.s64 = 544210944;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x830acdc4
	if (cr6.eq) goto loc_830ACDC4;
	// lwz r9,4(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// clrlwi r10,r11,12
	ctx.r10.u64 = r11.u32 & 0xFFFFF;
	// divwu r23,r9,r10
	r23.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplwi cr6,r23,1
	cr6.compare<uint32_t>(r23.u32, 1, xer);
	// ble cr6,0x830acdc4
	if (!cr6.gt) goto loc_830ACDC4;
	// lwz r11,128(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwz r8,136(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r6,124(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 124);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,148(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 148);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r1,80
	r30.s64 = ctx.r1.s64 + 80;
	// li r25,0
	r25.s64 = 0;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// stwx r25,r5,r9
	PPC_STORE_U32(ctx.r5.u32 + ctx.r9.u32, r25.u32);
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r25,r8,r4
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, r25.u32);
	// addi r26,r1,160
	r26.s64 = ctx.r1.s64 + 160;
	// stwx r25,r6,r30
	PPC_STORE_U32(ctx.r6.u32 + r30.u32, r25.u32);
	// li r11,1
	r11.s64 = 1;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// stwx r11,r5,r7
	PPC_STORE_U32(ctx.r5.u32 + ctx.r7.u32, r11.u32);
	// li r30,3
	r30.s64 = 3;
	// mr r22,r25
	r22.u64 = r25.u64;
	// stwx r30,r8,r3
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, r30.u32);
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// stwx r11,r6,r26
	PPC_STORE_U32(ctx.r6.u32 + r26.u32, r11.u32);
	// mr r29,r25
	r29.u64 = r25.u64;
	// stwx r25,r28,r9
	PPC_STORE_U32(r28.u32 + ctx.r9.u32, r25.u32);
	// stwx r11,r28,r4
	PPC_STORE_U32(r28.u32 + ctx.r4.u32, r11.u32);
	// beq cr6,0x830acdc4
	if (cr6.eq) goto loc_830ACDC4;
	// rlwinm r24,r10,2,0,29
	r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r28,r25
	r28.u64 = r25.u64;
loc_830ACC7C:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r26,r11,r9
	r26.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// rlwinm. r10,r11,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830accbc
	if (cr0.eq) goto loc_830ACCBC;
	// rlwinm. r9,r11,0,24,24
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830accbc
	if (!cr0.eq) goto loc_830ACCBC;
	// lwz r6,124(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 124);
	// b 0x830acd08
	goto loc_830ACD08;
loc_830ACCBC:
	// rlwinm. r9,r11,0,24,24
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830acccc
	if (cr0.eq) goto loc_830ACCCC;
	// lwz r6,148(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 148);
	// b 0x830acd08
	goto loc_830ACD08;
loc_830ACCCC:
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830acd04
	if (cr0.eq) goto loc_830ACD04;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830acd04
	if (!cr6.eq) goto loc_830ACD04;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,108(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r3,65535
	cr6.compare<uint32_t>(ctx.r3.u32, 65535, xer);
	// beq cr6,0x830acd04
	if (cr6.eq) goto loc_830ACD04;
	// lwz r6,128(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// b 0x830acd08
	goto loc_830ACD08;
loc_830ACD04:
	// lwz r6,136(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 136);
loc_830ACD08:
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830acd68
	if (cr6.eq) goto loc_830ACD68;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
loc_830ACD20:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r5,4(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r7,r5
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, xer);
	// bne cr6,0x830acd58
	if (!cr6.eq) goto loc_830ACD58;
	// lwz r5,8(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r4,8(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// bne cr6,0x830acd58
	if (!cr6.eq) goto loc_830ACD58;
	// lwz r5,12(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// beq cr6,0x830acd68
	if (cr6.eq) goto loc_830ACD68;
loc_830ACD58:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// add r11,r24,r11
	r11.u64 = r24.u64 + r11.u64;
	// cmplw cr6,r9,r29
	cr6.compare<uint32_t>(ctx.r9.u32, r29.u32, xer);
	// blt cr6,0x830acd20
	if (cr6.lt) goto loc_830ACD20;
loc_830ACD68:
	// cmplw cr6,r9,r29
	cr6.compare<uint32_t>(ctx.r9.u32, r29.u32, xer);
	// bne cr6,0x830acd9c
	if (!cr6.eq) goto loc_830ACD9C;
	// cmplwi cr6,r6,18
	cr6.compare<uint32_t>(ctx.r6.u32, 18, xer);
	// bge cr6,0x830acd9c
	if (!cr6.lt) goto loc_830ACD9C;
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// lwzx r10,r11,r9
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bgt cr6,0x830acdd0
	if (cr6.gt) goto loc_830ACDD0;
loc_830ACD9C:
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830acdb4
	if (cr0.eq) goto loc_830ACDB4;
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// cmplwi cr6,r22,2
	cr6.compare<uint32_t>(r22.u32, 2, xer);
	// bgt cr6,0x830acdd0
	if (cr6.gt) goto loc_830ACDD0;
loc_830ACDB4:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// add r28,r24,r28
	r28.u64 = r24.u64 + r28.u64;
	// cmplw cr6,r29,r23
	cr6.compare<uint32_t>(r29.u32, r23.u32, xer);
	// blt cr6,0x830acc7c
	if (cr6.lt) goto loc_830ACC7C;
loc_830ACDC4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830ACDC8:
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// b 0x82ca2c1c
	return;
loc_830ACDD0:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830acbc0
	if (cr6.eq) goto loc_830ACBC0;
	// stw r29,0(r21)
	PPC_STORE_U32(r21.u32 + 0, r29.u32);
	// b 0x830acbc0
	goto loc_830ACBC0;
}

__attribute__((alias("__imp__sub_830ACDE0"))) PPC_WEAK_FUNC(sub_830ACDE0);
PPC_FUNC_IMPL(__imp__sub_830ACDE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,24656
	r11.s64 = 1615855616;
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// beq cr6,0x830ace2c
	if (cr6.eq) goto loc_830ACE2C;
	// lis r11,24736
	r11.s64 = 1621098496;
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// beq cr6,0x830ace2c
	if (cr6.eq) goto loc_830ACE2C;
	// lis r11,24576
	r11.s64 = 1610612736;
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// beq cr6,0x830ace2c
	if (cr6.eq) goto loc_830ACE2C;
	// lis r11,29408
	r11.s64 = 1927282688;
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// beq cr6,0x830ace2c
	if (cr6.eq) goto loc_830ACE2C;
	// lis r11,24688
	r11.s64 = 1617952768;
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// beq cr6,0x830ace2c
	if (cr6.eq) goto loc_830ACE2C;
	// lis r11,24816
	r11.s64 = 1626341376;
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// bnelr cr6
	if (!cr6.eq) return;
loc_830ACE2C:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830ACE38"))) PPC_WEAK_FUNC(sub_830ACE38);
PPC_FUNC_IMPL(__imp__sub_830ACE38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8306ae98
	sub_8306AE98(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r30,0
	r30.s64 = 0;
	// addi r11,r11,28416
	r11.s64 = r11.s64 + 28416;
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r30,560(r31)
	PPC_STORE_U32(r31.u32 + 560, r30.u32);
	// addi r3,r31,712
	ctx.r3.s64 = r31.s64 + 712;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// li r5,64
	ctx.r5.s64 = 64;
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r10,1088(r31)
	PPC_STORE_U32(r31.u32 + 1088, ctx.r10.u32);
	// stw r30,1100(r31)
	PPC_STORE_U32(r31.u32 + 1100, r30.u32);
	// stw r30,696(r31)
	PPC_STORE_U32(r31.u32 + 696, r30.u32);
	// stw r30,700(r31)
	PPC_STORE_U32(r31.u32 + 700, r30.u32);
	// stw r30,708(r31)
	PPC_STORE_U32(r31.u32 + 708, r30.u32);
	// stw r30,704(r31)
	PPC_STORE_U32(r31.u32 + 704, r30.u32);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// stw r30,1032(r31)
	PPC_STORE_U32(r31.u32 + 1032, r30.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830ACEB8"))) PPC_WEAK_FUNC(sub_830ACEB8);
PPC_FUNC_IMPL(__imp__sub_830ACEB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// lwz r11,108(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 108);
	// li r7,2
	ctx.r7.s64 = 2;
	// lwz r10,200(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 200);
	// li r8,0
	ctx.r8.s64 = 0;
	// rlwinm r11,r11,0,7,5
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFDFFFFFF;
	// lwz r6,112(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	// lwz r5,204(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 204);
	// li r9,8
	ctx.r9.s64 = 8;
	// rlwinm r11,r11,0,2,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r7,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r7.u32);
	// li r4,24
	ctx.r4.s64 = 24;
	// stw r8,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, ctx.r8.u32);
	// oris r11,r11,10394
	r11.u64 = r11.u64 | 681181184;
	// stw r10,268(r3)
	PPC_STORE_U32(ctx.r3.u32 + 268, ctx.r10.u32);
	// li r31,1
	r31.s64 = 1;
	// stw r4,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, ctx.r4.u32);
	// li r30,64
	r30.s64 = 64;
	// stw r9,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, ctx.r9.u32);
	// ori r11,r11,18228
	r11.u64 = r11.u64 | 18228;
	// stw r31,72(r3)
	PPC_STORE_U32(ctx.r3.u32 + 72, r31.u32);
	// oris r6,r6,2048
	ctx.r6.u64 = ctx.r6.u64 | 134217728;
	// stw r30,100(r3)
	PPC_STORE_U32(ctx.r3.u32 + 100, r30.u32);
	// ori r5,r5,256
	ctx.r5.u64 = ctx.r5.u64 | 256;
	// stw r11,108(r3)
	PPC_STORE_U32(ctx.r3.u32 + 108, r11.u32);
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// stw r6,112(r3)
	PPC_STORE_U32(ctx.r3.u32 + 112, ctx.r6.u32);
	// stw r5,204(r3)
	PPC_STORE_U32(ctx.r3.u32 + 204, ctx.r5.u32);
	// cmplwi cr6,r10,260
	cr6.compare<uint32_t>(ctx.r10.u32, 260, xer);
	// bne cr6,0x830acf64
	if (!cr6.eq) goto loc_830ACF64;
	// lis r12,-4609
	r12.s64 = -302055424;
	// stw r9,68(r3)
	PPC_STORE_U32(ctx.r3.u32 + 68, ctx.r9.u32);
	// stw r8,80(r3)
	PPC_STORE_U32(ctx.r3.u32 + 80, ctx.r8.u32);
	// ori r12,r12,51071
	r12.u64 = r12.u64 | 51071;
	// and r10,r11,r12
	ctx.r10.u64 = r11.u64 & r12.u64;
	// li r11,6
	r11.s64 = 6;
	// oris r10,r10,1029
	ctx.r10.u64 = ctx.r10.u64 | 67436544;
	// stw r11,60(r3)
	PPC_STORE_U32(ctx.r3.u32 + 60, r11.u32);
	// ori r10,r10,32768
	ctx.r10.u64 = ctx.r10.u64 | 32768;
	// stw r11,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, r11.u32);
	// stw r10,108(r3)
	PPC_STORE_U32(ctx.r3.u32 + 108, ctx.r10.u32);
	// b 0x830acfa0
	goto loc_830ACFA0;
loc_830ACF64:
	// addi r9,r10,-257
	ctx.r9.s64 = ctx.r10.s64 + -257;
	// stw r7,80(r3)
	PPC_STORE_U32(ctx.r3.u32 + 80, ctx.r7.u32);
	// li r10,4
	ctx.r10.s64 = 4;
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// li r8,6
	ctx.r8.s64 = 6;
	// stw r10,60(r3)
	PPC_STORE_U32(ctx.r3.u32 + 60, ctx.r10.u32);
	// rlwinm r9,r9,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// stw r10,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, ctx.r10.u32);
	// stw r8,68(r3)
	PPC_STORE_U32(ctx.r3.u32 + 68, ctx.r8.u32);
	// rlwimi r11,r9,13,18,18
	r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 13) & 0x2000) | (r11.u64 & 0xFFFFFFFFFFFFDFFF);
	// rlwinm r11,r11,0,17,14
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFE7FFF;
	// rlwinm r11,r11,0,14,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFBFFFF;
	// oris r11,r11,5120
	r11.u64 = r11.u64 | 335544320;
	// ori r11,r11,6274
	r11.u64 = r11.u64 | 6274;
	// stw r11,108(r3)
	PPC_STORE_U32(ctx.r3.u32 + 108, r11.u32);
loc_830ACFA0:
	// li r3,0
	ctx.r3.s64 = 0;
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830ACFB0"))) PPC_WEAK_FUNC(sub_830ACFB0);
PPC_FUNC_IMPL(__imp__sub_830ACFB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,76(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 76);
	// lwz r29,552(r3)
	r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 552);
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bge cr6,0x830ad0b8
	if (!cr6.lt) goto loc_830AD0B8;
	// lwz r11,564(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 564);
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// add r30,r11,r10
	r30.u64 = r11.u64 + ctx.r10.u64;
loc_830ACFD8:
	// lwz r6,0(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830ad08c
	if (cr6.eq) goto loc_830AD08C;
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830ad08c
	if (cr6.eq) goto loc_830AD08C;
	// lwz r10,16(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// lwz r7,20(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r9,132(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830ad024
	if (!cr6.eq) goto loc_830AD024;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ad08c
	if (cr6.eq) goto loc_830AD08C;
loc_830AD024:
	// lwz r4,4(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830ad08c
	if (cr6.eq) goto loc_830AD08C;
	// lwz r9,8(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
loc_830AD038:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r8,60(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// b 0x830ad054
	goto loc_830AD054;
loc_830AD04C:
	// rlwinm r11,r10,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
loc_830AD054:
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x830ad04c
	if (!cr6.eq) goto loc_830AD04C;
	// lbz r10,111(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 111);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x830ad07c
	if (!cr6.eq) goto loc_830AD07C;
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// or r11,r11,r8
	r11.u64 = r11.u64 | ctx.r8.u64;
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830ad0a0
	if (cr0.eq) goto loc_830AD0A0;
loc_830AD07C:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// blt cr6,0x830ad038
	if (cr6.lt) goto loc_830AD038;
loc_830AD08C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// blt cr6,0x830acfd8
	if (cr6.lt) goto loc_830ACFD8;
	// b 0x830ad0b8
	goto loc_830AD0B8;
loc_830AD0A0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,60(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + 60);
	// li r5,4707
	ctx.r5.s64 = 4707;
	// lbz r7,203(r3)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r3.u32 + 203);
	// addi r6,r11,28800
	ctx.r6.s64 = r11.s64 + 28800;
	// bl 0x8308bee8
	sub_8308BEE8(ctx, base);
loc_830AD0B8:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830AD0C8"))) PPC_WEAK_FUNC(sub_830AD0C8);
PPC_FUNC_IMPL(__imp__sub_830AD0C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2bec
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830ad100
	if (!cr6.eq) goto loc_830AD100;
loc_830AD0F8:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830ad2a4
	goto loc_830AD2A4;
loc_830AD100:
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r6,4096
	ctx.r6.s64 = 268435456;
	// lwzx r5,r11,r9
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm r7,r11,0,0,11
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// beq cr6,0x830ad12c
	if (cr6.eq) goto loc_830AD12C;
	// lis r11,20480
	r11.s64 = 1342177280;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// bne cr6,0x830ad0f8
	if (!cr6.eq) goto loc_830AD0F8;
loc_830AD12C:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r30,-1
	r30.s64 = -1;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,24(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,72(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830ad1a8
	if (cr6.eq) goto loc_830AD1A8;
	// lwz r10,60(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830ad1a8
	if (!cr6.eq) goto loc_830AD1A8;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r9
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// bne cr6,0x830ad1a8
	if (!cr6.eq) goto loc_830AD1A8;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830ad1a8
	if (cr6.eq) goto loc_830AD1A8;
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// li r11,0
	r11.s64 = 0;
loc_830AD188:
	// lwzx r29,r11,r8
	r29.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmplw cr6,r29,r4
	cr6.compare<uint32_t>(r29.u32, ctx.r4.u32, xer);
	// bne cr6,0x830ad19c
	if (!cr6.eq) goto loc_830AD19C;
	// lwz r30,8(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwzx r30,r30,r11
	r30.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
loc_830AD19C:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830ad188
	if (!cr0.eq) goto loc_830AD188;
loc_830AD1A8:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// bne cr6,0x830ad220
	if (!cr6.eq) goto loc_830AD220;
	// lwz r10,4(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830ad0f8
	if (cr6.eq) goto loc_830AD0F8;
	// lwz r8,8(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// li r11,0
	r11.s64 = 0;
loc_830AD1CC:
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmplw cr6,r9,r4
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r4.u32, xer);
	// bne cr6,0x830ad1f0
	if (!cr6.eq) goto loc_830AD1F0;
	// lwz r7,16(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// lwz r29,28(r3)
	r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// lwzx r7,r7,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// cmplw cr6,r7,r29
	cr6.compare<uint32_t>(ctx.r7.u32, r29.u32, xer);
	// bne cr6,0x830ad1f0
	if (!cr6.eq) goto loc_830AD1F0;
	// li r6,1
	ctx.r6.s64 = 1;
loc_830AD1F0:
	// cmplw cr6,r9,r30
	cr6.compare<uint32_t>(ctx.r9.u32, r30.u32, xer);
	// bne cr6,0x830ad210
	if (!cr6.eq) goto loc_830AD210;
	// lwz r9,16(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// lwz r7,28(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// bne cr6,0x830ad210
	if (!cr6.eq) goto loc_830AD210;
	// li r6,1
	ctx.r6.s64 = 1;
loc_830AD210:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830ad1cc
	if (!cr0.eq) goto loc_830AD1CC;
	// b 0x830ad24c
	goto loc_830AD24C;
loc_830AD220:
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830ad0f8
	if (cr6.eq) goto loc_830AD0F8;
	// lwz r10,16(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
loc_830AD230:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r30,r9
	cr6.compare<uint32_t>(r30.u32, ctx.r9.u32, xer);
	// bne cr6,0x830ad240
	if (!cr6.eq) goto loc_830AD240;
	// li r6,1
	ctx.r6.s64 = 1;
loc_830AD240:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830ad230
	if (!cr0.eq) goto loc_830AD230;
loc_830AD24C:
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq cr6,0x830ad0f8
	if (cr6.eq) goto loc_830AD0F8;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lis r10,29408
	ctx.r10.s64 = 1927282688;
	// li r9,6
	ctx.r9.s64 = 6;
	// ori r10,r10,3
	ctx.r10.u64 = ctx.r10.u64 | 3;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
loc_830AD2A4:
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830AD2A8"))) PPC_WEAK_FUNC(sub_830AD2A8);
PPC_FUNC_IMPL(__imp__sub_830AD2A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r24,260(r29)
	r24.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x830ad57c
	if (!cr6.eq) goto loc_830AD57C;
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x830ad57c
	if (!cr6.eq) goto loc_830AD57C;
	// lwz r7,8(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rotlwi r11,r24,0
	r11.u64 = __builtin_rotateleft32(r24.u32, 0);
	// lwz r25,20(r29)
	r25.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r26,12(r7)
	r26.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r9,r26,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r25
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r25.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_830AD2FC:
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r6,r9
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r9.u32, xer);
	// beq cr6,0x830ad46c
	if (cr6.eq) goto loc_830AD46C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// blt cr6,0x830ad2fc
	if (cr6.lt) goto loc_830AD2FC;
	// lwz r27,72(r8)
	r27.u64 = PPC_LOAD_U32(ctx.r8.u32 + 72);
	// li r23,-1
	r23.s64 = -1;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// cmpwi cr6,r27,-1
	cr6.compare<int32_t>(r27.s32, -1, xer);
	// beq cr6,0x830ad380
	if (cr6.eq) goto loc_830AD380;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// rlwinm r10,r27,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x830ad380
	if (!cr6.eq) goto loc_830AD380;
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830ad380
	if (cr6.eq) goto loc_830AD380;
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// li r11,0
	r11.s64 = 0;
loc_830AD360:
	// lwzx r5,r11,r8
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmplw cr6,r26,r5
	cr6.compare<uint32_t>(r26.u32, ctx.r5.u32, xer);
	// bne cr6,0x830ad374
	if (!cr6.eq) goto loc_830AD374;
	// lwz r6,8(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwzx r6,r6,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
loc_830AD374:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830ad360
	if (!cr0.eq) goto loc_830AD360;
loc_830AD380:
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r11,r7
	r11.u64 = ctx.r7.u64;
loc_830AD388:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// beq cr6,0x830ad46c
	if (cr6.eq) goto loc_830AD46C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// blt cr6,0x830ad388
	if (cr6.lt) goto loc_830AD388;
	// li r28,0
	r28.s64 = 0;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
loc_830AD3AC:
	// lwz r31,0(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r25
	r11.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830ad520
	if (cr6.eq) goto loc_830AD520;
	// lwz r10,24(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r27,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r7,r9,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// xor r9,r11,r10
	ctx.r9.u64 = r11.u64 ^ ctx.r10.u64;
	// rlwinm. r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830ad520
	if (!cr0.eq) goto loc_830AD520;
	// clrlwi. r5,r11,12
	ctx.r5.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// clrlwi r4,r10,12
	ctx.r4.u64 = ctx.r10.u32 & 0xFFFFF;
	// beq 0x830ad520
	if (cr0.eq) goto loc_830AD520;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830ad520
	if (cr6.eq) goto loc_830AD520;
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// twllei r5,0
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// twllei r4,0
	// divwu r3,r11,r5
	ctx.r3.u32 = r11.u32 / ctx.r5.u32;
	// divwu r11,r10,r4
	r11.u32 = ctx.r10.u32 / ctx.r4.u32;
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// bne cr6,0x830ad520
	if (!cr6.eq) goto loc_830AD520;
	// lwz r11,12(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// bne cr6,0x830ad520
	if (!cr6.eq) goto loc_830AD520;
	// lwz r9,12(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplw cr6,r4,r9
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r9.u32, xer);
	// bne cr6,0x830ad520
	if (!cr6.eq) goto loc_830AD520;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830ad484
	if (cr6.eq) goto loc_830AD484;
	// lwz r10,16(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
loc_830AD44C:
	// lwz r22,0(r10)
	r22.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r22,r31
	cr6.compare<uint32_t>(r22.u32, r31.u32, xer);
	// beq cr6,0x830ad480
	if (cr6.eq) goto loc_830AD480;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x830ad44c
	if (cr6.lt) goto loc_830AD44C;
	// b 0x830ad484
	goto loc_830AD484;
loc_830AD46C:
	// lis r11,4352
	r11.s64 = 285212672;
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r11,r11,3
	r11.u64 = r11.u64 | 3;
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
	// b 0x830ad59c
	goto loc_830AD59C;
loc_830AD480:
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
loc_830AD484:
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830ad520
	if (cr6.eq) goto loc_830AD520;
	// lwz r10,16(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
loc_830AD494:
	// lwz r31,0(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r31,r26
	cr6.compare<uint32_t>(r31.u32, r26.u32, xer);
	// beq cr6,0x830ad4b4
	if (cr6.eq) goto loc_830AD4B4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x830ad494
	if (cr6.lt) goto loc_830AD494;
	// b 0x830ad520
	goto loc_830AD520;
loc_830AD4B4:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830ad520
	if (cr6.eq) goto loc_830AD520;
	// cmpwi cr6,r6,-1
	cr6.compare<int32_t>(ctx.r6.s32, -1, xer);
	// beq cr6,0x830ad520
	if (cr6.eq) goto loc_830AD520;
	// li r31,1
	r31.s64 = 1;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830ad550
	if (cr6.eq) goto loc_830AD550;
	// lwz r10,8(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,8(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// add r10,r11,r8
	ctx.r10.u64 = r11.u64 + ctx.r8.u64;
	// rlwinm r7,r5,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r6,r4,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_830AD4F4:
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r8,r5
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r5.u32, xer);
	// beq cr6,0x830ad508
	if (cr6.eq) goto loc_830AD508;
	// li r31,0
	r31.s64 = 0;
loc_830AD508:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r6,r10
	ctx.r10.u64 = ctx.r6.u64 + ctx.r10.u64;
	// add r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 + ctx.r9.u64;
	// bne 0x830ad4f4
	if (!cr0.eq) goto loc_830AD4F4;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x830ad550
	if (!cr6.eq) goto loc_830AD550;
loc_830AD520:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r28,3
	cr6.compare<uint32_t>(r28.u32, 3, xer);
	// blt cr6,0x830ad3ac
	if (cr6.lt) goto loc_830AD3AC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lbz r7,203(r29)
	ctx.r7.u64 = PPC_LOAD_U8(r29.u32 + 203);
	// li r5,4544
	ctx.r5.s64 = 4544;
	// lwz r4,60(r24)
	ctx.r4.u64 = PPC_LOAD_U32(r24.u32 + 60);
	// addi r6,r11,28972
	ctx.r6.s64 = r11.s64 + 28972;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// b 0x830ad594
	goto loc_830AD594;
loc_830AD550:
	// lwz r10,260(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// lis r9,4352
	ctx.r9.s64 = 285212672;
	// li r11,3
	r11.s64 = 3;
	// ori r9,r9,3
	ctx.r9.u64 = ctx.r9.u64 | 3;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,260(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// lwz r10,260(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r11.u32);
	// b 0x830ad59c
	goto loc_830AD59C;
loc_830AD57C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,60(r24)
	ctx.r4.u64 = PPC_LOAD_U32(r24.u32 + 60);
	// li r5,4820
	ctx.r5.s64 = 4820;
	// addi r6,r11,28932
	ctx.r6.s64 = r11.s64 + 28932;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830AD594:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_830AD59C:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
}

__attribute__((alias("__imp__sub_830AD5A8"))) PPC_WEAK_FUNC(sub_830AD5A8);
PPC_FUNC_IMPL(__imp__sub_830AD5A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r11,1
	r11.s64 = 1;
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// li r8,3
	ctx.r8.s64 = 3;
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// lwz r4,260(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// stw r9,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r9.u32);
	// stw r8,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r8.u32);
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// beq cr6,0x830ad5fc
	if (cr6.eq) goto loc_830AD5FC;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830ad64c
	goto loc_830AD64C;
loc_830AD5FC:
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r10,3
	ctx.r10.s64 = 3;
	// addi r5,r9,28352
	ctx.r5.s64 = ctx.r9.s64 + 28352;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,288
	ctx.r6.s64 = ctx.r1.s64 + 288;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83060f70
	sub_83060F70(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830ad64c
	if (!cr0.eq) goto loc_830AD64C;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r9,132(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r8,136(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
loc_830AD64C:
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830AD660"))) PPC_WEAK_FUNC(sub_830AD660);
PPC_FUNC_IMPL(__imp__sub_830AD660) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2bec
	// lwz r11,260(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 260);
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830ad7bc
	if (!cr6.eq) goto loc_830AD7BC;
	// lhz r11,202(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// bge cr6,0x830ad7bc
	if (!cr6.lt) goto loc_830AD7BC;
	// lwz r11,260(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 260);
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r10,r11,12
	ctx.r10.u64 = r11.u32 & 0xFFFFF;
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r8,0(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r8,60(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x830ad7bc
	if (!cr6.eq) goto loc_830AD7BC;
	// lwz r8,60(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// rlwinm. r8,r8,0,22,22
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x830ad7bc
	if (cr0.eq) goto loc_830AD7BC;
	// lbz r11,111(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 111);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830ad7bc
	if (!cr6.eq) goto loc_830AD7BC;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lwz r9,136(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x830ad7bc
	if (!cr6.eq) goto loc_830AD7BC;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830ad7b0
	if (cr6.eq) goto loc_830AD7B0;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r31,r10
	r31.u64 = ctx.r10.u64;
loc_830AD700:
	// lwz r11,260(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 260);
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,60(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// ori r10,r10,512
	ctx.r10.u64 = ctx.r10.u64 | 512;
	// stw r10,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r10.u32);
	// lwz r4,256(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 256);
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// bge cr6,0x830ad7a4
	if (!cr6.lt) goto loc_830AD7A4;
	// rlwinm r5,r4,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
loc_830AD738:
	// lwz r11,24(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwzx r8,r5,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830ad790
	if (!cr6.gt) goto loc_830AD790;
	// li r11,0
	r11.s64 = 0;
loc_830AD754:
	// lwz r10,260(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 260);
	// lwz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwz r30,16(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwzx r29,r9,r11
	r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r30,r30,r7
	r30.u64 = PPC_LOAD_U32(r30.u32 + ctx.r7.u32);
	// cmplw cr6,r29,r30
	cr6.compare<uint32_t>(r29.u32, r30.u32, xer);
	// bne cr6,0x830ad77c
	if (!cr6.eq) goto loc_830AD77C;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// stwx r10,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r10.u32);
loc_830AD77C:
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// blt cr6,0x830ad754
	if (cr6.lt) goto loc_830AD754;
loc_830AD790:
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x830ad738
	if (cr6.lt) goto loc_830AD738;
loc_830AD7A4:
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x830ad700
	if (!cr0.eq) goto loc_830AD700;
loc_830AD7B0:
	// lwz r11,260(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 260);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_830AD7BC:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830AD7C8"))) PPC_WEAK_FUNC(sub_830AD7C8);
PPC_FUNC_IMPL(__imp__sub_830AD7C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lis r10,4112
	ctx.r10.s64 = 269484032;
	// lwz r11,260(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ad7f8
	if (cr6.eq) goto loc_830AD7F8;
loc_830AD7F0:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830ada20
	goto loc_830ADA20;
loc_830AD7F8:
	// lwz r10,260(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r8,20(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwz r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r7,8(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// clrlwi r27,r10,12
	r27.u64 = ctx.r10.u32 & 0xFFFFF;
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830ad83c
	if (cr0.eq) goto loc_830AD83C;
	// li r6,1
	ctx.r6.s64 = 1;
loc_830AD83C:
	// lwz r10,108(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 108);
	// rlwinm. r10,r10,0,18,18
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830ad8a4
	if (cr0.eq) goto loc_830AD8A4;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830ad8a4
	if (cr6.eq) goto loc_830AD8A4;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
loc_830AD858:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r10,60(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// rlwinm. r10,r10,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830ad874
	if (cr0.eq) goto loc_830AD874;
	// li r6,1
	ctx.r6.s64 = 1;
loc_830AD874:
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830ad888
	if (cr6.eq) goto loc_830AD888;
	// rlwinm r11,r10,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
loc_830AD888:
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830ad898
	if (cr0.eq) goto loc_830AD898;
	// li r6,1
	ctx.r6.s64 = 1;
loc_830AD898:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830ad858
	if (!cr0.eq) goto loc_830AD858;
loc_830AD8A4:
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq cr6,0x830ad7f0
	if (cr6.eq) goto loc_830AD7F0;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830ad8c8
	if (cr0.eq) goto loc_830AD8C8;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830ad8cc
	goto loc_830AD8CC;
loc_830AD8C8:
	// li r31,0
	r31.s64 = 0;
loc_830AD8CC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x830ad8e0
	if (!cr6.eq) goto loc_830AD8E0;
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
	// b 0x830ada1c
	goto loc_830ADA1C;
loc_830AD8E0:
	// li r11,517
	r11.s64 = 517;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,20,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// rlwinm r5,r27,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830ada04
	if (cr0.lt) goto loc_830ADA04;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,260(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830ada04
	if (cr0.lt) goto loc_830ADA04;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r11,936
	ctx.r4.s64 = r11.s64 + 936;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,785
	ctx.r5.s64 = 785;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8307a8d8
	sub_8307A8D8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x830ad968
	if (cr6.eq) goto loc_830AD968;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lfd f1,3240(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 3240);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cmpwi cr6,r28,-1
	cr6.compare<int32_t>(r28.s32, -1, xer);
	// bne cr6,0x830ad974
	if (!cr6.eq) goto loc_830AD974;
loc_830AD968:
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
	// b 0x830ada04
	goto loc_830ADA04;
loc_830AD974:
	// lwz r11,260(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// rlwinm r30,r27,2,0,29
	r30.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,260(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830ad9c4
	if (cr6.eq) goto loc_830AD9C4;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_830AD9B0:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stwx r28,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, r28.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830ad9b0
	if (!cr0.eq) goto loc_830AD9B0;
loc_830AD9C4:
	// lwz r11,256(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 256);
	// lwz r10,24(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830ad9ec
	if (cr6.eq) goto loc_830AD9EC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830AD9EC:
	// lwz r11,256(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 256);
	// li r30,0
	r30.s64 = 0;
	// lwz r10,24(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r31,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r31.u32);
	// li r31,0
	r31.s64 = 0;
loc_830ADA04:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830ada1c
	if (cr6.eq) goto loc_830ADA1C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830ADA1C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_830ADA20:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830ADA28"))) PPC_WEAK_FUNC(sub_830ADA28);
PPC_FUNC_IMPL(__imp__sub_830ADA28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2bd4
	// lwz r6,552(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 552);
	// lwz r25,564(r3)
	r25.u64 = PPC_LOAD_U32(ctx.r3.u32 + 564);
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r25
	r11.u64 = r11.u64 + r25.u64;
	// lwz r26,-4(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830add2c
	if (cr6.eq) goto loc_830ADD2C;
	// lis r11,4096
	r11.s64 = 268435456;
	// lwz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830add2c
	if (!cr6.eq) goto loc_830ADD2C;
	// li r24,0
	r24.s64 = 0;
	// lwz r8,16(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwz r7,132(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r11,r24
	r11.u64 = r24.u64;
loc_830ADA74:
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r5,4(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r5,r7
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r7.u32, xer);
	// bne cr6,0x830add2c
	if (!cr6.eq) goto loc_830ADD2C;
	// lwz r9,60(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x830add2c
	if (!cr6.eq) goto loc_830ADD2C;
	// lwz r9,8(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r9,60(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// rlwinm. r9,r9,0,11,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1F0000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830add2c
	if (!cr0.eq) goto loc_830ADD2C;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830ada74
	if (cr6.lt) goto loc_830ADA74;
	// lhz r27,202(r3)
	r27.u64 = PPC_LOAD_U16(ctx.r3.u32 + 202);
	// li r29,1
	r29.s64 = 1;
	// lwz r30,8(r26)
	r30.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// mr r28,r24
	r28.u64 = r24.u64;
	// addi r31,r6,-1
	r31.s64 = ctx.r6.s64 + -1;
loc_830ADAD4:
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830adb48
	if (cr6.eq) goto loc_830ADB48;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
loc_830ADAE8:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830adb38
	if (cr6.eq) goto loc_830ADB38;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830adb38
	if (cr6.eq) goto loc_830ADB38;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830adb30
	if (cr6.eq) goto loc_830ADB30;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_830ADB14:
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r5,r9
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r9.u32, xer);
	// bne cr6,0x830adb24
	if (!cr6.eq) goto loc_830ADB24;
	// li r6,1
	ctx.r6.s64 = 1;
loc_830ADB24:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830adb14
	if (!cr0.eq) goto loc_830ADB14;
loc_830ADB30:
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne cr6,0x830adb48
	if (!cr6.eq) goto loc_830ADB48;
loc_830ADB38:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r8,r31
	cr6.compare<uint32_t>(ctx.r8.u32, r31.u32, xer);
	// blt cr6,0x830adae8
	if (cr6.lt) goto loc_830ADAE8;
loc_830ADB48:
	// lwz r11,76(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 76);
	// cmplwi cr6,r27,260
	cr6.compare<uint32_t>(r27.u32, 260, xer);
	// bne cr6,0x830adb68
	if (!cr6.eq) goto loc_830ADB68;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// bge cr6,0x830adb74
	if (!cr6.lt) goto loc_830ADB74;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830adb74
	if (cr6.eq) goto loc_830ADB74;
	// b 0x830adb70
	goto loc_830ADB70;
loc_830ADB68:
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// bge cr6,0x830adb74
	if (!cr6.lt) goto loc_830ADB74;
loc_830ADB70:
	// mr r29,r24
	r29.u64 = r24.u64;
loc_830ADB74:
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq cr6,0x830add2c
	if (cr6.eq) goto loc_830ADD2C;
	// addi r11,r8,1
	r11.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bge cr6,0x830adc6c
	if (!cr6.lt) goto loc_830ADC6C;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r4,r11,r31
	ctx.r4.s64 = r31.s64 - r11.s64;
	// add r5,r10,r25
	ctx.r5.u64 = ctx.r10.u64 + r25.u64;
loc_830ADB94:
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830adc60
	if (cr6.eq) goto loc_830ADC60;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830adc60
	if (cr6.eq) goto loc_830ADC60;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830adc08
	if (cr6.eq) goto loc_830ADC08;
	// lwz r7,20(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// lwz r6,136(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_830ADBC8:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r23,4(r10)
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r23,r6
	cr6.compare<uint32_t>(r23.u32, ctx.r6.u32, xer);
	// bne cr6,0x830adbfc
	if (!cr6.eq) goto loc_830ADBFC;
	// lwz r23,16(r10)
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplw cr6,r23,r28
	cr6.compare<uint32_t>(r23.u32, r28.u32, xer);
	// bne cr6,0x830adbfc
	if (!cr6.eq) goto loc_830ADBFC;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830adbfc
	if (!cr6.eq) goto loc_830ADBFC;
	// mr r29,r24
	r29.u64 = r24.u64;
loc_830ADBFC:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830adbc8
	if (!cr0.eq) goto loc_830ADBC8;
loc_830ADC08:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830adc60
	if (cr6.eq) goto loc_830ADC60;
	// lwz r8,20(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r7,136(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_830ADC20:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// bne cr6,0x830adc54
	if (!cr6.eq) goto loc_830ADC54;
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r6,r28
	cr6.compare<uint32_t>(ctx.r6.u32, r28.u32, xer);
	// bne cr6,0x830adc54
	if (!cr6.eq) goto loc_830ADC54;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830adc54
	if (!cr6.eq) goto loc_830ADC54;
	// mr r29,r24
	r29.u64 = r24.u64;
loc_830ADC54:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830adc20
	if (!cr0.eq) goto loc_830ADC20;
loc_830ADC60:
	// addic. r4,r4,-1
	xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// bne 0x830adb94
	if (!cr0.eq) goto loc_830ADB94;
loc_830ADC6C:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// blt cr6,0x830adad4
	if (cr6.lt) goto loc_830ADAD4;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x830add2c
	if (cr6.eq) goto loc_830ADD2C;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
loc_830ADC88:
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830add1c
	if (cr6.eq) goto loc_830ADD1C;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
loc_830ADC98:
	// lwz r11,564(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 564);
	// lwzx r10,r7,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830add04
	if (cr6.eq) goto loc_830ADD04;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830add04
	if (cr6.eq) goto loc_830ADD04;
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830add04
	if (!cr6.gt) goto loc_830ADD04;
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
loc_830ADCC8:
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r4,8(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r4,r5,r4
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// bne cr6,0x830adcf0
	if (!cr6.eq) goto loc_830ADCF0;
	// lwz r4,20(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r4
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// stw r24,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r24.u32);
loc_830ADCF0:
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x830adcc8
	if (cr6.lt) goto loc_830ADCC8;
loc_830ADD04:
	// lwz r11,552(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 552);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// addi r31,r11,-1
	r31.s64 = r11.s64 + -1;
	// cmplw cr6,r6,r31
	cr6.compare<uint32_t>(ctx.r6.u32, r31.u32, xer);
	// blt cr6,0x830adc98
	if (cr6.lt) goto loc_830ADC98;
loc_830ADD1C:
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// cmplwi cr6,r5,16
	cr6.compare<uint32_t>(ctx.r5.u32, 16, xer);
	// blt cr6,0x830adc88
	if (cr6.lt) goto loc_830ADC88;
	// stw r24,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r24.u32);
loc_830ADD2C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82ca2c24
	return;
}

__attribute__((alias("__imp__sub_830ADD38"))) PPC_WEAK_FUNC(sub_830ADD38);
PPC_FUNC_IMPL(__imp__sub_830ADD38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r24,0
	r24.s64 = 0;
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830adf18
	if (!cr6.gt) goto loc_830ADF18;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r25,0
	r25.s64 = 0;
	// lfd f31,3376(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830ADD68:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r10,r25,r11
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830adf04
	if (cr6.eq) goto loc_830ADF04;
	// rotlwi r9,r10,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lis r8,29200
	ctx.r8.s64 = 1913651200;
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r10,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x830adf04
	if (cr6.eq) goto loc_830ADF04;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830adf04
	if (cr6.eq) goto loc_830ADF04;
	// lis r8,4352
	ctx.r8.s64 = 285212672;
	// clrlwi r26,r10,12
	r26.u64 = ctx.r10.u32 & 0xFFFFF;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// li r11,0
	r11.s64 = 0;
	// beq cr6,0x830addb0
	if (cr6.eq) goto loc_830ADDB0;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_830ADDB0:
	// rlwinm r29,r11,2,0,29
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r10,r10,r29
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r29.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830adf04
	if (cr0.eq) goto loc_830ADF04;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830ade00
	if (cr0.eq) goto loc_830ADE00;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x830ade04
	goto loc_830ADE04;
loc_830ADE00:
	// li r28,0
	r28.s64 = 0;
loc_830ADE04:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830adf28
	if (cr6.eq) goto loc_830ADF28;
	// li r11,1
	r11.s64 = 1;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// blt 0x830adf34
	if (cr0.lt) goto loc_830ADF34;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r4,r25,r11
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830adf48
	if (cr0.lt) goto loc_830ADF48;
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830adecc
	if (cr6.eq) goto loc_830ADECC;
	// li r30,0
	r30.s64 = 0;
loc_830ADE5C:
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r9,r3,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// cmplw cr6,r27,r26
	cr6.compare<uint32_t>(r27.u32, r26.u32, xer);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stw r10,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r10.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// stwx r3,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, ctx.r3.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// stwx r11,r10,r30
	PPC_STORE_U32(ctx.r10.u32 + r30.u32, r11.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stwx r3,r11,r29
	PPC_STORE_U32(r11.u32 + r29.u32, ctx.r3.u32);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// blt cr6,0x830ade5c
	if (cr6.lt) goto loc_830ADE5C;
loc_830ADECC:
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830adf64
	if (!cr6.lt) goto loc_830ADF64;
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stwx r28,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r28.u32);
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r11.u32);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830adf48
	if (cr0.lt) goto loc_830ADF48;
loc_830ADF04:
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// blt cr6,0x830add68
	if (cr6.lt) goto loc_830ADD68;
loc_830ADF18:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830ADF1C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// b 0x82ca2c28
	return;
loc_830ADF28:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830adf1c
	goto loc_830ADF1C;
loc_830ADF34:
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x830adf1c
	goto loc_830ADF1C;
loc_830ADF48:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_830ADF4C:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x830adf1c
	goto loc_830ADF1C;
loc_830ADF64:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x830adf4c
	goto loc_830ADF4C;
}

__attribute__((alias("__imp__sub_830ADF70"))) PPC_WEAK_FUNC(sub_830ADF70);
PPC_FUNC_IMPL(__imp__sub_830ADF70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,116
	ctx.r3.s64 = 116;
	// lwz r26,12(r30)
	r26.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830adfa4
	if (cr0.eq) goto loc_830ADFA4;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x830adfa8
	goto loc_830ADFA8;
loc_830ADFA4:
	// li r27,0
	r27.s64 = 0;
loc_830ADFA8:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x830adfbc
	if (!cr6.eq) goto loc_830ADFBC;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830ae1b8
	goto loc_830AE1B8;
loc_830ADFBC:
	// lis r4,4096
	ctx.r4.s64 = 268435456;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,4
	ctx.r5.s64 = 4;
	// ori r4,r4,4
	ctx.r4.u64 = ctx.r4.u64 | 4;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830adffc
	if (!cr0.lt) goto loc_830ADFFC;
loc_830ADFE0:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_830ADFE4:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x830ae1b8
	goto loc_830AE1B8;
loc_830ADFFC:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r9,-1
	ctx.r9.s64 = -1;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r28,r9
	r28.u64 = ctx.r9.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830ae084
	if (!cr6.gt) goto loc_830AE084;
	// li r11,0
	r11.s64 = 0;
loc_830AE018:
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r7,132(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 132);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x830ae070
	if (!cr6.eq) goto loc_830AE070;
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r7,8(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r10,r8,r7
	PPC_STORE_U32(ctx.r8.u32 + ctx.r7.u32, ctx.r10.u32);
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r7,136(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 136);
	// stw r7,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r7.u32);
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// stw r9,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, ctx.r9.u32);
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r28,108(r8)
	r28.u64 = PPC_LOAD_U32(ctx.r8.u32 + 108);
loc_830AE070:
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// blt cr6,0x830ae018
	if (cr6.lt) goto loc_830AE018;
loc_830AE084:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r29,0
	r29.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830AE094:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lwz r4,132(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 132);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830ae1c4
	if (cr6.eq) goto loc_830AE1C4;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r31,16
	cr6.compare<uint32_t>(r31.u32, 16, xer);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stw r10,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r10.u32);
	// stw r28,108(r11)
	PPC_STORE_U32(r11.u32 + 108, r28.u32);
	// blt cr6,0x830ae094
	if (cr6.lt) goto loc_830AE094;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830adfe0
	if (cr0.lt) goto loc_830ADFE0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830ae1b4
	if (cr6.eq) goto loc_830AE1B4;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
loc_830AE118:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwzx r7,r11,r5
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830ae1a8
	if (cr6.eq) goto loc_830AE1A8;
	// lwz r6,12(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830ae1a8
	if (cr6.eq) goto loc_830AE1A8;
	// lwz r11,16(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r9,132(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 132);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x830ae1a8
	if (!cr6.eq) goto loc_830AE1A8;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi r6,0
	cr0.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq 0x830ae1a8
	if (cr0.eq) goto loc_830AE1A8;
loc_830AE164:
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,0
	r11.s64 = 0;
loc_830AE16C:
	// lwz r10,16(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// lwz r3,16(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwzx r31,r10,r9
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwzx r3,r11,r3
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// cmplw cr6,r31,r3
	cr6.compare<uint32_t>(r31.u32, ctx.r3.u32, xer);
	// bne cr6,0x830ae190
	if (!cr6.eq) goto loc_830AE190;
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// stwx r3,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r3.u32);
loc_830AE190:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830ae16c
	if (cr6.lt) goto loc_830AE16C;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// blt cr6,0x830ae164
	if (cr6.lt) goto loc_830AE164;
loc_830AE1A8:
	// addic. r4,r4,-1
	xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// bne 0x830ae118
	if (!cr0.eq) goto loc_830AE118;
loc_830AE1B4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830AE1B8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82ca2c30
	return;
loc_830AE1C4:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x830adfe4
	goto loc_830ADFE4;
}

__attribute__((alias("__imp__sub_830AE1D0"))) PPC_WEAK_FUNC(sub_830AE1D0);
PPC_FUNC_IMPL(__imp__sub_830AE1D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r31{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830ae23c
	if (cr6.eq) goto loc_830AE23C;
	// lis r11,-31952
	r11.s64 = -2094006272;
	// subf r6,r4,r3
	ctx.r6.s64 = ctx.r3.s64 - ctx.r4.s64;
	// addi r11,r11,4136
	r11.s64 = r11.s64 + 4136;
loc_830AE1EC:
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// li r9,4
	ctx.r9.s64 = 4;
loc_830AE1F8:
	// lwzx r3,r6,r10
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r3,r31
	cr6.compare<uint32_t>(ctx.r3.u32, r31.u32, xer);
	// beq cr6,0x830ae218
	if (cr6.eq) goto loc_830AE218;
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830ae218
	if (cr6.eq) goto loc_830AE218;
	// li r8,0
	ctx.r8.s64 = 0;
loc_830AE218:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830ae1f8
	if (!cr0.eq) goto loc_830AE1F8;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x830ae248
	if (!cr6.eq) goto loc_830AE248;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// cmplw cr6,r7,r5
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, xer);
	// blt cr6,0x830ae1ec
	if (cr6.lt) goto loc_830AE1EC;
loc_830AE23C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830AE240:
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
loc_830AE248:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830ae240
	goto loc_830AE240;
}

__attribute__((alias("__imp__sub_830AE250"))) PPC_WEAK_FUNC(sub_830AE250);
PPC_FUNC_IMPL(__imp__sub_830AE250) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// addi r8,r1,-16
	ctx.r8.s64 = ctx.r1.s64 + -16;
	// lwz r9,12(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// std r6,0(r8)
	PPC_STORE_U64(ctx.r8.u32 + 0, ctx.r6.u64);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// std r6,8(r8)
	PPC_STORE_U64(ctx.r8.u32 + 8, ctx.r6.u64);
	// beq cr6,0x830ae2b8
	if (cr6.eq) goto loc_830AE2B8;
	// lwz r7,20(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
loc_830AE280:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmplwi cr6,r8,3
	cr6.compare<uint32_t>(ctx.r8.u32, 3, xer);
	// bgt cr6,0x830ae2dc
	if (cr6.gt) goto loc_830AE2DC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r5,r1,-16
	ctx.r5.s64 = ctx.r1.s64 + -16;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// stwx r4,r8,r5
	PPC_STORE_U32(ctx.r8.u32 + ctx.r5.u32, ctx.r4.u32);
	// blt cr6,0x830ae280
	if (cr6.lt) goto loc_830AE280;
loc_830AE2B8:
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// addi r10,r1,-16
	ctx.r10.s64 = ctx.r1.s64 + -16;
	// li r11,3
	r11.s64 = 3;
loc_830AE2C8:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830ae2e4
	if (cr6.eq) goto loc_830AE2E4;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// b 0x830ae2e8
	goto loc_830AE2E8;
loc_830AE2DC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_830AE2E4:
	// li r9,1
	ctx.r9.s64 = 1;
loc_830AE2E8:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830ae2c8
	if (!cr0.eq) goto loc_830AE2C8;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bnelr cr6
	if (!cr6.eq) return;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830AE310"))) PPC_WEAK_FUNC(sub_830AE310);
PPC_FUNC_IMPL(__imp__sub_830AE310) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-432(r1)
	ea = -432 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r20,0
	r20.s64 = 0;
	// mr r18,r20
	r18.u64 = r20.u64;
	// mr r15,r20
	r15.u64 = r20.u64;
	// lwz r30,552(r27)
	r30.u64 = PPC_LOAD_U32(r27.u32 + 552);
	// lwz r14,76(r27)
	r14.u64 = PPC_LOAD_U32(r27.u32 + 76);
	// cmplw cr6,r14,r30
	cr6.compare<uint32_t>(r14.u32, r30.u32, xer);
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r30.u32);
	// bge cr6,0x830ae82c
	if (!cr6.lt) goto loc_830AE82C;
	// rlwinm r11,r14,2,0,29
	r11.u64 = __builtin_rotateleft64(r14.u32 | (r14.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lis r11,-31952
	r11.s64 = -2094006272;
	// li r16,-1
	r16.s64 = -1;
	// addi r11,r11,4136
	r11.s64 = r11.s64 + 4136;
	// lfd f31,3376(r10)
	f31.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3376);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
loc_830AE364:
	// lwz r11,564(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 564);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwzx r25,r11,r10
	r25.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830ae814
	if (cr6.eq) goto loc_830AE814;
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830ae814
	if (cr6.eq) goto loc_830AE814;
	// lwz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// clrlwi r22,r11,12
	r22.u64 = r11.u32 & 0xFFFFF;
	// mr r21,r20
	r21.u64 = r20.u64;
	// divwu. r19,r10,r22
	r19.u32 = ctx.r10.u32 / r22.u32;
	cr0.compare<int32_t>(r19.s32, 0, xer);
	// twllei r22,0
	// beq 0x830ae798
	if (cr0.eq) goto loc_830AE798;
	// mr r24,r20
	r24.u64 = r20.u64;
	// addi r23,r1,144
	r23.s64 = ctx.r1.s64 + 144;
	// rlwinm r17,r22,2,0,29
	r17.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
loc_830AE3A8:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// stw r16,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r16.u32);
	// stw r16,4(r23)
	PPC_STORE_U32(r23.u32 + 4, r16.u32);
	// mr r31,r20
	r31.u64 = r20.u64;
	// stw r16,8(r23)
	PPC_STORE_U32(r23.u32 + 8, r16.u32);
	// mr r30,r20
	r30.u64 = r20.u64;
	// stw r16,12(r23)
	PPC_STORE_U32(r23.u32 + 12, r16.u32);
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// std r16,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r16.u64);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// std r16,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r16.u64);
	// beq cr6,0x830ae518
	if (cr6.eq) goto loc_830AE518;
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// rlwinm r5,r21,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// mr r9,r20
	ctx.r9.u64 = r20.u64;
	// rlwinm r4,r10,0,0,11
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// lwz r7,20(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r3,16(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// add r10,r11,r24
	ctx.r10.u64 = r11.u64 + r24.u64;
loc_830AE3F8:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lis r29,20480
	r29.s64 = 1342177280;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r4,r29
	cr6.compare<uint32_t>(ctx.r4.u32, r29.u32, xer);
	// lwzx r8,r11,r7
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// beq cr6,0x830ae434
	if (cr6.eq) goto loc_830AE434;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// cmplw cr6,r22,r11
	cr6.compare<uint32_t>(r22.u32, r11.u32, xer);
	// bne cr6,0x830ae434
	if (!cr6.eq) goto loc_830AE434;
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// b 0x830ae438
	goto loc_830AE438;
loc_830AE434:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_830AE438:
	// lwz r28,4(r8)
	r28.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// addi r26,r1,144
	r26.s64 = ctx.r1.s64 + 144;
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// rlwinm r28,r28,2,0,29
	r28.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r28,r3
	r28.u64 = PPC_LOAD_U32(r28.u32 + ctx.r3.u32);
	// lwz r28,4(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// rlwinm. r28,r28,0,23,23
	r28.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// add r28,r5,r11
	r28.u64 = ctx.r5.u64 + r11.u64;
	// rlwinm r28,r28,2,0,29
	r28.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// beq 0x830ae468
	if (cr0.eq) goto loc_830AE468;
	// stwx r11,r28,r26
	PPC_STORE_U32(r28.u32 + r26.u32, r11.u32);
	// b 0x830ae46c
	goto loc_830AE46C;
loc_830AE468:
	// stwx r8,r28,r26
	PPC_STORE_U32(r28.u32 + r26.u32, ctx.r8.u32);
loc_830AE46C:
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830ae478
	if (!cr6.eq) goto loc_830AE478;
	// li r31,1
	r31.s64 = 1;
loc_830AE478:
	// cmplwi cr6,r8,3
	cr6.compare<uint32_t>(ctx.r8.u32, 3, xer);
	// bne cr6,0x830ae484
	if (!cr6.eq) goto loc_830AE484;
	// li r30,1
	r30.s64 = 1;
loc_830AE484:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r6,r22
	cr6.compare<uint32_t>(ctx.r6.u32, r22.u32, xer);
	// stwx r20,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, r20.u32);
	// blt cr6,0x830ae3f8
	if (cr6.lt) goto loc_830AE3F8;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// beq cr6,0x830ae518
	if (cr6.eq) goto loc_830AE518;
	// cmplwi cr6,r22,1
	cr6.compare<uint32_t>(r22.u32, 1, xer);
	// bne cr6,0x830ae518
	if (!cr6.eq) goto loc_830AE518;
	// cmplw cr6,r4,r29
	cr6.compare<uint32_t>(ctx.r4.u32, r29.u32, xer);
	// bne cr6,0x830ae4c8
	if (!cr6.eq) goto loc_830AE4C8;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x830ae518
	if (cr6.eq) goto loc_830AE518;
loc_830AE4C8:
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// mr r11,r20
	r11.u64 = r20.u64;
loc_830AE4D4:
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r8,r8,64
	ctx.r8.s64 = ctx.r8.s64 + 64;
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmplw cr6,r7,r8
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, xer);
	// beq cr6,0x830ae500
	if (cr6.eq) goto loc_830AE500;
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x830ae500
	if (cr6.eq) goto loc_830AE500;
	// mr r9,r20
	ctx.r9.u64 = r20.u64;
loc_830AE500:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830ae4d4
	if (cr6.lt) goto loc_830AE4D4;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x830ae780
	if (!cr6.eq) goto loc_830AE780;
loc_830AE518:
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x830ae1d0
	sub_830AE1D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830ae780
	if (!cr0.eq) goto loc_830AE780;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x830ae870
	if (!cr6.eq) goto loc_830AE870;
	// mr r30,r20
	r30.u64 = r20.u64;
	// addi r31,r1,128
	r31.s64 = ctx.r1.s64 + 128;
loc_830AE540:
	// li r6,3
	ctx.r6.s64 = 3;
	// lwz r4,136(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 136);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830ae8c0
	if (cr6.eq) goto loc_830AE8C0;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// blt cr6,0x830ae540
	if (cr6.lt) goto loc_830AE540;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830ae590
	if (cr0.eq) goto loc_830AE590;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// b 0x830ae594
	goto loc_830AE594;
loc_830AE590:
	// mr r18,r20
	r18.u64 = r20.u64;
loc_830AE594:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x830ae8c0
	if (cr6.eq) goto loc_830AE8C0;
	// lis r4,20480
	ctx.r4.s64 = 1342177280;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,6
	ctx.r5.s64 = 6;
	// ori r4,r4,3
	ctx.r4.u64 = ctx.r4.u64 | 3;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830ae830
	if (cr0.lt) goto loc_830AE830;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830ae830
	if (cr0.lt) goto loc_830AE830;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// mr r28,r20
	r28.u64 = r20.u64;
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r29,r20
	r29.u64 = r20.u64;
	// lwzx r11,r11,r24
	r11.u64 = PPC_LOAD_U32(r11.u32 + r24.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r10
	r31.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r26,16(r31)
	r26.u64 = PPC_LOAD_U32(r31.u32 + 16);
loc_830AE5F4:
	// cmplw cr6,r28,r26
	cr6.compare<uint32_t>(r28.u32, r26.u32, xer);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// bne cr6,0x830ae608
	if (!cr6.eq) goto loc_830AE608;
	// lwz r11,1096(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 1096);
	// b 0x830ae60c
	goto loc_830AE60C;
loc_830AE608:
	// lwz r11,1092(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 1092);
loc_830AE60C:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// lfd f1,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stwx r11,r29,r10
	PPC_STORE_U32(r29.u32 + ctx.r10.u32, r11.u32);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stwx r3,r29,r11
	PPC_STORE_U32(r29.u32 + r11.u32, ctx.r3.u32);
	// beq cr6,0x830ae8c0
	if (cr6.eq) goto loc_830AE8C0;
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8307a2f8
	sub_8307A2F8(ctx, base);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwzx r11,r11,r24
	r11.u64 = PPC_LOAD_U32(r11.u32 + r24.u32);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x830ae678
	if (!cr6.eq) goto loc_830AE678;
	// stw r11,56(r30)
	PPC_STORE_U32(r30.u32 + 56, r11.u32);
	// b 0x830ae67c
	goto loc_830AE67C;
loc_830AE678:
	// stw r10,56(r30)
	PPC_STORE_U32(r30.u32 + 56, ctx.r10.u32);
loc_830AE67C:
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplwi cr6,r29,12
	cr6.compare<uint32_t>(r29.u32, 12, xer);
	// blt cr6,0x830ae5f4
	if (cr6.lt) goto loc_830AE5F4;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwz r10,8(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// lwz r8,100(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// lwz r7,104(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r5,112(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r4,116(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r3,120(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// lwz r11,8(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// stw r5,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r5.u32);
	// stw r4,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r4.u32);
	// stw r3,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r3.u32);
	// lwz r11,16(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// beq cr6,0x830ae744
	if (cr6.eq) goto loc_830AE744;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// mr r11,r24
	r11.u64 = r24.u64;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_830AE6F4:
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r8,8(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwzx r7,r5,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// lwzx r9,r8,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r7,56(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 56);
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// beq cr6,0x830ae72c
	if (cr6.eq) goto loc_830AE72C;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830ae898
	if (cr6.eq) goto loc_830AE898;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// bne cr6,0x830ae898
	if (!cr6.eq) goto loc_830AE898;
loc_830AE72C:
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// cmplw cr6,r6,r22
	cr6.compare<uint32_t>(ctx.r6.u32, r22.u32, xer);
	// stwx r10,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// blt cr6,0x830ae6f4
	if (cr6.lt) goto loc_830AE6F4;
loc_830AE744:
	// lwz r11,552(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 552);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830ae8c0
	if (!cr6.lt) goto loc_830AE8C0;
	// lwz r10,564(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 564);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stwx r18,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r18.u32);
	// lwz r11,552(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 552);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,552(r27)
	PPC_STORE_U32(r27.u32 + 552, r11.u32);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830ae8c0
	if (cr0.lt) goto loc_830AE8C0;
	// mr r18,r20
	r18.u64 = r20.u64;
loc_830AE780:
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r23,r23,16
	r23.s64 = r23.s64 + 16;
	// add r24,r17,r24
	r24.u64 = r17.u64 + r24.u64;
	// cmplw cr6,r21,r19
	cr6.compare<uint32_t>(r21.u32, r19.u32, xer);
	// blt cr6,0x830ae3a8
	if (cr6.lt) goto loc_830AE3A8;
	// lwz r30,88(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_830AE798:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830ae7b4
	if (cr0.eq) goto loc_830AE7B4;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r15,r3
	r15.u64 = ctx.r3.u64;
	// b 0x830ae7b8
	goto loc_830AE7B8;
loc_830AE7B4:
	// mr r15,r20
	r15.u64 = r20.u64;
loc_830AE7B8:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x830ae8c0
	if (cr6.eq) goto loc_830AE8C0;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830ae8c0
	if (cr0.lt) goto loc_830AE8C0;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x8307a0a0
	sub_8307A0A0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830ae848
	if (cr0.lt) goto loc_830AE848;
	// lwz r11,552(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 552);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830ae8c0
	if (!cr6.lt) goto loc_830AE8C0;
	// lwz r10,564(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 564);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r15,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r15.u32);
	// mr r15,r20
	r15.u64 = r20.u64;
	// lwz r11,552(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 552);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,552(r27)
	PPC_STORE_U32(r27.u32 + 552, r11.u32);
	// stw r20,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r20.u32);
loc_830AE814:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r14,r14,1
	r14.s64 = r14.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r14,r30
	cr6.compare<uint32_t>(r14.u32, r30.u32, xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// blt cr6,0x830ae364
	if (cr6.lt) goto loc_830AE364;
loc_830AE82C:
	// mr r31,r20
	r31.u64 = r20.u64;
loc_830AE830:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x830ae848
	if (cr6.eq) goto loc_830AE848;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830AE848:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x830ae860
	if (cr6.eq) goto loc_830AE860;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830AE860:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,432
	ctx.r1.s64 = ctx.r1.s64 + 432;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82ca2c00
	return;
loc_830AE870:
	// lwz r11,260(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 260);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,4533
	ctx.r5.s64 = 4533;
	// addi r6,r10,29012
	ctx.r6.s64 = ctx.r10.s64 + 29012;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
	// b 0x830ae860
	goto loc_830AE860;
loc_830AE898:
	// lwz r11,260(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 260);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,4533
	ctx.r5.s64 = 4533;
	// addi r6,r10,29012
	ctx.r6.s64 = ctx.r10.s64 + 29012;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
	// b 0x830ae830
	goto loc_830AE830;
loc_830AE8C0:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x830ae830
	goto loc_830AE830;
}

__attribute__((alias("__imp__sub_830AE8D0"))) PPC_WEAK_FUNC(sub_830AE8D0);
PPC_FUNC_IMPL(__imp__sub_830AE8D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stfd f29,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, f29.u64);
	// stfd f30,-112(r1)
	PPC_STORE_U64(ctx.r1.u32 + -112, f30.u64);
	// stfd f31,-104(r1)
	PPC_STORE_U64(ctx.r1.u32 + -104, f31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r25,0
	r25.s64 = 0;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830ae93c
	if (!cr6.gt) goto loc_830AE93C;
	// lwz r8,136(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 136);
	// rotlwi r9,r11,0
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
loc_830AE908:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x830ae930
	if (!cr6.eq) goto loc_830AE930;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830ae930
	if (cr6.eq) goto loc_830AE930;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// blt cr6,0x830ae930
	if (cr6.lt) goto loc_830AE930;
	// addi r25,r11,1
	r25.s64 = r11.s64 + 1;
loc_830AE930:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830ae908
	if (!cr0.eq) goto loc_830AE908;
loc_830AE93C:
	// lwz r21,552(r30)
	r21.u64 = PPC_LOAD_U32(r30.u32 + 552);
	// lwz r24,76(r30)
	r24.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// cmplw cr6,r24,r21
	cr6.compare<uint32_t>(r24.u32, r21.u32, xer);
	// bge cr6,0x830aeed8
	if (!cr6.lt) goto loc_830AEED8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// rlwinm r22,r24,2,0,29
	r22.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// li r23,1
	r23.s64 = 1;
	// lfd f29,3368(r11)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(r11.u32 + 3368);
	// lfd f30,3240(r10)
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3240);
	// lfd f31,3376(r9)
	f31.u64 = PPC_LOAD_U64(ctx.r9.u32 + 3376);
loc_830AE96C:
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// lwzx r27,r11,r22
	r27.u64 = PPC_LOAD_U32(r11.u32 + r22.u32);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830aeec8
	if (cr6.eq) goto loc_830AEEC8;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830aeec8
	if (cr6.eq) goto loc_830AEEC8;
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// lis r9,28688
	ctx.r9.s64 = 1880096768;
	// clrlwi r26,r11,12
	r26.u64 = r11.u32 & 0xFFFFF;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830aeb40
	if (!cr6.eq) goto loc_830AEB40;
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm. r8,r8,0,22,22
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x830aeb40
	if (cr0.eq) goto loc_830AEB40;
	// rlwinm r8,r26,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm. r8,r8,0,22,22
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x830aeb40
	if (cr0.eq) goto loc_830AEB40;
	// rlwinm r8,r26,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830aeb40
	if (cr0.eq) goto loc_830AEB40;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830aea38
	if (cr0.eq) goto loc_830AEA38;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x830aea3c
	goto loc_830AEA3C;
loc_830AEA38:
	// li r29,0
	r29.s64 = 0;
loc_830AEA3C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830aef70
	if (cr6.eq) goto loc_830AEF70;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r23,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r23.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830aef0c
	if (cr0.lt) goto loc_830AEF0C;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830aef0c
	if (cr0.lt) goto loc_830AEF0C;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830aeb00
	if (cr6.eq) goto loc_830AEB00;
	// li r31,0
	r31.s64 = 0;
loc_830AEA8C:
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// lwzx r10,r10,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r31.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stwx r10,r8,r31
	PPC_STORE_U32(ctx.r8.u32 + r31.u32, ctx.r10.u32);
	// lwz r4,136(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 136);
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// stwx r3,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// stwx r11,r10,r31
	PPC_STORE_U32(ctx.r10.u32 + r31.u32, r11.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830aef70
	if (cr6.eq) goto loc_830AEF70;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r28,r26
	cr6.compare<uint32_t>(r28.u32, r26.u32, xer);
	// blt cr6,0x830aea8c
	if (cr6.lt) goto loc_830AEA8C;
loc_830AEB00:
	// lwz r11,552(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 552);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830aef70
	if (!cr6.lt) goto loc_830AEF70;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830aef0c
	if (cr0.lt) goto loc_830AEF0C;
	// lwz r11,552(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 552);
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r29,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r29.u32);
	// lwz r11,552(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 552);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,552(r30)
	PPC_STORE_U32(r30.u32 + 552, r11.u32);
loc_830AEB40:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lis r10,12288
	ctx.r10.s64 = 805306368;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830aee50
	if (!cr6.eq) goto loc_830AEE50;
	// lhz r11,202(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830aee50
	if (cr6.eq) goto loc_830AEE50;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// cmplwi cr6,r26,1
	cr6.compare<uint32_t>(r26.u32, 1, xer);
	// ble cr6,0x830aeb94
	if (!cr6.gt) goto loc_830AEB94;
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addi r11,r10,4
	r11.s64 = ctx.r10.s64 + 4;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
loc_830AEB78:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x830aef24
	if (!cr6.eq) goto loc_830AEF24;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r26
	cr6.compare<uint32_t>(ctx.r9.u32, r26.u32, xer);
	// blt cr6,0x830aeb78
	if (cr6.lt) goto loc_830AEB78;
loc_830AEB94:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830aebb0
	if (cr0.eq) goto loc_830AEBB0;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x830aebb4
	goto loc_830AEBB4;
loc_830AEBB0:
	// li r29,0
	r29.s64 = 0;
loc_830AEBB4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830aef70
	if (cr6.eq) goto loc_830AEF70;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// blt 0x830aef4c
	if (cr0.lt) goto loc_830AEF4C;
	// lis r4,28720
	ctx.r4.s64 = 1882193920;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830aef0c
	if (cr0.lt) goto loc_830AEF0C;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830aef0c
	if (cr0.lt) goto loc_830AEF0C;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r4,120(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 120);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// stw r3,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r3.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,120(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 120);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830aef70
	if (cr6.eq) goto loc_830AEF70;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830aef70
	if (cr6.eq) goto loc_830AEF70;
	// li r6,3
	ctx.r6.s64 = 3;
	// lwz r4,136(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 136);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// stw r3,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830aef70
	if (cr6.eq) goto loc_830AEF70;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830aecf8
	if (cr6.eq) goto loc_830AECF8;
	// li r8,0
	ctx.r8.s64 = 0;
	// rlwinm r10,r26,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r11,r26,2,0,29
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
loc_830AECBC:
	// lwz r7,16(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// lwz r6,8(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r7,0(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// stwx r7,r6,r8
	PPC_STORE_U32(ctx.r6.u32 + ctx.r8.u32, ctx.r7.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// lwz r7,8(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwzx r6,r7,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwzx r5,r7,r10
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// stwx r5,r7,r11
	PPC_STORE_U32(ctx.r7.u32 + r11.u32, ctx.r5.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r7,8(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// stwx r6,r7,r10
	PPC_STORE_U32(ctx.r7.u32 + ctx.r10.u32, ctx.r6.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830aecbc
	if (!cr0.eq) goto loc_830AECBC;
loc_830AECF8:
	// lwz r11,552(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 552);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830aef70
	if (!cr6.lt) goto loc_830AEF70;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stwx r29,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r29.u32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,552(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 552);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,552(r30)
	PPC_STORE_U32(r30.u32 + 552, r11.u32);
	// lwz r11,32(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830aee40
	if (cr0.eq) goto loc_830AEE40;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830aed60
	if (cr0.eq) goto loc_830AED60;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x830aed64
	goto loc_830AED64;
loc_830AED60:
	// li r28,0
	r28.s64 = 0;
loc_830AED64:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// blt 0x830aef58
	if (cr0.lt) goto loc_830AEF58;
	// beq cr6,0x830aef70
	if (cr6.eq) goto loc_830AEF70;
	// lis r4,8256
	ctx.r4.s64 = 541065216;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830aef0c
	if (cr0.lt) goto loc_830AEF0C;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830aef0c
	if (cr0.lt) goto loc_830AEF0C;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// li r6,3
	ctx.r6.s64 = 3;
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r4,136(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 136);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lis r10,8272
	ctx.r10.s64 = 542113792;
	// li r9,2
	ctx.r9.s64 = 2;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r3,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r3.u32);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r8,16(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r8,0(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r9,4(r29)
	PPC_STORE_U32(r29.u32 + 4, ctx.r9.u32);
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
	// lwz r11,552(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 552);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830aef70
	if (!cr6.lt) goto loc_830AEF70;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r28,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r28.u32);
	// lwz r11,552(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 552);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,552(r30)
	PPC_STORE_U32(r30.u32 + 552, r11.u32);
loc_830AEE40:
	// li r11,1807
	r11.s64 = 1807;
	// stw r23,1104(r30)
	PPC_STORE_U32(r30.u32 + 1104, r23.u32);
	// rlwimi r26,r11,20,0,11
	r26.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (r26.u64 & 0xFFFFFFFF000FFFFF);
	// stw r26,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r26.u32);
loc_830AEE50:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830aee6c
	if (cr0.eq) goto loc_830AEE6C;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x830aee70
	goto loc_830AEE70;
loc_830AEE6C:
	// li r29,0
	r29.s64 = 0;
loc_830AEE70:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830aef70
	if (cr6.eq) goto loc_830AEF70;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8307a0a0
	sub_8307A0A0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830aef0c
	if (cr0.lt) goto loc_830AEF0C;
	// lwz r11,552(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 552);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830aef70
	if (!cr6.lt) goto loc_830AEF70;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830aef0c
	if (cr0.lt) goto loc_830AEF0C;
	// lwz r11,552(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 552);
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r29,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r29.u32);
	// lwz r11,552(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 552);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,552(r30)
	PPC_STORE_U32(r30.u32 + 552, r11.u32);
loc_830AEEC8:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmplw cr6,r24,r21
	cr6.compare<uint32_t>(r24.u32, r21.u32, xer);
	// blt cr6,0x830ae96c
	if (cr6.lt) goto loc_830AE96C;
loc_830AEED8:
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bge cr6,0x830aef08
	if (!cr6.lt) goto loc_830AEF08;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r11,r21
	r11.s64 = r21.s64 - r11.s64;
loc_830AEEEC:
	// lwz r9,564(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// li r8,0
	ctx.r8.s64 = 0;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// bne 0x830aeeec
	if (!cr0.eq) goto loc_830AEEEC;
loc_830AEF08:
	// li r31,0
	r31.s64 = 0;
loc_830AEF0C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lfd f29,-120(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// lfd f30,-112(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// lfd f31,-104(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x82ca2c1c
	return;
loc_830AEF24:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lbz r7,203(r30)
	ctx.r7.u64 = PPC_LOAD_U8(r30.u32 + 203);
	// li r5,4554
	ctx.r5.s64 = 4554;
	// lwz r4,60(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 60);
	// addi r6,r11,29044
	ctx.r6.s64 = r11.s64 + 29044;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
	// b 0x830aef0c
	goto loc_830AEF0C;
loc_830AEF4C:
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x830aef68
	goto loc_830AEF68;
loc_830AEF58:
	// beq cr6,0x830aef0c
	if (cr6.eq) goto loc_830AEF0C;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_830AEF68:
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// b 0x830aef0c
	goto loc_830AEF0C;
loc_830AEF70:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x830aef0c
	goto loc_830AEF0C;
}

__attribute__((alias("__imp__sub_830AEF80"))) PPC_WEAK_FUNC(sub_830AEF80);
PPC_FUNC_IMPL(__imp__sub_830AEF80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// lwz r27,260(r19)
	r27.u64 = PPC_LOAD_U32(r19.u32 + 260);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// clrlwi r16,r11,12
	r16.u64 = r11.u32 & 0xFFFFF;
	// beq cr6,0x830af67c
	if (cr6.eq) goto loc_830AF67C;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830af67c
	if (cr6.eq) goto loc_830AF67C;
	// lwz r10,4(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// rlwinm r9,r11,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// li r21,0
	r21.s64 = 0;
	// lhz r11,202(r19)
	r11.u64 = PPC_LOAD_U16(r19.u32 + 202);
	// lis r8,20480
	ctx.r8.s64 = 1342177280;
	// divwu r18,r10,r16
	r18.u32 = ctx.r10.u32 / r16.u32;
	// twllei r16,0
	// mr r26,r21
	r26.u64 = r21.u64;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// beq cr6,0x830af660
	if (cr6.eq) goto loc_830AF660;
	// lwz r31,12(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// cmplw cr6,r31,r16
	cr6.compare<uint32_t>(r31.u32, r16.u32, xer);
	// bne cr6,0x830af660
	if (!cr6.eq) goto loc_830AF660;
	// mr r15,r21
	r15.u64 = r21.u64;
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830af03c
	if (cr6.eq) goto loc_830AF03C;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x830ae250
	sub_830AE250(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830af03c
	if (cr0.eq) goto loc_830AF03C;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830af03c
	if (cr6.eq) goto loc_830AF03C;
	// lwz r9,20(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
loc_830AF010:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmplwi cr6,r8,3
	cr6.compare<uint32_t>(ctx.r8.u32, 3, xer);
	// bne cr6,0x830af030
	if (!cr6.eq) goto loc_830AF030;
	// li r26,1
	r26.s64 = 1;
	// li r15,1
	r15.s64 = 1;
loc_830AF030:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830af010
	if (!cr0.eq) goto loc_830AF010;
loc_830AF03C:
	// mr r30,r21
	r30.u64 = r21.u64;
	// li r22,-1
	r22.s64 = -1;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x830af148
	if (cr6.eq) goto loc_830AF148;
	// addi r29,r1,80
	r29.s64 = ctx.r1.s64 + 80;
	// mr r31,r21
	r31.u64 = r21.u64;
	// rlwinm r28,r16,2,0,29
	r28.u64 = __builtin_rotateleft64(r16.u32 | (r16.u64 << 32), 2) & 0xFFFFFFFC;
loc_830AF058:
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// stw r22,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r22.u32);
	// stw r22,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r22.u32);
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// stw r22,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r22.u32);
	// stw r22,12(r29)
	PPC_STORE_U32(r29.u32 + 12, r22.u32);
	// std r22,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r22.u64);
	// std r22,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r22.u64);
	// beq cr6,0x830af118
	if (cr6.eq) goto loc_830AF118;
	// lwz r6,260(r19)
	ctx.r6.u64 = PPC_LOAD_U32(r19.u32 + 260);
	// rlwinm r3,r30,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// mr r11,r21
	r11.u64 = r21.u64;
	// lwz r4,16(r19)
	ctx.r4.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
loc_830AF098:
	// lwz r9,8(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// lwz r8,16(r6)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r25,r8,2,0,29
	r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwzx r9,r25,r7
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + ctx.r7.u32);
	// lwz r25,4(r8)
	r25.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// rlwinm r25,r25,2,0,29
	r25.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r25,r25,r4
	r25.u64 = PPC_LOAD_U32(r25.u32 + ctx.r4.u32);
	// lwz r25,4(r25)
	r25.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// rlwinm. r25,r25,0,23,23
	r25.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// beq 0x830af0e8
	if (cr0.eq) goto loc_830AF0E8;
	// add r8,r3,r9
	ctx.r8.u64 = ctx.r3.u64 + ctx.r9.u64;
	// addi r25,r1,80
	r25.s64 = ctx.r1.s64 + 80;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r8,r25
	PPC_STORE_U32(ctx.r8.u32 + r25.u32, ctx.r9.u32);
	// b 0x830af0fc
	goto loc_830AF0FC;
loc_830AF0E8:
	// add r25,r3,r9
	r25.u64 = ctx.r3.u64 + ctx.r9.u64;
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// addi r24,r1,80
	r24.s64 = ctx.r1.s64 + 80;
	// rlwinm r25,r25,2,0,29
	r25.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r8,r25,r24
	PPC_STORE_U32(r25.u32 + r24.u32, ctx.r8.u32);
loc_830AF0FC:
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stwx r21,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, r21.u32);
	// bne 0x830af098
	if (!cr0.eq) goto loc_830AF098;
loc_830AF118:
	// li r5,5
	ctx.r5.s64 = 5;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830ae1d0
	sub_830AE1D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830af134
	if (!cr0.eq) goto loc_830AF134;
	// li r26,1
	r26.s64 = 1;
loc_830AF134:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// add r31,r28,r31
	r31.u64 = r28.u64 + r31.u64;
	// addi r29,r29,16
	r29.s64 = r29.s64 + 16;
	// cmplw cr6,r30,r18
	cr6.compare<uint32_t>(r30.u32, r18.u32, xer);
	// blt cr6,0x830af058
	if (cr6.lt) goto loc_830AF058;
loc_830AF148:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x830af63c
	if (cr6.eq) goto loc_830AF63C;
	// mr r17,r21
	r17.u64 = r21.u64;
	// mr r20,r21
	r20.u64 = r21.u64;
	// cmplwi cr6,r16,4
	cr6.compare<uint32_t>(r16.u32, 4, xer);
	// bne cr6,0x830af424
	if (!cr6.eq) goto loc_830AF424;
	// li r30,1
	r30.s64 = 1;
	// mr r26,r21
	r26.u64 = r21.u64;
	// addi r31,r1,144
	r31.s64 = ctx.r1.s64 + 144;
	// li r29,-1
	r29.s64 = -1;
loc_830AF170:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x830af208
	if (cr6.eq) goto loc_830AF208;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// mr r30,r21
	r30.u64 = r21.u64;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// std r21,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r21.u64);
	// std r21,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r21.u64);
	// stw r22,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r22.u32);
	// stw r22,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r22.u32);
	// stw r22,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r22.u32);
	// stw r22,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r22.u32);
	// stw r29,-16(r31)
	PPC_STORE_U32(r31.u32 + -16, r29.u32);
	// stw r21,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r21.u32);
	// beq cr6,0x830af1dc
	if (cr6.eq) goto loc_830AF1DC;
	// addi r27,r1,80
	r27.s64 = ctx.r1.s64 + 80;
	// mr r28,r18
	r28.u64 = r18.u64;
loc_830AF1B4:
	// li r5,5
	ctx.r5.s64 = 5;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830ae1d0
	sub_830AE1D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830af1d0
	if (!cr0.eq) goto loc_830AF1D0;
	// li r30,1
	r30.s64 = 1;
loc_830AF1D0:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r27,r27,16
	r27.s64 = r27.s64 + 16;
	// bne 0x830af1b4
	if (!cr0.eq) goto loc_830AF1B4;
loc_830AF1DC:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x830af1f0
	if (cr6.eq) goto loc_830AF1F0;
	// cmplwi cr6,r26,3
	cr6.compare<uint32_t>(r26.u32, 3, xer);
	// beq cr6,0x830af1f0
	if (cr6.eq) goto loc_830AF1F0;
	// li r30,1
	r30.s64 = 1;
loc_830AF1F0:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x830af2a8
	if (cr6.eq) goto loc_830AF2A8;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi cr6,r26,4
	cr6.compare<uint32_t>(r26.u32, 4, xer);
	// blt cr6,0x830af170
	if (cr6.lt) goto loc_830AF170;
loc_830AF208:
	// li r25,1
	r25.s64 = 1;
	// mr r23,r21
	r23.u64 = r21.u64;
	// addi r28,r1,144
	r28.s64 = ctx.r1.s64 + 144;
loc_830AF214:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830af3a8
	if (cr6.eq) goto loc_830AF3A8;
	// mr r24,r21
	r24.u64 = r21.u64;
	// addi r31,r1,144
	r31.s64 = ctx.r1.s64 + 144;
loc_830AF224:
	// cmplw cr6,r24,r23
	cr6.compare<uint32_t>(r24.u32, r23.u32, xer);
	// beq cr6,0x830af380
	if (cr6.eq) goto loc_830AF380;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// mr r25,r21
	r25.u64 = r21.u64;
	// mr r26,r21
	r26.u64 = r21.u64;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// std r21,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r21.u64);
	// std r21,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r21.u64);
	// stw r22,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r22.u32);
	// stw r22,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r22.u32);
	// stw r22,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r22.u32);
	// stw r22,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r22.u32);
	// stw r29,-16(r28)
	PPC_STORE_U32(r28.u32 + -16, r29.u32);
	// stw r29,-16(r31)
	PPC_STORE_U32(r31.u32 + -16, r29.u32);
	// stw r21,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r21.u32);
	// stw r21,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r21.u32);
	// beq cr6,0x830af2f4
	if (cr6.eq) goto loc_830AF2F4;
	// addi r30,r1,80
	r30.s64 = ctx.r1.s64 + 80;
	// mr r27,r18
	r27.u64 = r18.u64;
loc_830AF274:
	// li r5,5
	ctx.r5.s64 = 5;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830ae1d0
	sub_830AE1D0(ctx, base);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// li r5,5
	ctx.r5.s64 = 5;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830ae1d0
	sub_830AE1D0(ctx, base);
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// bne cr6,0x830af2dc
	if (!cr6.eq) goto loc_830AF2DC;
	// li r26,1
	r26.s64 = 1;
	// b 0x830af2e4
	goto loc_830AF2E4;
loc_830AF2A8:
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830af680
	if (cr0.lt) goto loc_830AF680;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// b 0x830af648
	goto loc_830AF648;
loc_830AF2DC:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830af2e8
	if (!cr6.eq) goto loc_830AF2E8;
loc_830AF2E4:
	// li r25,1
	r25.s64 = 1;
loc_830AF2E8:
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// addi r30,r30,16
	r30.s64 = r30.s64 + 16;
	// bne 0x830af274
	if (!cr0.eq) goto loc_830AF274;
loc_830AF2F4:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x830af300
	if (cr6.eq) goto loc_830AF300;
	// li r25,1
	r25.s64 = 1;
loc_830AF300:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830af394
	if (cr6.eq) goto loc_830AF394;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// bne cr6,0x830af380
	if (!cr6.eq) goto loc_830AF380;
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x830af324
	if (cr6.eq) goto loc_830AF324;
	// lwz r11,140(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830af380
	if (cr6.eq) goto loc_830AF380;
loc_830AF324:
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// li r20,1
	r20.s64 = 1;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r7,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r7.u32);
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// stw r5,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r5.u32);
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r11.u32);
	// stw r22,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r22.u32);
	// stw r22,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, r22.u32);
	// stw r22,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, r22.u32);
	// stw r22,12(r9)
	PPC_STORE_U32(ctx.r9.u32 + 12, r22.u32);
	// stw r22,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r22.u32);
	// stw r22,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, r22.u32);
	// stw r22,8(r8)
	PPC_STORE_U32(ctx.r8.u32 + 8, r22.u32);
	// stw r22,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, r22.u32);
	// stw r21,32(r28)
	PPC_STORE_U32(r28.u32 + 32, r21.u32);
	// stw r21,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r21.u32);
loc_830AF380:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi cr6,r24,4
	cr6.compare<uint32_t>(r24.u32, 4, xer);
	// blt cr6,0x830af224
	if (cr6.lt) goto loc_830AF224;
	// b 0x830af398
	goto loc_830AF398;
loc_830AF394:
	// li r17,1
	r17.s64 = 1;
loc_830AF398:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplwi cr6,r23,4
	cr6.compare<uint32_t>(r23.u32, 4, xer);
	// blt cr6,0x830af214
	if (cr6.lt) goto loc_830AF214;
loc_830AF3A8:
	// cmpwi cr6,r17,0
	cr6.compare<int32_t>(r17.s32, 0, xer);
	// beq cr6,0x830af3d4
	if (cr6.eq) goto loc_830AF3D4;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830af680
	if (cr0.lt) goto loc_830AF680;
	// li r6,4
	ctx.r6.s64 = 4;
	// b 0x830af5a8
	goto loc_830AF5A8;
loc_830AF3D4:
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// beq cr6,0x830af5c8
	if (cr6.eq) goto loc_830AF5C8;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// li r17,1
	r17.s64 = 1;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830af680
	if (cr0.lt) goto loc_830AF680;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830af680
	if (cr0.lt) goto loc_830AF680;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// b 0x830af5ac
	goto loc_830AF5AC;
loc_830AF424:
	// cmplwi cr6,r16,3
	cr6.compare<uint32_t>(r16.u32, 3, xer);
	// bne cr6,0x830af5c8
	if (!cr6.eq) goto loc_830AF5C8;
	// li r29,-1
	r29.s64 = -1;
	// mr r11,r21
	r11.u64 = r21.u64;
	// mr r25,r29
	r25.u64 = r29.u64;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
loc_830AF43C:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x830af44c
	if (!cr6.eq) goto loc_830AF44C;
	// mr r25,r11
	r25.u64 = r11.u64;
loc_830AF44C:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x830af43c
	if (cr6.lt) goto loc_830AF43C;
	// mr r23,r21
	r23.u64 = r21.u64;
	// addi r26,r1,144
	r26.s64 = ctx.r1.s64 + 144;
loc_830AF464:
	// cmpwi cr6,r17,0
	cr6.compare<int32_t>(r17.s32, 0, xer);
	// bne cr6,0x830af588
	if (!cr6.eq) goto loc_830AF588;
	// mr r24,r21
	r24.u64 = r21.u64;
	// addi r27,r1,144
	r27.s64 = ctx.r1.s64 + 144;
loc_830AF474:
	// cmpwi cr6,r17,0
	cr6.compare<int32_t>(r17.s32, 0, xer);
	// bne cr6,0x830af570
	if (!cr6.eq) goto loc_830AF570;
	// cmplw cr6,r24,r23
	cr6.compare<uint32_t>(r24.u32, r23.u32, xer);
	// beq cr6,0x830af560
	if (cr6.eq) goto loc_830AF560;
	// cmplw cr6,r24,r25
	cr6.compare<uint32_t>(r24.u32, r25.u32, xer);
	// beq cr6,0x830af560
	if (cr6.eq) goto loc_830AF560;
	// cmplw cr6,r23,r25
	cr6.compare<uint32_t>(r23.u32, r25.u32, xer);
	// beq cr6,0x830af560
	if (cr6.eq) goto loc_830AF560;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// rlwinm r9,r25,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,144
	ctx.r8.s64 = ctx.r1.s64 + 144;
	// mr r30,r21
	r30.u64 = r21.u64;
	// std r22,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r22.u64);
	// mr r31,r21
	r31.u64 = r21.u64;
	// std r22,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r22.u64);
	// stw r21,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r21.u32);
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// stw r21,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r21.u32);
	// stw r21,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r21.u32);
	// stw r21,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r21.u32);
	// stw r21,-16(r26)
	PPC_STORE_U32(r26.u32 + -16, r21.u32);
	// stw r21,-16(r27)
	PPC_STORE_U32(r27.u32 + -16, r21.u32);
	// stw r29,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r29.u32);
	// stw r29,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r29.u32);
	// stwx r29,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, r29.u32);
	// beq cr6,0x830af518
	if (cr6.eq) goto loc_830AF518;
	// addi r28,r1,80
	r28.s64 = ctx.r1.s64 + 80;
loc_830AF4E4:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x830af518
	if (!cr6.eq) goto loc_830AF518;
	// li r5,5
	ctx.r5.s64 = 5;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830ae1d0
	sub_830AE1D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830af508
	if (!cr0.eq) goto loc_830AF508;
	// li r30,1
	r30.s64 = 1;
loc_830AF508:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r28,r28,16
	r28.s64 = r28.s64 + 16;
	// cmplw cr6,r31,r18
	cr6.compare<uint32_t>(r31.u32, r18.u32, xer);
	// blt cr6,0x830af4e4
	if (cr6.lt) goto loc_830AF4E4;
loc_830AF518:
	// lwz r11,140(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830af554
	if (!cr6.eq) goto loc_830AF554;
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830af548
	if (cr6.eq) goto loc_830AF548;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830af548
	if (cr6.eq) goto loc_830AF548;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830af554
	if (!cr6.eq) goto loc_830AF554;
loc_830AF548:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x830af554
	if (cr6.eq) goto loc_830AF554;
	// li r30,1
	r30.s64 = 1;
loc_830AF554:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x830af560
	if (!cr6.eq) goto loc_830AF560;
	// li r17,1
	r17.s64 = 1;
loc_830AF560:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplwi cr6,r24,4
	cr6.compare<uint32_t>(r24.u32, 4, xer);
	// blt cr6,0x830af474
	if (cr6.lt) goto loc_830AF474;
loc_830AF570:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplwi cr6,r23,4
	cr6.compare<uint32_t>(r23.u32, 4, xer);
	// blt cr6,0x830af464
	if (cr6.lt) goto loc_830AF464;
	// cmpwi cr6,r17,0
	cr6.compare<int32_t>(r17.s32, 0, xer);
	// beq cr6,0x830af5c8
	if (cr6.eq) goto loc_830AF5C8;
loc_830AF588:
	// li r6,3
	ctx.r6.s64 = 3;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830af680
	if (cr0.lt) goto loc_830AF680;
	// li r6,3
	ctx.r6.s64 = 3;
loc_830AF5A8:
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
loc_830AF5AC:
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830af680
	if (cr0.lt) goto loc_830AF680;
	// cmpwi cr6,r17,0
	cr6.compare<int32_t>(r17.s32, 0, xer);
	// bne cr6,0x830af650
	if (!cr6.eq) goto loc_830AF650;
loc_830AF5C8:
	// mr r30,r21
	r30.u64 = r21.u64;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x830af650
	if (cr6.eq) goto loc_830AF650;
	// mr r31,r21
	r31.u64 = r21.u64;
loc_830AF5D8:
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwz r10,260(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 260);
	// lwz r9,20(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// std r22,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r22.u64);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// std r22,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r22.u64);
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r21,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, r21.u32);
	// bl 0x83069c00
	sub_83069C00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830af680
	if (cr0.lt) goto loc_830AF680;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r30,r16
	cr6.compare<uint32_t>(r30.u32, r16.u32, xer);
	// blt cr6,0x830af5d8
	if (cr6.lt) goto loc_830AF5D8;
	// b 0x830af650
	goto loc_830AF650;
loc_830AF63C:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
loc_830AF648:
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830af680
	if (cr0.lt) goto loc_830AF680;
loc_830AF650:
	// lwz r11,260(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 260);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// stw r21,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r21.u32);
	// b 0x830af680
	goto loc_830AF680;
loc_830AF660:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830af680
	if (cr0.lt) goto loc_830AF680;
	// lwz r11,260(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 260);
	// stw r21,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r21.u32);
loc_830AF67C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830AF680:
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// b 0x82ca2c00
	return;
}

__attribute__((alias("__imp__sub_830AF688"))) PPC_WEAK_FUNC(sub_830AF688);
PPC_FUNC_IMPL(__imp__sub_830AF688) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-464(r1)
	ea = -464 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// lhz r11,202(r27)
	r11.u64 = PPC_LOAD_U16(r27.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// blt cr6,0x830af6b0
	if (cr6.lt) goto loc_830AF6B0;
loc_830AF6A8:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830afbbc
	goto loc_830AFBBC;
loc_830AF6B0:
	// lwz r11,260(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 260);
	// li r31,0
	r31.s64 = 0;
	// li r10,2
	ctx.r10.s64 = 2;
	// li r9,3
	ctx.r9.s64 = 3;
	// stw r31,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r31.u32);
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r31,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r31.u32);
	// stw r10,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r10.u32);
	// stw r8,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r8.u32);
	// stw r9,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r9.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// lis r11,-31952
	r11.s64 = -2094006272;
	// mr r29,r31
	r29.u64 = r31.u64;
	// addi r28,r11,4044
	r28.s64 = r11.s64 + 4044;
	// addi r30,r28,-36
	r30.s64 = r28.s64 + -36;
loc_830AF6F8:
	// li r10,3
	ctx.r10.s64 = 3;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// lwz r4,260(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 260);
	// addi r8,r1,224
	ctx.r8.s64 = ctx.r1.s64 + 224;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83060f70
	sub_83060F70(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830af738
	if (cr0.eq) goto loc_830AF738;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r29,9
	cr6.compare<uint32_t>(r29.u32, 9, xer);
	// blt cr6,0x830af6f8
	if (cr6.lt) goto loc_830AF6F8;
loc_830AF738:
	// mr r25,r31
	r25.u64 = r31.u64;
	// mr r26,r31
	r26.u64 = r31.u64;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// ble cr6,0x830af74c
	if (!cr6.gt) goto loc_830AF74C;
	// li r26,1
	r26.s64 = 1;
loc_830AF74C:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x830af7b8
	if (cr6.eq) goto loc_830AF7B8;
	// mr r30,r28
	r30.u64 = r28.u64;
	// mr r29,r31
	r29.u64 = r31.u64;
loc_830AF75C:
	// li r10,3
	ctx.r10.s64 = 3;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// lwz r4,260(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 260);
	// addi r8,r1,224
	ctx.r8.s64 = ctx.r1.s64 + 224;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83060f70
	sub_83060F70(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830af79c
	if (cr0.eq) goto loc_830AF79C;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r29,3
	cr6.compare<uint32_t>(r29.u32, 3, xer);
	// blt cr6,0x830af75c
	if (cr6.lt) goto loc_830AF75C;
loc_830AF79C:
	// mr r26,r31
	r26.u64 = r31.u64;
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// ble cr6,0x830af7ac
	if (!cr6.gt) goto loc_830AF7AC;
	// li r26,1
	r26.s64 = 1;
loc_830AF7AC:
	// li r25,1
	r25.s64 = 1;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
loc_830AF7B8:
	// addi r11,r1,120
	r11.s64 = ctx.r1.s64 + 120;
	// lwz r3,20(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r30,r31
	r30.u64 = r31.u64;
	// subfic r29,r11,12
	xer.ca = r11.u32 <= 12;
	r29.s64 = 12 - r11.s64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lfd f0,3240(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3240);
loc_830AF7D4:
	// addi r11,r1,288
	r11.s64 = ctx.r1.s64 + 288;
	// add r4,r5,r11
	ctx.r4.u64 = ctx.r5.u64 + r11.u64;
	// lwz r8,-48(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + -48);
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r3
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x830af8b0
	if (cr6.eq) goto loc_830AF8B0;
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,128(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 128);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// lbz r10,110(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 110);
	// addi r9,r30,1
	ctx.r9.s64 = r30.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// lbz r10,111(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 111);
	// cmplwi cr6,r10,5
	cr6.compare<uint32_t>(ctx.r10.u32, 5, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// addi r10,r1,120
	ctx.r10.s64 = ctx.r1.s64 + 120;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// stwx r8,r5,r10
	PPC_STORE_U32(ctx.r5.u32 + ctx.r10.u32, ctx.r8.u32);
	// bne cr6,0x830af85c
	if (!cr6.eq) goto loc_830AF85C;
	// lwz r10,60(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// lis r9,8
	ctx.r9.s64 = 524288;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// lwz r7,56(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// b 0x830af988
	goto loc_830AF988;
loc_830AF85C:
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// addi r11,r1,272
	r11.s64 = ctx.r1.s64 + 272;
	// add r11,r5,r11
	r11.u64 = ctx.r5.u64 + r11.u64;
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r6,r8
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, xer);
	// bne cr6,0x830af8a4
	if (!cr6.eq) goto loc_830AF8A4;
	// lwz r7,0(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r10,-16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -16);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// bne cr6,0x830af8a4
	if (!cr6.eq) goto loc_830AF8A4;
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r28,48(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// cmplw cr6,r9,r28
	cr6.compare<uint32_t>(ctx.r9.u32, r28.u32, xer);
	// bne cr6,0x830af8a4
	if (!cr6.eq) goto loc_830AF8A4;
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// beq cr6,0x830af9f4
	if (cr6.eq) goto loc_830AF9F4;
loc_830AF8A4:
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// b 0x830af9cc
	goto loc_830AF9CC;
loc_830AF8B0:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x830af8e0
	if (cr6.eq) goto loc_830AF8E0;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830af6a8
	if (cr0.eq) goto loc_830AF6A8;
	// addi r11,r1,120
	r11.s64 = ctx.r1.s64 + 120;
	// add r11,r5,r11
	r11.u64 = ctx.r5.u64 + r11.u64;
	// b 0x830af980
	goto loc_830AF980;
loc_830AF8E0:
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830af6a8
	if (cr6.eq) goto loc_830AF6A8;
	// lwz r10,24(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,8272
	ctx.r9.s64 = 542113792;
	// ori r9,r9,3
	ctx.r9.u64 = ctx.r9.u64 | 3;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,16(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwzx r8,r5,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r3
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,4(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm. r7,r7,0,22,22
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x830af6a8
	if (cr0.eq) goto loc_830AF6A8;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// addi r11,r1,120
	r11.s64 = ctx.r1.s64 + 120;
	// add r11,r5,r11
	r11.u64 = ctx.r5.u64 + r11.u64;
	// add r7,r29,r11
	ctx.r7.u64 = r29.u64 + r11.u64;
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r3
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// lwz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r7,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830af6a8
	if (cr0.eq) goto loc_830AF6A8;
	// lfd f13,32(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
loc_830AF980:
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// rotlwi r7,r8,0
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
loc_830AF988:
	// addi r10,r1,272
	ctx.r10.s64 = ctx.r1.s64 + 272;
	// add r11,r5,r10
	r11.u64 = ctx.r5.u64 + ctx.r10.u64;
	// lwzx r6,r5,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// bne cr6,0x830af9c4
	if (!cr6.eq) goto loc_830AF9C4;
	// lwz r10,-16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -16);
	// lwz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// bne cr6,0x830af9c4
	if (!cr6.eq) goto loc_830AF9C4;
	// lwz r28,48(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplw cr6,r9,r28
	cr6.compare<uint32_t>(ctx.r9.u32, r28.u32, xer);
	// bne cr6,0x830af9c4
	if (!cr6.eq) goto loc_830AF9C4;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x830af9f4
	if (cr6.eq) goto loc_830AF9F4;
loc_830AF9C4:
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
loc_830AF9CC:
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// lwz r10,-16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -16);
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// lwz r8,48(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// cmplw cr6,r6,r9
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r9.u32, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
loc_830AF9F4:
	// addi r8,r1,104
	ctx.r8.s64 = ctx.r1.s64 + 104;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// stwx r10,r5,r8
	PPC_STORE_U32(ctx.r5.u32 + ctx.r8.u32, ctx.r10.u32);
	// beq cr6,0x830afa10
	if (cr6.eq) goto loc_830AFA10;
	// lwz r11,64(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
loc_830AFA10:
	// rlwinm r11,r10,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r3
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x830af6a8
	if (!cr6.eq) goto loc_830AF6A8;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplwi cr6,r5,12
	cr6.compare<uint32_t>(ctx.r5.u32, 12, xer);
	// blt cr6,0x830af7d4
	if (cr6.lt) goto loc_830AF7D4;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r11,r31
	r11.u64 = r31.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830afa64
	if (cr6.eq) goto loc_830AFA64;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
loc_830AFA48:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r31,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r31.u32);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x830afa48
	if (cr6.lt) goto loc_830AFA48;
loc_830AFA64:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830afa7c
	if (cr0.eq) goto loc_830AFA7C;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_830AFA7C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x830afa90
	if (!cr6.eq) goto loc_830AFA90;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830afbbc
	goto loc_830AFBBC;
loc_830AFA90:
	// lwz r11,260(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 260);
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// beq cr6,0x830afab4
	if (cr6.eq) goto loc_830AFAB4;
	// lis r4,29376
	ctx.r4.s64 = 1925185536;
	// li r5,6
	ctx.r5.s64 = 6;
	// b 0x830afabc
	goto loc_830AFABC;
loc_830AFAB4:
	// lis r4,29392
	ctx.r4.s64 = 1926234112;
	// li r5,9
	ctx.r5.s64 = 9;
loc_830AFABC:
	// ori r4,r4,3
	ctx.r4.u64 = ctx.r4.u64 | 3;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bge cr6,0x830afae8
	if (!cr6.lt) goto loc_830AFAE8;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x830afbbc
	goto loc_830AFBBC;
loc_830AFAE8:
	// lwz r4,260(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 260);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bge 0x830afb0c
	if (!cr0.lt) goto loc_830AFB0C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// b 0x830afbb8
	goto loc_830AFBB8;
loc_830AFB0C:
	// lwz r11,260(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 260);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// addi r9,r1,104
	ctx.r9.s64 = ctx.r1.s64 + 104;
	// addi r10,r1,120
	ctx.r10.s64 = ctx.r1.s64 + 120;
	// li r11,12
	r11.s64 = 12;
	// addi r9,r9,-12
	ctx.r9.s64 = ctx.r9.s64 + -12;
	// addi r8,r10,-12
	ctx.r8.s64 = ctx.r10.s64 + -12;
loc_830AFB38:
	// lwz r7,260(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 260);
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r6,r9,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r7,8(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lwz r7,0(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// stw r7,-12(r10)
	PPC_STORE_U32(ctx.r10.u32 + -12, ctx.r7.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stwx r6,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r6.u32);
	// bne cr6,0x830afb74
	if (!cr6.eq) goto loc_830AFB74;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r7,r8,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// stw r7,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r7.u32);
loc_830AFB74:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// blt cr6,0x830afb38
	if (cr6.lt) goto loc_830AFB38;
	// lwz r11,256(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 256);
	// lwz r10,24(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830afba8
	if (cr6.eq) goto loc_830AFBA8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830AFBA8:
	// lwz r11,256(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 256);
	// lwz r10,24(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r31,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r31.u32);
loc_830AFBB8:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_830AFBBC:
	// addi r1,r1,464
	ctx.r1.s64 = ctx.r1.s64 + 464;
	// b 0x82ca2c28
	return;
}

__attribute__((alias("__imp__sub_830AFBC8"))) PPC_WEAK_FUNC(sub_830AFBC8);
PPC_FUNC_IMPL(__imp__sub_830AFBC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r30,12(r8)
	r30.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830afd30
	if (cr6.eq) goto loc_830AFD30;
	// lwz r5,24(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
	// lis r4,24768
	ctx.r4.s64 = 1623195648;
	// lis r31,4352
	r31.s64 = 285212672;
loc_830AFBFC:
	// stw r7,256(r8)
	PPC_STORE_U32(ctx.r8.u32 + 256, ctx.r7.u32);
	// lwz r6,0(r5)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplwi r6,0
	cr0.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// stw r6,260(r8)
	PPC_STORE_U32(ctx.r8.u32 + 260, ctx.r6.u32);
	// beq 0x830afd1c
	if (cr0.eq) goto loc_830AFD1C;
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830afd1c
	if (cr6.eq) goto loc_830AFD1C;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// clrlwi r9,r11,12
	ctx.r9.u64 = r11.u32 & 0xFFFFF;
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// bgt cr6,0x830afc84
	if (cr6.gt) goto loc_830AFC84;
	// beq cr6,0x830afdf8
	if (cr6.eq) goto loc_830AFDF8;
	// lis r11,24608
	r11.s64 = 1612709888;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x830afdf0
	if (cr6.eq) goto loc_830AFDF0;
	// lis r11,24624
	r11.s64 = 1613758464;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x830afde8
	if (cr6.eq) goto loc_830AFDE8;
	// lis r11,24688
	r11.s64 = 1617952768;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x830afc6c
	if (cr6.eq) goto loc_830AFC6C;
	// lis r11,24704
	r11.s64 = 1619001344;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830afca8
	if (!cr6.eq) goto loc_830AFCA8;
	// li r11,1
	r11.s64 = 1;
	// b 0x830afe14
	goto loc_830AFE14;
loc_830AFC6C:
	// lhz r11,202(r8)
	r11.u64 = PPC_LOAD_U16(ctx.r8.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830afca8
	if (cr6.eq) goto loc_830AFCA8;
	// li r11,1
	r11.s64 = 1;
loc_830AFC7C:
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x830afe18
	goto loc_830AFE18;
loc_830AFC84:
	// lis r11,24784
	r11.s64 = 1624244224;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x830afe10
	if (cr6.eq) goto loc_830AFE10;
	// lis r11,24848
	r11.s64 = 1628438528;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x830afe08
	if (cr6.eq) goto loc_830AFE08;
	// lis r11,24864
	r11.s64 = 1629487104;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x830afe00
	if (cr6.eq) goto loc_830AFE00;
loc_830AFCA8:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830afcc0
	if (!cr0.eq) goto loc_830AFCC0;
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bne cr6,0x830afd1c
	if (!cr6.eq) goto loc_830AFD1C;
loc_830AFCC0:
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// li r11,0
	r11.s64 = 0;
	// beq cr6,0x830afcd0
	if (cr6.eq) goto loc_830AFCD0;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_830AFCD0:
	// lwz r10,8(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r10,60(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830afd1c
	if (cr6.eq) goto loc_830AFD1C;
	// lhz r10,202(r8)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r8.u32 + 202);
	// cmplwi cr6,r10,260
	cr6.compare<uint32_t>(ctx.r10.u32, 260, xer);
	// beq cr6,0x830afd1c
	if (cr6.eq) goto loc_830AFD1C;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r10,16(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830afe5c
	if (!cr0.eq) goto loc_830AFE5C;
loc_830AFD1C:
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x830afbfc
	if (cr6.lt) goto loc_830AFBFC;
loc_830AFD30:
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830afdcc
	if (cr6.eq) goto loc_830AFDCC;
	// lwz r3,24(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
loc_830AFD40:
	// stw r4,256(r8)
	PPC_STORE_U32(ctx.r8.u32 + 256, ctx.r4.u32);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,260(r8)
	PPC_STORE_U32(ctx.r8.u32 + 260, r11.u32);
	// beq 0x830afdb8
	if (cr0.eq) goto loc_830AFDB8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830afdb8
	if (cr6.eq) goto loc_830AFDB8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830afdb8
	if (!cr6.gt) goto loc_830AFDB8;
	// lwz r7,20(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// lwz r6,128(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 128);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_830AFD7C:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r31,4(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r31,r6
	cr6.compare<uint32_t>(r31.u32, ctx.r6.u32, xer);
	// bne cr6,0x830afda0
	if (!cr6.eq) goto loc_830AFDA0;
	// lbz r9,111(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 111);
	// cmplwi cr6,r9,5
	cr6.compare<uint32_t>(ctx.r9.u32, 5, xer);
	// beq cr6,0x830afe7c
	if (cr6.eq) goto loc_830AFE7C;
loc_830AFDA0:
	// lwz r9,260(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 260);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r5,r9
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r9.u32, xer);
	// blt cr6,0x830afd7c
	if (cr6.lt) goto loc_830AFD7C;
loc_830AFDB8:
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x830afd40
	if (cr6.lt) goto loc_830AFD40;
loc_830AFDCC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830AFDD0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_830AFDE8:
	// li r11,0
	r11.s64 = 0;
	// b 0x830afe14
	goto loc_830AFE14;
loc_830AFDF0:
	// li r11,0
	r11.s64 = 0;
	// b 0x830afc7c
	goto loc_830AFC7C;
loc_830AFDF8:
	// li r11,2
	r11.s64 = 2;
	// b 0x830afc7c
	goto loc_830AFC7C;
loc_830AFE00:
	// li r11,3
	r11.s64 = 3;
	// b 0x830afe14
	goto loc_830AFE14;
loc_830AFE08:
	// li r11,3
	r11.s64 = 3;
	// b 0x830afc7c
	goto loc_830AFC7C;
loc_830AFE10:
	// li r11,2
	r11.s64 = 2;
loc_830AFE14:
	// li r10,0
	ctx.r10.s64 = 0;
loc_830AFE18:
	// lis r7,-31952
	ctx.r7.s64 = -2094006272;
	// lwz r4,60(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + 60);
	// rlwinm r31,r10,2,0,29
	r31.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lbz r9,203(r8)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r8.u32 + 203);
	// addi r10,r7,4216
	ctx.r10.s64 = ctx.r7.s64 + 4216;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r10,16
	r30.s64 = ctx.r10.s64 + 16;
	// lis r7,-32249
	ctx.r7.s64 = -2113470464;
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// addi r6,r7,29220
	ctx.r6.s64 = ctx.r7.s64 + 29220;
	// li r5,4532
	ctx.r5.s64 = 4532;
	// lwzx r7,r11,r10
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r8,r31,r30
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + r30.u32);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830AFE50:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830afdd0
	goto loc_830AFDD0;
loc_830AFE5C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,60(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + 60);
	// li r5,4532
	ctx.r5.s64 = 4532;
	// lbz r7,203(r8)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r8.u32 + 203);
	// addi r6,r11,29172
	ctx.r6.s64 = r11.s64 + 29172;
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// b 0x830afe50
	goto loc_830AFE50;
loc_830AFE7C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// li r5,4512
	ctx.r5.s64 = 4512;
	// addi r6,r10,29108
	ctx.r6.s64 = ctx.r10.s64 + 29108;
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// b 0x830afe50
	goto loc_830AFE50;
}

__attribute__((alias("__imp__sub_830AFE98"))) PPC_WEAK_FUNC(sub_830AFE98);
PPC_FUNC_IMPL(__imp__sub_830AFE98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// li r27,1
	r27.s64 = 1;
	// li r10,2
	ctx.r10.s64 = 2;
	// stw r28,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r28.u32);
	// li r9,3
	ctx.r9.s64 = 3;
	// stw r28,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r28.u32);
	// lhz r11,202(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 202);
	// stw r27,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r27.u32);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// stw r10,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r10.u32);
	// stw r9,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r9.u32);
	// bne cr6,0x830afee0
	if (!cr6.eq) goto loc_830AFEE0;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830b0280
	goto loc_830B0280;
loc_830AFEE0:
	// lwz r4,260(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
	// addi r31,r11,25248
	r31.s64 = r11.s64 + 25248;
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// addi r5,r31,-128
	ctx.r5.s64 = r31.s64 + -128;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// clrlwi r29,r11,12
	r29.u64 = r11.u32 & 0xFFFFF;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// bl 0x83060f70
	sub_83060F70(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b0280
	if (cr0.lt) goto loc_830B0280;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830aff9c
	if (!cr6.eq) goto loc_830AFF9C;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b027c
	if (cr6.eq) goto loc_830B027C;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r7,20(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r11,r1,240
	r11.s64 = ctx.r1.s64 + 240;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// lfd f0,3368(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3368);
loc_830AFF50:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r8
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r8.u32);
	// lwz r6,4(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm. r6,r6,0,23,23
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x830aff88
	if (cr0.eq) goto loc_830AFF88;
	// lfd f13,32(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x830aff88
	if (!cr6.eq) goto loc_830AFF88;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// b 0x830aff8c
	goto loc_830AFF8C;
loc_830AFF88:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_830AFF8C:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830aff50
	if (!cr0.eq) goto loc_830AFF50;
	// b 0x830b00d8
	goto loc_830B00D8;
loc_830AFF9C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,260(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83060f70
	sub_83060F70(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830b0280
	if (!cr0.eq) goto loc_830B0280;
	// lis r11,-32240
	r11.s64 = -2112880640;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lfd f0,2224(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 2224);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b027c
	if (cr6.eq) goto loc_830B027C;
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// lwz r7,16(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_830AFFFC:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r31,4(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r31,r31,2,0,29
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r31,r7
	r31.u64 = PPC_LOAD_U32(r31.u32 + ctx.r7.u32);
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm. r31,r31,0,23,23
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x830b0034
	if (cr0.eq) goto loc_830B0034;
	// lfd f13,32(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x830b0034
	if (!cr6.eq) goto loc_830B0034;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// b 0x830b0038
	goto loc_830B0038;
loc_830B0034:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
loc_830B0038:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830afffc
	if (!cr0.eq) goto loc_830AFFFC;
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq cr6,0x830b0078
	if (cr6.eq) goto loc_830B0078;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// bne cr6,0x830b0078
	if (!cr6.eq) goto loc_830B0078;
	// addi r11,r1,240
	r11.s64 = ctx.r1.s64 + 240;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_830B005C:
	// lwz r9,-48(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + -48);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// stw r8,-48(r11)
	PPC_STORE_U32(r11.u32 + -48, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830b005c
	if (!cr0.eq) goto loc_830B005C;
loc_830B0078:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b027c
	if (cr6.eq) goto loc_830B027C;
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r11,r1,240
	r11.s64 = ctx.r1.s64 + 240;
	// lwz r7,20(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_830B0090:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r8
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r8.u32);
	// lwz r6,4(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm. r6,r6,0,23,23
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x830b00c8
	if (cr0.eq) goto loc_830B00C8;
	// lfd f13,32(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x830b00c8
	if (!cr6.eq) goto loc_830B00C8;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// b 0x830b00cc
	goto loc_830B00CC;
loc_830B00C8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_830B00CC:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830b0090
	if (!cr0.eq) goto loc_830B0090;
loc_830B00D8:
	// cmpwi cr6,r4,1
	cr6.compare<int32_t>(ctx.r4.s32, 1, xer);
	// bne cr6,0x830b027c
	if (!cr6.eq) goto loc_830B027C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830b027c
	if (!cr6.eq) goto loc_830B027C;
	// mr r11,r27
	r11.u64 = r27.u64;
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// ble cr6,0x830b0118
	if (!cr6.gt) goto loc_830B0118;
	// addi r10,r1,196
	ctx.r10.s64 = ctx.r1.s64 + 196;
loc_830B00F8:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r8,192(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b027c
	if (!cr6.eq) goto loc_830B027C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// blt cr6,0x830b00f8
	if (cr6.lt) goto loc_830B00F8;
loc_830B0118:
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// li r8,1807
	ctx.r8.s64 = 1807;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// rlwimi r9,r8,20,0,11
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r8.u32, 20) & 0xFFF00000) | (ctx.r9.u64 & 0xFFFFFFFF000FFFFF);
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// stw r27,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r27.u32);
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// stw r27,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r27.u32);
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// stw r28,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r28.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b019c
	if (!cr6.gt) goto loc_830B019C;
	// lwz r8,136(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 136);
	// rotlwi r9,r11,0
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
loc_830B0170:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x830b0190
	if (!cr6.eq) goto loc_830B0190;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// blt cr6,0x830b0190
	if (cr6.lt) goto loc_830B0190;
	// addi r5,r11,1
	ctx.r5.s64 = r11.s64 + 1;
loc_830B0190:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830b0170
	if (!cr0.eq) goto loc_830B0170;
loc_830B019C:
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,136(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 136);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lfd f1,3376(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3376);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// stw r3,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r3.u32);
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,192(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830b0208
	if (!cr6.eq) goto loc_830B0208;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830b0280
	goto loc_830B0280;
loc_830B0208:
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_830B0210:
	// lwz r9,132(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,136(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r8,8(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stwx r9,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830b0210
	if (!cr0.eq) goto loc_830B0210;
	// rlwinm r10,r29,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r11,r29,2,0,29
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_830B0240:
	// lwz r8,260(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// lwz r8,8(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwzx r7,r10,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwzx r6,r11,r8
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// stwx r7,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r7.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r8,260(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// lwz r8,8(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// stwx r6,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, ctx.r6.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830b0240
	if (!cr0.eq) goto loc_830B0240;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r27,1104(r30)
	PPC_STORE_U32(r30.u32 + 1104, r27.u32);
	// b 0x830b0280
	goto loc_830B0280;
loc_830B027C:
	// li r3,1
	ctx.r3.s64 = 1;
loc_830B0280:
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830B0288"))) PPC_WEAK_FUNC(sub_830B0288);
PPC_FUNC_IMPL(__imp__sub_830B0288) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-416(r1)
	ea = -416 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r26,0
	r26.s64 = 0;
	// li r10,2
	ctx.r10.s64 = 2;
	// li r8,3
	ctx.r8.s64 = 3;
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r26.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r10,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r10.u32);
	// lwz r4,260(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stw r9,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r9.u32);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// stw r8,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r8.u32);
	// addi r29,r11,24928
	r29.s64 = r11.s64 + 24928;
	// stw r26,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r26.u32);
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r26.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// clrlwi r31,r11,12
	r31.u64 = r11.u32 & 0xFFFFF;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r30,r26
	r30.u64 = r26.u64;
	// mr r27,r26
	r27.u64 = r26.u64;
	// bl 0x83060f70
	sub_83060F70(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b0334
	if (cr0.eq) goto loc_830B0334;
	// addi r5,r29,96
	ctx.r5.s64 = r29.s64 + 96;
	// lwz r4,260(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r26.u32);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83060f70
	sub_83060F70(ctx, base);
	// li r27,1
	r27.s64 = 1;
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830b0528
	if (!cr0.eq) goto loc_830B0528;
loc_830B0334:
	// mr r25,r26
	r25.u64 = r26.u64;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x830b03a4
	if (cr6.eq) goto loc_830B03A4;
	// lwz r11,208(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,192(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lwz r8,16(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r9,r11,0,22,22
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830b0388
	if (cr0.eq) goto loc_830B0388;
	// li r25,1
	r25.s64 = 1;
loc_830B0388:
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,22,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x300;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830b03a4
	if (cr0.eq) goto loc_830B03A4;
	// rlwinm. r11,r11,0,22,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x300;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b03a4
	if (cr0.eq) goto loc_830B03A4;
	// li r29,1
	r29.s64 = 1;
	// b 0x830b0544
	goto loc_830B0544;
loc_830B03A4:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b03c0
	if (cr0.eq) goto loc_830B03C0;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830b03c4
	goto loc_830B03C4;
loc_830B03C0:
	// mr r30,r26
	r30.u64 = r26.u64;
loc_830B03C4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x830b03d8
	if (!cr6.eq) goto loc_830B03D8;
	// lis r29,-32761
	r29.s64 = -2147024896;
	// ori r29,r29,14
	r29.u64 = r29.u64 | 14;
	// b 0x830b0544
	goto loc_830B0544;
loc_830B03D8:
	// clrlwi r11,r31,12
	r11.u64 = r31.u32 & 0xFFFFF;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// oris r4,r11,28736
	ctx.r4.u64 = r11.u64 | 1883242496;
	// bne cr6,0x830b03ec
	if (!cr6.eq) goto loc_830B03EC;
	// oris r4,r11,28720
	ctx.r4.u64 = r11.u64 | 1882193920;
loc_830B03EC:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mulli r5,r31,3
	ctx.r5.s64 = r31.s64 * 3;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830b052c
	if (cr0.lt) goto loc_830B052C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,260(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830b052c
	if (cr0.lt) goto loc_830B052C;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b049c
	if (cr6.eq) goto loc_830B049C;
	// rlwinm r8,r31,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r9,r31,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_830B0430:
	// lwz r10,260(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// lwz r7,16(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stwx r10,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r10.u32);
	// addi r10,r1,208
	ctx.r10.s64 = ctx.r1.s64 + 208;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// beq cr6,0x830b0468
	if (cr6.eq) goto loc_830B0468;
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stwx r6,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r6.u32);
	// lwz r6,-16(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + -16);
	// b 0x830b0474
	goto loc_830B0474;
loc_830B0468:
	// lwz r6,-16(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + -16);
	// stwx r6,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r6.u32);
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
loc_830B0474:
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stwx r6,r9,r7
	PPC_STORE_U32(ctx.r9.u32 + ctx.r7.u32, ctx.r6.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stwx r10,r8,r7
	PPC_STORE_U32(ctx.r8.u32 + ctx.r7.u32, ctx.r10.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x830b0430
	if (!cr0.eq) goto loc_830B0430;
loc_830B049C:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b04c8
	if (cr0.eq) goto loc_830B04C8;
	// li r29,1
	r29.s64 = 1;
	// b 0x830b052c
	goto loc_830B052C;
loc_830B04C8:
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r11,r26
	r11.u64 = r26.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b04f8
	if (cr6.eq) goto loc_830B04F8;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
loc_830B04DC:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r26,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r26.u32);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b04dc
	if (cr6.lt) goto loc_830B04DC;
loc_830B04F8:
	// lwz r31,260(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b0514
	if (cr6.eq) goto loc_830B0514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830B0514:
	// lwz r11,256(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 256);
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r30,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r30.u32);
	// mr r30,r26
	r30.u64 = r26.u64;
loc_830B0528:
	// mr r29,r26
	r29.u64 = r26.u64;
loc_830B052C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830b0544
	if (cr6.eq) goto loc_830B0544;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830B0544:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,416
	ctx.r1.s64 = ctx.r1.s64 + 416;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830B0550"))) PPC_WEAK_FUNC(sub_830B0550);
PPC_FUNC_IMPL(__imp__sub_830B0550) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// clrlwi. r10,r11,29
	ctx.r10.u64 = r11.u32 & 0x7;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830b05b8
	if (!cr0.eq) goto loc_830B05B8;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// bge cr6,0x830b0588
	if (!cr6.lt) goto loc_830B0588;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b05d8
	goto loc_830B05D8;
loc_830B0588:
	// bl 0x83079ca8
	sub_83079CA8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x830b05a0
	if (!cr0.eq) goto loc_830B05A0;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830b05d8
	goto loc_830B05D8;
loc_830B05A0:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
loc_830B05B8:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r29,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r29.u32);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
loc_830B05D8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830B05E0"))) PPC_WEAK_FUNC(sub_830B05E0);
PPC_FUNC_IMPL(__imp__sub_830B05E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stwu r1,-1200(r1)
	ea = -1200 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r22,r5
	r22.u64 = ctx.r5.u64;
	// li r23,0
	r23.s64 = 0;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r21,r4
	r21.u64 = ctx.r4.u64;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// beq cr6,0x830b0670
	if (cr6.eq) goto loc_830B0670;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
loc_830B060C:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b0660
	if (cr6.eq) goto loc_830B0660;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830b0658
	if (!cr6.gt) goto loc_830B0658;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
loc_830B062C:
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r5,20(r24)
	ctx.r5.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// lwzx r6,r6,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r5
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// stw r8,72(r6)
	PPC_STORE_U32(ctx.r6.u32 + 72, ctx.r8.u32);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b062c
	if (cr6.lt) goto loc_830B062C;
loc_830B0658:
	// stw r23,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r23.u32);
	// stw r23,20(r11)
	PPC_STORE_U32(r11.u32 + 20, r23.u32);
loc_830B0660:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r8,r22
	cr6.compare<uint32_t>(ctx.r8.u32, r22.u32, xer);
	// blt cr6,0x830b060c
	if (cr6.lt) goto loc_830B060C;
loc_830B0670:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b06bc
	if (!cr6.gt) goto loc_830B06BC;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
loc_830B0684:
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// lwzx r10,r8,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r9,56(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x830b06a8
	if (cr6.eq) goto loc_830B06A8;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// stw r11,72(r10)
	PPC_STORE_U32(ctx.r10.u32 + 72, r11.u32);
loc_830B06A8:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x830b0684
	if (cr6.lt) goto loc_830B0684;
loc_830B06BC:
	// mr r26,r23
	r26.u64 = r23.u64;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x830b07b4
	if (cr6.eq) goto loc_830B07B4;
	// mr r25,r21
	r25.u64 = r21.u64;
loc_830B06CC:
	// lwz r30,0(r25)
	r30.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830b07a4
	if (cr6.eq) goto loc_830B07A4;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r31,r23
	r31.u64 = r23.u64;
	// mr r27,r23
	r27.u64 = r23.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b0780
	if (!cr6.gt) goto loc_830B0780;
	// mr r29,r23
	r29.u64 = r23.u64;
	// addi r28,r1,80
	r28.s64 = ctx.r1.s64 + 80;
loc_830B06F4:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r10,20(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x830b076c
	if (cr6.eq) goto loc_830B076C;
	// mr r11,r23
	r11.u64 = r23.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b0740
	if (cr6.eq) goto loc_830B0740;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
loc_830B0724:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0740
	if (cr6.eq) goto loc_830B0740;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// blt cr6,0x830b0724
	if (cr6.lt) goto loc_830B0724;
loc_830B0740:
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x830b0754
	if (!cr6.eq) goto loc_830B0754;
	// stw r9,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r9.u32);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
loc_830B0754:
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwzx r3,r11,r21
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + r21.u32);
	// bl 0x830b0550
	sub_830B0550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b07b8
	if (cr0.lt) goto loc_830B07B8;
loc_830B076C:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x830b06f4
	if (cr6.lt) goto loc_830B06F4;
loc_830B0780:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079ca8
	sub_83079CA8(ctx, base);
	// stw r3,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b07c0
	if (cr0.eq) goto loc_830B07C0;
	// rlwinm r5,r31,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// stw r31,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r31.u32);
loc_830B07A4:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r26,r22
	cr6.compare<uint32_t>(r26.u32, r22.u32, xer);
	// blt cr6,0x830b06cc
	if (cr6.lt) goto loc_830B06CC;
loc_830B07B4:
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
loc_830B07B8:
	// addi r1,r1,1200
	ctx.r1.s64 = ctx.r1.s64 + 1200;
	// b 0x82ca2c1c
	return;
loc_830B07C0:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830b07b8
	goto loc_830B07B8;
}

__attribute__((alias("__imp__sub_830B07D0"))) PPC_WEAK_FUNC(sub_830B07D0);
PPC_FUNC_IMPL(__imp__sub_830B07D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc0
	// stfd f31,-128(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -128, f31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r19,r6
	r19.u64 = ctx.r6.u64;
	// mr r18,r7
	r18.u64 = ctx.r7.u64;
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// mr r26,r9
	r26.u64 = ctx.r9.u64;
	// li r22,0
	r22.s64 = 0;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830b095c
	if (cr6.eq) goto loc_830B095C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r21,r4
	r21.u64 = ctx.r4.u64;
	// lfd f31,3376(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830B0810:
	// lwz r28,0(r21)
	r28.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b094c
	if (cr6.eq) goto loc_830B094C;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b094c
	if (cr6.eq) goto loc_830B094C;
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// lis r11,4352
	r11.s64 = 285212672;
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830b0848
	if (!cr6.eq) goto loc_830B0848;
	// li r20,1
	r20.s64 = 1;
loc_830B0848:
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b094c
	if (!cr6.gt) goto loc_830B094C;
	// li r29,0
	r29.s64 = 0;
loc_830B085C:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r9,128(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 128);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r10
	r31.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b0938
	if (!cr6.eq) goto loc_830B0938;
	// lbz r11,111(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 111);
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// bne cr6,0x830b0938
	if (!cr6.eq) goto loc_830B0938;
	// lbz r11,110(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 110);
	// cmplw cr6,r18,r11
	cr6.compare<uint32_t>(r18.u32, r11.u32, xer);
	// bne cr6,0x830b0938
	if (!cr6.eq) goto loc_830B0938;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// beq cr6,0x830b08ac
	if (cr6.eq) goto loc_830B08AC;
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b0938
	if (cr6.eq) goto loc_830B0938;
loc_830B08AC:
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830b0930
	if (cr6.eq) goto loc_830B0930;
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r11,r26
	r11.u64 = r26.u64;
loc_830B08C0:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// cmplw cr6,r6,r9
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b08ec
	if (cr6.eq) goto loc_830B08EC;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r30,r24
	cr6.compare<uint32_t>(r30.u32, r24.u32, xer);
	// blt cr6,0x830b08c0
	if (cr6.lt) goto loc_830B08C0;
	// b 0x830b0930
	goto loc_830B0930;
loc_830B08EC:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,136(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 136);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830b096c
	if (cr6.eq) goto loc_830B096C;
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r9,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r9.u32);
	// lwzx r10,r8,r26
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r26.u32);
	// stw r10,56(r11)
	PPC_STORE_U32(r11.u32 + 56, ctx.r10.u32);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// stwx r3,r29,r11
	PPC_STORE_U32(r29.u32 + r11.u32, ctx.r3.u32);
loc_830B0930:
	// cmplw cr6,r30,r24
	cr6.compare<uint32_t>(r30.u32, r24.u32, xer);
	// beq cr6,0x830b0978
	if (cr6.eq) goto loc_830B0978;
loc_830B0938:
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// blt cr6,0x830b085c
	if (cr6.lt) goto loc_830B085C;
loc_830B094C:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// addi r21,r21,4
	r21.s64 = r21.s64 + 4;
	// cmplw cr6,r22,r23
	cr6.compare<uint32_t>(r22.u32, r23.u32, xer);
	// blt cr6,0x830b0810
	if (cr6.lt) goto loc_830B0810;
loc_830B095C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B0960:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lfd f31,-128(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -128);
	// b 0x82ca2c10
	return;
loc_830B096C:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830b0960
	goto loc_830B0960;
loc_830B0978:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4801
	ctx.r5.s64 = 4801;
	// addi r6,r11,29256
	ctx.r6.s64 = r11.s64 + 29256;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b0960
	goto loc_830B0960;
}

__attribute__((alias("__imp__sub_830B09A0"))) PPC_WEAK_FUNC(sub_830B09A0);
PPC_FUNC_IMPL(__imp__sub_830B09A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, f31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r20,r6
	r20.u64 = ctx.r6.u64;
	// mr r19,r7
	r19.u64 = ctx.r7.u64;
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// mr r26,r9
	r26.u64 = ctx.r9.u64;
	// li r22,0
	r22.s64 = 0;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830b0af8
	if (cr6.eq) goto loc_830B0AF8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r21,r4
	r21.u64 = ctx.r4.u64;
	// lfd f31,3376(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830B09E0:
	// lwz r27,0(r21)
	r27.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830b0ae8
	if (cr6.eq) goto loc_830B0AE8;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b0ae8
	if (!cr6.gt) goto loc_830B0AE8;
	// li r28,0
	r28.s64 = 0;
loc_830B0A00:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwz r9,128(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 128);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r10
	r31.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b0ad4
	if (!cr6.eq) goto loc_830B0AD4;
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b0ad4
	if (cr6.eq) goto loc_830B0AD4;
	// lbz r11,111(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 111);
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// bne cr6,0x830b0ad4
	if (!cr6.eq) goto loc_830B0AD4;
	// lbz r11,110(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 110);
	// cmplw cr6,r19,r11
	cr6.compare<uint32_t>(r19.u32, r11.u32, xer);
	// bne cr6,0x830b0ad4
	if (!cr6.eq) goto loc_830B0AD4;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830b0acc
	if (cr6.eq) goto loc_830B0ACC;
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r11,r26
	r11.u64 = r26.u64;
loc_830B0A5C:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// cmplw cr6,r6,r9
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0a88
	if (cr6.eq) goto loc_830B0A88;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r30,r24
	cr6.compare<uint32_t>(r30.u32, r24.u32, xer);
	// blt cr6,0x830b0a5c
	if (cr6.lt) goto loc_830B0A5C;
	// b 0x830b0acc
	goto loc_830B0ACC;
loc_830B0A88:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,136(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 136);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830b0b08
	if (cr6.eq) goto loc_830B0B08;
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r9,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r9.u32);
	// lwzx r10,r8,r26
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r26.u32);
	// stw r10,56(r11)
	PPC_STORE_U32(r11.u32 + 56, ctx.r10.u32);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// stwx r3,r11,r28
	PPC_STORE_U32(r11.u32 + r28.u32, ctx.r3.u32);
loc_830B0ACC:
	// cmplw cr6,r30,r24
	cr6.compare<uint32_t>(r30.u32, r24.u32, xer);
	// beq cr6,0x830b0b14
	if (cr6.eq) goto loc_830B0B14;
loc_830B0AD4:
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// blt cr6,0x830b0a00
	if (cr6.lt) goto loc_830B0A00;
loc_830B0AE8:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// addi r21,r21,4
	r21.s64 = r21.s64 + 4;
	// cmplw cr6,r22,r23
	cr6.compare<uint32_t>(r22.u32, r23.u32, xer);
	// blt cr6,0x830b09e0
	if (cr6.lt) goto loc_830B09E0;
loc_830B0AF8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B0AFC:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// b 0x82ca2c14
	return;
loc_830B0B08:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830b0afc
	goto loc_830B0AFC;
loc_830B0B14:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4802
	ctx.r5.s64 = 4802;
	// addi r6,r11,29256
	ctx.r6.s64 = r11.s64 + 29256;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b0afc
	goto loc_830B0AFC;
}

__attribute__((alias("__imp__sub_830B0B38"))) PPC_WEAK_FUNC(sub_830B0B38);
PPC_FUNC_IMPL(__imp__sub_830B0B38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb4
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r15,r4
	r15.u64 = ctx.r4.u64;
	// mr r16,r5
	r16.u64 = ctx.r5.u64;
	// mr r19,r6
	r19.u64 = ctx.r6.u64;
	// mr r20,r7
	r20.u64 = ctx.r7.u64;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// li r17,0
	r17.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b0d8c
	if (!cr6.gt) goto loc_830B0D8C;
	// li r18,0
	r18.s64 = 0;
loc_830B0B6C:
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// lwzx r29,r18,r11
	r29.u64 = PPC_LOAD_U32(r18.u32 + r11.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b0d78
	if (cr6.eq) goto loc_830B0D78;
	// lwz r11,36(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 36);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x830b0d78
	if (cr6.eq) goto loc_830B0D78;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b0d78
	if (cr6.eq) goto loc_830B0D78;
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r21,0
	r21.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b0d78
	if (!cr6.gt) goto loc_830B0D78;
	// li r22,0
	r22.s64 = 0;
loc_830B0BAC:
	// li r23,0
	r23.s64 = 0;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x830b0c70
	if (cr6.eq) goto loc_830B0C70;
	// mr r24,r15
	r24.u64 = r15.u64;
loc_830B0BBC:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,128(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 128);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// bne cr6,0x830b0be8
	if (!cr6.eq) goto loc_830B0BE8;
	// lbz r10,111(r9)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + 111);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x830b0d98
	if (!cr6.eq) goto loc_830B0D98;
loc_830B0BE8:
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r10,r10,r22
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r22.u32);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x830b0c04
	if (cr6.eq) goto loc_830B0C04;
	// lwz r11,56(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830b0c60
	if (!cr6.eq) goto loc_830B0C60;
loc_830B0C04:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// li r28,0
	r28.s64 = 0;
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// clrlwi r30,r11,12
	r30.u64 = r11.u32 & 0xFFFFF;
	// divwu. r27,r10,r30
	r27.u32 = ctx.r10.u32 / r30.u32;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// twllei r30,0
	// beq 0x830b0c60
	if (cr0.eq) goto loc_830B0C60;
	// li r31,0
	r31.s64 = 0;
	// rlwinm r26,r30,2,0,29
	r26.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
loc_830B0C28:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// add r4,r11,r31
	ctx.r4.u64 = r11.u64 + r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x830b0b38
	sub_830B0B38(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b0d90
	if (cr0.lt) goto loc_830B0D90;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// li r8,1
	ctx.r8.s64 = 1;
	// add r31,r26,r31
	r31.u64 = r26.u64 + r31.u64;
	// cmplw cr6,r28,r27
	cr6.compare<uint32_t>(r28.u32, r27.u32, xer);
	// blt cr6,0x830b0c28
	if (cr6.lt) goto loc_830B0C28;
loc_830B0C60:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// cmplw cr6,r23,r16
	cr6.compare<uint32_t>(r23.u32, r16.u32, xer);
	// blt cr6,0x830b0bbc
	if (cr6.lt) goto loc_830B0BBC;
loc_830B0C70:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// blt cr6,0x830b0bac
	if (cr6.lt) goto loc_830B0BAC;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x830b0d78
	if (cr6.eq) goto loc_830B0D78;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lis r9,24576
	ctx.r9.s64 = 1610612736;
	// rlwinm r11,r10,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0d00
	if (cr6.eq) goto loc_830B0D00;
	// lis r9,24656
	ctx.r9.s64 = 1615855616;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0d00
	if (cr6.eq) goto loc_830B0D00;
	// lis r9,24736
	ctx.r9.s64 = 1621098496;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0d00
	if (cr6.eq) goto loc_830B0D00;
	// lis r9,24816
	ctx.r9.s64 = 1626341376;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0d00
	if (cr6.eq) goto loc_830B0D00;
	// lis r9,29408
	ctx.r9.s64 = 1927282688;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0d00
	if (cr6.eq) goto loc_830B0D00;
	// lis r9,24688
	ctx.r9.s64 = 1617952768;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0d00
	if (cr6.eq) goto loc_830B0D00;
	// lis r9,29376
	ctx.r9.s64 = 1925185536;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0d00
	if (cr6.eq) goto loc_830B0D00;
	// lis r9,29392
	ctx.r9.s64 = 1926234112;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0d00
	if (cr6.eq) goto loc_830B0D00;
	// lis r9,4352
	ctx.r9.s64 = 285212672;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b0d50
	if (!cr6.eq) goto loc_830B0D50;
loc_830B0D00:
	// clrlwi r11,r10,12
	r11.u64 = ctx.r10.u32 & 0xFFFFF;
	// rlwinm r6,r10,1,11,30
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1FFFFE;
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// bge cr6,0x830b0d50
	if (!cr6.lt) goto loc_830B0D50;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r8,136(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 136);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
loc_830B0D28:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// beq cr6,0x830b0dbc
	if (cr6.eq) goto loc_830B0DBC;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b0d28
	if (cr6.lt) goto loc_830B0D28;
loc_830B0D50:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r29,r11,r19
	PPC_STORE_U32(r11.u32 + r19.u32, r29.u32);
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// lwzx r11,r18,r11
	r11.u64 = PPC_LOAD_U32(r18.u32 + r11.u32);
	// stw r10,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r10.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r11.u32);
loc_830B0D78:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r17,r17,1
	r17.s64 = r17.s64 + 1;
	// addi r18,r18,4
	r18.s64 = r18.s64 + 4;
	// cmplw cr6,r17,r11
	cr6.compare<uint32_t>(r17.u32, r11.u32, xer);
	// blt cr6,0x830b0b6c
	if (cr6.lt) goto loc_830B0B6C;
loc_830B0D8C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B0D90:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c04
	return;
loc_830B0D98:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4513
	ctx.r5.s64 = 4513;
	// addi r6,r11,29368
	ctx.r6.s64 = r11.s64 + 29368;
loc_830B0DA4:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwz r4,60(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b0d90
	goto loc_830B0D90;
loc_830B0DBC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4534
	ctx.r5.s64 = 4534;
	// addi r6,r11,29308
	ctx.r6.s64 = r11.s64 + 29308;
	// b 0x830b0da4
	goto loc_830B0DA4;
}

__attribute__((alias("__imp__sub_830B0DD0"))) PPC_WEAK_FUNC(sub_830B0DD0);
PPC_FUNC_IMPL(__imp__sub_830B0DD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// li r21,0
	r21.s64 = 0;
	// mr r14,r5
	r14.u64 = ctx.r5.u64;
	// mr r20,r7
	r20.u64 = ctx.r7.u64;
	// mr r23,r9
	r23.u64 = ctx.r9.u64;
	// stw r14,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, r14.u32);
	// std r21,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r21.u64);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// std r21,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r21.u64);
	// mr r19,r4
	r19.u64 = ctx.r4.u64;
	// mr r18,r6
	r18.u64 = ctx.r6.u64;
	// std r21,16(r11)
	PPC_STORE_U64(r11.u32 + 16, r21.u64);
	// mr r22,r8
	r22.u64 = ctx.r8.u64;
	// add. r30,r20,r23
	r30.u64 = r20.u64 + r23.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// lis r16,24576
	r16.s64 = 1610612736;
	// lis r17,4352
	r17.s64 = 285212672;
	// lis r15,29392
	r15.s64 = 1926234112;
	// mr r31,r21
	r31.u64 = r21.u64;
	// beq 0x830b0f84
	if (cr0.eq) goto loc_830B0F84;
	// rlwinm r11,r20,2,0,29
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r29,r18
	r29.u64 = r18.u64;
	// subf r28,r11,r22
	r28.s64 = r22.s64 - r11.s64;
loc_830B0E38:
	// cmplw cr6,r31,r20
	cr6.compare<uint32_t>(r31.u32, r20.u32, xer);
	// bge cr6,0x830b0e48
	if (!cr6.lt) goto loc_830B0E48;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// b 0x830b0e4c
	goto loc_830B0E4C;
loc_830B0E48:
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
loc_830B0E4C:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b0f70
	if (cr6.eq) goto loc_830B0F70;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b0f70
	if (cr0.eq) goto loc_830B0F70;
	// lwz r9,36(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// beq cr6,0x830b0f70
	if (cr6.eq) goto loc_830B0F70;
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// beq cr6,0x830b0eb4
	if (cr6.eq) goto loc_830B0EB4;
	// lis r9,24656
	ctx.r9.s64 = 1615855616;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0eb4
	if (cr6.eq) goto loc_830B0EB4;
	// lis r9,24736
	ctx.r9.s64 = 1621098496;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0eb4
	if (cr6.eq) goto loc_830B0EB4;
	// lis r9,24816
	ctx.r9.s64 = 1626341376;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0eb4
	if (cr6.eq) goto loc_830B0EB4;
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// beq cr6,0x830b0eb4
	if (cr6.eq) goto loc_830B0EB4;
	// lis r9,29376
	ctx.r9.s64 = 1925185536;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b0eb4
	if (cr6.eq) goto loc_830B0EB4;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// bne cr6,0x830b0ebc
	if (!cr6.eq) goto loc_830B0EBC;
loc_830B0EB4:
	// cmplw cr6,r31,r20
	cr6.compare<uint32_t>(r31.u32, r20.u32, xer);
	// blt cr6,0x830b0f70
	if (cr6.lt) goto loc_830B0F70;
loc_830B0EBC:
	// lwz r3,4(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830b0f70
	if (cr6.eq) goto loc_830B0F70;
	// lwz r6,20(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r5,128(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 128);
	// lwz r7,8(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_830B0ED8:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x830b0f60
	if (!cr6.eq) goto loc_830B0F60;
	// lbz r10,110(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 110);
	// cmplwi cr6,r10,5
	cr6.compare<uint32_t>(ctx.r10.u32, 5, xer);
	// bgt cr6,0x830b0f70
	if (cr6.gt) goto loc_830B0F70;
	// lbz r9,111(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 111);
	// cmplwi cr6,r9,3
	cr6.compare<uint32_t>(ctx.r9.u32, 3, xer);
	// bne cr6,0x830b0f60
	if (!cr6.eq) goto loc_830B0F60;
	// cmplw cr6,r31,r20
	cr6.compare<uint32_t>(r31.u32, r20.u32, xer);
	// blt cr6,0x830b0f40
	if (cr6.lt) goto loc_830B0F40;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r27,r8,r9
	r27.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// cmplw cr6,r10,r27
	cr6.compare<uint32_t>(ctx.r10.u32, r27.u32, xer);
	// ble cr6,0x830b0f60
	if (!cr6.gt) goto loc_830B0F60;
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b0f60
	if (cr6.eq) goto loc_830B0F60;
	// stwx r10,r8,r9
	PPC_STORE_U32(ctx.r8.u32 + ctx.r9.u32, ctx.r10.u32);
	// b 0x830b0f60
	goto loc_830B0F60;
loc_830B0F40:
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r8,r9,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// ble cr6,0x830b0f60
	if (!cr6.gt) goto loc_830B0F60;
	// stwx r11,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, r11.u32);
loc_830B0F60:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r4,r3
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r3.u32, xer);
	// blt cr6,0x830b0ed8
	if (cr6.lt) goto loc_830B0ED8;
loc_830B0F70:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// blt cr6,0x830b0e38
	if (cr6.lt) goto loc_830B0E38;
loc_830B0F84:
	// lwz r11,60(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 60);
	// mr r29,r21
	r29.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b1174
	if (!cr6.gt) goto loc_830B1174;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// addi r25,r1,128
	r25.s64 = ctx.r1.s64 + 128;
	// subf r24,r11,r19
	r24.s64 = r19.s64 - r11.s64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830B0FA8:
	// lwz r28,0(r25)
	r28.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b1160
	if (cr6.eq) goto loc_830B1160;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b0fd0
	if (cr0.eq) goto loc_830B0FD0;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x830b0fd4
	goto loc_830B0FD4;
loc_830B0FD0:
	// mr r27,r21
	r27.u64 = r21.u64;
loc_830B0FD4:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830b11ac
	if (cr6.eq) goto loc_830B11AC;
	// li r11,1825
	r11.s64 = 1825;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,20,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b11b8
	if (cr0.lt) goto loc_830B11B8;
	// mr r30,r21
	r30.u64 = r21.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b107c
	if (cr6.eq) goto loc_830B107C;
	// mr r31,r21
	r31.u64 = r21.u64;
loc_830B1014:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// lwz r4,136(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 136);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// beq cr6,0x830b11d4
	if (cr6.eq) goto loc_830B11D4;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// li r9,3
	ctx.r9.s64 = 3;
	// lwz r8,0(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// li r7,-1
	ctx.r7.s64 = -1;
	// rlwimi r9,r29,8,0,23
	ctx.r9.u64 = (__builtin_rotateleft32(r29.u32, 8) & 0xFFFFFF00) | (ctx.r9.u64 & 0xFFFFFFFF000000FF);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// stwx r3,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r3.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// cmplw cr6,r30,r8
	cr6.compare<uint32_t>(r30.u32, ctx.r8.u32, xer);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r9,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r9.u32);
	// stw r21,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r21.u32);
	// stw r7,56(r11)
	PPC_STORE_U32(r11.u32 + 56, ctx.r7.u32);
	// blt cr6,0x830b1014
	if (cr6.lt) goto loc_830B1014;
loc_830B107C:
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r6,3
	ctx.r6.s64 = 3;
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830b07d0
	sub_830B07D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b11b8
	if (cr0.lt) goto loc_830B11B8;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r6,3
	ctx.r6.s64 = 3;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830b09a0
	sub_830B09A0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b11b8
	if (cr0.lt) goto loc_830B11B8;
	// mr r30,r21
	r30.u64 = r21.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b113c
	if (cr6.eq) goto loc_830B113C;
	// mr r31,r21
	r31.u64 = r21.u64;
loc_830B10DC:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// lwz r4,128(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 128);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// beq cr6,0x830b11d4
	if (cr6.eq) goto loc_830B11D4;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// li r9,3
	ctx.r9.s64 = 3;
	// lwz r8,0(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// rlwimi r9,r29,8,0,23
	ctx.r9.u64 = (__builtin_rotateleft32(r29.u32, 8) & 0xFFFFFF00) | (ctx.r9.u64 & 0xFFFFFFFF000000FF);
	// cmplw cr6,r30,r8
	cr6.compare<uint32_t>(r30.u32, ctx.r8.u32, xer);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r9,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r9.u32);
	// stw r21,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r21.u32);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// stwx r3,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r3.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// blt cr6,0x830b10dc
	if (cr6.lt) goto loc_830B10DC;
loc_830B113C:
	// lwzx r11,r24,r25
	r11.u64 = PPC_LOAD_U32(r24.u32 + r25.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830b11e0
	if (!cr6.eq) goto loc_830B11E0;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b178c
	if (cr0.lt) goto loc_830B178C;
	// stwx r27,r24,r25
	PPC_STORE_U32(r24.u32 + r25.u32, r27.u32);
loc_830B1160:
	// lwz r11,60(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 60);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830b0fa8
	if (cr6.lt) goto loc_830B0FA8;
loc_830B1174:
	// li r23,1
	r23.s64 = 1;
	// mr r22,r23
	r22.u64 = r23.u64;
loc_830B117C:
	// mr r25,r21
	r25.u64 = r21.u64;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x830b1604
	if (cr6.eq) goto loc_830B1604;
	// rlwinm r11,r20,2,0,29
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r27,r18
	r27.u64 = r18.u64;
	// subf r24,r11,r18
	r24.s64 = r18.s64 - r11.s64;
loc_830B1194:
	// cmplwi cr6,r25,512
	cr6.compare<uint32_t>(r25.u32, 512, xer);
	// bge cr6,0x830b1648
	if (!cr6.lt) goto loc_830B1648;
	// cmplw cr6,r25,r20
	cr6.compare<uint32_t>(r25.u32, r20.u32, xer);
	// bge cr6,0x830b1208
	if (!cr6.lt) goto loc_830B1208;
	// lwz r28,0(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// b 0x830b120c
	goto loc_830B120C;
loc_830B11AC:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830b178c
	goto loc_830B178C;
loc_830B11B8:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_830B11BC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x830b178c
	goto loc_830B178C;
loc_830B11D4:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x830b11bc
	goto loc_830B11BC;
loc_830B11E0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lbz r7,203(r26)
	ctx.r7.u64 = PPC_LOAD_U8(r26.u32 + 203);
	// li r5,4516
	ctx.r5.s64 = 4516;
	// addi r6,r11,30112
	ctx.r6.s64 = r11.s64 + 30112;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
	// b 0x830b11bc
	goto loc_830B11BC;
loc_830B1208:
	// lwz r28,0(r24)
	r28.u64 = PPC_LOAD_U32(r24.u32 + 0);
loc_830B120C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b15f0
	if (cr6.eq) goto loc_830B15F0;
	// lwz r11,36(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 36);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x830b15f0
	if (cr6.eq) goto loc_830B15F0;
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r10,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// beq cr6,0x830b1288
	if (cr6.eq) goto loc_830B1288;
	// lis r9,24656
	ctx.r9.s64 = 1615855616;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b1288
	if (cr6.eq) goto loc_830B1288;
	// lis r9,24736
	ctx.r9.s64 = 1621098496;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b1288
	if (cr6.eq) goto loc_830B1288;
	// lis r9,24816
	ctx.r9.s64 = 1626341376;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b1288
	if (cr6.eq) goto loc_830B1288;
	// lis r9,29408
	ctx.r9.s64 = 1927282688;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b1288
	if (cr6.eq) goto loc_830B1288;
	// lis r9,24688
	ctx.r9.s64 = 1617952768;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b1288
	if (cr6.eq) goto loc_830B1288;
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// beq cr6,0x830b1288
	if (cr6.eq) goto loc_830B1288;
	// lis r9,29376
	ctx.r9.s64 = 1925185536;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b1288
	if (cr6.eq) goto loc_830B1288;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// bne cr6,0x830b15f0
	if (!cr6.eq) goto loc_830B15F0;
loc_830B1288:
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// bne cr6,0x830b1298
	if (!cr6.eq) goto loc_830B1298;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
loc_830B1298:
	// lwz r6,8(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r10,r9,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bne cr6,0x830b12c0
	if (!cr6.eq) goto loc_830B12C0;
	// mr r31,r21
	r31.u64 = r21.u64;
	// b 0x830b12cc
	goto loc_830B12CC;
loc_830B12C0:
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r9,r11
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
loc_830B12CC:
	// lwz r5,4(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r4,128(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 128);
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// bne cr6,0x830b1428
	if (!cr6.eq) goto loc_830B1428;
	// lhz r11,202(r26)
	r11.u64 = PPC_LOAD_U16(r26.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830b1428
	if (cr6.eq) goto loc_830B1428;
	// cmplwi cr6,r22,1
	cr6.compare<uint32_t>(r22.u32, 1, xer);
	// bne cr6,0x830b1428
	if (!cr6.eq) goto loc_830B1428;
	// lbz r30,110(r10)
	r30.u64 = PPC_LOAD_U8(ctx.r10.u32 + 110);
	// cmplwi cr6,r30,6
	cr6.compare<uint32_t>(r30.u32, 6, xer);
	// bge cr6,0x830b1604
	if (!cr6.lt) goto loc_830B1604;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b135c
	if (cr6.eq) goto loc_830B135C;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,16(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// andi. r10,r10,2112
	ctx.r10.u64 = ctx.r10.u64 & 2112;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x830b1358
	if (cr0.eq) goto loc_830B1358;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r30,r10
	cr6.compare<uint32_t>(r30.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b135c
	if (cr6.eq) goto loc_830B135C;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r5,4515
	ctx.r5.s64 = 4515;
	// lbz r7,203(r26)
	ctx.r7.u64 = PPC_LOAD_U8(r26.u32 + 203);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r4,60(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 60);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b166c
	if (cr0.eq) goto loc_830B166C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,29992
	ctx.r6.s64 = r11.s64 + 29992;
	// b 0x830b1674
	goto loc_830B1674;
loc_830B1358:
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
loc_830B135C:
	// addi r11,r30,266
	r11.s64 = r30.s64 + 266;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r26
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x830b167c
	if (!cr6.eq) goto loc_830B167C;
	// rlwinm r29,r30,2,0,29
	r29.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r29,r19
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r19.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830b167c
	if (!cr6.eq) goto loc_830B167C;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b1420
	if (cr6.eq) goto loc_830B1420;
	// addi r10,r30,260
	ctx.r10.s64 = r30.s64 + 260;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r10,r26
	PPC_STORE_U32(ctx.r10.u32 + r26.u32, ctx.r9.u32);
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stwx r10,r11,r26
	PPC_STORE_U32(r11.u32 + r26.u32, ctx.r10.u32);
	// lfd f1,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 32);
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r5,12(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r11,r21
	r11.u64 = r21.u64;
	// clrlwi. r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830b13f0
	if (cr0.eq) goto loc_830B13F0;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
loc_830B13D0:
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwx r3,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r3.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// clrlwi r9,r9,12
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFFF;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b13d0
	if (cr6.lt) goto loc_830B13D0;
loc_830B13F0:
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bl 0x8307a2f8
	sub_8307A2F8(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r14,356(r1)
	r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// stw r30,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r30.u32);
	// stw r23,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r23.u32);
	// stw r21,64(r11)
	PPC_STORE_U32(r11.u32 + 64, r21.u32);
loc_830B1420:
	// stwx r28,r29,r19
	PPC_STORE_U32(r29.u32 + r19.u32, r28.u32);
	// b 0x830b15e8
	goto loc_830B15E8;
loc_830B1428:
	// cmplwi cr6,r22,2
	cr6.compare<uint32_t>(r22.u32, 2, xer);
	// bne cr6,0x830b15f0
	if (!cr6.eq) goto loc_830B15F0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b14d4
	if (cr6.eq) goto loc_830B14D4;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r30,6
	cr6.compare<uint32_t>(r30.u32, 6, xer);
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bge cr6,0x830b1604
	if (!cr6.lt) goto loc_830B1604;
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// andi. r11,r11,2112
	r11.u64 = r11.u64 & 2112;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x830b14d4
	if (cr0.eq) goto loc_830B14D4;
	// addi r11,r30,266
	r11.s64 = r30.s64 + 266;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r26
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x830b14a4
	if (!cr6.eq) goto loc_830B14A4;
	// rlwinm r7,r30,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r19
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r19.u32);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x830b14a4
	if (!cr6.eq) goto loc_830B14A4;
	// addi r10,r30,260
	ctx.r10.s64 = r30.s64 + 260;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r10,r26
	PPC_STORE_U32(ctx.r10.u32 + r26.u32, ctx.r9.u32);
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stwx r10,r11,r26
	PPC_STORE_U32(r11.u32 + r26.u32, ctx.r10.u32);
	// b 0x830b15e0
	goto loc_830B15E0;
loc_830B14A4:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830b1698
	if (!cr6.eq) goto loc_830B1698;
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r19
	r11.u64 = PPC_LOAD_U32(r11.u32 + r19.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b15e0
	if (cr6.eq) goto loc_830B15E0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4518
	ctx.r5.s64 = 4518;
	// addi r6,r11,29888
	ctx.r6.s64 = r11.s64 + 29888;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x830b168c
	goto loc_830B168C;
loc_830B14D4:
	// lwz r7,76(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 76);
	// mr r11,r21
	r11.u64 = r21.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830b1524
	if (cr6.eq) goto loc_830B1524;
	// mr r9,r19
	ctx.r9.u64 = r19.u64;
	// addi r10,r26,1064
	ctx.r10.s64 = r26.s64 + 1064;
loc_830B14EC:
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x830b1510
	if (!cr6.eq) goto loc_830B1510;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r8,r3
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r3.u32, xer);
	// beq cr6,0x830b1524
	if (cr6.eq) goto loc_830B1524;
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x830b1524
	if (cr6.eq) goto loc_830B1524;
loc_830B1510:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// blt cr6,0x830b14ec
	if (cr6.lt) goto loc_830B14EC;
loc_830B1524:
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// beq cr6,0x830b16c8
	if (cr6.eq) goto loc_830B16C8;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b15e0
	if (cr6.eq) goto loc_830B15E0;
	// lhz r10,202(r26)
	ctx.r10.u64 = PPC_LOAD_U16(r26.u32 + 202);
	// cmplwi cr6,r10,260
	cr6.compare<uint32_t>(ctx.r10.u32, 260, xer);
	// beq cr6,0x830b154c
	if (cr6.eq) goto loc_830B154C;
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// bne cr6,0x830b1570
	if (!cr6.eq) goto loc_830B1570;
loc_830B154C:
	// addi r10,r11,260
	ctx.r10.s64 = r11.s64 + 260;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,266
	r11.s64 = r11.s64 + 266;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r10,r26
	PPC_STORE_U32(ctx.r10.u32 + r26.u32, ctx.r9.u32);
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stwx r10,r11,r26
	PPC_STORE_U32(r11.u32 + r26.u32, ctx.r10.u32);
loc_830B1570:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lfd f1,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 32);
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r5,12(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r11,r21
	r11.u64 = r21.u64;
	// clrlwi. r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830b15bc
	if (cr0.eq) goto loc_830B15BC;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
loc_830B159C:
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwx r3,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r3.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// clrlwi r9,r9,12
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFFF;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b159c
	if (cr6.lt) goto loc_830B159C;
loc_830B15BC:
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwzx r29,r10,r11
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8307a2f8
	sub_8307A2F8(ctx, base);
	// stw r30,12(r29)
	PPC_STORE_U32(r29.u32 + 12, r30.u32);
	// stw r23,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r23.u32);
	// stw r21,64(r29)
	PPC_STORE_U32(r29.u32 + 64, r21.u32);
loc_830B15E0:
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r28,r11,r19
	PPC_STORE_U32(r11.u32 + r19.u32, r28.u32);
loc_830B15E8:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// stw r23,36(r11)
	PPC_STORE_U32(r11.u32 + 36, r23.u32);
loc_830B15F0:
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r25,r20
	cr6.compare<uint32_t>(r25.u32, r20.u32, xer);
	// blt cr6,0x830b1194
	if (cr6.lt) goto loc_830B1194;
loc_830B1604:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// cmplwi cr6,r22,3
	cr6.compare<uint32_t>(r22.u32, 3, xer);
	// blt cr6,0x830b117c
	if (cr6.lt) goto loc_830B117C;
	// lwz r11,60(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 60);
	// mr r30,r21
	r30.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b171c
	if (!cr6.gt) goto loc_830B171C;
	// mr r31,r19
	r31.u64 = r19.u64;
loc_830B1624:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830b1708
	if (!cr6.eq) goto loc_830B1708;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b16d8
	if (cr0.eq) goto loc_830B16D8;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// b 0x830b16dc
	goto loc_830B16DC;
loc_830B1648:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4514
	ctx.r5.s64 = 4514;
	// addi r6,r11,29872
	ctx.r6.s64 = r11.s64 + 29872;
loc_830B1654:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_830B165C:
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830B1660:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b178c
	goto loc_830B178C;
loc_830B166C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,29760
	ctx.r6.s64 = r11.s64 + 29760;
loc_830B1674:
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// b 0x830b1660
	goto loc_830B1660;
loc_830B167C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,60(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 60);
	// li r5,4516
	ctx.r5.s64 = 4516;
	// addi r6,r11,29672
	ctx.r6.s64 = r11.s64 + 29672;
loc_830B168C:
	// lbz r7,203(r26)
	ctx.r7.u64 = PPC_LOAD_U8(r26.u32 + 203);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// b 0x830b1674
	goto loc_830B1674;
loc_830B1698:
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// li r5,4517
	ctx.r5.s64 = 4517;
	// li r4,0
	ctx.r4.s64 = 0;
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// beq 0x830b16bc
	if (cr0.eq) goto loc_830B16BC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,29536
	ctx.r6.s64 = r11.s64 + 29536;
	// b 0x830b165c
	goto loc_830B165C;
loc_830B16BC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,29496
	ctx.r6.s64 = r11.s64 + 29496;
	// b 0x830b165c
	goto loc_830B165C;
loc_830B16C8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4519
	ctx.r5.s64 = 4519;
	// addi r6,r11,29448
	ctx.r6.s64 = r11.s64 + 29448;
	// b 0x830b1654
	goto loc_830B1654;
loc_830B16D8:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
loc_830B16DC:
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830b11ac
	if (cr6.eq) goto loc_830B11AC;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
loc_830B1708:
	// lwz r11,60(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 60);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830b1624
	if (cr6.lt) goto loc_830B1624;
loc_830B171C:
	// lwz r11,60(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 60);
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// stw r11,0(r14)
	PPC_STORE_U32(r14.u32 + 0, r11.u32);
	// beq cr6,0x830b1788
	if (cr6.eq) goto loc_830B1788;
	// mr r11,r18
	r11.u64 = r18.u64;
	// mr r9,r20
	ctx.r9.u64 = r20.u64;
loc_830B1734:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b177c
	if (cr6.eq) goto loc_830B177C;
	// lwz r8,36(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// beq cr6,0x830b177c
	if (cr6.eq) goto loc_830B177C;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b177c
	if (cr6.eq) goto loc_830B177C;
	// lwz r10,0(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r8,r10,r19
	PPC_STORE_U32(ctx.r10.u32 + r19.u32, ctx.r8.u32);
	// lwz r10,0(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,0(r14)
	PPC_STORE_U32(r14.u32 + 0, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r23,36(r10)
	PPC_STORE_U32(ctx.r10.u32 + 36, r23.u32);
loc_830B177C:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830b1734
	if (!cr0.eq) goto loc_830B1734;
loc_830B1788:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B178C:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82ca2c00
	return;
}

__attribute__((alias("__imp__sub_830B1798"))) PPC_WEAK_FUNC(sub_830B1798);
PPC_FUNC_IMPL(__imp__sub_830B1798) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2be4
	// li r11,0
	r11.s64 = 0;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// bge cr6,0x830b184c
	if (!cr6.lt) goto loc_830B184C;
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// add r30,r11,r4
	r30.u64 = r11.u64 + ctx.r4.u64;
loc_830B17C4:
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830b183c
	if (cr6.eq) goto loc_830B183C;
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b183c
	if (!cr6.gt) goto loc_830B183C;
	// li r10,0
	ctx.r10.s64 = 0;
loc_830B17E4:
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwz r28,20(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// lwzx r11,r27,r28
	r11.u64 = PPC_LOAD_U32(r27.u32 + r28.u32);
	// beq cr6,0x830b180c
	if (cr6.eq) goto loc_830B180C;
	// lwz r28,56(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmplw cr6,r28,r7
	cr6.compare<uint32_t>(r28.u32, ctx.r7.u32, xer);
	// bne cr6,0x830b1828
	if (!cr6.eq) goto loc_830B1828;
loc_830B180C:
	// lwz r28,12(r8)
	r28.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// li r27,1
	r27.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r28,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r28.u32);
	// lwz r28,16(r8)
	r28.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// stw r28,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r28.u32);
	// stw r27,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r27.u32);
loc_830B1828:
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x830b17e4
	if (cr6.lt) goto loc_830B17E4;
loc_830B183C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r31,r6
	cr6.compare<uint32_t>(r31.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b17c4
	if (cr6.lt) goto loc_830B17C4;
loc_830B184C:
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830B1850"))) PPC_WEAK_FUNC(sub_830B1850);
PPC_FUNC_IMPL(__imp__sub_830B1850) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r29,0
	r29.s64 = 0;
	// lwz r11,708(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 708);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b18d0
	if (!cr6.gt) goto loc_830B18D0;
	// li r30,0
	r30.s64 = 0;
loc_830B1874:
	// lwz r11,696(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 696);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwzx r10,r10,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,8(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,696(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 696);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwzx r10,r10,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,16(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,708(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 708);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830b1874
	if (cr6.lt) goto loc_830B1874;
loc_830B18D0:
	// lwz r11,704(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 704);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b1910
	if (!cr6.gt) goto loc_830B1910;
	// li r11,0
	r11.s64 = 0;
loc_830B18E4:
	// lwz r9,700(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 700);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r9,56(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	// stw r9,56(r8)
	PPC_STORE_U32(ctx.r8.u32 + 56, ctx.r9.u32);
	// lwz r9,704(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 704);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b18e4
	if (cr6.lt) goto loc_830B18E4;
loc_830B1910:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830B1920"))) PPC_WEAK_FUNC(sub_830B1920);
PPC_FUNC_IMPL(__imp__sub_830B1920) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, f31.u64);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// li r20,0
	r20.s64 = 0;
	// lis r19,4352
	r19.s64 = 285212672;
	// lwz r23,12(r26)
	r23.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// std r20,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r20.u64);
	// std r20,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r20.u64);
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// std r20,16(r11)
	PPC_STORE_U64(r11.u32 + 16, r20.u64);
	// beq cr6,0x830b1a4c
	if (cr6.eq) goto loc_830B1A4C;
	// lwz r30,24(r26)
	r30.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// mr r28,r23
	r28.u64 = r23.u64;
loc_830B1960:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b1a40
	if (cr6.eq) goto loc_830B1A40;
	// lwz r29,0(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b1a40
	if (cr6.eq) goto loc_830B1A40;
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b1a40
	if (cr6.eq) goto loc_830B1A40;
	// lwz r6,20(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r5,128(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 128);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_830B1994:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r6
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x830b1a30
	if (!cr6.eq) goto loc_830B1A30;
	// lbz r9,110(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 110);
	// cmplwi cr6,r9,5
	cr6.compare<uint32_t>(ctx.r9.u32, 5, xer);
	// bgt cr6,0x830b1a40
	if (cr6.gt) goto loc_830B1A40;
	// lbz r11,111(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 111);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830b1a30
	if (!cr6.eq) goto loc_830B1A30;
	// rlwinm r8,r29,0,0,11
	ctx.r8.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0xFFF00000;
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830b1a04
	if (!cr0.eq) goto loc_830B1A04;
	// cmplw cr6,r8,r19
	cr6.compare<uint32_t>(ctx.r8.u32, r19.u32, xer);
	// beq cr6,0x830b1a04
	if (cr6.eq) goto loc_830B1A04;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r8,r9,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// ble cr6,0x830b1a30
	if (!cr6.gt) goto loc_830B1A30;
	// stwx r11,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, r11.u32);
	// b 0x830b1a30
	goto loc_830B1A30;
loc_830B1A04:
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r3,r8,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// ble cr6,0x830b1a30
	if (!cr6.gt) goto loc_830B1A30;
	// lwz r10,60(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b1a30
	if (cr6.eq) goto loc_830B1A30;
	// stwx r11,r8,r9
	PPC_STORE_U32(ctx.r8.u32 + ctx.r9.u32, r11.u32);
loc_830B1A30:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r4,r31
	cr6.compare<uint32_t>(ctx.r4.u32, r31.u32, xer);
	// blt cr6,0x830b1994
	if (cr6.lt) goto loc_830B1994;
loc_830B1A40:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x830b1960
	if (!cr0.eq) goto loc_830B1960;
loc_830B1A4C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r27,r20
	r27.u64 = r20.u64;
	// addi r25,r1,80
	r25.s64 = ctx.r1.s64 + 80;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830B1A5C:
	// lwz r28,0(r25)
	r28.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b1bb0
	if (cr6.eq) goto loc_830B1BB0;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b1a84
	if (cr0.eq) goto loc_830B1A84;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830b1a88
	goto loc_830B1A88;
loc_830B1A84:
	// mr r30,r20
	r30.u64 = r20.u64;
loc_830B1A88:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830b1c30
	if (cr6.eq) goto loc_830B1C30;
	// li r11,1825
	r11.s64 = 1825;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,20,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b1f80
	if (cr0.lt) goto loc_830B1F80;
	// mr r29,r20
	r29.u64 = r20.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b1b0c
	if (cr6.eq) goto loc_830B1B0C;
	// mr r31,r20
	r31.u64 = r20.u64;
loc_830B1AC8:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lwz r4,136(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 136);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stwx r3,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r3.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830b1c20
	if (cr6.eq) goto loc_830B1C20;
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830b1ac8
	if (cr6.lt) goto loc_830B1AC8;
loc_830B1B0C:
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// li r6,3
	ctx.r6.s64 = 3;
	// lwz r4,24(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830b07d0
	sub_830B07D0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b1c3c
	if (cr0.lt) goto loc_830B1C3C;
	// mr r31,r20
	r31.u64 = r20.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b1b9c
	if (cr6.eq) goto loc_830B1B9C;
	// mr r29,r20
	r29.u64 = r20.u64;
loc_830B1B44:
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// lwz r4,128(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 128);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830b1c50
	if (cr6.eq) goto loc_830B1C50;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// li r9,3
	ctx.r9.s64 = 3;
	// lwz r8,0(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// rlwimi r9,r27,8,0,23
	ctx.r9.u64 = (__builtin_rotateleft32(r27.u32, 8) & 0xFFFFFF00) | (ctx.r9.u64 & 0xFFFFFFFF000000FF);
	// cmplw cr6,r31,r8
	cr6.compare<uint32_t>(r31.u32, ctx.r8.u32, xer);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r9,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r9.u32);
	// stw r20,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r20.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stwx r3,r11,r29
	PPC_STORE_U32(r11.u32 + r29.u32, ctx.r3.u32);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// blt cr6,0x830b1b44
	if (cr6.lt) goto loc_830B1B44;
loc_830B1B9C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b1f80
	if (cr0.lt) goto loc_830B1F80;
loc_830B1BB0:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplwi cr6,r27,6
	cr6.compare<uint32_t>(r27.u32, 6, xer);
	// blt cr6,0x830b1a5c
	if (cr6.lt) goto loc_830B1A5C;
	// mr r24,r20
	r24.u64 = r20.u64;
	// li r21,1
	r21.s64 = 1;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830b1d90
	if (cr6.eq) goto loc_830B1D90;
	// mr r25,r20
	r25.u64 = r20.u64;
loc_830B1BD4:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// lwzx r27,r25,r11
	r27.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// clrlwi r29,r11,12
	r29.u64 = r11.u32 & 0xFFFFF;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830b1c00
	if (!cr0.eq) goto loc_830B1C00;
	// cmplw cr6,r10,r19
	cr6.compare<uint32_t>(ctx.r10.u32, r19.u32, xer);
	// bne cr6,0x830b1d80
	if (!cr6.eq) goto loc_830B1D80;
loc_830B1C00:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// cmplw cr6,r10,r19
	cr6.compare<uint32_t>(ctx.r10.u32, r19.u32, xer);
	// bne cr6,0x830b1c6c
	if (!cr6.eq) goto loc_830B1C6C;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x830b1c80
	goto loc_830B1C80;
loc_830B1C20:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830B1C30:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x830b1f80
	goto loc_830B1F80;
loc_830B1C3C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// b 0x830b1f80
	goto loc_830B1F80;
loc_830B1C50:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830b1f84
	goto loc_830B1F84;
loc_830B1C6C:
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
loc_830B1C80:
	// lwz r10,60(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// rlwinm. r10,r10,0,11,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1F0000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830b1d80
	if (cr0.eq) goto loc_830B1D80;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r10,136(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 136);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b1d80
	if (!cr6.eq) goto loc_830B1D80;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b1cb8
	if (cr0.eq) goto loc_830B1CB8;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x830b1cbc
	goto loc_830B1CBC;
loc_830B1CB8:
	// mr r28,r20
	r28.u64 = r20.u64;
loc_830B1CBC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b1c30
	if (cr6.eq) goto loc_830B1C30;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r21,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r21.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b1f80
	if (cr0.lt) goto loc_830B1F80;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// cmplw cr6,r10,r19
	cr6.compare<uint32_t>(ctx.r10.u32, r19.u32, xer);
	// bne cr6,0x830b1d00
	if (!cr6.eq) goto loc_830B1D00;
	// mr r11,r20
	r11.u64 = r20.u64;
loc_830B1D00:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b1d6c
	if (cr6.eq) goto loc_830B1D6C;
	// mr r31,r20
	r31.u64 = r20.u64;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_830B1D10:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// stwx r11,r31,r9
	PPC_STORE_U32(r31.u32 + ctx.r9.u32, r11.u32);
	// lwz r6,16(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r4,136(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 136);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// stwx r11,r10,r30
	PPC_STORE_U32(ctx.r10.u32 + r30.u32, r11.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x830b1d10
	if (!cr0.eq) goto loc_830B1D10;
loc_830B1D6C:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b1f80
	if (cr0.lt) goto loc_830B1F80;
loc_830B1D80:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r24,r23
	cr6.compare<uint32_t>(r24.u32, r23.u32, xer);
	// blt cr6,0x830b1bd4
	if (cr6.lt) goto loc_830B1BD4;
loc_830B1D90:
	// mr r29,r20
	r29.u64 = r20.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830b1dd4
	if (cr6.eq) goto loc_830B1DD4;
	// mr r30,r20
	r30.u64 = r20.u64;
loc_830B1DA0:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwzx r4,r30,r11
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b1f80
	if (cr0.lt) goto loc_830B1F80;
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmplw cr6,r29,r23
	cr6.compare<uint32_t>(r29.u32, r23.u32, xer);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// stw r20,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r20.u32);
	// blt cr6,0x830b1da0
	if (cr6.lt) goto loc_830B1DA0;
loc_830B1DD4:
	// lwz r22,12(r26)
	r22.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r23,r20
	r23.u64 = r20.u64;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x830b1f74
	if (cr6.eq) goto loc_830B1F74;
	// mr r24,r20
	r24.u64 = r20.u64;
loc_830B1DE8:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// lwzx r27,r24,r11
	r27.u64 = PPC_LOAD_U32(r24.u32 + r11.u32);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b1f64
	if (cr6.eq) goto loc_830B1F64;
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// clrlwi r25,r11,12
	r25.u64 = r11.u32 & 0xFFFFF;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830b1e1c
	if (!cr0.eq) goto loc_830B1E1C;
	// cmplw cr6,r10,r19
	cr6.compare<uint32_t>(ctx.r10.u32, r19.u32, xer);
	// bne cr6,0x830b1f54
	if (!cr6.eq) goto loc_830B1F54;
loc_830B1E1C:
	// cmplw cr6,r10,r19
	cr6.compare<uint32_t>(ctx.r10.u32, r19.u32, xer);
	// mr r11,r20
	r11.u64 = r20.u64;
	// beq cr6,0x830b1e2c
	if (cr6.eq) goto loc_830B1E2C;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_830B1E2C:
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r9,16(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r9,r11,0,22,22
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830b1e74
	if (!cr0.eq) goto loc_830B1E74;
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b1f54
	if (cr0.eq) goto loc_830B1F54;
	// lbz r11,111(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 111);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x830b1f54
	if (!cr6.eq) goto loc_830B1F54;
loc_830B1E74:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b1e90
	if (cr0.eq) goto loc_830B1E90;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x830b1e94
	goto loc_830B1E94;
loc_830B1E90:
	// mr r29,r20
	r29.u64 = r20.u64;
loc_830B1E94:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b1c30
	if (cr6.eq) goto loc_830B1C30;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r21,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r21.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b1f80
	if (cr0.lt) goto loc_830B1F80;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b1f80
	if (cr0.lt) goto loc_830B1F80;
	// mr r28,r20
	r28.u64 = r20.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830b1f48
	if (cr6.eq) goto loc_830B1F48;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r31,r20
	r31.u64 = r20.u64;
loc_830B1EE8:
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// stwx r11,r31,r10
	PPC_STORE_U32(r31.u32 + ctx.r10.u32, r11.u32);
	// lwz r4,136(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 136);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// stwx r11,r30,r10
	PPC_STORE_U32(r30.u32 + ctx.r10.u32, r11.u32);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwzx r10,r11,r30
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830b1c30
	if (cr6.eq) goto loc_830B1C30;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r28,r25
	cr6.compare<uint32_t>(r28.u32, r25.u32, xer);
	// blt cr6,0x830b1ee8
	if (cr6.lt) goto loc_830B1EE8;
loc_830B1F48:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8307a808
	sub_8307A808(ctx, base);
loc_830B1F54:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// stw r20,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r20.u32);
loc_830B1F64:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// cmplw cr6,r23,r22
	cr6.compare<uint32_t>(r23.u32, r22.u32, xer);
	// blt cr6,0x830b1de8
	if (cr6.lt) goto loc_830B1DE8;
loc_830B1F74:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8307f3a8
	sub_8307F3A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_830B1F80:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_830B1F84:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// lfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// b 0x82ca2c14
	return;
}

__attribute__((alias("__imp__sub_830B1F90"))) PPC_WEAK_FUNC(sub_830B1F90);
PPC_FUNC_IMPL(__imp__sub_830B1F90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r5,12(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x830b05e0
	sub_830B05E0(ctx, base);
	// mr. r27,r3
	r27.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// blt 0x830b2060
	if (cr0.lt) goto loc_830B2060;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r29,0
	r29.s64 = 0;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b1ff8
	if (!cr6.gt) goto loc_830B1FF8;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_830B1FCC:
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stw r29,40(r9)
	PPC_STORE_U32(ctx.r9.u32 + 40, r29.u32);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r29,36(r9)
	PPC_STORE_U32(ctx.r9.u32 + 36, r29.u32);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b1fcc
	if (cr6.lt) goto loc_830B1FCC;
loc_830B1FF8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r28,r29
	r28.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b2060
	if (!cr6.gt) goto loc_830B2060;
loc_830B2008:
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r30,r29,r4
	r30.u64 = PPC_LOAD_U32(r29.u32 + ctx.r4.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830b2034
	if (!cr0.eq) goto loc_830B2034;
	// lis r11,4352
	r11.s64 = 285212672;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830b204c
	if (!cr6.eq) goto loc_830B204C;
loc_830B2034:
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r26,36(r30)
	r26.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830617f0
	sub_830617F0(ctx, base);
	// stw r26,36(r30)
	PPC_STORE_U32(r30.u32 + 36, r26.u32);
loc_830B204C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x830b2008
	if (cr6.lt) goto loc_830B2008;
loc_830B2060:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

__attribute__((alias("__imp__sub_830B2070"))) PPC_WEAK_FUNC(sub_830B2070);
PPC_FUNC_IMPL(__imp__sub_830B2070) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b20fc
	if (!cr6.gt) goto loc_830B20FC;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r6,r10,1108
	ctx.r6.s64 = ctx.r10.s64 + 1108;
loc_830B209C:
	// lwz r11,24(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r11,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830b20d4
	if (!cr0.eq) goto loc_830B20D4;
	// lis r11,29200
	r11.s64 = 1913651200;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x830b20d4
	if (cr6.eq) goto loc_830B20D4;
	// lis r11,4352
	r11.s64 = 285212672;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x830b20e8
	if (!cr6.eq) goto loc_830B20E8;
loc_830B20D4:
	// cmplwi cr6,r5,12
	cr6.compare<uint32_t>(ctx.r5.u32, 12, xer);
	// bge cr6,0x830b2118
	if (!cr6.lt) goto loc_830B2118;
	// stw r7,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r7.u32);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
loc_830B20E8:
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x830b209c
	if (cr6.lt) goto loc_830B209C;
loc_830B20FC:
	// li r11,1
	r11.s64 = 1;
	// stw r5,1156(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1156, ctx.r5.u32);
	// slw r3,r11,r5
	ctx.r3.u64 = ctx.r5.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r5.u8 & 0x3F));
loc_830B2108:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_830B2118:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x830b2108
	goto loc_830B2108;
}

__attribute__((alias("__imp__sub_830B2120"))) PPC_WEAK_FUNC(sub_830B2120);
PPC_FUNC_IMPL(__imp__sub_830B2120) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r3,r11,0,0,11
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b2184
	if (cr0.eq) goto loc_830B2184;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2184
	if (cr6.eq) goto loc_830B2184;
	// cmplwi cr6,r27,1
	cr6.compare<uint32_t>(r27.u32, 1, xer);
	// blt cr6,0x830b2180
	if (cr6.lt) goto loc_830B2180;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,60(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// li r5,4500
	ctx.r5.s64 = 4500;
	// addi r6,r11,30180
	ctx.r6.s64 = r11.s64 + 30180;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830B2178:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830b21d8
	goto loc_830B21D8;
loc_830B2180:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
loc_830B2184:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b21d4
	if (!cr6.gt) goto loc_830B21D4;
	// li r30,0
	r30.s64 = 0;
loc_830B2198:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x830b2120
	sub_830B2120(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b2178
	if (cr0.eq) goto loc_830B2178;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830b2198
	if (cr6.lt) goto loc_830B2198;
loc_830B21D4:
	// li r3,1
	ctx.r3.s64 = 1;
loc_830B21D8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830B21E0"))) PPC_WEAK_FUNC(sub_830B21E0);
PPC_FUNC_IMPL(__imp__sub_830B21E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r25,0
	r25.s64 = 0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,64
	cr6.compare<uint32_t>(r11.u32, 64, xer);
	// ble cr6,0x830b221c
	if (!cr6.gt) goto loc_830B221C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4500
	ctx.r5.s64 = 4500;
	// addi r6,r11,30316
	ctx.r6.s64 = r11.s64 + 30316;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830b2324
	goto loc_830B2324;
loc_830B221C:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2250
	if (cr6.eq) goto loc_830B2250;
	// li r11,0
	r11.s64 = 0;
loc_830B222C:
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r8,40(r9)
	PPC_STORE_U32(ctx.r9.u32 + 40, ctx.r8.u32);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b222c
	if (cr6.lt) goto loc_830B222C;
loc_830B2250:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b2320
	if (!cr6.gt) goto loc_830B2320;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r28,0
	r28.s64 = 0;
	// addi r27,r11,30240
	r27.s64 = r11.s64 + 30240;
loc_830B226C:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b22ec
	if (cr6.eq) goto loc_830B22EC;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b22ec
	if (!cr6.gt) goto loc_830B22EC;
	// li r30,0
	r30.s64 = 0;
loc_830B2298:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwzx r9,r9,r30
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r30.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lbz r10,111(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 111);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x830b22d4
	if (!cr6.eq) goto loc_830B22D4;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// li r5,4500
	ctx.r5.s64 = 4500;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r25,1
	r25.s64 = 1;
loc_830B22D4:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830b2298
	if (cr6.lt) goto loc_830B2298;
loc_830B22EC:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,260(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2120
	sub_830B2120(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b231c
	if (cr0.eq) goto loc_830B231C;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x830b226c
	if (cr6.lt) goto loc_830B226C;
	// b 0x830b2320
	goto loc_830B2320;
loc_830B231C:
	// li r25,1
	r25.s64 = 1;
loc_830B2320:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_830B2324:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830B2330"))) PPC_WEAK_FUNC(sub_830B2330);
PPC_FUNC_IMPL(__imp__sub_830B2330) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r30{};
	PPCRegister r31{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x830b2410
	if (!cr6.eq) goto loc_830B2410;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830b256c
	if (cr6.eq) goto loc_830B256C;
loc_830B234C:
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lis r9,4352
	ctx.r9.s64 = 285212672;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b23f4
	if (cr6.eq) goto loc_830B23F4;
	// lis r9,29200
	ctx.r9.s64 = 1913651200;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b23f4
	if (cr6.eq) goto loc_830B23F4;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r30,16(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r30
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r30.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// andi. r9,r9,2112
	ctx.r9.u64 = ctx.r9.u64 & 2112;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x830b23f4
	if (cr0.eq) goto loc_830B23F4;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bge cr6,0x830b2408
	if (!cr6.lt) goto loc_830B2408;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r4
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x830b2408
	if (!cr6.eq) goto loc_830B2408;
	// lwzx r9,r11,r5
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x830b23d4
	if (!cr6.eq) goto loc_830B23D4;
	// stwx r8,r11,r5
	PPC_STORE_U32(r11.u32 + ctx.r5.u32, ctx.r8.u32);
	// b 0x830b23dc
	goto loc_830B23DC;
loc_830B23D4:
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b2408
	if (!cr6.eq) goto loc_830B2408;
loc_830B23DC:
	// li r9,0
	ctx.r9.s64 = 0;
	// stwx r10,r11,r4
	PPC_STORE_U32(r11.u32 + ctx.r4.u32, ctx.r10.u32);
	// stw r9,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r9.u32);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stwx r10,r11,r5
	PPC_STORE_U32(r11.u32 + ctx.r5.u32, ctx.r10.u32);
loc_830B23F4:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r31,r7
	cr6.compare<uint32_t>(r31.u32, ctx.r7.u32, xer);
	// blt cr6,0x830b234c
	if (cr6.lt) goto loc_830B234C;
	// b 0x830b256c
	goto loc_830B256C;
loc_830B2408:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830b2570
	goto loc_830B2570;
loc_830B2410:
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// bne cr6,0x830b24d0
	if (!cr6.eq) goto loc_830B24D0;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830b256c
	if (cr6.eq) goto loc_830B256C;
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
loc_830B2428:
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830b24bc
	if (cr6.eq) goto loc_830B24BC;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lis r10,4352
	ctx.r10.s64 = 285212672;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b24bc
	if (cr6.eq) goto loc_830B24BC;
	// lis r10,29200
	ctx.r10.s64 = 1913651200;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b24bc
	if (cr6.eq) goto loc_830B24BC;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// subf r6,r5,r4
	ctx.r6.s64 = ctx.r4.s64 - ctx.r5.s64;
loc_830B2460:
	// lwzx r8,r6,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x830b2488
	if (!cr6.eq) goto loc_830B2488;
	// lwz r30,8(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r30,0(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r8,r30
	cr6.compare<uint32_t>(ctx.r8.u32, r30.u32, xer);
	// beq cr6,0x830b2498
	if (cr6.eq) goto loc_830B2498;
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x830b2498
	if (cr6.eq) goto loc_830B2498;
loc_830B2488:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// blt cr6,0x830b2460
	if (cr6.lt) goto loc_830B2460;
loc_830B2498:
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// beq cr6,0x830b2408
	if (cr6.eq) goto loc_830B2408;
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stwx r11,r10,r5
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, r11.u32);
	// stwx r9,r10,r4
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, ctx.r9.u32);
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
loc_830B24BC:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// cmplw cr6,r31,r7
	cr6.compare<uint32_t>(r31.u32, ctx.r7.u32, xer);
	// blt cr6,0x830b2428
	if (cr6.lt) goto loc_830B2428;
	// b 0x830b256c
	goto loc_830B256C;
loc_830B24D0:
	// cmplwi cr6,r8,2
	cr6.compare<uint32_t>(ctx.r8.u32, 2, xer);
	// bne cr6,0x830b256c
	if (!cr6.eq) goto loc_830B256C;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830b256c
	if (cr6.eq) goto loc_830B256C;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
loc_830B24E8:
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830b255c
	if (cr6.eq) goto loc_830B255C;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lis r10,4352
	ctx.r10.s64 = 285212672;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b2514
	if (cr6.eq) goto loc_830B2514;
	// lis r10,29200
	ctx.r10.s64 = 1913651200;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b255c
	if (!cr6.eq) goto loc_830B255C;
loc_830B2514:
	// li r11,0
	r11.s64 = 0;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_830B251C:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830b2538
	if (cr6.eq) goto loc_830B2538;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// blt cr6,0x830b251c
	if (cr6.lt) goto loc_830B251C;
loc_830B2538:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// beq cr6,0x830b2408
	if (cr6.eq) goto loc_830B2408;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stwx r10,r11,r5
	PPC_STORE_U32(r11.u32 + ctx.r5.u32, ctx.r10.u32);
	// stwx r9,r11,r4
	PPC_STORE_U32(r11.u32 + ctx.r4.u32, ctx.r9.u32);
	// stw r6,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r6.u32);
loc_830B255C:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r3,r7
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r7.u32, xer);
	// blt cr6,0x830b24e8
	if (cr6.lt) goto loc_830B24E8;
loc_830B256C:
	// li r3,1
	ctx.r3.s64 = 1;
loc_830B2570:
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830B2580"))) PPC_WEAK_FUNC(sub_830B2580);
PPC_FUNC_IMPL(__imp__sub_830B2580) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r24,0
	r24.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_830B25A0:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b25bc
	if (cr6.eq) goto loc_830B25BC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r10,-1
	ctx.r9.s64 = ctx.r10.s64 + -1;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// and r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ctx.r10.u64;
	// blt cr6,0x830b25a0
	if (cr6.lt) goto loc_830B25A0;
loc_830B25BC:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bgt cr6,0x830b2a24
	if (cr6.gt) goto loc_830B2A24;
	// lwz r10,1156(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1156);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bgt cr6,0x830b2a24
	if (cr6.gt) goto loc_830B2A24;
	// mr r30,r24
	r30.u64 = r24.u64;
	// mr r29,r24
	r29.u64 = r24.u64;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b26a0
	if (cr6.eq) goto loc_830B26A0;
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r8,r31,1108
	ctx.r8.s64 = r31.s64 + 1108;
loc_830B25F8:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r10,r10,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r7.u8 & 0x3F));
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// and. r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 & ctx.r4.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r10,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// beq 0x830b2638
	if (cr0.eq) goto loc_830B2638;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x830b2a24
	if (cr6.eq) goto loc_830B2A24;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// b 0x830b268c
	goto loc_830B268C;
loc_830B2638:
	// lis r27,4352
	r27.s64 = 285212672;
	// cmplw cr6,r9,r27
	cr6.compare<uint32_t>(ctx.r9.u32, r27.u32, xer);
	// beq cr6,0x830b2a24
	if (cr6.eq) goto loc_830B2A24;
	// lis r27,29200
	r27.s64 = 1913651200;
	// cmplw cr6,r9,r27
	cr6.compare<uint32_t>(ctx.r9.u32, r27.u32, xer);
	// beq cr6,0x830b2680
	if (cr6.eq) goto loc_830B2680;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r10,r10,2,10,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x3FFFFC;
	// lwz r27,20(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r27
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r27.u32);
	// lbz r9,111(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 111);
	// cmplwi cr6,r9,3
	cr6.compare<uint32_t>(ctx.r9.u32, 3, xer);
	// bne cr6,0x830b2a24
	if (!cr6.eq) goto loc_830B2A24;
	// lwz r10,60(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830b2a24
	if (!cr6.eq) goto loc_830B2A24;
loc_830B2680:
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
loc_830B268C:
	// lwz r11,1156(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1156);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x830b25f8
	if (cr6.lt) goto loc_830B25F8;
loc_830B26A0:
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// li r11,-1
	r11.s64 = -1;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// std r11,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, r11.u64);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// std r11,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, r11.u64);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// std r11,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, r11.u64);
	// bl 0x830b2330
	sub_830B2330(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b2a24
	if (cr0.eq) goto loc_830B2A24;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2330
	sub_830B2330(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b2a24
	if (cr0.eq) goto loc_830B2A24;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2330
	sub_830B2330(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b2a24
	if (cr0.eq) goto loc_830B2A24;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2330
	sub_830B2330(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b2a24
	if (cr0.eq) goto loc_830B2A24;
	// li r8,2
	ctx.r8.s64 = 2;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2330
	sub_830B2330(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b2a24
	if (cr0.eq) goto loc_830B2A24;
	// li r8,2
	ctx.r8.s64 = 2;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2330
	sub_830B2330(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b2a24
	if (cr0.eq) goto loc_830B2A24;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x830b2a10
	if (!cr6.eq) goto loc_830B2A10;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// mr r25,r24
	r25.u64 = r24.u64;
	// mr r30,r24
	r30.u64 = r24.u64;
	// std r24,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r24.u64);
	// std r24,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, r24.u64);
	// std r24,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r24.u64);
	// std r24,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, r24.u64);
	// std r24,16(r11)
	PPC_STORE_U64(r11.u32 + 16, r24.u64);
	// std r24,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, r24.u64);
loc_830B27BC:
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// lwzx r11,r30,r10
	r11.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830b27dc
	if (!cr6.eq) goto loc_830B27DC;
	// lwz r9,564(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r9,r30,r9
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830b29c0
	if (cr6.eq) goto loc_830B29C0;
loc_830B27DC:
	// mr r27,r24
	r27.u64 = r24.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b27f8
	if (cr6.eq) goto loc_830B27F8;
	// lwzx r11,r30,r10
	r11.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r3,r11,0,0,11
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
loc_830B27F8:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r9,r30,r11
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830b2814
	if (cr6.eq) goto loc_830B2814;
	// rotlwi r11,r9,0
	r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r27,r11,0,0,11
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
loc_830B2814:
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// mr. r26,r3
	r26.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// bne 0x830b2830
	if (!cr0.eq) goto loc_830B2830;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b29c0
	if (cr0.eq) goto loc_830B29C0;
loc_830B2830:
	// li r29,-1
	r29.s64 = -1;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x830b28e8
	if (cr6.eq) goto loc_830B28E8;
	// lwzx r11,r30,r10
	r11.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r11,r10
	r28.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lfd f1,32(r28)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r28.u32 + 32);
	// lwz r6,16(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// lwz r4,4(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x830b2a24
	if (cr6.eq) goto loc_830B2A24;
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r11,r24
	r11.u64 = r24.u64;
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// clrlwi. r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830b28c4
	if (cr0.eq) goto loc_830B28C4;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_830B2894:
	// lwz r9,560(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r9,r30,r9
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// lwz r9,8(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// stwx r29,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, r29.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,560(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// lwzx r9,r30,r9
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// clrlwi r9,r9,12
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFFF;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b2894
	if (cr6.lt) goto loc_830B2894;
loc_830B28C4:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwzx r23,r10,r11
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stwx r28,r30,r9
	PPC_STORE_U32(r30.u32 + ctx.r9.u32, r28.u32);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8307a2f8
	sub_8307A2F8(ctx, base);
	// stw r25,12(r23)
	PPC_STORE_U32(r23.u32 + 12, r25.u32);
loc_830B28E8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b29b8
	if (cr0.eq) goto loc_830B29B8;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r11,r10
	r28.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bne cr6,0x830b2940
	if (!cr6.eq) goto loc_830B2940;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfd f1,32(r28)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r28.u32 + 32);
	// lwz r6,16(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// lwz r4,4(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x830b2a24
	if (cr6.eq) goto loc_830B2A24;
loc_830B2940:
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r11,r24
	r11.u64 = r24.u64;
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// clrlwi. r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830b298c
	if (cr0.eq) goto loc_830B298C;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_830B295C:
	// lwz r9,564(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r9,r30,r9
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// lwz r9,8(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// stwx r29,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, r29.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,564(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r9,r30,r9
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// clrlwi r9,r9,12
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFFF;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b295c
	if (cr6.lt) goto loc_830B295C;
loc_830B298C:
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// stwx r28,r30,r11
	PPC_STORE_U32(r30.u32 + r11.u32, r28.u32);
	// bne cr6,0x830b29b8
	if (!cr6.eq) goto loc_830B29B8;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwzx r28,r10,r11
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8307a2f8
	sub_8307A2F8(ctx, base);
	// stw r25,12(r28)
	PPC_STORE_U32(r28.u32 + 12, r25.u32);
loc_830B29B8:
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x830b2a24
	if (cr6.eq) goto loc_830B2A24;
loc_830B29C0:
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// cmplwi cr6,r30,24
	cr6.compare<uint32_t>(r30.u32, 24, xer);
	// blt cr6,0x830b27bc
	if (cr6.lt) goto loc_830B27BC;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_830B29D4:
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b29ec
	if (cr6.eq) goto loc_830B29EC;
	// lwz r9,116(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
loc_830B29EC:
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2a04
	if (cr6.eq) goto loc_830B2A04;
	// lwz r9,116(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
loc_830B2A04:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r10,24
	cr6.compare<uint32_t>(ctx.r10.u32, 24, xer);
	// blt cr6,0x830b29d4
	if (cr6.lt) goto loc_830B29D4;
loc_830B2A10:
	// li r11,6
	r11.s64 = 6;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r11.u32);
	// stw r11,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r11.u32);
	// b 0x830b2a28
	goto loc_830B2A28;
loc_830B2A24:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B2A28:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82ca2c24
	return;
}

__attribute__((alias("__imp__sub_830B2A30"))) PPC_WEAK_FUNC(sub_830B2A30);
PPC_FUNC_IMPL(__imp__sub_830B2A30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r16,0
	r16.s64 = 0;
	// stw r4,428(r1)
	PPC_STORE_U32(ctx.r1.u32 + 428, ctx.r4.u32);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
	// mr r15,r16
	r15.u64 = r16.u64;
	// mr r18,r16
	r18.u64 = r16.u64;
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// mr r21,r16
	r21.u64 = r16.u64;
	// li r17,-1
	r17.s64 = -1;
	// li r14,-1
	r14.s64 = -1;
loc_830B2A64:
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// lwzx r11,r21,r11
	r11.u64 = PPC_LOAD_U32(r21.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2c04
	if (cr6.eq) goto loc_830B2C04;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2c04
	if (cr6.eq) goto loc_830B2C04;
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r20,r16
	r20.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b2c04
	if (!cr6.gt) goto loc_830B2C04;
	// mr r19,r16
	r19.u64 = r16.u64;
loc_830B2A94:
	// lwz r24,564(r31)
	r24.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r23,r24,r19
	r23.u64 = PPC_LOAD_U32(r24.u32 + r19.u32);
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830b2bec
	if (cr6.eq) goto loc_830B2BEC;
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2bec
	if (cr6.eq) goto loc_830B2BEC;
	// li r9,6
	ctx.r9.s64 = 6;
	// clrlwi. r10,r11,12
	ctx.r10.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// subfc r11,r9,r20
	xer.ca = r20.u32 >= ctx.r9.u32;
	r11.s64 = r20.s64 - ctx.r9.s64;
	// mr r22,r16
	r22.u64 = r16.u64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r27,r11,31
	r27.u64 = r11.u32 & 0x1;
	// beq 0x830b2bec
	if (cr0.eq) goto loc_830B2BEC;
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r25,r16
	r25.u64 = r16.u64;
	// lwz r29,4(r23)
	r29.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// twllei r10,0
	// divwu r28,r29,r10
	r28.u32 = r29.u32 / ctx.r10.u32;
	// lwzx r5,r21,r11
	ctx.r5.u64 = PPC_LOAD_U32(r21.u32 + r11.u32);
	// lwz r11,12(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b2bec
	if (!cr6.gt) goto loc_830B2BEC;
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// lwzx r11,r21,r11
	r11.u64 = PPC_LOAD_U32(r21.u32 + r11.u32);
	// lwz r26,12(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_830B2B00:
	// cmplw cr6,r27,r28
	cr6.compare<uint32_t>(r27.u32, r28.u32, xer);
	// bge cr6,0x830b2bb4
	if (!cr6.lt) goto loc_830B2BB4;
	// mullw r11,r10,r27
	r11.s64 = int64_t(ctx.r10.s32) * int64_t(r27.s32);
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r30,r10,2,0,29
	r30.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r3,r27,r28
	ctx.r3.s64 = r28.s64 - r27.s64;
loc_830B2B18:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b2ba8
	if (cr6.eq) goto loc_830B2BA8;
	// lwz r8,16(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// mr r6,r10
	ctx.r6.u64 = ctx.r10.u64;
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// add r9,r11,r7
	ctx.r9.u64 = r11.u64 + ctx.r7.u64;
	// lwzx r8,r8,r4
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
loc_830B2B34:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x830b2b5c
	if (cr6.eq) goto loc_830B2B5C;
	// lwz r14,20(r31)
	r14.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r14
	r11.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b2b98
	if (!cr6.eq) goto loc_830B2B98;
	// li r14,-1
	r14.s64 = -1;
loc_830B2B5C:
	// cmplw cr6,r20,r18
	cr6.compare<uint32_t>(r20.u32, r18.u32, xer);
	// ble cr6,0x830b2b9c
	if (!cr6.gt) goto loc_830B2B9C;
	// lwzx r11,r24,r21
	r11.u64 = PPC_LOAD_U32(r24.u32 + r21.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2b9c
	if (cr6.eq) goto loc_830B2B9C;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2b9c
	if (cr6.eq) goto loc_830B2B9C;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// lis r14,4352
	r14.s64 = 285212672;
	// cmplw cr6,r11,r14
	cr6.compare<uint32_t>(r11.u32, r14.u32, xer);
	// beq cr6,0x830b2b98
	if (cr6.eq) goto loc_830B2B98;
	// li r25,1
	r25.s64 = 1;
	// mr r22,r5
	r22.u64 = ctx.r5.u64;
loc_830B2B98:
	// li r14,-1
	r14.s64 = -1;
loc_830B2B9C:
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830b2b34
	if (!cr0.eq) goto loc_830B2B34;
loc_830B2BA8:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// add r7,r30,r7
	ctx.r7.u64 = r30.u64 + ctx.r7.u64;
	// bne 0x830b2b18
	if (!cr0.eq) goto loc_830B2B18;
loc_830B2BB4:
	// addic. r26,r26,-1
	xer.ca = r26.u32 > 0;
	r26.s64 = r26.s64 + -1;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bne 0x830b2b00
	if (!cr0.eq) goto loc_830B2B00;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830b2bec
	if (cr6.eq) goto loc_830B2BEC;
	// lwz r11,428(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2e40
	if (cr6.eq) goto loc_830B2E40;
	// rotlwi r10,r11,0
	ctx.r10.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
loc_830B2BEC:
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r20,r20,1
	r20.s64 = r20.s64 + 1;
	// addi r19,r19,4
	r19.s64 = r19.s64 + 4;
	// cmplw cr6,r20,r11
	cr6.compare<uint32_t>(r20.u32, r11.u32, xer);
	// blt cr6,0x830b2a94
	if (cr6.lt) goto loc_830B2A94;
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_830B2C04:
	// addi r21,r21,4
	r21.s64 = r21.s64 + 4;
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// cmplwi cr6,r21,24
	cr6.compare<uint32_t>(r21.u32, 24, xer);
	// blt cr6,0x830b2a64
	if (cr6.lt) goto loc_830B2A64;
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// mr r22,r16
	r22.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b3340
	if (!cr6.gt) goto loc_830B3340;
	// mr r23,r16
	r23.u64 = r16.u64;
	// addi r24,r1,176
	r24.s64 = ctx.r1.s64 + 176;
loc_830B2C2C:
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b3328
	if (cr6.eq) goto loc_830B3328;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b3328
	if (cr6.eq) goto loc_830B3328;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
	// mr r25,r16
	r25.u64 = r16.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b3328
	if (cr6.eq) goto loc_830B3328;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
loc_830B2C64:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r3
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmplwi cr6,r7,3
	cr6.compare<uint32_t>(ctx.r7.u32, 3, xer);
	// bne cr6,0x830b2c84
	if (!cr6.eq) goto loc_830B2C84;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r25,r11
	r25.u64 = r11.u64;
loc_830B2C84:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830b2c64
	if (!cr0.eq) goto loc_830B2C64;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x830b3328
	if (cr6.eq) goto loc_830B3328;
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r29,r16
	r29.u64 = r16.u64;
	// li r4,6
	ctx.r4.s64 = 6;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// ble cr6,0x830b2d44
	if (!cr6.gt) goto loc_830B2D44;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r5,r11,24
	ctx.r5.s64 = r11.s64 + 24;
loc_830B2CB4:
	// lwz r8,0(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830b2d30
	if (cr6.eq) goto loc_830B2D30;
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2d30
	if (cr6.eq) goto loc_830B2D30;
	// lwz r6,4(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// mr r7,r16
	ctx.r7.u64 = r16.u64;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830b2d30
	if (cr6.eq) goto loc_830B2D30;
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
loc_830B2CEC:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r30,r3
	r30.u64 = PPC_LOAD_U32(r30.u32 + ctx.r3.u32);
	// lwz r30,56(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 56);
	// cmplw cr6,r30,r25
	cr6.compare<uint32_t>(r30.u32, r25.u32, xer);
	// beq cr6,0x830b2d0c
	if (cr6.eq) goto loc_830B2D0C;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x830b2d20
	if (!cr6.eq) goto loc_830B2D20;
loc_830B2D0C:
	// cmplwi cr6,r29,16
	cr6.compare<uint32_t>(r29.u32, 16, xer);
	// bge cr6,0x830b335c
	if (!cr6.lt) goto loc_830B335C;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_830B2D20:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b2cec
	if (cr6.lt) goto loc_830B2CEC;
loc_830B2D30:
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x830b2cb4
	if (cr6.lt) goto loc_830B2CB4;
loc_830B2D44:
	// lwz r11,428(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2e04
	if (cr6.eq) goto loc_830B2E04;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b2dec
	if (!cr6.gt) goto loc_830B2DEC;
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
loc_830B2D64:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b2dd8
	if (cr6.eq) goto loc_830B2DD8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b2dd8
	if (cr6.eq) goto loc_830B2DD8;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x830b2dd8
	if (cr6.eq) goto loc_830B2DD8;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mr r9,r16
	ctx.r9.u64 = r16.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830b2dd8
	if (cr6.eq) goto loc_830B2DD8;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_830B2D9C:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r5,r3
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	// lwz r5,56(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 56);
	// cmplw cr6,r5,r25
	cr6.compare<uint32_t>(ctx.r5.u32, r25.u32, xer);
	// beq cr6,0x830b2dbc
	if (cr6.eq) goto loc_830B2DBC;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x830b2dc8
	if (!cr6.eq) goto loc_830B2DC8;
loc_830B2DBC:
	// cmplwi cr6,r29,16
	cr6.compare<uint32_t>(r29.u32, 16, xer);
	// bge cr6,0x830b335c
	if (!cr6.lt) goto loc_830B335C;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
loc_830B2DC8:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x830b2d9c
	if (cr6.lt) goto loc_830B2D9C;
loc_830B2DD8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x830b2d64
	if (cr6.lt) goto loc_830B2D64;
loc_830B2DEC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b3328
	if (cr6.eq) goto loc_830B3328;
	// lwz r10,428(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
loc_830B2E04:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b3328
	if (cr6.eq) goto loc_830B3328;
	// lwz r11,428(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830b3328
	if (!cr6.eq) goto loc_830B3328;
	// lwz r11,1032(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1032);
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// bge cr6,0x830b3368
	if (!cr6.lt) goto loc_830B3368;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b313c
	if (cr0.eq) goto loc_830B313C;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830b3140
	goto loc_830B3140;
loc_830B2E40:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// mr r30,r16
	r30.u64 = r16.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// std r17,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r17.u64);
	// std r17,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r17.u64);
	// beq cr6,0x830b2f00
	if (cr6.eq) goto loc_830B2F00;
	// lwz r3,12(r22)
	ctx.r3.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
loc_830B2E60:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830b2ef4
	if (cr6.eq) goto loc_830B2EF4;
	// lwz r9,8(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lwz r8,16(r22)
	ctx.r8.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// add r7,r10,r11
	ctx.r7.u64 = ctx.r10.u64 + r11.u64;
	// lwzx r6,r9,r5
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
loc_830B2E84:
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// beq cr6,0x830b2ea8
	if (cr6.eq) goto loc_830B2EA8;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x830b2ee8
	if (!cr6.eq) goto loc_830B2EE8;
loc_830B2EA8:
	// mr r11,r16
	r11.u64 = r16.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830b2ed4
	if (cr6.eq) goto loc_830B2ED4;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
loc_830B2EB8:
	// lwz r28,0(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r28,r9
	cr6.compare<uint32_t>(r28.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b2ed4
	if (cr6.eq) goto loc_830B2ED4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// blt cr6,0x830b2eb8
	if (cr6.lt) goto loc_830B2EB8;
loc_830B2ED4:
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x830b2ee8
	if (!cr6.eq) goto loc_830B2EE8;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
loc_830B2EE8:
	// addic. r4,r4,-1
	xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x830b2e84
	if (!cr0.eq) goto loc_830B2E84;
loc_830B2EF4:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// bne 0x830b2e60
	if (!cr0.eq) goto loc_830B2E60;
loc_830B2F00:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b2f1c
	if (cr0.eq) goto loc_830B2F1C;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r15,r3
	r15.u64 = ctx.r3.u64;
	// b 0x830b2f20
	goto loc_830B2F20;
loc_830B2F1C:
	// mr r15,r16
	r15.u64 = r16.u64;
loc_830B2F20:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x830b3130
	if (cr6.eq) goto loc_830B3130;
	// li r11,1
	r11.s64 = 1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830b33f0
	if (cr0.lt) goto loc_830B33F0;
	// rlwinm r5,r30,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,16(r15)
	ctx.r3.u64 = PPC_LOAD_U32(r15.u32 + 16);
	// li r4,255
	ctx.r4.s64 = 255;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b30e8
	if (!cr6.gt) goto loc_830B30E8;
loc_830B2F70:
	// lwz r11,12(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b30d8
	if (!cr6.gt) goto loc_830B30D8;
	// rlwinm r5,r4,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
loc_830B2F88:
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// lwz r9,16(r22)
	ctx.r9.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r8,r5,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// lwzx r11,r6,r9
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// lwzx r7,r9,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// beq cr6,0x830b2fb8
	if (cr6.eq) goto loc_830B2FB8;
	// lwz r9,56(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 56);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b30c4
	if (!cr6.eq) goto loc_830B30C4;
loc_830B2FB8:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r29,16(r15)
	r29.u64 = PPC_LOAD_U32(r15.u32 + 16);
	// divwu r9,r4,r30
	ctx.r9.u32 = ctx.r4.u32 / r30.u32;
	// twllei r30,0
	// mullw r8,r9,r30
	ctx.r8.s64 = int64_t(ctx.r9.s32) * int64_t(r30.s32);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// subf r11,r8,r4
	r11.s64 = ctx.r4.s64 - ctx.r8.s64;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r8,r29
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r29.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830b302c
	if (!cr6.eq) goto loc_830B302C;
	// lwz r11,1036(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1036);
	// cmplwi cr6,r11,64
	cr6.compare<uint32_t>(r11.u32, 64, xer);
	// bge cr6,0x830b3130
	if (!cr6.lt) goto loc_830B3130;
	// addi r29,r11,194
	r29.s64 = r11.s64 + 194;
	// lwz r28,136(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// addi r27,r11,1
	r27.s64 = r11.s64 + 1;
	// rlwinm r11,r29,2,0,29
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// stw r27,1036(r31)
	PPC_STORE_U32(r31.u32 + 1036, r27.u32);
	// rlwinm r29,r11,2,0,29
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// lwzx r10,r29,r10
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + ctx.r10.u32);
	// stw r28,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r28.u32);
	// stw r16,60(r10)
	PPC_STORE_U32(ctx.r10.u32 + 60, r16.u32);
	// stw r14,56(r10)
	PPC_STORE_U32(ctx.r10.u32 + 56, r14.u32);
	// lwz r29,16(r9)
	r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// stw r29,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, r29.u32);
	// beq cr6,0x830b3130
	if (cr6.eq) goto loc_830B3130;
loc_830B302C:
	// lwz r10,16(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// lwz r29,56(r7)
	r29.u64 = PPC_LOAD_U32(ctx.r7.u32 + 56);
	// lwzx r10,r6,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// bne cr6,0x830b3094
	if (!cr6.eq) goto loc_830B3094;
	// lwz r10,1036(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1036);
	// cmplwi cr6,r10,64
	cr6.compare<uint32_t>(ctx.r10.u32, 64, xer);
	// bge cr6,0x830b3130
	if (!cr6.lt) goto loc_830B3130;
	// addi r29,r10,194
	r29.s64 = ctx.r10.s64 + 194;
	// lwz r28,20(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r29,r29,2,0,29
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r29,r31
	r29.u64 = PPC_LOAD_U32(r29.u32 + r31.u32);
	// stw r10,1036(r31)
	PPC_STORE_U32(r31.u32 + 1036, ctx.r10.u32);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwzx r10,r10,r28
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r28.u32);
	// stw r9,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, ctx.r9.u32);
	// lwz r9,60(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 60);
	// stw r9,60(r10)
	PPC_STORE_U32(ctx.r10.u32 + 60, ctx.r9.u32);
	// stw r11,56(r10)
	PPC_STORE_U32(ctx.r10.u32 + 56, r11.u32);
	// lwz r9,136(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// lwz r10,8(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// stwx r29,r5,r10
	PPC_STORE_U32(ctx.r5.u32 + ctx.r10.u32, r29.u32);
	// b 0x830b309c
	goto loc_830B309C;
loc_830B3094:
	// lwz r10,8(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// stwx r11,r5,r10
	PPC_STORE_U32(ctx.r5.u32 + ctx.r10.u32, r11.u32);
loc_830B309C:
	// lwz r10,16(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r15)
	ctx.r7.u64 = PPC_LOAD_U32(r15.u32 + 8);
	// lwzx r10,r6,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// stwx r10,r7,r8
	PPC_STORE_U32(ctx.r7.u32 + ctx.r8.u32, ctx.r10.u32);
	// lwz r10,16(r15)
	ctx.r10.u64 = PPC_LOAD_U32(r15.u32 + 16);
	// stwx r11,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, r11.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stw r16,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r16.u32);
loc_830B30C4:
	// lwz r11,12(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// blt cr6,0x830b2f88
	if (cr6.lt) goto loc_830B2F88;
loc_830B30D8:
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x830b2f70
	if (cr6.lt) goto loc_830B2F70;
loc_830B30E8:
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r15,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r15.u32);
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// lwz r11,1032(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1032);
	// stw r10,548(r31)
	PPC_STORE_U32(r31.u32 + 548, ctx.r10.u32);
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// bge cr6,0x830b3130
	if (!cr6.lt) goto loc_830B3130;
	// addi r11,r11,178
	r11.s64 = r11.s64 + 178;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r15,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, r15.u32);
	// mr r15,r16
	r15.u64 = r16.u64;
	// lwz r11,1032(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1032);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,1032(r31)
	PPC_STORE_U32(r31.u32 + 1032, r11.u32);
	// b 0x830b2bec
	goto loc_830B2BEC;
loc_830B3130:
	// lis r29,-32761
	r29.s64 = -2147024896;
	// ori r29,r29,14
	r29.u64 = r29.u64 | 14;
	// b 0x830b33f0
	goto loc_830B33F0;
loc_830B313C:
	// mr r30,r16
	r30.u64 = r16.u64;
loc_830B3140:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b315c
	if (cr0.eq) goto loc_830B315C;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x830b3160
	goto loc_830B3160;
loc_830B315C:
	// mr r28,r16
	r28.u64 = r16.u64;
loc_830B3160:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830b3370
	if (cr6.eq) goto loc_830B3370;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b3370
	if (cr6.eq) goto loc_830B3370;
	// lwz r11,1036(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1036);
	// cmplwi cr6,r11,64
	cr6.compare<uint32_t>(r11.u32, 64, xer);
	// bgt cr6,0x830b3370
	if (cr6.gt) goto loc_830B3370;
	// addi r10,r11,195
	ctx.r10.s64 = r11.s64 + 195;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,194
	r11.s64 = r11.s64 + 194;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r8,3
	ctx.r8.s64 = 3;
	// li r7,4
	ctx.r7.s64 = 4;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// lwzx r26,r10,r31
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + r31.u32);
	// lwzx r27,r11,r31
	r27.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// rlwinm r11,r26,2,0,29
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r27,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stw r16,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r16.u32);
	// stw r8,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r8.u32);
	// stw r14,56(r11)
	PPC_STORE_U32(r11.u32 + 56, r14.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r7,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r7.u32);
	// stw r16,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r16.u32);
	// stw r14,56(r11)
	PPC_STORE_U32(r11.u32 + 56, r14.u32);
	// lwz r11,1036(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1036);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,1036(r31)
	PPC_STORE_U32(r31.u32 + 1036, r11.u32);
	// beq cr6,0x830b3254
	if (cr6.eq) goto loc_830B3254;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
loc_830B31E8:
	// lwz r7,0(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b3248
	if (!cr6.gt) goto loc_830B3248;
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
loc_830B3200:
	// lwz r9,8(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r9,r8
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r3,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r10.u32);
	// lwz r3,56(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmplw cr6,r3,r25
	cr6.compare<uint32_t>(ctx.r3.u32, r25.u32, xer);
	// bne cr6,0x830b3228
	if (!cr6.eq) goto loc_830B3228;
	// stw r26,56(r10)
	PPC_STORE_U32(ctx.r10.u32 + 56, r26.u32);
	// b 0x830b3234
	goto loc_830B3234;
loc_830B3228:
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x830b3234
	if (!cr6.eq) goto loc_830B3234;
	// stwx r26,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, r26.u32);
loc_830B3234:
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x830b3200
	if (cr6.lt) goto loc_830B3200;
loc_830B3248:
	// addic. r4,r4,-1
	xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// bne 0x830b31e8
	if (!cr0.eq) goto loc_830B31E8;
loc_830B3254:
	// lis r4,4096
	ctx.r4.s64 = 268435456;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830b3408
	if (cr0.lt) goto loc_830B3408;
	// lis r4,4096
	ctx.r4.s64 = 268435456;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830b3408
	if (cr0.lt) goto loc_830B3408;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,2
	ctx.r9.s64 = 2;
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r28,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r28.u32);
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stw r27,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r27.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r25,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r25.u32);
	// stw r10,40(r30)
	PPC_STORE_U32(r30.u32 + 40, ctx.r10.u32);
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// stw r26,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r26.u32);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// stw r27,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r27.u32);
	// stw r9,40(r30)
	PPC_STORE_U32(r30.u32 + 40, ctx.r9.u32);
	// lwz r11,1032(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1032);
	// addi r11,r11,178
	r11.s64 = r11.s64 + 178;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r30,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, r30.u32);
	// lwz r11,1032(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1032);
	// addi r11,r11,179
	r11.s64 = r11.s64 + 179;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r28,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, r28.u32);
	// lwz r11,1032(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1032);
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// lwz r9,548(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,1032(r31)
	PPC_STORE_U32(r31.u32 + 1032, r11.u32);
	// stwx r30,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, r30.u32);
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r11.u32);
loc_830B3328:
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// addi r23,r23,4
	r23.s64 = r23.s64 + 4;
	// cmplw cr6,r22,r11
	cr6.compare<uint32_t>(r22.u32, r11.u32, xer);
	// blt cr6,0x830b2c2c
	if (cr6.lt) goto loc_830B2C2C;
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_830B3340:
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// add r10,r11,r8
	ctx.r10.u64 = r11.u64 + ctx.r8.u64;
	// cmplwi cr6,r10,512
	cr6.compare<uint32_t>(ctx.r10.u32, 512, xer);
	// ble cr6,0x830b337c
	if (!cr6.gt) goto loc_830B337C;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b340c
	goto loc_830B340C;
loc_830B335C:
	// lis r29,-32768
	r29.s64 = -2147483648;
	// ori r29,r29,16389
	r29.u64 = r29.u64 | 16389;
	// b 0x830b3408
	goto loc_830B3408;
loc_830B3368:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830b340c
	goto loc_830B340C;
loc_830B3370:
	// lis r29,-32761
	r29.s64 = -2147024896;
	// ori r29,r29,14
	r29.u64 = r29.u64 | 14;
	// b 0x830b3408
	goto loc_830B3408;
loc_830B337C:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// blt cr6,0x830b33b0
	if (cr6.lt) goto loc_830B33B0;
	// add r9,r11,r8
	ctx.r9.u64 = r11.u64 + ctx.r8.u64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
loc_830B3394:
	// lwz r7,564(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwzx r6,r7,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// stwx r6,r7,r9
	PPC_STORE_U32(ctx.r7.u32 + ctx.r9.u32, ctx.r6.u32);
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// bne 0x830b3394
	if (!cr0.eq) goto loc_830B3394;
loc_830B33B0:
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830b33e0
	if (cr6.eq) goto loc_830B33E0;
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// li r11,24
	r11.s64 = 24;
	// addi r9,r10,-24
	ctx.r9.s64 = ctx.r10.s64 + -24;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_830B33C8:
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r6,564(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// stwx r7,r11,r6
	PPC_STORE_U32(r11.u32 + ctx.r6.u32, ctx.r7.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830b33c8
	if (!cr0.eq) goto loc_830B33C8;
loc_830B33E0:
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r29,r16
	r29.u64 = r16.u64;
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// stw r11,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r11.u32);
loc_830B33F0:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x830b3408
	if (cr6.eq) goto loc_830B3408;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830B3408:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_830B340C:
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// b 0x82ca2c00
	return;
}

__attribute__((alias("__imp__sub_830B3418"))) PPC_WEAK_FUNC(sub_830B3418);
PPC_FUNC_IMPL(__imp__sub_830B3418) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r23,18
	r23.s64 = 18;
	// li r10,6
	ctx.r10.s64 = 6;
	// lwz r11,564(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 564);
loc_830B3434:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830b345c
	if (cr6.eq) goto loc_830B345C;
	// rotlwi r9,r9,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// lis r8,4352
	ctx.r8.s64 = 285212672;
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// beq cr6,0x830b345c
	if (cr6.eq) goto loc_830B345C;
	// addi r23,r23,-3
	r23.s64 = r23.s64 + -3;
loc_830B345C:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830b3434
	if (!cr0.eq) goto loc_830B3434;
	// lwz r11,548(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 548);
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b3570
	if (cr6.eq) goto loc_830B3570;
	// lwz r26,560(r5)
	r26.u64 = PPC_LOAD_U32(ctx.r5.u32 + 560);
	// mr r25,r11
	r25.u64 = r11.u64;
loc_830B3480:
	// lwz r27,0(r26)
	r27.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830b3558
	if (cr6.eq) goto loc_830B3558;
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b3558
	if (cr6.eq) goto loc_830B3558;
	// lwz r29,12(r5)
	r29.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r28,r11
	r28.u64 = r11.u64;
loc_830B34A4:
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b3540
	if (cr6.eq) goto loc_830B3540;
	// lwz r30,24(r5)
	r30.u64 = PPC_LOAD_U32(ctx.r5.u32 + 24);
loc_830B34B4:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,40(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x830b3530
	if (cr6.eq) goto loc_830B3530;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r3,r11,0,0,11
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830b3530
	if (!cr0.eq) goto loc_830B3530;
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830b3528
	if (cr6.eq) goto loc_830B3528;
	// lwz r9,16(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwz r8,20(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 20);
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwzx r9,r9,r4
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
loc_830B34F8:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r3,r8
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r8.u32);
	// lwz r3,56(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// cmplw cr6,r3,r9
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b3528
	if (cr6.eq) goto loc_830B3528;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b3528
	if (cr6.eq) goto loc_830B3528;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b34f8
	if (cr6.lt) goto loc_830B34F8;
loc_830B3528:
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// bne cr6,0x830b3540
	if (!cr6.eq) goto loc_830B3540;
loc_830B3530:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// blt cr6,0x830b34b4
	if (cr6.lt) goto loc_830B34B4;
loc_830B3540:
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// beq cr6,0x830b354c
	if (cr6.eq) goto loc_830B354C;
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
loc_830B354C:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bne 0x830b34a4
	if (!cr0.eq) goto loc_830B34A4;
loc_830B3558:
	// addic. r25,r25,-1
	xer.ca = r25.u32 > 0;
	r25.s64 = r25.s64 + -1;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// bne 0x830b3480
	if (!cr0.eq) goto loc_830B3480;
	// cmplw cr6,r24,r23
	cr6.compare<uint32_t>(r24.u32, r23.u32, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bgt cr6,0x830b3574
	if (cr6.gt) goto loc_830B3574;
loc_830B3570:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B3574:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c24
	return;
}

__attribute__((alias("__imp__sub_830B3580"))) PPC_WEAK_FUNC(sub_830B3580);
PPC_FUNC_IMPL(__imp__sub_830B3580) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x830b35a8
	if (cr6.eq) goto loc_830B35A8;
loc_830B35A0:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830b35f8
	goto loc_830B35F8;
loc_830B35A8:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b35f4
	if (!cr6.gt) goto loc_830B35F4;
	// li r31,0
	r31.s64 = 0;
loc_830B35BC:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x830b3580
	sub_830B3580(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830b35a0
	if (!cr0.eq) goto loc_830B35A0;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830b35bc
	if (cr6.lt) goto loc_830B35BC;
loc_830B35F4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B35F8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830B3600"))) PPC_WEAK_FUNC(sub_830B3600);
PPC_FUNC_IMPL(__imp__sub_830B3600) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830b3730
	if (cr6.eq) goto loc_830B3730;
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830b3730
	if (cr6.eq) goto loc_830B3730;
loc_830B3620:
	// lwz r30,0(r4)
	r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830b3720
	if (cr6.eq) goto loc_830B3720;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b3720
	if (cr6.eq) goto loc_830B3720;
	// lwz r28,12(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b3720
	if (cr6.eq) goto loc_830B3720;
	// lwz r29,0(r7)
	r29.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
loc_830B3650:
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b3688
	if (cr6.eq) goto loc_830B3688;
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
loc_830B3668:
	// lwz r26,0(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r8,r26
	cr6.compare<uint32_t>(ctx.r8.u32, r26.u32, xer);
	// beq cr6,0x830b369c
	if (cr6.eq) goto loc_830B369C;
	// lwz r26,0(r7)
	r26.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r26
	cr6.compare<uint32_t>(ctx.r9.u32, r26.u32, xer);
	// blt cr6,0x830b3668
	if (cr6.lt) goto loc_830B3668;
loc_830B3688:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// blt cr6,0x830b3650
	if (cr6.lt) goto loc_830B3650;
	// b 0x830b3720
	goto loc_830B3720;
loc_830B369C:
	// li r29,0
	r29.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
loc_830B36A4:
	// lwz r8,0(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830b36e0
	if (cr6.eq) goto loc_830B36E0;
	// lwz r31,16(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwzx r31,r31,r9
	r31.u64 = PPC_LOAD_U32(r31.u32 + ctx.r9.u32);
loc_830B36C0:
	// lwz r28,0(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r28,r31
	cr6.compare<uint32_t>(r28.u32, r31.u32, xer);
	// beq cr6,0x830b36e0
	if (cr6.eq) goto loc_830B36E0;
	// lwz r28,0(r7)
	r28.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r28
	cr6.compare<uint32_t>(ctx.r10.u32, r28.u32, xer);
	// blt cr6,0x830b36c0
	if (cr6.lt) goto loc_830B36C0;
loc_830B36E0:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b370c
	if (!cr6.eq) goto loc_830B370C;
	// cmplwi cr6,r10,32
	cr6.compare<uint32_t>(ctx.r10.u32, 32, xer);
	// beq cr6,0x830b373c
	if (cr6.eq) goto loc_830B373C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stwx r11,r10,r6
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, r11.u32);
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r11.u32);
loc_830B370C:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830b36a4
	if (cr6.lt) goto loc_830B36A4;
loc_830B3720:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// cmplw cr6,r27,r5
	cr6.compare<uint32_t>(r27.u32, ctx.r5.u32, xer);
	// blt cr6,0x830b3620
	if (cr6.lt) goto loc_830B3620;
loc_830B3730:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B3734:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_830B373C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4803
	ctx.r5.s64 = 4803;
	// addi r6,r11,30380
	ctx.r6.s64 = r11.s64 + 30380;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b3734
	goto loc_830B3734;
}

__attribute__((alias("__imp__sub_830B3760"))) PPC_WEAK_FUNC(sub_830B3760);
PPC_FUNC_IMPL(__imp__sub_830B3760) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bbc
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r19,r5
	r19.u64 = ctx.r5.u64;
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// bge cr6,0x830b38ec
	if (!cr6.lt) goto loc_830B38EC;
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// add r18,r11,r4
	r18.u64 = r11.u64 + ctx.r4.u64;
loc_830B3780:
	// lwz r23,0(r18)
	r23.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830b38dc
	if (cr6.eq) goto loc_830B38DC;
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// clrlwi r24,r11,12
	r24.u64 = r11.u32 & 0xFFFFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b38dc
	if (cr6.eq) goto loc_830B38DC;
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// li r22,0
	r22.s64 = 0;
	// twllei r24,0
	// divwu. r21,r11,r24
	r21.u32 = r11.u32 / r24.u32;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// beq 0x830b38dc
	if (cr0.eq) goto loc_830B38DC;
	// li r25,0
	r25.s64 = 0;
	// rlwinm r20,r24,2,0,29
	r20.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
loc_830B37B8:
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830b38cc
	if (cr6.eq) goto loc_830B38CC;
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// mr r27,r24
	r27.u64 = r24.u64;
	// lwz r28,20(r3)
	r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// add r4,r11,r25
	ctx.r4.u64 = r11.u64 + r25.u64;
loc_830B37D4:
	// lwz r30,0(r4)
	r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r11,r28
	r29.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// beq cr6,0x830b3824
	if (cr6.eq) goto loc_830B3824;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r31,r8
	r31.u64 = ctx.r8.u64;
loc_830B37F0:
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// beq cr6,0x830b3808
	if (cr6.eq) goto loc_830B3808;
	// lwz r17,56(r29)
	r17.u64 = PPC_LOAD_U32(r29.u32 + 56);
	// cmplw cr6,r17,r11
	cr6.compare<uint32_t>(r17.u32, r11.u32, xer);
	// bne cr6,0x830b3818
	if (!cr6.eq) goto loc_830B3818;
loc_830B3808:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830b3818
	if (!cr6.eq) goto loc_830B3818;
	// li r26,1
	r26.s64 = 1;
loc_830B3818:
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// bne 0x830b37f0
	if (!cr0.eq) goto loc_830B37F0;
loc_830B3824:
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bne 0x830b37d4
	if (!cr0.eq) goto loc_830B37D4;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x830b38cc
	if (cr6.eq) goto loc_830B38CC;
	// li r29,0
	r29.s64 = 0;
	// mr r30,r25
	r30.u64 = r25.u64;
loc_830B3840:
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// lwz r5,20(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r4,r5
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r5.u32);
	// lwz r5,56(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 56);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// bne cr6,0x830b3864
	if (!cr6.eq) goto loc_830B3864;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
loc_830B3864:
	// lwz r31,0(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b3898
	if (cr6.eq) goto loc_830B3898;
	// mr r4,r9
	ctx.r4.u64 = ctx.r9.u64;
loc_830B3878:
	// lwz r28,0(r4)
	r28.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r28,r5
	cr6.compare<uint32_t>(r28.u32, ctx.r5.u32, xer);
	// beq cr6,0x830b3898
	if (cr6.eq) goto loc_830B3898;
	// lwz r28,0(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// blt cr6,0x830b3878
	if (cr6.lt) goto loc_830B3878;
loc_830B3898:
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x830b38bc
	if (!cr6.eq) goto loc_830B38BC;
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// beq cr6,0x830b38f8
	if (cr6.eq) goto loc_830B38F8;
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r5,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r5.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
loc_830B38BC:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r24
	cr6.compare<uint32_t>(r29.u32, r24.u32, xer);
	// blt cr6,0x830b3840
	if (cr6.lt) goto loc_830B3840;
loc_830B38CC:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// add r25,r20,r25
	r25.u64 = r20.u64 + r25.u64;
	// cmplw cr6,r22,r21
	cr6.compare<uint32_t>(r22.u32, r21.u32, xer);
	// blt cr6,0x830b37b8
	if (cr6.lt) goto loc_830B37B8;
loc_830B38DC:
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// addi r18,r18,4
	r18.s64 = r18.s64 + 4;
	// cmplw cr6,r19,r6
	cr6.compare<uint32_t>(r19.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b3780
	if (cr6.lt) goto loc_830B3780;
loc_830B38EC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B38F0:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c0c
	return;
loc_830B38F8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4803
	ctx.r5.s64 = 4803;
	// addi r6,r11,30380
	ctx.r6.s64 = r11.s64 + 30380;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b38f0
	goto loc_830B38F0;
}

__attribute__((alias("__imp__sub_830B3918"))) PPC_WEAK_FUNC(sub_830B3918);
PPC_FUNC_IMPL(__imp__sub_830B3918) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b3978
	if (!cr6.gt) goto loc_830B3978;
	// li r9,0
	ctx.r9.s64 = 0;
loc_830B392C:
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830b3964
	if (cr6.eq) goto loc_830B3964;
	// lwz r7,20(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r7,12(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// stw r7,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r7.u32);
	// lwz r7,20(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
loc_830B3964:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x830b392c
	if (cr6.lt) goto loc_830B392C;
loc_830B3978:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830B3980"))) PPC_WEAK_FUNC(sub_830B3980);
PPC_FUNC_IMPL(__imp__sub_830B3980) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2bb0
	// lwz r15,84(r1)
	r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r22,0
	r22.s64 = 0;
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// stw r22,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r22.u32);
	// mr r19,r22
	r19.u64 = r22.u64;
	// stw r22,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r22.u32);
	// bge cr6,0x830b3b28
	if (!cr6.lt) goto loc_830B3B28;
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r17,r5,r6
	r17.s64 = ctx.r6.s64 - ctx.r5.s64;
	// add r18,r11,r4
	r18.u64 = r11.u64 + ctx.r4.u64;
	// li r16,1
	r16.s64 = 1;
loc_830B39B4:
	// lwz r4,0(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830b3b1c
	if (cr6.eq) goto loc_830B3B1C;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b3b1c
	if (cr6.eq) goto loc_830B3B1C;
	// lwz r6,4(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// clrlwi r30,r11,12
	r30.u64 = r11.u32 & 0xFFFFF;
	// mr r23,r22
	r23.u64 = r22.u64;
	// divwu r21,r6,r30
	r21.u32 = ctx.r6.u32 / r30.u32;
	// twllei r30,0
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830b3b1c
	if (cr6.eq) goto loc_830B3B1C;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r20,r8
	r20.u64 = ctx.r8.u64;
loc_830B39F0:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830b3b10
	if (cr6.eq) goto loc_830B3B10;
	// mr r27,r22
	r27.u64 = r22.u64;
	// rlwinm r24,r30,2,0,29
	r24.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r26,r21
	r26.u64 = r21.u64;
loc_830B3A04:
	// mr r28,r22
	r28.u64 = r22.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830b3af0
	if (cr6.eq) goto loc_830B3AF0;
	// mr r31,r27
	r31.u64 = r27.u64;
	// mr r29,r30
	r29.u64 = r30.u64;
loc_830B3A18:
	// lwz r6,8(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r5,20(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// lwzx r6,r6,r31
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + r31.u32);
	// rlwinm r14,r6,2,0,29
	r14.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r14,r14,r5
	r14.u64 = PPC_LOAD_U32(r14.u32 + ctx.r5.u32);
	// lwz r14,56(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 56);
	// cmplw cr6,r14,r11
	cr6.compare<uint32_t>(r14.u32, r11.u32, xer);
	// beq cr6,0x830b3a44
	if (cr6.eq) goto loc_830B3A44;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// bne cr6,0x830b3ae4
	if (!cr6.eq) goto loc_830B3AE4;
loc_830B3A44:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplw cr6,r23,r19
	cr6.compare<uint32_t>(r23.u32, r19.u32, xer);
	// ble cr6,0x830b3a58
	if (!cr6.gt) goto loc_830B3A58;
	// mr r19,r23
	r19.u64 = r23.u64;
loc_830B3A58:
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x830b3a84
	if (!cr6.eq) goto loc_830B3A84;
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830b3a84
	if (!cr6.eq) goto loc_830B3A84;
	// stw r16,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r16.u32);
loc_830B3A84:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lis r6,20480
	ctx.r6.s64 = 1342177280;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// beq cr6,0x830b3ae4
	if (cr6.eq) goto loc_830B3AE4;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b3ae4
	if (!cr6.gt) goto loc_830B3AE4;
	// mr r11,r22
	r11.u64 = r22.u64;
loc_830B3AAC:
	// lwz r5,16(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// lwz r14,20(r3)
	r14.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r5,r5,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r5,r14
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + r14.u32);
	// lwz r5,16(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// cmplwi cr6,r5,3
	cr6.compare<uint32_t>(ctx.r5.u32, 3, xer);
	// bne cr6,0x830b3ad0
	if (!cr6.eq) goto loc_830B3AD0;
	// stw r16,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r16.u32);
loc_830B3AD0:
	// lwz r5,12(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// blt cr6,0x830b3aac
	if (cr6.lt) goto loc_830B3AAC;
loc_830B3AE4:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// bne 0x830b3a18
	if (!cr0.eq) goto loc_830B3A18;
loc_830B3AF0:
	// cmplw cr6,r28,r30
	cr6.compare<uint32_t>(r28.u32, r30.u32, xer);
	// beq cr6,0x830b3b04
	if (cr6.eq) goto loc_830B3B04;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b3b04
	if (cr6.eq) goto loc_830B3B04;
	// stw r16,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r16.u32);
loc_830B3B04:
	// addic. r26,r26,-1
	xer.ca = r26.u32 > 0;
	r26.s64 = r26.s64 + -1;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// add r27,r24,r27
	r27.u64 = r24.u64 + r27.u64;
	// bne 0x830b3a04
	if (!cr0.eq) goto loc_830B3A04;
loc_830B3B10:
	// addic. r20,r20,-1
	xer.ca = r20.u32 > 0;
	r20.s64 = r20.s64 + -1;
	cr0.compare<int32_t>(r20.s32, 0, xer);
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// bne 0x830b39f0
	if (!cr0.eq) goto loc_830B39F0;
loc_830B3B1C:
	// addic. r17,r17,-1
	xer.ca = r17.u32 > 0;
	r17.s64 = r17.s64 + -1;
	cr0.compare<int32_t>(r17.s32, 0, xer);
	// addi r18,r18,4
	r18.s64 = r18.s64 + 4;
	// bne 0x830b39b4
	if (!cr0.eq) goto loc_830B39B4;
loc_830B3B28:
	// stw r19,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r19.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82ca2c00
	return;
}

__attribute__((alias("__imp__sub_830B3B38"))) PPC_WEAK_FUNC(sub_830B3B38);
PPC_FUNC_IMPL(__imp__sub_830B3B38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -168, f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-592(r1)
	ea = -592 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r5,128
	ctx.r5.s64 = 128;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// lwz r31,8(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// li r5,128
	ctx.r5.s64 = 128;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// li r23,0
	r23.s64 = 0;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r10,936
	ctx.r4.s64 = ctx.r10.s64 + 936;
	// std r23,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r23.u64);
	// li r6,8
	ctx.r6.s64 = 8;
	// std r23,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r23.u64);
	// li r5,785
	ctx.r5.s64 = 785;
	// std r23,16(r11)
	PPC_STORE_U64(r11.u32 + 16, r23.u64);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// std r23,24(r11)
	PPC_STORE_U64(r11.u32 + 24, r23.u64);
	// bl 0x8307a8d8
	sub_8307A8D8(ctx, base);
	// mr r16,r3
	r16.u64 = ctx.r3.u64;
	// li r17,1
	r17.s64 = 1;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b3c4c
	if (cr6.eq) goto loc_830B3C4C;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
loc_830B3BC4:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r10,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830b3c3c
	if (!cr0.eq) goto loc_830B3C3C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r7,16(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r7,r10,0,22,22
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x830b3c3c
	if (cr0.eq) goto loc_830B3C3C;
	// rlwinm. r10,r10,0,23,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x180;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830b3c3c
	if (!cr0.eq) goto loc_830B3C3C;
	// lwz r10,56(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 56);
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// bgt cr6,0x830b3c98
	if (cr6.gt) goto loc_830B3C98;
	// rotlwi r11,r7,0
	r11.u64 = __builtin_rotateleft32(ctx.r7.u32, 0);
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// rlwinm r6,r11,4,0,27
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r7,r1,164
	ctx.r7.s64 = ctx.r1.s64 + 164;
	// addi r5,r1,168
	ctx.r5.s64 = ctx.r1.s64 + 168;
	// addi r4,r1,172
	ctx.r4.s64 = ctx.r1.s64 + 172;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stwx r17,r6,r10
	PPC_STORE_U32(ctx.r6.u32 + ctx.r10.u32, r17.u32);
	// stwx r17,r6,r7
	PPC_STORE_U32(ctx.r6.u32 + ctx.r7.u32, r17.u32);
	// stwx r17,r6,r5
	PPC_STORE_U32(ctx.r6.u32 + ctx.r5.u32, r17.u32);
	// stwx r17,r6,r4
	PPC_STORE_U32(ctx.r6.u32 + ctx.r4.u32, r17.u32);
	// stwx r17,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r17.u32);
loc_830B3C3C:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r9,r31
	cr6.compare<uint32_t>(ctx.r9.u32, r31.u32, xer);
	// blt cr6,0x830b3bc4
	if (cr6.lt) goto loc_830B3BC4;
loc_830B3C4C:
	// lwz r6,552(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 552);
	// mr r18,r23
	r18.u64 = r23.u64;
	// lwz r11,548(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 548);
	// add. r10,r11,r6
	ctx.r10.u64 = r11.u64 + ctx.r6.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830b4170
	if (cr0.eq) goto loc_830B4170;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r15,r23
	r15.u64 = r23.u64;
	// addi r10,r10,30520
	ctx.r10.s64 = ctx.r10.s64 + 30520;
	// lfs f30,3800(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 3800);
	f30.f64 = double(temp.f32);
	// lis r14,20480
	r14.s64 = 1342177280;
	// lfs f31,3080(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 3080);
	f31.f64 = double(temp.f32);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_830B3C84:
	// cmplw cr6,r18,r11
	cr6.compare<uint32_t>(r18.u32, r11.u32, xer);
	// bge cr6,0x830b3cbc
	if (!cr6.lt) goto loc_830B3CBC;
	// lwz r10,560(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 560);
	// lwzx r26,r10,r15
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + r15.u32);
	// b 0x830b3ccc
	goto loc_830B3CCC;
loc_830B3C98:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,30484
	ctx.r6.s64 = r11.s64 + 30484;
loc_830B3CA0:
	// li r5,4507
	ctx.r5.s64 = 4507;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b41bc
	goto loc_830B41BC;
loc_830B3CBC:
	// subf r10,r11,r18
	ctx.r10.s64 = r18.s64 - r11.s64;
	// lwz r9,564(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 564);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r26,r10,r9
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
loc_830B3CCC:
	// mr r19,r23
	r19.u64 = r23.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830b4154
	if (cr6.eq) goto loc_830B4154;
	// lwz r9,12(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830b4154
	if (cr6.eq) goto loc_830B4154;
	// lwz r10,16(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830b4154
	if (cr6.eq) goto loc_830B4154;
	// lwz r4,0(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm. r8,r4,0,0,11
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x830b4154
	if (cr0.eq) goto loc_830B4154;
	// lwz r5,20(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// beq cr6,0x830b3dcc
	if (cr6.eq) goto loc_830B3DCC;
	// cmplwi cr6,r9,4
	cr6.compare<uint32_t>(ctx.r9.u32, 4, xer);
	// beq cr6,0x830b3dcc
	if (cr6.eq) goto loc_830B3DCC;
	// cmplw cr6,r18,r11
	cr6.compare<uint32_t>(r18.u32, r11.u32, xer);
	// blt cr6,0x830b3dcc
	if (cr6.lt) goto loc_830B3DCC;
	// subf r10,r11,r18
	ctx.r10.s64 = r18.s64 - r11.s64;
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// bge cr6,0x830b3d84
	if (!cr6.lt) goto loc_830B3D84;
	// subf r10,r11,r18
	ctx.r10.s64 = r18.s64 - r11.s64;
	// lwz r7,564(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 564);
	// subf r9,r11,r18
	ctx.r9.s64 = r18.s64 - r11.s64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
loc_830B3D50:
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r10,r7
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830b3d70
	if (cr6.eq) goto loc_830B3D70;
	// rotlwi r10,r3,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830b3d84
	if (!cr0.eq) goto loc_830B3D84;
loc_830B3D70:
	// addi r10,r9,1
	ctx.r10.s64 = ctx.r9.s64 + 1;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b3d50
	if (cr6.lt) goto loc_830B3D50;
loc_830B3D84:
	// subf r11,r11,r8
	r11.s64 = ctx.r8.s64 - r11.s64;
	// add r11,r11,r18
	r11.u64 = r11.u64 + r18.u64;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// bge cr6,0x830b3dcc
	if (!cr6.lt) goto loc_830B3DCC;
	// lwz r10,564(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 564);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r19,r11,r10
	r19.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,12(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 12);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x830b3dc8
	if (!cr6.eq) goto loc_830B3DC8;
	// lwz r11,16(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x830b3dcc
	if (cr6.eq) goto loc_830B3DCC;
loc_830B3DC8:
	// mr r19,r23
	r19.u64 = r23.u64;
loc_830B3DCC:
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// clrlwi r25,r4,12
	r25.u64 = ctx.r4.u32 & 0xFFFFF;
	// mr r22,r23
	r22.u64 = r23.u64;
	// divwu. r21,r11,r25
	r21.u32 = r11.u32 / r25.u32;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// twllei r25,0
	// beq 0x830b4154
	if (cr0.eq) goto loc_830B4154;
	// mr r24,r23
	r24.u64 = r23.u64;
	// rlwinm r20,r25,2,0,29
	r20.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
loc_830B3DEC:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// lwz r7,20(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// add r10,r24,r11
	ctx.r10.u64 = r24.u64 + r11.u64;
	// lwz r5,16(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwzx r11,r24,r11
	r11.u64 = PPC_LOAD_U32(r24.u32 + r11.u32);
	// std r23,0(r9)
	PPC_STORE_U64(ctx.r9.u32 + 0, r23.u64);
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// std r23,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, r23.u64);
	// lwzx r9,r8,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830b4144
	if (cr0.eq) goto loc_830B4144;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bge cr6,0x830b4144
	if (!cr6.lt) goto loc_830B4144;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830b3eac
	if (cr6.eq) goto loc_830B3EAC;
	// lwz r8,0(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r11,r23
	r11.u64 = r23.u64;
	// rlwinm r6,r8,0,0,11
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFF00000;
loc_830B3E4C:
	// cmplw cr6,r6,r14
	cr6.compare<uint32_t>(ctx.r6.u32, r14.u32, xer);
	// bne cr6,0x830b3e5c
	if (!cr6.eq) goto loc_830B3E5C;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// b 0x830b3e70
	goto loc_830B3E70;
loc_830B3E5C:
	// lwz r8,16(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
loc_830B3E70:
	// lwz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r1,96
	r30.s64 = ctx.r1.s64 + 96;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwzx r4,r4,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r7.u32);
	// cmplw cr6,r9,r25
	cr6.compare<uint32_t>(ctx.r9.u32, r25.u32, xer);
	// stwx r17,r8,r30
	PPC_STORE_U32(ctx.r8.u32 + r30.u32, r17.u32);
	// lfd f0,32(r4)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r4.u32 + 32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfsx f0,r8,r3
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// blt cr6,0x830b3e4c
	if (cr6.lt) goto loc_830B3E4C;
loc_830B3EAC:
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x830b3f10
	if (cr6.eq) goto loc_830B3F10;
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b3f10
	if (cr6.eq) goto loc_830B3F10;
	// lwz r9,8(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
loc_830B3EC8:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r5
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// lwz r6,4(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm. r6,r6,0,23,23
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x830b3f04
	if (cr0.eq) goto loc_830B3F04;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bge cr6,0x830b3f04
	if (!cr6.lt) goto loc_830B3F04;
	// lfd f0,32(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// stw r17,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r17.u32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,124(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
loc_830B3F04:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830b3ec8
	if (!cr0.eq) goto loc_830B3EC8;
loc_830B3F10:
	// mr r28,r23
	r28.u64 = r23.u64;
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
loc_830B3F18:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830b3f84
	if (!cr6.eq) goto loc_830B3F84;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// rlwinm r10,r28,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r11,r23
	r11.u64 = r23.u64;
loc_830B3F30:
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// lwzx r7,r11,r7
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x830b3f6c
	if (cr6.eq) goto loc_830B3F6C;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// addi r6,r1,288
	ctx.r6.s64 = ctx.r1.s64 + 288;
	// lfsx f0,r11,r7
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	f0.f64 = double(temp.f32);
	// lfsx f13,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x830b3f6c
	if (cr6.eq) goto loc_830B3F6C;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// lwzx r7,r10,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x830b3f6c
	if (cr6.eq) goto loc_830B3F6C;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
loc_830B3F6C:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830b3f30
	if (cr6.lt) goto loc_830B3F30;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x830b3f94
	if (!cr6.eq) goto loc_830B3F94;
loc_830B3F84:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplwi cr6,r28,8
	cr6.compare<uint32_t>(r28.u32, 8, xer);
	// blt cr6,0x830b3f18
	if (cr6.lt) goto loc_830B3F18;
loc_830B3F94:
	// cmplwi cr6,r28,8
	cr6.compare<uint32_t>(r28.u32, 8, xer);
	// beq cr6,0x830b41cc
	if (cr6.eq) goto loc_830B41CC;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// mr r11,r23
	r11.u64 = r23.u64;
loc_830B3FA8:
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830b3ff0
	if (cr6.eq) goto loc_830B3FF0;
	// rlwinm r9,r28,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r5,r1,288
	ctx.r5.s64 = ctx.r1.s64 + 288;
	// lfsx f0,r11,r7
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// stwx r17,r9,r6
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, r17.u32);
	// stfsx f0,r9,r5
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// bgt cr6,0x830b3fec
	if (cr6.gt) goto loc_830B3FEC;
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// bge cr6,0x830b3ff0
	if (!cr6.lt) goto loc_830B3FF0;
loc_830B3FEC:
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
loc_830B3FF0:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830b3fa8
	if (cr6.lt) goto loc_830B3FA8;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x830b401c
	if (cr6.eq) goto loc_830B401C;
	// li r5,4704
	ctx.r5.s64 = 4704;
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,60(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 60);
	// bl 0x8308bee8
	sub_8308BEE8(ctx, base);
loc_830B401C:
	// mr r29,r23
	r29.u64 = r23.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830b40b4
	if (cr6.eq) goto loc_830B40B4;
	// mr r30,r23
	r30.u64 = r23.u64;
	// mr r31,r24
	r31.u64 = r24.u64;
loc_830B4030:
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// lwz r9,0(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// rlwinm r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// lwzx r10,r31,r10
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// cmplw cr6,r9,r14
	cr6.compare<uint32_t>(ctx.r9.u32, r14.u32, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lfd f1,32(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// bne cr6,0x830b406c
	if (!cr6.eq) goto loc_830B406C;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// b 0x830b4080
	goto loc_830B4080;
loc_830B406C:
	// lwz r9,16(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwzx r10,r30,r9
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_830B4080:
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r23,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r23.u32);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// blt cr6,0x830b4030
	if (cr6.lt) goto loc_830B4030;
	// lwz r31,80(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_830B40B4:
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x830b4144
	if (cr6.eq) goto loc_830B4144;
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// mr r30,r23
	r30.u64 = r23.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b4144
	if (!cr6.gt) goto loc_830B4144;
	// mr r31,r23
	r31.u64 = r23.u64;
loc_830B40D0:
	// lwz r11,8(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// lwz r9,20(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r8,16(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwzx r10,r31,r11
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// rlwinm r11,r10,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830b412c
	if (cr0.eq) goto loc_830B412C;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830b412c
	if (!cr6.lt) goto loc_830B412C;
	// li r6,3
	ctx.r6.s64 = 3;
	// lfd f1,32(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,8(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
loc_830B412C:
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830b40d0
	if (cr6.lt) goto loc_830B40D0;
	// lwz r31,80(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_830B4144:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// add r24,r20,r24
	r24.u64 = r20.u64 + r24.u64;
	// cmplw cr6,r22,r21
	cr6.compare<uint32_t>(r22.u32, r21.u32, xer);
	// blt cr6,0x830b3dec
	if (cr6.lt) goto loc_830B3DEC;
loc_830B4154:
	// lwz r6,552(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 552);
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// lwz r11,548(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 548);
	// addi r15,r15,4
	r15.s64 = r15.s64 + 4;
	// add r10,r11,r6
	ctx.r10.u64 = r11.u64 + ctx.r6.u64;
	// cmplw cr6,r18,r10
	cr6.compare<uint32_t>(r18.u32, ctx.r10.u32, xer);
	// blt cr6,0x830b3c84
	if (cr6.lt) goto loc_830B3C84;
loc_830B4170:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b41b8
	if (cr6.eq) goto loc_830B41B8;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
loc_830B4180:
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r8,16(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm. r8,r8,0,23,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x830b41ac
	if (cr0.eq) goto loc_830B41AC;
	// lwz r8,116(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 116);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
loc_830B41AC:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830b4180
	if (!cr0.eq) goto loc_830B4180;
loc_830B41B8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B41BC:
	// addi r1,r1,592
	ctx.r1.s64 = ctx.r1.s64 + 592;
	// lfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82ca2c00
	return;
loc_830B41CC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,30424
	ctx.r6.s64 = r11.s64 + 30424;
	// b 0x830b3ca0
	goto loc_830B3CA0;
}

__attribute__((alias("__imp__sub_830B41D8"))) PPC_WEAK_FUNC(sub_830B41D8);
PPC_FUNC_IMPL(__imp__sub_830B41D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830b43d4
	if (cr6.eq) goto loc_830B43D4;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// lis r22,29200
	r22.s64 = 1913651200;
loc_830B41F8:
	// lwz r25,0(r23)
	r25.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830b43c4
	if (cr6.eq) goto loc_830B43C4;
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b43c4
	if (cr6.eq) goto loc_830B43C4;
	// rlwinm r11,r10,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// lis r9,24576
	ctx.r9.s64 = 1610612736;
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b430c
	if (cr6.eq) goto loc_830B430C;
	// lis r9,24656
	ctx.r9.s64 = 1615855616;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b430c
	if (cr6.eq) goto loc_830B430C;
	// lis r9,24736
	ctx.r9.s64 = 1621098496;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b430c
	if (cr6.eq) goto loc_830B430C;
	// lis r9,24816
	ctx.r9.s64 = 1626341376;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b430c
	if (cr6.eq) goto loc_830B430C;
	// lis r9,29408
	ctx.r9.s64 = 1927282688;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b430c
	if (cr6.eq) goto loc_830B430C;
	// lis r9,24688
	ctx.r9.s64 = 1617952768;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b430c
	if (cr6.eq) goto loc_830B430C;
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// beq cr6,0x830b4314
	if (cr6.eq) goto loc_830B4314;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830b43c4
	if (cr6.eq) goto loc_830B43C4;
	// lwz r29,4(r25)
	r29.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
loc_830B427C:
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b42f8
	if (cr6.eq) goto loc_830B42F8;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 8);
loc_830B4290:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b42b4
	if (cr6.eq) goto loc_830B42B4;
	// lwz r27,20(r3)
	r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b42e8
	if (!cr6.eq) goto loc_830B42E8;
loc_830B42B4:
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b42e8
	if (cr6.eq) goto loc_830B42E8;
	// cmplw cr6,r4,r24
	cr6.compare<uint32_t>(ctx.r4.u32, r24.u32, xer);
	// bge cr6,0x830b42e8
	if (!cr6.lt) goto loc_830B42E8;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b42e8
	if (cr6.eq) goto loc_830B42E8;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// lis r27,4352
	r27.s64 = 285212672;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x830b43e0
	if (!cr6.eq) goto loc_830B43E0;
loc_830B42E8:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// blt cr6,0x830b4290
	if (cr6.lt) goto loc_830B4290;
loc_830B42F8:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r28,r8
	cr6.compare<uint32_t>(r28.u32, ctx.r8.u32, xer);
	// blt cr6,0x830b427c
	if (cr6.lt) goto loc_830B427C;
	// b 0x830b43c4
	goto loc_830B43C4;
loc_830B430C:
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// bne cr6,0x830b431c
	if (!cr6.eq) goto loc_830B431C;
loc_830B4314:
	// li r28,0
	r28.s64 = 0;
	// b 0x830b4320
	goto loc_830B4320;
loc_830B431C:
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
loc_830B4320:
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830b43c4
	if (cr6.eq) goto loc_830B43C4;
	// lwz r27,4(r25)
	r27.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
loc_830B4334:
	// mr r29,r28
	r29.u64 = r28.u64;
	// cmplw cr6,r28,r27
	cr6.compare<uint32_t>(r28.u32, r27.u32, xer);
	// bge cr6,0x830b43b4
	if (!cr6.lt) goto loc_830B43B4;
	// lwz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// rlwinm r11,r28,2,0,29
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
loc_830B4350:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r9,r30
	cr6.compare<uint32_t>(ctx.r9.u32, r30.u32, xer);
	// bne cr6,0x830b4380
	if (!cr6.eq) goto loc_830B4380;
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b4380
	if (cr6.eq) goto loc_830B4380;
	// cmplw cr6,r4,r24
	cr6.compare<uint32_t>(ctx.r4.u32, r24.u32, xer);
	// bge cr6,0x830b4380
	if (!cr6.lt) goto loc_830B4380;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830b43e0
	if (!cr6.eq) goto loc_830B43E0;
loc_830B4380:
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r9,60(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// rlwinm. r9,r9,0,11,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1F0000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830b43e8
	if (!cr0.eq) goto loc_830B43E8;
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830b43e8
	if (!cr6.eq) goto loc_830B43E8;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r29,r27
	cr6.compare<uint32_t>(r29.u32, r27.u32, xer);
	// blt cr6,0x830b4350
	if (cr6.lt) goto loc_830B4350;
loc_830B43B4:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r26,r8
	cr6.compare<uint32_t>(r26.u32, ctx.r8.u32, xer);
	// blt cr6,0x830b4334
	if (cr6.lt) goto loc_830B4334;
loc_830B43C4:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r23,r23,4
	r23.s64 = r23.s64 + 4;
	// cmplw cr6,r24,r6
	cr6.compare<uint32_t>(r24.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b41f8
	if (cr6.lt) goto loc_830B41F8;
loc_830B43D4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B43D8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
loc_830B43E0:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830b43d8
	goto loc_830B43D8;
loc_830B43E8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4806
	ctx.r5.s64 = 4806;
	// addi r6,r11,30600
	ctx.r6.s64 = r11.s64 + 30600;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b43d8
	goto loc_830B43D8;
}

__attribute__((alias("__imp__sub_830B4408"))) PPC_WEAK_FUNC(sub_830B4408);
PPC_FUNC_IMPL(__imp__sub_830B4408) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb4
	// stfd f31,-152(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -152, f31.u64);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// mr r16,r4
	r16.u64 = ctx.r4.u64;
	// mr r15,r6
	r15.u64 = ctx.r6.u64;
	// li r29,0
	r29.s64 = 0;
	// li r17,0
	r17.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830b44ec
	if (cr6.eq) goto loc_830B44EC;
loc_830B4438:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b44d4
	if (cr6.eq) goto loc_830B44D4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r9,r10,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830b44d4
	if (cr0.eq) goto loc_830B44D4;
	// clrlwi. r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830b44d4
	if (cr0.eq) goto loc_830B44D4;
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830b44d4
	if (cr6.eq) goto loc_830B44D4;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r6,20(r19)
	ctx.r6.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r3,12(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r3,r15
	cr6.compare<uint32_t>(ctx.r3.u32, r15.u32, xer);
	// bne cr6,0x830b44d4
	if (!cr6.eq) goto loc_830B44D4;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r3,136(r19)
	ctx.r3.u64 = PPC_LOAD_U32(r19.u32 + 136);
	// cmplw cr6,r10,r3
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r3.u32, xer);
	// bne cr6,0x830b44d4
	if (!cr6.eq) goto loc_830B44D4;
	// mr r29,r11
	r29.u64 = r11.u64;
	// mr r17,r7
	r17.u64 = ctx.r7.u64;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830b44d4
	if (cr6.eq) goto loc_830B44D4;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
loc_830B44AC:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// cmplwi cr6,r9,2
	cr6.compare<uint32_t>(ctx.r9.u32, 2, xer);
	// beq cr6,0x830b4510
	if (cr6.eq) goto loc_830B4510;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x830b44ac
	if (cr6.lt) goto loc_830B44AC;
loc_830B44D4:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// cmplw cr6,r7,r5
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, xer);
	// blt cr6,0x830b4438
	if (cr6.lt) goto loc_830B4438;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x830b4518
	if (!cr6.eq) goto loc_830B4518;
loc_830B44EC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4823
	ctx.r5.s64 = 4823;
	// addi r6,r11,30684
	ctx.r6.s64 = r11.s64 + 30684;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b483c
	goto loc_830B483C;
loc_830B4510:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830b483c
	goto loc_830B483C;
loc_830B4518:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// li r3,116
	ctx.r3.s64 = 116;
	// rlwinm r9,r11,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// clrlwi r21,r11,12
	r21.u64 = r11.u32 & 0xFFFFF;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b4608
	if (!cr6.eq) goto loc_830B4608;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b454c
	if (cr0.eq) goto loc_830B454C;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830b4550
	goto loc_830B4550;
loc_830B454C:
	// li r31,0
	r31.s64 = 0;
loc_830B4550:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x830b4564
	if (!cr6.eq) goto loc_830B4564;
loc_830B4558:
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
	// b 0x830b4838
	goto loc_830B4838;
loc_830B4564:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,4(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// addi r6,r11,1
	ctx.r6.s64 = r11.s64 + 1;
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830b4820
	if (cr0.lt) goto loc_830B4820;
	// rlwinm r28,r17,2,0,29
	r28.u64 = __builtin_rotateleft64(r17.u32 | (r17.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r4,r28,r16
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + r16.u32);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830b4820
	if (cr0.lt) goto loc_830B4820;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r4,136(r19)
	ctx.r4.u64 = PPC_LOAD_U32(r19.u32 + 136);
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lfd f1,3376(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// beq cr6,0x830b4848
	if (cr6.eq) goto loc_830B4848;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r4,8(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lwz r4,16(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r30,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r30.u32);
	// lwzx r3,r28,r16
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + r16.u32);
	// b 0x830b4800
	goto loc_830B4800;
loc_830B4608:
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b4620
	if (cr0.eq) goto loc_830B4620;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830b4624
	goto loc_830B4624;
loc_830B4620:
	// li r31,0
	r31.s64 = 0;
loc_830B4624:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b4558
	if (cr6.eq) goto loc_830B4558;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// addi r4,r21,1
	ctx.r4.s64 = r21.s64 + 1;
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,12(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// divwu r20,r11,r21
	r20.u32 = r11.u32 / r21.u32;
	// rlwimi r4,r9,0,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// add r5,r11,r20
	ctx.r5.u64 = r11.u64 + r20.u64;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// twllei r21,0
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830b4820
	if (cr0.lt) goto loc_830B4820;
	// rlwinm r18,r17,2,0,29
	r18.u64 = __builtin_rotateleft64(r17.u32 | (r17.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r4,r18,r16
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + r16.u32);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830b4820
	if (cr0.lt) goto loc_830B4820;
	// li r22,0
	r22.s64 = 0;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x830b47fc
	if (cr6.eq) goto loc_830B47FC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// rlwinm r25,r21,2,0,29
	r25.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// li r26,0
	r26.s64 = 0;
	// addi r23,r25,4
	r23.s64 = r25.s64 + 4;
	// li r28,0
	r28.s64 = 0;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// mr r24,r25
	r24.u64 = r25.u64;
loc_830B46A4:
	// li r30,1
	r30.s64 = 1;
	// cmplwi cr6,r21,1
	cr6.compare<uint32_t>(r21.u32, 1, xer);
	// ble cr6,0x830b46fc
	if (!cr6.gt) goto loc_830B46FC;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r8,r21,-1
	ctx.r8.s64 = r21.s64 + -1;
	// lwz r10,20(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_830B46D4:
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// beq cr6,0x830b46f0
	if (cr6.eq) goto loc_830B46F0;
	// li r30,0
	r30.s64 = 0;
loc_830B46F0:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830b46d4
	if (!cr0.eq) goto loc_830B46D4;
loc_830B46FC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// add r3,r26,r11
	ctx.r3.u64 = r26.u64 + r11.u64;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// add r4,r11,r28
	ctx.r4.u64 = r11.u64 + r28.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x830b4730
	if (cr6.eq) goto loc_830B4730;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// stwx r11,r24,r10
	PPC_STORE_U32(r24.u32 + ctx.r10.u32, r11.u32);
	// b 0x830b479c
	goto loc_830B479C;
loc_830B4730:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r6,2
	ctx.r6.s64 = 2;
	// lwz r10,20(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwzx r11,r26,r11
	r11.u64 = PPC_LOAD_U32(r26.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r27,12(r30)
	r27.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830b4848
	if (cr6.eq) goto loc_830B4848;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stwx r3,r24,r11
	PPC_STORE_U32(r24.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r10,136(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 136);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b479c
	if (!cr6.eq) goto loc_830B479C;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x830b4408
	sub_830B4408(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830b4820
	if (cr0.lt) goto loc_830B4820;
loc_830B479C:
	// li r6,2
	ctx.r6.s64 = 2;
	// lwz r4,136(r19)
	ctx.r4.u64 = PPC_LOAD_U32(r19.u32 + 136);
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// beq cr6,0x830b4848
	if (cr6.eq) goto loc_830B4848;
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lwz r4,16(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r25,r28
	r28.u64 = r25.u64 + r28.u64;
	// add r26,r23,r26
	r26.u64 = r23.u64 + r26.u64;
	// add r24,r23,r24
	r24.u64 = r23.u64 + r24.u64;
	// cmplw cr6,r22,r20
	cr6.compare<uint32_t>(r22.u32, r20.u32, xer);
	// stwx r30,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r30.u32);
	// blt cr6,0x830b46a4
	if (cr6.lt) goto loc_830B46A4;
loc_830B47FC:
	// lwzx r3,r18,r16
	ctx.r3.u64 = PPC_LOAD_U32(r18.u32 + r16.u32);
loc_830B4800:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8307a0a0
	sub_8307A0A0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// li r31,0
	r31.s64 = 0;
	// li r30,0
	r30.s64 = 0;
loc_830B4820:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b4838
	if (cr6.eq) goto loc_830B4838;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830B4838:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_830B483C:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// lfd f31,-152(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -152);
	// b 0x82ca2c04
	return;
loc_830B4848:
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
	// b 0x830b4820
	goto loc_830B4820;
}

__attribute__((alias("__imp__sub_830B4858"))) PPC_WEAK_FUNC(sub_830B4858);
PPC_FUNC_IMPL(__imp__sub_830B4858) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r29,0
	r29.s64 = 0;
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b4920
	if (!cr6.gt) goto loc_830B4920;
	// li r30,0
	r30.s64 = 0;
loc_830B487C:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r10,r30,r11
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b490c
	if (cr6.eq) goto loc_830B490C;
	// rotlwi r10,r11,0
	ctx.r10.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lis r9,24656
	ctx.r9.s64 = 1615855616;
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r10,0,0,11
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b48c4
	if (cr6.eq) goto loc_830B48C4;
	// lwzx r9,r30,r11
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lis r8,24576
	ctx.r8.s64 = 1610612736;
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b490c
	if (!cr6.eq) goto loc_830B490C;
loc_830B48C4:
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r8,136(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b490c
	if (!cr6.eq) goto loc_830B490C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r5,548(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// bl 0x830b4408
	sub_830B4408(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b4924
	if (cr0.lt) goto loc_830B4924;
loc_830B490C:
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830b487c
	if (cr6.lt) goto loc_830B487C;
loc_830B4920:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B4924:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830B4930"))) PPC_WEAK_FUNC(sub_830B4930);
PPC_FUNC_IMPL(__imp__sub_830B4930) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-768(r1)
	ea = -768 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r20,0
	r20.s64 = 0;
	// mr r15,r4
	r15.u64 = ctx.r4.u64;
	// mr r16,r5
	r16.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r15,796(r1)
	PPC_STORE_U32(ctx.r1.u32 + 796, r15.u32);
	// mr r19,r20
	r19.u64 = r20.u64;
	// stw r16,804(r1)
	PPC_STORE_U32(ctx.r1.u32 + 804, r16.u32);
	// li r5,96
	ctx.r5.s64 = 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r19,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r19.u32);
	// addi r3,r1,480
	ctx.r3.s64 = ctx.r1.s64 + 480;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// li r5,96
	ctx.r5.s64 = 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// std r20,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r20.u64);
	// std r20,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r20.u64);
	// std r20,16(r11)
	PPC_STORE_U64(r11.u32 + 16, r20.u64);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// addi r8,r1,416
	ctx.r8.s64 = ctx.r1.s64 + 416;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r7,r1,448
	ctx.r7.s64 = ctx.r1.s64 + 448;
	// li r17,-1
	r17.s64 = -1;
	// mr r11,r20
	r11.u64 = r20.u64;
	// std r20,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, r20.u64);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// std r20,0(r8)
	PPC_STORE_U64(ctx.r8.u32 + 0, r20.u64);
	// std r20,0(r7)
	PPC_STORE_U64(ctx.r7.u32 + 0, r20.u64);
	// std r20,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, r20.u64);
	// std r20,8(r8)
	PPC_STORE_U64(ctx.r8.u32 + 8, r20.u64);
	// std r20,8(r7)
	PPC_STORE_U64(ctx.r7.u32 + 8, r20.u64);
	// std r20,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, r20.u64);
	// std r20,16(r8)
	PPC_STORE_U64(ctx.r8.u32 + 16, r20.u64);
	// std r20,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, r20.u64);
	// ble cr6,0x830b4a08
	if (!cr6.gt) goto loc_830B4A08;
	// mr r10,r20
	ctx.r10.u64 = r20.u64;
loc_830B49D8:
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r8,136(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r7,4(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r7,r8
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b49f4
	if (!cr6.eq) goto loc_830B49F4;
	// stw r17,12(r9)
	PPC_STORE_U32(ctx.r9.u32 + 12, r17.u32);
loc_830B49F4:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b49d8
	if (cr6.lt) goto loc_830B49D8;
loc_830B4A08:
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// li r18,1
	r18.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b4fcc
	if (cr6.eq) goto loc_830B4FCC;
	// lwz r6,548(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// mr r21,r20
	r21.u64 = r20.u64;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830b4fcc
	if (cr6.eq) goto loc_830B4FCC;
	// mr r23,r20
	r23.u64 = r20.u64;
loc_830B4A2C:
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// lwzx r10,r11,r23
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b4fb8
	if (cr6.eq) goto loc_830B4FB8;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b4fb8
	if (cr0.eq) goto loc_830B4FB8;
	// lis r9,4352
	ctx.r9.s64 = 285212672;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b4fb8
	if (cr6.eq) goto loc_830B4FB8;
	// lis r9,24576
	ctx.r9.s64 = 1610612736;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b4db4
	if (cr6.eq) goto loc_830B4DB4;
	// lis r9,24656
	ctx.r9.s64 = 1615855616;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b4db4
	if (cr6.eq) goto loc_830B4DB4;
	// lis r9,24736
	ctx.r9.s64 = 1621098496;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b4db4
	if (cr6.eq) goto loc_830B4DB4;
	// lis r9,29408
	ctx.r9.s64 = 1927282688;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b4db4
	if (cr6.eq) goto loc_830B4DB4;
	// lis r9,24688
	ctx.r9.s64 = 1617952768;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b4db4
	if (cr6.eq) goto loc_830B4DB4;
	// lis r9,24816
	ctx.r9.s64 = 1626341376;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b4db4
	if (cr6.eq) goto loc_830B4DB4;
	// lis r9,29200
	ctx.r9.s64 = 1913651200;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b4db4
	if (cr6.eq) goto loc_830B4DB4;
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// mr r8,r20
	ctx.r8.u64 = r20.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b4b10
	if (cr6.eq) goto loc_830B4B10;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_830B4AC8:
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r5,r9
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
	// lwz r5,12(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// bne cr6,0x830b4ae8
	if (!cr6.eq) goto loc_830B4AE8;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// b 0x830b4aec
	goto loc_830B4AEC;
loc_830B4AE8:
	// mr r8,r18
	ctx.r8.u64 = r18.u64;
loc_830B4AEC:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830b4ac8
	if (!cr0.eq) goto loc_830B4AC8;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x830b4b10
	if (cr6.eq) goto loc_830B4B10;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x830b4fb8
	if (cr6.eq) goto loc_830B4FB8;
	// li r5,4808
	ctx.r5.s64 = 4808;
	// b 0x830b526c
	goto loc_830B526C;
loc_830B4B10:
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r20.u32);
	// addi r22,r21,1
	r22.s64 = r21.s64 + 1;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r9,r1,288
	ctx.r9.s64 = ctx.r1.s64 + 288;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r11,r4,r23
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + r23.u32);
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x830b3760
	sub_830B3760(ctx, base);
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r9,r1,288
	ctx.r9.s64 = ctx.r1.s64 + 288;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x830b3760
	sub_830B3760(ctx, base);
	// lwz r28,96(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_830B4B6C:
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// lwz r5,548(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// addi r6,r1,288
	ctx.r6.s64 = ctx.r1.s64 + 288;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r30,r28
	r30.u64 = r28.u64;
	// bl 0x830b3600
	sub_830B3600(ctx, base);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,288
	ctx.r6.s64 = ctx.r1.s64 + 288;
	// lwz r5,552(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x830b3600
	sub_830B3600(ctx, base);
	// lwz r28,96(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// bne cr6,0x830b4b6c
	if (!cr6.eq) goto loc_830B4B6C;
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r25,r20
	r25.u64 = r20.u64;
	// mr r27,r20
	r27.u64 = r20.u64;
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x830b4bec
	if (!cr6.eq) goto loc_830B4BEC;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r27,r11,r10
	r27.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x830b4bec
	if (cr6.eq) goto loc_830B4BEC;
	// mr r27,r20
	r27.u64 = r20.u64;
loc_830B4BEC:
	// mr r26,r20
	r26.u64 = r20.u64;
	// addi r29,r1,160
	r29.s64 = ctx.r1.s64 + 160;
	// addi r30,r1,480
	r30.s64 = ctx.r1.s64 + 480;
loc_830B4BF8:
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// lwz r5,564(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x830b41d8
	sub_830B41D8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b5c0c
	if (cr0.lt) goto loc_830B5C0C;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x830b4c78
	if (cr6.eq) goto loc_830B4C78;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830b4c6c
	if (cr6.eq) goto loc_830B4C6C;
	// mr r11,r20
	r11.u64 = r20.u64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_830B4C3C:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r9,r21
	cr6.compare<uint32_t>(ctx.r9.u32, r21.u32, xer);
	// ble cr6,0x830b4c5c
	if (!cr6.gt) goto loc_830B4C5C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x830b4c3c
	if (cr6.lt) goto loc_830B4C3C;
	// b 0x830b4c60
	goto loc_830B4C60;
loc_830B4C5C:
	// mr r25,r11
	r25.u64 = r11.u64;
loc_830B4C60:
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830b4c8c
	if (!cr6.eq) goto loc_830B4C8C;
	// b 0x830b4c78
	goto loc_830B4C78;
loc_830B4C6C:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// ble cr6,0x830b4c98
	if (!cr6.gt) goto loc_830B4C98;
loc_830B4C78:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r30,r30,16
	r30.s64 = r30.s64 + 16;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplwi cr6,r26,6
	cr6.compare<uint32_t>(r26.u32, 6, xer);
	// blt cr6,0x830b4bf8
	if (cr6.lt) goto loc_830B4BF8;
loc_830B4C8C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830b4c98
	if (cr6.eq) goto loc_830B4C98;
	// stw r25,16(r27)
	PPC_STORE_U32(r27.u32 + 16, r25.u32);
loc_830B4C98:
	// cmplwi cr6,r26,6
	cr6.compare<uint32_t>(r26.u32, 6, xer);
	// beq cr6,0x830b5218
	if (cr6.eq) goto loc_830B5218;
	// mr r24,r20
	r24.u64 = r20.u64;
	// mr r25,r20
	r25.u64 = r20.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b4d94
	if (cr6.eq) goto loc_830B4D94;
	// mr r19,r26
	r19.u64 = r26.u64;
	// rlwinm r27,r26,2,0,29
	r27.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r19,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r19.u32);
	// addi r30,r1,288
	r30.s64 = ctx.r1.s64 + 288;
loc_830B4CC0:
	// lwz r14,0(r30)
	r14.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r9,r1,100
	ctx.r9.s64 = ctx.r1.s64 + 100;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// rlwinm r10,r14,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r14.u32 | (r14.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r26,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, r26.u32);
	// lwz r6,548(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// bl 0x830b1798
	sub_830B1798(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r9,r1,100
	ctx.r9.s64 = ctx.r1.s64 + 100;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b1798
	sub_830B1798(ctx, base);
	// cmplw cr6,r3,r25
	cr6.compare<uint32_t>(ctx.r3.u32, r25.u32, xer);
	// ble cr6,0x830b4d18
	if (!cr6.gt) goto loc_830B4D18;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
loc_830B4D18:
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// blt cr6,0x830b4d38
	if (cr6.lt) goto loc_830B4D38;
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830b4d38
	if (!cr6.eq) goto loc_830B4D38;
	// addi r11,r1,416
	r11.s64 = ctx.r1.s64 + 416;
	// stwx r18,r27,r11
	PPC_STORE_U32(r27.u32 + r11.u32, r18.u32);
loc_830B4D38:
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830b4d4c
	if (cr6.eq) goto loc_830B4D4C;
	// addi r10,r1,448
	ctx.r10.s64 = ctx.r1.s64 + 448;
	// stwx r18,r27,r10
	PPC_STORE_U32(r27.u32 + ctx.r10.u32, r18.u32);
loc_830B4D4C:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x830b4d5c
	if (!cr6.eq) goto loc_830B4D5C;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830b4d60
	if (cr6.eq) goto loc_830B4D60;
loc_830B4D5C:
	// mr r29,r17
	r29.u64 = r17.u64;
loc_830B4D60:
	// cmplw cr6,r29,r24
	cr6.compare<uint32_t>(r29.u32, r24.u32, xer);
	// ble cr6,0x830b4d6c
	if (!cr6.gt) goto loc_830B4D6C;
	// mr r24,r29
	r24.u64 = r29.u64;
loc_830B4D6C:
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// addi r10,r1,480
	ctx.r10.s64 = ctx.r1.s64 + 480;
	// addi r9,r1,192
	ctx.r9.s64 = ctx.r1.s64 + 192;
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// stwx r29,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r29.u32);
	// stwx r3,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r3.u32);
	// bne 0x830b4cc0
	if (!cr0.eq) goto loc_830B4CC0;
loc_830B4D94:
	// rlwinm r11,r26,2,0,29
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stwx r24,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r24.u32);
	// stwx r25,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, r25.u32);
	// bl 0x830b3918
	sub_830B3918(ctx, base);
	// b 0x830b4fb8
	goto loc_830B4FB8;
loc_830B4DB4:
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r20.u32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// addi r9,r1,288
	ctx.r9.s64 = ctx.r1.s64 + 288;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r26,r20
	r26.u64 = r20.u64;
	// mr r25,r20
	r25.u64 = r20.u64;
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x830b3760
	sub_830B3760(ctx, base);
	// lwz r24,96(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_830B4DF0:
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// lwz r5,548(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// addi r6,r1,288
	ctx.r6.s64 = ctx.r1.s64 + 288;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r30,r24
	r30.u64 = r24.u64;
	// bl 0x830b3600
	sub_830B3600(ctx, base);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,288
	ctx.r6.s64 = ctx.r1.s64 + 288;
	// lwz r5,552(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x830b3600
	sub_830B3600(ctx, base);
	// lwz r24,96(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r30,r24
	cr6.compare<uint32_t>(r30.u32, r24.u32, xer);
	// bne cr6,0x830b4df0
	if (!cr6.eq) goto loc_830B4DF0;
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r28,r20
	r28.u64 = r20.u64;
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b4f28
	if (!cr6.gt) goto loc_830B4F28;
	// mr r19,r21
	r19.u64 = r21.u64;
	// addi r27,r21,1
	r27.s64 = r21.s64 + 1;
	// stw r19,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r19.u32);
	// mr r30,r20
	r30.u64 = r20.u64;
loc_830B4E58:
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// addi r9,r1,100
	ctx.r9.s64 = ctx.r1.s64 + 100;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r21,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, r21.u32);
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// lwzx r11,r23,r4
	r11.u64 = PPC_LOAD_U32(r23.u32 + ctx.r4.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r6,548(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// lwzx r7,r11,r30
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// bl 0x830b1798
	sub_830B1798(ctx, base);
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r9,r1,100
	ctx.r9.s64 = ctx.r1.s64 + 100;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r7,r11,r30
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// bl 0x830b1798
	sub_830B1798(ctx, base);
	// cmplw cr6,r3,r26
	cr6.compare<uint32_t>(ctx.r3.u32, r26.u32, xer);
	// ble cr6,0x830b4ed4
	if (!cr6.gt) goto loc_830B4ED4;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
loc_830B4ED4:
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830b4ee4
	if (cr6.eq) goto loc_830B4EE4;
	// mr r29,r17
	r29.u64 = r17.u64;
loc_830B4EE4:
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// ble cr6,0x830b4ef0
	if (!cr6.gt) goto loc_830B4EF0;
	// mr r25,r29
	r25.u64 = r29.u64;
loc_830B4EF0:
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// addi r9,r1,480
	ctx.r9.s64 = ctx.r1.s64 + 480;
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// add r11,r11,r23
	r11.u64 = r11.u64 + r23.u64;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwzx r10,r10,r23
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r23.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stwx r29,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, r29.u32);
	// stwx r3,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r3.u32);
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// blt cr6,0x830b4e58
	if (cr6.lt) goto loc_830B4E58;
loc_830B4F28:
	// rlwinm r11,r19,2,0,29
	r11.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// stwx r25,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r25.u32);
	// stwx r26,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, r26.u32);
	// beq cr6,0x830b4fac
	if (cr6.eq) goto loc_830B4FAC;
	// mr r19,r21
	r19.u64 = r21.u64;
	// addi r30,r1,288
	r30.s64 = ctx.r1.s64 + 288;
	// stw r19,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r19.u32);
	// mr r29,r24
	r29.u64 = r24.u64;
loc_830B4F54:
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r9,r1,100
	ctx.r9.s64 = ctx.r1.s64 + 100;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r21,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, r21.u32);
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x830b1798
	sub_830B1798(ctx, base);
	// cmplw cr6,r3,r26
	cr6.compare<uint32_t>(ctx.r3.u32, r26.u32, xer);
	// ble cr6,0x830b4f8c
	if (!cr6.gt) goto loc_830B4F8C;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
loc_830B4F8C:
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// add r11,r11,r23
	r11.u64 = r11.u64 + r23.u64;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r3,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r3.u32);
	// bne 0x830b4f54
	if (!cr0.eq) goto loc_830B4F54;
loc_830B4FAC:
	// rlwinm r11,r19,2,0,29
	r11.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stwx r26,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r26.u32);
loc_830B4FB8:
	// lwz r6,548(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r23,r23,4
	r23.s64 = r23.s64 + 4;
	// cmplw cr6,r21,r6
	cr6.compare<uint32_t>(r21.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b4a2c
	if (cr6.lt) goto loc_830B4A2C;
loc_830B4FCC:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b5bd8
	if (cr6.eq) goto loc_830B5BD8;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r14,r20
	r14.u64 = r20.u64;
	// stw r14,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r14.u32);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830b5bd8
	if (cr6.eq) goto loc_830B5BD8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830B4FF4:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r15,r14,2,0,29
	r15.u64 = __builtin_rotateleft64(r14.u32 | (r14.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r15,r11
	ctx.r10.u64 = PPC_LOAD_U32(r15.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b5bc0
	if (cr6.eq) goto loc_830B5BC0;
	// rotlwi r24,r10,0
	r24.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b5bc0
	if (cr0.eq) goto loc_830B5BC0;
	// lis r10,4352
	ctx.r10.s64 = 285212672;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5bc0
	if (cr6.eq) goto loc_830B5BC0;
	// lis r10,24576
	ctx.r10.s64 = 1610612736;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,24656
	ctx.r10.s64 = 1615855616;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,24736
	ctx.r10.s64 = 1621098496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,24816
	ctx.r10.s64 = 1626341376;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,29408
	ctx.r10.s64 = 1927282688;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,24688
	ctx.r10.s64 = 1617952768;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,29232
	ctx.r10.s64 = 1915748352;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,29264
	ctx.r10.s64 = 1917845504;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,29200
	ctx.r10.s64 = 1913651200;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,29280
	ctx.r10.s64 = 1918894080;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,29296
	ctx.r10.s64 = 1919942656;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,29312
	ctx.r10.s64 = 1920991232;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,29344
	ctx.r10.s64 = 1923088384;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,29328
	ctx.r10.s64 = 1922039808;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,29360
	ctx.r10.s64 = 1924136960;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5a0c
	if (cr6.eq) goto loc_830B5A0C;
	// lis r10,29216
	ctx.r10.s64 = 1914699776;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5bc0
	if (cr6.eq) goto loc_830B5BC0;
	// lis r10,29248
	ctx.r10.s64 = 1916796928;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5bc0
	if (cr6.eq) goto loc_830B5BC0;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,257
	cr6.compare<uint32_t>(r11.u32, 257, xer);
	// bne cr6,0x830b51dc
	if (!cr6.eq) goto loc_830B51DC;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r27,r20
	r27.u64 = r20.u64;
	// mr r9,r20
	ctx.r9.u64 = r20.u64;
	// lwzx r11,r15,r11
	r11.u64 = PPC_LOAD_U32(r15.u32 + r11.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi r11,r10,12
	r11.u64 = ctx.r10.u32 & 0xFFFFF;
	// divwu. r28,r8,r11
	r28.u32 = ctx.r8.u32 / r11.u32;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// twllei r11,0
	// beq 0x830b51dc
	if (cr0.eq) goto loc_830B51DC;
	// lwz r29,8(r24)
	r29.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
loc_830B5134:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r8,r20
	ctx.r8.u64 = r20.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r11,r3
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// beq cr6,0x830b519c
	if (cr6.eq) goto loc_830B519C;
	// lwz r5,4(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// mr r11,r29
	r11.u64 = r29.u64;
loc_830B5154:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r3
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// lwz r26,4(r10)
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r5,r26
	cr6.compare<uint32_t>(ctx.r5.u32, r26.u32, xer);
	// bne cr6,0x830b518c
	if (!cr6.eq) goto loc_830B518C;
	// lwz r26,8(r7)
	r26.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lwz r25,8(r10)
	r25.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// bne cr6,0x830b518c
	if (!cr6.eq) goto loc_830B518C;
	// lwz r26,12(r7)
	r26.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r26,r10
	cr6.compare<uint32_t>(r26.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b519c
	if (cr6.eq) goto loc_830B519C;
loc_830B518C:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b5154
	if (cr6.lt) goto loc_830B5154;
loc_830B519C:
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b51c4
	if (!cr6.eq) goto loc_830B51C4;
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// lwz r10,136(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b51c4
	if (!cr6.eq) goto loc_830B51C4;
	// lwz r11,12(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// blt cr6,0x830b51c4
	if (cr6.lt) goto loc_830B51C4;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
loc_830B51C4:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// add r4,r4,r30
	ctx.r4.u64 = ctx.r4.u64 + r30.u64;
	// cmplw cr6,r9,r28
	cr6.compare<uint32_t>(ctx.r9.u32, r28.u32, xer);
	// blt cr6,0x830b5134
	if (cr6.lt) goto loc_830B5134;
	// cmplwi cr6,r27,2
	cr6.compare<uint32_t>(r27.u32, 2, xer);
	// bgt cr6,0x830b5c18
	if (cr6.gt) goto loc_830B5C18;
loc_830B51DC:
	// lwz r11,12(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// mr r8,r20
	ctx.r8.u64 = r20.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b528c
	if (cr6.eq) goto loc_830B528C;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,16(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 16);
loc_830B51F8:
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r5,r9
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
	// lwz r5,12(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// bne cr6,0x830b5248
	if (!cr6.eq) goto loc_830B5248;
	// li r7,1
	ctx.r7.s64 = 1;
	// b 0x830b524c
	goto loc_830B524C;
loc_830B5218:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// bne cr6,0x830b5280
	if (!cr6.eq) goto loc_830B5280;
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// bne cr6,0x830b5280
	if (!cr6.eq) goto loc_830B5280;
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// rlwinm r10,r21,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
loc_830B5230:
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// li r5,4521
	ctx.r5.s64 = 4521;
	// addi r6,r9,30636
	ctx.r6.s64 = ctx.r9.s64 + 30636;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// b 0x830b5278
	goto loc_830B5278;
loc_830B5248:
	// li r8,1
	ctx.r8.s64 = 1;
loc_830B524C:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830b51f8
	if (!cr0.eq) goto loc_830B51F8;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x830b528c
	if (cr6.eq) goto loc_830B528C;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x830b5bc0
	if (cr6.eq) goto loc_830B5BC0;
	// li r5,4809
	ctx.r5.s64 = 4809;
loc_830B526C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r6,r11,30724
	ctx.r6.s64 = r11.s64 + 30724;
loc_830B5278:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830B5280:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b5c0c
	goto loc_830B5C0C;
loc_830B528C:
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r20.u32);
	// addi r17,r14,1
	r17.s64 = r14.s64 + 1;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r9,r1,480
	ctx.r9.s64 = ctx.r1.s64 + 480;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r11,r15,r4
	r11.u64 = PPC_LOAD_U32(r15.u32 + ctx.r4.u32);
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x830b3760
	sub_830B3760(ctx, base);
	// lwz r16,96(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_830B52BC:
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// lwz r5,548(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// addi r6,r1,480
	ctx.r6.s64 = ctx.r1.s64 + 480;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r30,r16
	r30.u64 = r16.u64;
	// bl 0x830b3600
	sub_830B3600(ctx, base);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,480
	ctx.r6.s64 = ctx.r1.s64 + 480;
	// lwz r5,552(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x830b3600
	sub_830B3600(ctx, base);
	// lwz r16,96(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r30,r16
	cr6.compare<uint32_t>(r30.u32, r16.u32, xer);
	// bne cr6,0x830b52bc
	if (!cr6.eq) goto loc_830B52BC;
	// lhz r27,202(r31)
	r27.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// li r29,-1
	r29.s64 = -1;
	// mr r28,r29
	r28.u64 = r29.u64;
	// cmplwi cr6,r27,258
	cr6.compare<uint32_t>(r27.u32, 258, xer);
	// beq cr6,0x830b5318
	if (cr6.eq) goto loc_830B5318;
	// cmplwi cr6,r27,259
	cr6.compare<uint32_t>(r27.u32, 259, xer);
	// bne cr6,0x830b5378
	if (!cr6.eq) goto loc_830B5378;
loc_830B5318:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// lwzx r11,r15,r11
	r11.u64 = PPC_LOAD_U32(r15.u32 + r11.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b5378
	if (!cr6.eq) goto loc_830B5378;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,136(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwz r7,4(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b535c
	if (!cr6.eq) goto loc_830B535C;
	// lwz r28,12(r8)
	r28.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
loc_830B535C:
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b5378
	if (!cr6.eq) goto loc_830B5378;
	// lwz r29,12(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_830B5378:
	// mr r30,r20
	r30.u64 = r20.u64;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x830b542c
	if (cr6.eq) goto loc_830B542C;
	// lwz r4,552(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r5,r1,480
	ctx.r5.s64 = ctx.r1.s64 + 480;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
loc_830B5390:
	// cmplw cr6,r17,r4
	cr6.compare<uint32_t>(r17.u32, ctx.r4.u32, xer);
	// bge cr6,0x830b5418
	if (!cr6.lt) goto loc_830B5418;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r10,r17,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r17.u32 | (r17.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r6,r17,r4
	ctx.r6.s64 = ctx.r4.s64 - r17.s64;
	// add r7,r10,r11
	ctx.r7.u64 = ctx.r10.u64 + r11.u64;
loc_830B53A8:
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b540c
	if (cr6.eq) goto loc_830B540C;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lis r9,28912
	ctx.r9.s64 = 1894776832;
	// rlwinm r8,r11,0,0,11
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b540c
	if (!cr6.eq) goto loc_830B540C;
	// clrlwi. r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b540c
	if (cr0.eq) goto loc_830B540C;
	// lwz r8,0(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_830B53D8:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// beq cr6,0x830b53fc
	if (cr6.eq) goto loc_830B53FC;
	// lwz r26,20(r31)
	r26.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r26
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r26.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b5400
	if (!cr6.eq) goto loc_830B5400;
loc_830B53FC:
	// li r30,1
	r30.s64 = 1;
loc_830B5400:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830b53d8
	if (!cr0.eq) goto loc_830B53D8;
loc_830B540C:
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x830b53a8
	if (!cr0.eq) goto loc_830B53A8;
loc_830B5418:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// bne 0x830b5390
	if (!cr0.eq) goto loc_830B5390;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x830b543c
	if (!cr6.eq) goto loc_830B543C;
loc_830B542C:
	// lwz r11,1104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1104);
	// li r8,1
	ctx.r8.s64 = 1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830b5440
	if (!cr6.eq) goto loc_830B5440;
loc_830B543C:
	// mr r8,r20
	ctx.r8.u64 = r20.u64;
loc_830B5440:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r7,r15,r11
	ctx.r7.u64 = PPC_LOAD_U32(r15.u32 + r11.u32);
	// lwz r9,0(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// clrlwi r11,r9,12
	r11.u64 = ctx.r9.u32 & 0xFFFFF;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x830b54d4
	if (!cr6.eq) goto loc_830B54D4;
	// rlwinm r11,r9,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b54d4
	if (cr6.eq) goto loc_830B54D4;
	// cmplwi cr6,r16,1
	cr6.compare<uint32_t>(r16.u32, 1, xer);
	// bne cr6,0x830b54d4
	if (!cr6.eq) goto loc_830B54D4;
	// lwz r11,480(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830b54d4
	if (!cr6.eq) goto loc_830B54D4;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x830b54d4
	if (cr6.eq) goto loc_830B54D4;
	// li r18,1
	r18.s64 = 1;
	// addi r10,r1,220
	ctx.r10.s64 = ctx.r1.s64 + 220;
	// addi r11,r1,132
	r11.s64 = ctx.r1.s64 + 132;
loc_830B54A0:
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r6,r14
	cr6.compare<uint32_t>(ctx.r6.u32, r14.u32, xer);
	// ble cr6,0x830b54b8
	if (!cr6.gt) goto loc_830B54B8;
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r6,r14
	cr6.compare<uint32_t>(ctx.r6.u32, r14.u32, xer);
	// ble cr6,0x830b54cc
	if (!cr6.gt) goto loc_830B54CC;
loc_830B54B8:
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplwi cr6,r18,6
	cr6.compare<uint32_t>(r18.u32, 6, xer);
	// blt cr6,0x830b54a0
	if (cr6.lt) goto loc_830B54A0;
loc_830B54CC:
	// cmplwi cr6,r18,6
	cr6.compare<uint32_t>(r18.u32, 6, xer);
	// bne cr6,0x830b5520
	if (!cr6.eq) goto loc_830B5520;
loc_830B54D4:
	// cntlzw r11,r8
	r11.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r18,r11,1
	r18.u64 = r11.u64 ^ 1;
	// cmplwi cr6,r18,6
	cr6.compare<uint32_t>(r18.u32, 6, xer);
	// bge cr6,0x830b5520
	if (!cr6.lt) goto loc_830B5520;
	// rlwinm r10,r18,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
loc_830B54F4:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r14
	cr6.compare<uint32_t>(ctx.r10.u32, r14.u32, xer);
	// bgt cr6,0x830b5510
	if (cr6.gt) goto loc_830B5510;
	// cmplw cr6,r18,r28
	cr6.compare<uint32_t>(r18.u32, r28.u32, xer);
	// beq cr6,0x830b5510
	if (cr6.eq) goto loc_830B5510;
	// cmplw cr6,r18,r29
	cr6.compare<uint32_t>(r18.u32, r29.u32, xer);
	// bne cr6,0x830b5520
	if (!cr6.eq) goto loc_830B5520;
loc_830B5510:
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r18,6
	cr6.compare<uint32_t>(r18.u32, 6, xer);
	// blt cr6,0x830b54f4
	if (cr6.lt) goto loc_830B54F4;
loc_830B5520:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x830b553c
	if (cr6.eq) goto loc_830B553C;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x830b553c
	if (!cr6.eq) goto loc_830B553C;
	// lwz r11,1104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1104);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830b5c18
	if (!cr6.eq) goto loc_830B5C18;
loc_830B553C:
	// cmplwi cr6,r18,6
	cr6.compare<uint32_t>(r18.u32, 6, xer);
	// beq cr6,0x830b5c3c
	if (cr6.eq) goto loc_830B5C3C;
	// rlwinm r11,r9,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// mr r30,r20
	r30.u64 = r20.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b5968
	if (!cr6.eq) goto loc_830B5968;
	// cmplwi cr6,r27,260
	cr6.compare<uint32_t>(r27.u32, 260, xer);
	// bge cr6,0x830b5968
	if (!cr6.lt) goto loc_830B5968;
	// lwz r11,12(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x830b5968
	if (!cr6.eq) goto loc_830B5968;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// addi r9,r1,108
	ctx.r9.s64 = ctx.r1.s64 + 108;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r11,r15,r4
	r11.u64 = PPC_LOAD_U32(r15.u32 + ctx.r4.u32);
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x830b3980
	sub_830B3980(ctx, base);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830b55b4
	if (cr6.eq) goto loc_830B55B4;
	// li r19,4
	r19.s64 = 4;
	// stw r19,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r19.u32);
	// b 0x830b55b8
	goto loc_830B55B8;
loc_830B55B4:
	// lwz r19,108(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
loc_830B55B8:
	// cmplwi cr6,r19,4
	cr6.compare<uint32_t>(r19.u32, 4, xer);
	// bge cr6,0x830b55cc
	if (!cr6.lt) goto loc_830B55CC;
	// li r19,3
	r19.s64 = 3;
	// stw r19,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r19.u32);
	// cmplwi cr6,r19,4
	cr6.compare<uint32_t>(r19.u32, 4, xer);
loc_830B55CC:
	// ble cr6,0x830b55d8
	if (!cr6.gt) goto loc_830B55D8;
	// li r19,4
	r19.s64 = 4;
	// stw r19,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r19.u32);
loc_830B55D8:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b55f4
	if (cr0.eq) goto loc_830B55F4;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x830b55f8
	goto loc_830B55F8;
loc_830B55F4:
	// mr r27,r20
	r27.u64 = r20.u64;
loc_830B55F8:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830b5c60
	if (cr6.eq) goto loc_830B5C60;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwzx r11,r15,r11
	r11.u64 = PPC_LOAD_U32(r15.u32 + r11.u32);
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b5c0c
	if (cr0.lt) goto loc_830B5C0C;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwzx r4,r15,r11
	ctx.r4.u64 = PPC_LOAD_U32(r15.u32 + r11.u32);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b5c0c
	if (cr0.lt) goto loc_830B5C0C;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r10,4(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r15,r11
	r11.u64 = PPC_LOAD_U32(r15.u32 + r11.u32);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// lwzx r11,r15,r11
	r11.u64 = PPC_LOAD_U32(r15.u32 + r11.u32);
	// lwz r21,12(r11)
	r21.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r5,r21,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stwx r27,r15,r11
	PPC_STORE_U32(r15.u32 + r11.u32, r27.u32);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b5c0c
	if (cr0.lt) goto loc_830B5C0C;
	// li r26,0
	r26.s64 = 0;
	// li r20,0
	r20.s64 = 0;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830b58ec
	if (cr6.eq) goto loc_830B58EC;
	// addi r22,r1,160
	r22.s64 = ctx.r1.s64 + 160;
loc_830B56A8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r25,0
	r25.s64 = 0;
	// lwz r23,0(r22)
	r23.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b58dc
	if (!cr6.gt) goto loc_830B58DC;
	// li r24,0
	r24.s64 = 0;
loc_830B56C0:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplw cr6,r25,r23
	cr6.compare<uint32_t>(r25.u32, r23.u32, xer);
	// lwzx r28,r24,r11
	r28.u64 = PPC_LOAD_U32(r24.u32 + r11.u32);
	// beq cr6,0x830b56dc
	if (cr6.eq) goto loc_830B56DC;
	// lwz r11,56(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 56);
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// bne cr6,0x830b58c8
	if (!cr6.eq) goto loc_830B58C8;
loc_830B56DC:
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x830b5760
	if (cr6.eq) goto loc_830B5760;
	// li r30,0
	r30.s64 = 0;
loc_830B56EC:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// stwx r3,r30,r11
	PPC_STORE_U32(r30.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830b5c60
	if (cr6.eq) goto loc_830B5C60;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,72(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 72);
	// cmplw cr6,r29,r19
	cr6.compare<uint32_t>(r29.u32, r19.u32, xer);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r9,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r9.u32);
	// lwz r10,84(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 84);
	// stw r10,84(r11)
	PPC_STORE_U32(r11.u32 + 84, ctx.r10.u32);
	// lwz r10,88(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 88);
	// stw r10,88(r11)
	PPC_STORE_U32(r11.u32 + 88, ctx.r10.u32);
	// lwz r10,60(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 60);
	// stw r10,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r10.u32);
	// blt cr6,0x830b56ec
	if (cr6.lt) goto loc_830B56EC;
loc_830B5760:
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// cmplw cr6,r17,r11
	cr6.compare<uint32_t>(r17.u32, r11.u32, xer);
	// bge cr6,0x830b58c4
	if (!cr6.lt) goto loc_830B58C4;
	// rlwinm r28,r4,2,0,29
	r28.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
loc_830B5774:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r3,r28,r11
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830b58b0
	if (cr6.eq) goto loc_830B58B0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b58b0
	if (cr6.eq) goto loc_830B58B0;
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi r7,r11,12
	ctx.r7.u64 = r11.u32 & 0xFFFFF;
	// divwu. r11,r10,r7
	r11.u32 = ctx.r10.u32 / ctx.r7.u32;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// twllei r7,0
	// beq 0x830b58b0
	if (cr0.eq) goto loc_830B58B0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r29,r7,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_830B57B4:
	// cmplwi cr6,r7,3
	cr6.compare<uint32_t>(ctx.r7.u32, 3, xer);
	// blt cr6,0x830b580c
	if (cr6.lt) goto loc_830B580C;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830b58a0
	if (cr6.eq) goto loc_830B58A0;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
loc_830B57D0:
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwzx r14,r11,r10
	r14.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplw cr6,r14,r25
	cr6.compare<uint32_t>(r14.u32, r25.u32, xer);
	// bne cr6,0x830b57f8
	if (!cr6.eq) goto loc_830B57F8;
	// lwz r14,16(r27)
	r14.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplw cr6,r4,r26
	cr6.compare<uint32_t>(ctx.r4.u32, r26.u32, xer);
	// lwzx r14,r14,r9
	r14.u64 = PPC_LOAD_U32(r14.u32 + ctx.r9.u32);
	// stwx r14,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r14.u32);
	// ble cr6,0x830b57f8
	if (!cr6.gt) goto loc_830B57F8;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
loc_830B57F8:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830b57d0
	if (!cr0.eq) goto loc_830B57D0;
	// b 0x830b589c
	goto loc_830B589C;
loc_830B580C:
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// bne cr6,0x830b5850
	if (!cr6.eq) goto loc_830B5850;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwzx r10,r11,r5
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// cmplw cr6,r10,r25
	cr6.compare<uint32_t>(ctx.r10.u32, r25.u32, xer);
	// bne cr6,0x830b58a0
	if (!cr6.eq) goto loc_830B58A0;
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplwi cr6,r19,4
	cr6.compare<uint32_t>(r19.u32, 4, xer);
	// bne cr6,0x830b5838
	if (!cr6.eq) goto loc_830B5838;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// b 0x830b583c
	goto loc_830B583C;
loc_830B5838:
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
loc_830B583C:
	// stwx r10,r11,r5
	PPC_STORE_U32(r11.u32 + ctx.r5.u32, ctx.r10.u32);
	// cmplw cr6,r4,r26
	cr6.compare<uint32_t>(ctx.r4.u32, r26.u32, xer);
	// ble cr6,0x830b58a0
	if (!cr6.gt) goto loc_830B58A0;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// b 0x830b58a0
	goto loc_830B58A0;
loc_830B5850:
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830b58a0
	if (cr6.eq) goto loc_830B58A0;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
loc_830B5864:
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwzx r14,r11,r10
	r14.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplw cr6,r14,r25
	cr6.compare<uint32_t>(r14.u32, r25.u32, xer);
	// bne cr6,0x830b588c
	if (!cr6.eq) goto loc_830B588C;
	// lwz r14,16(r27)
	r14.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplw cr6,r4,r26
	cr6.compare<uint32_t>(ctx.r4.u32, r26.u32, xer);
	// lwzx r14,r14,r9
	r14.u64 = PPC_LOAD_U32(r14.u32 + ctx.r9.u32);
	// stwx r14,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r14.u32);
	// ble cr6,0x830b588c
	if (!cr6.gt) goto loc_830B588C;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
loc_830B588C:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830b5864
	if (!cr0.eq) goto loc_830B5864;
loc_830B589C:
	// lwz r14,100(r1)
	r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
loc_830B58A0:
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// add r6,r29,r6
	ctx.r6.u64 = r29.u64 + ctx.r6.u64;
	// bne 0x830b57b4
	if (!cr0.eq) goto loc_830B57B4;
loc_830B58B0:
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x830b5774
	if (cr6.lt) goto loc_830B5774;
loc_830B58C4:
	// li r30,1
	r30.s64 = 1;
loc_830B58C8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// blt cr6,0x830b56c0
	if (cr6.lt) goto loc_830B56C0;
loc_830B58DC:
	// addi r20,r20,1
	r20.s64 = r20.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmplw cr6,r20,r21
	cr6.compare<uint32_t>(r20.u32, r21.u32, xer);
	// blt cr6,0x830b56a8
	if (cr6.lt) goto loc_830B56A8;
loc_830B58EC:
	// rlwinm r10,r18,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplw cr6,r9,r26
	cr6.compare<uint32_t>(ctx.r9.u32, r26.u32, xer);
	// bge cr6,0x830b5904
	if (!cr6.lt) goto loc_830B5904;
	// stwx r26,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r26.u32);
loc_830B5904:
	// rlwinm r11,r18,4,0,27
	r11.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplw cr6,r9,r26
	cr6.compare<uint32_t>(ctx.r9.u32, r26.u32, xer);
	// bge cr6,0x830b591c
	if (!cr6.lt) goto loc_830B591C;
	// stwx r26,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r26.u32);
loc_830B591C:
	// addi r10,r1,196
	ctx.r10.s64 = ctx.r1.s64 + 196;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplw cr6,r9,r26
	cr6.compare<uint32_t>(ctx.r9.u32, r26.u32, xer);
	// bge cr6,0x830b5930
	if (!cr6.lt) goto loc_830B5930;
	// stwx r26,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r26.u32);
loc_830B5930:
	// addi r10,r1,200
	ctx.r10.s64 = ctx.r1.s64 + 200;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplw cr6,r9,r26
	cr6.compare<uint32_t>(ctx.r9.u32, r26.u32, xer);
	// bge cr6,0x830b5944
	if (!cr6.lt) goto loc_830B5944;
	// stwx r26,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r26.u32);
loc_830B5944:
	// addi r10,r1,204
	ctx.r10.s64 = ctx.r1.s64 + 204;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplw cr6,r9,r26
	cr6.compare<uint32_t>(ctx.r9.u32, r26.u32, xer);
	// bge cr6,0x830b5958
	if (!cr6.lt) goto loc_830B5958;
	// stwx r26,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r26.u32);
loc_830B5958:
	// lwz r19,104(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// li r20,0
	r20.s64 = 0;
	// bne cr6,0x830b5bc0
	if (!cr6.eq) goto loc_830B5BC0;
loc_830B5968:
	// mr r28,r20
	r28.u64 = r20.u64;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x830b5984
	if (!cr6.eq) goto loc_830B5984;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r11,r15,r11
	r11.u64 = PPC_LOAD_U32(r15.u32 + r11.u32);
	// stw r20,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r20.u32);
	// b 0x830b5bc0
	goto loc_830B5BC0;
loc_830B5984:
	// rlwinm r27,r18,2,0,29
	r27.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r1,480
	r30.s64 = ctx.r1.s64 + 480;
	// mr r29,r16
	r29.u64 = r16.u64;
loc_830B5990:
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r9,r1,100
	ctx.r9.s64 = ctx.r1.s64 + 100;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r18,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, r18.u32);
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x830b1798
	sub_830B1798(ctx, base);
	// cmplw cr6,r3,r28
	cr6.compare<uint32_t>(ctx.r3.u32, r28.u32, xer);
	// ble cr6,0x830b59c8
	if (!cr6.gt) goto loc_830B59C8;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
loc_830B59C8:
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r3,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r3.u32);
	// bne 0x830b5990
	if (!cr0.eq) goto loc_830B5990;
	// rlwinm r10,r18,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplw cr6,r9,r28
	cr6.compare<uint32_t>(ctx.r9.u32, r28.u32, xer);
	// bge cr6,0x830b5a00
	if (!cr6.lt) goto loc_830B5A00;
	// stwx r28,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r28.u32);
loc_830B5A00:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b3918
	sub_830B3918(ctx, base);
	// b 0x830b5bc0
	goto loc_830B5BC0;
loc_830B5A0C:
	// lwz r11,12(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// mr r26,r20
	r26.u64 = r20.u64;
	// mr r23,r20
	r23.u64 = r20.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b5ba8
	if (!cr6.gt) goto loc_830B5BA8;
	// addi r27,r14,1
	r27.s64 = r14.s64 + 1;
	// mr r25,r20
	r25.u64 = r20.u64;
loc_830B5A28:
	// lwz r11,16(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 16);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lhz r9,202(r31)
	ctx.r9.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r9,260
	cr6.compare<uint32_t>(ctx.r9.u32, 260, xer);
	// lwzx r11,r11,r25
	r11.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bne cr6,0x830b5a54
	if (!cr6.eq) goto loc_830B5A54;
	// mr r19,r14
	r19.u64 = r14.u64;
	// stw r14,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, r14.u32);
	// b 0x830b5a60
	goto loc_830B5A60;
loc_830B5A54:
	// addi r11,r14,2
	r11.s64 = r14.s64 + 2;
	// stw r11,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, r11.u32);
	// mr r19,r11
	r19.u64 = r11.u64;
loc_830B5A60:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r9,r1,100
	ctx.r9.s64 = ctx.r1.s64 + 100;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r19,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r19.u32);
	// lwzx r11,r15,r4
	r11.u64 = PPC_LOAD_U32(r15.u32 + ctx.r4.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r7,r11,r25
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// bl 0x830b1798
	sub_830B1798(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// ble cr6,0x830b5a98
	if (!cr6.gt) goto loc_830B5A98;
	// mr r26,r11
	r26.u64 = r11.u64;
loc_830B5A98:
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r20.u32);
	// rlwinm r28,r19,2,0,29
	r28.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,16(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r9,r1,288
	ctx.r9.s64 = ctx.r1.s64 + 288;
	// add r7,r10,r28
	ctx.r7.u64 = ctx.r10.u64 + r28.u64;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwzx r30,r15,r4
	r30.u64 = PPC_LOAD_U32(r15.u32 + ctx.r4.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stwx r11,r7,r8
	PPC_STORE_U32(ctx.r7.u32 + ctx.r8.u32, r11.u32);
	// lwz r8,12(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r7,16(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// bl 0x830b3760
	sub_830B3760(ctx, base);
	// lwz r29,96(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_830B5AE0:
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// lwz r5,548(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// addi r6,r1,288
	ctx.r6.s64 = ctx.r1.s64 + 288;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r30,r29
	r30.u64 = r29.u64;
	// bl 0x830b3600
	sub_830B3600(ctx, base);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,288
	ctx.r6.s64 = ctx.r1.s64 + 288;
	// lwz r5,552(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x830b3600
	sub_830B3600(ctx, base);
	// lwz r29,96(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// bne cr6,0x830b5ae0
	if (!cr6.eq) goto loc_830B5AE0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b5b84
	if (cr6.eq) goto loc_830B5B84;
	// addi r30,r1,288
	r30.s64 = ctx.r1.s64 + 288;
loc_830B5B2C:
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r9,r1,100
	ctx.r9.s64 = ctx.r1.s64 + 100;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r19,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, r19.u32);
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x830b1798
	sub_830B1798(ctx, base);
	// cmplw cr6,r3,r26
	cr6.compare<uint32_t>(ctx.r3.u32, r26.u32, xer);
	// ble cr6,0x830b5b64
	if (!cr6.gt) goto loc_830B5B64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
loc_830B5B64:
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r3,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r3.u32);
	// bne 0x830b5b2c
	if (!cr0.eq) goto loc_830B5B2C;
loc_830B5B84:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b3918
	sub_830B3918(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// lwzx r24,r15,r11
	r24.u64 = PPC_LOAD_U32(r15.u32 + r11.u32);
	// lwz r11,12(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// cmplw cr6,r23,r11
	cr6.compare<uint32_t>(r23.u32, r11.u32, xer);
	// blt cr6,0x830b5a28
	if (cr6.lt) goto loc_830B5A28;
loc_830B5BA8:
	// rlwinm r10,r19,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplw cr6,r9,r26
	cr6.compare<uint32_t>(ctx.r9.u32, r26.u32, xer);
	// bge cr6,0x830b5bc0
	if (!cr6.lt) goto loc_830B5BC0;
	// stwx r26,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r26.u32);
loc_830B5BC0:
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r14,r14,1
	r14.s64 = r14.s64 + 1;
	// stw r14,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r14.u32);
	// cmplw cr6,r14,r6
	cr6.compare<uint32_t>(r14.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b4ff4
	if (cr6.lt) goto loc_830B4FF4;
	// lwz r15,796(r1)
	r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 796);
loc_830B5BD8:
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b5c08
	if (cr6.eq) goto loc_830B5C08;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// bne cr6,0x830b5c08
	if (!cr6.eq) goto loc_830B5C08;
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// bne cr6,0x830b5c08
	if (!cr6.eq) goto loc_830B5C08;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b4858
	sub_830B4858(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b5c0c
	if (cr0.lt) goto loc_830B5C0C;
loc_830B5C08:
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
loc_830B5C0C:
	// addi r1,r1,768
	ctx.r1.s64 = ctx.r1.s64 + 768;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82ca2c00
	return;
loc_830B5C18:
	// lwz r11,796(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830b5280
	if (!cr6.eq) goto loc_830B5280;
	// lwz r11,804(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830b5280
	if (!cr6.eq) goto loc_830B5280;
loc_830B5C30:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r10,r14,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r14.u32 | (r14.u64 << 32), 2) & 0xFFFFFFFC;
	// b 0x830b5230
	goto loc_830B5230;
loc_830B5C3C:
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// bne cr6,0x830b5c30
	if (!cr6.eq) goto loc_830B5C30;
	// lwz r10,804(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x830b5c30
	if (cr6.eq) goto loc_830B5C30;
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830b5280
	if (cr6.eq) goto loc_830B5280;
	// b 0x830b5c30
	goto loc_830B5C30;
loc_830B5C60:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830b5c0c
	goto loc_830B5C0C;
}

__attribute__((alias("__imp__sub_830B5C70"))) PPC_WEAK_FUNC(sub_830B5C70);
PPC_FUNC_IMPL(__imp__sub_830B5C70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2bcc
	// li r23,0
	r23.s64 = 0;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830b5d8c
	if (cr6.eq) goto loc_830B5D8C;
	// mr r22,r4
	r22.u64 = ctx.r4.u64;
loc_830B5C88:
	// lwz r25,0(r22)
	r25.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830b5d7c
	if (cr6.eq) goto loc_830B5D7C;
	// lwz r29,12(r25)
	r29.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// cmplw cr6,r29,r7
	cr6.compare<uint32_t>(r29.u32, ctx.r7.u32, xer);
	// blt cr6,0x830b5d7c
	if (cr6.lt) goto loc_830B5D7C;
	// li r24,1
	r24.s64 = 1;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830b5d94
	if (cr6.eq) goto loc_830B5D94;
	// lwz r27,20(r3)
	r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
loc_830B5CB8:
	// lwz r31,0(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r27
	r30.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// beq cr6,0x830b5d08
	if (cr6.eq) goto loc_830B5D08;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b5d5c
	if (cr6.eq) goto loc_830B5D5C;
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
loc_830B5CDC:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// beq cr6,0x830b5d5c
	if (cr6.eq) goto loc_830B5D5C;
	// lwz r21,56(r30)
	r21.u64 = PPC_LOAD_U32(r30.u32 + 56);
	// cmplw cr6,r10,r21
	cr6.compare<uint32_t>(ctx.r10.u32, r21.u32, xer);
	// beq cr6,0x830b5d5c
	if (cr6.eq) goto loc_830B5D5C;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r29
	cr6.compare<uint32_t>(ctx.r9.u32, r29.u32, xer);
	// blt cr6,0x830b5cdc
	if (cr6.lt) goto loc_830B5CDC;
	// b 0x830b5d5c
	goto loc_830B5D5C;
loc_830B5D08:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b5d5c
	if (cr6.eq) goto loc_830B5D5C;
	// lwz r10,16(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 16);
loc_830B5D14:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x830b5d2c
	if (!cr6.eq) goto loc_830B5D2C;
	// lwz r21,60(r30)
	r21.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830b5d5c
	if (cr6.eq) goto loc_830B5D5C;
loc_830B5D2C:
	// lwz r21,56(r30)
	r21.u64 = PPC_LOAD_U32(r30.u32 + 56);
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bne cr6,0x830b5d4c
	if (!cr6.eq) goto loc_830B5D4C;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b5d5c
	if (cr6.eq) goto loc_830B5D5C;
loc_830B5D4C:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r29
	cr6.compare<uint32_t>(ctx.r9.u32, r29.u32, xer);
	// blt cr6,0x830b5d14
	if (cr6.lt) goto loc_830B5D14;
loc_830B5D5C:
	// cmplw cr6,r9,r29
	cr6.compare<uint32_t>(ctx.r9.u32, r29.u32, xer);
	// bne cr6,0x830b5d68
	if (!cr6.eq) goto loc_830B5D68;
	// li r24,0
	r24.s64 = 0;
loc_830B5D68:
	// addic. r26,r26,-1
	xer.ca = r26.u32 > 0;
	r26.s64 = r26.s64 + -1;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// bne 0x830b5cb8
	if (!cr0.eq) goto loc_830B5CB8;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x830b5d94
	if (!cr6.eq) goto loc_830B5D94;
loc_830B5D7C:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmplw cr6,r23,r5
	cr6.compare<uint32_t>(r23.u32, ctx.r5.u32, xer);
	// blt cr6,0x830b5c88
	if (cr6.lt) goto loc_830B5C88;
loc_830B5D8C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B5D90:
	// b 0x82ca2c1c
	return;
loc_830B5D94:
	// rlwinm r11,r23,2,0,29
	r11.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r4
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// b 0x830b5d90
	goto loc_830B5D90;
}

__attribute__((alias("__imp__sub_830B5DA0"))) PPC_WEAK_FUNC(sub_830B5DA0);
PPC_FUNC_IMPL(__imp__sub_830B5DA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r21,r9
	r21.u64 = ctx.r9.u64;
	// mr r22,r8
	r22.u64 = ctx.r8.u64;
	// mr r20,r7
	r20.u64 = ctx.r7.u64;
	// li r28,0
	r28.s64 = 0;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// stw r28,0(r21)
	PPC_STORE_U32(r21.u32 + 0, r28.u32);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// stw r28,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r28.u32);
	// clrlwi. r7,r11,12
	ctx.r7.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// stw r28,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r28.u32);
	// bne 0x830b5dec
	if (!cr0.eq) goto loc_830B5DEC;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b5f5c
	goto loc_830B5F5C;
loc_830B5DEC:
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// twllei r7,0
	// lwz r10,276(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// divwu r23,r11,r7
	r23.u32 = r11.u32 / ctx.r7.u32;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x830b5e68
	if (!cr6.eq) goto loc_830B5E68;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830b5e68
	if (cr6.eq) goto loc_830B5E68;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// rlwinm r31,r7,2,0,29
	r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_830B5E18:
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830b5e58
	if (cr6.eq) goto loc_830B5E58;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r6,20(r25)
	ctx.r6.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
loc_830B5E30:
	// lwz r30,0(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r30,r30,2,0,29
	r30.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r30,r6
	r30.u64 = PPC_LOAD_U32(r30.u32 + ctx.r6.u32);
	// lwz r30,16(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplw cr6,r30,r9
	cr6.compare<uint32_t>(r30.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b5f10
	if (!cr6.eq) goto loc_830B5F10;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// blt cr6,0x830b5e30
	if (cr6.lt) goto loc_830B5E30;
loc_830B5E58:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// add r10,r31,r10
	ctx.r10.u64 = r31.u64 + ctx.r10.u64;
	// cmplw cr6,r3,r23
	cr6.compare<uint32_t>(ctx.r3.u32, r23.u32, xer);
	// blt cr6,0x830b5e18
	if (cr6.lt) goto loc_830B5E18;
loc_830B5E68:
	// mr r24,r28
	r24.u64 = r28.u64;
	// mr r29,r28
	r29.u64 = r28.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830b5f58
	if (cr6.eq) goto loc_830B5F58;
	// mr r30,r28
	r30.u64 = r28.u64;
	// mr r31,r28
	r31.u64 = r28.u64;
	// rlwinm r26,r7,2,0,29
	r26.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_830B5E84:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// add r6,r31,r11
	ctx.r6.u64 = r31.u64 + r11.u64;
	// bl 0x830b5c70
	sub_830B5C70(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b5f44
	if (cr0.eq) goto loc_830B5F44;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// beq cr6,0x830b5f18
	if (cr6.eq) goto loc_830B5F18;
	// lis r10,24576
	ctx.r10.s64 = 1610612736;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5edc
	if (cr6.eq) goto loc_830B5EDC;
	// lis r10,24656
	ctx.r10.s64 = 1615855616;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5edc
	if (cr6.eq) goto loc_830B5EDC;
	// lis r10,24736
	ctx.r10.s64 = 1621098496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b5edc
	if (cr6.eq) goto loc_830B5EDC;
	// lis r10,24816
	ctx.r10.s64 = 1626341376;
loc_830B5ED4:
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b5f44
	if (!cr6.eq) goto loc_830B5F44;
loc_830B5EDC:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x830b5f64
	if (!cr6.eq) goto loc_830B5F64;
	// stw r3,0(r21)
	PPC_STORE_U32(r21.u32 + 0, ctx.r3.u32);
	// li r24,1
	r24.s64 = 1;
	// stw r30,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r30.u32);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x830b5f20
	if (!cr6.eq) goto loc_830B5F20;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x830b5f3c
	goto loc_830B5F3C;
loc_830B5F10:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830b5f5c
	goto loc_830B5F5C;
loc_830B5F18:
	// lis r10,29200
	ctx.r10.s64 = 1913651200;
	// b 0x830b5ed4
	goto loc_830B5ED4;
loc_830B5F20:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm r11,r11,2,10,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x3FFFFC;
	// lwz r9,20(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
loc_830B5F3C:
	// lbz r11,110(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 110);
	// stw r11,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r11.u32);
loc_830B5F44:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// add r30,r30,r7
	r30.u64 = r30.u64 + ctx.r7.u64;
	// add r31,r31,r26
	r31.u64 = r31.u64 + r26.u64;
	// cmplw cr6,r29,r23
	cr6.compare<uint32_t>(r29.u32, r23.u32, xer);
	// blt cr6,0x830b5e84
	if (cr6.lt) goto loc_830B5E84;
loc_830B5F58:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B5F5C:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	return;
loc_830B5F64:
	// stw r28,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r28.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r28,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r28.u32);
	// stw r28,0(r21)
	PPC_STORE_U32(r21.u32 + 0, r28.u32);
	// b 0x830b5f5c
	goto loc_830B5F5C;
}

__attribute__((alias("__imp__sub_830B5F78"))) PPC_WEAK_FUNC(sub_830B5F78);
PPC_FUNC_IMPL(__imp__sub_830B5F78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r16,0
	r16.s64 = 0;
	// mr r14,r4
	r14.u64 = ctx.r4.u64;
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// mr r15,r16
	r15.u64 = r16.u64;
	// stw r14,332(r1)
	PPC_STORE_U32(ctx.r1.u32 + 332, r14.u32);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// stw r24,340(r1)
	PPC_STORE_U32(ctx.r1.u32 + 340, r24.u32);
	// mr r18,r6
	r18.u64 = ctx.r6.u64;
	// stw r15,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r15.u32);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// mr r21,r16
	r21.u64 = r16.u64;
	// beq cr6,0x830b64b8
	if (cr6.eq) goto loc_830B64B8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r19,r14
	r19.u64 = r14.u64;
	// li r17,1
	r17.s64 = 1;
	// lfd f31,3376(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830B5FC8:
	// lwz r31,0(r19)
	r31.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// mr r28,r16
	r28.u64 = r16.u64;
	// mr r26,r16
	r26.u64 = r16.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b64a4
	if (cr6.eq) goto loc_830B64A4;
	// lwz r29,0(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r10,1
	ctx.r10.s64 = 1;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// stw r17,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r17.u32);
	// addi r8,r1,104
	ctx.r8.s64 = ctx.r1.s64 + 104;
	// addi r7,r1,100
	ctx.r7.s64 = ctx.r1.s64 + 100;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// clrlwi r20,r29,12
	r20.u64 = r29.u32 & 0xFFFFF;
	// bl 0x830b5da0
	sub_830B5DA0(ctx, base);
	// lwz r25,96(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x830b60d0
	if (!cr6.eq) goto loc_830B60D0;
	// cmplwi cr6,r20,2
	cr6.compare<uint32_t>(r20.u32, 2, xer);
	// bne cr6,0x830b64a4
	if (!cr6.eq) goto loc_830B64A4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r30,548(r27)
	r30.u64 = PPC_LOAD_U32(r27.u32 + 548);
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r26,560(r27)
	r26.u64 = PPC_LOAD_U32(r27.u32 + 560);
	// addi r6,r11,8
	ctx.r6.s64 = r11.s64 + 8;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830b5c70
	sub_830B5C70(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830b5c70
	sub_830B5C70(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b64a4
	if (cr6.eq) goto loc_830B64A4;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830b64a4
	if (cr6.eq) goto loc_830B64A4;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r17,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r17.u32);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// addi r8,r1,104
	ctx.r8.s64 = ctx.r1.s64 + 104;
	// addi r7,r1,100
	ctx.r7.s64 = ctx.r1.s64 + 100;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830b5da0
	sub_830B5DA0(ctx, base);
	// lwz r30,112(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830b64a4
	if (cr6.eq) goto loc_830B64A4;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r17,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r17.u32);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r8,r1,104
	ctx.r8.s64 = ctx.r1.s64 + 104;
	// addi r7,r1,100
	ctx.r7.s64 = ctx.r1.s64 + 100;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830b5da0
	sub_830B5DA0(ctx, base);
	// lwz r25,96(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r30,r25
	cr6.compare<uint32_t>(r30.u32, r25.u32, xer);
	// bne cr6,0x830b64a4
	if (!cr6.eq) goto loc_830B64A4;
	// b 0x830b60d8
	goto loc_830B60D8;
loc_830B60D0:
	// cmplwi cr6,r20,2
	cr6.compare<uint32_t>(r20.u32, 2, xer);
	// beq cr6,0x830b64a4
	if (cr6.eq) goto loc_830B64A4;
loc_830B60D8:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830b64a4
	if (cr6.eq) goto loc_830B64A4;
	// mr r21,r16
	r21.u64 = r16.u64;
	// cmplwi cr6,r20,3
	cr6.compare<uint32_t>(r20.u32, 3, xer);
	// bne cr6,0x830b61ac
	if (!cr6.eq) goto loc_830B61AC;
	// rlwinm r11,r29,0,0,11
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0xFFF00000;
	// lis r10,24816
	ctx.r10.s64 = 1626341376;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b6108
	if (cr6.eq) goto loc_830B6108;
	// lis r10,24736
	ctx.r10.s64 = 1621098496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b64a4
	if (!cr6.eq) goto loc_830B64A4;
loc_830B6108:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
loc_830B611C:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r6,16(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b6138
	if (cr6.eq) goto loc_830B6138;
	// mr r7,r16
	ctx.r7.u64 = r16.u64;
loc_830B6138:
	// lwz r9,60(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830b6150
	if (cr6.eq) goto loc_830B6150;
	// lis r6,6
	ctx.r6.s64 = 393216;
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// bne cr6,0x830b64e4
	if (!cr6.eq) goto loc_830B64E4;
loc_830B6150:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// blt cr6,0x830b611c
	if (cr6.lt) goto loc_830B611C;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x830b64a4
	if (cr6.eq) goto loc_830B64A4;
	// lhz r11,202(r27)
	r11.u64 = PPC_LOAD_U16(r27.u32 + 202);
	// cmplwi cr6,r11,258
	cr6.compare<uint32_t>(r11.u32, 258, xer);
	// blt cr6,0x830b6510
	if (cr6.lt) goto loc_830B6510;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b6190
	if (cr0.eq) goto loc_830B6190;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// b 0x830b6194
	goto loc_830B6194;
loc_830B6190:
	// mr r21,r16
	r21.u64 = r16.u64;
loc_830B6194:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830b6544
	if (cr6.eq) goto loc_830B6544;
	// lis r4,29280
	ctx.r4.s64 = 1918894080;
	// li r5,6
	ctx.r5.s64 = 6;
	// ori r4,r4,3
	ctx.r4.u64 = ctx.r4.u64 | 3;
	// b 0x830b62a4
	goto loc_830B62A4;
loc_830B61AC:
	// cmplwi cr6,r20,2
	cr6.compare<uint32_t>(r20.u32, 2, xer);
	// bne cr6,0x830b64a4
	if (!cr6.eq) goto loc_830B64A4;
	// rlwinm r11,r29,0,0,11
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0xFFF00000;
	// lis r10,24656
	ctx.r10.s64 = 1615855616;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b64a4
	if (!cr6.eq) goto loc_830B64A4;
	// li r11,3
	r11.s64 = 3;
	// stw r16,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r16.u32);
	// li r10,2
	ctx.r10.s64 = 2;
	// stw r17,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r17.u32);
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// stw r10,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r10.u32);
	// mr r31,r17
	r31.u64 = r17.u64;
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
loc_830B61E8:
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x830b61fc
	if (!cr6.eq) goto loc_830B61FC;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// b 0x830b6200
	goto loc_830B6200;
loc_830B61FC:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
loc_830B6200:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,16(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwzx r6,r11,r6
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x830b6228
	if (cr6.eq) goto loc_830B6228;
	// mr r7,r16
	ctx.r7.u64 = r16.u64;
loc_830B6228:
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x830b623c
	if (cr6.eq) goto loc_830B623C;
	// mr r31,r16
	r31.u64 = r16.u64;
loc_830B623C:
	// lwz r11,60(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830b6538
	if (!cr6.eq) goto loc_830B6538;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplwi cr6,r8,2
	cr6.compare<uint32_t>(ctx.r8.u32, 2, xer);
	// blt cr6,0x830b61e8
	if (cr6.lt) goto loc_830B61E8;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne cr6,0x830b6264
	if (!cr6.eq) goto loc_830B6264;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// beq cr6,0x830b64a4
	if (cr6.eq) goto loc_830B64A4;
loc_830B6264:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b6280
	if (cr0.eq) goto loc_830B6280;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// b 0x830b6284
	goto loc_830B6284;
loc_830B6280:
	// mr r21,r16
	r21.u64 = r16.u64;
loc_830B6284:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830b6544
	if (cr6.eq) goto loc_830B6544;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// lis r4,29312
	ctx.r4.s64 = 1920991232;
	// bne cr6,0x830b629c
	if (!cr6.eq) goto loc_830B629C;
	// lis r4,29296
	ctx.r4.s64 = 1919942656;
loc_830B629C:
	// ori r4,r4,2
	ctx.r4.u64 = ctx.r4.u64 | 2;
	// li r5,4
	ctx.r5.s64 = 4;
loc_830B62A4:
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b64bc
	if (cr0.lt) goto loc_830B64BC;
	// mr r11,r16
	r11.u64 = r16.u64;
loc_830B62C0:
	// lwz r10,0(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// lwz r9,16(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830b62c0
	if (cr6.lt) goto loc_830B62C0;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// lwz r8,8(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r9,16(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwz r22,100(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r8,12(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r23,r8,r10
	r23.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b6350
	if (cr0.eq) goto loc_830B6350;
	// lwz r24,12(r10)
	r24.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi cr6,r24,3
	cr6.compare<uint32_t>(r24.u32, 3, xer);
	// bgt cr6,0x830b6344
	if (cr6.gt) goto loc_830B6344;
	// rlwinm r11,r24,2,0,29
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r18
	r11.u64 = PPC_LOAD_U32(r11.u32 + r18.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b638c
	if (cr6.eq) goto loc_830B638C;
loc_830B6344:
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
	// b 0x830b64bc
	goto loc_830B64BC;
loc_830B6350:
	// mr r24,r22
	r24.u64 = r22.u64;
	// cmplwi cr6,r22,4
	cr6.compare<uint32_t>(r22.u32, 4, xer);
	// bge cr6,0x830b6380
	if (!cr6.lt) goto loc_830B6380;
	// rlwinm r11,r22,2,0,29
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r18
	r11.u64 = r11.u64 + r18.u64;
loc_830B6364:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830b6380
	if (cr6.eq) goto loc_830B6380;
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r24,4
	cr6.compare<uint32_t>(r24.u32, 4, xer);
	// blt cr6,0x830b6364
	if (cr6.lt) goto loc_830B6364;
loc_830B6380:
	// cmplwi cr6,r24,4
	cr6.compare<uint32_t>(r24.u32, 4, xer);
	// beq cr6,0x830b6344
	if (cr6.eq) goto loc_830B6344;
	// stw r24,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r24.u32);
loc_830B638C:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,128(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 128);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,-1
	cr6.compare<int32_t>(r25.s32, -1, xer);
	// beq cr6,0x830b6544
	if (cr6.eq) goto loc_830B6544;
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// rlwinm r10,r25,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8307a2f8
	sub_8307A2F8(ctx, base);
	// li r11,3
	r11.s64 = 3;
	// stw r24,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r24.u32);
	// mr r31,r16
	r31.u64 = r16.u64;
	// rlwimi r11,r24,8,0,23
	r11.u64 = (__builtin_rotateleft32(r24.u32, 8) & 0xFFFFFF00) | (r11.u64 & 0xFFFFFFFF000000FF);
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// stw r11,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r11.u32);
	// beq cr6,0x830b647c
	if (cr6.eq) goto loc_830B647C;
	// rlwinm r26,r20,2,0,29
	r26.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r30,r16
	r30.u64 = r16.u64;
	// mr r29,r26
	r29.u64 = r26.u64;
loc_830B63F0:
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// lwz r4,128(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 128);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cmpwi cr6,r28,-1
	cr6.compare<int32_t>(r28.s32, -1, xer);
	// beq cr6,0x830b6544
	if (cr6.eq) goto loc_830B6544;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r10,r28,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwzx r15,r10,r9
	r15.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r14,r11,r9
	r14.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// bl 0x8307a2f8
	sub_8307A2F8(ctx, base);
	// stw r31,16(r15)
	PPC_STORE_U32(r15.u32 + 16, r31.u32);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// stw r22,12(r15)
	PPC_STORE_U32(r15.u32 + 12, r22.u32);
	// lwz r11,60(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 60);
	// cmplw cr6,r31,r20
	cr6.compare<uint32_t>(r31.u32, r20.u32, xer);
	// stw r11,60(r15)
	PPC_STORE_U32(r15.u32 + 60, r11.u32);
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// stwx r25,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, r25.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// stwx r28,r11,r29
	PPC_STORE_U32(r11.u32 + r29.u32, r28.u32);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// blt cr6,0x830b63f0
	if (cr6.lt) goto loc_830B63F0;
	// lwz r14,332(r1)
	r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// lwz r15,108(r1)
	r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
loc_830B647C:
	// rlwinm r11,r24,2,0,29
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stwx r21,r11,r18
	PPC_STORE_U32(r11.u32 + r18.u32, r21.u32);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b64bc
	if (cr0.lt) goto loc_830B64BC;
	// lwz r24,340(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// mr r21,r16
	r21.u64 = r16.u64;
	// stw r16,0(r19)
	PPC_STORE_U32(r19.u32 + 0, r16.u32);
loc_830B64A4:
	// addi r15,r15,1
	r15.s64 = r15.s64 + 1;
	// addi r19,r19,4
	r19.s64 = r19.s64 + 4;
	// stw r15,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r15.u32);
	// cmplw cr6,r15,r24
	cr6.compare<uint32_t>(r15.u32, r24.u32, xer);
	// blt cr6,0x830b5fc8
	if (cr6.lt) goto loc_830B5FC8;
loc_830B64B8:
	// mr r31,r16
	r31.u64 = r16.u64;
loc_830B64BC:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830b64d4
	if (cr6.eq) goto loc_830B64D4;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830B64D4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82ca2c00
	return;
loc_830B64E4:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r6,r10,30944
	ctx.r6.s64 = ctx.r10.s64 + 30944;
loc_830B64EC:
	// rlwinm r11,r15,2,0,29
	r11.u64 = __builtin_rotateleft64(r15.u32 | (r15.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,4535
	ctx.r5.s64 = 4535;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwzx r11,r11,r14
	r11.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830B6504:
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
	// b 0x830b64d4
	goto loc_830B64D4;
loc_830B6510:
	// rlwinm r11,r15,2,0,29
	r11.u64 = __builtin_rotateleft64(r15.u32 | (r15.u64 << 32), 2) & 0xFFFFFFFC;
	// lbz r7,203(r27)
	ctx.r7.u64 = PPC_LOAD_U8(r27.u32 + 203);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,4536
	ctx.r5.s64 = 4536;
	// addi r6,r10,30856
	ctx.r6.s64 = ctx.r10.s64 + 30856;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwzx r11,r11,r14
	r11.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// b 0x830b6504
	goto loc_830B6504;
loc_830B6538:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r6,r10,30768
	ctx.r6.s64 = ctx.r10.s64 + 30768;
	// b 0x830b64ec
	goto loc_830B64EC;
loc_830B6544:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x830b64bc
	goto loc_830B64BC;
}

__attribute__((alias("__imp__sub_830B6550"))) PPC_WEAK_FUNC(sub_830B6550);
PPC_FUNC_IMPL(__imp__sub_830B6550) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,120
	r11.s64 = ctx.r1.s64 + 120;
	// stw r4,412(r1)
	PPC_STORE_U32(ctx.r1.u32 + 412, ctx.r4.u32);
	// li r19,0
	r19.s64 = 0;
	// stw r5,420(r1)
	PPC_STORE_U32(ctx.r1.u32 + 420, ctx.r5.u32);
	// mr r15,r6
	r15.u64 = ctx.r6.u64;
	// mr r17,r19
	r17.u64 = r19.u64;
	// mr r14,r19
	r14.u64 = r19.u64;
	// stw r15,428(r1)
	PPC_STORE_U32(ctx.r1.u32 + 428, r15.u32);
	// std r19,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r19.u64);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// stw r17,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r17.u32);
	// mr r20,r7
	r20.u64 = ctx.r7.u64;
	// stw r14,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r14.u32);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// stw r19,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r19.u32);
	// beq cr6,0x830b6c3c
	if (cr6.eq) goto loc_830B6C3C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,29392
	ctx.r10.s64 = 1926234112;
	// mr r18,r4
	r18.u64 = ctx.r4.u64;
	// ori r16,r10,3
	r16.u64 = ctx.r10.u64 | 3;
	// lfd f31,3376(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830B65B4:
	// lwz r11,0(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b6c24
	if (cr6.eq) goto loc_830B6C24;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lis r8,24576
	ctx.r8.s64 = 1610612736;
	// rlwinm r7,r9,0,0,11
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// clrlwi r10,r9,12
	ctx.r10.u64 = ctx.r9.u32 & 0xFFFFF;
	// cmplw cr6,r7,r8
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, xer);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// bne cr6,0x830b65e0
	if (!cr6.eq) goto loc_830B65E0;
	// li r10,1
	ctx.r10.s64 = 1;
loc_830B65E0:
	// cmplw cr6,r10,r20
	cr6.compare<uint32_t>(ctx.r10.u32, r20.u32, xer);
	// bne cr6,0x830b6c24
	if (!cr6.eq) goto loc_830B6C24;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lis r8,4352
	ctx.r8.s64 = 285212672;
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// beq cr6,0x830b6c24
	if (cr6.eq) goto loc_830B6C24;
	// mr r22,r19
	r22.u64 = r19.u64;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x830b670c
	if (cr6.eq) goto loc_830B670C;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r27,548(r23)
	r27.u64 = PPC_LOAD_U32(r23.u32 + 548);
	// mr r31,r19
	r31.u64 = r19.u64;
	// lwz r26,560(r23)
	r26.u64 = PPC_LOAD_U32(r23.u32 + 560);
	// add r25,r10,r11
	r25.u64 = ctx.r10.u64 + r11.u64;
	// mr r24,r20
	r24.u64 = r20.u64;
loc_830B6624:
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x830b5c70
	sub_830B5C70(ctx, base);
	// addi r11,r1,184
	r11.s64 = ctx.r1.s64 + 184;
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// stwx r30,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, r30.u32);
	// beq 0x830b66f0
	if (cr0.eq) goto loc_830B66F0;
	// lis r11,20480
	r11.s64 = 1342177280;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// ori r11,r11,3
	r11.u64 = r11.u64 | 3;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830b66f0
	if (!cr6.eq) goto loc_830B66F0;
	// addi r11,r1,200
	r11.s64 = ctx.r1.s64 + 200;
	// stw r19,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r19.u32);
	// addi r8,r1,168
	ctx.r8.s64 = ctx.r1.s64 + 168;
	// add r29,r31,r11
	r29.u64 = r31.u64 + r11.u64;
	// addi r11,r1,104
	r11.s64 = ctx.r1.s64 + 104;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// add r8,r31,r8
	ctx.r8.u64 = r31.u64 + ctx.r8.u64;
	// add r7,r31,r11
	ctx.r7.u64 = r31.u64 + r11.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x830b5da0
	sub_830B5DA0(ctx, base);
	// addi r11,r1,136
	r11.s64 = ctx.r1.s64 + 136;
	// addi r8,r1,152
	ctx.r8.s64 = ctx.r1.s64 + 152;
	// stw r19,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r19.u32);
	// add r28,r31,r11
	r28.u64 = r31.u64 + r11.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// add r8,r31,r8
	ctx.r8.u64 = r31.u64 + ctx.r8.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x830b5da0
	sub_830B5DA0(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r17,96(r1)
	r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// beq cr6,0x830b66f0
	if (cr6.eq) goto loc_830B66F0;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b66f0
	if (!cr6.eq) goto loc_830B66F0;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// bne cr6,0x830b66f4
	if (!cr6.eq) goto loc_830B66F4;
loc_830B66F0:
	// li r22,1
	r22.s64 = 1;
loc_830B66F4:
	// addic. r24,r24,-1
	xer.ca = r24.u32 > 0;
	r24.s64 = r24.s64 + -1;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// bne 0x830b6624
	if (!cr0.eq) goto loc_830B6624;
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// bne cr6,0x830b6c24
	if (!cr6.eq) goto loc_830B6C24;
loc_830B670C:
	// mr r26,r19
	r26.u64 = r19.u64;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x830b696c
	if (cr6.eq) goto loc_830B696C;
	// li r27,-4
	r27.s64 = -4;
loc_830B671C:
	// lwz r30,76(r23)
	r30.u64 = PPC_LOAD_U32(r23.u32 + 76);
	// lwz r28,552(r23)
	r28.u64 = PPC_LOAD_U32(r23.u32 + 552);
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// bge cr6,0x830b67f4
	if (!cr6.lt) goto loc_830B67F4;
	// lwz r10,564(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 564);
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// add r29,r10,r11
	r29.u64 = ctx.r10.u64 + r11.u64;
loc_830B6738:
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830b67e4
	if (cr6.eq) goto loc_830B67E4;
	// lwz r5,0(r18)
	ctx.r5.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830b67e4
	if (cr6.eq) goto loc_830B67E4;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b67e4
	if (cr6.eq) goto loc_830B67E4;
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// lwz r31,4(r5)
	r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// clrlwi r11,r10,12
	r11.u64 = ctx.r10.u32 & 0xFFFFF;
	// cmplw cr6,r10,r16
	cr6.compare<uint32_t>(ctx.r10.u32, r16.u32, xer);
	// bne cr6,0x830b6774
	if (!cr6.eq) goto loc_830B6774;
	// li r31,6
	r31.s64 = 6;
loc_830B6774:
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bge cr6,0x830b67e4
	if (!cr6.lt) goto loc_830B67E4;
	// lwz r6,4(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_830B6788:
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830b67d4
	if (cr6.eq) goto loc_830B67D4;
	// lwz r10,8(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwzx r9,r10,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
loc_830B67A0:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b6c80
	if (cr6.eq) goto loc_830B6C80;
	// lwz r25,20(r23)
	r25.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b6c80
	if (cr6.eq) goto loc_830B6C80;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b67a0
	if (cr6.lt) goto loc_830B67A0;
loc_830B67D4:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r3,r31
	cr6.compare<uint32_t>(ctx.r3.u32, r31.u32, xer);
	// blt cr6,0x830b6788
	if (cr6.lt) goto loc_830B6788;
loc_830B67E4:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// blt cr6,0x830b6738
	if (cr6.lt) goto loc_830B6738;
loc_830B67F4:
	// cmplwi cr6,r26,1
	cr6.compare<uint32_t>(r26.u32, 1, xer);
	// blt cr6,0x830b6824
	if (cr6.lt) goto loc_830B6824;
	// addi r11,r1,104
	r11.s64 = ctx.r1.s64 + 104;
	// lwz r9,136(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// add r11,r27,r11
	r11.u64 = r27.u64 + r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x830b6c94
	if (!cr6.gt) goto loc_830B6C94;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b6c94
	if (!cr6.eq) goto loc_830B6C94;
loc_830B6824:
	// addi r10,r1,188
	ctx.r10.s64 = ctx.r1.s64 + 188;
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// addi r9,r1,172
	ctx.r9.s64 = ctx.r1.s64 + 172;
	// lwzx r10,r27,r10
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + ctx.r10.u32);
	// lwzx r9,r27,r9
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r9,60(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x830b6cb0
	if (!cr6.eq) goto loc_830B6CB0;
	// addi r9,r1,156
	ctx.r9.s64 = ctx.r1.s64 + 156;
	// lwzx r9,r27,r9
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b6888
	if (cr6.eq) goto loc_830B6888;
	// lis r10,6
	ctx.r10.s64 = 393216;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b6cc0
	if (!cr6.eq) goto loc_830B6CC0;
loc_830B6888:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b68a0
	if (cr0.eq) goto loc_830B68A0;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// b 0x830b68a4
	goto loc_830B68A4;
loc_830B68A0:
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
loc_830B68A4:
	// addi r11,r1,124
	r11.s64 = ctx.r1.s64 + 124;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stwx r3,r27,r11
	PPC_STORE_U32(r27.u32 + r11.u32, ctx.r3.u32);
	// beq cr6,0x830b6cd0
	if (cr6.eq) goto loc_830B6CD0;
	// addi r11,r20,-1
	r11.s64 = r20.s64 + -1;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// bne cr6,0x830b6930
	if (!cr6.eq) goto loc_830B6930;
	// lwz r11,0(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// bne cr6,0x830b68e8
	if (!cr6.eq) goto loc_830B68E8;
	// cmplwi cr6,r20,3
	cr6.compare<uint32_t>(r20.u32, 3, xer);
	// bne cr6,0x830b6cdc
	if (!cr6.eq) goto loc_830B6CDC;
	// lis r4,29344
	ctx.r4.s64 = 1923088384;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,9
	ctx.r5.s64 = 9;
	// b 0x830b6948
	goto loc_830B6948;
loc_830B68E8:
	// lis r10,29376
	ctx.r10.s64 = 1925185536;
	// ori r10,r10,3
	ctx.r10.u64 = ctx.r10.u64 | 3;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b690c
	if (!cr6.eq) goto loc_830B690C;
	// cmplwi cr6,r20,3
	cr6.compare<uint32_t>(r20.u32, 3, xer);
	// bne cr6,0x830b6cdc
	if (!cr6.eq) goto loc_830B6CDC;
	// lis r4,29328
	ctx.r4.s64 = 1922039808;
loc_830B6904:
	// li r6,4
	ctx.r6.s64 = 4;
	// b 0x830b6944
	goto loc_830B6944;
loc_830B690C:
	// cmplwi cr6,r20,1
	cr6.compare<uint32_t>(r20.u32, 1, xer);
	// bne cr6,0x830b691c
	if (!cr6.eq) goto loc_830B691C;
	// lis r4,29360
	ctx.r4.s64 = 1924136960;
	// b 0x830b6904
	goto loc_830B6904;
loc_830B691C:
	// cmplwi cr6,r20,3
	cr6.compare<uint32_t>(r20.u32, 3, xer);
	// lis r4,29264
	ctx.r4.s64 = 1917845504;
	// beq cr6,0x830b6904
	if (cr6.eq) goto loc_830B6904;
	// lis r4,29232
	ctx.r4.s64 = 1915748352;
	// b 0x830b6904
	goto loc_830B6904;
loc_830B6930:
	// cmplwi cr6,r20,3
	cr6.compare<uint32_t>(r20.u32, 3, xer);
	// lis r4,29248
	ctx.r4.s64 = 1916796928;
	// beq cr6,0x830b6940
	if (cr6.eq) goto loc_830B6940;
	// lis r4,29216
	ctx.r4.s64 = 1914699776;
loc_830B6940:
	// li r6,0
	ctx.r6.s64 = 0;
loc_830B6944:
	// li r5,6
	ctx.r5.s64 = 6;
loc_830B6948:
	// ori r4,r4,3
	ctx.r4.u64 = ctx.r4.u64 | 3;
	// li r7,0
	ctx.r7.s64 = 0;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b6c40
	if (cr0.lt) goto loc_830B6C40;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r26,r20
	cr6.compare<uint32_t>(r26.u32, r20.u32, xer);
	// blt cr6,0x830b671c
	if (cr6.lt) goto loc_830B671C;
loc_830B696C:
	// mr r21,r19
	r21.u64 = r19.u64;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x830b6ad4
	if (cr6.eq) goto loc_830B6AD4;
	// mr r28,r19
	r28.u64 = r19.u64;
loc_830B697C:
	// addi r11,r1,152
	r11.s64 = ctx.r1.s64 + 152;
	// addi r10,r1,168
	ctx.r10.s64 = ctx.r1.s64 + 168;
	// addi r9,r1,184
	ctx.r9.s64 = ctx.r1.s64 + 184;
	// addi r8,r1,200
	ctx.r8.s64 = ctx.r1.s64 + 200;
	// addi r7,r1,120
	ctx.r7.s64 = ctx.r1.s64 + 120;
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// mr r26,r19
	r26.u64 = r19.u64;
	// lwzx r10,r28,r10
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + ctx.r10.u32);
	// li r31,12
	r31.s64 = 12;
	// lwzx r27,r28,r9
	r27.u64 = PPC_LOAD_U32(r28.u32 + ctx.r9.u32);
	// rlwinm r24,r11,2,0,29
	r24.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r22,r28,r8
	r22.u64 = PPC_LOAD_U32(r28.u32 + ctx.r8.u32);
	// rlwinm r25,r10,2,0,29
	r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r28,r7
	r30.u64 = PPC_LOAD_U32(r28.u32 + ctx.r7.u32);
loc_830B69B4:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addi r29,r31,-12
	r29.s64 = r31.s64 + -12;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// stwx r11,r10,r29
	PPC_STORE_U32(ctx.r10.u32 + r29.u32, r11.u32);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwzx r11,r24,r11
	r11.u64 = PPC_LOAD_U32(r24.u32 + r11.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stwx r11,r31,r10
	PPC_STORE_U32(r31.u32 + ctx.r10.u32, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r10,20(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// lwz r4,128(r23)
	ctx.r4.u64 = PPC_LOAD_U32(r23.u32 + 128);
	// lwzx r9,r31,r11
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r15,r11,r10
	r15.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r14,r9,r10
	r14.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r10,20(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r15,r8,r10
	r15.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// stwx r11,r31,r9
	PPC_STORE_U32(r31.u32 + ctx.r9.u32, r11.u32);
	// lwz r11,8(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// lwz r10,20(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x8307a2f8
	sub_8307A2F8(ctx, base);
	// lwz r11,0(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 0);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// lwz r10,8(r17)
	ctx.r10.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// rlwinm r11,r11,2,10,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x3FFFFC;
	// lwz r9,20(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// lwz r29,60(r14)
	r29.u64 = PPC_LOAD_U32(r14.u32 + 60);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r9
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// bl 0x8307a2f8
	sub_8307A2F8(ctx, base);
	// stw r26,16(r15)
	PPC_STORE_U32(r15.u32 + 16, r26.u32);
	// stw r29,60(r15)
	PPC_STORE_U32(r15.u32 + 60, r29.u32);
	// lwz r11,0(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r16
	cr6.compare<uint32_t>(ctx.r10.u32, r16.u32, xer);
	// bne cr6,0x830b6aa4
	if (!cr6.eq) goto loc_830B6AA4;
	// addi r10,r20,-1
	ctx.r10.s64 = r20.s64 + -1;
	// cmplw cr6,r21,r10
	cr6.compare<uint32_t>(r21.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b6aa4
	if (!cr6.eq) goto loc_830B6AA4;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r11,r31,12
	r11.s64 = r31.s64 + 12;
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stwx r10,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r10.u32);
loc_830B6AA4:
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// cmplwi cr6,r31,24
	cr6.compare<uint32_t>(r31.u32, 24, xer);
	// blt cr6,0x830b69b4
	if (cr6.lt) goto loc_830B69B4;
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r21,r20
	cr6.compare<uint32_t>(r21.u32, r20.u32, xer);
	// blt cr6,0x830b697c
	if (cr6.lt) goto loc_830B697C;
	// lwz r15,428(r1)
	r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// lwz r14,100(r1)
	r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
loc_830B6AD4:
	// addi r10,r1,120
	ctx.r10.s64 = ctx.r1.s64 + 120;
	// rlwinm r8,r20,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r11,r19
	r11.u64 = r19.u64;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r10,-4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
loc_830B6AE8:
	// lwz r9,0(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// lwz r7,16(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stwx r9,r7,r11
	PPC_STORE_U32(ctx.r7.u32 + r11.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830b6ae8
	if (cr6.lt) goto loc_830B6AE8;
	// mr r11,r19
	r11.u64 = r19.u64;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x830b6b3c
	if (cr6.eq) goto loc_830B6B3C;
	// addi r10,r1,104
	ctx.r10.s64 = ctx.r1.s64 + 104;
loc_830B6B18:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r15
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r15.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x830b6d10
	if (!cr6.eq) goto loc_830B6D10;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// blt cr6,0x830b6b18
	if (cr6.lt) goto loc_830B6B18;
loc_830B6B3C:
	// lwz r11,0(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// lwz r10,20(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// lwz r9,16(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r7,r10,0,24,24
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x830b6ce4
	if (cr0.eq) goto loc_830B6CE4;
	// andi. r10,r10,2112
	ctx.r10.u64 = ctx.r10.u64 & 2112;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// addi r10,r1,104
	ctx.r10.s64 = ctx.r1.s64 + 104;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r10,-4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	// beq 0x830b6bd0
	if (cr0.eq) goto loc_830B6BD0;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x830b6bd4
	if (cr6.eq) goto loc_830B6BD4;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r8,r14,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r14.u32 | (r14.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,412(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	// rlwinm r10,r20,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r11,r1,104
	r11.s64 = ctx.r1.s64 + 104;
	// li r5,4515
	ctx.r5.s64 = 4515;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwzx r10,r8,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// lwz r4,60(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// beq 0x830b6d00
	if (cr0.eq) goto loc_830B6D00;
	// lis r7,-32249
	ctx.r7.s64 = -2113470464;
	// addi r6,r7,31528
	ctx.r6.s64 = ctx.r7.s64 + 31528;
	// b 0x830b6d08
	goto loc_830B6D08;
loc_830B6BD0:
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
loc_830B6BD4:
	// mr r28,r19
	r28.u64 = r19.u64;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x830b6c24
	if (cr6.eq) goto loc_830B6C24;
	// mr r30,r19
	r30.u64 = r19.u64;
loc_830B6BE4:
	// addi r11,r1,104
	r11.s64 = ctx.r1.s64 + 104;
	// addi r29,r1,120
	r29.s64 = ctx.r1.s64 + 120;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwzx r4,r30,r29
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + r29.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r4,r11,r15
	PPC_STORE_U32(r11.u32 + r15.u32, ctx.r4.u32);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830b6c40
	if (cr0.lt) goto loc_830B6C40;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// stwx r19,r30,r29
	PPC_STORE_U32(r30.u32 + r29.u32, r19.u32);
	// stw r19,0(r18)
	PPC_STORE_U32(r18.u32 + 0, r19.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r28,r20
	cr6.compare<uint32_t>(r28.u32, r20.u32, xer);
	// blt cr6,0x830b6be4
	if (cr6.lt) goto loc_830B6BE4;
loc_830B6C24:
	// lwz r11,420(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// addi r14,r14,1
	r14.s64 = r14.s64 + 1;
	// addi r18,r18,4
	r18.s64 = r18.s64 + 4;
	// stw r14,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r14.u32);
	// cmplw cr6,r14,r11
	cr6.compare<uint32_t>(r14.u32, r11.u32, xer);
	// blt cr6,0x830b65b4
	if (cr6.lt) goto loc_830B65B4;
loc_830B6C3C:
	// mr r31,r19
	r31.u64 = r19.u64;
loc_830B6C40:
	// addi r30,r1,120
	r30.s64 = ctx.r1.s64 + 120;
	// li r28,3
	r28.s64 = 3;
loc_830B6C48:
	// lwz r29,0(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b6c64
	if (cr6.eq) goto loc_830B6C64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830B6C64:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x830b6c48
	if (!cr0.eq) goto loc_830B6C48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82ca2c00
	return;
loc_830B6C80:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,60(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 60);
	// li r5,4524
	ctx.r5.s64 = 4524;
	// addi r6,r11,31456
	ctx.r6.s64 = r11.s64 + 31456;
	// b 0x830b6cf4
	goto loc_830B6CF4;
loc_830B6C94:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lbz r7,203(r23)
	ctx.r7.u64 = PPC_LOAD_U8(r23.u32 + 203);
	// li r5,4525
	ctx.r5.s64 = 4525;
	// addi r6,r11,31312
	ctx.r6.s64 = r11.s64 + 31312;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// b 0x830b6d0c
	goto loc_830B6D0C;
loc_830B6CB0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4526
	ctx.r5.s64 = 4526;
	// addi r6,r11,31224
	ctx.r6.s64 = r11.s64 + 31224;
	// b 0x830b6cf0
	goto loc_830B6CF0;
loc_830B6CC0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4527
	ctx.r5.s64 = 4527;
	// addi r6,r11,31144
	ctx.r6.s64 = r11.s64 + 31144;
	// b 0x830b6cf0
	goto loc_830B6CF0;
loc_830B6CD0:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x830b6c40
	goto loc_830B6C40;
loc_830B6CDC:
	// li r31,1
	r31.s64 = 1;
	// b 0x830b6c40
	goto loc_830B6C40;
loc_830B6CE4:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4812
	ctx.r5.s64 = 4812;
	// addi r6,r11,31100
	ctx.r6.s64 = r11.s64 + 31100;
loc_830B6CF0:
	// li r4,0
	ctx.r4.s64 = 0;
loc_830B6CF4:
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// b 0x830b6d10
	goto loc_830B6D10;
loc_830B6D00:
	// lis r7,-32249
	ctx.r7.s64 = -2113470464;
	// addi r6,r7,31032
	ctx.r6.s64 = ctx.r7.s64 + 31032;
loc_830B6D08:
	// lwz r7,-4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + -4);
loc_830B6D0C:
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830B6D10:
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
	// b 0x830b6c40
	goto loc_830B6C40;
}

__attribute__((alias("__imp__sub_830B6D20"))) PPC_WEAK_FUNC(sub_830B6D20);
PPC_FUNC_IMPL(__imp__sub_830B6D20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// li r27,0
	r27.s64 = 0;
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r27,540(r31)
	PPC_STORE_U32(r31.u32 + 540, r27.u32);
	// addi r3,r31,508
	ctx.r3.s64 = r31.s64 + 508;
	// std r27,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r27.u64);
	// mr r28,r27
	r28.u64 = r27.u64;
	// stw r27,544(r31)
	PPC_STORE_U32(r31.u32 + 544, r27.u32);
	// std r27,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r27.u64);
	// mr r25,r27
	r25.u64 = r27.u64;
	// mr r26,r27
	r26.u64 = r27.u64;
	// mr r20,r27
	r20.u64 = r27.u64;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r21,r27
	r21.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b6ed4
	if (!cr6.gt) goto loc_830B6ED4;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r22,r27
	r22.u64 = r27.u64;
	// addi r24,r11,-5376
	r24.s64 = r11.s64 + -5376;
	// addi r23,r10,31604
	r23.s64 = ctx.r10.s64 + 31604;
loc_830B6D8C:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r30,r11,r22
	r30.u64 = PPC_LOAD_U32(r11.u32 + r22.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// lwzx r29,r11,r10
	r29.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// beq cr6,0x830b6dd4
	if (cr6.eq) goto loc_830B6DD4;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x830b6dd4
	if (!cr6.eq) goto loc_830B6DD4;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// lwz r4,96(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 96);
	// li r5,4511
	ctx.r5.s64 = 4511;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r25,1
	r25.s64 = 1;
	// li r28,1
	r28.s64 = 1;
loc_830B6DD4:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwinm. r10,r11,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830b6e60
	if (cr0.eq) goto loc_830B6E60;
	// lbz r10,110(r30)
	ctx.r10.u64 = PPC_LOAD_U8(r30.u32 + 110);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bgt cr6,0x830b6ed4
	if (cr6.gt) goto loc_830B6ED4;
	// lbz r11,111(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 111);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x830b6e3c
	if (cr6.eq) goto loc_830B6E3C;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x830b6ec0
	if (!cr6.eq) goto loc_830B6EC0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830b6ec0
	if (!cr6.eq) goto loc_830B6EC0;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b6ec0
	if (cr6.eq) goto loc_830B6EC0;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// bne cr6,0x830b6ec0
	if (!cr6.eq) goto loc_830B6EC0;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// lwz r4,96(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 96);
	// li r5,4528
	ctx.r5.s64 = 4528;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r26,1
	r26.s64 = 1;
	// li r28,1
	r28.s64 = 1;
	// b 0x830b6ec0
	goto loc_830B6EC0;
loc_830B6E3C:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830b6ec0
	if (!cr6.eq) goto loc_830B6EC0;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r20,96(r30)
	r20.u64 = PPC_LOAD_U32(r30.u32 + 96);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// b 0x830b6ec0
	goto loc_830B6EC0;
loc_830B6E60:
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830b6ec0
	if (cr0.eq) goto loc_830B6EC0;
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830b6ec0
	if (!cr0.eq) goto loc_830B6EC0;
	// lbz r10,111(r30)
	ctx.r10.u64 = PPC_LOAD_U8(r30.u32 + 111);
	// lbz r11,110(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 110);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x830b6e98
	if (cr6.eq) goto loc_830B6E98;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x830b6ec0
	if (!cr6.eq) goto loc_830B6EC0;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bge cr6,0x830b6ec0
	if (!cr6.lt) goto loc_830B6EC0;
	// addi r10,r11,127
	ctx.r10.s64 = r11.s64 + 127;
	// b 0x830b6ea4
	goto loc_830B6EA4;
loc_830B6E98:
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bge cr6,0x830b6ec0
	if (!cr6.lt) goto loc_830B6EC0;
	// addi r10,r11,135
	ctx.r10.s64 = r11.s64 + 135;
loc_830B6EA4:
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r9,r10,r31
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r31.u32);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bge cr6,0x830b6ec0
	if (!cr6.lt) goto loc_830B6EC0;
	// stwx r11,r10,r31
	PPC_STORE_U32(ctx.r10.u32 + r31.u32, r11.u32);
loc_830B6EC0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// blt cr6,0x830b6d8c
	if (cr6.lt) goto loc_830B6D8C;
loc_830B6ED4:
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r11,4
	r11.s64 = 4;
loc_830B6EE0:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// bne 0x830b6ee0
	if (!cr0.eq) goto loc_830B6EE0;
	// cmplwi cr6,r9,4
	cr6.compare<uint32_t>(ctx.r9.u32, 4, xer);
	// beq cr6,0x830b6f24
	if (cr6.eq) goto loc_830B6F24;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r5,4530
	ctx.r5.s64 = 4530;
	// addi r6,r11,-5480
	ctx.r6.s64 = r11.s64 + -5480;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r28,1
	r28.s64 = 1;
loc_830B6F24:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x830b6f38
	if (cr6.eq) goto loc_830B6F38;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b6f3c
	goto loc_830B6F3C;
loc_830B6F38:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_830B6F3C:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c18
	return;
}

__attribute__((alias("__imp__sub_830B6F48"))) PPC_WEAK_FUNC(sub_830B6F48);
PPC_FUNC_IMPL(__imp__sub_830B6F48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, f31.u64);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// mr r11,r30
	r11.u64 = r30.u64;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// lwz r27,16(r9)
	r27.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r26,12(r9)
	r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
loc_830B6F74:
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// addi r8,r1,144
	ctx.r8.s64 = ctx.r1.s64 + 144;
	// addi r7,r1,128
	ctx.r7.s64 = ctx.r1.s64 + 128;
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// stwx r9,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r9.u32);
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r9,28(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28);
	// stwx r9,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830b6f74
	if (cr6.lt) goto loc_830B6F74;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,132(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b7034
	if (!cr6.eq) goto loc_830B7034;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x830b6ff4
	if (cr6.eq) goto loc_830B6FF4;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,4813
	ctx.r5.s64 = 4813;
	// addi r6,r10,31648
	ctx.r6.s64 = ctx.r10.s64 + 31648;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b7118
	goto loc_830B7118;
loc_830B6FF4:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830b70a4
	if (cr6.eq) goto loc_830B70A4;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_830B7000:
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// stw r30,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r30.u32);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,136(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwz r8,0(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// bne 0x830b7000
	if (!cr0.eq) goto loc_830B7000;
loc_830B7034:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830b70a4
	if (cr6.eq) goto loc_830B70A4;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// mr r29,r27
	r29.u64 = r27.u64;
	// subf r25,r27,r11
	r25.s64 = r11.s64 - r27.s64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r28,r26
	r28.u64 = r26.u64;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830B7054:
	// li r6,0
	ctx.r6.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// stwx r3,r25,r29
	PPC_STORE_U32(r25.u32 + r29.u32, ctx.r3.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,128
	ctx.r5.s64 = 128;
	// lwzx r24,r10,r11
	r24.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwzx r4,r10,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// stw r30,60(r24)
	PPC_STORE_U32(r24.u32 + 60, r30.u32);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// bne 0x830b7054
	if (!cr0.eq) goto loc_830B7054;
loc_830B70A4:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r10,2
	ctx.r10.s64 = 2;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r8,r7,16
	ctx.r8.s64 = ctx.r7.s64 + 16;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7118
	if (cr0.lt) goto loc_830B7118;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
loc_830B7118:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// lfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// b 0x82ca2c28
	return;
}

__attribute__((alias("__imp__sub_830B7128"))) PPC_WEAK_FUNC(sub_830B7128);
PPC_FUNC_IMPL(__imp__sub_830B7128) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi r29,r10,12
	r29.u64 = ctx.r10.u32 & 0xFFFFF;
	// lwz r30,8(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r29,r9
	cr6.compare<uint32_t>(r29.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b715c
	if (!cr6.eq) goto loc_830B715C;
	// li r28,0
	r28.s64 = 0;
	// b 0x830b7164
	goto loc_830B7164;
loc_830B715C:
	// rlwinm r11,r29,2,0,29
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r11,r30
	r28.u64 = r11.u64 + r30.u64;
loc_830B7164:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// rlwinm r10,r29,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x830b7180
	if (cr6.gt) goto loc_830B7180;
	// li r27,0
	r27.s64 = 0;
	// b 0x830b7188
	goto loc_830B7188;
loc_830B7180:
	// rlwinm r11,r29,3,0,28
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 3) & 0xFFFFFFF8;
	// add r27,r11,r30
	r27.u64 = r11.u64 + r30.u64;
loc_830B7188:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83073378
	sub_83073378(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b732c
	if (cr0.lt) goto loc_830B732C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lis r5,15
	ctx.r5.s64 = 983040;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,312(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 312);
	// lbz r11,110(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 110);
	// oris r4,r11,45056
	ctx.r4.u64 = r11.u64 | 2952790016;
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b732c
	if (cr0.lt) goto loc_830B732C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b726c
	if (cr6.eq) goto loc_830B726C;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,328(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 328);
	// lwzx r4,r11,r9
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b732c
	if (cr0.lt) goto loc_830B732C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// lis r6,15
	ctx.r6.s64 = 983040;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,332(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 332);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b732c
	if (cr0.lt) goto loc_830B732C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,316(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 316);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b732c
	if (cr0.lt) goto loc_830B732C;
loc_830B726C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830b72fc
	if (cr6.eq) goto loc_830B72FC;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,328(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 328);
	// lwzx r4,r11,r9
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b732c
	if (cr0.lt) goto loc_830B732C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// lis r6,15
	ctx.r6.s64 = 983040;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,332(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 332);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b732c
	if (cr0.lt) goto loc_830B732C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,316(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 316);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b732c
	if (cr0.lt) goto loc_830B732C;
loc_830B72FC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,308(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 308);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b732c
	if (cr0.lt) goto loc_830B732C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ab90
	sub_8306AB90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b732c
	if (cr0.lt) goto loc_830B732C;
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B732C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830B7338"))) PPC_WEAK_FUNC(sub_830B7338);
PPC_FUNC_IMPL(__imp__sub_830B7338) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r4,66
	ctx.r4.s64 = 66;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r29,r11,12
	r29.u64 = r11.u32 & 0xFFFFF;
	// bl 0x83073378
	sub_83073378(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7498
	if (cr0.lt) goto loc_830B7498;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,320(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 320);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r9
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7498
	if (cr0.lt) goto loc_830B7498;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r5,15
	ctx.r5.s64 = 983040;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,312(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 312);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7498
	if (cr0.lt) goto loc_830B7498;
	// lwz r10,260(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// rlwinm r11,r29,2,0,29
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r9,328(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// add r30,r11,r10
	r30.u64 = r11.u64 + ctx.r10.u64;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7498
	if (cr0.lt) goto loc_830B7498;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// lis r6,15
	ctx.r6.s64 = 983040;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,332(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 332);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7498
	if (cr0.lt) goto loc_830B7498;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// oris r5,r10,2304
	ctx.r5.u64 = ctx.r10.u64 | 150994944;
	// lwz r11,316(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 316);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7498
	if (cr0.lt) goto loc_830B7498;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,308(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 308);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7498
	if (cr0.lt) goto loc_830B7498;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ab90
	sub_8306AB90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7498
	if (cr0.lt) goto loc_830B7498;
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B7498:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830B74A0"))) PPC_WEAK_FUNC(sub_830B74A0);
PPC_FUNC_IMPL(__imp__sub_830B74A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r4,66
	ctx.r4.s64 = 66;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r29,r11,12
	r29.u64 = r11.u32 & 0xFFFFF;
	// bl 0x83073378
	sub_83073378(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b75fc
	if (cr0.lt) goto loc_830B75FC;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,320(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 320);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r9
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b75fc
	if (cr0.lt) goto loc_830B75FC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r5,15
	ctx.r5.s64 = 983040;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,312(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 312);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b75fc
	if (cr0.lt) goto loc_830B75FC;
	// lwz r10,260(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// rlwinm r11,r29,2,0,29
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r9,328(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// add r30,r11,r10
	r30.u64 = r11.u64 + ctx.r10.u64;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b75fc
	if (cr0.lt) goto loc_830B75FC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// lis r6,15
	ctx.r6.s64 = 983040;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,332(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 332);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b75fc
	if (cr0.lt) goto loc_830B75FC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r5,2804
	ctx.r5.s64 = 183762944;
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,316(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 316);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b75fc
	if (cr0.lt) goto loc_830B75FC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,308(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 308);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b75fc
	if (cr0.lt) goto loc_830B75FC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ab90
	sub_8306AB90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b75fc
	if (cr0.lt) goto loc_830B75FC;
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B75FC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830B7608"))) PPC_WEAK_FUNC(sub_830B7608);
PPC_FUNC_IMPL(__imp__sub_830B7608) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r4,66
	ctx.r4.s64 = 66;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lhz r10,202(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r10,260
	cr6.compare<uint32_t>(ctx.r10.u32, 260, xer);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r29,r11,12
	r29.u64 = r11.u32 & 0xFFFFF;
	// bne cr6,0x830b7778
	if (!cr6.eq) goto loc_830B7778;
	// bl 0x83073378
	sub_83073378(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7770
	if (cr0.lt) goto loc_830B7770;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,320(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 320);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r9
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7770
	if (cr0.lt) goto loc_830B7770;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r5,15
	ctx.r5.s64 = 983040;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,312(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 312);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7770
	if (cr0.lt) goto loc_830B7770;
	// lwz r10,260(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// rlwinm r11,r29,2,0,29
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r9,328(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// add r30,r11,r10
	r30.u64 = r11.u64 + ctx.r10.u64;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7770
	if (cr0.lt) goto loc_830B7770;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// lis r6,15
	ctx.r6.s64 = 983040;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,332(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 332);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7770
	if (cr0.lt) goto loc_830B7770;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r11,316(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 316);
loc_830B7728:
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7770
	if (cr0.lt) goto loc_830B7770;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,308(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 308);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7770
	if (cr0.lt) goto loc_830B7770;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ab90
	sub_8306AB90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7770
	if (cr0.lt) goto loc_830B7770;
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B7770:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_830B7778:
	// bl 0x83073378
	sub_83073378(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7770
	if (cr0.lt) goto loc_830B7770;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,320(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 320);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r9
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7770
	if (cr0.lt) goto loc_830B7770;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lis r5,15
	ctx.r5.s64 = 983040;
	// lwz r11,312(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 312);
	// b 0x830b7728
	goto loc_830B7728;
}

__attribute__((alias("__imp__sub_830B77D8"))) PPC_WEAK_FUNC(sub_830B77D8);
PPC_FUNC_IMPL(__imp__sub_830B77D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r4,64
	ctx.r4.s64 = 64;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lhz r9,202(r31)
	ctx.r9.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi cr6,r9,260
	cr6.compare<uint32_t>(ctx.r9.u32, 260, xer);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r29,r11,12
	r29.u64 = r11.u32 & 0xFFFFF;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bne cr6,0x830b7970
	if (!cr6.eq) goto loc_830B7970;
	// bl 0x83073378
	sub_83073378(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,320(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 320);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// lwz r10,260(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,324(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 324);
	// lwz r4,16(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r5,7
	ctx.r5.s64 = 458752;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,312(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 312);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r6,r1,92
	ctx.r6.s64 = ctx.r1.s64 + 92;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r30,8(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,328(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 328);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r10,r9
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// lwz r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,332(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 332);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r5,228
	ctx.r5.s64 = 14942208;
	// lwz r6,92(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r11,316(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 316);
loc_830B7920:
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,308(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 308);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ab90
	sub_8306AB90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B7968:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_830B7970:
	// bl 0x83073378
	sub_83073378(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,320(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 320);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// lwz r10,260(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,324(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 324);
	// lwz r4,16(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7968
	if (cr0.lt) goto loc_830B7968;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lis r5,15
	ctx.r5.s64 = 983040;
	// lwz r11,312(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 312);
	// b 0x830b7920
	goto loc_830B7920;
}

__attribute__((alias("__imp__sub_830B79F0"))) PPC_WEAK_FUNC(sub_830B79F0);
PPC_FUNC_IMPL(__imp__sub_830B79F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,260(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 260);
	// oris r3,r4,16384
	ctx.r3.u64 = ctx.r4.u64 | 1073741824;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830B7A10"))) PPC_WEAK_FUNC(sub_830B7A10);
PPC_FUNC_IMPL(__imp__sub_830B7A10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r4,200(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7a48
	if (cr0.lt) goto loc_830B7A48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ab90
	sub_8306AB90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b7a48
	if (cr0.lt) goto loc_830B7A48;
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B7A48:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830B7A60"))) PPC_WEAK_FUNC(sub_830B7A60);
PPC_FUNC_IMPL(__imp__sub_830B7A60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r10,111(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 111);
	// lbz r11,110(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 110);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x830b7a88
	if (!cr6.eq) goto loc_830B7A88;
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x830b7ab0
	if (cr6.lt) goto loc_830B7AB0;
loc_830B7A7C:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
loc_830B7A88:
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x830b7aa4
	if (!cr6.eq) goto loc_830B7AA4;
	// lwz r10,60(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x830b7a7c
	if (!cr6.lt) goto loc_830B7A7C;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// b 0x830b7ab0
	goto loc_830B7AB0;
loc_830B7AA4:
	// cmplwi cr6,r10,5
	cr6.compare<uint32_t>(ctx.r10.u32, 5, xer);
	// bne cr6,0x830b7a7c
	if (!cr6.eq) goto loc_830B7A7C;
	// li r11,12
	r11.s64 = 12;
loc_830B7AB0:
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830B7AC0"))) PPC_WEAK_FUNC(sub_830B7AC0);
PPC_FUNC_IMPL(__imp__sub_830B7AC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,110(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 110);
	// lbz r10,111(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 111);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// bne cr6,0x830b7ae8
	if (!cr6.eq) goto loc_830B7AE8;
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x830b7b0c
	if (!cr6.lt) goto loc_830B7B0C;
	// li r11,1
	r11.s64 = 1;
	// b 0x830b7b00
	goto loc_830B7B00;
loc_830B7AE8:
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x830b7b0c
	if (!cr6.eq) goto loc_830B7B0C;
	// lwz r10,60(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x830b7b0c
	if (!cr6.lt) goto loc_830B7B0C;
	// li r11,3
	r11.s64 = 3;
loc_830B7B00:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_830B7B0C:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830B7B18"))) PPC_WEAK_FUNC(sub_830B7B18);
PPC_FUNC_IMPL(__imp__sub_830B7B18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,110(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 110);
	// lbz r10,111(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 111);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// bne cr6,0x830b7b48
	if (!cr6.eq) goto loc_830B7B48;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bge cr6,0x830b7b78
	if (!cr6.lt) goto loc_830B7B78;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// beq cr6,0x830b7b70
	if (cr6.eq) goto loc_830B7B70;
	// b 0x830b7b6c
	goto loc_830B7B6C;
loc_830B7B48:
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// bne cr6,0x830b7b78
	if (!cr6.eq) goto loc_830B7B78;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830b7b78
	if (!cr6.eq) goto loc_830B7B78;
	// li r11,9
	r11.s64 = 9;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// beq cr6,0x830b7b70
	if (cr6.eq) goto loc_830B7B70;
	// li r11,1
	r11.s64 = 1;
loc_830B7B6C:
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r11.u32);
loc_830B7B70:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_830B7B78:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830B7B88"))) PPC_WEAK_FUNC(sub_830B7B88);
PPC_FUNC_IMPL(__imp__sub_830B7B88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r7
	r24.u64 = ctx.r7.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r20,r4
	r20.u64 = ctx.r4.u64;
	// mr r21,r6
	r21.u64 = ctx.r6.u64;
	// li r22,0
	r22.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830b7bb4
	if (cr6.eq) goto loc_830B7BB4;
	// stw r22,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r22.u32);
loc_830B7BB4:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830b7edc
	if (cr6.eq) goto loc_830B7EDC;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x830b7bf4
	if (!cr6.eq) goto loc_830B7BF4;
	// cmplw cr6,r5,r21
	cr6.compare<uint32_t>(ctx.r5.u32, r21.u32, xer);
	// bge cr6,0x830b7bf4
	if (!cr6.lt) goto loc_830B7BF4;
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r5,r21
	ctx.r10.s64 = r21.s64 - ctx.r5.s64;
	// add r11,r11,r20
	r11.u64 = r11.u64 + r20.u64;
loc_830B7BD8:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830b7be8
	if (cr6.eq) goto loc_830B7BE8;
	// stw r22,36(r9)
	PPC_STORE_U32(ctx.r9.u32 + 36, r22.u32);
loc_830B7BE8:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830b7bd8
	if (!cr0.eq) goto loc_830B7BD8;
loc_830B7BF4:
	// addi r23,r21,-1
	r23.s64 = r21.s64 + -1;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// cmplw cr6,r5,r23
	cr6.compare<uint32_t>(ctx.r5.u32, r23.u32, xer);
	// bge cr6,0x830b7ec0
	if (!cr6.lt) goto loc_830B7EC0;
	// li r25,1
	r25.s64 = 1;
loc_830B7C08:
	// rlwinm r11,r29,2,0,29
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r20
	r11.u64 = r11.u64 + r20.u64;
	// lwz r30,0(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// mr r31,r22
	r31.u64 = r22.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830b7c34
	if (cr6.eq) goto loc_830B7C34;
	// lwz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,0(r24)
	PPC_STORE_U32(r24.u32 + 0, ctx.r10.u32);
loc_830B7C34:
	// cmplw cr6,r29,r23
	cr6.compare<uint32_t>(r29.u32, r23.u32, xer);
	// bge cr6,0x830b7c50
	if (!cr6.lt) goto loc_830B7C50;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b7c34
	if (cr6.eq) goto loc_830B7C34;
loc_830B7C50:
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// mr r27,r22
	r27.u64 = r22.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// mr r28,r22
	r28.u64 = r22.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x830b7c74
	if (!cr6.eq) goto loc_830B7C74;
	// stw r22,36(r30)
	PPC_STORE_U32(r30.u32 + 36, r22.u32);
	// stw r22,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r22.u32);
loc_830B7C74:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x830b7ca8
	if (!cr6.eq) goto loc_830B7CA8;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// bge cr6,0x830b7ca8
	if (!cr6.lt) goto loc_830B7CA8;
	// mr r11,r30
	r11.u64 = r30.u64;
	// mr r30,r31
	r30.u64 = r31.u64;
	// mr r31,r11
	r31.u64 = r11.u64;
	// mr r28,r25
	r28.u64 = r25.u64;
	// b 0x830b7cc0
	goto loc_830B7CC0;
loc_830B7CA8:
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x830b7eb4
	if (!cr6.eq) goto loc_830B7EB4;
loc_830B7CC0:
	// lhz r11,202(r26)
	r11.u64 = PPC_LOAD_U16(r26.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830b7cf0
	if (cr6.eq) goto loc_830B7CF0;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,376(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 376);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830b7eb4
	if (!cr0.eq) goto loc_830B7EB4;
loc_830B7CF0:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r10,29200
	ctx.r10.s64 = 1913651200;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// lis r10,29184
	ctx.r10.s64 = 1912602624;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// lis r10,29408
	ctx.r10.s64 = 1927282688;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// lis r10,24688
	ctx.r10.s64 = 1617952768;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// lis r10,24656
	ctx.r10.s64 = 1615855616;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// lis r10,24736
	ctx.r10.s64 = 1621098496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// lis r10,24576
	ctx.r10.s64 = 1610612736;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// lis r10,24816
	ctx.r10.s64 = 1626341376;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// lis r10,4352
	ctx.r10.s64 = 285212672;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b7eb4
	if (cr6.eq) goto loc_830B7EB4;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b7df4
	if (!cr6.gt) goto loc_830B7DF4;
	// lwz r7,20(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rotlwi r5,r11,0
	ctx.r5.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r6,16(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
loc_830B7D8C:
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830b7da8
	if (!cr6.eq) goto loc_830B7DA8;
	// mr r27,r25
	r27.u64 = r25.u64;
loc_830B7DA8:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830b7de8
	if (cr6.eq) goto loc_830B7DE8;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 4);
loc_830B7DB8:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r19,r11,2,0,29
	r19.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r19,r19,r7
	r19.u64 = PPC_LOAD_U32(r19.u32 + ctx.r7.u32);
	// lwz r19,56(r19)
	r19.u64 = PPC_LOAD_U32(r19.u32 + 56);
	// cmplw cr6,r19,r9
	cr6.compare<uint32_t>(r19.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b7dd8
	if (cr6.eq) goto loc_830B7DD8;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b7ddc
	if (!cr6.eq) goto loc_830B7DDC;
loc_830B7DD8:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_830B7DDC:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830b7db8
	if (!cr0.eq) goto loc_830B7DB8;
loc_830B7DE8:
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// bne 0x830b7d8c
	if (!cr0.eq) goto loc_830B7D8C;
loc_830B7DF4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b7e64
	if (!cr6.gt) goto loc_830B7E64;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rotlwi r5,r11,0
	ctx.r5.u64 = __builtin_rotateleft32(r11.u32, 0);
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
loc_830B7E0C:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830b7e58
	if (cr6.eq) goto loc_830B7E58;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r6,20(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwzx r9,r10,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
loc_830B7E28:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r19,r10,2,0,29
	r19.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r19,r19,r6
	r19.u64 = PPC_LOAD_U32(r19.u32 + ctx.r6.u32);
	// lwz r19,56(r19)
	r19.u64 = PPC_LOAD_U32(r19.u32 + 56);
	// cmplw cr6,r19,r9
	cr6.compare<uint32_t>(r19.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b7e48
	if (cr6.eq) goto loc_830B7E48;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b7e4c
	if (!cr6.eq) goto loc_830B7E4C;
loc_830B7E48:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_830B7E4C:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830b7e28
	if (!cr0.eq) goto loc_830B7E28;
loc_830B7E58:
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x830b7e0c
	if (!cr0.eq) goto loc_830B7E0C;
loc_830B7E64:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830b7eb4
	if (!cr6.eq) goto loc_830B7EB4;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x830b7eb4
	if (!cr6.eq) goto loc_830B7EB4;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830b7eb4
	if (!cr6.eq) goto loc_830B7EB4;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x830b7eb0
	if (!cr6.eq) goto loc_830B7EB0;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x830b7eac
	if (cr6.eq) goto loc_830B7EAC;
	// stw r25,36(r30)
	PPC_STORE_U32(r30.u32 + 36, r25.u32);
	// b 0x830b7eb0
	goto loc_830B7EB0;
loc_830B7EAC:
	// stw r25,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r25.u32);
loc_830B7EB0:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
loc_830B7EB4:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmplw cr6,r29,r23
	cr6.compare<uint32_t>(r29.u32, r23.u32, xer);
	// blt cr6,0x830b7c08
	if (cr6.lt) goto loc_830B7C08;
loc_830B7EC0:
	// cmplw cr6,r29,r21
	cr6.compare<uint32_t>(r29.u32, r21.u32, xer);
	// beq cr6,0x830b7edc
	if (cr6.eq) goto loc_830B7EDC;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830b7edc
	if (cr6.eq) goto loc_830B7EDC;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
loc_830B7EDC:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c14
	return;
}

__attribute__((alias("__imp__sub_830B7EE8"))) PPC_WEAK_FUNC(sub_830B7EE8);
PPC_FUNC_IMPL(__imp__sub_830B7EE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// rlwinm. r9,r6,0,15,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x10000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// beq 0x830b7f14
	if (cr0.eq) goto loc_830B7F14;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r11,1
	r11.s64 = 1;
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
loc_830B7F14:
	// rlwinm. r9,r6,0,14,14
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x20000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830b7f30
	if (cr0.eq) goto loc_830B7F30;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwx r5,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, ctx.r5.u32);
loc_830B7F30:
	// rlwinm. r9,r6,0,13,13
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830b7f4c
	if (cr0.eq) goto loc_830B7F4C;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwx r5,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, ctx.r5.u32);
loc_830B7F4C:
	// rlwinm. r9,r6,0,12,12
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x80000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830b7f68
	if (cr0.eq) goto loc_830B7F68;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwx r5,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, ctx.r5.u32);
loc_830B7F68:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// ble cr6,0x830b7f74
	if (!cr6.gt) goto loc_830B7F74;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_830B7F74:
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// li r11,-1
	r11.s64 = -1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// std r11,0(r9)
	PPC_STORE_U64(ctx.r9.u32 + 0, r11.u64);
	// std r11,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, r11.u64);
	// beq cr6,0x830b7fc8
	if (cr6.eq) goto loc_830B7FC8;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// subf r8,r8,r4
	ctx.r8.s64 = ctx.r4.s64 - ctx.r8.s64;
loc_830B7F9C:
	// lwzx r5,r8,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r31,r31,2,0,29
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwzx r5,r5,r9
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
	// lwz r5,16(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// stwx r5,r31,r4
	PPC_STORE_U32(r31.u32 + ctx.r4.u32, ctx.r5.u32);
	// bne 0x830b7f9c
	if (!cr0.eq) goto loc_830B7F9C;
loc_830B7FC8:
	// lhz r11,202(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// bne cr6,0x830b8060
	if (!cr6.eq) goto loc_830B8060;
	// lis r11,-31952
	r11.s64 = -2094006272;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r6,r11,4056
	ctx.r6.s64 = r11.s64 + 4056;
loc_830B7FE4:
	// li r11,0
	r11.s64 = 0;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
loc_830B7FEC:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830b800c
	if (cr6.eq) goto loc_830B800C;
	// add r4,r8,r11
	ctx.r4.u64 = ctx.r8.u64 + r11.u64;
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r6
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r6.u32);
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// bne cr6,0x830b804c
	if (!cr6.eq) goto loc_830B804C;
loc_830B800C:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x830b7fec
	if (cr6.lt) goto loc_830B7FEC;
	// rlwinm r11,r5,4,0,27
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 4) & 0xFFFFFFF0;
	// add. r11,r11,r6
	r11.u64 = r11.u64 + ctx.r6.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830b811c
	if (!cr0.eq) goto loc_830B811C;
loc_830B8028:
	// lwz r11,260(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 260);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,4533
	ctx.r5.s64 = 4533;
	// addi r6,r10,31692
	ctx.r6.s64 = ctx.r10.s64 + 31692;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b8148
	goto loc_830B8148;
loc_830B804C:
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplwi cr6,r8,20
	cr6.compare<uint32_t>(ctx.r8.u32, 20, xer);
	// blt cr6,0x830b7fe4
	if (cr6.lt) goto loc_830B7FE4;
	// b 0x830b8028
	goto loc_830B8028;
loc_830B8060:
	// lis r10,-31952
	ctx.r10.s64 = -2094006272;
	// li r11,0
	r11.s64 = 0;
	// addi r9,r10,4056
	ctx.r9.s64 = ctx.r10.s64 + 4056;
loc_830B806C:
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830b808c
	if (cr6.eq) goto loc_830B808C;
	// addi r8,r9,48
	ctx.r8.s64 = ctx.r9.s64 + 48;
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b80a0
	if (!cr6.eq) goto loc_830B80A0;
loc_830B808C:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830b806c
	if (cr6.lt) goto loc_830B806C;
	// addi r11,r9,48
	r11.s64 = ctx.r9.s64 + 48;
	// b 0x830b811c
	goto loc_830B811C;
loc_830B80A0:
	// li r11,0
	r11.s64 = 0;
loc_830B80A4:
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830b80c4
	if (cr6.eq) goto loc_830B80C4;
	// addi r8,r9,64
	ctx.r8.s64 = ctx.r9.s64 + 64;
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b80d4
	if (!cr6.eq) goto loc_830B80D4;
loc_830B80C4:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830b80a4
	if (cr6.lt) goto loc_830B80A4;
	// b 0x830b8118
	goto loc_830B8118;
loc_830B80D4:
	// li r11,0
	r11.s64 = 0;
loc_830B80D8:
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830b80f8
	if (cr6.eq) goto loc_830B80F8;
	// addi r8,r9,32
	ctx.r8.s64 = ctx.r9.s64 + 32;
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x830b8118
	if (!cr6.eq) goto loc_830B8118;
loc_830B80F8:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830b80d8
	if (cr6.lt) goto loc_830B80D8;
	// rlwinm r11,r6,0,12,15
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xF0000;
	// lis r10,8
	ctx.r10.s64 = 524288;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// addi r11,r9,32
	r11.s64 = ctx.r9.s64 + 32;
	// beq cr6,0x830b811c
	if (cr6.eq) goto loc_830B811C;
loc_830B8118:
	// addi r11,r9,64
	r11.s64 = ctx.r9.s64 + 64;
loc_830B811C:
	// li r9,0
	ctx.r9.s64 = 0;
	// li r10,16
	ctx.r10.s64 = 16;
loc_830B8124:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// slw r8,r8,r10
	ctx.r8.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r10.u8 & 0x3F));
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// or r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 | ctx.r9.u64;
	// cmplwi cr6,r10,24
	cr6.compare<uint32_t>(ctx.r10.u32, 24, xer);
	// blt cr6,0x830b8124
	if (cr6.lt) goto loc_830B8124;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B8148:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830B8160"))) PPC_WEAK_FUNC(sub_830B8160);
PPC_FUNC_IMPL(__imp__sub_830B8160) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// addi r11,r11,28416
	r11.s64 = r11.s64 + 28416;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// lwz r3,560(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lwz r11,696(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 696);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b81e8
	if (cr6.eq) goto loc_830B81E8;
	// lwz r11,708(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 708);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b81e8
	if (!cr6.gt) goto loc_830B81E8;
	// li r30,0
	r30.s64 = 0;
loc_830B81B4:
	// lwz r11,696(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 696);
	// lwzx r29,r11,r30
	r29.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b81d4
	if (cr6.eq) goto loc_830B81D4;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830B81D4:
	// lwz r11,708(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 708);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x830b81b4
	if (cr6.lt) goto loc_830B81B4;
loc_830B81E8:
	// lwz r11,700(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 700);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b823c
	if (cr6.eq) goto loc_830B823C;
	// lwz r11,704(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 704);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b823c
	if (!cr6.gt) goto loc_830B823C;
	// li r30,0
	r30.s64 = 0;
loc_830B8208:
	// lwz r11,700(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 700);
	// lwzx r29,r30,r11
	r29.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b8228
	if (cr6.eq) goto loc_830B8228;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8307a4d0
	sub_8307A4D0(ctx, base);
loc_830B8228:
	// lwz r11,704(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 704);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x830b8208
	if (cr6.lt) goto loc_830B8208;
loc_830B823C:
	// addi r30,r31,712
	r30.s64 = r31.s64 + 712;
	// li r29,16
	r29.s64 = 16;
loc_830B8244:
	// lwz r28,0(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830b8260
	if (cr6.eq) goto loc_830B8260;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830B8260:
	// li r11,0
	r11.s64 = 0;
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x830b8244
	if (!cr0.eq) goto loc_830B8244;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,696(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 696);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,700(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 700);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306af88
	sub_8306AF88(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830B82A0"))) PPC_WEAK_FUNC(sub_830B82A0);
PPC_FUNC_IMPL(__imp__sub_830B82A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r3,r31,508
	ctx.r3.s64 = r31.s64 + 508;
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// stw r30,540(r31)
	PPC_STORE_U32(r31.u32 + 540, r30.u32);
	// stw r30,544(r31)
	PPC_STORE_U32(r31.u32 + 544, r30.u32);
	// stw r30,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r30.u32);
	// stw r30,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r30.u32);
	// lwz r3,560(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// stw r30,560(r31)
	PPC_STORE_U32(r31.u32 + 560, r30.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83071ec8
	sub_83071EC8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830B8310"))) PPC_WEAK_FUNC(sub_830B8310);
PPC_FUNC_IMPL(__imp__sub_830B8310) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r28,4352
	r28.s64 = 285212672;
	// li r30,0
	r30.s64 = 0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b837c
	if (!cr6.gt) goto loc_830B837C;
	// li r29,0
	r29.s64 = 0;
loc_830B8338:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x830b8368
	if (!cr6.eq) goto loc_830B8368;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ad2a8
	sub_830AD2A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b8430
	if (cr0.lt) goto loc_830B8430;
loc_830B8368:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830b8338
	if (cr6.lt) goto loc_830B8338;
loc_830B837C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b83dc
	if (!cr6.gt) goto loc_830B83DC;
	// li r29,0
	r29.s64 = 0;
loc_830B8398:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x830b83c8
	if (!cr6.eq) goto loc_830B83C8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ad5a8
	sub_830AD5A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b8430
	if (cr0.lt) goto loc_830B8430;
loc_830B83C8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830b8398
	if (cr6.lt) goto loc_830B8398;
loc_830B83DC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084778
	sub_83084778(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b8430
	if (cr0.lt) goto loc_830B8430;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084e68
	sub_83084E68(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b8430
	if (cr0.lt) goto loc_830B8430;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307f3a8
	sub_8307F3A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b8430
	if (cr0.lt) goto loc_830B8430;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830878b8
	sub_830878B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b8430
	if (cr0.lt) goto loc_830B8430;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B8430:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830B8438"))) PPC_WEAK_FUNC(sub_830B8438);
PPC_FUNC_IMPL(__imp__sub_830B8438) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-496(r1)
	ea = -496 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r14,0
	r14.s64 = 0;
	// mr r17,r14
	r17.u64 = r14.u64;
	// stw r14,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r14.u32);
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b84a4
	if (!cr6.gt) goto loc_830B84A4;
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
loc_830B846C:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r14,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r14.u32);
	// lwz r7,136(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x830b8490
	if (!cr6.eq) goto loc_830B8490;
	// li r8,-1
	ctx.r8.s64 = -1;
	// stw r8,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r8.u32);
loc_830B8490:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x830b846c
	if (cr6.lt) goto loc_830B846C;
loc_830B84A4:
	// lwz r8,76(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// bge cr6,0x830b8528
	if (!cr6.lt) goto loc_830B8528;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
loc_830B84B8:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b8514
	if (cr6.eq) goto loc_830B8514;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b8514
	if (cr6.eq) goto loc_830B8514;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830b8514
	if (!cr6.gt) goto loc_830B8514;
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
loc_830B84E8:
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r6,r10,r6
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r5
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// stw r8,72(r6)
	PPC_STORE_U32(ctx.r6.u32 + 72, ctx.r8.u32);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// blt cr6,0x830b84e8
	if (cr6.lt) goto loc_830B84E8;
loc_830B8514:
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x830b84b8
	if (cr6.lt) goto loc_830B84B8;
loc_830B8528:
	// lwz r21,552(r31)
	r21.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// lwz r22,76(r31)
	r22.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmplw cr6,r22,r21
	cr6.compare<uint32_t>(r22.u32, r21.u32, xer);
	// stw r21,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r21.u32);
	// stw r22,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r22.u32);
	// bge cr6,0x830b8ec0
	if (!cr6.lt) goto loc_830B8EC0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_830B8548:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r10,r22,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r19,r10,r11
	r19.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x830b8eb0
	if (cr6.eq) goto loc_830B8EB0;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b8eb0
	if (cr6.eq) goto loc_830B8EB0;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b8580
	if (cr0.eq) goto loc_830B8580;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// b 0x830b8584
	goto loc_830B8584;
loc_830B8580:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
loc_830B8584:
	// stw r3,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830b8768
	if (cr6.eq) goto loc_830B8768;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// rotlwi r3,r3,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// bl 0x8307a0a0
	sub_8307A0A0(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// blt 0x830b8f08
	if (cr0.lt) goto loc_830B8F08;
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830b8768
	if (!cr6.lt) goto loc_830B8768;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// mr r16,r14
	r16.u64 = r14.u64;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// mr r15,r14
	r15.u64 = r14.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b8774
	if (!cr6.eq) goto loc_830B8774;
	// lwz r10,12(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 12);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x830b8774
	if (!cr6.eq) goto loc_830B8774;
	// lwz r7,16(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,0(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r9,r10
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x830b8774
	if (!cr6.eq) goto loc_830B8774;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r1,104
	ctx.r10.s64 = ctx.r1.s64 + 104;
	// lwz r6,108(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r5,100(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b3980
	sub_830B3980(ctx, base);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830b87e0
	if (cr6.eq) goto loc_830B87E0;
	// li r6,3
	ctx.r6.s64 = 3;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x830b8768
	if (cr6.eq) goto loc_830B8768;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8307a2f8
	sub_8307A2F8(ctx, base);
	// lwz r10,136(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// li r11,3
	r11.s64 = 3;
	// stw r14,60(r30)
	PPC_STORE_U32(r30.u32 + 60, r14.u32);
	// li r3,116
	ctx.r3.s64 = 116;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b8698
	if (cr0.eq) goto loc_830B8698;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830b869c
	goto loc_830B869C;
loc_830B8698:
	// mr r30,r14
	r30.u64 = r14.u64;
loc_830B869C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830b8768
	if (cr6.eq) goto loc_830B8768;
	// lis r4,4096
	ctx.r4.s64 = 268435456;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// blt 0x830b8f80
	if (cr0.lt) goto loc_830B8F80;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// blt 0x830b8f80
	if (cr0.lt) goto loc_830B8F80;
	// lwz r11,16(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r18,r4
	r18.u64 = ctx.r4.u64;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r10,552(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r4,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r4.u32);
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r11.u32);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b8768
	if (cr0.lt) goto loc_830B8768;
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830b8768
	if (!cr6.lt) goto loc_830B8768;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stwx r30,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r30.u32);
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r11.u32);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830b882c
	if (!cr0.lt) goto loc_830B882C;
loc_830B8768:
	// lis r21,-32761
	r21.s64 = -2147024896;
	// ori r21,r21,14
	r21.u64 = r21.u64 | 14;
	// b 0x830b8ef0
	goto loc_830B8EF0;
loc_830B8774:
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b87dc
	if (!cr6.eq) goto loc_830B87DC;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ae250
	sub_830AE250(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b87dc
	if (cr0.eq) goto loc_830B87DC;
	// lwz r11,12(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 12);
	// li r16,1
	r16.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b8814
	if (cr6.eq) goto loc_830B8814;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,16(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 16);
loc_830B87AC:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r8,60(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 60);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830b87c8
	if (cr6.eq) goto loc_830B87C8;
	// mr r16,r14
	r16.u64 = r14.u64;
loc_830B87C8:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830b87ac
	if (!cr0.eq) goto loc_830B87AC;
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// bne cr6,0x830b8814
	if (!cr6.eq) goto loc_830B8814;
loc_830B87DC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_830B87E0:
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b8768
	if (cr0.lt) goto loc_830B8768;
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// lwz r18,96(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r18,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r18.u32);
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r11.u32);
	// b 0x830b882c
	goto loc_830B882C;
loc_830B8814:
	// lwz r30,96(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// mr r18,r14
	r18.u64 = r14.u64;
loc_830B882C:
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// stw r14,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r14.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ae250
	sub_830AE250(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b8e58
	if (cr0.eq) goto loc_830B8E58;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwz r8,12(r19)
	ctx.r8.u64 = PPC_LOAD_U32(r19.u32 + 12);
	// li r29,-1
	r29.s64 = -1;
	// mr r30,r14
	r30.u64 = r14.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// std r29,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r29.u64);
	// std r29,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r29.u64);
	// beq cr6,0x830b88bc
	if (cr6.eq) goto loc_830B88BC;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r11,r14
	r11.u64 = r14.u64;
	// lwz r6,16(r19)
	ctx.r6.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// mr r5,r8
	ctx.r5.u64 = ctx.r8.u64;
loc_830B8874:
	// lwzx r10,r11,r6
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r4,48(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830b88b0
	if (cr6.eq) goto loc_830B88B0;
	// lwz r4,8(r19)
	ctx.r4.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// addi r28,r1,192
	r28.s64 = ctx.r1.s64 + 192;
	// li r30,1
	r30.s64 = 1;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + r11.u32);
	// stwx r10,r9,r3
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, ctx.r10.u32);
	// stwx r4,r9,r28
	PPC_STORE_U32(ctx.r9.u32 + r28.u32, ctx.r4.u32);
loc_830B88B0:
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830b8874
	if (!cr0.eq) goto loc_830B8874;
loc_830B88BC:
	// stw r14,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r14.u32);
	// addi r10,r1,104
	ctx.r10.s64 = ctx.r1.s64 + 104;
	// lwz r21,108(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// addi r9,r1,208
	ctx.r9.s64 = ctx.r1.s64 + 208;
	// lwz r22,100(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// lwz r7,16(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x830b3760
	sub_830B3760(ctx, base);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x830b8f34
	if (cr6.eq) goto loc_830B8F34;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// lwz r23,104(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// mr r24,r14
	r24.u64 = r14.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// std r29,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r29.u64);
	// std r29,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r29.u64);
	// beq cr6,0x830b8a34
	if (cr6.eq) goto loc_830B8A34;
	// lwz r25,20(r31)
	r25.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r26,r1,208
	r26.s64 = ctx.r1.s64 + 208;
loc_830B8914:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r27,r11
	r27.u64 = r11.u64;
	// lwzx r29,r10,r25
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r11,56(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 56);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830b8940
	if (cr6.eq) goto loc_830B8940;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r27,r11
	r27.u64 = r11.u64;
	// lwzx r29,r10,r25
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
loc_830B8940:
	// lwz r11,72(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 72);
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bge cr6,0x830b8954
	if (!cr6.lt) goto loc_830B8954;
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// bge cr6,0x830b8a24
	if (!cr6.lt) goto loc_830B8A24;
loc_830B8954:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830b8a24
	if (cr6.eq) goto loc_830B8A24;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r30,r28,r10
	r30.u64 = PPC_LOAD_U32(r28.u32 + ctx.r10.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x830ae250
	sub_830AE250(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b8a24
	if (cr0.eq) goto loc_830B8A24;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b89fc
	if (!cr6.eq) goto loc_830B89FC;
	// lwz r11,56(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 56);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830b89fc
	if (!cr6.eq) goto loc_830B89FC;
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r11,r14
	r11.u64 = r14.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830b89fc
	if (!cr6.gt) goto loc_830B89FC;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
loc_830B89B0:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r27,r9
	cr6.compare<uint32_t>(r27.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b89dc
	if (cr6.eq) goto loc_830B89DC;
	// lwz r9,564(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwzx r9,r28,r9
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + ctx.r9.u32);
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b89b0
	if (cr6.lt) goto loc_830B89B0;
	// b 0x830b89fc
	goto loc_830B89FC;
loc_830B89DC:
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// addi r8,r1,176
	ctx.r8.s64 = ctx.r1.s64 + 176;
	// li r15,1
	r15.s64 = 1;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stwx r11,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, r11.u32);
loc_830B89FC:
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x830b8a1c
	if (!cr6.eq) goto loc_830B8A1C;
	// stwx r27,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r27.u32);
	// b 0x830b8a24
	goto loc_830B8A24;
loc_830B8A1C:
	// cmplw cr6,r9,r27
	cr6.compare<uint32_t>(ctx.r9.u32, r27.u32, xer);
	// bne cr6,0x830b8f90
	if (!cr6.eq) goto loc_830B8F90;
loc_830B8A24:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r24,r23
	cr6.compare<uint32_t>(r24.u32, r23.u32, xer);
	// blt cr6,0x830b8914
	if (cr6.lt) goto loc_830B8914;
loc_830B8A34:
	// mr r20,r14
	r20.u64 = r14.u64;
	// mr r11,r14
	r11.u64 = r14.u64;
loc_830B8A3C:
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830b8a64
	if (cr6.eq) goto loc_830B8A64;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x830b8f90
	if (!cr6.eq) goto loc_830B8F90;
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x830b8a74
	if (!cr6.eq) goto loc_830B8A74;
loc_830B8A64:
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830b8a78
	if (cr6.eq) goto loc_830B8A78;
loc_830B8A74:
	// addi r20,r20,1
	r20.s64 = r20.s64 + 1;
loc_830B8A78:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x830b8a3c
	if (cr6.lt) goto loc_830B8A3C;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b8aa0
	if (cr0.eq) goto loc_830B8AA0;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r17,r3
	r17.u64 = ctx.r3.u64;
	// b 0x830b8aa4
	goto loc_830B8AA4;
loc_830B8AA0:
	// mr r17,r14
	r17.u64 = r14.u64;
loc_830B8AA4:
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x830b8fb8
	if (cr6.eq) goto loc_830B8FB8;
	// li r11,1793
	r11.s64 = 1793;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,20,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// mulli r5,r20,3
	ctx.r5.s64 = r20.s64 * 3;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// blt 0x830b8ef0
	if (cr0.lt) goto loc_830B8EF0;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// blt 0x830b8ef0
	if (cr0.lt) goto loc_830B8EF0;
	// rlwinm r28,r20,2,0,29
	r28.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r26,r14
	r26.u64 = r14.u64;
	// mr r22,r14
	r22.u64 = r14.u64;
	// mr r24,r14
	r24.u64 = r14.u64;
	// mr r27,r14
	r27.u64 = r14.u64;
	// mr r25,r28
	r25.u64 = r28.u64;
	// mr r23,r14
	r23.u64 = r14.u64;
loc_830B8B04:
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwzx r29,r23,r11
	r29.u64 = PPC_LOAD_U32(r23.u32 + r11.u32);
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x830b8be0
	if (cr6.eq) goto loc_830B8BE0;
	// lwz r11,16(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 16);
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r29,r11,r27
	PPC_STORE_U32(r11.u32 + r27.u32, r29.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// bne cr6,0x830b8bb0
	if (!cr6.eq) goto loc_830B8BB0;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwz r6,16(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830b8768
	if (cr6.eq) goto loc_830B8768;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,60(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r8,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r8.u32);
	// stw r14,60(r30)
	PPC_STORE_U32(r30.u32 + 60, r14.u32);
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// stw r11,72(r30)
	PPC_STORE_U32(r30.u32 + 72, r11.u32);
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b8bc4
	if (!cr6.gt) goto loc_830B8BC4;
	// mr r11,r14
	r11.u64 = r14.u64;
loc_830B8B84:
	// lwz r10,16(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplw cr6,r8,r29
	cr6.compare<uint32_t>(ctx.r8.u32, r29.u32, xer);
	// bne cr6,0x830b8b98
	if (!cr6.eq) goto loc_830B8B98;
	// stwx r3,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r3.u32);
loc_830B8B98:
	// lwz r10,12(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// blt cr6,0x830b8b84
	if (cr6.lt) goto loc_830B8B84;
	// b 0x830b8bc4
	goto loc_830B8BC4;
loc_830B8BB0:
	// lwz r9,552(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r3,r23,r8
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + ctx.r8.u32);
	// stw r9,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r9.u32);
loc_830B8BC4:
	// lwz r11,8(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// stwx r3,r11,r25
	PPC_STORE_U32(r11.u32 + r25.u32, ctx.r3.u32);
	// lwz r11,8(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// lwz r10,1096(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1096);
	// stwx r10,r11,r27
	PPC_STORE_U32(r11.u32 + r27.u32, ctx.r10.u32);
	// b 0x830b8ce8
	goto loc_830B8CE8;
loc_830B8BE0:
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// lwzx r29,r23,r11
	r29.u64 = PPC_LOAD_U32(r23.u32 + r11.u32);
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x830b8cf4
	if (cr6.eq) goto loc_830B8CF4;
	// lwz r11,16(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 16);
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r29,r11,r27
	PPC_STORE_U32(r11.u32 + r27.u32, r29.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// bne cr6,0x830b8cb0
	if (!cr6.eq) goto loc_830B8CB0;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwz r6,16(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830b8768
	if (cr6.eq) goto loc_830B8768;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,60(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r9,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r9.u32);
	// lwz r11,72(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// stw r14,60(r30)
	PPC_STORE_U32(r30.u32 + 60, r14.u32);
	// beq cr6,0x830b8fc4
	if (cr6.eq) goto loc_830B8FC4;
	// lwz r10,552(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b8fc4
	if (cr6.eq) goto loc_830B8FC4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r8,r14
	ctx.r8.u64 = r14.u64;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b8ca4
	if (!cr6.gt) goto loc_830B8CA4;
	// mr r11,r14
	r11.u64 = r14.u64;
loc_830B8C7C:
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmplw cr6,r7,r29
	cr6.compare<uint32_t>(ctx.r7.u32, r29.u32, xer);
	// bne cr6,0x830b8c90
	if (!cr6.eq) goto loc_830B8C90;
	// stwx r3,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r3.u32);
loc_830B8C90:
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b8c7c
	if (cr6.lt) goto loc_830B8C7C;
loc_830B8CA4:
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// stw r11,72(r30)
	PPC_STORE_U32(r30.u32 + 72, r11.u32);
	// b 0x830b8cc4
	goto loc_830B8CC4;
loc_830B8CB0:
	// lwz r9,552(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r8,r1,176
	ctx.r8.s64 = ctx.r1.s64 + 176;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r3,r23,r8
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + ctx.r8.u32);
	// stw r9,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r9.u32);
loc_830B8CC4:
	// lwz r10,1092(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1092);
	// rlwinm r11,r20,1,0,30
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r9,8(r17)
	ctx.r9.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// add r11,r11,r26
	r11.u64 = r11.u64 + r26.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r10,r9,r27
	PPC_STORE_U32(ctx.r9.u32 + r27.u32, ctx.r10.u32);
	// lwz r10,8(r17)
	ctx.r10.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// stwx r3,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r3.u32);
loc_830B8CE8:
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
loc_830B8CF4:
	// addi r23,r23,4
	r23.s64 = r23.s64 + 4;
	// cmplwi cr6,r23,16
	cr6.compare<uint32_t>(r23.u32, 16, xer);
	// blt cr6,0x830b8b04
	if (cr6.lt) goto loc_830B8B04;
	// mr r29,r14
	r29.u64 = r14.u64;
	// mr r27,r14
	r27.u64 = r14.u64;
loc_830B8D08:
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830b8d90
	if (cr6.eq) goto loc_830B8D90;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r6,16(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830b8768
	if (cr6.eq) goto loc_830B8768;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpwi cr6,r24,-1
	cr6.compare<int32_t>(r24.s32, -1, xer);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r24,56(r11)
	PPC_STORE_U32(r11.u32 + 56, r24.u32);
	// lwz r10,60(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// stw r10,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r10.u32);
	// beq cr6,0x830b8d78
	if (cr6.eq) goto loc_830B8D78;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r9,r24,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_830B8D78:
	// rlwinm r11,r20,1,0,30
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r10,8(r17)
	ctx.r10.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r3,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r3.u32);
	// b 0x830b8e08
	goto loc_830B8E08;
loc_830B8D90:
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830b8e10
	if (cr6.eq) goto loc_830B8E10;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r6,16(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830b8768
	if (cr6.eq) goto loc_830B8768;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpwi cr6,r22,-1
	cr6.compare<int32_t>(r22.s32, -1, xer);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r22,56(r11)
	PPC_STORE_U32(r11.u32 + 56, r22.u32);
	// lwz r10,60(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// stw r10,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r10.u32);
	// beq cr6,0x830b8e00
	if (cr6.eq) goto loc_830B8E00;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r9,r22,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_830B8E00:
	// lwz r11,8(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// stwx r3,r11,r28
	PPC_STORE_U32(r11.u32 + r28.u32, ctx.r3.u32);
loc_830B8E08:
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
loc_830B8E10:
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplwi cr6,r27,16
	cr6.compare<uint32_t>(r27.u32, 16, xer);
	// blt cr6,0x830b8d08
	if (cr6.lt) goto loc_830B8D08;
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830b8768
	if (!cr6.lt) goto loc_830B8768;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stwx r17,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r17.u32);
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r11.u32);
	// bl 0x8307a808
	sub_8307A808(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830b8768
	if (cr0.lt) goto loc_830B8768;
	// mr r17,r14
	r17.u64 = r14.u64;
loc_830B8E58:
	// lwz r21,108(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lwz r22,100(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
loc_830B8E60:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x830b8eb0
	if (cr6.eq) goto loc_830B8EB0;
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b8eb0
	if (!cr6.gt) goto loc_830B8EB0;
	// mr r11,r14
	r11.u64 = r14.u64;
loc_830B8E7C:
	// lwz r8,16(r18)
	ctx.r8.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,552(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// stw r9,72(r8)
	PPC_STORE_U32(ctx.r8.u32 + 72, ctx.r9.u32);
	// lwz r9,12(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b8e7c
	if (cr6.lt) goto loc_830B8E7C;
loc_830B8EB0:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// stw r22,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r22.u32);
	// cmplw cr6,r22,r21
	cr6.compare<uint32_t>(r22.u32, r21.u32, xer);
	// blt cr6,0x830b8548
	if (cr6.lt) goto loc_830B8548;
loc_830B8EC0:
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bge cr6,0x830b8eec
	if (!cr6.lt) goto loc_830B8EEC;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r11,r21
	r11.s64 = r21.s64 - r11.s64;
loc_830B8ED4:
	// lwz r9,564(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r14,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r14.u32);
	// bne 0x830b8ed4
	if (!cr0.eq) goto loc_830B8ED4;
loc_830B8EEC:
	// mr r21,r14
	r21.u64 = r14.u64;
loc_830B8EF0:
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x830b8f08
	if (cr6.eq) goto loc_830B8F08;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
loc_830B8F04:
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830B8F08:
	// lwz r31,96(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b8f24
	if (cr6.eq) goto loc_830B8F24;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830B8F24:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// addi r1,r1,496
	ctx.r1.s64 = ctx.r1.s64 + 496;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82ca2c00
	return;
loc_830B8F34:
	// lwz r7,104(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830b8e60
	if (cr6.eq) goto loc_830B8E60;
	// addi r10,r1,208
	ctx.r10.s64 = ctx.r1.s64 + 208;
loc_830B8F44:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r8,56(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x830b8f68
	if (cr6.eq) goto loc_830B8F68;
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
loc_830B8F68:
	// li r9,1
	ctx.r9.s64 = 1;
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r9.u32);
	// bne 0x830b8f44
	if (!cr0.eq) goto loc_830B8F44;
	// b 0x830b8e60
	goto loc_830B8E60;
loc_830B8F80:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x830b8f04
	goto loc_830B8F04;
loc_830B8F90:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lbz r7,203(r31)
	ctx.r7.u64 = PPC_LOAD_U8(r31.u32 + 203);
	// li r5,4537
	ctx.r5.s64 = 4537;
	// lwz r4,60(r19)
	ctx.r4.u64 = PPC_LOAD_U32(r19.u32 + 60);
	// addi r6,r11,31764
	ctx.r6.s64 = r11.s64 + 31764;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r21,-32768
	r21.s64 = -2147483648;
	// ori r21,r21,16389
	r21.u64 = r21.u64 | 16389;
	// b 0x830b8f24
	goto loc_830B8F24;
loc_830B8FB8:
	// lis r21,-32761
	r21.s64 = -2147024896;
	// ori r21,r21,14
	r21.u64 = r21.u64 | 14;
	// b 0x830b8f24
	goto loc_830B8F24;
loc_830B8FC4:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,60(r19)
	ctx.r4.u64 = PPC_LOAD_U32(r19.u32 + 60);
	// li r5,4810
	ctx.r5.s64 = 4810;
	// addi r6,r11,31724
	ctx.r6.s64 = r11.s64 + 31724;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// b 0x830b8ef0
	goto loc_830B8EF0;
}

__attribute__((alias("__imp__sub_830B8FE0"))) PPC_WEAK_FUNC(sub_830B8FE0);
PPC_FUNC_IMPL(__imp__sub_830B8FE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb8
	// stfd f30,-152(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -152, f30.u64);
	// stfd f31,-144(r1)
	PPC_STORE_U64(ctx.r1.u32 + -144, f31.u64);
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// li r18,0
	r18.s64 = 0;
	// lis r3,8272
	ctx.r3.s64 = 542113792;
	// mr r19,r18
	r19.u64 = r18.u64;
	// lwz r8,260(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// lfs f13,3140(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 3140);
	ctx.f13.f64 = double(temp.f32);
	// lwz r4,20(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// mr r29,r18
	r29.u64 = r18.u64;
	// lwz r9,136(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 136);
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwz r8,0(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// clrlwi r21,r8,12
	r21.u64 = ctx.r8.u32 & 0xFFFFF;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r21,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 + r11.u64;
	// lwzx r6,r7,r4
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	// lwz r7,0(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r31,4(r6)
	r31.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm r30,r31,2,0,29
	r30.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r4
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	// cmplw cr6,r31,r9
	cr6.compare<uint32_t>(r31.u32, ctx.r9.u32, xer);
	// lwzx r7,r30,r10
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// bne cr6,0x830b90ec
	if (!cr6.eq) goto loc_830B90EC;
	// lwz r31,4(r4)
	r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// rlwinm r31,r31,2,0,29
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r31,r10
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830b90ec
	if (cr0.eq) goto loc_830B90EC;
	// lwz r10,260(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r3
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r3.u32, xer);
	// bne cr6,0x830b90ec
	if (!cr6.eq) goto loc_830B90EC;
	// mr r22,r11
	r22.u64 = r11.u64;
	// mr r5,r8
	ctx.r5.u64 = ctx.r8.u64;
loc_830B9098:
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// frsp f31,f0
	f31.f64 = double(float(f0.f64));
loc_830B90B0:
	// mr r30,r18
	r30.u64 = r18.u64;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830b9274
	if (cr6.eq) goto loc_830B9274;
	// lwz r6,20(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r31,256(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 256);
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// subf r3,r5,r22
	ctx.r3.s64 = r22.s64 - ctx.r5.s64;
loc_830B90D0:
	// lwzx r11,r3,r7
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r7.u32);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r11,r6
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// beq cr6,0x830b91d4
	if (cr6.eq) goto loc_830B91D4;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// b 0x830b91e0
	goto loc_830B91E0;
loc_830B90EC:
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b9124
	if (!cr6.eq) goto loc_830B9124;
	// lwz r7,4(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm. r7,r7,0,23,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x830b9124
	if (cr0.eq) goto loc_830B9124;
	// lwz r7,260(r28)
	ctx.r7.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// lwz r7,0(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r7,r7,0,0,11
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r7,r3
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r3.u32, xer);
	// bne cr6,0x830b9124
	if (!cr6.eq) goto loc_830B9124;
	// mr r22,r8
	r22.u64 = ctx.r8.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// b 0x830b9098
	goto loc_830B9098;
loc_830B9124:
	// lwz r7,4(r6)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b96d4
	if (!cr6.eq) goto loc_830B96D4;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b96d4
	if (!cr6.eq) goto loc_830B96D4;
	// lwz r10,260(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// lis r9,8256
	ctx.r9.s64 = 541065216;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b96d4
	if (!cr6.eq) goto loc_830B96D4;
	// li r29,1
	r29.s64 = 1;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x830b9188
	if (cr6.eq) goto loc_830B9188;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// subf r8,r11,r8
	ctx.r8.s64 = ctx.r8.s64 - r11.s64;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
loc_830B9168:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwzx r3,r8,r10
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// cmplw cr6,r7,r3
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r3.u32, xer);
	// beq cr6,0x830b917c
	if (cr6.eq) goto loc_830B917C;
	// mr r29,r18
	r29.u64 = r18.u64;
loc_830B917C:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830b9168
	if (!cr0.eq) goto loc_830B9168;
loc_830B9188:
	// lwz r10,60(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 60);
	// lwz r9,60(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 60);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b96d4
	if (!cr6.eq) goto loc_830B96D4;
	// lis r9,8
	ctx.r9.s64 = 524288;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b91b0
	if (!cr6.eq) goto loc_830B91B0;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,3800(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3800);
	f0.f64 = double(temp.f32);
	// b 0x830b91c0
	goto loc_830B91C0;
loc_830B91B0:
	// rlwinm. r10,r10,0,12,12
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830b96d4
	if (!cr0.eq) goto loc_830B96D4;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,3080(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3080);
	f0.f64 = double(temp.f32);
loc_830B91C0:
	// mr r22,r11
	r22.u64 = r11.u64;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x830b96d4
	if (cr6.eq) goto loc_830B96D4;
	// fmuls f31,f0,f13
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(f0.f64 * ctx.f13.f64));
	// b 0x830b90b0
	goto loc_830B90B0;
loc_830B91D4:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r11,r6
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
loc_830B91E0:
	// lwz r11,88(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 88);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x830b96d4
	if (!cr6.eq) goto loc_830B96D4;
	// lwz r11,84(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 84);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x830b96d4
	if (!cr6.eq) goto loc_830B96D4;
	// lwz r11,60(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 60);
	// rlwinm. r11,r11,0,11,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1FFE00;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830b96d4
	if (!cr0.eq) goto loc_830B96D4;
	// mr r10,r18
	ctx.r10.u64 = r18.u64;
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x830b9234
	if (cr6.eq) goto loc_830B9234;
	// lwz r9,72(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 72);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_830B9218:
	// lwz r27,0(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r9,r27
	cr6.compare<uint32_t>(ctx.r9.u32, r27.u32, xer);
	// beq cr6,0x830b9234
	if (cr6.eq) goto loc_830B9234;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r19
	cr6.compare<uint32_t>(ctx.r10.u32, r19.u32, xer);
	// blt cr6,0x830b9218
	if (cr6.lt) goto loc_830B9218;
loc_830B9234:
	// cmplw cr6,r10,r19
	cr6.compare<uint32_t>(ctx.r10.u32, r19.u32, xer);
	// bne cr6,0x830b924c
	if (!cr6.eq) goto loc_830B924C;
	// lwz r11,72(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 72);
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
loc_830B924C:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x830b9264
	if (!cr6.eq) goto loc_830B9264;
	// lfd f0,32(r5)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fcmpu cr6,f31,f0
	cr6.compare(f31.f64, f0.f64);
	// bne cr6,0x830b96d4
	if (!cr6.eq) goto loc_830B96D4;
loc_830B9264:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r30,r21
	cr6.compare<uint32_t>(r30.u32, r21.u32, xer);
	// blt cr6,0x830b90d0
	if (cr6.lt) goto loc_830B90D0;
loc_830B9274:
	// fabs f0,f31
	ctx.fpscr.disableFlushMode();
	f0.u64 = f31.u64 & ~0x8000000000000000;
	// fabs f0,f0
	f0.u64 = f0.u64 & ~0x8000000000000000;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x830b9298
	if (!cr6.eq) goto loc_830B9298;
	// lwz r11,108(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// rlwinm. r11,r11,0,11,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b9298
	if (cr0.eq) goto loc_830B9298;
	// li r20,1024
	r20.s64 = 1024;
	// b 0x830b9360
	goto loc_830B9360;
loc_830B9298:
	// fabs f13,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = f31.u64 & ~0x8000000000000000;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2636(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2636);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x830b92c0
	if (!cr6.eq) goto loc_830B92C0;
	// lwz r11,108(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// rlwinm. r11,r11,0,12,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b92c0
	if (cr0.eq) goto loc_830B92C0;
	// li r20,2048
	r20.s64 = 2048;
	// b 0x830b9360
	goto loc_830B9360;
loc_830B92C0:
	// fabs f13,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = f31.u64 & ~0x8000000000000000;
	// lis r11,-32252
	r11.s64 = -2113667072;
	// lfs f0,-16944(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -16944);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x830b92e8
	if (!cr6.eq) goto loc_830B92E8;
	// lwz r11,108(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b92e8
	if (cr0.eq) goto loc_830B92E8;
	// li r20,4096
	r20.s64 = 4096;
	// b 0x830b9360
	goto loc_830B9360;
loc_830B92E8:
	// fabs f13,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = f31.u64 & ~0x8000000000000000;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,3056(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3056);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x830b9310
	if (!cr6.eq) goto loc_830B9310;
	// lwz r11,108(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// rlwinm. r11,r11,0,14,14
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b9310
	if (cr0.eq) goto loc_830B9310;
	// li r20,8192
	r20.s64 = 8192;
	// b 0x830b9360
	goto loc_830B9360;
loc_830B9310:
	// fabs f13,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = f31.u64 & ~0x8000000000000000;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2680(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2680);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x830b9338
	if (!cr6.eq) goto loc_830B9338;
	// lwz r11,108(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// rlwinm. r11,r11,0,15,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b9338
	if (cr0.eq) goto loc_830B9338;
	// li r20,16384
	r20.s64 = 16384;
	// b 0x830b9360
	goto loc_830B9360;
loc_830B9338:
	// fabs f13,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = f31.u64 & ~0x8000000000000000;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,3128(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3128);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x830b96d4
	if (!cr6.eq) goto loc_830B96D4;
	// lwz r11,108(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// rlwinm. r11,r11,0,16,16
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b96d4
	if (cr0.eq) goto loc_830B96D4;
	// lis r20,0
	r20.s64 = 0;
	// ori r20,r20,32768
	r20.u64 = r20.u64 | 32768;
loc_830B9360:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,3084(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f30.f64 = double(temp.f32);
	// fcmpu cr6,f31,f30
	cr6.compare(f31.f64, f30.f64);
	// bge cr6,0x830b9374
	if (!cr6.lt) goto loc_830B9374;
	// oris r20,r20,8
	r20.u64 = r20.u64 | 524288;
loc_830B9374:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// mr r24,r18
	r24.u64 = r18.u64;
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// std r18,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r18.u64);
	// std r18,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r18.u64);
	// beq cr6,0x830b94ac
	if (cr6.eq) goto loc_830B94AC;
	// lwz r23,24(r28)
	r23.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// mr r26,r18
	r26.u64 = r18.u64;
	// li r27,-1
	r27.s64 = -1;
loc_830B93A0:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lis r10,24576
	ctx.r10.s64 = 1610612736;
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r23
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r9,r11,0,0,3
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b96d4
	if (cr6.eq) goto loc_830B96D4;
	// rlwinm r11,r11,0,0,7
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFF000000;
	// lis r10,29184
	ctx.r10.s64 = 1912602624;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830b96d4
	if (cr6.eq) goto loc_830B96D4;
	// stw r27,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r27.u32);
	// mr r25,r18
	r25.u64 = r18.u64;
	// stw r27,4(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4, r27.u32);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// stw r27,8(r7)
	PPC_STORE_U32(ctx.r7.u32 + 8, r27.u32);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// stw r27,12(r7)
	PPC_STORE_U32(ctx.r7.u32 + 12, r27.u32);
	// lwz r29,12(r4)
	r29.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// beq cr6,0x830b948c
	if (cr6.eq) goto loc_830B948C;
	// mr r8,r18
	ctx.r8.u64 = r18.u64;
loc_830B93FC:
	// mr r30,r18
	r30.u64 = r18.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830b947c
	if (cr6.eq) goto loc_830B947C;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lwzx r31,r8,r22
	r31.u64 = PPC_LOAD_U32(ctx.r8.u32 + r22.u32);
	// lwz r6,16(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// add r10,r26,r11
	ctx.r10.u64 = r26.u64 + r11.u64;
loc_830B9418:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x830b9468
	if (!cr6.eq) goto loc_830B9468;
	// lwz r9,260(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lwz r17,20(r28)
	r17.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// stw r5,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r5.u32);
	// lwz r16,16(r9)
	r16.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwzx r9,r3,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwzx r16,r16,r8
	r16.u64 = PPC_LOAD_U32(r16.u32 + ctx.r8.u32);
	// stwx r9,r3,r11
	PPC_STORE_U32(ctx.r3.u32 + r11.u32, ctx.r9.u32);
	// rlwinm r11,r16,2,0,29
	r11.u64 = __builtin_rotateleft64(r16.u32 | (r16.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r17
	r11.u64 = PPC_LOAD_U32(r11.u32 + r17.u32);
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830b9464
	if (cr0.eq) goto loc_830B9464;
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// blt cr6,0x830b96d4
	if (cr6.lt) goto loc_830B96D4;
loc_830B9464:
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
loc_830B9468:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// blt cr6,0x830b9418
	if (cr6.lt) goto loc_830B9418;
loc_830B947C:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r5,r21
	cr6.compare<uint32_t>(ctx.r5.u32, r21.u32, xer);
	// blt cr6,0x830b93fc
	if (cr6.lt) goto loc_830B93FC;
loc_830B948C:
	// cmplw cr6,r25,r29
	cr6.compare<uint32_t>(r25.u32, r29.u32, xer);
	// bne cr6,0x830b96d4
	if (!cr6.eq) goto loc_830B96D4;
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r7,r7,16
	ctx.r7.s64 = ctx.r7.s64 + 16;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// addi r26,r26,16
	r26.s64 = r26.s64 + 16;
	// cmplw cr6,r24,r19
	cr6.compare<uint32_t>(r24.u32, r19.u32, xer);
	// blt cr6,0x830b93a0
	if (cr6.lt) goto loc_830B93A0;
loc_830B94AC:
	// mr r23,r18
	r23.u64 = r18.u64;
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x830b96a0
	if (cr6.eq) goto loc_830B96A0;
	// mr r26,r18
	r26.u64 = r18.u64;
	// addi r24,r1,112
	r24.s64 = ctx.r1.s64 + 112;
loc_830B94C0:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// lwzx r11,r26,r11
	r11.u64 = PPC_LOAD_U32(r26.u32 + r11.u32);
	// lwzx r25,r26,r9
	r25.u64 = PPC_LOAD_U32(r26.u32 + ctx.r9.u32);
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r10,r27
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r27.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// beq cr6,0x830b9574
	if (cr6.eq) goto loc_830B9574;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b9504
	if (cr0.eq) goto loc_830B9504;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830b9508
	goto loc_830B9508;
loc_830B9504:
	// mr r31,r18
	r31.u64 = r18.u64;
loc_830B9508:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830b96b0
	if (cr6.eq) goto loc_830B96B0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// lwz r5,4(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// blt 0x830b96c0
	if (cr0.lt) goto loc_830B96C0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830b96bc
	if (cr0.lt) goto loc_830B96BC;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// mr r30,r31
	r30.u64 = r31.u64;
	// stwx r31,r11,r27
	PPC_STORE_U32(r11.u32 + r27.u32, r31.u32);
loc_830B9574:
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// cmplwi r25,0
	cr0.compare<uint32_t>(r25.u32, 0, xer);
	// beq 0x830b968c
	if (cr0.eq) goto loc_830B968C;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
loc_830B9588:
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplwi cr6,r5,4
	cr6.compare<uint32_t>(ctx.r5.u32, 4, xer);
	// bge cr6,0x830b95b4
	if (!cr6.lt) goto loc_830B95B4;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_830B9598:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x830b95b4
	if (!cr6.eq) goto loc_830B95B4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x830b9598
	if (cr6.lt) goto loc_830B9598;
loc_830B95B4:
	// add r11,r26,r11
	r11.u64 = r26.u64 + r11.u64;
	// lwz r10,260(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// lwz r7,16(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r8,r18
	ctx.r8.u64 = r18.u64;
	// lwz r3,16(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r3,r10
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r10.u32);
	// stwx r11,r6,r7
	PPC_STORE_U32(ctx.r6.u32 + ctx.r7.u32, r11.u32);
	// lwz r11,260(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// lwz r9,20(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,60(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// or r9,r9,r20
	ctx.r9.u64 = ctx.r9.u64 | r20.u64;
	// stw r9,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r9.u32);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b9678
	if (!cr6.gt) goto loc_830B9678;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
loc_830B9614:
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r9,260(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r3,56(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// cmplw cr6,r3,r9
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b9664
	if (!cr6.eq) goto loc_830B9664;
	// lwz r9,60(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// rlwinm r3,r20,0,13,11
	ctx.r3.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 0) & 0xFFFFFFFFFFF7FFFF;
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// or r9,r3,r9
	ctx.r9.u64 = ctx.r3.u64 | ctx.r9.u64;
	// stw r9,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r9.u32);
	// bge cr6,0x830b9664
	if (!cr6.lt) goto loc_830B9664;
	// rlwinm. r3,r9,0,12,12
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x80000;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b965c
	if (cr0.eq) goto loc_830B965C;
	// rlwinm r9,r9,0,13,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFF7FFFF;
	// b 0x830b9660
	goto loc_830B9660;
loc_830B965C:
	// oris r9,r9,8
	ctx.r9.u64 = ctx.r9.u64 | 524288;
loc_830B9660:
	// stw r9,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r9.u32);
loc_830B9664:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x830b9614
	if (cr6.lt) goto loc_830B9614;
loc_830B9678:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// cmplw cr6,r5,r25
	cr6.compare<uint32_t>(ctx.r5.u32, r25.u32, xer);
	// blt cr6,0x830b9588
	if (cr6.lt) goto loc_830B9588;
loc_830B968C:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// addi r24,r24,16
	r24.s64 = r24.s64 + 16;
	// cmplw cr6,r23,r19
	cr6.compare<uint32_t>(r23.u32, r19.u32, xer);
	// blt cr6,0x830b94c0
	if (cr6.lt) goto loc_830B94C0;
loc_830B96A0:
	// lwz r11,260(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r18,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r18.u32);
	// b 0x830b96d8
	goto loc_830B96D8;
loc_830B96B0:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830b96d8
	goto loc_830B96D8;
loc_830B96BC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_830B96C0:
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x830b96d8
	goto loc_830B96D8;
loc_830B96D4:
	// li r3,1
	ctx.r3.s64 = 1;
loc_830B96D8:
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// lfd f30,-152(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -152);
	// lfd f31,-144(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// b 0x82ca2c08
	return;
}

__attribute__((alias("__imp__sub_830B96E8"))) PPC_WEAK_FUNC(sub_830B96E8);
PPC_FUNC_IMPL(__imp__sub_830B96E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// li r29,0
	r29.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r29,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r29.u64);
	// li r22,1
	r22.s64 = 1;
	// std r29,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, r29.u64);
	// li r5,24
	ctx.r5.s64 = 24;
	// std r29,0(r9)
	PPC_STORE_U64(ctx.r9.u32 + 0, r29.u64);
	// li r4,255
	ctx.r4.s64 = 255;
	// std r29,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r29.u64);
	// addi r3,r31,1040
	ctx.r3.s64 = r31.s64 + 1040;
	// std r29,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, r29.u64);
	// mr r17,r29
	r17.u64 = r29.u64;
	// std r29,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, r29.u64);
	// mr r23,r22
	r23.u64 = r22.u64;
	// std r29,16(r11)
	PPC_STORE_U64(r11.u32 + 16, r29.u64);
	// std r29,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, r29.u64);
	// std r29,16(r9)
	PPC_STORE_U64(ctx.r9.u32 + 16, r29.u64);
	// mr r18,r29
	r18.u64 = r29.u64;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// li r5,24
	ctx.r5.s64 = 24;
	// li r4,255
	ctx.r4.s64 = 255;
	// addi r3,r31,1064
	ctx.r3.s64 = r31.s64 + 1064;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r21,r29
	r21.u64 = r29.u64;
	// lis r20,24576
	r20.s64 = 1610612736;
	// mr r25,r29
	r25.u64 = r29.u64;
	// lis r14,24688
	r14.s64 = 1617952768;
	// lis r19,4352
	r19.s64 = 285212672;
	// lis r15,29376
	r15.s64 = 1925185536;
	// lis r16,29392
	r16.s64 = 1926234112;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b99a8
	if (!cr6.gt) goto loc_830B99A8;
	// mr r24,r29
	r24.u64 = r29.u64;
loc_830B9788:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r11,r24
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r24.u32);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r29,36(r10)
	PPC_STORE_U32(ctx.r10.u32 + 36, r29.u32);
	// rlwinm r11,r9,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// beq cr6,0x830b98f4
	if (cr6.eq) goto loc_830B98F4;
	// lis r8,24656
	ctx.r8.s64 = 1615855616;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x830b98f4
	if (cr6.eq) goto loc_830B98F4;
	// lis r8,24736
	ctx.r8.s64 = 1621098496;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x830b98f4
	if (cr6.eq) goto loc_830B98F4;
	// lis r8,24816
	ctx.r8.s64 = 1626341376;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x830b98f4
	if (cr6.eq) goto loc_830B98F4;
	// lis r8,29408
	ctx.r8.s64 = 1927282688;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x830b98f4
	if (cr6.eq) goto loc_830B98F4;
	// cmplw cr6,r11,r14
	cr6.compare<uint32_t>(r11.u32, r14.u32, xer);
	// beq cr6,0x830b98f4
	if (cr6.eq) goto loc_830B98F4;
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// beq cr6,0x830b98fc
	if (cr6.eq) goto loc_830B98FC;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// beq cr6,0x830b98f4
	if (cr6.eq) goto loc_830B98F4;
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// beq cr6,0x830b98f4
	if (cr6.eq) goto loc_830B98F4;
	// clrlwi. r3,r9,12
	ctx.r3.u64 = ctx.r9.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830b9988
	if (cr0.eq) goto loc_830B9988;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830b9988
	if (cr6.eq) goto loc_830B9988;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b98ec
	if (!cr6.gt) goto loc_830B98EC;
	// lwz r26,128(r31)
	r26.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// rlwinm r28,r3,2,0,29
	r28.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r30,20(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rotlwi r27,r11,0
	r27.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r4,8(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_830B9828:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r26
	cr6.compare<uint32_t>(ctx.r10.u32, r26.u32, xer);
	// bne cr6,0x830b98dc
	if (!cr6.eq) goto loc_830B98DC;
	// lbz r10,111(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 111);
	// lbz r11,110(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 110);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x830b98dc
	if (!cr6.eq) goto loc_830B98DC;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// lwzx r11,r10,r9
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830b9884
	if (cr6.eq) goto loc_830B9884;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830b9884
	if (cr6.eq) goto loc_830B9884;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830b9884
	if (!cr6.eq) goto loc_830B9884;
	// mr r23,r29
	r23.u64 = r29.u64;
loc_830B9884:
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// stwx r22,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, r22.u32);
	// add r11,r5,r3
	r11.u64 = ctx.r5.u64 + ctx.r3.u64;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// stwx r22,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, r22.u32);
	// bge cr6,0x830b98dc
	if (!cr6.lt) goto loc_830B98DC;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// subf r6,r5,r11
	ctx.r6.s64 = r11.s64 - ctx.r5.s64;
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
	// lwzx r11,r10,r7
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
loc_830B98AC:
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r30
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r30.u32);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// ble cr6,0x830b98cc
	if (!cr6.gt) goto loc_830B98CC;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
loc_830B98CC:
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830b98ac
	if (!cr0.eq) goto loc_830B98AC;
	// stwx r11,r10,r7
	PPC_STORE_U32(ctx.r10.u32 + ctx.r7.u32, r11.u32);
loc_830B98DC:
	// add r5,r5,r3
	ctx.r5.u64 = ctx.r5.u64 + ctx.r3.u64;
	// add r4,r28,r4
	ctx.r4.u64 = r28.u64 + ctx.r4.u64;
	// cmplw cr6,r5,r27
	cr6.compare<uint32_t>(ctx.r5.u32, r27.u32, xer);
	// blt cr6,0x830b9828
	if (cr6.lt) goto loc_830B9828;
loc_830B98EC:
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// b 0x830b9988
	goto loc_830B9988;
loc_830B98F4:
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// bne cr6,0x830b9914
	if (!cr6.eq) goto loc_830B9914;
loc_830B98FC:
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x830b992c
	goto loc_830B992C;
loc_830B9914:
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r10,r9,2,10,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0x3FFFFC;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
loc_830B992C:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,128(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830b9984
	if (!cr6.eq) goto loc_830B9984;
	// lwz r10,60(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830b9984
	if (!cr6.eq) goto loc_830B9984;
	// lbz r9,111(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 111);
	// lbz r10,110(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 110);
	// cmplwi cr6,r9,3
	cr6.compare<uint32_t>(ctx.r9.u32, 3, xer);
	// bne cr6,0x830b9a10
	if (!cr6.eq) goto loc_830B9A10;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830b997c
	if (cr6.eq) goto loc_830B997C;
	// lhz r9,202(r31)
	ctx.r9.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r9,260
	cr6.compare<uint32_t>(ctx.r9.u32, 260, xer);
	// beq cr6,0x830b997c
	if (cr6.eq) goto loc_830B997C;
	// mr r23,r29
	r23.u64 = r29.u64;
loc_830B997C:
	// stwx r22,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r22.u32);
	// b 0x830b9988
	goto loc_830B9988;
loc_830B9984:
	// mr r23,r29
	r23.u64 = r29.u64;
loc_830B9988:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// blt cr6,0x830b9788
	if (cr6.lt) goto loc_830B9788;
	// cmplwi cr6,r21,16
	cr6.compare<uint32_t>(r21.u32, 16, xer);
	// ble cr6,0x830b99a8
	if (!cr6.gt) goto loc_830B99A8;
	// mr r23,r29
	r23.u64 = r29.u64;
loc_830B99A8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b99dc
	if (!cr6.gt) goto loc_830B99DC;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_830B99BC:
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r29,64(r9)
	PPC_STORE_U32(ctx.r9.u32 + 64, r29.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b99bc
	if (cr6.lt) goto loc_830B99BC;
loc_830B99DC:
	// lwz r24,12(r31)
	r24.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,2048
	ctx.r3.s64 = 2048;
	// beq cr6,0x830b9a6c
	if (cr6.eq) goto loc_830B9A6C;
	// stw r29,560(r31)
	PPC_STORE_U32(r31.u32 + 560, r29.u32);
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,564(r31)
	PPC_STORE_U32(r31.u32 + 564, ctx.r3.u32);
	// bne 0x830b9a34
	if (!cr0.eq) goto loc_830B9A34;
loc_830B9A04:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830b9d94
	goto loc_830B9D94;
loc_830B9A10:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lwz r4,96(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// li r5,4513
	ctx.r5.s64 = 4513;
	// addi r6,r10,31904
	ctx.r6.s64 = ctx.r10.s64 + 31904;
loc_830B9A20:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830b9d94
	goto loc_830B9D94;
loc_830B9A34:
	// li r5,2048
	ctx.r5.s64 = 2048;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r5,r31,552
	ctx.r5.s64 = r31.s64 + 552;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b0dd0
	sub_830B0DD0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830b9d20
	if (!cr0.lt) goto loc_830B9D20;
	// b 0x830b9d94
	goto loc_830B9D94;
loc_830B9A6C:
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,560(r31)
	PPC_STORE_U32(r31.u32 + 560, ctx.r3.u32);
	// beq 0x830b9a04
	if (cr0.eq) goto loc_830B9A04;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,2048
	ctx.r3.s64 = 2048;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,564(r31)
	PPC_STORE_U32(r31.u32 + 564, ctx.r3.u32);
	// beq 0x830b9a04
	if (cr0.eq) goto loc_830B9A04;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,2048
	ctx.r3.s64 = 2048;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// mr. r17,r3
	r17.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r17.s32, 0, xer);
	// beq 0x830b9a04
	if (cr0.eq) goto loc_830B9A04;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,2048
	ctx.r3.s64 = 2048;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// lwz r3,560(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r25,r31,548
	r25.s64 = r31.s64 + 548;
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// addi r26,r31,552
	r26.s64 = r31.s64 + 552;
	// stw r29,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r29.u32);
	// mr r27,r29
	r27.u64 = r29.u64;
	// stw r29,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r29.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b9c6c
	if (!cr6.gt) goto loc_830B9C6C;
	// mr r28,r29
	r28.u64 = r29.u64;
loc_830B9B20:
	// cmplwi cr6,r28,2048
	cr6.compare<uint32_t>(r28.u32, 2048, xer);
	// bge cr6,0x830b9d9c
	if (!cr6.lt) goto loc_830B9D9C;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r8,r11,r28
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r11,r10,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// beq cr6,0x830b9b90
	if (cr6.eq) goto loc_830B9B90;
	// lis r9,24656
	ctx.r9.s64 = 1615855616;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b9b90
	if (cr6.eq) goto loc_830B9B90;
	// lis r9,24736
	ctx.r9.s64 = 1621098496;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b9b90
	if (cr6.eq) goto loc_830B9B90;
	// lis r9,29408
	ctx.r9.s64 = 1927282688;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b9b90
	if (cr6.eq) goto loc_830B9B90;
	// cmplw cr6,r11,r14
	cr6.compare<uint32_t>(r11.u32, r14.u32, xer);
	// beq cr6,0x830b9b90
	if (cr6.eq) goto loc_830B9B90;
	// lis r9,24816
	ctx.r9.s64 = 1626341376;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830b9b90
	if (cr6.eq) goto loc_830B9B90;
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// beq cr6,0x830b9b90
	if (cr6.eq) goto loc_830B9B90;
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// beq cr6,0x830b9b90
	if (cr6.eq) goto loc_830B9B90;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// bne cr6,0x830b9c58
	if (!cr6.eq) goto loc_830B9C58;
loc_830B9B90:
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// bne cr6,0x830b9ba0
	if (!cr6.eq) goto loc_830B9BA0;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_830B9BA0:
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// add r4,r9,r11
	ctx.r4.u64 = ctx.r9.u64 + r11.u64;
	// lwz r6,136(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// beq cr6,0x830b9c38
	if (cr6.eq) goto loc_830B9C38;
	// lwz r7,60(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x830b9c38
	if (!cr6.eq) goto loc_830B9C38;
	// lwz r10,128(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x830b9c58
	if (!cr6.eq) goto loc_830B9C58;
	// lbz r10,111(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 111);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x830b9db0
	if (!cr6.eq) goto loc_830B9DB0;
	// lbz r11,110(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 110);
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// rotlwi r11,r11,2
	r11.u64 = __builtin_rotateleft32(r11.u32, 2);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830b9c58
	if (cr6.eq) goto loc_830B9C58;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830b9c58
	if (cr6.eq) goto loc_830B9C58;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4520
	ctx.r5.s64 = 4520;
	// addi r6,r11,31824
	ctx.r6.s64 = r11.s64 + 31824;
loc_830B9C20:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r30,-32768
	r30.s64 = -2147483648;
	// ori r30,r30,16389
	r30.u64 = r30.u64 | 16389;
	// b 0x830b9d68
	goto loc_830B9D68;
loc_830B9C38:
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// subf r5,r10,r11
	ctx.r5.s64 = r11.s64 - ctx.r10.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b0b38
	sub_830B0B38(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830b9d68
	if (cr0.lt) goto loc_830B9D68;
loc_830B9C58:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x830b9b20
	if (cr6.lt) goto loc_830B9B20;
loc_830B9C6C:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b9ca4
	if (cr6.eq) goto loc_830B9CA4;
	// mr r11,r17
	r11.u64 = r17.u64;
	// subf r9,r17,r18
	ctx.r9.s64 = r18.s64 - r17.s64;
loc_830B9C84:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwx r8,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r8.u32);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// blt cr6,0x830b9c84
	if (cr6.lt) goto loc_830B9C84;
loc_830B9CA4:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b0dd0
	sub_830B0DD0(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830b9d68
	if (cr0.lt) goto loc_830B9D68;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x830b9cfc
	if (cr6.eq) goto loc_830B9CFC;
	// mr r11,r18
	r11.u64 = r18.u64;
loc_830B9CE0:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r29,36(r9)
	PPC_STORE_U32(ctx.r9.u32 + 36, r29.u32);
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// blt cr6,0x830b9ce0
	if (cr6.lt) goto loc_830B9CE0;
loc_830B9CFC:
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// lwz r9,76(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// lwz r8,564(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// bl 0x830b0dd0
	sub_830B0DD0(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830b9d68
	if (cr0.lt) goto loc_830B9D68;
loc_830B9D20:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b9d64
	if (!cr6.gt) goto loc_830B9D64;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_830B9D34:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r8,64(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// bne cr6,0x830b9d50
	if (!cr6.eq) goto loc_830B9D50;
	// lwz r8,116(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
loc_830B9D50:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// blt cr6,0x830b9d34
	if (cr6.lt) goto loc_830B9D34;
loc_830B9D64:
	// mr r30,r29
	r30.u64 = r29.u64;
loc_830B9D68:
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x830b9d7c
	if (cr6.eq) goto loc_830B9D7C;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
loc_830B9D7C:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x830b9d90
	if (cr6.eq) goto loc_830B9D90;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
loc_830B9D90:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_830B9D94:
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// b 0x82ca2c00
	return;
loc_830B9D9C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4514
	ctx.r5.s64 = 4514;
	// addi r6,r11,29872
	ctx.r6.s64 = r11.s64 + 29872;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x830b9a20
	goto loc_830B9A20;
loc_830B9DB0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4513
	ctx.r5.s64 = 4513;
	// addi r6,r11,29368
	ctx.r6.s64 = r11.s64 + 29368;
	// b 0x830b9c20
	goto loc_830B9C20;
}

__attribute__((alias("__imp__sub_830B9DC0"))) PPC_WEAK_FUNC(sub_830B9DC0);
PPC_FUNC_IMPL(__imp__sub_830B9DC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r29,0
	r29.s64 = 0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,696(r31)
	PPC_STORE_U32(r31.u32 + 696, ctx.r3.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// lwz r11,696(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 696);
	// stw r3,700(r31)
	PPC_STORE_U32(r31.u32 + 700, ctx.r3.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830b9f0c
	if (cr6.eq) goto loc_830B9F0C;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830b9f0c
	if (cr6.eq) goto loc_830B9F0C;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b9e84
	if (!cr6.gt) goto loc_830B9E84;
	// li r30,0
	r30.s64 = 0;
loc_830B9E24:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b9e3c
	if (cr0.eq) goto loc_830B9E3C;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// b 0x830b9e40
	goto loc_830B9E40;
loc_830B9E3C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B9E40:
	// lwz r11,696(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 696);
	// stwx r3,r30,r11
	PPC_STORE_U32(r30.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,696(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 696);
	// lwzx r10,r30,r11
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b9f0c
	if (cr6.eq) goto loc_830B9F0C;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r3,r30,r11
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwzx r4,r10,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
	// bl 0x8307a0a0
	sub_8307A0A0(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830b9f14
	if (cr0.lt) goto loc_830B9F14;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x830b9e24
	if (cr6.lt) goto loc_830B9E24;
loc_830B9E84:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b9ef8
	if (!cr6.gt) goto loc_830B9EF8;
	// li r30,0
	r30.s64 = 0;
loc_830B9E98:
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x8307a478
	sub_8307A478(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830b9eb0
	if (cr0.eq) goto loc_830B9EB0;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// b 0x830b9eb4
	goto loc_830B9EB4;
loc_830B9EB0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830B9EB4:
	// lwz r11,700(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 700);
	// stwx r3,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, ctx.r3.u32);
	// lwz r11,700(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 700);
	// lwzx r10,r11,r30
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b9f0c
	if (cr6.eq) goto loc_830B9F0C;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwzx r4,r10,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
	// bl 0x8307a2f8
	sub_8307A2F8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830b9f14
	if (cr0.lt) goto loc_830B9F14;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x830b9e98
	if (cr6.lt) goto loc_830B9E98;
loc_830B9EF8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r11,708(r31)
	PPC_STORE_U32(r31.u32 + 708, r11.u32);
	// stw r10,704(r31)
	PPC_STORE_U32(r31.u32 + 704, ctx.r10.u32);
	// b 0x830b9f14
	goto loc_830B9F14;
loc_830B9F0C:
	// lis r29,-32761
	r29.s64 = -2147024896;
	// ori r29,r29,14
	r29.u64 = r29.u64 | 14;
loc_830B9F14:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830B9F20"))) PPC_WEAK_FUNC(sub_830B9F20);
PPC_FUNC_IMPL(__imp__sub_830B9F20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r25,0
	r25.s64 = 0;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830b9f68
	if (!cr6.gt) goto loc_830B9F68;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_830B9F48:
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r25,40(r9)
	PPC_STORE_U32(ctx.r9.u32 + 40, r25.u32);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x830b9f48
	if (cr6.lt) goto loc_830B9F48;
loc_830B9F68:
	// mr r30,r25
	r30.u64 = r25.u64;
	// li r23,1
	r23.s64 = 1;
loc_830B9F70:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r10,r30,r11
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b9fac
	if (cr6.eq) goto loc_830B9FAC;
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rotlwi r5,r10,0
	ctx.r5.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061870
	sub_83061870(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r6,2
	ctx.r6.s64 = 2;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r5,r30,r11
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// bl 0x830618f0
	sub_830618F0(ctx, base);
loc_830B9FAC:
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// lwzx r10,r30,r11
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830b9fc4
	if (cr6.eq) goto loc_830B9FC4;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// stw r23,40(r11)
	PPC_STORE_U32(r11.u32 + 40, r23.u32);
loc_830B9FC4:
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r30,24
	cr6.compare<uint32_t>(r30.u32, 24, xer);
	// blt cr6,0x830b9f70
	if (cr6.lt) goto loc_830B9F70;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// lis r22,29200
	r22.s64 = 1913651200;
	// lis r21,4352
	r21.s64 = 285212672;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830ba060
	if (!cr6.gt) goto loc_830BA060;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
loc_830B9FEC:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r9,r8,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830ba04c
	if (!cr0.eq) goto loc_830BA04C;
	// cmplw cr6,r10,r22
	cr6.compare<uint32_t>(ctx.r10.u32, r22.u32, xer);
	// beq cr6,0x830ba04c
	if (cr6.eq) goto loc_830BA04C;
	// cmplw cr6,r10,r21
	cr6.compare<uint32_t>(ctx.r10.u32, r21.u32, xer);
	// beq cr6,0x830ba04c
	if (cr6.eq) goto loc_830BA04C;
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830ba308
	if (!cr6.lt) goto loc_830BA308;
	// lwz r10,40(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 40);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x830ba04c
	if (!cr6.eq) goto loc_830BA04C;
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r11.u32);
loc_830BA04C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x830b9fec
	if (cr6.lt) goto loc_830B9FEC;
loc_830BA060:
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r24,r23
	r24.u64 = r23.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830ba09c
	if (cr6.eq) goto loc_830BA09C;
	// lwz r10,548(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830ba09c
	if (!cr6.gt) goto loc_830BA09C;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
loc_830BA080:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830ba090
	if (cr6.eq) goto loc_830BA090;
	// mr r24,r25
	r24.u64 = r25.u64;
loc_830BA090:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830ba080
	if (!cr0.eq) goto loc_830BA080;
loc_830BA09C:
	// lis r11,-31946
	r11.s64 = -2093613056;
	// mr r26,r25
	r26.u64 = r25.u64;
	// addi r27,r11,-23384
	r27.s64 = r11.s64 + -23384;
loc_830BA0A8:
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2a30
	sub_830B2A30(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830ba4b4
	if (cr0.lt) goto loc_830BA4B4;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// li r5,6
	ctx.r5.s64 = 6;
	// lwz r6,548(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b7b88
	sub_830B7B88(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830ba168
	if (!cr6.gt) goto loc_830BA168;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
loc_830BA0F4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r8,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830ba154
	if (cr6.eq) goto loc_830BA154;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r11,40(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// rlwinm r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x830ba120
	if (cr6.eq) goto loc_830BA120;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830ba14c
	if (!cr6.eq) goto loc_830BA14C;
loc_830BA120:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830ba14c
	if (!cr0.eq) goto loc_830BA14C;
	// cmplw cr6,r9,r21
	cr6.compare<uint32_t>(ctx.r9.u32, r21.u32, xer);
	// beq cr6,0x830ba14c
	if (cr6.eq) goto loc_830BA14C;
	// cmplw cr6,r9,r22
	cr6.compare<uint32_t>(ctx.r9.u32, r22.u32, xer);
	// beq cr6,0x830ba14c
	if (cr6.eq) goto loc_830BA14C;
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
loc_830BA14C:
	// cmplwi cr6,r6,512
	cr6.compare<uint32_t>(ctx.r6.u32, 512, xer);
	// bge cr6,0x830ba4bc
	if (!cr6.lt) goto loc_830BA4BC;
loc_830BA154:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x830ba0f4
	if (cr6.lt) goto loc_830BA0F4;
loc_830BA168:
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b7b88
	sub_830B7B88(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bge cr6,0x830ba1ac
	if (!cr6.lt) goto loc_830BA1AC;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// ble cr6,0x830ba408
	if (!cr6.gt) goto loc_830BA408;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x830ba408
	if (!cr6.eq) goto loc_830BA408;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x830ba408
	if (!cr6.eq) goto loc_830BA408;
loc_830BA1AC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r28,r25
	r28.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830ba338
	if (!cr6.gt) goto loc_830BA338;
	// mr r29,r25
	r29.u64 = r25.u64;
loc_830BA1C0:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r30,r29,r11
	r30.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830ba2f0
	if (!cr6.eq) goto loc_830BA2F0;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830ba2f0
	if (!cr0.eq) goto loc_830BA2F0;
	// cmplw cr6,r10,r22
	cr6.compare<uint32_t>(ctx.r10.u32, r22.u32, xer);
	// beq cr6,0x830ba2f0
	if (cr6.eq) goto loc_830BA2F0;
	// lwz r8,4(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830ba238
	if (cr6.eq) goto loc_830BA238;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
loc_830BA20C:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lbz r7,111(r7)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r7.u32 + 111);
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// beq cr6,0x830ba238
	if (cr6.eq) goto loc_830BA238;
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// blt cr6,0x830ba20c
	if (cr6.lt) goto loc_830BA20C;
loc_830BA238:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x830ba2f0
	if (!cr6.eq) goto loc_830BA2F0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x830ba294
	if (!cr6.eq) goto loc_830BA294;
	// lwz r8,12(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830ba28c
	if (cr6.eq) goto loc_830BA28C;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
loc_830BA260:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmplwi cr6,r7,3
	cr6.compare<uint32_t>(ctx.r7.u32, 3, xer);
	// beq cr6,0x830ba28c
	if (cr6.eq) goto loc_830BA28C;
	// lwz r7,12(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// blt cr6,0x830ba260
	if (cr6.lt) goto loc_830BA260;
loc_830BA28C:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x830ba2f0
	if (!cr6.eq) goto loc_830BA2F0;
loc_830BA294:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830ba2f0
	if (!cr0.eq) goto loc_830BA2F0;
	// stw r23,40(r30)
	PPC_STORE_U32(r30.u32 + 40, r23.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b3418
	sub_830B3418(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830ba2ec
	if (!cr0.eq) goto loc_830BA2EC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b3580
	sub_830B3580(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830ba314
	if (cr0.eq) goto loc_830BA314;
loc_830BA2EC:
	// stw r25,40(r30)
	PPC_STORE_U32(r30.u32 + 40, r25.u32);
loc_830BA2F0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x830ba1c0
	if (cr6.lt) goto loc_830BA1C0;
	// b 0x830ba338
	goto loc_830BA338;
loc_830BA308:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830ba4b4
	goto loc_830BA4B4;
loc_830BA314:
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// bge cr6,0x830ba4bc
	if (!cr6.lt) goto loc_830BA4BC;
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r30,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r30.u32);
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r11.u32);
loc_830BA338:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// beq cr6,0x830ba408
	if (cr6.eq) goto loc_830BA408;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2a30
	sub_830B2A30(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830ba4b4
	if (cr0.lt) goto loc_830BA4B4;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// lwz r6,548(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// li r5,6
	ctx.r5.s64 = 6;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b7b88
	sub_830B7B88(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830ba168
	if (!cr6.gt) goto loc_830BA168;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
loc_830BA390:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r8,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830ba3f0
	if (cr6.eq) goto loc_830BA3F0;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r11,40(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// rlwinm r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x830ba3bc
	if (cr6.eq) goto loc_830BA3BC;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830ba3e8
	if (!cr6.eq) goto loc_830BA3E8;
loc_830BA3BC:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830ba3e8
	if (!cr0.eq) goto loc_830BA3E8;
	// cmplw cr6,r9,r21
	cr6.compare<uint32_t>(ctx.r9.u32, r21.u32, xer);
	// beq cr6,0x830ba3e8
	if (cr6.eq) goto loc_830BA3E8;
	// cmplw cr6,r9,r22
	cr6.compare<uint32_t>(ctx.r9.u32, r22.u32, xer);
	// beq cr6,0x830ba3e8
	if (cr6.eq) goto loc_830BA3E8;
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
loc_830BA3E8:
	// cmplwi cr6,r6,512
	cr6.compare<uint32_t>(ctx.r6.u32, 512, xer);
	// bge cr6,0x830ba4bc
	if (!cr6.lt) goto loc_830BA4BC;
loc_830BA3F0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x830ba390
	if (cr6.lt) goto loc_830BA390;
	// b 0x830ba168
	goto loc_830BA168;
loc_830BA408:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmplwi cr6,r26,2
	cr6.compare<uint32_t>(r26.u32, 2, xer);
	// blt cr6,0x830ba0a8
	if (cr6.lt) goto loc_830BA0A8;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830ba4b0
	if (!cr6.gt) goto loc_830BA4B0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
loc_830BA428:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r7,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r11,40(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830ba444
	if (!cr6.eq) goto loc_830BA444;
	// li r11,2
	r11.s64 = 2;
	// stw r11,40(r10)
	PPC_STORE_U32(ctx.r10.u32 + 40, r11.u32);
loc_830BA444:
	// lwz r8,552(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// cmplwi cr6,r8,512
	cr6.compare<uint32_t>(ctx.r8.u32, 512, xer);
	// bge cr6,0x830ba308
	if (!cr6.lt) goto loc_830BA308;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r5,40(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// rlwinm r9,r11,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplwi cr6,r5,2
	cr6.compare<uint32_t>(ctx.r5.u32, 2, xer);
	// bne cr6,0x830ba49c
	if (!cr6.eq) goto loc_830BA49C;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x830acde0
	sub_830ACDE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830ba49c
	if (!cr0.eq) goto loc_830BA49C;
	// cmplw cr6,r9,r21
	cr6.compare<uint32_t>(ctx.r9.u32, r21.u32, xer);
	// beq cr6,0x830ba49c
	if (cr6.eq) goto loc_830BA49C;
	// cmplw cr6,r9,r22
	cr6.compare<uint32_t>(ctx.r9.u32, r22.u32, xer);
	// beq cr6,0x830ba49c
	if (cr6.eq) goto loc_830BA49C;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r10,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r10.u32);
	// lwz r11,552(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r11.u32);
loc_830BA49C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x830ba428
	if (cr6.lt) goto loc_830BA428;
loc_830BA4B0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BA4B4:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c1c
	return;
loc_830BA4BC:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830ba4b4
	goto loc_830BA4B4;
}

__attribute__((alias("__imp__sub_830BA4C8"))) PPC_WEAK_FUNC(sub_830BA4C8);
PPC_FUNC_IMPL(__imp__sub_830BA4C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r25,0
	r25.s64 = 0;
	// mr r24,r25
	r24.u64 = r25.u64;
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x830ba4f8
	if (cr6.eq) goto loc_830BA4F8;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830ba7b8
	goto loc_830BA7B8;
loc_830BA4F8:
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// mr r29,r25
	r29.u64 = r25.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r11,r25
	r11.u64 = r25.u64;
	// std r25,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, r25.u64);
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// std r25,0(r9)
	PPC_STORE_U64(ctx.r9.u32 + 0, r25.u64);
	// lis r4,29200
	ctx.r4.s64 = 1913651200;
	// std r25,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, r25.u64);
	// std r25,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, r25.u64);
loc_830BA524:
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830ba5c0
	if (cr6.eq) goto loc_830BA5C0;
	// rotlwi r7,r9,0
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// lwz r9,0(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830ba5c0
	if (cr6.eq) goto loc_830BA5C0;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r8,0(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r3,r8,0,0,11
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r3,r4
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r4.u32, xer);
	// beq cr6,0x830ba5b0
	if (cr6.eq) goto loc_830BA5B0;
	// rlwinm r3,r9,0,0,11
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// lis r31,4352
	r31.s64 = 285212672;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// cmplw cr6,r3,r31
	cr6.compare<uint32_t>(ctx.r3.u32, r31.u32, xer);
	// beq cr6,0x830ba570
	if (cr6.eq) goto loc_830BA570;
	// clrlwi r9,r8,12
	ctx.r9.u64 = ctx.r8.u32 & 0xFFFFF;
loc_830BA570:
	// lwz r8,8(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r3,136(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 136);
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r9,r3
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r3.u32, xer);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stwx r25,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r25.u32);
	// bne cr6,0x830ba5b8
	if (!cr6.eq) goto loc_830BA5B8;
	// stw r9,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r9.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// b 0x830ba5c0
	goto loc_830BA5C0;
loc_830BA5B0:
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stwx r25,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r25.u32);
loc_830BA5B8:
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// stwx r9,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r9.u32);
loc_830BA5C0:
	// lwz r10,76(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// blt cr6,0x830ba524
	if (cr6.lt) goto loc_830BA524;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830ba644
	if (!cr6.gt) goto loc_830BA644;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_830BA5E8:
	// lwz r10,560(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 560);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830ba630
	if (cr6.eq) goto loc_830BA630;
	// rotlwi r9,r9,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830ba630
	if (cr6.eq) goto loc_830BA630;
	// rlwinm r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r9,r4
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r4.u32, xer);
	// beq cr6,0x830ba630
	if (cr6.eq) goto loc_830BA630;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwzx r7,r11,r9
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x830ba7c0
	if (!cr6.eq) goto loc_830BA7C0;
	// lwzx r7,r11,r10
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stwx r25,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r25.u32);
	// stwx r7,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r7.u32);
loc_830BA630:
	// lwz r10,76(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// blt cr6,0x830ba5e8
	if (cr6.lt) goto loc_830BA5E8;
loc_830BA644:
	// lhz r11,202(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 202);
	// cmplwi cr6,r11,257
	cr6.compare<uint32_t>(r11.u32, 257, xer);
	// ble cr6,0x830ba670
	if (!cr6.gt) goto loc_830BA670;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830b6550
	sub_830B6550(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830ba790
	if (cr0.lt) goto loc_830BA790;
loc_830BA670:
	// li r7,2
	ctx.r7.s64 = 2;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830b6550
	sub_830B6550(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830ba790
	if (cr0.lt) goto loc_830BA790;
	// li r7,3
	ctx.r7.s64 = 3;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830b6550
	sub_830B6550(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830ba790
	if (cr0.lt) goto loc_830BA790;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830b5f78
	sub_830B5F78(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x830ba790
	if (cr0.lt) goto loc_830BA790;
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// lis r10,-32768
	ctx.r10.s64 = -2147483648;
	// mr r28,r25
	r28.u64 = r25.u64;
	// ori r27,r10,16389
	r27.u64 = ctx.r10.u64 | 16389;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830ba730
	if (!cr6.gt) goto loc_830BA730;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r26,r1,96
	r26.s64 = ctx.r1.s64 + 96;
	// addi r29,r11,32104
	r29.s64 = r11.s64 + 32104;
loc_830BA6F0:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830ba71c
	if (cr6.eq) goto loc_830BA71C;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lbz r7,203(r30)
	ctx.r7.u64 = PPC_LOAD_U8(r30.u32 + 203);
	// li r5,4523
	ctx.r5.s64 = 4523;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r31,r27
	r31.u64 = r27.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r24,1
	r24.s64 = 1;
loc_830BA71C:
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x830ba6f0
	if (cr6.lt) goto loc_830BA6F0;
loc_830BA730:
	// cmpw cr6,r31,r27
	cr6.compare<int32_t>(r31.s32, r27.s32, xer);
	// beq cr6,0x830ba788
	if (cr6.eq) goto loc_830BA788;
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830ba770
	if (!cr6.gt) goto loc_830BA770;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_830BA74C:
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwz r8,564(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stwx r9,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r9,76(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x830ba74c
	if (cr6.lt) goto loc_830BA74C;
loc_830BA770:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,560(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 560);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// stw r25,560(r30)
	PPC_STORE_U32(r30.u32 + 560, r25.u32);
	// mr r31,r25
	r31.u64 = r25.u64;
	// stw r25,548(r30)
	PPC_STORE_U32(r30.u32 + 548, r25.u32);
loc_830BA788:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bge cr6,0x830ba7b4
	if (!cr6.lt) goto loc_830BA7B4;
loc_830BA790:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x830ba7b4
	if (!cr6.eq) goto loc_830BA7B4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lbz r7,203(r30)
	ctx.r7.u64 = PPC_LOAD_U8(r30.u32 + 203);
	// li r5,4523
	ctx.r5.s64 = 4523;
	// addi r6,r11,31976
	ctx.r6.s64 = r11.s64 + 31976;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830BA7B4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_830BA7B8:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	return;
loc_830BA7C0:
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
	// b 0x830ba790
	goto loc_830BA790;
}

__attribute__((alias("__imp__sub_830BA7D0"))) PPC_WEAK_FUNC(sub_830BA7D0);
PPC_FUNC_IMPL(__imp__sub_830BA7D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830babfc
	if (cr6.eq) goto loc_830BABFC;
	// lis r11,-32768
	r11.s64 = -2147483648;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lis r27,28720
	r27.s64 = 1882193920;
	// lis r24,20480
	r24.s64 = 1342177280;
	// ori r28,r11,16385
	r28.u64 = r11.u64 | 16385;
	// lis r25,29280
	r25.s64 = 1918894080;
loc_830BA808:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// beq 0x830babec
	if (cr0.eq) goto loc_830BABEC;
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830ba83c
	if (cr6.eq) goto loc_830BA83C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x830ba83c
	if (!cr6.eq) goto loc_830BA83C;
	// addi r11,r11,48
	r11.s64 = r11.s64 + 48;
	// stw r11,264(r31)
	PPC_STORE_U32(r31.u32 + 264, r11.u32);
loc_830BA83C:
	// lwz r10,260(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830babec
	if (cr6.eq) goto loc_830BABEC;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830bac08
	if (!cr6.eq) goto loc_830BAC08;
	// rlwinm r11,r8,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bgt cr6,0x830baabc
	if (cr6.gt) goto loc_830BAABC;
	// beq cr6,0x830baab0
	if (cr6.eq) goto loc_830BAAB0;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bgt cr6,0x830baa44
	if (cr6.gt) goto loc_830BAA44;
	// beq cr6,0x830ba940
	if (cr6.eq) goto loc_830BA940;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830babec
	if (cr6.eq) goto loc_830BABEC;
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ba928
	if (cr6.eq) goto loc_830BA928;
	// lis r10,4112
	ctx.r10.s64 = 269484032;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ba91c
	if (cr6.eq) goto loc_830BA91C;
	// lis r10,4352
	ctx.r10.s64 = 285212672;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ba910
	if (cr6.eq) goto loc_830BA910;
	// lis r10,8256
	ctx.r10.s64 = 541065216;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ba904
	if (cr6.eq) goto loc_830BA904;
	// lis r10,8272
	ctx.r10.s64 = 542113792;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830ba8f8
	if (cr6.eq) goto loc_830BA8F8;
	// lis r10,12288
	ctx.r10.s64 = 805306368;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bac30
	if (!cr6.eq) goto loc_830BAC30;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// bne cr6,0x830ba8f0
	if (!cr6.eq) goto loc_830BA8F0;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,188(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 188);
	// b 0x830ba930
	goto loc_830BA930;
loc_830BA8F0:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// b 0x830babdc
	goto loc_830BABDC;
loc_830BA8F8:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,176(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 176);
	// b 0x830ba930
	goto loc_830BA930;
loc_830BA904:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,172(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 172);
	// b 0x830ba930
	goto loc_830BA930;
loc_830BA910:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,220(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 220);
	// b 0x830ba930
	goto loc_830BA930;
loc_830BA91C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,128(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 128);
	// b 0x830ba930
	goto loc_830BA930;
loc_830BA928:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,124(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 124);
loc_830BA930:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x830babdc
	goto loc_830BABDC;
loc_830BA940:
	// clrlwi r8,r8,12
	ctx.r8.u64 = ctx.r8.u32 & 0xFFFFF;
	// cmplwi cr6,r8,2
	cr6.compare<uint32_t>(ctx.r8.u32, 2, xer);
	// beq cr6,0x830bac30
	if (cr6.eq) goto loc_830BAC30;
	// cmplwi cr6,r8,4
	cr6.compare<uint32_t>(ctx.r8.u32, 4, xer);
	// bne cr6,0x830ba96c
	if (!cr6.eq) goto loc_830BA96C;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,257
	cr6.compare<uint32_t>(r11.u32, 257, xer);
	// bne cr6,0x830ba96c
	if (!cr6.eq) goto loc_830BA96C;
loc_830BA960:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b6f48
	sub_830B6F48(ctx, base);
	// b 0x830babdc
	goto loc_830BABDC;
loc_830BA96C:
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,258
	cr6.compare<uint32_t>(r11.u32, 258, xer);
	// beq cr6,0x830ba980
	if (cr6.eq) goto loc_830BA980;
	// cmplwi cr6,r11,259
	cr6.compare<uint32_t>(r11.u32, 259, xer);
	// bne cr6,0x830baa04
	if (!cr6.eq) goto loc_830BAA04;
loc_830BA980:
	// cmplwi cr6,r8,4
	cr6.compare<uint32_t>(ctx.r8.u32, 4, xer);
	// bne cr6,0x830baa04
	if (!cr6.eq) goto loc_830BAA04;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r7,132(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r6,r10,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r10,r8,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwzx r8,r6,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// lwz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// bne cr6,0x830baa10
	if (!cr6.eq) goto loc_830BAA10;
	// lwz r9,136(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lbz r11,111(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 111);
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// bne cr6,0x830ba9e4
	if (!cr6.eq) goto loc_830BA9E4;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830ba9fc
	if (cr6.eq) goto loc_830BA9FC;
loc_830BA9E4:
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830baa04
	if (!cr6.eq) goto loc_830BAA04;
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830baa04
	if (!cr6.eq) goto loc_830BAA04;
loc_830BA9FC:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
loc_830BAA00:
	// beq cr6,0x830ba960
	if (cr6.eq) goto loc_830BA960;
loc_830BAA04:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,180(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 180);
	// b 0x830ba930
	goto loc_830BA930;
loc_830BAA10:
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// bne cr6,0x830baa28
	if (!cr6.eq) goto loc_830BAA28;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// beq cr6,0x830ba960
	if (cr6.eq) goto loc_830BA960;
loc_830BAA28:
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830baa04
	if (!cr6.eq) goto loc_830BAA04;
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// b 0x830baa00
	goto loc_830BAA00;
loc_830BAA44:
	// lis r10,24576
	ctx.r10.s64 = 1610612736;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830baaa4
	if (cr6.eq) goto loc_830BAAA4;
	// lis r10,24656
	ctx.r10.s64 = 1615855616;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830baaa4
	if (cr6.eq) goto loc_830BAAA4;
	// lis r10,24688
	ctx.r10.s64 = 1617952768;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830baa98
	if (cr6.eq) goto loc_830BAA98;
	// lis r10,24736
	ctx.r10.s64 = 1621098496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830baaa4
	if (cr6.eq) goto loc_830BAAA4;
	// lis r10,24816
	ctx.r10.s64 = 1626341376;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830baaa4
	if (cr6.eq) goto loc_830BAAA4;
	// lis r10,28688
	ctx.r10.s64 = 1880096768;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bac30
	if (!cr6.eq) goto loc_830BAC30;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,200(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 200);
	// b 0x830ba930
	goto loc_830BA930;
loc_830BAA98:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b74a0
	sub_830B74A0(ctx, base);
	// b 0x830babdc
	goto loc_830BABDC;
loc_830BAAA4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b7608
	sub_830B7608(ctx, base);
	// b 0x830babdc
	goto loc_830BABDC;
loc_830BAAB0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,208(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 208);
	// b 0x830ba930
	goto loc_830BA930;
loc_830BAABC:
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bgt cr6,0x830bab5c
	if (cr6.gt) goto loc_830BAB5C;
	// beq cr6,0x830bab54
	if (cr6.eq) goto loc_830BAB54;
	// lis r10,28736
	ctx.r10.s64 = 1883242496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830baab0
	if (cr6.eq) goto loc_830BAAB0;
	// lis r10,28912
	ctx.r10.s64 = 1894776832;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bab48
	if (cr6.eq) goto loc_830BAB48;
	// lis r10,29200
	ctx.r10.s64 = 1913651200;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bab3c
	if (cr6.eq) goto loc_830BAB3C;
	// lis r10,29216
	ctx.r10.s64 = 1914699776;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bab34
	if (cr6.eq) goto loc_830BAB34;
	// lis r10,29232
	ctx.r10.s64 = 1915748352;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bab2c
	if (cr6.eq) goto loc_830BAB2C;
	// lis r10,29248
	ctx.r10.s64 = 1916796928;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bab24
	if (cr6.eq) goto loc_830BAB24;
	// lis r10,29264
	ctx.r10.s64 = 1917845504;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bac30
	if (!cr6.eq) goto loc_830BAC30;
	// li r4,74
	ctx.r4.s64 = 74;
	// b 0x830babd4
	goto loc_830BABD4;
loc_830BAB24:
	// li r4,73
	ctx.r4.s64 = 73;
	// b 0x830babd4
	goto loc_830BABD4;
loc_830BAB2C:
	// li r4,72
	ctx.r4.s64 = 72;
	// b 0x830babd4
	goto loc_830BABD4;
loc_830BAB34:
	// li r4,71
	ctx.r4.s64 = 71;
	// b 0x830babd4
	goto loc_830BABD4;
loc_830BAB3C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b77d8
	sub_830B77D8(ctx, base);
	// b 0x830babdc
	goto loc_830BABDC;
loc_830BAB48:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,192(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 192);
	// b 0x830ba930
	goto loc_830BA930;
loc_830BAB54:
	// li r4,82
	ctx.r4.s64 = 82;
	// b 0x830babd4
	goto loc_830BABD4;
loc_830BAB5C:
	// lis r10,29296
	ctx.r10.s64 = 1919942656;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830babd0
	if (cr6.eq) goto loc_830BABD0;
	// lis r10,29312
	ctx.r10.s64 = 1920991232;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830babc8
	if (cr6.eq) goto loc_830BABC8;
	// lis r10,29328
	ctx.r10.s64 = 1922039808;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830babc0
	if (cr6.eq) goto loc_830BABC0;
	// lis r10,29344
	ctx.r10.s64 = 1923088384;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830babb8
	if (cr6.eq) goto loc_830BABB8;
	// lis r10,29360
	ctx.r10.s64 = 1924136960;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830babb0
	if (cr6.eq) goto loc_830BABB0;
	// lis r10,29408
	ctx.r10.s64 = 1927282688;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bac30
	if (!cr6.eq) goto loc_830BAC30;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b7338
	sub_830B7338(ctx, base);
	// b 0x830babdc
	goto loc_830BABDC;
loc_830BABB0:
	// li r4,83
	ctx.r4.s64 = 83;
	// b 0x830babd4
	goto loc_830BABD4;
loc_830BABB8:
	// li r4,76
	ctx.r4.s64 = 76;
	// b 0x830babd4
	goto loc_830BABD4;
loc_830BABC0:
	// li r4,77
	ctx.r4.s64 = 77;
	// b 0x830babd4
	goto loc_830BABD4;
loc_830BABC8:
	// li r4,70
	ctx.r4.s64 = 70;
	// b 0x830babd4
	goto loc_830BABD4;
loc_830BABD0:
	// li r4,69
	ctx.r4.s64 = 69;
loc_830BABD4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b7128
	sub_830B7128(ctx, base);
loc_830BABDC:
	// cmpw cr6,r3,r28
	cr6.compare<int32_t>(ctx.r3.s32, r28.s32, xer);
	// beq cr6,0x830bac30
	if (cr6.eq) goto loc_830BAC30;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x830bac00
	if (cr6.lt) goto loc_830BAC00;
loc_830BABEC:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r26
	cr6.compare<uint32_t>(r30.u32, r26.u32, xer);
	// blt cr6,0x830ba808
	if (cr6.lt) goto loc_830BA808;
loc_830BABFC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BAC00:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
loc_830BAC08:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r5,4511
	ctx.r5.s64 = 4511;
	// addi r6,r10,24852
	ctx.r6.s64 = ctx.r10.s64 + 24852;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830bac00
	goto loc_830BAC00;
loc_830BAC30:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r5,4532
	ctx.r5.s64 = 4532;
	// addi r6,r10,-22616
	ctx.r6.s64 = ctx.r10.s64 + -22616;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// b 0x830bac00
	goto loc_830BAC00;
}

__attribute__((alias("__imp__sub_830BAC58"))) PPC_WEAK_FUNC(sub_830BAC58);
PPC_FUNC_IMPL(__imp__sub_830BAC58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830baccc
	if (cr6.eq) goto loc_830BACCC;
	// lwz r5,548(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830baccc
	if (cr6.eq) goto loc_830BACCC;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830bac9c
	if (cr6.eq) goto loc_830BAC9C;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830bacdc
	goto loc_830BACDC;
loc_830BAC9C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ba7d0
	sub_830BA7D0(ctx, base);
	// lis r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r4,r4,65533
	ctx.r4.u64 = ctx.r4.u64 | 65533;
	// bl 0x83073378
	sub_83073378(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bacdc
	if (cr0.lt) goto loc_830BACDC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ab90
	sub_8306AB90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bacdc
	if (cr0.lt) goto loc_830BACDC;
loc_830BACCC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,552(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x830ba7d0
	sub_830BA7D0(ctx, base);
loc_830BACDC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BACF0"))) PPC_WEAK_FUNC(sub_830BACF0);
PPC_FUNC_IMPL(__imp__sub_830BACF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	// mflr r12
	// bl 0x82ca2bc8
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x830bad08
	if (!cr6.eq) goto loc_830BAD08;
loc_830BAD00:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830bafb4
	goto loc_830BAFB4;
loc_830BAD08:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm. r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bafb0
	if (cr0.eq) goto loc_830BAFB0;
	// lis r9,8304
	ctx.r9.s64 = 544210944;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x830bafb0
	if (cr6.eq) goto loc_830BAFB0;
	// lwz r9,4(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// clrlwi r10,r11,12
	ctx.r10.u64 = r11.u32 & 0xFFFFF;
	// divwu r22,r9,r10
	r22.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplwi cr6,r22,1
	cr6.compare<uint32_t>(r22.u32, 1, xer);
	// ble cr6,0x830bafb0
	if (!cr6.gt) goto loc_830BAFB0;
	// lwz r11,128(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	// addi r9,r1,-256
	ctx.r9.s64 = ctx.r1.s64 + -256;
	// lwz r8,136(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// addi r30,r1,-256
	r30.s64 = ctx.r1.s64 + -256;
	// lwz r6,124(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	// rlwinm r31,r11,2,0,29
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,148(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 148);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r28,r1,-256
	r28.s64 = ctx.r1.s64 + -256;
	// li r25,0
	r25.s64 = 0;
	// addi r7,r1,-176
	ctx.r7.s64 = ctx.r1.s64 + -176;
	// stwx r25,r31,r9
	PPC_STORE_U32(r31.u32 + ctx.r9.u32, r25.u32);
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r29,r1,-176
	r29.s64 = ctx.r1.s64 + -176;
	// stwx r25,r8,r30
	PPC_STORE_U32(ctx.r8.u32 + r30.u32, r25.u32);
	// li r11,2
	r11.s64 = 2;
	// stwx r25,r6,r28
	PPC_STORE_U32(ctx.r6.u32 + r28.u32, r25.u32);
	// addi r26,r1,-176
	r26.s64 = ctx.r1.s64 + -176;
	// addi r9,r1,-256
	ctx.r9.s64 = ctx.r1.s64 + -256;
	// stwx r11,r31,r7
	PPC_STORE_U32(r31.u32 + ctx.r7.u32, r11.u32);
	// addi r30,r1,-176
	r30.s64 = ctx.r1.s64 + -176;
	// li r28,3
	r28.s64 = 3;
	// li r7,1
	ctx.r7.s64 = 1;
	// stwx r28,r8,r29
	PPC_STORE_U32(ctx.r8.u32 + r29.u32, r28.u32);
	// mr r21,r25
	r21.u64 = r25.u64;
	// stwx r11,r6,r26
	PPC_STORE_U32(ctx.r6.u32 + r26.u32, r11.u32);
	// mr r29,r25
	r29.u64 = r25.u64;
	// stwx r25,r27,r9
	PPC_STORE_U32(r27.u32 + ctx.r9.u32, r25.u32);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// stwx r7,r27,r30
	PPC_STORE_U32(r27.u32 + r30.u32, ctx.r7.u32);
	// beq cr6,0x830bafb0
	if (cr6.eq) goto loc_830BAFB0;
	// lwz r23,8(r4)
	r23.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm r24,r10,2,0,29
	r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r27,20(r3)
	r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r26,16(r3)
	r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// mr r28,r23
	r28.u64 = r23.u64;
loc_830BADCC:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r27
	r31.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r6,r4,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r26,r6
	r30.u64 = PPC_LOAD_U32(r26.u32 + ctx.r6.u32);
	// beq cr6,0x830bae74
	if (cr6.eq) goto loc_830BAE74;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
loc_830BADF4:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r4,r8
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r8.u32, xer);
	// bne cr6,0x830bae64
	if (!cr6.eq) goto loc_830BAE64;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r20,8(r11)
	r20.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r10,r20
	cr6.compare<uint32_t>(ctx.r10.u32, r20.u32, xer);
	// bne cr6,0x830bae64
	if (!cr6.eq) goto loc_830BAE64;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r20,12(r11)
	r20.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r20
	cr6.compare<uint32_t>(ctx.r10.u32, r20.u32, xer);
	// bne cr6,0x830bae64
	if (!cr6.eq) goto loc_830BAE64;
	// lwz r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwzx r20,r10,r6
	r20.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r20,4(r20)
	r20.u64 = PPC_LOAD_U32(r20.u32 + 4);
	// rlwinm. r20,r20,0,23,23
	r20.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r20.s32, 0, xer);
	// beq 0x830bae74
	if (cr0.eq) goto loc_830BAE74;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bae74
	if (cr0.eq) goto loc_830BAE74;
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 32);
	// lfd f13,32(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x830bae74
	if (cr6.eq) goto loc_830BAE74;
loc_830BAE64:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// add r7,r24,r7
	ctx.r7.u64 = r24.u64 + ctx.r7.u64;
	// cmplw cr6,r9,r29
	cr6.compare<uint32_t>(ctx.r9.u32, r29.u32, xer);
	// blt cr6,0x830badf4
	if (cr6.lt) goto loc_830BADF4;
loc_830BAE74:
	// cmplw cr6,r9,r29
	cr6.compare<uint32_t>(ctx.r9.u32, r29.u32, xer);
	// bne cr6,0x830bafa0
	if (!cr6.eq) goto loc_830BAFA0;
	// lwz r11,128(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// bne cr6,0x830baebc
	if (!cr6.eq) goto loc_830BAEBC;
	// lbz r10,111(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 111);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x830baeec
	if (!cr6.eq) goto loc_830BAEEC;
	// lhz r11,202(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 202);
	// cmplwi cr6,r11,257
	cr6.compare<uint32_t>(r11.u32, 257, xer);
	// bne cr6,0x830baeb4
	if (!cr6.eq) goto loc_830BAEB4;
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// cmplwi cr6,r21,2
	cr6.compare<uint32_t>(r21.u32, 2, xer);
	// ble cr6,0x830baeb4
	if (!cr6.gt) goto loc_830BAEB4;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830bad00
	if (cr6.eq) goto loc_830BAD00;
loc_830BAEB4:
	// lwz r11,136(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// b 0x830baeec
	goto loc_830BAEEC;
loc_830BAEBC:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r10,r11,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830baed8
	if (cr0.eq) goto loc_830BAED8;
	// rlwinm. r10,r11,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830baed8
	if (!cr0.eq) goto loc_830BAED8;
	// lwz r11,124(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	// b 0x830baeec
	goto loc_830BAEEC;
loc_830BAED8:
	// rlwinm. r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830baee8
	if (cr0.eq) goto loc_830BAEE8;
	// lwz r11,148(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 148);
	// b 0x830baeec
	goto loc_830BAEEC;
loc_830BAEE8:
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
loc_830BAEEC:
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830baf74
	if (cr6.eq) goto loc_830BAF74;
	// lwz r9,136(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// cmplw cr6,r4,r9
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r9.u32, xer);
	// bne cr6,0x830baf74
	if (!cr6.eq) goto loc_830BAF74;
	// lhz r8,202(r3)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r3.u32 + 202);
	// cmplwi cr6,r8,257
	cr6.compare<uint32_t>(ctx.r8.u32, 257, xer);
	// bne cr6,0x830baf74
	if (!cr6.eq) goto loc_830BAF74;
	// lwz r11,24(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830baf70
	if (cr6.eq) goto loc_830BAF70;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lis r10,24816
	ctx.r10.s64 = 1626341376;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830baf5c
	if (cr6.eq) goto loc_830BAF5C;
	// lis r10,24656
	ctx.r10.s64 = 1615855616;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830baf5c
	if (cr6.eq) goto loc_830BAF5C;
	// lis r10,24736
	ctx.r10.s64 = 1621098496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830baf5c
	if (cr6.eq) goto loc_830BAF5C;
	// lis r10,24576
	ctx.r10.s64 = 1610612736;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830baf70
	if (!cr6.eq) goto loc_830BAF70;
loc_830BAF5C:
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// cmplwi cr6,r21,2
	cr6.compare<uint32_t>(r21.u32, 2, xer);
	// ble cr6,0x830baf70
	if (!cr6.gt) goto loc_830BAF70;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830bad00
	if (cr6.eq) goto loc_830BAD00;
loc_830BAF70:
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_830BAF74:
	// cmplwi cr6,r11,18
	cr6.compare<uint32_t>(r11.u32, 18, xer);
	// bge cr6,0x830bafa0
	if (!cr6.lt) goto loc_830BAFA0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-256
	ctx.r9.s64 = ctx.r1.s64 + -256;
	// addi r8,r1,-176
	ctx.r8.s64 = ctx.r1.s64 + -176;
	// lwzx r10,r11,r9
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bgt cr6,0x830bafb8
	if (cr6.gt) goto loc_830BAFB8;
loc_830BAFA0:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// add r28,r28,r24
	r28.u64 = r28.u64 + r24.u64;
	// cmplw cr6,r29,r22
	cr6.compare<uint32_t>(r29.u32, r22.u32, xer);
	// blt cr6,0x830badcc
	if (cr6.lt) goto loc_830BADCC;
loc_830BAFB0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BAFB4:
	// b 0x82ca2c18
	return;
loc_830BAFB8:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830bad00
	if (cr6.eq) goto loc_830BAD00;
	// stw r29,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r29.u32);
	// b 0x830bad00
	goto loc_830BAD00;
}

__attribute__((alias("__imp__sub_830BAFC8"))) PPC_WEAK_FUNC(sub_830BAFC8);
PPC_FUNC_IMPL(__imp__sub_830BAFC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2bb8
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x830bafe0
	if (!cr6.eq) goto loc_830BAFE0;
loc_830BAFD8:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830bb20c
	goto loc_830BB20C;
loc_830BAFE0:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm. r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bb208
	if (cr0.eq) goto loc_830BB208;
	// lwz r8,128(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	// addi r7,r1,-288
	ctx.r7.s64 = ctx.r1.s64 + -288;
	// lwz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// clrlwi r10,r11,12
	ctx.r10.u64 = r11.u32 & 0xFFFFF;
	// lwz r6,136(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// li r28,0
	r28.s64 = 0;
	// lwz r31,4(r4)
	r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// clrlwi r11,r9,12
	r11.u64 = ctx.r9.u32 & 0xFFFFF;
	// lwz r9,124(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r30,4(r5)
	r30.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// addi r26,r1,-288
	r26.s64 = ctx.r1.s64 + -288;
	// addi r29,r1,-208
	r29.s64 = ctx.r1.s64 + -208;
	// stwx r28,r8,r7
	PPC_STORE_U32(ctx.r8.u32 + ctx.r7.u32, r28.u32);
	// addi r24,r1,-208
	r24.s64 = ctx.r1.s64 + -208;
	// rlwinm r25,r9,2,0,29
	r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// divwu r27,r31,r10
	r27.u32 = r31.u32 / ctx.r10.u32;
	// addi r23,r1,-288
	r23.s64 = ctx.r1.s64 + -288;
	// stwx r28,r6,r26
	PPC_STORE_U32(ctx.r6.u32 + r26.u32, r28.u32);
	// addi r7,r1,-208
	ctx.r7.s64 = ctx.r1.s64 + -208;
	// divwu r9,r30,r11
	ctx.r9.u32 = r30.u32 / r11.u32;
	// li r31,2
	r31.s64 = 2;
	// li r30,5
	r30.s64 = 5;
	// li r26,3
	r26.s64 = 3;
	// stwx r31,r8,r29
	PPC_STORE_U32(ctx.r8.u32 + r29.u32, r31.u32);
	// stwx r30,r6,r24
	PPC_STORE_U32(ctx.r6.u32 + r24.u32, r30.u32);
	// twllei r10,0
	// twllei r11,0
	// stwx r28,r25,r23
	PPC_STORE_U32(r25.u32 + r23.u32, r28.u32);
	// add. r21,r9,r27
	r21.u64 = ctx.r9.u64 + r27.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// stwx r26,r25,r7
	PPC_STORE_U32(r25.u32 + ctx.r7.u32, r26.u32);
	// mr r19,r28
	r19.u64 = r28.u64;
	// mr r18,r28
	r18.u64 = r28.u64;
	// mr r30,r28
	r30.u64 = r28.u64;
	// beq 0x830bb208
	if (cr0.eq) goto loc_830BB208;
	// mullw r9,r11,r27
	ctx.r9.s64 = int64_t(r11.s32) * int64_t(r27.s32);
	// lwz r20,16(r3)
	r20.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// neg r9,r9
	ctx.r9.s64 = -ctx.r9.s64;
	// rlwinm r24,r10,2,0,29
	r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r22,r9,2,0,29
	r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r11,2,0,29
	r23.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r25,r28
	r25.u64 = r28.u64;
	// mr r26,r22
	r26.u64 = r22.u64;
loc_830BB09C:
	// lwz r7,20(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// cmplw cr6,r30,r27
	cr6.compare<uint32_t>(r30.u32, r27.u32, xer);
	// bge cr6,0x830bb0b4
	if (!cr6.lt) goto loc_830BB0B4;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwzx r11,r11,r25
	r11.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// b 0x830bb0bc
	goto loc_830BB0BC;
loc_830BB0B4:
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
loc_830BB0BC:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lwzx r31,r11,r7
	r31.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r11,r20
	r29.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// beq cr6,0x830bb148
	if (cr6.eq) goto loc_830BB148;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
loc_830BB0E4:
	// cmplw cr6,r10,r27
	cr6.compare<uint32_t>(ctx.r10.u32, r27.u32, xer);
	// bge cr6,0x830bb0f8
	if (!cr6.lt) goto loc_830BB0F8;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// b 0x830bb100
	goto loc_830BB100;
loc_830BB0F8:
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
loc_830BB100:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r17,4(r11)
	r17.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r6,r17
	cr6.compare<uint32_t>(ctx.r6.u32, r17.u32, xer);
	// bne cr6,0x830bb134
	if (!cr6.eq) goto loc_830BB134;
	// lwz r17,8(r31)
	r17.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r16,8(r11)
	r16.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r17,r16
	cr6.compare<uint32_t>(r17.u32, r16.u32, xer);
	// bne cr6,0x830bb134
	if (!cr6.eq) goto loc_830BB134;
	// lwz r17,12(r31)
	r17.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r17,r11
	cr6.compare<uint32_t>(r17.u32, r11.u32, xer);
	// beq cr6,0x830bb148
	if (cr6.eq) goto loc_830BB148;
loc_830BB134:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// add r9,r23,r9
	ctx.r9.u64 = r23.u64 + ctx.r9.u64;
	// add r8,r24,r8
	ctx.r8.u64 = r24.u64 + ctx.r8.u64;
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// blt cr6,0x830bb0e4
	if (cr6.lt) goto loc_830BB0E4;
loc_830BB148:
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x830bb1f4
	if (!cr6.eq) goto loc_830BB1F4;
	// lwz r10,136(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bb174
	if (!cr6.eq) goto loc_830BB174;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x830bb174
	if (!cr6.gt) goto loc_830BB174;
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// cmplwi cr6,r19,3
	cr6.compare<uint32_t>(r19.u32, 3, xer);
	// bgt cr6,0x830bafd8
	if (cr6.gt) goto loc_830BAFD8;
loc_830BB174:
	// lwz r11,128(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// bne cr6,0x830bb1ac
	if (!cr6.eq) goto loc_830BB1AC;
	// lbz r9,111(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 111);
	// cmplwi cr6,r9,3
	cr6.compare<uint32_t>(ctx.r9.u32, 3, xer);
	// bne cr6,0x830bb1d0
	if (!cr6.eq) goto loc_830BB1D0;
	// lhz r11,202(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 202);
	// cmplwi cr6,r11,257
	cr6.compare<uint32_t>(r11.u32, 257, xer);
	// bne cr6,0x830bb1a4
	if (!cr6.eq) goto loc_830BB1A4;
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// cmplwi cr6,r19,3
	cr6.compare<uint32_t>(r19.u32, 3, xer);
	// bgt cr6,0x830bafd8
	if (cr6.gt) goto loc_830BAFD8;
loc_830BB1A4:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// b 0x830bb1d0
	goto loc_830BB1D0;
loc_830BB1AC:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwinm. r10,r11,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830bb208
	if (!cr0.eq) goto loc_830BB208;
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830bb1cc
	if (cr0.eq) goto loc_830BB1CC;
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// cmplwi cr6,r18,3
	cr6.compare<uint32_t>(r18.u32, 3, xer);
	// b 0x830bb1f0
	goto loc_830BB1F0;
loc_830BB1CC:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
loc_830BB1D0:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-288
	ctx.r9.s64 = ctx.r1.s64 + -288;
	// addi r8,r1,-208
	ctx.r8.s64 = ctx.r1.s64 + -208;
	// lwzx r10,r11,r9
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
loc_830BB1F0:
	// bgt cr6,0x830bafd8
	if (cr6.gt) goto loc_830BAFD8;
loc_830BB1F4:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// add r26,r26,r23
	r26.u64 = r26.u64 + r23.u64;
	// add r25,r24,r25
	r25.u64 = r24.u64 + r25.u64;
	// cmplw cr6,r30,r21
	cr6.compare<uint32_t>(r30.u32, r21.u32, xer);
	// blt cr6,0x830bb09c
	if (cr6.lt) goto loc_830BB09C;
loc_830BB208:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BB20C:
	// b 0x82ca2c08
	return;
}

__attribute__((alias("__imp__sub_830BB210"))) PPC_WEAK_FUNC(sub_830BB210);
PPC_FUNC_IMPL(__imp__sub_830BB210) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x830b8160
	sub_830B8160(ctx, base);
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830bb244
	if (cr0.eq) goto loc_830BB244;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
loc_830BB244:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BB260"))) PPC_WEAK_FUNC(sub_830BB260);
PPC_FUNC_IMPL(__imp__sub_830BB260) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stfd f31,-104(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -104, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r11,936
	ctx.r4.s64 = r11.s64 + 936;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,785
	ctx.r5.s64 = 785;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8307a8d8
	sub_8307A8D8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// stw r3,1092(r31)
	PPC_STORE_U32(r31.u32 + 1092, ctx.r3.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfd f1,3248(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 3248);
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// li r21,0
	r21.s64 = 0;
	// stw r3,1096(r31)
	PPC_STORE_U32(r31.u32 + 1096, ctx.r3.u32);
	// lis r25,24688
	r25.s64 = 1617952768;
	// stw r21,1104(r31)
	PPC_STORE_U32(r31.u32 + 1104, r21.u32);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// bne cr6,0x830bb354
	if (!cr6.eq) goto loc_830BB354;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r21
	r29.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb344
	if (!cr6.gt) goto loc_830BB344;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_830BB300:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x830bb330
	if (!cr6.eq) goto loc_830BB330;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ad0c8
	sub_830AD0C8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
loc_830BB330:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830bb300
	if (cr6.lt) goto loc_830BB300;
loc_830BB344:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084778
	sub_83084778(ctx, base);
loc_830BB354:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r30,r21
	r30.u64 = r21.u64;
	// mr r26,r21
	r26.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb4a8
	if (!cr6.gt) goto loc_830BB4A8;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r28,r21
	r28.u64 = r21.u64;
	// addi r27,r11,-22616
	r27.s64 = r11.s64 + -22616;
	// addi r29,r10,32328
	r29.s64 = ctx.r10.s64 + 32328;
loc_830BB37C:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830bb438
	if (!cr6.gt) goto loc_830BB438;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_830BB3A4:
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r4,r9,0,27,27
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x830bb400
	if (cr0.eq) goto loc_830BB400;
	// rlwinm. r9,r9,0,22,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830bb400
	if (!cr0.eq) goto loc_830BB400;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplwi cr6,r9,3
	cr6.compare<uint32_t>(ctx.r9.u32, 3, xer);
	// bne cr6,0x830bb400
	if (!cr6.eq) goto loc_830BB400;
	// lbz r10,111(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 111);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x830bb400
	if (!cr6.eq) goto loc_830BB400;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r25
	cr6.compare<uint32_t>(ctx.r10.u32, r25.u32, xer);
	// bne cr6,0x830bb41c
	if (!cr6.eq) goto loc_830BB41C;
	// cmplwi cr6,r5,7
	cr6.compare<uint32_t>(ctx.r5.u32, 7, xer);
	// bne cr6,0x830bb41c
	if (!cr6.eq) goto loc_830BB41C;
loc_830BB400:
	// lwz r10,260(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// blt cr6,0x830bb3a4
	if (cr6.lt) goto loc_830BB3A4;
	// b 0x830bb438
	goto loc_830BB438;
loc_830BB41C:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lbz r7,203(r31)
	ctx.r7.u64 = PPC_LOAD_U8(r31.u32 + 203);
	// li r5,4512
	ctx.r5.s64 = 4512;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r30,1
	r30.s64 = 1;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830BB438:
	// lwz r10,260(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lis r9,24672
	ctx.r9.s64 = 1616904192;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830bb474
	if (cr6.eq) goto loc_830BB474;
	// lis r9,24752
	ctx.r9.s64 = 1622147072;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830bb474
	if (cr6.eq) goto loc_830BB474;
	// lis r9,24592
	ctx.r9.s64 = 1611661312;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830bb474
	if (cr6.eq) goto loc_830BB474;
	// lis r9,24832
	ctx.r9.s64 = 1627389952;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x830bb48c
	if (!cr6.eq) goto loc_830BB48C;
loc_830BB474:
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// lwz r4,60(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// li r5,4532
	ctx.r5.s64 = 4532;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r30,1
	r30.s64 = 1;
loc_830BB48C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x830bb37c
	if (cr6.lt) goto loc_830BB37C;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x830bbebc
	if (!cr6.eq) goto loc_830BBEBC;
loc_830BB4A8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r25,-1
	r25.s64 = -1;
	// li r7,20
	ctx.r7.s64 = 20;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb530
	if (!cr6.gt) goto loc_830BB530;
	// mr r11,r21
	r11.u64 = r21.u64;
loc_830BB4C4:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r25,56(r10)
	PPC_STORE_U32(ctx.r10.u32 + 56, r25.u32);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r8,128(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r6,r8
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, xer);
	// bne cr6,0x830bb51c
	if (!cr6.eq) goto loc_830BB51C;
	// lbz r8,111(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 111);
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// bne cr6,0x830bb4f8
	if (!cr6.eq) goto loc_830BB4F8;
	// stw r7,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r7.u32);
loc_830BB4F8:
	// lhz r10,202(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r10,260
	cr6.compare<uint32_t>(ctx.r10.u32, 260, xer);
	// bge cr6,0x830bb51c
	if (!cr6.lt) goto loc_830BB51C;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lbz r8,111(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 111);
	// cmplwi cr6,r8,3
	cr6.compare<uint32_t>(ctx.r8.u32, 3, xer);
	// bne cr6,0x830bb51c
	if (!cr6.eq) goto loc_830BB51C;
	// stw r7,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r7.u32);
loc_830BB51C:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// blt cr6,0x830bb4c4
	if (cr6.lt) goto loc_830BB4C4;
loc_830BB530:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// lis r22,24816
	r22.s64 = 1626341376;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb5f0
	if (!cr6.gt) goto loc_830BB5F0;
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
loc_830BB548:
	// stw r9,256(r31)
	PPC_STORE_U32(r31.u32 + 256, ctx.r9.u32);
	// lis r6,24576
	ctx.r6.s64 = 1610612736;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x830bb58c
	if (cr6.eq) goto loc_830BB58C;
	// lis r6,24656
	ctx.r6.s64 = 1615855616;
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x830bb58c
	if (cr6.eq) goto loc_830BB58C;
	// lis r6,24736
	ctx.r6.s64 = 1621098496;
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x830bb58c
	if (cr6.eq) goto loc_830BB58C;
	// cmplw cr6,r10,r22
	cr6.compare<uint32_t>(ctx.r10.u32, r22.u32, xer);
	// bne cr6,0x830bb5d4
	if (!cr6.eq) goto loc_830BB5D4;
loc_830BB58C:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb5d4
	if (!cr6.gt) goto loc_830BB5D4;
	// mr r11,r21
	r11.u64 = r21.u64;
loc_830BB5A0:
	// lwz r6,260(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r6,16(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// lwzx r6,r6,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r5
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// stw r7,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r7.u32);
	// lwz r6,260(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r6,12(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// blt cr6,0x830bb5a0
	if (cr6.lt) goto loc_830BB5A0;
loc_830BB5D4:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// stw r21,36(r11)
	PPC_STORE_U32(r11.u32 + 36, r21.u32);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x830bb548
	if (cr6.lt) goto loc_830BB548;
loc_830BB5F0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r21
	r29.u64 = r21.u64;
	// lis r27,12288
	r27.s64 = 805306368;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb668
	if (!cr6.gt) goto loc_830BB668;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_830BB608:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lis r10,8192
	ctx.r10.s64 = 536870912;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bb640
	if (cr6.eq) goto loc_830BB640;
	// lis r10,8208
	ctx.r10.s64 = 537919488;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bb640
	if (cr6.eq) goto loc_830BB640;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x830bb654
	if (!cr6.eq) goto loc_830BB654;
loc_830BB640:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306c5b0
	sub_8306C5B0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x830bc010
	if (cr6.lt) goto loc_830BC010;
loc_830BB654:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830bb608
	if (cr6.lt) goto loc_830BB608;
loc_830BB668:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r21
	r29.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb6c0
	if (!cr6.gt) goto loc_830BB6C0;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_830BB67C:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x830bb6ac
	if (!cr6.eq) goto loc_830BB6AC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830afe98
	sub_830AFE98(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
loc_830BB6AC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830bb67c
	if (cr6.lt) goto loc_830BB67C;
loc_830BB6C0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r21
	r29.u64 = r21.u64;
	// lis r27,4112
	r27.s64 = 269484032;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb738
	if (!cr6.gt) goto loc_830BB738;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_830BB6D8:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bb710
	if (cr6.eq) goto loc_830BB710;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x830bb724
	if (!cr6.eq) goto loc_830BB724;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ad7c8
	sub_830AD7C8(ctx, base);
	// b 0x830bb718
	goto loc_830BB718;
loc_830BB710:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ad660
	sub_830AD660(ctx, base);
loc_830BB718:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x830bc010
	if (cr6.lt) goto loc_830BC010;
loc_830BB724:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830bb6d8
	if (cr6.lt) goto loc_830BB6D8;
loc_830BB738:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r21
	r29.u64 = r21.u64;
	// lis r26,8256
	r26.s64 = 541065216;
	// lis r23,8272
	r23.s64 = 542113792;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb80c
	if (!cr6.gt) goto loc_830BB80C;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_830BB75C:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// beq cr6,0x830bb7d8
	if (cr6.eq) goto loc_830BB7D8;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// beq cr6,0x830bb7b0
	if (cr6.eq) goto loc_830BB7B0;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// beq cr6,0x830bb7a4
	if (cr6.eq) goto loc_830BB7A4;
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bb7f8
	if (!cr6.eq) goto loc_830BB7F8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83063678
	sub_83063678(ctx, base);
	// b 0x830bb7ec
	goto loc_830BB7EC;
loc_830BB7A4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ff70
	sub_8306FF70(ctx, base);
	// b 0x830bb7e4
	goto loc_830BB7E4;
loc_830BB7B0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830703d8
	sub_830703D8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306fbc0
	sub_8306FBC0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83070110
	sub_83070110(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ff70
	sub_8306FF70(ctx, base);
	// b 0x830bb7ec
	goto loc_830BB7EC;
loc_830BB7D8:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306fa98
	sub_8306FA98(ctx, base);
loc_830BB7E4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830702f8
	sub_830702F8(ctx, base);
loc_830BB7EC:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x830bc010
	if (cr6.lt) goto loc_830BC010;
loc_830BB7F8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830bb75c
	if (cr6.lt) goto loc_830BB75C;
loc_830BB80C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r21
	r29.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb878
	if (!cr6.gt) goto loc_830BB878;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_830BB828:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// beq cr6,0x830bb850
	if (cr6.eq) goto loc_830BB850;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// bne cr6,0x830bb864
	if (!cr6.eq) goto loc_830BB864;
loc_830BB850:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b8fe0
	sub_830B8FE0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x830bc010
	if (cr6.lt) goto loc_830BC010;
loc_830BB864:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830bb828
	if (cr6.lt) goto loc_830BB828;
loc_830BB878:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r21
	r29.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb8f0
	if (!cr6.gt) goto loc_830BB8F0;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_830BB894:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// bne cr6,0x830bb8dc
	if (!cr6.eq) goto loc_830BB8DC;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830af688
	sub_830AF688(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830af688
	sub_830AF688(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
loc_830BB8DC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830bb894
	if (cr6.lt) goto loc_830BB894;
loc_830BB8F0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r21
	r29.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb950
	if (!cr6.gt) goto loc_830BB950;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_830BB90C:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bne cr6,0x830bb93c
	if (!cr6.eq) goto loc_830BB93C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b0288
	sub_830B0288(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
loc_830BB93C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830bb90c
	if (cr6.lt) goto loc_830BB90C;
loc_830BB950:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r21
	r29.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bb9d8
	if (!cr6.gt) goto loc_830BB9D8;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_830BB96C:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// beq cr6,0x830bb9b0
	if (cr6.eq) goto loc_830BB9B0;
	// lis r10,28720
	ctx.r10.s64 = 1882193920;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bb9c4
	if (!cr6.eq) goto loc_830BB9C4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306da58
	sub_8306DA58(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83067818
	sub_83067818(ctx, base);
	// b 0x830bb9b8
	goto loc_830BB9B8;
loc_830BB9B0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83066318
	sub_83066318(ctx, base);
loc_830BB9B8:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x830bc010
	if (cr6.lt) goto loc_830BC010;
loc_830BB9C4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830bb96c
	if (cr6.lt) goto loc_830BB96C;
loc_830BB9D8:
	// lwz r27,12(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r21
	r29.u64 = r21.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830bba1c
	if (cr6.eq) goto loc_830BBA1C;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_830BB9EC:
	// stw r29,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r29.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// bl 0x830aef80
	sub_830AEF80(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r27
	cr6.compare<uint32_t>(r29.u32, r27.u32, xer);
	// blt cr6,0x830bb9ec
	if (cr6.lt) goto loc_830BB9EC;
loc_830BBA1C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306e0a8
	sub_8306E0A8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830afbc8
	sub_830AFBC8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830adf70
	sub_830ADF70(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// lwz r11,200(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// clrlwi r10,r11,16
	ctx.r10.u64 = r11.u32 & 0xFFFF;
	// cmplwi cr6,r10,260
	cr6.compare<uint32_t>(ctx.r10.u32, 260, xer);
	// bne cr6,0x830bbe94
	if (!cr6.eq) goto loc_830BBE94;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,2048
	ctx.r3.s64 = 2048;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,560(r31)
	PPC_STORE_U32(r31.u32 + 560, ctx.r3.u32);
	// bne 0x830bba88
	if (!cr0.eq) goto loc_830BBA88;
loc_830BBA7C:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830bc014
	goto loc_830BC014;
loc_830BBA88:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,2048
	ctx.r3.s64 = 2048;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,564(r31)
	PPC_STORE_U32(r31.u32 + 564, ctx.r3.u32);
	// beq 0x830bba7c
	if (cr0.eq) goto loc_830BBA7C;
	// li r5,2048
	ctx.r5.s64 = 2048;
	// lwz r3,560(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r21,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r21.u32);
	// stw r21,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r21.u32);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b1920
	sub_830B1920(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b1f90
	sub_830B1F90(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b21e0
	sub_830B21E0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830bbebc
	if (!cr0.eq) goto loc_830BBEBC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2070
	sub_830B2070(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmpwi cr6,r23,-1
	cr6.compare<int32_t>(r23.s32, -1, xer);
	// bne cr6,0x830bbb1c
	if (!cr6.eq) goto loc_830BBB1C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,32264
	ctx.r6.s64 = r11.s64 + 32264;
	// b 0x830bbde8
	goto loc_830BBDE8;
loc_830BBB1C:
	// bl 0x830b9dc0
	sub_830B9DC0(ctx, base);
	// mr r29,r21
	r29.u64 = r21.u64;
	// addi r30,r31,776
	r30.s64 = r31.s64 + 776;
loc_830BBB28:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307a978
	sub_8307A978(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830bbe00
	if (cr6.eq) goto loc_830BBE00;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r29,64
	cr6.compare<uint32_t>(r29.u32, 64, xer);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r21,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r21.u32);
	// blt cr6,0x830bbb28
	if (cr6.lt) goto loc_830BBB28;
	// addi r27,r31,712
	r27.s64 = r31.s64 + 712;
	// li r5,64
	ctx.r5.s64 = 64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// mr r24,r25
	r24.u64 = r25.u64;
	// mr r26,r21
	r26.u64 = r21.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830bbd78
	if (cr6.eq) goto loc_830BBD78;
loc_830BBB90:
	// li r5,2048
	ctx.r5.s64 = 2048;
	// lwz r3,560(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// stw r21,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r21.u32);
	// stw r21,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r21.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2580
	sub_830B2580(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830bbd6c
	if (cr0.eq) goto loc_830BBD6C;
	// stw r21,1036(r31)
	PPC_STORE_U32(r31.u32 + 1036, r21.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r21,1032(r31)
	PPC_STORE_U32(r31.u32 + 1032, r21.u32);
	// bl 0x830b1850
	sub_830B1850(ctx, base);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r5,6
	ctx.r5.s64 = 6;
	// lwz r6,548(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// bl 0x830b7b88
	sub_830B7B88(ctx, base);
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// li r5,6
	ctx.r5.s64 = 6;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x830b7b88
	sub_830B7B88(ctx, base);
	// mr r30,r27
	r30.u64 = r27.u64;
	// li r29,16
	r29.s64 = 16;
loc_830BBC18:
	// lwz r28,0(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830bbc34
	if (cr6.eq) goto loc_830BBC34;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830BBC34:
	// stw r21,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r21.u32);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x830bbc18
	if (!cr0.eq) goto loc_830BBC18;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b9f20
	sub_830B9F20(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// beq cr6,0x830bbd6c
	if (cr6.eq) goto loc_830BBD6C;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2a30
	sub_830B2A30(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bbd6c
	if (cr0.lt) goto loc_830BBD6C;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b4930
	sub_830B4930(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bbd6c
	if (cr0.lt) goto loc_830BBD6C;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// lwz r6,548(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// li r5,6
	ctx.r5.s64 = 6;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b7b88
	sub_830B7B88(ctx, base);
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// li r5,6
	ctx.r5.s64 = 6;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x830b7b88
	sub_830B7B88(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r9,560(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// li r10,6
	ctx.r10.s64 = 6;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
loc_830BBCD0:
	// lwzx r6,r9,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830bbce0
	if (cr6.eq) goto loc_830BBCE0;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
loc_830BBCE0:
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x830bbcf0
	if (cr6.eq) goto loc_830BBCF0;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
loc_830BBCF0:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830bbcd0
	if (!cr0.eq) goto loc_830BBCD0;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r10,r8,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// bgt cr6,0x830bbd14
	if (cr6.gt) goto loc_830BBD14;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
loc_830BBD14:
	// rlwinm r10,r7,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// ble cr6,0x830bbd28
	if (!cr6.gt) goto loc_830BBD28;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
loc_830BBD28:
	// add r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 + r11.u64;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// subfic r11,r8,0
	xer.ca = ctx.r8.u32 <= 0;
	r11.s64 = 0 - ctx.r8.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// andi. r11,r11,10
	r11.u64 = r11.u64 & 10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// ble cr6,0x830bbd4c
	if (!cr6.gt) goto loc_830BBD4C;
	// addi r11,r11,20
	r11.s64 = r11.s64 + 20;
loc_830BBD4C:
	// cmplwi cr6,r7,8
	cr6.compare<uint32_t>(ctx.r7.u32, 8, xer);
	// ble cr6,0x830bbd58
	if (!cr6.gt) goto loc_830BBD58;
	// addi r11,r11,20
	r11.s64 = r11.s64 + 20;
loc_830BBD58:
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bge cr6,0x830bbd68
	if (!cr6.lt) goto loc_830BBD68;
	// mr r24,r26
	r24.u64 = r26.u64;
	// mr r25,r11
	r25.u64 = r11.u64;
loc_830BBD68:
	// stw r21,1032(r31)
	PPC_STORE_U32(r31.u32 + 1032, r21.u32);
loc_830BBD6C:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmplw cr6,r26,r23
	cr6.compare<uint32_t>(r26.u32, r23.u32, xer);
	// blt cr6,0x830bbb90
	if (cr6.lt) goto loc_830BBB90;
loc_830BBD78:
	// li r5,2048
	ctx.r5.s64 = 2048;
	// lwz r3,560(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// stw r21,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r21.u32);
	// mr r30,r27
	r30.u64 = r27.u64;
	// stw r21,552(r31)
	PPC_STORE_U32(r31.u32 + 552, r21.u32);
	// li r29,12
	r29.s64 = 12;
loc_830BBDA8:
	// lwz r28,0(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830bbdc4
	if (cr6.eq) goto loc_830BBDC4;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830BBDC4:
	// stw r21,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r21.u32);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x830bbda8
	if (!cr0.eq) goto loc_830BBDA8;
	// cmpwi cr6,r24,-1
	cr6.compare<int32_t>(r24.s32, -1, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x830bbe0c
	if (!cr6.eq) goto loc_830BBE0C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,32220
	ctx.r6.s64 = r11.s64 + 32220;
loc_830BBDE8:
	// lis r30,-32768
	r30.s64 = -2147483648;
	// li r5,4500
	ctx.r5.s64 = 4500;
	// li r4,0
	ctx.r4.s64 = 0;
	// ori r30,r30,16389
	r30.u64 = r30.u64 | 16389;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// b 0x830bc010
	goto loc_830BC010;
loc_830BBE00:
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
	// b 0x830bc010
	goto loc_830BC010;
loc_830BBE0C:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x830b2580
	sub_830B2580(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b1850
	sub_830B1850(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b9f20
	sub_830B9F20(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b2a30
	sub_830B2A30(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b4930
	sub_830B4930(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r11,r21
	r11.u64 = r21.u64;
loc_830BBE5C:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x830bbe78
	if (!cr6.eq) goto loc_830BBE78;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// blt cr6,0x830bbe5c
	if (cr6.lt) goto loc_830BBE5C;
loc_830BBE78:
	// lwz r10,548(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// bne cr6,0x830bbf7c
	if (!cr6.eq) goto loc_830BBF7C;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x830bbf7c
	if (!cr6.eq) goto loc_830BBF7C;
	// stw r21,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r21.u32);
	// b 0x830bbf7c
	goto loc_830BBF7C;
loc_830BBE94:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r10,128
	cr6.compare<uint32_t>(ctx.r10.u32, 128, xer);
	// ble cr6,0x830bbec8
	if (!cr6.gt) goto loc_830BBEC8;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// clrlwi r7,r11,24
	ctx.r7.u64 = r11.u32 & 0xFF;
	// addi r6,r10,32156
	ctx.r6.s64 = ctx.r10.s64 + 32156;
	// li r5,4500
	ctx.r5.s64 = 4500;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830BBEBC:
	// lis r30,-32768
	r30.s64 = -2147483648;
	// ori r30,r30,16389
	r30.u64 = r30.u64 | 16389;
	// b 0x830bc010
	goto loc_830BC010;
loc_830BBEC8:
	// bl 0x830b96e8
	sub_830B96E8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bbef0
	if (cr6.eq) goto loc_830BBEF0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830add38
	sub_830ADD38(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
loc_830BBEF0:
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bbf18
	if (cr6.eq) goto loc_830BBF18;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830bbf18
	if (cr6.eq) goto loc_830BBF18;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ba4c8
	sub_830BA4C8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
loc_830BBF18:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bbf60
	if (cr6.eq) goto loc_830BBF60;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830bbf60
	if (cr6.eq) goto loc_830BBF60;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ae310
	sub_830AE310(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b8438
	sub_830B8438(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ae8d0
	sub_830AE8D0(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
loc_830BBF60:
	// stw r21,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r21.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b4930
	sub_830B4930(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
loc_830BBF7C:
	// li r11,1
	r11.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r11.u32);
	// bl 0x830b3b38
	sub_830B3B38(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r6,548(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b7b88
	sub_830B7B88(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r6,552(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 552);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830b7b88
	sub_830B7B88(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830ada28
	sub_830ADA28(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bc00c
	if (cr6.eq) goto loc_830BC00C;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// beq cr6,0x830bc00c
	if (cr6.eq) goto loc_830BC00C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830acfb0
	sub_830ACFB0(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x830bc010
	if (cr0.lt) goto loc_830BC010;
loc_830BC00C:
	// mr r30,r21
	r30.u64 = r21.u64;
loc_830BC010:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_830BC014:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-104(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x82ca2c1c
	return;
}

__attribute__((alias("__imp__sub_830BC020"))) PPC_WEAK_FUNC(sub_830BC020);
PPC_FUNC_IMPL(__imp__sub_830BC020) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// li r20,0
	r20.s64 = 0;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r21,r5
	r21.u64 = ctx.r5.u64;
	// lwz r11,104(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 104);
	// mr r30,r20
	r30.u64 = r20.u64;
	// mr r24,r20
	r24.u64 = r20.u64;
	// mr r28,r20
	r28.u64 = r20.u64;
	// li r10,32
	ctx.r10.s64 = 32;
	// lwz r23,24(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// subf r9,r9,r23
	ctx.r9.s64 = r23.s64 - ctx.r9.s64;
loc_830BC060:
	// lbzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + r11.u32);
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x830bc07c
	if (cr0.eq) goto loc_830BC07C;
	// stb r8,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r8.u8);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne 0x830bc060
	if (!cr0.eq) goto loc_830BC060;
loc_830BC07C:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830bc088
	if (!cr6.eq) goto loc_830BC088;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
loc_830BC088:
	// stb r20,0(r11)
	PPC_STORE_U8(r11.u32 + 0, r20.u8);
	// addi r31,r1,80
	r31.s64 = ctx.r1.s64 + 80;
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x830bc0c0
	if (cr0.eq) goto loc_830BC0C0;
loc_830BC09C:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x82ca6ab0
	sub_82CA6AB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830bc0c0
	if (cr0.eq) goto loc_830BC0C0;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830bc09c
	if (!cr6.eq) goto loc_830BC09C;
loc_830BC0C0:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bc0dc
	if (cr6.eq) goto loc_830BC0DC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82ca3b30
	sub_82CA3B30(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x830bc0e0
	goto loc_830BC0E0;
loc_830BC0DC:
	// mr r29,r20
	r29.u64 = r20.u64;
loc_830BC0E0:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bc104
	if (cr6.eq) goto loc_830BC104;
	// stb r20,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r20.u8);
	// b 0x830bc100
	goto loc_830BC100;
loc_830BC0F4:
	// bl 0x82ca6b10
	sub_82CA6B10(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830bc110
	if (cr0.eq) goto loc_830BC110;
loc_830BC100:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_830BC104:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb. r3,r11
	ctx.r3.s64 = r11.s8;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830bc0f4
	if (!cr0.eq) goto loc_830BC0F4;
loc_830BC110:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// li r22,-1
	r22.s64 = -1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bc128
	if (cr6.eq) goto loc_830BC128;
	// mr r31,r22
	r31.u64 = r22.u64;
	// b 0x830bc134
	goto loc_830BC134;
loc_830BC128:
	// lwz r11,112(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 112);
	// rlwinm r11,r11,30,2,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	// add r31,r11,r29
	r31.u64 = r11.u64 + r29.u64;
loc_830BC134:
	// lwz r11,108(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// li r29,1
	r29.s64 = 1;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830bc17c
	if (cr6.eq) goto loc_830BC17C;
	// clrlwi r28,r11,24
	r28.u64 = r11.u32 & 0xFF;
	// lbz r31,110(r26)
	r31.u64 = PPC_LOAD_U8(r26.u32 + 110);
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// bne cr6,0x830bc480
	if (!cr6.eq) goto loc_830BC480;
	// lwz r11,1100(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 1100);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830bc584
	if (!cr6.eq) goto loc_830BC584;
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// bne cr6,0x830bc584
	if (!cr6.eq) goto loc_830BC584;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// addi r6,r11,32680
	ctx.r6.s64 = r11.s64 + 32680;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// b 0x830bc398
	goto loc_830BC398;
loc_830BC17C:
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x8307a548
	sub_8307A548(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bc3b4
	if (cr0.eq) goto loc_830BC3B4;
	// rlwinm. r10,r11,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830bc3b4
	if (!cr0.eq) goto loc_830BC3B4;
	// lis r11,-32240
	r11.s64 = -2112880640;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-3060
	ctx.r4.s64 = r11.s64 + -3060;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830bc1e0
	if (!cr0.eq) goto loc_830BC1E0;
	// mr r28,r29
	r28.u64 = r29.u64;
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// li r11,2
	r11.s64 = 2;
	// bne cr6,0x830bc20c
	if (!cr6.eq) goto loc_830BC20C;
	// lwz r11,40(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 40);
	// b 0x830bc20c
	goto loc_830BC20C;
loc_830BC1E0:
	// lis r11,-32240
	r11.s64 = -2112880640;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-3008
	ctx.r4.s64 = r11.s64 + -3008;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830bc214
	if (!cr0.eq) goto loc_830BC214;
	// li r28,3
	r28.s64 = 3;
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// li r11,8
	r11.s64 = 8;
	// bne cr6,0x830bc20c
	if (!cr6.eq) goto loc_830BC20C;
	// lwz r11,60(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 60);
loc_830BC20C:
	// subfc r11,r11,r31
	xer.ca = r31.u32 >= r11.u32;
	r11.s64 = r31.s64 - r11.s64;
	// b 0x830bc264
	goto loc_830BC264;
loc_830BC214:
	// lis r11,-32243
	r11.s64 = -2113077248;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-25032
	ctx.r4.s64 = r11.s64 + -25032;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830bc25c
	if (cr0.eq) goto loc_830BC25C;
	// lis r11,-32240
	r11.s64 = -2112880640;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-3064
	ctx.r4.s64 = r11.s64 + -3064;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830bc25c
	if (cr0.eq) goto loc_830BC25C;
	// lis r11,-32240
	r11.s64 = -2112880640;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-2996
	ctx.r4.s64 = r11.s64 + -2996;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830bc270
	if (!cr0.eq) goto loc_830BC270;
loc_830BC25C:
	// subfc r11,r29,r31
	xer.ca = r31.u32 >= r29.u32;
	r11.s64 = r31.s64 - r29.s64;
	// li r28,4
	r28.s64 = 4;
loc_830BC264:
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
	// b 0x830bc2e8
	goto loc_830BC2E8;
loc_830BC270:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,29840
	ctx.r4.s64 = r11.s64 + 29840;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830bc2a8
	if (!cr0.eq) goto loc_830BC2A8;
	// subfc r11,r29,r31
	xer.ca = r31.u32 >= r29.u32;
	r11.s64 = r31.s64 - r29.s64;
	// mr r28,r29
	r28.u64 = r29.u64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// mr r24,r29
	r24.u64 = r29.u64;
	// addic. r30,r11,1
	xer.ca = r11.u32 > 4294967294;
	r30.s64 = r11.s64 + 1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x830bc2e8
	if (!cr0.eq) goto loc_830BC2E8;
	// mr r31,r20
	r31.u64 = r20.u64;
	// b 0x830bc2e8
	goto loc_830BC2E8;
loc_830BC2A8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,32668
	ctx.r4.s64 = r11.s64 + 32668;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830bc2e0
	if (!cr0.eq) goto loc_830BC2E0;
	// subfc r11,r29,r31
	xer.ca = r31.u32 >= r29.u32;
	r11.s64 = r31.s64 - r29.s64;
	// mr r28,r29
	r28.u64 = r29.u64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// mr r24,r29
	r24.u64 = r29.u64;
	// addic. r30,r11,1
	xer.ca = r11.u32 > 4294967294;
	r30.s64 = r11.s64 + 1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x830bc2e8
	if (!cr0.eq) goto loc_830BC2E8;
	// mr r31,r29
	r31.u64 = r29.u64;
	// b 0x830bc2e8
	goto loc_830BC2E8;
loc_830BC2E0:
	// mr r28,r20
	r28.u64 = r20.u64;
	// mr r30,r29
	r30.u64 = r29.u64;
loc_830BC2E8:
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// beq cr6,0x830bc2fc
	if (cr6.eq) goto loc_830BC2FC;
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830bc364
	if (!cr6.eq) goto loc_830BC364;
loc_830BC2FC:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x830bc328
	if (cr6.eq) goto loc_830BC328;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,104(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 104);
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// addi r6,r11,32640
	ctx.r6.s64 = r11.s64 + 32640;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// li r5,4502
	ctx.r5.s64 = 4502;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// b 0x830bc364
	goto loc_830BC364;
loc_830BC328:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x830bc364
	if (cr6.eq) goto loc_830BC364;
	// lis r11,-31952
	r11.s64 = -2094006272;
	// lwz r4,104(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 104);
	// lis r8,-32249
	ctx.r8.s64 = -2113470464;
	// addi r11,r11,3984
	r11.s64 = r11.s64 + 3984;
	// rlwinm r9,r28,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r8,32580
	ctx.r6.s64 = ctx.r8.s64 + 32580;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// li r5,4705
	ctx.r5.s64 = 4705;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8308bee8
	sub_8308BEE8(ctx, base);
loc_830BC364:
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// beq cr6,0x830bc374
	if (cr6.eq) goto loc_830BC374;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x830bc480
	if (cr6.eq) goto loc_830BC480;
loc_830BC374:
	// lwz r11,1100(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 1100);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830bc480
	if (!cr6.eq) goto loc_830BC480;
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// bne cr6,0x830bc480
	if (!cr6.eq) goto loc_830BC480;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// addi r6,r11,32540
	ctx.r6.s64 = r11.s64 + 32540;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
loc_830BC398:
	// stw r29,1100(r27)
	PPC_STORE_U32(r27.u32 + 1100, r29.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// li r5,4502
	ctx.r5.s64 = 4502;
	// lwz r4,104(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 104);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// mr r30,r29
	r30.u64 = r29.u64;
	// b 0x830bc480
	goto loc_830BC480;
loc_830BC3B4:
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830bc580
	if (cr0.eq) goto loc_830BC580;
	// lis r11,-32240
	r11.s64 = -2112880640;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-3060
	ctx.r4.s64 = r11.s64 + -3060;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830bc3ec
	if (!cr0.eq) goto loc_830BC3EC;
	// lwz r11,72(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 72);
	// mr r28,r29
	r28.u64 = r29.u64;
	// subfc r11,r11,r31
	xer.ca = r31.u32 >= r11.u32;
	r11.s64 = r31.s64 - r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
	// b 0x830bc414
	goto loc_830BC414;
loc_830BC3EC:
	// lis r11,-32240
	r11.s64 = -2112880640;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-3072
	ctx.r4.s64 = r11.s64 + -3072;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// bne 0x830bc410
	if (!cr0.eq) goto loc_830BC410;
	// li r28,4
	r28.s64 = 4;
	// b 0x830bc41c
	goto loc_830BC41C;
loc_830BC410:
	// mr r28,r20
	r28.u64 = r20.u64;
loc_830BC414:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x830bc450
	if (cr6.eq) goto loc_830BC450;
loc_830BC41C:
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// beq cr6,0x830bc430
	if (cr6.eq) goto loc_830BC430;
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830bc450
	if (!cr6.eq) goto loc_830BC450;
loc_830BC430:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,104(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 104);
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// addi r6,r11,32640
	ctx.r6.s64 = r11.s64 + 32640;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// li r5,4502
	ctx.r5.s64 = 4502;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830BC450:
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// bne cr6,0x830bc480
	if (!cr6.eq) goto loc_830BC480;
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// bne cr6,0x830bc584
	if (!cr6.eq) goto loc_830BC584;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,104(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 104);
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// addi r6,r11,32492
	ctx.r6.s64 = r11.s64 + 32492;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// li r5,4502
	ctx.r5.s64 = 4502;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830BC480:
	// cmplwi cr6,r28,3
	cr6.compare<uint32_t>(r28.u32, 3, xer);
	// bne cr6,0x830bc54c
	if (!cr6.eq) goto loc_830BC54C;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830bc50c
	if (cr6.eq) goto loc_830BC50C;
	// cmplwi cr6,r31,4
	cr6.compare<uint32_t>(r31.u32, 4, xer);
	// bge cr6,0x830bc50c
	if (!cr6.lt) goto loc_830BC50C;
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830bc50c
	if (!cr6.eq) goto loc_830BC50C;
	// lhz r11,202(r27)
	r11.u64 = PPC_LOAD_U16(r27.u32 + 202);
	// cmplwi cr6,r11,260
	cr6.compare<uint32_t>(r11.u32, 260, xer);
	// bge cr6,0x830bc50c
	if (!cr6.lt) goto loc_830BC50C;
	// lwz r11,1088(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 1088);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830bc4dc
	if (!cr6.eq) goto loc_830BC4DC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r11,32484
	ctx.r4.s64 = r11.s64 + 32484;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// li r5,81
	ctx.r5.s64 = 81;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8307a8d8
	sub_8307A8D8(ctx, base);
	// stw r3,1088(r27)
	PPC_STORE_U32(r27.u32 + 1088, ctx.r3.u32);
loc_830BC4DC:
	// lwz r11,1088(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 1088);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830bc4f4
	if (!cr6.eq) goto loc_830BC4F4;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830bc5b0
	goto loc_830BC5B0;
loc_830BC4F4:
	// addi r10,r31,-1
	ctx.r10.s64 = r31.s64 + -1;
	// stw r11,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r11.u32);
	// li r28,5
	r28.s64 = 5;
	// stw r20,12(r26)
	PPC_STORE_U32(r26.u32 + 12, r20.u32);
	// stw r10,16(r26)
	PPC_STORE_U32(r26.u32 + 16, ctx.r10.u32);
	// b 0x830bc584
	goto loc_830BC584;
loc_830BC50C:
	// lwz r7,60(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 60);
	// cmplw cr6,r31,r7
	cr6.compare<uint32_t>(r31.u32, ctx.r7.u32, xer);
	// blt cr6,0x830bc584
	if (cr6.lt) goto loc_830BC584;
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// bne cr6,0x830bc584
	if (!cr6.eq) goto loc_830BC584;
	// lwz r11,1100(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 1100);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830bc584
	if (!cr6.eq) goto loc_830BC584;
	// stw r29,1100(r27)
	PPC_STORE_U32(r27.u32 + 1100, r29.u32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,4502
	ctx.r5.s64 = 4502;
	// lwz r4,104(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 104);
	// addi r6,r11,32408
	ctx.r6.s64 = r11.s64 + 32408;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// mr r30,r29
	r30.u64 = r29.u64;
loc_830BC54C:
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// bne cr6,0x830bc578
	if (!cr6.eq) goto loc_830BC578;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// ori r10,r10,276
	ctx.r10.u64 = ctx.r10.u64 | 276;
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// lfd f0,3376(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// lfd f13,3248(r9)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r9.u32 + 3248);
	// stfd f0,32(r26)
	PPC_STORE_U64(r26.u32 + 32, f0.u64);
	// stfd f13,40(r26)
	PPC_STORE_U64(r26.u32 + 40, ctx.f13.u64);
loc_830BC578:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x830bc584
	if (!cr6.eq) goto loc_830BC584;
loc_830BC580:
	// mr r30,r29
	r30.u64 = r29.u64;
loc_830BC584:
	// cmplwi cr6,r31,65535
	cr6.compare<uint32_t>(r31.u32, 65535, xer);
	// ble cr6,0x830bc590
	if (!cr6.gt) goto loc_830BC590;
	// mr r30,r29
	r30.u64 = r29.u64;
loc_830BC590:
	// rlwimi r28,r31,8,0,23
	r28.u64 = (__builtin_rotateleft32(r31.u32, 8) & 0xFFFFFF00) | (r28.u64 & 0xFFFFFFFF000000FF);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// stw r28,108(r26)
	PPC_STORE_U32(r26.u32 + 108, r28.u32);
	// beq cr6,0x830bc5ac
	if (cr6.eq) goto loc_830BC5AC;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830bc5b0
	goto loc_830BC5B0;
loc_830BC5AC:
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
loc_830BC5B0:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c18
	return;
}

__attribute__((alias("__imp__sub_830BC5B8"))) PPC_WEAK_FUNC(sub_830BC5B8);
PPC_FUNC_IMPL(__imp__sub_830BC5B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8306ae98
	sub_8306AE98(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lis r10,-31952
	ctx.r10.s64 = -2094006272;
	// stw r30,348(r31)
	PPC_STORE_U32(r31.u32 + 348, r30.u32);
	// lis r9,-31952
	ctx.r9.s64 = -2094006272;
	// addi r11,r11,32728
	r11.s64 = r11.s64 + 32728;
	// addi r10,r10,4240
	ctx.r10.s64 = ctx.r10.s64 + 4240;
	// addi r9,r9,4816
	ctx.r9.s64 = ctx.r9.s64 + 4816;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r10,244(r31)
	PPC_STORE_U32(r31.u32 + 244, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,248(r31)
	PPC_STORE_U32(r31.u32 + 248, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BC620"))) PPC_WEAK_FUNC(sub_830BC620);
PPC_FUNC_IMPL(__imp__sub_830BC620) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// li r7,256
	ctx.r7.s64 = 256;
	// ori r10,r10,257
	ctx.r10.u64 = ctx.r10.u64 | 257;
	// lwz r9,200(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 200);
	// lwz r8,112(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// stw r7,56(r11)
	PPC_STORE_U32(r11.u32 + 56, ctx.r7.u32);
	// subf. r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// oris r8,r8,256
	ctx.r8.u64 = ctx.r8.u64 | 16777216;
	// stw r8,112(r11)
	PPC_STORE_U32(r11.u32 + 112, ctx.r8.u32);
	// stw r9,268(r11)
	PPC_STORE_U32(r11.u32 + 268, ctx.r9.u32);
	// beq 0x830bc7a8
	if (cr0.eq) goto loc_830BC7A8;
	// cmplwi cr6,r10,255
	cr6.compare<uint32_t>(ctx.r10.u32, 255, xer);
	// beq cr6,0x830bc75c
	if (cr6.eq) goto loc_830BC75C;
	// cmplwi cr6,r10,257
	cr6.compare<uint32_t>(ctx.r10.u32, 257, xer);
	// beq cr6,0x830bc6f4
	if (cr6.eq) goto loc_830BC6F4;
	// cmplwi cr6,r10,510
	cr6.compare<uint32_t>(ctx.r10.u32, 510, xer);
	// beq cr6,0x830bc694
	if (cr6.eq) goto loc_830BC694;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r10,-32432
	ctx.r6.s64 = ctx.r10.s64 + -32432;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830bc7fc
	goto loc_830BC7FC;
loc_830BC694:
	// lwz r6,108(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// li r7,2048
	ctx.r7.s64 = 2048;
	// li r5,32
	ctx.r5.s64 = 32;
	// oris r6,r6,64
	ctx.r6.u64 = ctx.r6.u64 | 4194304;
	// stw r7,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r7.u32);
	// stw r5,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r5.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r7,64(r11)
	PPC_STORE_U32(r11.u32 + 64, ctx.r7.u32);
	// li r10,16
	ctx.r10.s64 = 16;
	// li r4,8192
	ctx.r4.s64 = 8192;
	// stw r9,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r9.u32);
	// li r3,255
	ctx.r3.s64 = 255;
	// stw r9,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r9.u32);
	// ori r6,r6,513
	ctx.r6.u64 = ctx.r6.u64 | 513;
	// stw r4,56(r11)
	PPC_STORE_U32(r11.u32 + 56, ctx.r4.u32);
	// li r7,24
	ctx.r7.s64 = 24;
	// stw r3,104(r11)
	PPC_STORE_U32(r11.u32 + 104, ctx.r3.u32);
	// li r5,4
	ctx.r5.s64 = 4;
	// stw r6,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r6.u32);
	// oris r8,r8,4096
	ctx.r8.u64 = ctx.r8.u64 | 268435456;
	// stw r10,84(r11)
	PPC_STORE_U32(r11.u32 + 84, ctx.r10.u32);
	// stw r7,88(r11)
	PPC_STORE_U32(r11.u32 + 88, ctx.r7.u32);
	// stw r5,92(r11)
	PPC_STORE_U32(r11.u32 + 92, ctx.r5.u32);
	// b 0x830bc7cc
	goto loc_830BC7CC;
loc_830BC6F4:
	// lwz r7,108(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// li r5,13
	ctx.r5.s64 = 13;
	// li r4,8192
	ctx.r4.s64 = 8192;
	// lis r6,-2
	ctx.r6.s64 = -131072;
	// stw r5,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r5.u32);
	// oris r7,r7,64
	ctx.r7.u64 = ctx.r7.u64 | 4194304;
	// stw r4,56(r11)
	PPC_STORE_U32(r11.u32 + 56, ctx.r4.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// li r10,16
	ctx.r10.s64 = 16;
	// li r3,255
	ctx.r3.s64 = 255;
	// stw r9,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r9.u32);
	// ori r7,r7,513
	ctx.r7.u64 = ctx.r7.u64 | 513;
	// stw r10,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r10.u32);
	// li r5,8
	ctx.r5.s64 = 8;
	// stw r10,64(r11)
	PPC_STORE_U32(r11.u32 + 64, ctx.r10.u32);
	// li r4,24
	ctx.r4.s64 = 24;
	// stw r3,104(r11)
	PPC_STORE_U32(r11.u32 + 104, ctx.r3.u32);
	// ori r6,r6,513
	ctx.r6.u64 = ctx.r6.u64 | 513;
	// stw r9,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r9.u32);
	// oris r8,r8,4096
	ctx.r8.u64 = ctx.r8.u64 | 268435456;
	// stw r7,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r7.u32);
	// stw r5,84(r11)
	PPC_STORE_U32(r11.u32 + 84, ctx.r5.u32);
	// stw r4,88(r11)
	PPC_STORE_U32(r11.u32 + 88, ctx.r4.u32);
	// stw r9,92(r11)
	PPC_STORE_U32(r11.u32 + 92, ctx.r9.u32);
	// stw r6,200(r11)
	PPC_STORE_U32(r11.u32 + 200, ctx.r6.u32);
	// b 0x830bc7cc
	goto loc_830BC7CC;
loc_830BC75C:
	// lwz r7,108(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// li r6,12
	ctx.r6.s64 = 12;
	// li r9,1
	ctx.r9.s64 = 1;
	// oris r7,r7,64
	ctx.r7.u64 = ctx.r7.u64 | 4194304;
	// stw r6,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r6.u32);
	// li r10,16
	ctx.r10.s64 = 16;
	// stw r9,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r9.u32);
	// li r5,255
	ctx.r5.s64 = 255;
	// stw r9,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r9.u32);
	// ori r7,r7,512
	ctx.r7.u64 = ctx.r7.u64 | 512;
	// stw r10,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r10.u32);
	// li r6,8
	ctx.r6.s64 = 8;
	// stw r10,64(r11)
	PPC_STORE_U32(r11.u32 + 64, ctx.r10.u32);
	// oris r8,r8,8192
	ctx.r8.u64 = ctx.r8.u64 | 536870912;
	// stw r5,104(r11)
	PPC_STORE_U32(r11.u32 + 104, ctx.r5.u32);
	// stw r7,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r7.u32);
	// stw r6,84(r11)
	PPC_STORE_U32(r11.u32 + 84, ctx.r6.u32);
	// stw r9,92(r11)
	PPC_STORE_U32(r11.u32 + 92, ctx.r9.u32);
	// b 0x830bc7cc
	goto loc_830BC7CC;
loc_830BC7A8:
	// lwz r9,108(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// li r7,12
	ctx.r7.s64 = 12;
	// li r6,10
	ctx.r6.s64 = 10;
	// ori r9,r9,64
	ctx.r9.u64 = ctx.r9.u64 | 64;
	// stw r7,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r7.u32);
	// li r10,16
	ctx.r10.s64 = 16;
	// stw r6,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r6.u32);
	// oris r8,r8,8194
	ctx.r8.u64 = ctx.r8.u64 | 537001984;
	// stw r9,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r9.u32);
loc_830BC7CC:
	// stw r8,112(r11)
	PPC_STORE_U32(r11.u32 + 112, ctx.r8.u32);
	// rotlwi r8,r8,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
	// lwz r9,108(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r7,44(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// oris r8,r8,96
	ctx.r8.u64 = ctx.r8.u64 | 6291456;
	// oris r9,r9,256
	ctx.r9.u64 = ctx.r9.u64 | 16777216;
	// stw r10,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r10.u32);
	// stw r10,68(r11)
	PPC_STORE_U32(r11.u32 + 68, ctx.r10.u32);
	// stw r9,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r9.u32);
	// stw r8,112(r11)
	PPC_STORE_U32(r11.u32 + 112, ctx.r8.u32);
	// stw r7,468(r11)
	PPC_STORE_U32(r11.u32 + 468, ctx.r7.u32);
loc_830BC7FC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BC810"))) PPC_WEAK_FUNC(sub_830BC810);
PPC_FUNC_IMPL(__imp__sub_830BC810) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,348(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 348);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830bc834
	if (cr6.eq) goto loc_830BC834;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830bc9f4
	goto loc_830BC9F4;
loc_830BC834:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r20,0
	r20.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// mr r26,r20
	r26.u64 = r20.u64;
	// mr r27,r20
	r27.u64 = r20.u64;
	// std r20,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r20.u64);
	// mr r28,r20
	r28.u64 = r20.u64;
	// std r20,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r20.u64);
	// mr r21,r20
	r21.u64 = r20.u64;
	// mr r23,r20
	r23.u64 = r20.u64;
	// ble cr6,0x830bc990
	if (!cr6.gt) goto loc_830BC990;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// mr r22,r20
	r22.u64 = r20.u64;
	// addi r25,r11,-32364
	r25.s64 = r11.s64 + -32364;
	// addi r24,r10,-5284
	r24.s64 = ctx.r10.s64 + -5284;
loc_830BC878:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r31,r22,r11
	r31.u64 = PPC_LOAD_U32(r22.u32 + r11.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830bc97c
	if (cr0.eq) goto loc_830BC97C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,108(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r4,108(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,116(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// beq cr6,0x830bc95c
	if (cr6.eq) goto loc_830BC95C;
	// cmplwi cr6,r29,5
	cr6.compare<uint32_t>(r29.u32, 5, xer);
	// beq cr6,0x830bc920
	if (cr6.eq) goto loc_830BC920;
	// cmplwi cr6,r29,12
	cr6.compare<uint32_t>(r29.u32, 12, xer);
	// bne cr6,0x830bc97c
	if (!cr6.eq) goto loc_830BC97C;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830bc97c
	if (!cr6.eq) goto loc_830BC97C;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bc97c
	if (!cr6.gt) goto loc_830BC97C;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// bne cr6,0x830bc97c
	if (!cr6.eq) goto loc_830BC97C;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// lwz r4,96(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// li r5,4540
	ctx.r5.s64 = 4540;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r26,1
	r26.s64 = 1;
	// b 0x830bc954
	goto loc_830BC954;
loc_830BC920:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830bc97c
	if (!cr6.eq) goto loc_830BC97C;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bc97c
	if (!cr6.gt) goto loc_830BC97C;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x830bc97c
	if (!cr6.eq) goto loc_830BC97C;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// lwz r4,96(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// li r5,4540
	ctx.r5.s64 = 4540;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r27,1
	r27.s64 = 1;
loc_830BC954:
	// li r28,1
	r28.s64 = 1;
	// b 0x830bc97c
	goto loc_830BC97C;
loc_830BC95C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830bc97c
	if (!cr6.eq) goto loc_830BC97C;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r21,96(r31)
	r21.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_830BC97C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmplw cr6,r23,r11
	cr6.compare<uint32_t>(r23.u32, r11.u32, xer);
	// blt cr6,0x830bc878
	if (cr6.lt) goto loc_830BC878;
loc_830BC990:
	// mr r9,r20
	ctx.r9.u64 = r20.u64;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r11,4
	r11.s64 = 4;
loc_830BC99C:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x830bc9ac
	if (cr6.eq) goto loc_830BC9AC;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
loc_830BC9AC:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830bc99c
	if (!cr0.eq) goto loc_830BC99C;
	// cmplwi cr6,r9,4
	cr6.compare<uint32_t>(ctx.r9.u32, 4, xer);
	// beq cr6,0x830bc9dc
	if (cr6.eq) goto loc_830BC9DC;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r5,4541
	ctx.r5.s64 = 4541;
	// addi r6,r11,-5352
	ctx.r6.s64 = r11.s64 + -5352;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r28,1
	r28.s64 = 1;
loc_830BC9DC:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x830bc9f0
	if (cr6.eq) goto loc_830BC9F0;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830bc9f4
	goto loc_830BC9F4;
loc_830BC9F0:
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
loc_830BC9F4:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c18
	return;
}

__attribute__((alias("__imp__sub_830BCA00"))) PPC_WEAK_FUNC(sub_830BCA00);
PPC_FUNC_IMPL(__imp__sub_830BCA00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r4,108(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r4,108(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,116(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830bca64
	if (cr6.eq) goto loc_830BCA64;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_830BCA64:
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// bne cr6,0x830bca88
	if (!cr6.eq) goto loc_830BCA88;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830bcb3c
	if (!cr6.eq) goto loc_830BCB3C;
	// li r10,4
	ctx.r10.s64 = 4;
	// stw r10,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r10.u32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x830bcb34
	goto loc_830BCB34;
loc_830BCA88:
	// cmplwi cr6,r29,5
	cr6.compare<uint32_t>(r29.u32, 5, xer);
	// bne cr6,0x830bcabc
	if (!cr6.eq) goto loc_830BCABC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830bcb3c
	if (!cr6.eq) goto loc_830BCB3C;
	// li r11,4
	r11.s64 = 4;
	// li r10,2
	ctx.r10.s64 = 2;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// beq cr6,0x830bcb34
	if (cr6.eq) goto loc_830BCB34;
	// li r11,1
	r11.s64 = 1;
	// b 0x830bcae8
	goto loc_830BCAE8;
loc_830BCABC:
	// cmplwi cr6,r29,12
	cr6.compare<uint32_t>(r29.u32, 12, xer);
	// bne cr6,0x830bcaf0
	if (!cr6.eq) goto loc_830BCAF0;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830bcb3c
	if (!cr6.eq) goto loc_830BCB3C;
	// li r10,4
	ctx.r10.s64 = 4;
	// li r11,1
	r11.s64 = 1;
	// stw r10,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq cr6,0x830bcb34
	if (cr6.eq) goto loc_830BCB34;
loc_830BCAE8:
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// b 0x830bcb34
	goto loc_830BCB34;
loc_830BCAF0:
	// cmplwi cr6,r29,11
	cr6.compare<uint32_t>(r29.u32, 11, xer);
	// bne cr6,0x830bcb0c
	if (!cr6.eq) goto loc_830BCB0C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bge cr6,0x830bcb3c
	if (!cr6.lt) goto loc_830BCB3C;
	// li r11,5
	r11.s64 = 5;
	// b 0x830bcb30
	goto loc_830BCB30;
loc_830BCB0C:
	// cmplwi cr6,r29,6
	cr6.compare<uint32_t>(r29.u32, 6, xer);
	// bne cr6,0x830bcb28
	if (!cr6.eq) goto loc_830BCB28;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bge cr6,0x830bcb3c
	if (!cr6.lt) goto loc_830BCB3C;
	// li r11,6
	r11.s64 = 6;
	// b 0x830bcb30
	goto loc_830BCB30;
loc_830BCB28:
	// cmplwi cr6,r29,65535
	cr6.compare<uint32_t>(r29.u32, 65535, xer);
	// bne cr6,0x830bcb3c
	if (!cr6.eq) goto loc_830BCB3C;
loc_830BCB30:
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
loc_830BCB34:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830bcb44
	goto loc_830BCB44;
loc_830BCB3C:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_830BCB44:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

__attribute__((alias("__imp__sub_830BCB50"))) PPC_WEAK_FUNC(sub_830BCB50);
PPC_FUNC_IMPL(__imp__sub_830BCB50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r4,108(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r3,65535
	cr6.compare<uint32_t>(ctx.r3.u32, 65535, xer);
	// bne cr6,0x830bcbb0
	if (!cr6.eq) goto loc_830BCBB0;
	// li r11,0
	r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r4,108(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// lwz r11,116(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r3.u32);
	// b 0x830bcbc0
	goto loc_830BCBC0;
loc_830BCBB0:
	// li r11,1
	r11.s64 = 1;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_830BCBC0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830BCBD0"))) PPC_WEAK_FUNC(sub_830BCBD0);
PPC_FUNC_IMPL(__imp__sub_830BCBD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lhz r11,202(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 202);
	// cmplwi cr6,r11,256
	cr6.compare<uint32_t>(r11.u32, 256, xer);
	// li r11,0
	r11.s64 = 0;
	// ble cr6,0x830bcbe4
	if (!cr6.gt) goto loc_830BCBE4;
	// li r11,1
	r11.s64 = 1;
loc_830BCBE4:
	// stw r11,344(r3)
	PPC_STORE_U32(ctx.r3.u32 + 344, r11.u32);
	// b 0x83071ec8
	sub_83071EC8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_830BCBF0"))) PPC_WEAK_FUNC(sub_830BCBF0);
PPC_FUNC_IMPL(__imp__sub_830BCBF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r21,4416
	r21.s64 = 289406976;
	// li r30,0
	r30.s64 = 0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bcc8c
	if (!cr6.gt) goto loc_830BCC8C;
	// li r29,0
	r29.s64 = 0;
loc_830BCC18:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lis r9,4160
	ctx.r9.s64 = 272629760;
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x830bcc50
	if (cr6.eq) goto loc_830BCC50;
	// cmplw cr6,r10,r21
	cr6.compare<uint32_t>(ctx.r10.u32, r21.u32, xer);
	// bne cr6,0x830bcc78
	if (!cr6.eq) goto loc_830BCC78;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83064830
	sub_83064830(ctx, base);
	// b 0x830bcc70
	goto loc_830BCC70;
loc_830BCC50:
	// lwz r10,112(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// rlwinm. r10,r10,0,14,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bcc6c
	if (cr0.eq) goto loc_830BCC6C;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// li r9,113
	ctx.r9.s64 = 113;
	// rlwimi r10,r9,24,0,11
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 24) & 0xFFF00000) | (ctx.r10.u64 & 0xFFFFFFFF000FFFFF);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_830BCC6C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BCC70:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x830bd330
	if (cr6.lt) goto loc_830BD330;
loc_830BCC78:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bcc18
	if (cr6.lt) goto loc_830BCC18;
loc_830BCC8C:
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// lis r19,4176
	r19.s64 = 273678336;
	// lis r20,28720
	r20.s64 = 1882193920;
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r24,29792
	r24.s64 = 1952448512;
	// lis r23,29808
	r23.s64 = 1953497088;
	// lis r25,29760
	r25.s64 = 1950351360;
	// lis r22,29776
	r22.s64 = 1951399936;
	// bne 0x830bcfc4
	if (!cr0.eq) goto loc_830BCFC4;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// lis r28,8272
	r28.s64 = 542113792;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bcdbc
	if (!cr6.gt) goto loc_830BCDBC;
	// li r29,0
	r29.s64 = 0;
loc_830BCCC8:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lis r10,4112
	ctx.r10.s64 = 269484032;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bcd94
	if (cr6.eq) goto loc_830BCD94;
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// beq cr6,0x830bcd74
	if (cr6.eq) goto loc_830BCD74;
	// lis r10,4336
	ctx.r10.s64 = 284164096;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bcd68
	if (cr6.eq) goto loc_830BCD68;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// beq cr6,0x830bcd5c
	if (cr6.eq) goto loc_830BCD5C;
	// lis r10,8208
	ctx.r10.s64 = 537919488;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bcd44
	if (cr6.eq) goto loc_830BCD44;
	// lis r10,8256
	ctx.r10.s64 = 541065216;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bcd34
	if (cr6.eq) goto loc_830BCD34;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x830bcda8
	if (!cr6.eq) goto loc_830BCDA8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83066318
	sub_83066318(ctx, base);
	// b 0x830bcda0
	goto loc_830BCDA0;
loc_830BCD34:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306d3f0
	sub_8306D3F0(ctx, base);
	// b 0x830bcda0
	goto loc_830BCDA0;
loc_830BCD44:
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// blt cr6,0x830bcd8c
	if (cr6.lt) goto loc_830BCD8C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83066f48
	sub_83066F48(ctx, base);
	// b 0x830bcda0
	goto loc_830BCDA0;
loc_830BCD5C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83064830
	sub_83064830(ctx, base);
	// b 0x830bcda0
	goto loc_830BCDA0;
loc_830BCD68:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83063a78
	sub_83063A78(ctx, base);
	// b 0x830bcda0
	goto loc_830BCDA0;
loc_830BCD74:
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// blt cr6,0x830bcd8c
	if (cr6.lt) goto loc_830BCD8C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83062918
	sub_83062918(ctx, base);
	// b 0x830bcda0
	goto loc_830BCDA0;
loc_830BCD8C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830bcda0
	goto loc_830BCDA0;
loc_830BCD94:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306fa98
	sub_8306FA98(ctx, base);
loc_830BCDA0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x830bd330
	if (cr6.lt) goto loc_830BD330;
loc_830BCDA8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bccc8
	if (cr6.lt) goto loc_830BCCC8;
loc_830BCDBC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084778
	sub_83084778(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// lis r26,29520
	r26.s64 = 1934622720;
	// lis r27,29536
	r27.s64 = 1935671296;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bcec4
	if (!cr6.gt) goto loc_830BCEC4;
	// li r29,0
	r29.s64 = 0;
loc_830BCDF0:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x830bce8c
	if (cr6.eq) goto loc_830BCE8C;
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// beq cr6,0x830bce70
	if (cr6.eq) goto loc_830BCE70;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// beq cr6,0x830bce54
	if (cr6.eq) goto loc_830BCE54;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// beq cr6,0x830bce54
	if (cr6.eq) goto loc_830BCE54;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// beq cr6,0x830bce38
	if (cr6.eq) goto loc_830BCE38;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// bne cr6,0x830bceb0
	if (!cr6.eq) goto loc_830BCEB0;
loc_830BCE38:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83065d40
	sub_83065D40(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83065ee0
	sub_83065EE0(ctx, base);
	// b 0x830bcea8
	goto loc_830BCEA8;
loc_830BCE54:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83064258
	sub_83064258(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830643f8
	sub_830643F8(ctx, base);
	// b 0x830bcea8
	goto loc_830BCEA8;
loc_830BCE70:
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// blt cr6,0x830bcea4
	if (cr6.lt) goto loc_830BCEA4;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83067818
	sub_83067818(ctx, base);
	// b 0x830bcea8
	goto loc_830BCEA8;
loc_830BCE8C:
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// blt cr6,0x830bcea4
	if (cr6.lt) goto loc_830BCEA4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830664b8
	sub_830664B8(ctx, base);
	// b 0x830bcea8
	goto loc_830BCEA8;
loc_830BCEA4:
	// li r3,1
	ctx.r3.s64 = 1;
loc_830BCEA8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x830bd330
	if (cr6.lt) goto loc_830BD330;
loc_830BCEB0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bcdf0
	if (cr6.lt) goto loc_830BCDF0;
loc_830BCEC4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// lis r28,29552
	r28.s64 = 1936719872;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bcf6c
	if (!cr6.gt) goto loc_830BCF6C;
	// li r29,0
	r29.s64 = 0;
loc_830BCEDC:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bgt cr6,0x830bcf30
	if (cr6.gt) goto loc_830BCF30;
	// beq cr6,0x830bcf48
	if (cr6.eq) goto loc_830BCF48;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// beq cr6,0x830bcf24
	if (cr6.eq) goto loc_830BCF24;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// beq cr6,0x830bcf24
	if (cr6.eq) goto loc_830BCF24;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x830bcf24
	if (cr6.eq) goto loc_830BCF24;
	// lis r10,29568
	ctx.r10.s64 = 1937768448;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bcf58
	if (!cr6.eq) goto loc_830BCF58;
loc_830BCF24:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83064598
	sub_83064598(ctx, base);
	// b 0x830bcf50
	goto loc_830BCF50;
loc_830BCF30:
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// beq cr6,0x830bcf48
	if (cr6.eq) goto loc_830BCF48;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// beq cr6,0x830bcf48
	if (cr6.eq) goto loc_830BCF48;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// bne cr6,0x830bcf58
	if (!cr6.eq) goto loc_830BCF58;
loc_830BCF48:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83066080
	sub_83066080(ctx, base);
loc_830BCF50:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x830bd330
	if (cr6.lt) goto loc_830BD330;
loc_830BCF58:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bcedc
	if (cr6.lt) goto loc_830BCEDC;
loc_830BCF6C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bcfc4
	if (!cr6.gt) goto loc_830BCFC4;
	// li r29,0
	r29.s64 = 0;
loc_830BCF80:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x830bcfb0
	if (!cr6.eq) goto loc_830BCFB0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83064128
	sub_83064128(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
loc_830BCFB0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bcf80
	if (cr6.lt) goto loc_830BCF80;
loc_830BCFC4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bd03c
	if (!cr6.gt) goto loc_830BD03C;
	// li r29,0
	r29.s64 = 0;
loc_830BCFE0:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// beq cr6,0x830bd008
	if (cr6.eq) goto loc_830BD008;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// bne cr6,0x830bd028
	if (!cr6.eq) goto loc_830BD028;
loc_830BD008:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83065d40
	sub_83065D40(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83065ee0
	sub_83065EE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
loc_830BD028:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bcfe0
	if (cr6.lt) goto loc_830BCFE0;
loc_830BD03C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bd0a4
	if (!cr6.gt) goto loc_830BD0A4;
	// li r29,0
	r29.s64 = 0;
loc_830BD050:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// beq cr6,0x830bd088
	if (cr6.eq) goto loc_830BD088;
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// beq cr6,0x830bd088
	if (cr6.eq) goto loc_830BD088;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// beq cr6,0x830bd088
	if (cr6.eq) goto loc_830BD088;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// bne cr6,0x830bd090
	if (!cr6.eq) goto loc_830BD090;
loc_830BD088:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83066080
	sub_83066080(ctx, base);
loc_830BD090:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bd050
	if (cr6.lt) goto loc_830BD050;
loc_830BD0A4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bd100
	if (!cr6.gt) goto loc_830BD100;
	// li r29,0
	r29.s64 = 0;
loc_830BD0B8:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lis r11,8336
	r11.s64 = 546308096;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r10,r29
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r29.u32);
	// stw r10,260(r31)
	PPC_STORE_U32(r31.u32 + 260, ctx.r10.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830bd0ec
	if (!cr6.eq) goto loc_830BD0EC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83065340
	sub_83065340(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
loc_830BD0EC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bd0b8
	if (cr6.lt) goto loc_830BD0B8;
loc_830BD100:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bd158
	if (!cr6.gt) goto loc_830BD158;
	// li r29,0
	r29.s64 = 0;
loc_830BD114:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bne cr6,0x830bd144
	if (!cr6.eq) goto loc_830BD144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061c48
	sub_83061C48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
loc_830BD144:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bd114
	if (cr6.lt) goto loc_830BD114;
loc_830BD158:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bd1c8
	if (!cr6.gt) goto loc_830BD1C8;
	// li r29,0
	r29.s64 = 0;
loc_830BD16C:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// bne cr6,0x830bd1b4
	if (!cr6.eq) goto loc_830BD1B4;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// blt cr6,0x830bd1a8
	if (cr6.lt) goto loc_830BD1A8;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83067818
	sub_83067818(ctx, base);
	// b 0x830bd1ac
	goto loc_830BD1AC;
loc_830BD1A8:
	// li r3,1
	ctx.r3.s64 = 1;
loc_830BD1AC:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x830bd330
	if (cr6.lt) goto loc_830BD330;
loc_830BD1B4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bd16c
	if (cr6.lt) goto loc_830BD16C;
loc_830BD1C8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bd280
	if (!cr6.gt) goto loc_830BD280;
	// li r29,0
	r29.s64 = 0;
loc_830BD1E4:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lis r10,4144
	ctx.r10.s64 = 271581184;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bd25c
	if (cr6.eq) goto loc_830BD25C;
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// beq cr6,0x830bd25c
	if (cr6.eq) goto loc_830BD25C;
	// lis r10,4192
	ctx.r10.s64 = 274726912;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bd25c
	if (cr6.eq) goto loc_830BD25C;
	// lis r10,4208
	ctx.r10.s64 = 275775488;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bd25c
	if (cr6.eq) goto loc_830BD25C;
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bd25c
	if (cr6.eq) goto loc_830BD25C;
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// bne cr6,0x830bd26c
	if (!cr6.eq) goto loc_830BD26C;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// blt cr6,0x830bd254
	if (cr6.lt) goto loc_830BD254;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306da58
	sub_8306DA58(ctx, base);
	// b 0x830bd264
	goto loc_830BD264;
loc_830BD254:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830bd264
	goto loc_830BD264;
loc_830BD25C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83063678
	sub_83063678(ctx, base);
loc_830BD264:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x830bd330
	if (cr6.lt) goto loc_830BD330;
loc_830BD26C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bd1e4
	if (cr6.lt) goto loc_830BD1E4;
loc_830BD280:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bd2e4
	if (!cr6.gt) goto loc_830BD2E4;
	// li r29,0
	r29.s64 = 0;
loc_830BD29C:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lis r11,20528
	r11.s64 = 1345323008;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r10,r29
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r29.u32);
	// stw r10,260(r31)
	PPC_STORE_U32(r31.u32 + 260, ctx.r10.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830bd2d0
	if (!cr6.eq) goto loc_830BD2D0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830620a8
	sub_830620A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
loc_830BD2D0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bd29c
	if (cr6.lt) goto loc_830BD29C;
loc_830BD2E4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084778
	sub_83084778(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084e68
	sub_83084E68(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307f3a8
	sub_8307F3A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830878b8
	sub_830878B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd330
	if (cr0.lt) goto loc_830BD330;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BD330:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c14
	return;
}

__attribute__((alias("__imp__sub_830BD338"))) PPC_WEAK_FUNC(sub_830BD338);
PPC_FUNC_IMPL(__imp__sub_830BD338) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8306bb68
	sub_8306BB68(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd394
	if (cr0.lt) goto loc_830BD394;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83084778
	sub_83084778(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd394
	if (cr0.lt) goto loc_830BD394;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830878b8
	sub_830878B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd394
	if (cr0.lt) goto loc_830BD394;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307f3a8
	sub_8307F3A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd394
	if (cr0.lt) goto loc_830BD394;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BD394:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BD3A8"))) PPC_WEAK_FUNC(sub_830BD3A8);
PPC_FUNC_IMPL(__imp__sub_830BD3A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// lhz r10,202(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 202);
	// cmplwi cr6,r10,512
	cr6.compare<uint32_t>(ctx.r10.u32, 512, xer);
	// bltlr cr6
	if (cr6.lt) return;
	// lwz r9,284(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 284);
	// lwz r8,276(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 276);
	// lwz r10,272(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 272);
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r9,r9,24,0,7
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFF000000;
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BD3E8"))) PPC_WEAK_FUNC(sub_830BD3E8);
PPC_FUNC_IMPL(__imp__sub_830BD3E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r22,0
	r22.s64 = 0;
	// lwz r27,260(r28)
	r27.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// clrlwi r29,r11,12
	r29.u64 = r11.u32 & 0xFFFFF;
	// cmplwi cr6,r29,3
	cr6.compare<uint32_t>(r29.u32, 3, xer);
	// blt cr6,0x830bd8a4
	if (cr6.lt) goto loc_830BD8A4;
	// lis r4,4096
	ctx.r4.s64 = 268435456;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// ori r4,r4,2
	ctx.r4.u64 = ctx.r4.u64 | 2;
	// bl 0x830696c8
	sub_830696C8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x830bd484
	if (!cr0.eq) goto loc_830BD484;
	// lis r4,4096
	ctx.r4.s64 = 268435456;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// ori r4,r4,3
	ctx.r4.u64 = ctx.r4.u64 | 3;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830696c8
	sub_830696C8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x830bd484
	if (!cr0.eq) goto loc_830BD484;
	// lis r4,4096
	ctx.r4.s64 = 268435456;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// ori r4,r4,4
	ctx.r4.u64 = ctx.r4.u64 | 4;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830696c8
	sub_830696C8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x830bd5e4
	if (cr0.eq) goto loc_830BD5E4;
loc_830BD484:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r6,20(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r10,132(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 132);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bd5e4
	if (!cr6.eq) goto loc_830BD5E4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r7,1
	ctx.r7.s64 = 1;
	// clrlwi. r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830bd4fc
	if (cr0.eq) goto loc_830BD4FC;
	// lwz r9,16(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
loc_830BD4C4:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x830bd4e4
	if (!cr6.eq) goto loc_830BD4E4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// lwz r9,52(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 52);
	// rlwinm. r9,r9,0,11,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1FFE00;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830bd4e8
	if (cr0.eq) goto loc_830BD4E8;
loc_830BD4E4:
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
loc_830BD4E8:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830bd4c4
	if (!cr0.eq) goto loc_830BD4C4;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x830bd5e4
	if (cr6.eq) goto loc_830BD5E4;
loc_830BD4FC:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830bd518
	if (cr0.eq) goto loc_830BD518;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830bd51c
	goto loc_830BD51C;
loc_830BD518:
	// mr r31,r22
	r31.u64 = r22.u64;
loc_830BD51C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x830bd530
	if (!cr6.eq) goto loc_830BD530;
loc_830BD524:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830bd8a8
	goto loc_830BD8A8;
loc_830BD530:
	// li r11,5
	r11.s64 = 5;
	// lwz r6,12(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r5,4(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830bd5cc
	if (cr0.lt) goto loc_830BD5CC;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830bd5cc
	if (cr0.lt) goto loc_830BD5CC;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r4,8(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// stw r22,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r22.u32);
	// lwz r30,260(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830bd5b4
	if (cr6.eq) goto loc_830BD5B4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830BD5B4:
	// lwz r11,256(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 256);
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r31,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r31.u32);
	// stw r31,260(r28)
	PPC_STORE_U32(r28.u32 + 260, r31.u32);
	// b 0x830bd8a4
	goto loc_830BD8A4;
loc_830BD5CC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x830bd8a8
	goto loc_830BD8A8;
loc_830BD5E4:
	// cmplwi cr6,r29,3
	cr6.compare<uint32_t>(r29.u32, 3, xer);
	// bne cr6,0x830bd8a4
	if (!cr6.eq) goto loc_830BD8A4;
	// lhz r11,202(r28)
	r11.u64 = PPC_LOAD_U16(r28.u32 + 202);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// blt cr6,0x830bd8a4
	if (cr6.lt) goto loc_830BD8A4;
	// lwz r25,260(r28)
	r25.u64 = PPC_LOAD_U32(r28.u32 + 260);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// addi r10,r11,12
	ctx.r10.s64 = r11.s64 + 12;
	// addi r9,r11,12
	ctx.r9.s64 = r11.s64 + 12;
loc_830BD608:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x830bd628
	if (!cr0.eq) goto loc_830BD628;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x830bd608
	if (!cr6.eq) goto loc_830BD608;
loc_830BD628:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x830bd8a4
	if (!cr0.eq) goto loc_830BD8A4;
	// lis r11,4208
	r11.s64 = 275775488;
	// li r8,1
	ctx.r8.s64 = 1;
	// ori r23,r11,1
	r23.u64 = r11.u64 | 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830696c8
	sub_830696C8(ctx, base);
	// mr. r24,r3
	r24.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// beq 0x830bd8a4
	if (cr0.eq) goto loc_830BD8A4;
	// lis r4,8272
	ctx.r4.s64 = 542113792;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// ori r4,r4,3
	ctx.r4.u64 = ctx.r4.u64 | 3;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830696c8
	sub_830696C8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x830bd6ac
	if (!cr0.eq) goto loc_830BD6AC;
	// lis r4,8272
	ctx.r4.s64 = 542113792;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// ori r4,r4,4
	ctx.r4.u64 = ctx.r4.u64 | 4;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830696c8
	sub_830696C8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x830bd8a4
	if (cr0.eq) goto loc_830BD8A4;
loc_830BD6AC:
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// clrlwi r29,r7,12
	r29.u64 = ctx.r7.u32 & 0xFFFFF;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r6,0(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r27,r29,2,0,29
	r27.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r5,r7,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r27,r11
	r11.u64 = r27.u64 + r11.u64;
	// addi r7,r11,12
	ctx.r7.s64 = r11.s64 + 12;
	// lwzx r5,r5,r10
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// lwzx r4,r6,r10
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
loc_830BD6EC:
	// lbz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// subf. r6,r3,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r3.s64;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x830bd70c
	if (!cr0.eq) goto loc_830BD70C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r11,r7
	cr6.compare<int32_t>(r11.s32, ctx.r7.s32, xer);
	// bne cr6,0x830bd6ec
	if (!cr6.eq) goto loc_830BD6EC;
loc_830BD70C:
	// cmpwi r6,0
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x830bd8a4
	if (!cr0.eq) goto loc_830BD8A4;
	// mr r11,r22
	r11.u64 = r22.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830bd748
	if (cr6.eq) goto loc_830BD748;
loc_830BD720:
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x830bd8a4
	if (!cr6.eq) goto loc_830BD8A4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// blt cr6,0x830bd720
	if (cr6.lt) goto loc_830BD720;
loc_830BD748:
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bd768
	if (!cr6.eq) goto loc_830BD768;
	// lwz r11,12(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// lwz r10,12(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bd8a4
	if (cr6.eq) goto loc_830BD8A4;
loc_830BD768:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830bd784
	if (cr0.eq) goto loc_830BD784;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830bd788
	goto loc_830BD788;
loc_830BD784:
	// mr r30,r22
	r30.u64 = r22.u64;
loc_830BD788:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830bd524
	if (cr6.eq) goto loc_830BD524;
	// clrlwi r26,r29,12
	r26.u64 = r29.u32 & 0xFFFFF;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// oris r4,r26,28704
	ctx.r4.u64 = r26.u64 | 1881145344;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd8a8
	if (cr0.lt) goto loc_830BD8A8;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bd8a8
	if (cr0.lt) goto loc_830BD8A8;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// add r4,r27,r11
	ctx.r4.u64 = r27.u64 + r11.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830bd894
	if (!cr0.eq) goto loc_830BD894;
	// stw r22,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r22.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r22,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r22.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r22,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r22.u32);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,52(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830bd87c
	if (!cr0.eq) goto loc_830BD87C;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r10
	r31.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830bd868
	if (cr6.eq) goto loc_830BD868;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830BD868:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r30,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r30.u32);
	// b 0x830bd8a4
	goto loc_830BD8A4;
loc_830BD87C:
	// lis r11,20480
	r11.s64 = 1342177280;
	// oris r10,r26,8272
	ctx.r10.u64 = r26.u64 | 542113792;
	// ori r11,r11,3
	r11.u64 = r11.u64 | 3;
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// stw r23,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r23.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
loc_830BD894:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830BD8A4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BD8A8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
}

__attribute__((alias("__imp__sub_830BD8B0"))) PPC_WEAK_FUNC(sub_830BD8B0);
PPC_FUNC_IMPL(__imp__sub_830BD8B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// mr r25,r31
	r25.u64 = r31.u64;
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// ble cr6,0x830bd9c0
	if (!cr6.gt) goto loc_830BD9C0;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdca8
	if (cr0.lt) goto loc_830BDCA8;
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// li r4,78
	ctx.r4.s64 = 78;
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdca8
	if (cr0.lt) goto loc_830BDCA8;
	// lwz r9,260(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// mr r11,r31
	r11.u64 = r31.u64;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830bd97c
	if (!cr6.gt) goto loc_830BD97C;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
loc_830BD960:
	// lwz r8,116(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x830bd960
	if (cr6.lt) goto loc_830BD960;
loc_830BD97C:
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830bdca4
	if (!cr0.lt) goto loc_830BDCA4;
	// b 0x830bdca8
	goto loc_830BDCA8;
loc_830BD9C0:
	// mr r24,r31
	r24.u64 = r31.u64;
loc_830BD9C4:
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// mr r26,r31
	r26.u64 = r31.u64;
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x830bdc98
	if (cr6.eq) goto loc_830BDC98;
	// mr r29,r31
	r29.u64 = r31.u64;
	// li r27,1
	r27.s64 = 1;
	// li r28,2
	r28.s64 = 2;
loc_830BD9E4:
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x830bda74
	if (!cr6.eq) goto loc_830BDA74;
	// cmplw cr6,r28,r8
	cr6.compare<uint32_t>(r28.u32, ctx.r8.u32, xer);
	// bge cr6,0x830bda74
	if (!cr6.lt) goto loc_830BDA74;
	// cmplwi cr6,r24,1
	cr6.compare<uint32_t>(r24.u32, 1, xer);
	// bne cr6,0x830bda60
	if (!cr6.eq) goto loc_830BDA60;
	// lwz r7,260(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// li r4,78
	ctx.r4.s64 = 78;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// lwz r5,16(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,8(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// add r5,r5,r29
	ctx.r5.u64 = ctx.r5.u64 + r29.u64;
	// add r7,r11,r29
	ctx.r7.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
loc_830BDA58:
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdca8
	if (cr0.lt) goto loc_830BDCA8;
loc_830BDA60:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// b 0x830bdc88
	goto loc_830BDC88;
loc_830BDA74:
	// cmplw cr6,r27,r8
	cr6.compare<uint32_t>(r27.u32, ctx.r8.u32, xer);
	// blt cr6,0x830bdb44
	if (cr6.lt) goto loc_830BDB44;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x830bda60
	if (!cr6.eq) goto loc_830BDA60;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x830bdac0
	if (!cr6.eq) goto loc_830BDAC0;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdca8
	if (cr0.lt) goto loc_830BDCA8;
	// li r25,1
	r25.s64 = 1;
loc_830BDAC0:
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// li r4,78
	ctx.r4.s64 = 78;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// add r7,r11,r29
	ctx.r7.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdca8
	if (cr0.lt) goto loc_830BDCA8;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// addi r7,r1,116
	ctx.r7.s64 = ctx.r1.s64 + 116;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// add r5,r11,r29
	ctx.r5.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// b 0x830bda58
	goto loc_830BDA58;
loc_830BDB44:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x830bdbac
	if (!cr6.eq) goto loc_830BDBAC;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x830bdbac
	if (!cr6.eq) goto loc_830BDBAC;
	// cmplwi cr6,r24,1
	cr6.compare<uint32_t>(r24.u32, 1, xer);
	// bne cr6,0x830bdc78
	if (!cr6.eq) goto loc_830BDC78;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// li r10,2
	ctx.r10.s64 = 2;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// li r6,2
	ctx.r6.s64 = 2;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// li r4,19
	ctx.r4.s64 = 19;
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// add r7,r7,r29
	ctx.r7.u64 = ctx.r7.u64 + r29.u64;
	// add r5,r11,r29
	ctx.r5.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// b 0x830bdc70
	goto loc_830BDC70;
loc_830BDBAC:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x830bdc78
	if (!cr6.eq) goto loc_830BDC78;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x830bdbf0
	if (!cr6.eq) goto loc_830BDBF0;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdca8
	if (cr0.lt) goto loc_830BDCA8;
	// li r25,1
	r25.s64 = 1;
loc_830BDBF0:
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// li r10,2
	ctx.r10.s64 = 2;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// li r6,2
	ctx.r6.s64 = 2;
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// li r4,19
	ctx.r4.s64 = 19;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// add r7,r11,r29
	ctx.r7.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdca8
	if (cr0.lt) goto loc_830BDCA8;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// li r10,2
	ctx.r10.s64 = 2;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// li r6,2
	ctx.r6.s64 = 2;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// add r5,r11,r29
	ctx.r5.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
loc_830BDC70:
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdca8
	if (cr0.lt) goto loc_830BDCA8;
loc_830BDC78:
	// addi r29,r29,8
	r29.s64 = r29.s64 + 8;
	// addi r27,r27,2
	r27.s64 = r27.s64 + 2;
	// addi r28,r28,2
	r28.s64 = r28.s64 + 2;
	// addi r26,r26,2
	r26.s64 = r26.s64 + 2;
loc_830BDC88:
	// lwz r11,260(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 260);
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r26,r8
	cr6.compare<uint32_t>(r26.u32, ctx.r8.u32, xer);
	// blt cr6,0x830bd9e4
	if (cr6.lt) goto loc_830BD9E4;
loc_830BDC98:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// cmplwi cr6,r24,2
	cr6.compare<uint32_t>(r24.u32, 2, xer);
	// blt cr6,0x830bd9c4
	if (cr6.lt) goto loc_830BD9C4;
loc_830BDCA4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BDCA8:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c28
	return;
}

__attribute__((alias("__imp__sub_830BDCB0"))) PPC_WEAK_FUNC(sub_830BDCB0);
PPC_FUNC_IMPL(__imp__sub_830BDCB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830bdd08
	if (cr6.eq) goto loc_830BDD08;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_830BDCE0:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwz r7,0(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r7,r7,0,6,6
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x830bdd08
	if (cr0.eq) goto loc_830BDD08;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x830bdce0
	if (cr6.lt) goto loc_830BDCE0;
loc_830BDD08:
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830bdd3c
	if (!cr6.lt) goto loc_830BDD3C;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r4,14
	ctx.r4.s64 = 14;
loc_830BDD18:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,8(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x83075d40
	sub_83075D40(ctx, base);
	// b 0x830bdfe8
	goto loc_830BDFE8;
loc_830BDD3C:
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// blt cr6,0x830bdd54
	if (cr6.lt) goto loc_830BDD54;
	// li r4,78
	ctx.r4.s64 = 78;
	// b 0x830bdd18
	goto loc_830BDD18;
loc_830BDD54:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r27,r30
	r27.u64 = r30.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// ble cr6,0x830bde50
	if (!cr6.gt) goto loc_830BDE50;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdfe8
	if (cr0.lt) goto loc_830BDFE8;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// li r4,78
	ctx.r4.s64 = 78;
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdfe8
	if (cr0.lt) goto loc_830BDFE8;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// mr r11,r30
	r11.u64 = r30.u64;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830bde0c
	if (!cr6.gt) goto loc_830BDE0C;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
loc_830BDDF0:
	// lwz r8,120(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x830bddf0
	if (cr6.lt) goto loc_830BDDF0;
loc_830BDE0C:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830bdfe4
	if (!cr0.lt) goto loc_830BDFE4;
	// b 0x830bdfe8
	goto loc_830BDFE8;
loc_830BDE50:
	// mr r28,r30
	r28.u64 = r30.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830bdfe4
	if (cr6.eq) goto loc_830BDFE4;
	// mr r29,r30
	r29.u64 = r30.u64;
loc_830BDE60:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwzx r9,r9,r29
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,16(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830bdea0
	if (!cr6.eq) goto loc_830BDEA0;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830bdf84
	if (!cr0.eq) goto loc_830BDF84;
loc_830BDEA0:
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x830bdf84
	if (cr6.eq) goto loc_830BDF84;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x830bdec4
	if (!cr6.eq) goto loc_830BDEC4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bdec4
	if (cr0.eq) goto loc_830BDEC4;
	// rlwinm. r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830bdf84
	if (!cr0.eq) goto loc_830BDF84;
loc_830BDEC4:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x830bdf00
	if (!cr6.eq) goto loc_830BDF00;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdfe8
	if (cr0.lt) goto loc_830BDFE8;
	// li r27,1
	r27.s64 = 1;
loc_830BDF00:
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// li r4,78
	ctx.r4.s64 = 78;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r7,r11,r29
	ctx.r7.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdfe8
	if (cr0.lt) goto loc_830BDFE8;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// addi r7,r1,120
	ctx.r7.s64 = ctx.r1.s64 + 120;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// add r5,r11,r29
	ctx.r5.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// b 0x830bdfc4
	goto loc_830BDFC4;
loc_830BDF84:
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r7,260(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r4,78
	ctx.r4.s64 = 78;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,16(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// lwz r11,8(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// add r5,r5,r29
	ctx.r5.u64 = ctx.r5.u64 + r29.u64;
	// add r7,r11,r29
	ctx.r7.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
loc_830BDFC4:
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bdfe8
	if (cr0.lt) goto loc_830BDFE8;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x830bde60
	if (cr6.lt) goto loc_830BDE60;
loc_830BDFE4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BDFE8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830BDFF0"))) PPC_WEAK_FUNC(sub_830BDFF0);
PPC_FUNC_IMPL(__imp__sub_830BDFF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830be048
	if (cr6.eq) goto loc_830BE048;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_830BE020:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwz r7,0(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r7,r7,0,6,6
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x830be048
	if (cr0.eq) goto loc_830BE048;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x830be020
	if (cr6.lt) goto loc_830BE020;
loc_830BE048:
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830be07c
	if (!cr6.lt) goto loc_830BE07C;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r4,15
	ctx.r4.s64 = 15;
loc_830BE058:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,8(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x83075d40
	sub_83075D40(ctx, base);
	// b 0x830be2e8
	goto loc_830BE2E8;
loc_830BE07C:
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// blt cr6,0x830be094
	if (cr6.lt) goto loc_830BE094;
	// li r4,79
	ctx.r4.s64 = 79;
	// b 0x830be058
	goto loc_830BE058;
loc_830BE094:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r27,r30
	r27.u64 = r30.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// ble cr6,0x830be190
	if (!cr6.gt) goto loc_830BE190;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830be2e8
	if (cr0.lt) goto loc_830BE2E8;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// li r4,79
	ctx.r4.s64 = 79;
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830be2e8
	if (cr0.lt) goto loc_830BE2E8;
	// lwz r9,260(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// mr r11,r30
	r11.u64 = r30.u64;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830be14c
	if (!cr6.gt) goto loc_830BE14C;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
loc_830BE130:
	// lwz r8,120(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x830be130
	if (cr6.lt) goto loc_830BE130;
loc_830BE14C:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830be2e4
	if (!cr0.lt) goto loc_830BE2E4;
	// b 0x830be2e8
	goto loc_830BE2E8;
loc_830BE190:
	// mr r28,r30
	r28.u64 = r30.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830be2e4
	if (cr6.eq) goto loc_830BE2E4;
	// mr r29,r30
	r29.u64 = r30.u64;
loc_830BE1A0:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x830be208
	if (!cr6.eq) goto loc_830BE208;
	// lwz r7,260(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// li r4,79
	ctx.r4.s64 = 79;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// lwz r5,16(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// add r5,r5,r29
	ctx.r5.u64 = ctx.r5.u64 + r29.u64;
	// add r7,r11,r29
	ctx.r7.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// b 0x830be2c4
	goto loc_830BE2C4;
loc_830BE208:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x830be244
	if (!cr6.eq) goto loc_830BE244;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,256(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 340);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830be2e8
	if (cr0.lt) goto loc_830BE2E8;
	// li r27,1
	r27.s64 = 1;
loc_830BE244:
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// li r4,79
	ctx.r4.s64 = 79;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// add r7,r11,r29
	ctx.r7.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830be2e8
	if (cr0.lt) goto loc_830BE2E8;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// addi r7,r1,120
	ctx.r7.s64 = ctx.r1.s64 + 120;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r5,r11,r29
	ctx.r5.u64 = r11.u64 + r29.u64;
	// bl 0x830735f0
	sub_830735F0(ctx, base);
loc_830BE2C4:
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830be2e8
	if (cr0.lt) goto loc_830BE2E8;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x830be1a0
	if (cr6.lt) goto loc_830BE1A0;
loc_830BE2E4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BE2E8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830BE2F0"))) PPC_WEAK_FUNC(sub_830BE2F0);
PPC_FUNC_IMPL(__imp__sub_830BE2F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// or r30,r4,r5
	r30.u64 = ctx.r4.u64 | ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// bl 0x83073490
	sub_83073490(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830be3b0
	if (cr0.lt) goto loc_830BE3B0;
	// rlwinm. r11,r30,0,18,18
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x2000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830be3ac
	if (cr0.eq) goto loc_830BE3AC;
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// blt cr6,0x830be3ac
	if (cr6.lt) goto loc_830BE3AC;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r29,2,0,29
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830be360
	if (cr0.eq) goto loc_830BE360;
	// lis r4,-3868
	ctx.r4.s64 = -253493248;
	// ori r4,r4,2048
	ctx.r4.u64 = ctx.r4.u64 | 2048;
	// b 0x830be3a4
	goto loc_830BE3A4;
loc_830BE360:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// clrlwi r10,r10,21
	ctx.r10.u64 = ctx.r10.u32 & 0x7FF;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// oris r4,r10,45056
	ctx.r4.u64 = ctx.r10.u64 | 2952790016;
	// blt cr6,0x830be3a4
	if (cr6.lt) goto loc_830BE3A4;
	// beq cr6,0x830be3a0
	if (cr6.eq) goto loc_830BE3A0;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x830be398
	if (cr6.lt) goto loc_830BE398;
	// bne cr6,0x830be3a4
	if (!cr6.eq) goto loc_830BE3A4;
	// oris r4,r4,255
	ctx.r4.u64 = ctx.r4.u64 | 16711680;
	// b 0x830be3a4
	goto loc_830BE3A4;
loc_830BE398:
	// oris r4,r4,170
	ctx.r4.u64 = ctx.r4.u64 | 11141120;
	// b 0x830be3a4
	goto loc_830BE3A4;
loc_830BE3A0:
	// oris r4,r4,85
	ctx.r4.u64 = ctx.r4.u64 | 5570560;
loc_830BE3A4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83073490
	sub_83073490(ctx, base);
loc_830BE3AC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BE3B0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830BE3B8"))) PPC_WEAK_FUNC(sub_830BE3B8);
PPC_FUNC_IMPL(__imp__sub_830BE3B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r11,r11,32728
	r11.s64 = r11.s64 + 32728;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8306af88
	sub_8306AF88(ctx, base);
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830be3f8
	if (cr0.eq) goto loc_830BE3F8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
loc_830BE3F8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BE418"))) PPC_WEAK_FUNC(sub_830BE418);
PPC_FUNC_IMPL(__imp__sub_830BE418) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// lwz r24,260(r21)
	r24.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r29,r11,12
	r29.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x830be8ec
	if (cr0.eq) goto loc_830BE8EC;
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// li r19,0
	r19.s64 = 0;
	// twllei r29,0
	// divwu. r18,r11,r29
	r18.u32 = r11.u32 / r29.u32;
	cr0.compare<int32_t>(r18.s32, 0, xer);
	// beq 0x830be8ec
	if (cr0.eq) goto loc_830BE8EC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r26,0
	r26.s64 = 0;
	// rlwinm r17,r29,2,0,29
	r17.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// li r22,-1
	r22.s64 = -1;
	// li r27,-1
	r27.s64 = -1;
	// lfd f0,3248(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3248);
	// lis r20,4096
	r20.s64 = 268435456;
loc_830BE468:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// li r30,0
	r30.s64 = 0;
	// mr r15,r27
	r15.u64 = r27.u64;
	// mr r23,r30
	r23.u64 = r30.u64;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// std r22,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r22.u64);
	// mr r25,r30
	r25.u64 = r30.u64;
	// std r22,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r22.u64);
	// mr r16,r30
	r16.u64 = r30.u64;
	// mr r14,r27
	r14.u64 = r27.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830be654
	if (cr6.eq) goto loc_830BE654;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// lwz r5,20(r21)
	ctx.r5.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// add r6,r11,r26
	ctx.r6.u64 = r11.u64 + r26.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
loc_830BE4B4:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// lwz r7,16(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// blt cr6,0x830be610
	if (cr6.lt) goto loc_830BE610;
	// beq cr6,0x830be5e8
	if (cr6.eq) goto loc_830BE5E8;
	// cmplwi cr6,r7,3
	cr6.compare<uint32_t>(ctx.r7.u32, 3, xer);
	// blt cr6,0x830be564
	if (cr6.lt) goto loc_830BE564;
	// bne cr6,0x830be648
	if (!cr6.eq) goto loc_830BE648;
	// cmpwi cr6,r14,-1
	cr6.compare<int32_t>(r14.s32, -1, xer);
	// bne cr6,0x830be648
	if (!cr6.eq) goto loc_830BE648;
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// mr r14,r11
	r14.u64 = r11.u64;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// stw r27,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r27.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830be63c
	if (cr6.eq) goto loc_830BE63C;
	// lwz r11,24(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r20
	cr6.compare<uint32_t>(ctx.r10.u32, r20.u32, xer);
	// bne cr6,0x830be55c
	if (!cr6.eq) goto loc_830BE55C;
	// clrlwi. r7,r11,12
	ctx.r7.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// mr r11,r30
	r11.u64 = r30.u64;
	// beq 0x830be63c
	if (cr0.eq) goto loc_830BE63C;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
loc_830BE52C:
	// lwz r28,0(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r28,r14
	cr6.compare<uint32_t>(r28.u32, r14.u32, xer);
	// beq cr6,0x830be54c
	if (cr6.eq) goto loc_830BE54C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// blt cr6,0x830be52c
	if (cr6.lt) goto loc_830BE52C;
	// b 0x830be63c
	goto loc_830BE63C;
loc_830BE54C:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r14,r11,r10
	r14.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x830be63c
	goto loc_830BE63C;
loc_830BE55C:
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// b 0x830be63c
	goto loc_830BE63C;
loc_830BE564:
	// cmpwi cr6,r15,-1
	cr6.compare<int32_t>(r15.s32, -1, xer);
	// bne cr6,0x830be648
	if (!cr6.eq) goto loc_830BE648;
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// mr r15,r11
	r15.u64 = r11.u64;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// stw r27,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r27.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x830be63c
	if (cr6.eq) goto loc_830BE63C;
	// lwz r11,24(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r16,r10,r11
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 0);
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r20
	cr6.compare<uint32_t>(ctx.r10.u32, r20.u32, xer);
	// bne cr6,0x830be5e0
	if (!cr6.eq) goto loc_830BE5E0;
	// clrlwi. r7,r11,12
	ctx.r7.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// mr r11,r30
	r11.u64 = r30.u64;
	// beq 0x830be63c
	if (cr0.eq) goto loc_830BE63C;
	// lwz r10,16(r16)
	ctx.r10.u64 = PPC_LOAD_U32(r16.u32 + 16);
loc_830BE5B0:
	// lwz r31,0(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r31,r15
	cr6.compare<uint32_t>(r31.u32, r15.u32, xer);
	// beq cr6,0x830be5d0
	if (cr6.eq) goto loc_830BE5D0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// blt cr6,0x830be5b0
	if (cr6.lt) goto loc_830BE5B0;
	// b 0x830be63c
	goto loc_830BE63C;
loc_830BE5D0:
	// lwz r10,8(r16)
	ctx.r10.u64 = PPC_LOAD_U32(r16.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r15,r11,r10
	r15.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x830be63c
	goto loc_830BE63C;
loc_830BE5E0:
	// mr r16,r30
	r16.u64 = r30.u64;
	// b 0x830be63c
	goto loc_830BE63C;
loc_830BE5E8:
	// lwz r7,72(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// beq cr6,0x830be648
	if (cr6.eq) goto loc_830BE648;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x830be648
	if (!cr6.eq) goto loc_830BE648;
	// rotlwi r10,r7,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r7.u32, 0);
	// lwz r7,24(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 24);
	// rlwinm r31,r10,2,0,29
	r31.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r25,r31,r7
	r25.u64 = PPC_LOAD_U32(r31.u32 + ctx.r7.u32);
	// b 0x830be634
	goto loc_830BE634;
loc_830BE610:
	// lwz r7,72(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// beq cr6,0x830be648
	if (cr6.eq) goto loc_830BE648;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830be648
	if (!cr6.eq) goto loc_830BE648;
	// rotlwi r10,r7,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r7.u32, 0);
	// lwz r7,24(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 24);
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r3,r7
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r7.u32);
loc_830BE634:
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
loc_830BE63C:
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
loc_830BE648:
	// addic. r4,r4,-1
	xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// bne 0x830be4b4
	if (!cr0.eq) goto loc_830BE4B4;
loc_830BE654:
	// cmplw cr6,r23,r29
	cr6.compare<uint32_t>(r23.u32, r29.u32, xer);
	// bne cr6,0x830be8dc
	if (!cr6.eq) goto loc_830BE8DC;
	// cmplwi cr6,r23,1
	cr6.compare<uint32_t>(r23.u32, 1, xer);
	// ble cr6,0x830be8dc
	if (!cr6.gt) goto loc_830BE8DC;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830be708
	if (cr6.eq) goto loc_830BE708;
	// lis r11,8272
	r11.s64 = 542113792;
	// lwz r9,0(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x830be704
	if (!cr6.eq) goto loc_830BE704;
	// cmpwi cr6,r15,-1
	cr6.compare<int32_t>(r15.s32, -1, xer);
	// beq cr6,0x830be6ac
	if (cr6.eq) goto loc_830BE6AC;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r15,r9
	cr6.compare<uint32_t>(r15.u32, ctx.r9.u32, xer);
	// beq cr6,0x830be6ac
	if (cr6.eq) goto loc_830BE6AC;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r15,r11
	cr6.compare<uint32_t>(r15.u32, r11.u32, xer);
	// beq cr6,0x830be6ac
	if (cr6.eq) goto loc_830BE6AC;
	// li r10,1
	ctx.r10.s64 = 1;
loc_830BE6AC:
	// cmpwi cr6,r14,-1
	cr6.compare<int32_t>(r14.s32, -1, xer);
	// beq cr6,0x830be708
	if (cr6.eq) goto loc_830BE708;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r14,r9
	cr6.compare<uint32_t>(r14.u32, ctx.r9.u32, xer);
	// beq cr6,0x830be6d4
	if (cr6.eq) goto loc_830BE6D4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r14,r11
	cr6.compare<uint32_t>(r14.u32, r11.u32, xer);
	// beq cr6,0x830be6d4
	if (cr6.eq) goto loc_830BE6D4;
	// li r10,1
	ctx.r10.s64 = 1;
loc_830BE6D4:
	// cmpwi cr6,r15,-1
	cr6.compare<int32_t>(r15.s32, -1, xer);
	// beq cr6,0x830be708
	if (cr6.eq) goto loc_830BE708;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// cmplw cr6,r14,r15
	cr6.compare<uint32_t>(r14.u32, r15.u32, xer);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// beq cr6,0x830be6fc
	if (cr6.eq) goto loc_830BE6FC;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x830be708
	if (!cr6.eq) goto loc_830BE708;
	// b 0x830be704
	goto loc_830BE704;
loc_830BE6FC:
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x830be708
	if (cr6.eq) goto loc_830BE708;
loc_830BE704:
	// li r10,1
	ctx.r10.s64 = 1;
loc_830BE708:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830be764
	if (cr6.eq) goto loc_830BE764;
	// lis r11,4096
	r11.s64 = 268435456;
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x830be8dc
	if (!cr6.eq) goto loc_830BE8DC;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r9,20(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// lwz r8,16(r21)
	ctx.r8.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830be760
	if (cr0.eq) goto loc_830BE760;
	// lfd f13,32(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// beq cr6,0x830be764
	if (cr6.eq) goto loc_830BE764;
loc_830BE760:
	// li r10,1
	ctx.r10.s64 = 1;
loc_830BE764:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x830be8dc
	if (!cr6.eq) goto loc_830BE8DC;
	// mr r31,r30
	r31.u64 = r30.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830be8dc
	if (cr6.eq) goto loc_830BE8DC;
	// addi r30,r1,96
	r30.s64 = ctx.r1.s64 + 96;
loc_830BE77C:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x830be8ac
	if (cr6.eq) goto loc_830BE8AC;
	// li r3,1
	ctx.r3.s64 = 1;
	// mr r28,r29
	r28.u64 = r29.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830be828
	if (cr6.eq) goto loc_830BE828;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// lwz r8,20(r21)
	ctx.r8.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// lwz r7,256(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 256);
	// add r10,r11,r26
	ctx.r10.u64 = r11.u64 + r26.u64;
loc_830BE7AC:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r6,80(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// bge cr6,0x830be7c8
	if (!cr6.lt) goto loc_830BE7C8;
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BE7C8:
	// lwz r6,76(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 76);
	// cmplw cr6,r6,r4
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, xer);
	// ble cr6,0x830be7d8
	if (!cr6.gt) goto loc_830BE7D8;
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BE7D8:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x830be7ec
	if (!cr6.eq) goto loc_830BE7EC;
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r6,2
	cr6.compare<uint32_t>(ctx.r6.u32, 2, xer);
	// beq cr6,0x830be804
	if (cr6.eq) goto loc_830BE804;
loc_830BE7EC:
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x830be80c
	if (!cr6.eq) goto loc_830BE80C;
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r6,3
	cr6.compare<uint32_t>(ctx.r6.u32, 3, xer);
	// bne cr6,0x830be80c
	if (!cr6.eq) goto loc_830BE80C;
loc_830BE804:
	// addi r28,r28,-1
	r28.s64 = r28.s64 + -1;
	// b 0x830be81c
	goto loc_830BE81C;
loc_830BE80C:
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// bge cr6,0x830be81c
	if (!cr6.lt) goto loc_830BE81C;
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BE81C:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830be7ac
	if (!cr0.eq) goto loc_830BE7AC;
loc_830BE828:
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
loc_830BE830:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830be898
	if (cr6.eq) goto loc_830BE898;
	// lwz r10,24(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830be898
	if (cr6.eq) goto loc_830BE898;
	// lwz r7,20(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_830BE85C:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmplw cr6,r9,r4
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r4.u32, xer);
	// ble cr6,0x830be87c
	if (!cr6.gt) goto loc_830BE87C;
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x830be888
	if (!cr6.eq) goto loc_830BE888;
loc_830BE87C:
	// lwz r11,80(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// bge cr6,0x830be88c
	if (!cr6.lt) goto loc_830BE88C;
loc_830BE888:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BE88C:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x830be85c
	if (!cr0.eq) goto loc_830BE85C;
loc_830BE898:
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// bne 0x830be830
	if (!cr0.eq) goto loc_830BE830;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830be8c0
	if (!cr6.eq) goto loc_830BE8C0;
loc_830BE8AC:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r31,r23
	cr6.compare<uint32_t>(r31.u32, r23.u32, xer);
	// blt cr6,0x830be77c
	if (cr6.lt) goto loc_830BE77C;
	// b 0x830be8dc
	goto loc_830BE8DC;
loc_830BE8C0:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// beq cr6,0x830be8dc
	if (cr6.eq) goto loc_830BE8DC;
	// cmplwi cr6,r28,2
	cr6.compare<uint32_t>(r28.u32, 2, xer);
	// bge cr6,0x830be8f8
	if (!cr6.lt) goto loc_830BE8F8;
loc_830BE8DC:
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// add r26,r17,r26
	r26.u64 = r17.u64 + r26.u64;
	// cmplw cr6,r19,r18
	cr6.compare<uint32_t>(r19.u32, r18.u32, xer);
	// blt cr6,0x830be468
	if (cr6.lt) goto loc_830BE468;
loc_830BE8EC:
	// li r3,1
	ctx.r3.s64 = 1;
loc_830BE8F0:
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// b 0x82ca2c00
	return;
loc_830BE8F8:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830be918
	if (cr0.eq) goto loc_830BE918;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r27,0
	r27.s64 = 0;
	// b 0x830be920
	goto loc_830BE920;
loc_830BE918:
	// li r27,0
	r27.s64 = 0;
	// mr r29,r27
	r29.u64 = r27.u64;
loc_830BE920:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x830be934
	if (!cr6.eq) goto loc_830BE934;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830be8f0
	goto loc_830BE8F0;
loc_830BE934:
	// li r11,1801
	r11.s64 = 1801;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,20,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// rlwinm r5,r28,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bge 0x830be974
	if (!cr0.lt) goto loc_830BE974;
loc_830BE960:
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x830be8f0
	goto loc_830BE8F0;
loc_830BE974:
	// lwz r4,260(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// bl 0x83079640
	sub_83079640(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830be990
	if (!cr0.lt) goto loc_830BE990;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_830BE988:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x830be960
	goto loc_830BE960;
loc_830BE990:
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830bea20
	if (cr6.eq) goto loc_830BEA20;
	// mr r11,r27
	r11.u64 = r27.u64;
	// rlwinm r10,r28,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
loc_830BE9A4:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830be9d0
	if (cr6.eq) goto loc_830BE9D0;
	// lwz r8,8(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r8,0(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stwx r8,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r8.u32);
	// lwz r8,8(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// stwx r8,r10,r7
	PPC_STORE_U32(ctx.r10.u32 + ctx.r7.u32, ctx.r8.u32);
	// b 0x830bea0c
	goto loc_830BEA0C;
loc_830BE9D0:
	// cmpwi cr6,r14,-1
	cr6.compare<int32_t>(r14.s32, -1, xer);
	// bne cr6,0x830be9f4
	if (!cr6.eq) goto loc_830BE9F4;
	// cmpwi cr6,r15,-1
	cr6.compare<int32_t>(r15.s32, -1, xer);
	// beq cr6,0x830bec7c
	if (cr6.eq) goto loc_830BEC7C;
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// stwx r15,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, r15.u32);
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// stwx r15,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, r15.u32);
	// b 0x830bea0c
	goto loc_830BEA0C;
loc_830BE9F4:
	// cmpwi cr6,r15,-1
	cr6.compare<int32_t>(r15.s32, -1, xer);
	// bne cr6,0x830bec7c
	if (!cr6.eq) goto loc_830BEC7C;
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// stwx r14,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, r14.u32);
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// stwx r14,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, r14.u32);
loc_830BEA0C:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r28
	cr6.compare<uint32_t>(ctx.r9.u32, r28.u32, xer);
	// blt cr6,0x830be9a4
	if (cr6.lt) goto loc_830BE9A4;
loc_830BEA20:
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830bea9c
	if (cr6.eq) goto loc_830BEA9C;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
loc_830BEA3C:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// lwz r10,20(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r5,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// bne cr6,0x830bea60
	if (!cr6.eq) goto loc_830BEA60;
	// lwz r5,16(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplwi cr6,r5,2
	cr6.compare<uint32_t>(ctx.r5.u32, 2, xer);
	// beq cr6,0x830bea84
	if (cr6.eq) goto loc_830BEA84;
loc_830BEA60:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x830bea74
	if (!cr6.eq) goto loc_830BEA74;
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// beq cr6,0x830bea84
	if (cr6.eq) goto loc_830BEA84;
loc_830BEA74:
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// stwx r11,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, r11.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
loc_830BEA84:
	// cmplw cr6,r7,r28
	cr6.compare<uint32_t>(ctx.r7.u32, r28.u32, xer);
	// bgt cr6,0x830beca0
	if (cr6.gt) goto loc_830BECA0;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r6,r23
	cr6.compare<uint32_t>(ctx.r6.u32, r23.u32, xer);
	// blt cr6,0x830bea3c
	if (cr6.lt) goto loc_830BEA3C;
loc_830BEA9C:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830beb48
	if (cr6.eq) goto loc_830BEB48;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// li r7,1
	ctx.r7.s64 = 1;
loc_830BEAB4:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// bge cr6,0x830beb30
	if (!cr6.lt) goto loc_830BEB30;
	// addi r11,r10,4
	r11.s64 = ctx.r10.s64 + 4;
loc_830BEAC4:
	// lwz r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r8,20(r21)
	ctx.r8.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// lwzx r3,r10,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r31,r9,2,0,29
	r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r3,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r8.u32);
	// lwzx r8,r31,r8
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + ctx.r8.u32);
	// lwz r3,16(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r31,16(r8)
	r31.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmplw cr6,r3,r31
	cr6.compare<uint32_t>(ctx.r3.u32, r31.u32, xer);
	// ble cr6,0x830beb0c
	if (!cr6.gt) goto loc_830BEB0C;
	// lwz r3,16(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r31,r10,r3
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// lwzx r28,r11,r3
	r28.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
	// lwz r3,16(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// stwx r28,r10,r3
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, r28.u32);
loc_830BEB0C:
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// beq cr6,0x830beca8
	if (cr6.eq) goto loc_830BECA8;
	// lwz r9,12(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r6,r9
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r9.u32, xer);
	// blt cr6,0x830beac4
	if (cr6.lt) goto loc_830BEAC4;
loc_830BEB30:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x830beab4
	if (cr6.lt) goto loc_830BEAB4;
loc_830BEB48:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x830beb80
	if (cr6.eq) goto loc_830BEB80;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
loc_830BEB58:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830beb74
	if (cr6.eq) goto loc_830BEB74;
	// lwz r8,24(r21)
	ctx.r8.u64 = PPC_LOAD_U32(r21.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// stw r27,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r27.u32);
loc_830BEB74:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830beb58
	if (!cr0.eq) goto loc_830BEB58;
loc_830BEB80:
	// lis r11,4096
	r11.s64 = 268435456;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// ori r10,r11,2
	ctx.r10.u64 = r11.u64 | 2;
	// beq cr6,0x830bebe8
	if (cr6.eq) goto loc_830BEBE8;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// lwz r11,0(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 0);
	// ori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 | 1;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830bebe4
	if (cr6.eq) goto loc_830BEBE4;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bebe8
	if (!cr6.eq) goto loc_830BEBE8;
	// lwz r11,8(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 8);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r9,r15
	cr6.compare<uint32_t>(ctx.r9.u32, r15.u32, xer);
	// bne cr6,0x830bebcc
	if (!cr6.eq) goto loc_830BEBCC;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r9,r14
	cr6.compare<uint32_t>(ctx.r9.u32, r14.u32, xer);
	// bne cr6,0x830bebcc
	if (!cr6.eq) goto loc_830BEBCC;
	// stw r27,0(r16)
	PPC_STORE_U32(r16.u32 + 0, r27.u32);
loc_830BEBCC:
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r9,r15
	cr6.compare<uint32_t>(ctx.r9.u32, r15.u32, xer);
	// bne cr6,0x830bebe8
	if (!cr6.eq) goto loc_830BEBE8;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r11,r14
	cr6.compare<uint32_t>(r11.u32, r14.u32, xer);
	// bne cr6,0x830bebe8
	if (!cr6.eq) goto loc_830BEBE8;
loc_830BEBE4:
	// stw r27,0(r16)
	PPC_STORE_U32(r16.u32 + 0, r27.u32);
loc_830BEBE8:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830bec48
	if (cr6.eq) goto loc_830BEC48;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// ori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 | 1;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830bec44
	if (cr6.eq) goto loc_830BEC44;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bec48
	if (!cr6.eq) goto loc_830BEC48;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r15
	cr6.compare<uint32_t>(ctx.r10.u32, r15.u32, xer);
	// bne cr6,0x830bec2c
	if (!cr6.eq) goto loc_830BEC2C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r14
	cr6.compare<uint32_t>(ctx.r10.u32, r14.u32, xer);
	// bne cr6,0x830bec2c
	if (!cr6.eq) goto loc_830BEC2C;
	// stw r27,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r27.u32);
loc_830BEC2C:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r15
	cr6.compare<uint32_t>(ctx.r10.u32, r15.u32, xer);
	// bne cr6,0x830bec48
	if (!cr6.eq) goto loc_830BEC48;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r11,r14
	cr6.compare<uint32_t>(r11.u32, r14.u32, xer);
	// bne cr6,0x830bec48
	if (!cr6.eq) goto loc_830BEC48;
loc_830BEC44:
	// stw r27,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r27.u32);
loc_830BEC48:
	// lwz r11,24(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 24);
	// rlwinm r31,r30,2,0,29
	r31.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r31
	r30.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830bec6c
	if (cr6.eq) goto loc_830BEC6C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
loc_830BEC6C:
	// lwz r11,24(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 24);
	// li r3,0
	ctx.r3.s64 = 0;
	// stwx r29,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, r29.u32);
	// b 0x830be8f0
	goto loc_830BE8F0;
loc_830BEC7C:
	// li r5,4825
	ctx.r5.s64 = 4825;
loc_830BEC80:
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// addi r6,r10,-32340
	ctx.r6.s64 = ctx.r10.s64 + -32340;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// li r31,1
	r31.s64 = 1;
	// b 0x830be988
	goto loc_830BE988;
loc_830BECA0:
	// li r5,4826
	ctx.r5.s64 = 4826;
	// b 0x830bec80
	goto loc_830BEC80;
loc_830BECA8:
	// lwz r11,260(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 260);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r5,4827
	ctx.r5.s64 = 4827;
	// addi r6,r10,-9056
	ctx.r6.s64 = ctx.r10.s64 + -9056;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
	// b 0x830be988
	goto loc_830BE988;
}

__attribute__((alias("__imp__sub_830BECD0"))) PPC_WEAK_FUNC(sub_830BECD0);
PPC_FUNC_IMPL(__imp__sub_830BECD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r25,0
	r25.s64 = 0;
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bed78
	if (cr6.eq) goto loc_830BED78;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r30,r25
	r30.u64 = r25.u64;
	// stw r25,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r25.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bed78
	if (!cr6.gt) goto loc_830BED78;
loc_830BED04:
	// lwz r11,256(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// lis r10,8320
	ctx.r10.s64 = 545259520;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bed4c
	if (!cr6.eq) goto loc_830BED4C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061e20
	sub_83061E20(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf050
	if (cr0.lt) goto loc_830BF050;
	// subf r11,r25,r3
	r11.s64 = ctx.r3.s64 - r25.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or r30,r11,r30
	r30.u64 = r11.u64 | r30.u64;
loc_830BED4C:
	// lwz r11,256(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r11.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x830bed04
	if (cr6.lt) goto loc_830BED04;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x830bed78
	if (cr6.eq) goto loc_830BED78;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
loc_830BED78:
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830beec0
	if (!cr0.eq) goto loc_830BEEC0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r30,r25
	r30.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bedd4
	if (!cr6.gt) goto loc_830BEDD4;
	// mr r29,r25
	r29.u64 = r25.u64;
loc_830BED98:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// bl 0x830be418
	sub_830BE418(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830bedc0
	if (!cr0.eq) goto loc_830BEDC0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
loc_830BEDC0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bed98
	if (cr6.lt) goto loc_830BED98;
loc_830BEDD4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r30,r25
	r30.u64 = r25.u64;
	// lis r28,20480
	r28.s64 = 1342177280;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bee30
	if (!cr6.gt) goto loc_830BEE30;
	// mr r29,r25
	r29.u64 = r25.u64;
loc_830BEDEC:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x830bee1c
	if (!cr6.eq) goto loc_830BEE1C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830bd3e8
	sub_830BD3E8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf050
	if (cr0.lt) goto loc_830BF050;
loc_830BEE1C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bedec
	if (cr6.lt) goto loc_830BEDEC;
loc_830BEE30:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r30,r25
	r30.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830beec0
	if (!cr6.gt) goto loc_830BEEC0;
	// mr r29,r25
	r29.u64 = r25.u64;
loc_830BEE4C:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lis r10,4144
	ctx.r10.s64 = 271581184;
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bee9c
	if (cr6.eq) goto loc_830BEE9C;
	// lis r10,4176
	ctx.r10.s64 = 273678336;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bee9c
	if (cr6.eq) goto loc_830BEE9C;
	// lis r10,4192
	ctx.r10.s64 = 274726912;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bee9c
	if (cr6.eq) goto loc_830BEE9C;
	// lis r10,4208
	ctx.r10.s64 = 275775488;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bee9c
	if (cr6.eq) goto loc_830BEE9C;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x830beeac
	if (!cr6.eq) goto loc_830BEEAC;
loc_830BEE9C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83063678
	sub_83063678(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf050
	if (cr0.lt) goto loc_830BF050;
loc_830BEEAC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bee4c
	if (cr6.lt) goto loc_830BEE4C;
loc_830BEEC0:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bf018
	if (cr6.eq) goto loc_830BF018;
	// mr r26,r25
	r26.u64 = r25.u64;
loc_830BEED0:
	// cmplwi cr6,r26,16
	cr6.compare<uint32_t>(r26.u32, 16, xer);
	// bge cr6,0x830bef68
	if (!cr6.lt) goto loc_830BEF68;
	// lwz r28,12(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r27,1
	r27.s64 = 1;
	// mr r30,r25
	r30.u64 = r25.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830bef44
	if (cr6.eq) goto loc_830BEF44;
	// mr r29,r25
	r29.u64 = r25.u64;
loc_830BEEF0:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// bl 0x83062458
	sub_83062458(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf050
	if (cr0.lt) goto loc_830BF050;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830bef18
	if (!cr6.eq) goto loc_830BEF18;
	// mr r27,r25
	r27.u64 = r25.u64;
loc_830BEF18:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,260(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf050
	if (cr0.lt) goto loc_830BF050;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// stw r25,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r25.u32);
	// blt cr6,0x830beef0
	if (cr6.lt) goto loc_830BEEF0;
loc_830BEF44:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307f3a8
	sub_8307F3A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf050
	if (cr0.lt) goto loc_830BF050;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x830beed0
	if (cr6.eq) goto loc_830BEED0;
	// cmplwi cr6,r26,16
	cr6.compare<uint32_t>(r26.u32, 16, xer);
	// blt cr6,0x830bf018
	if (cr6.lt) goto loc_830BF018;
loc_830BEF68:
	// lwz r28,12(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r26,1
	r26.s64 = 1;
	// mr r30,r25
	r30.u64 = r25.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830beff4
	if (cr6.eq) goto loc_830BEFF4;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// mr r29,r25
	r29.u64 = r25.u64;
	// addi r27,r11,-5260
	r27.s64 = r11.s64 + -5260;
loc_830BEF88:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// bl 0x83062458
	sub_83062458(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf050
	if (cr0.lt) goto loc_830BF050;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830befc8
	if (!cr6.eq) goto loc_830BEFC8;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// li r5,4553
	ctx.r5.s64 = 4553;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// mr r26,r25
	r26.u64 = r25.u64;
loc_830BEFC8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,260(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf050
	if (cr0.lt) goto loc_830BF050;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// stw r25,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r25.u32);
	// blt cr6,0x830bef88
	if (cr6.lt) goto loc_830BEF88;
loc_830BEFF4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307f3a8
	sub_8307F3A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf050
	if (cr0.lt) goto loc_830BF050;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// bne cr6,0x830bf018
	if (!cr6.eq) goto loc_830BF018;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830bf050
	goto loc_830BF050;
loc_830BF018:
	// lwz r11,96(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bf04c
	if (cr6.eq) goto loc_830BF04C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306e498
	sub_8306E498(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf050
	if (cr0.lt) goto loc_830BF050;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83061a80
	sub_83061A80(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830878b8
	sub_830878B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf050
	if (cr0.lt) goto loc_830BF050;
loc_830BF04C:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_830BF050:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830BF058"))) PPC_WEAK_FUNC(sub_830BF058);
PPC_FUNC_IMPL(__imp__sub_830BF058) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r22,r5
	r22.u64 = ctx.r5.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x830bf080
	if (!cr6.eq) goto loc_830BF080;
loc_830BF078:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830bf294
	goto loc_830BF294;
loc_830BF080:
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r10,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830bf290
	if (cr0.eq) goto loc_830BF290;
	// lis r9,8304
	ctx.r9.s64 = 544210944;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830bf290
	if (cr6.eq) goto loc_830BF290;
	// lwz r9,4(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// lis r8,28752
	ctx.r8.s64 = 1884291072;
	// divwu r24,r9,r10
	r24.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x830bf0cc
	if (cr6.eq) goto loc_830BF0CC;
	// lis r9,28768
	ctx.r9.s64 = 1885339648;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x830bf0cc
	if (cr6.eq) goto loc_830BF0CC;
	// lis r9,28784
	ctx.r9.s64 = 1886388224;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x830bf0d0
	if (!cr6.eq) goto loc_830BF0D0;
loc_830BF0CC:
	// li r24,2
	r24.s64 = 2;
loc_830BF0D0:
	// cmplwi cr6,r24,1
	cr6.compare<uint32_t>(r24.u32, 1, xer);
	// ble cr6,0x830bf290
	if (!cr6.gt) goto loc_830BF290;
	// lwz r11,128(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwz r8,136(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// li r26,0
	r26.s64 = 0;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,124(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 124);
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r26,r5,r9
	PPC_STORE_U32(ctx.r5.u32 + ctx.r9.u32, r26.u32);
	// addi r30,r1,80
	r30.s64 = ctx.r1.s64 + 80;
	// addi r28,r1,160
	r28.s64 = ctx.r1.s64 + 160;
	// li r11,1
	r11.s64 = 1;
	// stwx r26,r8,r4
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, r26.u32);
	// li r9,3
	ctx.r9.s64 = 3;
	// stwx r11,r5,r7
	PPC_STORE_U32(ctx.r5.u32 + ctx.r7.u32, r11.u32);
	// mr r23,r26
	r23.u64 = r26.u64;
	// stwx r9,r8,r3
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, ctx.r9.u32);
	// mr r29,r26
	r29.u64 = r26.u64;
	// stwx r26,r6,r30
	PPC_STORE_U32(ctx.r6.u32 + r30.u32, r26.u32);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// stwx r11,r6,r28
	PPC_STORE_U32(ctx.r6.u32 + r28.u32, r11.u32);
	// beq cr6,0x830bf290
	if (cr6.eq) goto loc_830BF290;
	// rlwinm r25,r10,2,0,29
	r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r28,r26
	r28.u64 = r26.u64;
loc_830BF144:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r10,r11,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bf184
	if (cr0.eq) goto loc_830BF184;
	// rlwinm. r9,r11,0,24,24
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830bf184
	if (!cr0.eq) goto loc_830BF184;
	// lwz r6,124(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 124);
	// b 0x830bf1d0
	goto loc_830BF1D0;
loc_830BF184:
	// rlwinm. r9,r11,0,24,24
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830bf194
	if (cr0.eq) goto loc_830BF194;
	// lwz r6,148(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 148);
	// b 0x830bf1d0
	goto loc_830BF1D0;
loc_830BF194:
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830bf1cc
	if (cr0.eq) goto loc_830BF1CC;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830bf1cc
	if (!cr6.eq) goto loc_830BF1CC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,108(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r3,65535
	cr6.compare<uint32_t>(ctx.r3.u32, 65535, xer);
	// beq cr6,0x830bf1cc
	if (cr6.eq) goto loc_830BF1CC;
	// lwz r6,128(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// b 0x830bf1d0
	goto loc_830BF1D0;
loc_830BF1CC:
	// lwz r6,136(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 136);
loc_830BF1D0:
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830bf230
	if (cr6.eq) goto loc_830BF230;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
loc_830BF1E8:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r5,4(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r7,r5
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, xer);
	// bne cr6,0x830bf220
	if (!cr6.eq) goto loc_830BF220;
	// lwz r5,8(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r4,8(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// bne cr6,0x830bf220
	if (!cr6.eq) goto loc_830BF220;
	// lwz r5,12(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf230
	if (cr6.eq) goto loc_830BF230;
loc_830BF220:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// add r11,r25,r11
	r11.u64 = r25.u64 + r11.u64;
	// cmplw cr6,r9,r29
	cr6.compare<uint32_t>(ctx.r9.u32, r29.u32, xer);
	// blt cr6,0x830bf1e8
	if (cr6.lt) goto loc_830BF1E8;
loc_830BF230:
	// cmplw cr6,r9,r29
	cr6.compare<uint32_t>(ctx.r9.u32, r29.u32, xer);
	// bne cr6,0x830bf25c
	if (!cr6.eq) goto loc_830BF25C;
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// lwzx r10,r11,r9
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bgt cr6,0x830bf29c
	if (cr6.gt) goto loc_830BF29C;
loc_830BF25C:
	// lhz r11,202(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 202);
	// cmplwi cr6,r11,512
	cr6.compare<uint32_t>(r11.u32, 512, xer);
	// blt cr6,0x830bf280
	if (cr6.lt) goto loc_830BF280;
	// lwz r11,124(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 124);
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// bne cr6,0x830bf280
	if (!cr6.eq) goto loc_830BF280;
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// cmplwi cr6,r23,2
	cr6.compare<uint32_t>(r23.u32, 2, xer);
	// bgt cr6,0x830bf29c
	if (cr6.gt) goto loc_830BF29C;
loc_830BF280:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// add r28,r25,r28
	r28.u64 = r25.u64 + r28.u64;
	// cmplw cr6,r29,r24
	cr6.compare<uint32_t>(r29.u32, r24.u32, xer);
	// blt cr6,0x830bf144
	if (cr6.lt) goto loc_830BF144;
loc_830BF290:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BF294:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// b 0x82ca2c20
	return;
loc_830BF29C:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x830bf078
	if (cr6.eq) goto loc_830BF078;
	// stw r29,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r29.u32);
	// b 0x830bf078
	goto loc_830BF078;
}

__attribute__((alias("__imp__sub_830BF2B0"))) PPC_WEAK_FUNC(sub_830BF2B0);
PPC_FUNC_IMPL(__imp__sub_830BF2B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bf300
	if (!cr6.gt) goto loc_830BF300;
	// li r29,0
	r29.s64 = 0;
loc_830BF2D4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// bl 0x83062368
	sub_83062368(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bf2d4
	if (cr6.lt) goto loc_830BF2D4;
loc_830BF300:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830bf84c
	if (!cr6.gt) goto loc_830BF84C;
	// lis r11,-32768
	r11.s64 = -2147483648;
	// lis r28,28768
	r28.s64 = 1885339648;
	// lis r22,8240
	r22.s64 = 540016640;
	// lis r23,4208
	r23.s64 = 275775488;
	// lis r24,20528
	r24.s64 = 1345323008;
	// lis r25,29600
	r25.s64 = 1939865600;
	// lis r26,29488
	r26.s64 = 1932525568;
	// lis r27,29728
	r27.s64 = 1948254208;
	// ori r29,r11,16385
	r29.u64 = r11.u64 | 16385;
loc_830BF334:
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r11,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r11.u32);
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bf368
	if (cr6.eq) goto loc_830BF368;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x830bf368
	if (!cr6.eq) goto loc_830BF368;
	// addi r11,r11,48
	r11.s64 = r11.s64 + 48;
	// stw r11,264(r31)
	PPC_STORE_U32(r31.u32 + 264, r11.u32);
loc_830BF368:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83077d08
	sub_83077D08(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bf850
	if (cr0.lt) goto loc_830BF850;
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bgt cr6,0x830bf608
	if (cr6.gt) goto loc_830BF608;
	// beq cr6,0x830bf5cc
	if (cr6.eq) goto loc_830BF5CC;
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// bgt cr6,0x830bf4dc
	if (cr6.gt) goto loc_830BF4DC;
	// beq cr6,0x830bf4d0
	if (cr6.eq) goto loc_830BF4D0;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// bgt cr6,0x830bf458
	if (cr6.gt) goto loc_830BF458;
	// beq cr6,0x830bf44c
	if (cr6.eq) goto loc_830BF44C;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bf440
	if (cr6.eq) goto loc_830BF440;
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf434
	if (cr6.eq) goto loc_830BF434;
	// lis r10,4112
	ctx.r10.s64 = 269484032;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf428
	if (cr6.eq) goto loc_830BF428;
	// lis r10,4144
	ctx.r10.s64 = 271581184;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf41c
	if (cr6.eq) goto loc_830BF41C;
	// lis r10,4160
	ctx.r10.s64 = 272629760;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf410
	if (cr6.eq) goto loc_830BF410;
	// lis r10,4176
	ctx.r10.s64 = 273678336;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf404
	if (cr6.eq) goto loc_830BF404;
	// lis r10,4192
	ctx.r10.s64 = 274726912;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bf858
	if (!cr6.eq) goto loc_830BF858;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830bdff0
	sub_830BDFF0(ctx, base);
	// b 0x830bf834
	goto loc_830BF834;
loc_830BF404:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830bdcb0
	sub_830BDCB0(ctx, base);
	// b 0x830bf834
	goto loc_830BF834;
loc_830BF410:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,136(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 136);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF41C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,132(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 132);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF428:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,128(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 128);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF434:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,124(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 124);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF440:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,120(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 120);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF44C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,152(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 152);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF458:
	// lis r10,4336
	ctx.r10.s64 = 284164096;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf71c
	if (cr6.eq) goto loc_830BF71C;
	// lis r10,4384
	ctx.r10.s64 = 287309824;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf434
	if (cr6.eq) goto loc_830BF434;
	// lis r10,4400
	ctx.r10.s64 = 288358400;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf83c
	if (cr6.eq) goto loc_830BF83C;
	// lis r10,4432
	ctx.r10.s64 = 290455552;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf434
	if (cr6.eq) goto loc_830BF434;
	// lis r10,8192
	ctx.r10.s64 = 536870912;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf4c4
	if (cr6.eq) goto loc_830BF4C4;
	// lis r10,8208
	ctx.r10.s64 = 537919488;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf4b8
	if (cr6.eq) goto loc_830BF4B8;
	// lis r10,8224
	ctx.r10.s64 = 538968064;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bf858
	if (!cr6.eq) goto loc_830BF858;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,164(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 164);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF4B8:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,160(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 160);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF4C4:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,156(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 156);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF4D0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,168(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 168);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF4DC:
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bgt cr6,0x830bf584
	if (cr6.gt) goto loc_830BF584;
	// beq cr6,0x830bf578
	if (cr6.eq) goto loc_830BF578;
	// lis r10,8256
	ctx.r10.s64 = 541065216;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf56c
	if (cr6.eq) goto loc_830BF56C;
	// lis r10,8272
	ctx.r10.s64 = 542113792;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf560
	if (cr6.eq) goto loc_830BF560;
	// lis r10,8304
	ctx.r10.s64 = 544210944;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf554
	if (cr6.eq) goto loc_830BF554;
	// lis r10,8320
	ctx.r10.s64 = 545259520;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf83c
	if (cr6.eq) goto loc_830BF83C;
	// lis r10,8336
	ctx.r10.s64 = 546308096;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf434
	if (cr6.eq) goto loc_830BF434;
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf548
	if (cr6.eq) goto loc_830BF548;
	// lis r10,20496
	ctx.r10.s64 = 1343225856;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bf858
	if (!cr6.eq) goto loc_830BF858;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,184(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 184);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF548:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,180(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 180);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF554:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,260(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 260);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF560:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,176(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 176);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF56C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,172(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 172);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF578:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,232(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 232);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF584:
	// lis r10,28672
	ctx.r10.s64 = 1879048192;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf5fc
	if (cr6.eq) goto loc_830BF5FC;
	// lis r10,28688
	ctx.r10.s64 = 1880096768;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf5f0
	if (cr6.eq) goto loc_830BF5F0;
	// lis r10,28704
	ctx.r10.s64 = 1881145344;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf5e4
	if (cr6.eq) goto loc_830BF5E4;
	// lis r10,28720
	ctx.r10.s64 = 1882193920;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf5d8
	if (cr6.eq) goto loc_830BF5D8;
	// lis r10,28736
	ctx.r10.s64 = 1883242496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf5d8
	if (cr6.eq) goto loc_830BF5D8;
	// lis r10,28752
	ctx.r10.s64 = 1884291072;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bf858
	if (!cr6.eq) goto loc_830BF858;
loc_830BF5CC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,216(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 216);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF5D8:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,208(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 208);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF5E4:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,204(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 204);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF5F0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,200(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 200);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF5FC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,196(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 196);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF608:
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bgt cr6,0x830bf734
	if (cr6.gt) goto loc_830BF734;
	// beq cr6,0x830bf710
	if (cr6.eq) goto loc_830BF710;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bgt cr6,0x830bf6c8
	if (cr6.gt) goto loc_830BF6C8;
	// beq cr6,0x830bf67c
	if (cr6.eq) goto loc_830BF67C;
	// lis r10,28784
	ctx.r10.s64 = 1886388224;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf5cc
	if (cr6.eq) goto loc_830BF5CC;
	// lis r10,28816
	ctx.r10.s64 = 1888485376;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf6bc
	if (cr6.eq) goto loc_830BF6BC;
	// lis r10,28880
	ctx.r10.s64 = 1892679680;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf6b0
	if (cr6.eq) goto loc_830BF6B0;
	// lis r10,28928
	ctx.r10.s64 = 1895825408;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf6a4
	if (cr6.eq) goto loc_830BF6A4;
	// lis r10,29440
	ctx.r10.s64 = 1929379840;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf688
	if (cr6.eq) goto loc_830BF688;
	// lis r10,29456
	ctx.r10.s64 = 1930428416;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf67c
	if (cr6.eq) goto loc_830BF67C;
	// lis r10,29472
	ctx.r10.s64 = 1931476992;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bf858
	if (!cr6.eq) goto loc_830BF858;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x830bf68c
	goto loc_830BF68C;
loc_830BF67C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,296(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 296);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF688:
	// li r4,0
	ctx.r4.s64 = 0;
loc_830BF68C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,292(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 292);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x830bf834
	goto loc_830BF834;
loc_830BF6A4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830bd8b0
	sub_830BD8B0(ctx, base);
	// b 0x830bf834
	goto loc_830BF834;
loc_830BF6B0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,148(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF6BC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,212(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 212);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF6C8:
	// lis r10,29504
	ctx.r10.s64 = 1933574144;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf728
	if (cr6.eq) goto loc_830BF728;
	// lis r10,29520
	ctx.r10.s64 = 1934622720;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf71c
	if (cr6.eq) goto loc_830BF71C;
	// lis r10,29536
	ctx.r10.s64 = 1935671296;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf71c
	if (cr6.eq) goto loc_830BF71C;
	// lis r10,29552
	ctx.r10.s64 = 1936719872;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf71c
	if (cr6.eq) goto loc_830BF71C;
	// lis r10,29568
	ctx.r10.s64 = 1937768448;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf71c
	if (cr6.eq) goto loc_830BF71C;
	// lis r10,29584
	ctx.r10.s64 = 1938817024;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bf858
	if (!cr6.eq) goto loc_830BF858;
loc_830BF710:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,288(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 288);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF71C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,256(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 256);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF728:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,300(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 300);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF734:
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bgt cr6,0x830bf7ac
	if (cr6.gt) goto loc_830BF7AC;
	// beq cr6,0x830bf7a0
	if (cr6.eq) goto loc_830BF7A0;
	// lis r10,29616
	ctx.r10.s64 = 1940914176;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf710
	if (cr6.eq) goto loc_830BF710;
	// lis r10,29632
	ctx.r10.s64 = 1941962752;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf710
	if (cr6.eq) goto loc_830BF710;
	// lis r10,29648
	ctx.r10.s64 = 1943011328;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf67c
	if (cr6.eq) goto loc_830BF67C;
	// lis r10,29664
	ctx.r10.s64 = 1944059904;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf67c
	if (cr6.eq) goto loc_830BF67C;
	// lis r10,29680
	ctx.r10.s64 = 1945108480;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf67c
	if (cr6.eq) goto loc_830BF67C;
	// lis r10,29696
	ctx.r10.s64 = 1946157056;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf67c
	if (cr6.eq) goto loc_830BF67C;
	// lis r10,29712
	ctx.r10.s64 = 1947205632;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bf858
	if (!cr6.eq) goto loc_830BF858;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,244(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 244);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF7A0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,236(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 236);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF7AC:
	// lis r10,29760
	ctx.r10.s64 = 1950351360;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf80c
	if (cr6.eq) goto loc_830BF80C;
	// lis r10,29776
	ctx.r10.s64 = 1951399936;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf80c
	if (cr6.eq) goto loc_830BF80C;
	// lis r10,29792
	ctx.r10.s64 = 1952448512;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf80c
	if (cr6.eq) goto loc_830BF80C;
	// lis r10,29808
	ctx.r10.s64 = 1953497088;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf80c
	if (cr6.eq) goto loc_830BF80C;
	// lis r10,29856
	ctx.r10.s64 = 1956642816;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830bf800
	if (cr6.eq) goto loc_830BF800;
	// lis r10,29872
	ctx.r10.s64 = 1957691392;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bf858
	if (!cr6.eq) goto loc_830BF858;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,240(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 240);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF800:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,248(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 248);
	// b 0x830bf820
	goto loc_830BF820;
loc_830BF80C:
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// rlwinm. r11,r11,0,3,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830bf830
	if (cr0.eq) goto loc_830BF830;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,252(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 252);
loc_830BF820:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x830bf834
	goto loc_830BF834;
loc_830BF830:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_830BF834:
	// cmpw cr6,r3,r29
	cr6.compare<int32_t>(ctx.r3.s32, r29.s32, xer);
	// beq cr6,0x830bf858
	if (cr6.eq) goto loc_830BF858;
loc_830BF83C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830bf334
	if (cr6.lt) goto loc_830BF334;
loc_830BF84C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830BF850:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
loc_830BF858:
	// lwz r11,260(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r5,4532
	ctx.r5.s64 = 4532;
	// addi r6,r10,-22560
	ctx.r6.s64 = ctx.r10.s64 + -22560;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x830bf850
	goto loc_830BF850;
}

__attribute__((alias("__imp__sub_830BF880"))) PPC_WEAK_FUNC(sub_830BF880);
PPC_FUNC_IMPL(__imp__sub_830BF880) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r4,108(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r4,108(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,116(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,348(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 348);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830bfa3c
	if (cr6.eq) goto loc_830BFA3C;
	// lwz r11,108(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830bf8ec
	if (!cr6.eq) goto loc_830BF8EC;
loc_830BF8E4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830bfc90
	goto loc_830BFC90;
loc_830BF8EC:
	// cmplwi cr6,r30,65535
	cr6.compare<uint32_t>(r30.u32, 65535, xer);
	// beq cr6,0x830bfa28
	if (cr6.eq) goto loc_830BFA28;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306eff8
	sub_8306EFF8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r5,r10,-5148
	ctx.r5.s64 = ctx.r10.s64 + -5148;
	// li r4,32
	ctx.r4.s64 = 32;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x82d16878
	sub_82D16878(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// addi r27,r31,472
	r27.s64 = r31.s64 + 472;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// stb r11,127(r1)
	PPC_STORE_U8(ctx.r1.u32 + 127, r11.u8);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83026318
	sub_83026318(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bfc90
	if (cr0.lt) goto loc_830BFC90;
	// lwz r11,500(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 500);
	// lwz r10,204(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r11,500(r31)
	PPC_STORE_U32(r31.u32 + 500, r11.u32);
	// beq 0x830bfa28
	if (cr0.eq) goto loc_830BFA28;
	// lwz r11,96(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 96);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830bfa28
	if (cr6.eq) goto loc_830BFA28;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x830bfa28
	if (!cr6.eq) goto loc_830BFA28;
	// lwz r28,20(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x830bfa28
	if (!cr6.eq) goto loc_830BFA28;
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_830BF990:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x830bf990
	if (!cr6.eq) goto loc_830BF990;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// addi r29,r11,3
	r29.s64 = r11.s64 + 3;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x830bf9d0
	if (!cr0.eq) goto loc_830BF9D0;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830bfc90
	goto loc_830BFC90;
loc_830BF9D0:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// lwz r6,24(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r5,r11,-5164
	ctx.r5.s64 = r11.s64 + -5164;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82d16878
	sub_82D16878(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83026318
	sub_83026318(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bge cr6,0x830bfa1c
	if (!cr6.lt) goto loc_830BFA1C;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x830bfc90
	goto loc_830BFC90;
loc_830BFA1C:
	// lwz r11,500(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 500);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,500(r31)
	PPC_STORE_U32(r31.u32 + 500, r11.u32);
loc_830BFA28:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830bf8e4
	if (cr6.eq) goto loc_830BF8E4;
	// lwz r11,108(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// b 0x830bf8e4
	goto loc_830BF8E4;
loc_830BFA3C:
	// cmplwi cr6,r30,14
	cr6.compare<uint32_t>(r30.u32, 14, xer);
	// bgt cr6,0x830bfc88
	if (cr6.gt) goto loc_830BFC88;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,-32304
	r12.s64 = r12.s64 + -32304;
	// lbzx r0,r12,r30
	r0.u64 = PPC_LOAD_U8(r12.u32 + r30.u32);
	// rlwinm r0,r0,2,0,29
	r0.u64 = __builtin_rotateleft64(r0.u32 | (r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-31988
	r12.s64 = -2096365568;
	// addi r12,r12,-1428
	r12.s64 = r12.s64 + -1428;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r30.u64) {
	case 0:
		goto loc_830BFCC0;
	case 1:
		goto loc_830BFA6C;
	case 2:
		goto loc_830BFC44;
	case 3:
		goto loc_830BFC4C;
	case 4:
		goto loc_830BFC54;
	case 5:
		goto loc_830BFC5C;
	case 6:
		goto loc_830BFC64;
	case 7:
		goto loc_830BFC6C;
	case 8:
		goto loc_830BFC74;
	case 9:
		goto loc_830BFC7C;
	case 10:
		goto loc_830BFC98;
	case 11:
		goto loc_830BFCA0;
	case 12:
		goto loc_830BFCA8;
	case 13:
		goto loc_830BFCB0;
	case 14:
		goto loc_830BFCB8;
	default:
		__builtin_unreachable();
	}
loc_830BFA6C:
	// li r11,0
	r11.s64 = 0;
loc_830BFA70:
	// cmplwi cr6,r29,15
	cr6.compare<uint32_t>(r29.u32, 15, xer);
	// bgt cr6,0x830bfc88
	if (cr6.gt) goto loc_830BFC88;
loc_830BFA78:
	// lis r10,-32768
	ctx.r10.s64 = -2147483648;
	// li r4,31
	ctx.r4.s64 = 31;
	// rlwimi r10,r29,16,1,15
	ctx.r10.u64 = (__builtin_rotateleft32(r29.u32, 16) & 0x7FFF0000) | (ctx.r10.u64 & 0xFFFFFFFF8000FFFF);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// or r30,r10,r11
	r30.u64 = ctx.r10.u64 | r11.u64;
	// bl 0x83073378
	sub_83073378(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bfc90
	if (cr0.lt) goto loc_830BFC90;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bfc90
	if (cr0.lt) goto loc_830BFC90;
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830bfb98
	if (cr0.eq) goto loc_830BFB98;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r11,-1
	r11.s64 = -1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// stw r11,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r11.u32);
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r11.u32);
	// ble cr6,0x830bfb40
	if (!cr6.gt) goto loc_830BFB40;
	// lwz r8,4(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
loc_830BFAF0:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// bne cr6,0x830bfb30
	if (!cr6.eq) goto loc_830BFB30;
	// lwz r6,8(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r6,r4
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, xer);
	// bne cr6,0x830bfb30
	if (!cr6.eq) goto loc_830BFB30;
	// lwz r6,12(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// lwz r4,12(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r6,r4
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, xer);
	// bne cr6,0x830bfb30
	if (!cr6.eq) goto loc_830BFB30;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r11,r6
	PPC_STORE_U32(r11.u32 + ctx.r6.u32, ctx.r9.u32);
loc_830BFB30:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// blt cr6,0x830bfaf0
	if (cr6.lt) goto loc_830BFAF0;
loc_830BFB40:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// li r8,4
	ctx.r8.s64 = 4;
loc_830BFB4C:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x830bfb64
	if (cr6.eq) goto loc_830BFB64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
loc_830BFB64:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830bfb4c
	if (!cr0.eq) goto loc_830BFB4C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,324(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 324);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bfc90
	if (cr0.lt) goto loc_830BFC90;
loc_830BFB98:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,348(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 348);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bfc90
	if (cr0.lt) goto loc_830BFC90;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-128
	ctx.r10.s64 = -8388608;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwimi r10,r11,20,9,11
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0x700000) | (ctx.r10.u64 & 0xFFFFFFFFFF8FFFFF);
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r8,r11,0,27,28
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x18;
	// clrlwi r11,r7,21
	r11.u64 = ctx.r7.u32 & 0x7FF;
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// lwz r9,312(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 312);
	// lis r5,15
	ctx.r5.s64 = 983040;
	// rlwinm r10,r10,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// or r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 | r11.u64;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bfc90
	if (cr0.lt) goto loc_830BFC90;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,308(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 308);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bfc90
	if (cr0.lt) goto loc_830BFC90;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306ab90
	sub_8306AB90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bfc90
	if (cr0.lt) goto loc_830BFC90;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830bf8e4
	if (cr6.eq) goto loc_830BF8E4;
	// stw r30,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r30.u32);
	// b 0x830bf8e4
	goto loc_830BF8E4;
loc_830BFC44:
	// li r11,1
	r11.s64 = 1;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFC4C:
	// li r11,2
	r11.s64 = 2;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFC54:
	// li r11,3
	r11.s64 = 3;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFC5C:
	// li r11,4
	r11.s64 = 4;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFC64:
	// li r11,5
	r11.s64 = 5;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFC6C:
	// li r11,6
	r11.s64 = 6;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFC74:
	// li r11,7
	r11.s64 = 7;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFC7C:
	// li r11,8
	r11.s64 = 8;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830bfa78
	if (cr6.eq) goto loc_830BFA78;
loc_830BFC88:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_830BFC90:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c2c
	return;
loc_830BFC98:
	// li r11,9
	r11.s64 = 9;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFCA0:
	// li r11,10
	r11.s64 = 10;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFCA8:
	// li r11,11
	r11.s64 = 11;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFCB0:
	// li r11,12
	r11.s64 = 12;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFCB8:
	// li r11,13
	r11.s64 = 13;
	// b 0x830bfa70
	goto loc_830BFA70;
loc_830BFCC0:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830bfc90
	goto loc_830BFC90;
}

__attribute__((alias("__imp__sub_830BFCC8"))) PPC_WEAK_FUNC(sub_830BFCC8);
PPC_FUNC_IMPL(__imp__sub_830BFCC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x8306ae98
	sub_8306AE98(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r30,224(r31)
	PPC_STORE_U32(r31.u32 + 224, r30.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,-32288
	r11.s64 = r11.s64 + -32288;
	// stw r10,508(r31)
	PPC_STORE_U32(r31.u32 + 508, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BFD20"))) PPC_WEAK_FUNC(sub_830BFD20);
PPC_FUNC_IMPL(__imp__sub_830BFD20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r3,r11,31236
	ctx.r3.s64 = r11.s64 + 31236;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8301d1e0
	sub_8301D1E0(ctx, base);
	// li r11,64
	r11.s64 = 64;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// li r9,8192
	ctx.r9.s64 = 8192;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r10.u32);
	// stw r9,56(r31)
	PPC_STORE_U32(r31.u32 + 56, ctx.r9.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r10,112(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// rlwinm r11,r11,0,10,8
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFBFFFFF;
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// oris r10,r10,32800
	ctx.r10.u64 = ctx.r10.u64 | 2149580800;
	// rlwinm r11,r11,0,2,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r10,112(r31)
	PPC_STORE_U32(r31.u32 + 112, ctx.r10.u32);
	// oris r11,r11,9248
	r11.u64 = r11.u64 | 606076928;
	// stw r9,268(r31)
	PPC_STORE_U32(r31.u32 + 268, ctx.r9.u32);
	// stw r11,108(r31)
	PPC_STORE_U32(r31.u32 + 108, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BFDA8"))) PPC_WEAK_FUNC(sub_830BFDA8);
PPC_FUNC_IMPL(__imp__sub_830BFDA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r10,r11,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bfddc
	if (cr0.eq) goto loc_830BFDDC;
	// li r4,1
	ctx.r4.s64 = 1;
loc_830BFDD4:
	// bl 0x83070600
	sub_83070600(ctx, base);
	// b 0x830bfebc
	goto loc_830BFEBC;
loc_830BFDDC:
	// rlwinm. r10,r11,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bfdf4
	if (cr0.eq) goto loc_830BFDF4;
	// rlwinm. r9,r11,0,24,24
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830bfdf4
	if (cr0.eq) goto loc_830BFDF4;
	// li r4,9
	ctx.r4.s64 = 9;
	// b 0x830bfdd4
	goto loc_830BFDD4;
loc_830BFDF4:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x830bfe04
	if (cr6.eq) goto loc_830BFE04;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x830bfdd4
	goto loc_830BFDD4;
loc_830BFE04:
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bfe14
	if (cr0.eq) goto loc_830BFE14;
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x830bfdd4
	goto loc_830BFDD4;
loc_830BFE14:
	// andi. r10,r11,8224
	ctx.r10.u64 = r11.u64 & 8224;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,8224
	cr6.compare<uint32_t>(ctx.r10.u32, 8224, xer);
	// bne cr6,0x830bfe28
	if (!cr6.eq) goto loc_830BFE28;
	// li r4,5
	ctx.r4.s64 = 5;
	// b 0x830bfdd4
	goto loc_830BFDD4;
loc_830BFE28:
	// lis r10,4
	ctx.r10.s64 = 262144;
	// rlwinm r9,r11,0,13,26
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x7FFE0;
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// rlwinm r9,r9,0,26,13
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFC003F;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x830bfe48
	if (!cr6.eq) goto loc_830BFE48;
	// li r4,6
	ctx.r4.s64 = 6;
	// b 0x830bfdd4
	goto loc_830BFDD4;
loc_830BFE48:
	// rlwinm. r10,r11,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bfe58
	if (cr0.eq) goto loc_830BFE58;
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x830bfdd4
	goto loc_830BFDD4;
loc_830BFE58:
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bfe70
	if (cr0.eq) goto loc_830BFE70;
	// rlwinm. r10,r11,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bfe70
	if (cr0.eq) goto loc_830BFE70;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x830bfdd4
	goto loc_830BFDD4;
loc_830BFE70:
	// rlwinm. r10,r11,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bfe88
	if (cr0.eq) goto loc_830BFE88;
	// rlwinm. r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830bfe88
	if (cr0.eq) goto loc_830BFE88;
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x830bfdd4
	goto loc_830BFDD4;
loc_830BFE88:
	// rlwinm. r11,r11,0,15,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830bfeb4
	if (cr0.eq) goto loc_830BFEB4;
	// lwz r11,72(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 72);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lwz r9,24(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// li r5,4500
	ctx.r5.s64 = 4500;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,-31912
	ctx.r6.s64 = ctx.r10.s64 + -31912;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830BFEB4:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_830BFEBC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BFED0"))) PPC_WEAK_FUNC(sub_830BFED0);
PPC_FUNC_IMPL(__imp__sub_830BFED0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,2
	ctx.r4.s64 = 2;
	// stfd f1,120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.f1.u64);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8306ec08
	sub_8306EC08(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bff1c
	if (cr0.lt) goto loc_830BFF1C;
	// lwz r11,276(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 276);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r10,272(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// ld r9,120(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stdx r9,r11,r10
	PPC_STORE_U64(r11.u32 + ctx.r10.u32, ctx.r9.u64);
	// lwz r11,276(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 276);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,276(r31)
	PPC_STORE_U32(r31.u32 + 276, r11.u32);
loc_830BFF1C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BFF30"))) PPC_WEAK_FUNC(sub_830BFF30);
PPC_FUNC_IMPL(__imp__sub_830BFF30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,2
	ctx.r4.s64 = 2;
	// stfd f1,120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.f1.u64);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8306ec08
	sub_8306EC08(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830bff94
	if (cr0.lt) goto loc_830BFF94;
	// lwz r11,276(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 276);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r10,272(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,124(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lwz r8,120(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// lwz r10,272(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// lwz r11,276(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 276);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r8,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r8.u32);
	// lwz r11,276(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 276);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,276(r31)
	PPC_STORE_U32(r31.u32 + 276, r11.u32);
loc_830BFF94:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830BFFA8"))) PPC_WEAK_FUNC(sub_830BFFA8);
PPC_FUNC_IMPL(__imp__sub_830BFFA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r11,r11,-32288
	r11.s64 = r11.s64 + -32288;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8306af88
	sub_8306AF88(ctx, base);
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830bffe8
	if (cr0.eq) goto loc_830BFFE8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
loc_830BFFE8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C0008"))) PPC_WEAK_FUNC(sub_830C0008);
PPC_FUNC_IMPL(__imp__sub_830C0008) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x830c0040
	if (cr6.eq) goto loc_830C0040;
	// bl 0x830c0008
	sub_830C0008(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830c0074
	if (cr0.lt) goto loc_830C0074;
loc_830C0040:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830bfda8
	sub_830BFDA8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830c0074
	if (cr0.lt) goto loc_830C0074;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830c0080
	if (!cr0.lt) goto loc_830C0080;
loc_830C0074:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x830c0098
	goto loc_830C0098;
loc_830C0080:
	// lwz r11,272(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// li r3,0
	ctx.r3.s64 = 0;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_830C0098:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830C00A0"))) PPC_WEAK_FUNC(sub_830C00A0);
PPC_FUNC_IMPL(__imp__sub_830C00A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb4
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r1,104
	r11.s64 = ctx.r1.s64 + 104;
	// addi r9,r1,88
	ctx.r9.s64 = ctx.r1.s64 + 88;
	// li r17,0
	r17.s64 = 0;
	// mr r16,r4
	r16.u64 = ctx.r4.u64;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r15,r17
	r15.u64 = r17.u64;
	// std r17,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r17.u64);
	// std r17,0(r9)
	PPC_STORE_U64(ctx.r9.u32 + 0, r17.u64);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// stw r17,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r17.u32);
	// stw r17,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, r17.u32);
	// bne cr6,0x830c00e8
	if (!cr6.eq) goto loc_830C00E8;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830c0ffc
	goto loc_830C0FFC;
loc_830C00E8:
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83095528
	sub_83095528(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lis r7,4
	ctx.r7.s64 = 262144;
	// lwz r5,56(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r8,99
	ctx.r8.s64 = 99;
	// lwz r4,124(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 124);
	// ori r7,r7,8320
	ctx.r7.u64 = ctx.r7.u64 | 8320;
	// li r6,512
	ctx.r6.s64 = 512;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8306b058
	sub_8306B058(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r18,r17
	r18.u64 = r17.u64;
	// mr r24,r17
	r24.u64 = r17.u64;
	// std r10,0(r9)
	PPC_STORE_U64(ctx.r9.u32 + 0, ctx.r10.u64);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// std r17,0(r8)
	PPC_STORE_U64(ctx.r8.u32 + 0, r17.u64);
	// std r10,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, ctx.r10.u64);
	// std r17,8(r8)
	PPC_STORE_U64(ctx.r8.u32 + 8, r17.u64);
	// beq cr6,0x830c0264
	if (cr6.eq) goto loc_830C0264;
	// lwz r6,120(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// lwz r5,132(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// lwz r4,180(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 180);
	// lwz r3,184(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 184);
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
loc_830C0168:
	// lwz r9,0(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r6,r8
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, xer);
	// bne cr6,0x830c0190
	if (!cr6.eq) goto loc_830C0190;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r18
	cr6.compare<uint32_t>(ctx.r10.u32, r18.u32, xer);
	// ble cr6,0x830c0190
	if (!cr6.gt) goto loc_830C0190;
	// mr r18,r10
	r18.u64 = ctx.r10.u64;
	// b 0x830c01b0
	goto loc_830C01B0;
loc_830C0190:
	// lwz r10,136(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x830c01b0
	if (!cr6.eq) goto loc_830C01B0;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r24
	cr6.compare<uint32_t>(ctx.r10.u32, r24.u32, xer);
	// ble cr6,0x830c01b0
	if (!cr6.gt) goto loc_830C01B0;
	// mr r24,r10
	r24.u64 = ctx.r10.u64;
loc_830C01B0:
	// cmplw cr6,r5,r8
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r8.u32, xer);
	// bne cr6,0x830c01e8
	if (!cr6.eq) goto loc_830C01E8;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r30,160(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// ble cr6,0x830c01cc
	if (!cr6.gt) goto loc_830C01CC;
	// stw r10,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r10.u32);
loc_830C01CC:
	// cmplw cr6,r5,r8
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r8.u32, xer);
	// bne cr6,0x830c01e8
	if (!cr6.eq) goto loc_830C01E8;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r30,144(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bge cr6,0x830c01e8
	if (!cr6.lt) goto loc_830C01E8;
	// stw r10,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r10.u32);
loc_830C01E8:
	// cmplw cr6,r4,r8
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r8.u32, xer);
	// bne cr6,0x830c0220
	if (!cr6.eq) goto loc_830C0220;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r30,164(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// ble cr6,0x830c0204
	if (!cr6.gt) goto loc_830C0204;
	// stw r10,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r10.u32);
loc_830C0204:
	// cmplw cr6,r4,r8
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r8.u32, xer);
	// bne cr6,0x830c0220
	if (!cr6.eq) goto loc_830C0220;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r30,148(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bge cr6,0x830c0220
	if (!cr6.lt) goto loc_830C0220;
	// stw r10,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r10.u32);
loc_830C0220:
	// cmplw cr6,r3,r8
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r8.u32, xer);
	// bne cr6,0x830c0258
	if (!cr6.eq) goto loc_830C0258;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r30,168(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// ble cr6,0x830c023c
	if (!cr6.gt) goto loc_830C023C;
	// stw r10,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r10.u32);
loc_830C023C:
	// cmplw cr6,r3,r8
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r8.u32, xer);
	// bne cr6,0x830c0258
	if (!cr6.eq) goto loc_830C0258;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r9,152(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c0258
	if (!cr6.lt) goto loc_830C0258;
	// stw r10,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r10.u32);
loc_830C0258:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x830c0168
	if (!cr0.eq) goto loc_830C0168;
loc_830C0264:
	// lwz r11,180(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 180);
	// mr r25,r17
	r25.u64 = r17.u64;
	// lwz r10,184(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 184);
	// li r19,1
	r19.s64 = 1;
	// lwz r9,132(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r11.u32);
	// stw r10,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r10.u32);
	// stw r9,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r9.u32);
loc_830C0284:
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// lwzx r26,r25,r11
	r26.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// cmpwi cr6,r26,-1
	cr6.compare<int32_t>(r26.s32, -1, xer);
	// beq cr6,0x830c0410
	if (cr6.eq) goto loc_830C0410;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// subf r11,r26,r11
	r11.s64 = r11.s64 - r26.s64;
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x830c04f0
	if (cr0.eq) goto loc_830C04F0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c0318
	if (!cr6.gt) goto loc_830C0318;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// lwzx r8,r25,r11
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
loc_830C02E4:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x830c0304
	if (!cr6.eq) goto loc_830C0304;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// subf r11,r26,r11
	r11.s64 = r11.s64 - r26.s64;
	// stbx r19,r11,r28
	PPC_STORE_U8(r11.u32 + r28.u32, r19.u8);
loc_830C0304:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x830c02e4
	if (cr6.lt) goto loc_830C02E4;
loc_830C0318:
	// mr r27,r17
	r27.u64 = r17.u64;
	// mr r11,r17
	r11.u64 = r17.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830c0370
	if (cr6.eq) goto loc_830C0370;
	// b 0x830c033c
	goto loc_830C033C;
loc_830C032C:
	// lbzx r10,r11,r28
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne 0x830c0344
	if (!cr0.eq) goto loc_830C0344;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_830C033C:
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// blt cr6,0x830c032c
	if (cr6.lt) goto loc_830C032C;
loc_830C0344:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// b 0x830c035c
	goto loc_830C035C;
loc_830C034C:
	// lbzx r10,r11,r28
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x830c0364
	if (cr0.eq) goto loc_830C0364;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_830C035C:
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// blt cr6,0x830c034c
	if (cr6.lt) goto loc_830C034C;
loc_830C0364:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// blt cr6,0x830c032c
	if (cr6.lt) goto loc_830C032C;
loc_830C0370:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r27,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// addi r11,r1,88
	r11.s64 = ctx.r1.s64 + 88;
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stwx r10,r25,r11
	PPC_STORE_U32(r25.u32 + r11.u32, ctx.r10.u32);
	// beq 0x830c04e4
	if (cr0.eq) goto loc_830C04E4;
	// mr r11,r17
	r11.u64 = r17.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830c03fc
	if (cr6.eq) goto loc_830C03FC;
	// b 0x830c03ac
	goto loc_830C03AC;
loc_830C039C:
	// lbzx r9,r11,r28
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne 0x830c03b4
	if (!cr0.eq) goto loc_830C03B4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_830C03AC:
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// blt cr6,0x830c039c
	if (cr6.lt) goto loc_830C039C;
loc_830C03B4:
	// add r9,r26,r11
	ctx.r9.u64 = r26.u64 + r11.u64;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x830c03d4
	goto loc_830C03D4;
loc_830C03C4:
	// lbzx r9,r11,r28
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x830c03dc
	if (cr0.eq) goto loc_830C03DC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_830C03D4:
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// blt cr6,0x830c03c4
	if (cr6.lt) goto loc_830C03C4;
loc_830C03DC:
	// lwz r9,-4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	// subf r9,r9,r26
	ctx.r9.s64 = r26.s64 - ctx.r9.s64;
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// blt cr6,0x830c039c
	if (cr6.lt) goto loc_830C039C;
loc_830C03FC:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// addi r11,r1,104
	r11.s64 = ctx.r1.s64 + 104;
	// stwx r27,r25,r11
	PPC_STORE_U32(r25.u32 + r11.u32, r27.u32);
loc_830C0410:
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplwi cr6,r25,12
	cr6.compare<uint32_t>(r25.u32, 12, xer);
	// blt cr6,0x830c0284
	if (cr6.lt) goto loc_830C0284;
	// rlwinm r30,r18,5,0,26
	r30.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 5) & 0xFFFFFFE0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// mr. r15,r3
	r15.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r15.s32, 0, xer);
	// beq 0x830c04f0
	if (cr0.eq) goto loc_830C04F0;
	// cmplwi cr6,r24,64
	cr6.compare<uint32_t>(r24.u32, 64, xer);
	// bgt cr6,0x830c0fc8
	if (cr6.gt) goto loc_830C0FC8;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c0534
	if (!cr6.gt) goto loc_830C0534;
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
loc_830C0460:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,120(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830c04a0
	if (!cr6.eq) goto loc_830C04A0;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x830c04a0
	if (!cr6.eq) goto loc_830C04A0;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// stfdx f0,r10,r15
	PPC_STORE_U64(ctx.r10.u32 + r15.u32, f0.u64);
loc_830C04A0:
	// lis r10,21592
	ctx.r10.s64 = 1415053312;
	// lwz r9,200(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x830c0520
	if (!cr6.eq) goto loc_830C0520;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r10,128(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830c0508
	if (!cr6.eq) goto loc_830C0508;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bgt cr6,0x830c0578
	if (cr6.gt) goto loc_830C0578;
	// lbz r10,111(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 111);
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// bne cr6,0x830c04fc
	if (!cr6.eq) goto loc_830C04FC;
	// stw r17,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r17.u32);
	// b 0x830c0508
	goto loc_830C0508;
loc_830C04E4:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
loc_830C04F0:
	// lis r29,-32761
	r29.s64 = -2147024896;
	// ori r29,r29,14
	r29.u64 = r29.u64 | 14;
	// b 0x830c0fc8
	goto loc_830C0FC8;
loc_830C04FC:
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x830c0508
	if (!cr6.eq) goto loc_830C0508;
	// stw r19,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r19.u32);
loc_830C0508:
	// lwz r10,132(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x830c0520
	if (!cr6.eq) goto loc_830C0520;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bgt cr6,0x830c0584
	if (cr6.gt) goto loc_830C0584;
loc_830C0520:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x830c0460
	if (cr6.lt) goto loc_830C0460;
loc_830C0534:
	// lwz r20,12(r31)
	r20.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r21,r17
	r21.u64 = r17.u64;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x830c0a38
	if (cr6.eq) goto loc_830C0A38;
	// mr r22,r17
	r22.u64 = r17.u64;
loc_830C0548:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r27,r17
	r27.u64 = r17.u64;
	// lwzx r28,r22,r11
	r28.u64 = PPC_LOAD_U32(r22.u32 + r11.u32);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// stw r17,40(r28)
	PPC_STORE_U32(r28.u32 + 40, r17.u32);
	// clrlwi. r25,r11,12
	r25.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// rlwinm r23,r11,0,0,11
	r23.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// bne 0x830c05a0
	if (!cr0.eq) goto loc_830C05A0;
loc_830C0568:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// b 0x830c0a24
	goto loc_830C0A24;
loc_830C0578:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-31840
	ctx.r6.s64 = r11.s64 + -31840;
	// b 0x830c058c
	goto loc_830C058C;
loc_830C0584:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-31872
	ctx.r6.s64 = r11.s64 + -31872;
loc_830C058C:
	// li r5,4500
	ctx.r5.s64 = 4500;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
	// b 0x830c0fc8
	goto loc_830C0FC8;
loc_830C05A0:
	// lwz r7,16(r28)
	ctx.r7.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// twllei r25,0
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// divwu. r24,r11,r25
	r24.u32 = r11.u32 / r25.u32;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r4
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// stw r9,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r9.u32);
	// beq 0x830c0604
	if (cr0.eq) goto loc_830C0604;
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r9,r1,132
	ctx.r9.s64 = ctx.r1.s64 + 132;
	// rlwinm r8,r25,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_830C05DC:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r4
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r4.u32);
	// lwz r6,16(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// stw r6,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r6.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830c05dc
	if (!cr0.eq) goto loc_830C05DC;
	// lwz r9,128(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_830C0604:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// bne cr6,0x830c065c
	if (!cr6.eq) goto loc_830C065C;
	// cmplwi cr6,r25,1
	cr6.compare<uint32_t>(r25.u32, 1, xer);
	// ble cr6,0x830c065c
	if (!cr6.gt) goto loc_830C065C;
	// addi r10,r9,1
	ctx.r10.s64 = ctx.r9.s64 + 1;
	// addi r11,r7,4
	r11.s64 = ctx.r7.s64 + 4;
	// addi r8,r25,-1
	ctx.r8.s64 = r25.s64 + -1;
loc_830C0624:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r4
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// beq cr6,0x830c0644
	if (cr6.eq) goto loc_830C0644;
	// mr r27,r19
	r27.u64 = r19.u64;
	// b 0x830c064c
	goto loc_830C064C;
loc_830C0644:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
loc_830C064C:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830c0624
	if (!cr0.eq) goto loc_830C0624;
	// stw r9,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r9.u32);
loc_830C065C:
	// cmplwi cr6,r24,2
	cr6.compare<uint32_t>(r24.u32, 2, xer);
	// bne cr6,0x830c07e4
	if (!cr6.eq) goto loc_830C07E4;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x830c07e4
	if (!cr6.eq) goto loc_830C07E4;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// cmplwi cr6,r25,1
	cr6.compare<uint32_t>(r25.u32, 1, xer);
	// addi r6,r11,1
	ctx.r6.s64 = r11.s64 + 1;
	// ble cr6,0x830c07dc
	if (!cr6.gt) goto loc_830C07DC;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// rlwinm r30,r25,2,0,29
	r30.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r29,r25,-1
	r29.s64 = r25.s64 + -1;
	// add r10,r30,r11
	ctx.r10.u64 = r30.u64 + r11.u64;
	// addi r8,r11,4
	ctx.r8.s64 = r11.s64 + 4;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_830C06B0:
	// lwz r3,0(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r3,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r9.u32);
	// lwz r3,16(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// beq cr6,0x830c06cc
	if (cr6.eq) goto loc_830C06CC;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
loc_830C06CC:
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r3,r4
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r4.u32);
	// lwz r3,16(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmplw cr6,r3,r6
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r6.u32, xer);
	// beq cr6,0x830c06ec
	if (cr6.eq) goto loc_830C06EC;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// b 0x830c06f0
	goto loc_830C06F0;
loc_830C06EC:
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
loc_830C06F0:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x830c06b0
	if (!cr0.eq) goto loc_830C06B0;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// bne cr6,0x830c07dc
	if (!cr6.eq) goto loc_830C07DC;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83079750
	sub_83079750(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830c07e4
	if (cr0.eq) goto loc_830C07E4;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// add r10,r30,r11
	ctx.r10.u64 = r30.u64 + r11.u64;
	// lwz r7,132(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// addi r8,r11,4
	ctx.r8.s64 = r11.s64 + 4;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_830C074C:
	// lwz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r9
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r9.u32);
	// lwz r4,16(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// beq cr6,0x830c0768
	if (cr6.eq) goto loc_830C0768;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
loc_830C0768:
	// lwz r4,0(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r5
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r5.u32);
	// lwz r4,16(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplw cr6,r4,r7
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r7.u32, xer);
	// beq cr6,0x830c0788
	if (cr6.eq) goto loc_830C0788;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// b 0x830c078c
	goto loc_830C078C;
loc_830C0788:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
loc_830C078C:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x830c074c
	if (!cr0.eq) goto loc_830C074C;
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq cr6,0x830c07e4
	if (cr6.eq) goto loc_830C07E4;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830c07dc
	if (cr6.eq) goto loc_830C07DC;
	// mr r11,r17
	r11.u64 = r17.u64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_830C07B4:
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r8,r9,r30
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r30.u32);
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stwx r8,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// stwx r7,r9,r30
	PPC_STORE_U32(ctx.r9.u32 + r30.u32, ctx.r7.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x830c07b4
	if (!cr0.eq) goto loc_830C07B4;
loc_830C07DC:
	// stw r19,40(r28)
	PPC_STORE_U32(r28.u32 + 40, r19.u32);
	// b 0x830c0568
	goto loc_830C0568;
loc_830C07E4:
	// cmplwi cr6,r25,1
	cr6.compare<uint32_t>(r25.u32, 1, xer);
	// ble cr6,0x830c085c
	if (!cr6.gt) goto loc_830C085C;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r25,-1
	ctx.r4.s64 = r25.s64 + -1;
loc_830C07F4:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x830c0850
	if (cr6.eq) goto loc_830C0850;
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r11,r1,132
	r11.s64 = ctx.r1.s64 + 132;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r6,r25,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r5
	ctx.r10.u64 = ctx.r10.u64 + ctx.r5.u64;
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
loc_830C0814:
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lwzx r3,r3,r7
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r7.u32);
	// lwz r3,16(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmplw cr6,r3,r8
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r8.u32, xer);
	// beq cr6,0x830c083c
	if (cr6.eq) goto loc_830C083C;
	// mr r27,r19
	r27.u64 = r19.u64;
	// b 0x830c0840
	goto loc_830C0840;
loc_830C083C:
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
loc_830C0840:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// add r10,r6,r10
	ctx.r10.u64 = ctx.r6.u64 + ctx.r10.u64;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830c0814
	if (!cr0.eq) goto loc_830C0814;
loc_830C0850:
	// addic. r4,r4,-1
	xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// bne 0x830c07f4
	if (!cr0.eq) goto loc_830C07F4;
loc_830C085C:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x830c0568
	if (cr6.eq) goto loc_830C0568;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830c0888
	if (!cr6.eq) goto loc_830C0888;
	// lis r11,28896
	r11.s64 = 1893728256;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// b 0x830c0568
	goto loc_830C0568;
loc_830C0888:
	// lis r10,20528
	ctx.r10.s64 = 1345323008;
	// mr r26,r17
	r26.u64 = r17.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x830c0940
	if (!cr6.eq) goto loc_830C0940;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830c0a24
	if (cr6.eq) goto loc_830C0A24;
loc_830C08A0:
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// rlwinm r27,r26,2,0,29
	r27.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,92(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c0930
	if (cr6.eq) goto loc_830C0930;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lis r4,4240
	ctx.r4.s64 = 277872640;
	// beq cr6,0x830c08e0
	if (cr6.eq) goto loc_830C08E0;
	// lis r4,4224
	ctx.r4.s64 = 276824064;
loc_830C08E0:
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// bl 0x8307aa18
	sub_8307AA18(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x830c04f0
	if (cr6.eq) goto loc_830C04F0;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
loc_830C0930:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// blt cr6,0x830c08a0
	if (cr6.lt) goto loc_830C08A0;
	// b 0x830c0a24
	goto loc_830C0A24;
loc_830C0940:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x830c0a24
	if (cr6.eq) goto loc_830C0A24;
	// mr r27,r17
	r27.u64 = r17.u64;
loc_830C094C:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x83079ce8
	sub_83079CE8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c0968
	if (cr0.eq) goto loc_830C0968;
	// bl 0x830795f0
	sub_830795F0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830c096c
	goto loc_830C096C;
loc_830C0968:
	// mr r30,r17
	r30.u64 = r17.u64;
loc_830C096C:
	// addi r11,r1,176
	r11.s64 = ctx.r1.s64 + 176;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stwx r30,r27,r11
	PPC_STORE_U32(r27.u32 + r11.u32, r30.u32);
	// beq cr6,0x830c04f0
	if (cr6.eq) goto loc_830C04F0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// ori r4,r23,1
	ctx.r4.u64 = r23.u64 | 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d80
	sub_83079D80(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079640
	sub_83079640(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// beq cr6,0x830c09f8
	if (cr6.eq) goto loc_830C09F8;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// rlwinm r8,r25,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_830C09D8:
	// lwz r7,8(r28)
	ctx.r7.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r6,8(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r7,r10,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// stwx r7,r6,r9
	PPC_STORE_U32(ctx.r6.u32 + ctx.r9.u32, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x830c09d8
	if (!cr0.eq) goto loc_830C09D8;
loc_830C09F8:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307abb8
	sub_8307ABB8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83079d40
	sub_83079D40(ctx, base);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// blt cr6,0x830c094c
	if (cr6.lt) goto loc_830C094C;
loc_830C0A24:
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// stw r17,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r17.u32);
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmplw cr6,r21,r20
	cr6.compare<uint32_t>(r21.u32, r20.u32, xer);
	// blt cr6,0x830c0548
	if (cr6.lt) goto loc_830C0548;
loc_830C0A38:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8307f3a8
	sub_8307F3A8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,200(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lis r11,18008
	r11.s64 = 1180172288;
	// lwz r10,200(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// ori r11,r11,513
	r11.u64 = r11.u64 | 513;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830c0bd4
	if (!cr6.eq) goto loc_830C0BD4;
	// lwz r26,112(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r27,108(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lwz r28,104(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// add r11,r26,r27
	r11.u64 = r26.u64 + r27.u64;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// addi r11,r11,5
	r11.s64 = r11.s64 + 5;
	// rlwinm r11,r11,17,1,14
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 17) & 0x7FFE0000;
	// ori r4,r11,65534
	ctx.r4.u64 = r11.u64 | 65534;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// lis r4,18771
	ctx.r4.s64 = 1230176256;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r4,r4,21072
	ctx.r4.u64 = ctx.r4.u64 | 21072;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// addi r30,r1,144
	r30.s64 = ctx.r1.s64 + 144;
	// li r29,3
	r29.s64 = 3;
loc_830C0AB0:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// bne cr6,0x830c0ac4
	if (!cr6.eq) goto loc_830C0AC4;
	// li r4,0
	ctx.r4.s64 = 0;
loc_830C0AC4:
	// bl 0x83070600
	sub_83070600(ctx, base);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x830c0ab0
	if (!cr0.eq) goto loc_830C0AB0;
	// mr r30,r17
	r30.u64 = r17.u64;
loc_830C0AD8:
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830c0af4
	if (!cr6.eq) goto loc_830C0AF4;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x830c0b04
	goto loc_830C0B04;
loc_830C0AF4:
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
loc_830C0B04:
	// bl 0x83070600
	sub_83070600(ctx, base);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r30,12
	cr6.compare<uint32_t>(r30.u32, 12, xer);
	// blt cr6,0x830c0ad8
	if (cr6.lt) goto loc_830C0AD8;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830c0b54
	if (cr6.eq) goto loc_830C0B54;
	// lwz r30,88(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r29,r28
	r29.u64 = r28.u64;
loc_830C0B30:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// bne 0x830c0b30
	if (!cr0.eq) goto loc_830C0B30;
loc_830C0B54:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x830c0b94
	if (cr6.eq) goto loc_830C0B94;
	// lwz r30,92(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r29,r27
	r29.u64 = r27.u64;
loc_830C0B70:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// bne 0x830c0b70
	if (!cr0.eq) goto loc_830C0B70;
loc_830C0B94:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830c0bd4
	if (cr6.eq) goto loc_830C0BD4;
	// lwz r30,96(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r29,r26
	r29.u64 = r26.u64;
loc_830C0BB0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// bne 0x830c0bb0
	if (!cr0.eq) goto loc_830C0BB0;
loc_830C0BD4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830707f8
	sub_830707F8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// rlwinm r11,r18,19,0,12
	r11.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 19) & 0xFFF80000;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addis r11,r11,2
	r11.s64 = r11.s64 + 131072;
	// rlwinm r11,r11,0,1,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x7FFF0000;
	// ori r4,r11,65534
	ctx.r4.u64 = r11.u64 | 65534;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lis r4,21577
	ctx.r4.s64 = 1414070272;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r4,r4,19523
	ctx.r4.u64 = ctx.r4.u64 | 19523;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// rlwinm r28,r18,2,0,29
	r28.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r11,224(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// mr r27,r17
	r27.u64 = r17.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830c0c78
	if (cr6.eq) goto loc_830C0C78;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830c0ca8
	if (cr6.eq) goto loc_830C0CA8;
	// mr r30,r15
	r30.u64 = r15.u64;
loc_830C0C50:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfd f1,0(r30)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// bl 0x830bff30
	sub_830BFF30(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// cmplw cr6,r27,r28
	cr6.compare<uint32_t>(r27.u32, r28.u32, xer);
	// blt cr6,0x830c0c50
	if (cr6.lt) goto loc_830C0C50;
	// b 0x830c0ca8
	goto loc_830C0CA8;
loc_830C0C78:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830c0ca8
	if (cr6.eq) goto loc_830C0CA8;
	// mr r30,r15
	r30.u64 = r15.u64;
loc_830C0C84:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfd f1,0(r30)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// bl 0x830bfed0
	sub_830BFED0(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// cmplw cr6,r27,r28
	cr6.compare<uint32_t>(r27.u32, r28.u32, xer);
	// blt cr6,0x830c0c84
	if (cr6.lt) goto loc_830C0C84;
loc_830C0CA8:
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r20,276(r31)
	r20.u64 = PPC_LOAD_U32(r31.u32 + 276);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lis r4,17228
	ctx.r4.s64 = 1129054208;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r4,r4,22598
	ctx.r4.u64 = ctx.r4.u64 | 22598;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r21,r17
	r21.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c0f10
	if (!cr6.gt) goto loc_830C0F10;
	// mr r22,r17
	r22.u64 = r17.u64;
loc_830C0D00:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r22,r11
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + r11.u32);
	// lwz r11,40(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32768
	r11.s64 = -2147483648;
	// bne cr6,0x830c0d1c
	if (!cr6.eq) goto loc_830C0D1C;
	// mr r11,r17
	r11.u64 = r17.u64;
loc_830C0D1C:
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// or r4,r11,r10
	ctx.r4.u64 = r11.u64 | ctx.r10.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r11,r22,r11
	r11.u64 = PPC_LOAD_U32(r22.u32 + r11.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi r28,r10,12
	r28.u64 = ctx.r10.u32 & 0xFFFFF;
	// divwu r24,r11,r28
	r24.u32 = r11.u32 / r28.u32;
	// twllei r28,0
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r11,272(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// rlwinm r30,r20,2,0,29
	r30.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r26,r17
	r26.u64 = r17.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// lwzx r10,r11,r30
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// stwx r10,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, ctx.r10.u32);
	// beq cr6,0x830c0e44
	if (cr6.eq) goto loc_830C0E44;
	// mr r27,r17
	r27.u64 = r17.u64;
	// rlwinm r23,r28,2,0,29
	r23.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
loc_830C0D8C:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r25,276(r31)
	r25.u64 = PPC_LOAD_U32(r31.u32 + 276);
	// lwzx r11,r22,r11
	r11.u64 = PPC_LOAD_U32(r22.u32 + r11.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r11,r10
	r28.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r4,8(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x830c0de0
	if (cr6.eq) goto loc_830C0DE0;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c0008
	sub_830C0008(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
loc_830C0DE0:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830bfda8
	sub_830BFDA8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r10,12(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r9,272(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// rlwinm r11,r25,2,0,29
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// add r27,r23,r27
	r27.u64 = r23.u64 + r27.u64;
	// cmplw cr6,r26,r24
	cr6.compare<uint32_t>(r26.u32, r24.u32, xer);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r10,r9,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r30.u32);
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// stwx r11,r9,r30
	PPC_STORE_U32(ctx.r9.u32 + r30.u32, r11.u32);
	// blt cr6,0x830c0d8c
	if (cr6.lt) goto loc_830C0D8C;
loc_830C0E44:
	// mr r27,r17
	r27.u64 = r17.u64;
loc_830C0E48:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r26,276(r31)
	r26.u64 = PPC_LOAD_U32(r31.u32 + 276);
	// lwzx r11,r22,r11
	r11.u64 = PPC_LOAD_U32(r22.u32 + r11.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r11,r10
	r28.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r4,8(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x830c0e9c
	if (cr6.eq) goto loc_830C0E9C;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c0008
	sub_830C0008(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
loc_830C0E9C:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830bfda8
	sub_830BFDA8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r9,272(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// rlwinm r11,r26,2,0,29
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplwi cr6,r27,4
	cr6.compare<uint32_t>(r27.u32, 4, xer);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r10,r9,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r30.u32);
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// stwx r11,r9,r30
	PPC_STORE_U32(ctx.r9.u32 + r30.u32, r11.u32);
	// blt cr6,0x830c0e48
	if (cr6.lt) goto loc_830C0E48;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// blt cr6,0x830c0d00
	if (cr6.lt) goto loc_830C0D00;
loc_830C0F10:
	// lis r4,-3856
	ctx.r4.s64 = -252706816;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r4,r4,61680
	ctx.r4.u64 = ctx.r4.u64 | 61680;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lis r4,3855
	ctx.r4.s64 = 252641280;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r4,r4,3855
	ctx.r4.u64 = ctx.r4.u64 | 3855;
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r10,272(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// rlwinm r11,r20,2,0,29
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r4,r4,65535
	ctx.r4.u64 = ctx.r4.u64 | 65535;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// rlwinm r9,r9,16,1,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0x7FFF0000;
	// ori r9,r9,65534
	ctx.r9.u64 = ctx.r9.u64 | 65534;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// bl 0x83070600
	sub_83070600(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x830c0fc4
	if (cr6.eq) goto loc_830C0FC4;
	// lwz r11,276(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 276);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82d27900
	sub_82D27900(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x830c0fc8
	if (cr0.lt) goto loc_830C0FC8;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r30,276(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 276);
	// lwz r31,272(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// rlwinm r5,r30,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r16)
	PPC_STORE_U32(r16.u32 + 0, r11.u32);
loc_830C0FC4:
	// mr r29,r17
	r29.u64 = r17.u64;
loc_830C0FC8:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,88(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,92(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_830C0FFC:
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// b 0x82ca2c04
	return;
}

__attribute__((alias("__imp__sub_830C1008"))) PPC_WEAK_FUNC(sub_830C1008);
PPC_FUNC_IMPL(__imp__sub_830C1008) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// lis r10,18008
	ctx.r10.s64 = 1180172288;
	// li r25,0
	r25.s64 = 0;
	// lwz r11,200(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 200);
	// mr r28,r25
	r28.u64 = r25.u64;
	// rlwinm r11,r11,0,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// lwz r11,108(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 108);
	// bne cr6,0x830c1060
	if (!cr6.eq) goto loc_830C1060;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830c1058
	if (!cr6.eq) goto loc_830C1058;
	// lwz r11,508(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 508);
	// stw r11,108(r27)
	PPC_STORE_U32(r27.u32 + 108, r11.u32);
	// lwz r11,508(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 508);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,508(r26)
	PPC_STORE_U32(r26.u32 + 508, r11.u32);
loc_830C1058:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830c129c
	goto loc_830C129C;
loc_830C1060:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830c1058
	if (!cr6.eq) goto loc_830C1058;
	// lwz r9,104(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 104);
	// li r10,32
	ctx.r10.s64 = 32;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
loc_830C1078:
	// lbz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x830c1098
	if (cr0.eq) goto loc_830C1098;
	// stb r8,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r8.u8);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// bne 0x830c1078
	if (!cr0.eq) goto loc_830C1078;
loc_830C1098:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830c10a4
	if (!cr6.eq) goto loc_830C10A4;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
loc_830C10A4:
	// stb r25,0(r11)
	PPC_STORE_U8(r11.u32 + 0, r25.u8);
	// addi r31,r1,80
	r31.s64 = ctx.r1.s64 + 80;
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x830c10dc
	if (cr0.eq) goto loc_830C10DC;
loc_830C10B8:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x82ca6ab0
	sub_82CA6AB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830c10dc
	if (cr0.eq) goto loc_830C10DC;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830c10b8
	if (!cr6.eq) goto loc_830C10B8;
loc_830C10DC:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c10f8
	if (cr6.eq) goto loc_830C10F8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82ca3b30
	sub_82CA3B30(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830c10fc
	goto loc_830C10FC;
loc_830C10F8:
	// mr r30,r25
	r30.u64 = r25.u64;
loc_830C10FC:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c1120
	if (cr6.eq) goto loc_830C1120;
	// stb r25,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r25.u8);
	// b 0x830c111c
	goto loc_830C111C;
loc_830C1110:
	// bl 0x82ca6b10
	sub_82CA6B10(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x830c112c
	if (cr0.eq) goto loc_830C112C;
loc_830C111C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_830C1120:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb. r3,r11
	ctx.r3.s64 = r11.s8;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830c1110
	if (!cr0.eq) goto loc_830C1110;
loc_830C112C:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c1140
	if (cr6.eq) goto loc_830C1140;
	// li r30,-1
	r30.s64 = -1;
	// b 0x830c114c
	goto loc_830C114C;
loc_830C1140:
	// lwz r11,112(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 112);
	// rlwinm r11,r11,30,2,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
loc_830C114C:
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// li r29,1
	r29.s64 = 1;
	// lwz r10,16(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830c11e8
	if (cr0.eq) goto loc_830C11E8;
	// rlwinm. r10,r11,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x830c11e8
	if (!cr0.eq) goto loc_830C11E8;
	// lis r11,-32243
	r11.s64 = -2113077248;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-25032
	ctx.r4.s64 = r11.s64 + -25032;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830c1194
	if (!cr0.eq) goto loc_830C1194;
	// li r28,2
	r28.s64 = 2;
	// b 0x830c11b0
	goto loc_830C11B0;
loc_830C1194:
	// lis r11,-32240
	r11.s64 = -2112880640;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-2996
	ctx.r4.s64 = r11.s64 + -2996;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830c11c0
	if (!cr0.eq) goto loc_830C11C0;
	// li r28,3
	r28.s64 = 3;
loc_830C11B0:
	// subfc r11,r29,r30
	xer.ca = r30.u32 >= r29.u32;
	r11.s64 = r30.s64 - r29.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// addi r31,r11,1
	r31.s64 = r11.s64 + 1;
	// b 0x830c11c8
	goto loc_830C11C8;
loc_830C11C0:
	// mr r28,r25
	r28.u64 = r25.u64;
	// mr r31,r29
	r31.u64 = r29.u64;
loc_830C11C8:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// beq cr6,0x830c1258
	if (cr6.eq) goto loc_830C1258;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830c1258
	if (!cr6.eq) goto loc_830C1258;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,32680
	ctx.r6.s64 = r11.s64 + 32680;
	// b 0x830c1240
	goto loc_830C1240;
loc_830C11E8:
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830c1260
	if (cr0.eq) goto loc_830C1260;
	// lis r11,-32240
	r11.s64 = -2112880640;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-3060
	ctx.r4.s64 = r11.s64 + -3060;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x830c121c
	if (!cr0.eq) goto loc_830C121C;
	// subfc r11,r29,r30
	xer.ca = r30.u32 >= r29.u32;
	r11.s64 = r30.s64 - r29.s64;
	// mr r28,r29
	r28.u64 = r29.u64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// addi r31,r11,1
	r31.s64 = r11.s64 + 1;
	// b 0x830c1224
	goto loc_830C1224;
loc_830C121C:
	// mr r28,r25
	r28.u64 = r25.u64;
	// mr r31,r29
	r31.u64 = r29.u64;
loc_830C1224:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// beq cr6,0x830c1258
	if (cr6.eq) goto loc_830C1258;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830c1258
	if (!cr6.eq) goto loc_830C1258;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-31808
	ctx.r6.s64 = r11.s64 + -31808;
loc_830C1240:
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// lwz r4,104(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 104);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r5,4502
	ctx.r5.s64 = 4502;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8308be30
	sub_8308BE30(ctx, base);
loc_830C1258:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x830c1264
	if (!cr6.eq) goto loc_830C1264;
loc_830C1260:
	// mr r31,r29
	r31.u64 = r29.u64;
loc_830C1264:
	// cmplwi cr6,r30,65535
	cr6.compare<uint32_t>(r30.u32, 65535, xer);
	// ble cr6,0x830c1270
	if (!cr6.gt) goto loc_830C1270;
	// mr r31,r29
	r31.u64 = r29.u64;
loc_830C1270:
	// lis r11,-1
	r11.s64 = -65536;
	// clrlwi r10,r28,24
	ctx.r10.u64 = r28.u32 & 0xFF;
	// rlwimi r11,r30,8,16,23
	r11.u64 = (__builtin_rotateleft32(r30.u32, 8) & 0xFF00) | (r11.u64 & 0xFFFFFFFFFFFF00FF);
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// stw r11,108(r27)
	PPC_STORE_U32(r27.u32 + 108, r11.u32);
	// beq cr6,0x830c1298
	if (cr6.eq) goto loc_830C1298;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x830c129c
	goto loc_830C129C;
loc_830C1298:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_830C129C:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830C12A8"))) PPC_WEAK_FUNC(sub_830C12A8);
PPC_FUNC_IMPL(__imp__sub_830C12A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83046768
	sub_83046768(ctx, base);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// li r11,0
	r11.s64 = 0;
	// addi r10,r10,-31764
	ctx.r10.s64 = ctx.r10.s64 + -31764;
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// stw r11,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r11.u32);
	// stw r11,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r11.u32);
	// stw r11,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r11.u32);
	// stw r11,68(r31)
	PPC_STORE_U32(r31.u32 + 68, r11.u32);
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
	// stw r11,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r11.u32);
	// stw r11,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r11.u32);
	// stw r11,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r11.u32);
	// stw r11,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r11.u32);
	// stw r11,116(r31)
	PPC_STORE_U32(r31.u32 + 116, r11.u32);
	// stw r11,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r11.u32);
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
	// std r11,16(r31)
	PPC_STORE_U64(r31.u32 + 16, r11.u64);
	// std r11,24(r31)
	PPC_STORE_U64(r31.u32 + 24, r11.u64);
	// std r11,32(r31)
	PPC_STORE_U64(r31.u32 + 32, r11.u64);
	// std r11,40(r31)
	PPC_STORE_U64(r31.u32 + 40, r11.u64);
	// std r11,96(r31)
	PPC_STORE_U64(r31.u32 + 96, r11.u64);
	// std r11,104(r31)
	PPC_STORE_U64(r31.u32 + 104, r11.u64);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C1340"))) PPC_WEAK_FUNC(sub_830C1340);
PPC_FUNC_IMPL(__imp__sub_830C1340) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// mr r27,r9
	r27.u64 = ctx.r9.u64;
	// bl 0x83046768
	sub_83046768(ctx, base);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// li r11,0
	r11.s64 = 0;
	// addi r9,r10,-31764
	ctx.r9.s64 = ctx.r10.s64 + -31764;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// cmplwi cr6,r25,3
	cr6.compare<uint32_t>(r25.u32, 3, xer);
	// ld r9,0(r26)
	ctx.r9.u64 = PPC_LOAD_U64(r26.u32 + 0);
	// std r9,16(r31)
	PPC_STORE_U64(r31.u32 + 16, ctx.r9.u64);
	// ld r9,8(r26)
	ctx.r9.u64 = PPC_LOAD_U64(r26.u32 + 8);
	// std r9,24(r31)
	PPC_STORE_U64(r31.u32 + 24, ctx.r9.u64);
	// ld r9,16(r26)
	ctx.r9.u64 = PPC_LOAD_U64(r26.u32 + 16);
	// std r9,32(r31)
	PPC_STORE_U64(r31.u32 + 32, ctx.r9.u64);
	// ld r9,24(r26)
	ctx.r9.u64 = PPC_LOAD_U64(r26.u32 + 24);
	// std r9,40(r31)
	PPC_STORE_U64(r31.u32 + 40, ctx.r9.u64);
	// stw r25,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r25.u32);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// stw r11,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r11.u32);
	// stw r11,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r11.u32);
	// stw r11,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r11.u32);
	// stw r11,68(r31)
	PPC_STORE_U32(r31.u32 + 68, r11.u32);
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
	// bne cr6,0x830c13cc
	if (!cr6.eq) goto loc_830C13CC;
	// li r10,1
	ctx.r10.s64 = 1;
loc_830C13CC:
	// addi r9,r10,13
	ctx.r9.s64 = ctx.r10.s64 + 13;
	// addi r8,r10,15
	ctx.r8.s64 = ctx.r10.s64 + 15;
	// addi r10,r10,17
	ctx.r10.s64 = ctx.r10.s64 + 17;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stwx r30,r9,r31
	PPC_STORE_U32(ctx.r9.u32 + r31.u32, r30.u32);
	// stwx r29,r8,r31
	PPC_STORE_U32(ctx.r8.u32 + r31.u32, r29.u32);
	// stwx r28,r10,r31
	PPC_STORE_U32(ctx.r10.u32 + r31.u32, r28.u32);
	// stw r27,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r27.u32);
	// stw r11,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r11.u32);
	// stw r11,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r11.u32);
	// stw r11,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r11.u32);
	// stw r11,116(r31)
	PPC_STORE_U32(r31.u32 + 116, r11.u32);
	// std r11,96(r31)
	PPC_STORE_U64(r31.u32 + 96, r11.u64);
	// std r11,104(r31)
	PPC_STORE_U64(r31.u32 + 104, r11.u64);
	// stw r11,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r11.u32);
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830C1420"))) PPC_WEAK_FUNC(sub_830C1420);
PPC_FUNC_IMPL(__imp__sub_830C1420) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// addi r11,r11,-3
	r11.s64 = r11.s64 + -3;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r11,r11,21
	r11.s64 = r11.s64 + 21;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r4,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, ctx.r4.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C1440"))) PPC_WEAK_FUNC(sub_830C1440);
PPC_FUNC_IMPL(__imp__sub_830C1440) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c146c
	if (cr0.eq) goto loc_830C146C;
	// bl 0x830c12a8
	sub_830C12A8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830c1470
	goto loc_830C1470;
loc_830C146C:
	// li r30,0
	r30.s64 = 0;
loc_830C1470:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x830c1480
	if (!cr6.eq) goto loc_830C1480;
loc_830C1478:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830c15bc
	goto loc_830C15BC;
loc_830C1480:
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(r31.u32 + 16);
	// addi r11,r31,16
	r11.s64 = r31.s64 + 16;
	// addi r11,r30,16
	r11.s64 = r30.s64 + 16;
	// addi r10,r31,68
	ctx.r10.s64 = r31.s64 + 68;
	// addi r11,r30,52
	r11.s64 = r30.s64 + 52;
	// subf r8,r30,r31
	ctx.r8.s64 = r31.s64 - r30.s64;
	// std r9,16(r30)
	PPC_STORE_U64(r30.u32 + 16, ctx.r9.u64);
	// li r9,2
	ctx.r9.s64 = 2;
	// ld r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U64(r31.u32 + 24);
	// std r7,24(r30)
	PPC_STORE_U64(r30.u32 + 24, ctx.r7.u64);
	// ld r7,32(r31)
	ctx.r7.u64 = PPC_LOAD_U64(r31.u32 + 32);
	// std r7,32(r30)
	PPC_STORE_U64(r30.u32 + 32, ctx.r7.u64);
	// ld r7,40(r31)
	ctx.r7.u64 = PPC_LOAD_U64(r31.u32 + 40);
	// std r7,40(r30)
	PPC_STORE_U64(r30.u32 + 40, ctx.r7.u64);
	// lwz r7,48(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// stw r7,48(r30)
	PPC_STORE_U32(r30.u32 + 48, ctx.r7.u32);
loc_830C14C0:
	// lwzx r7,r8,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,-8(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + -8);
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r7,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r7.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830c14c0
	if (!cr0.eq) goto loc_830C14C0;
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// li r28,0
	r28.s64 = 0;
	// addi r29,r31,84
	r29.s64 = r31.s64 + 84;
	// subf r27,r31,r30
	r27.s64 = r30.s64 - r31.s64;
	// stw r11,76(r30)
	PPC_STORE_U32(r30.u32 + 76, r11.u32);
	// lwz r11,116(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// stw r11,116(r30)
	PPC_STORE_U32(r30.u32 + 116, r11.u32);
loc_830C1504:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c1530
	if (cr6.eq) goto loc_830C1530;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stwx r3,r27,r29
	PPC_STORE_U32(r27.u32 + r29.u32, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c1478
	if (cr0.eq) goto loc_830C1478;
loc_830C1530:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplwi cr6,r28,2
	cr6.compare<uint32_t>(r28.u32, 2, xer);
	// blt cr6,0x830c1504
	if (cr6.lt) goto loc_830C1504;
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c156c
	if (cr6.eq) goto loc_830C156C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,92(r30)
	PPC_STORE_U32(r30.u32 + 92, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c1478
	if (cr0.eq) goto loc_830C1478;
loc_830C156C:
	// li r28,0
	r28.s64 = 0;
	// addi r29,r31,96
	r29.s64 = r31.s64 + 96;
loc_830C1574:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c15a0
	if (cr6.eq) goto loc_830C15A0;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stwx r3,r29,r27
	PPC_STORE_U32(r29.u32 + r27.u32, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c1478
	if (cr0.eq) goto loc_830C1478;
loc_830C15A0:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// blt cr6,0x830c1574
	if (cr6.lt) goto loc_830C1574;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r11,80(r30)
	PPC_STORE_U32(r30.u32 + 80, r11.u32);
loc_830C15BC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830C15C8"))) PPC_WEAK_FUNC(sub_830C15C8);
PPC_FUNC_IMPL(__imp__sub_830C15C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,28
	ctx.r4.s64 = 28;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83046768
	sub_83046768(ctx, base);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// li r11,0
	r11.s64 = 0;
	// addi r10,r10,-31748
	ctx.r10.s64 = ctx.r10.s64 + -31748;
	// li r9,2257
	ctx.r9.s64 = 2257;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// li r8,228
	ctx.r8.s64 = 228;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// stw r9,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r9.u32);
	// stw r8,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r8.u32);
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// std r11,48(r31)
	PPC_STORE_U64(r31.u32 + 48, r11.u64);
	// std r11,56(r31)
	PPC_STORE_U64(r31.u32 + 56, r11.u64);
	// std r11,64(r31)
	PPC_STORE_U64(r31.u32 + 64, r11.u64);
	// std r11,72(r31)
	PPC_STORE_U64(r31.u32 + 72, r11.u64);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C1648"))) PPC_WEAK_FUNC(sub_830C1648);
PPC_FUNC_IMPL(__imp__sub_830C1648) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r4,28
	ctx.r4.s64 = 28;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// mr r26,r8
	r26.u64 = ctx.r8.u64;
	// mr r25,r9
	r25.u64 = ctx.r9.u64;
	// bl 0x83046768
	sub_83046768(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r29,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r29.u32);
	// li r10,2257
	ctx.r10.s64 = 2257;
	// stw r28,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r28.u32);
	// addi r11,r11,-31748
	r11.s64 = r11.s64 + -31748;
	// stw r27,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r27.u32);
	// li r9,228
	ctx.r9.s64 = 228;
	// stw r26,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r26.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r10,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r9.u32);
	// stw r25,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r25.u32);
	// stw r8,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r8.u32);
	// ld r11,0(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// std r11,48(r31)
	PPC_STORE_U64(r31.u32 + 48, r11.u64);
	// ld r11,8(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 8);
	// std r11,56(r31)
	PPC_STORE_U64(r31.u32 + 56, r11.u64);
	// ld r11,16(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 16);
	// std r11,64(r31)
	PPC_STORE_U64(r31.u32 + 64, r11.u64);
	// ld r11,24(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 24);
	// std r11,72(r31)
	PPC_STORE_U64(r31.u32 + 72, r11.u64);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830C16E0"))) PPC_WEAK_FUNC(sub_830C16E0);
PPC_FUNC_IMPL(__imp__sub_830C16E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c1714
	if (cr0.eq) goto loc_830C1714;
	// bl 0x830c15c8
	sub_830C15C8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830c1718
	goto loc_830C1718;
loc_830C1714:
	// li r31,0
	r31.s64 = 0;
loc_830C1718:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x830c1728
	if (!cr6.eq) goto loc_830C1728;
loc_830C1720:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830c17dc
	goto loc_830C17DC;
loc_830C1728:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c1784
	if (cr6.eq) goto loc_830C1784;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c1720
	if (cr0.eq) goto loc_830C1720;
loc_830C1784:
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c17b0
	if (cr6.eq) goto loc_830C17B0;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c1720
	if (cr0.eq) goto loc_830C1720;
loc_830C17B0:
	// ld r11,48(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 48);
	// addi r10,r30,48
	ctx.r10.s64 = r30.s64 + 48;
	// addi r10,r31,48
	ctx.r10.s64 = r31.s64 + 48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// std r11,48(r31)
	PPC_STORE_U64(r31.u32 + 48, r11.u64);
	// ld r11,56(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 56);
	// std r11,56(r31)
	PPC_STORE_U64(r31.u32 + 56, r11.u64);
	// ld r11,64(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 64);
	// std r11,64(r31)
	PPC_STORE_U64(r31.u32 + 64, r11.u64);
	// ld r11,72(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 72);
	// std r11,72(r31)
	PPC_STORE_U64(r31.u32 + 72, r11.u64);
loc_830C17DC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C17F8"))) PPC_WEAK_FUNC(sub_830C17F8);
PPC_FUNC_IMPL(__imp__sub_830C17F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r4,29
	ctx.r4.s64 = 29;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83046768
	sub_83046768(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,-31732
	r11.s64 = r11.s64 + -31732;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C1848"))) PPC_WEAK_FUNC(sub_830C1848);
PPC_FUNC_IMPL(__imp__sub_830C1848) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c1878
	if (cr0.eq) goto loc_830C1878;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x830c17f8
	sub_830C17F8(ctx, base);
	// b 0x830c187c
	goto loc_830C187C;
loc_830C1878:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830C187C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C1890"))) PPC_WEAK_FUNC(sub_830C1890);
PPC_FUNC_IMPL(__imp__sub_830C1890) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-31764
	r11.s64 = r11.s64 + -31764;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C18A0"))) PPC_WEAK_FUNC(sub_830C18A0);
PPC_FUNC_IMPL(__imp__sub_830C18A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-31748
	r11.s64 = r11.s64 + -31748;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C18B0"))) PPC_WEAK_FUNC(sub_830C18B0);
PPC_FUNC_IMPL(__imp__sub_830C18B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-31732
	r11.s64 = r11.s64 + -31732;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C18C0"))) PPC_WEAK_FUNC(sub_830C18C0);
PPC_FUNC_IMPL(__imp__sub_830C18C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r7,4
	cr6.compare<uint32_t>(ctx.r7.u32, 4, xer);
	// ble cr6,0x830c18d0
	if (!cr6.gt) goto loc_830C18D0;
	// li r7,4
	ctx.r7.s64 = 4;
loc_830C18D0:
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r4,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r4.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r5,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r5.u32);
	// stw r6,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r6.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r7,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r7.u32);
	// stw r9,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r9.u32);
	// stw r9,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r9.u32);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// stw r9,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r9.u32);
	// stw r9,32(r11)
	PPC_STORE_U32(r11.u32 + 32, ctx.r9.u32);
	// stw r10,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r10.u32);
	// stw r10,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r10.u32);
	// stw r9,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r9.u32);
	// stw r9,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C1918"))) PPC_WEAK_FUNC(sub_830C1918);
PPC_FUNC_IMPL(__imp__sub_830C1918) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x830c1930
	if (!cr6.eq) goto loc_830C1930;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
loc_830C1930:
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r10,12(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// lwz r10,16(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
	// lwz r10,20(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// lwz r10,24(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r10,28(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
	// lwz r10,32(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// stw r10,32(r11)
	PPC_STORE_U32(r11.u32 + 32, ctx.r10.u32);
	// lwz r10,36(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	// stw r10,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r10.u32);
	// lwz r10,40(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 40);
	// stw r10,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r10.u32);
	// lwz r10,44(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 44);
	// stw r10,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r10.u32);
	// lwz r10,48(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 48);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C19A0"))) PPC_WEAK_FUNC(sub_830C19A0);
PPC_FUNC_IMPL(__imp__sub_830C19A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
loc_830C19A0:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,56(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 56);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x830c19c4
	if (cr6.eq) goto loc_830C19C4;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// b 0x830c19a0
	goto loc_830C19A0;
loc_830C19C4:
	// li r11,-1
	r11.s64 = -1;
	// stw r4,116(r8)
	PPC_STORE_U32(ctx.r8.u32 + 116, ctx.r4.u32);
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// stw r11,48(r8)
	PPC_STORE_U32(ctx.r8.u32 + 48, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830c1a30
	if (!cr0.eq) goto loc_830C1A30;
	// lwz r9,16(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830c1a1c
	if (cr6.eq) goto loc_830C1A1C;
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r5,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r5.u32);
loc_830C1A1C:
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_830C1A30:
	// lwz r5,8(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// bne cr6,0x830c19a0
	if (!cr6.eq) goto loc_830C19A0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C1A40"))) PPC_WEAK_FUNC(sub_830C1A40);
PPC_FUNC_IMPL(__imp__sub_830C1A40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r8,r9,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830c1ab8
	if (!cr0.eq) goto loc_830C1AB8;
	// lwz r11,92(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c1ab8
	if (cr6.eq) goto loc_830C1AB8;
	// lwz r9,36(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830c1aa4
	if (cr6.eq) goto loc_830C1AA4;
	// lwz r11,32(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// rlwinm r7,r4,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,28(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// lwzx r10,r11,r7
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwzx r11,r6,r7
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r7.u32);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r5,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r5.u32);
loc_830C1AA4:
	// lwz r10,28(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_830C1AB8:
	// lwz r5,20(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// b 0x830c19a0
	sub_830C19A0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_830C1AC8"))) PPC_WEAK_FUNC(sub_830C1AC8);
PPC_FUNC_IMPL(__imp__sub_830C1AC8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C1AD0"))) PPC_WEAK_FUNC(sub_830C1AD0);
PPC_FUNC_IMPL(__imp__sub_830C1AD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// lwz r11,60(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 60);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r4,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,44(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 44);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r7,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwzx r7,r7,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// ble cr6,0x830c1b08
	if (!cr6.gt) goto loc_830C1B08;
loc_830C1B00:
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
loc_830C1B08:
	// lwz r7,44(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 44);
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x830c1b24
	if (!cr6.lt) goto loc_830C1B24;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_830C1B24:
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x830c1b00
	if (cr6.lt) goto loc_830C1B00;
	// subfc r11,r9,r8
	xer.ca = ctx.r8.u32 >= ctx.r9.u32;
	r11.s64 = ctx.r8.s64 - ctx.r9.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r3,r11,31
	ctx.r3.u64 = r11.u32 & 0x1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C1B40"))) PPC_WEAK_FUNC(sub_830C1B40);
PPC_FUNC_IMPL(__imp__sub_830C1B40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// cmplw cr6,r3,r4
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r4.u32, xer);
	// bge cr6,0x830c1b50
	if (!cr6.lt) goto loc_830C1B50;
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
loc_830C1B50:
	// subfc r11,r3,r4
	xer.ca = ctx.r4.u32 >= ctx.r3.u32;
	r11.s64 = ctx.r4.s64 - ctx.r3.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r3,r11,31
	ctx.r3.u64 = r11.u32 & 0x1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C1B60"))) PPC_WEAK_FUNC(sub_830C1B60);
PPC_FUNC_IMPL(__imp__sub_830C1B60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// ble cr6,0x830c1be8
	if (!cr6.gt) goto loc_830C1BE8;
	// lis r11,-31988
	r11.s64 = -2096365568;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r3,r11,6976
	ctx.r3.s64 = r11.s64 + 6976;
	// bl 0x8307b5c8
	sub_8307B5C8(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x830c1be4
	if (!cr6.gt) goto loc_830C1BE4;
	// addi r10,r31,4
	ctx.r10.s64 = r31.s64 + 4;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_830C1BB4:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r6,-4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// beq cr6,0x830c1bd0
	if (cr6.eq) goto loc_830C1BD0;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_830C1BD0:
	// lwz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x830c1bb4
	if (cr6.lt) goto loc_830C1BB4;
loc_830C1BE4:
	// stw r7,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r7.u32);
loc_830C1BE8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C1C00"))) PPC_WEAK_FUNC(sub_830C1C00);
PPC_FUNC_IMPL(__imp__sub_830C1C00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2be4
	// lwz r11,56(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// li r31,0
	r31.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// li r27,0
	r27.s64 = 0;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c1d58
	if (!cr6.gt) goto loc_830C1D58;
	// li r30,0
	r30.s64 = 0;
loc_830C1C28:
	// lwz r11,60(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r8,44(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// lwzx r6,r30,r11
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stwx r31,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, r31.u32);
	// lwz r8,40(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// stwx r10,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r10.u32);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm. r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x830c1d44
	if (cr0.eq) goto loc_830C1D44;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r8,16(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// beq cr6,0x830c1cc4
	if (cr6.eq) goto loc_830C1CC4;
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
loc_830C1C88:
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r8,0(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,88(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 88);
	// cmplw cr6,r6,r9
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r9.u32, xer);
	// bne cr6,0x830c1cb8
	if (!cr6.eq) goto loc_830C1CB8;
	// lwz r9,40(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// stwx r8,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r8.u32);
loc_830C1CB8:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x830c1c88
	if (!cr0.eq) goto loc_830C1C88;
loc_830C1CC4:
	// lwz r10,32(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// lwz r9,28(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// lwz r8,36(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// beq cr6,0x830c1d28
	if (cr6.eq) goto loc_830C1D28;
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
loc_830C1CEC:
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r8,0(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,92(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 92);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x830c1d1c
	if (cr6.eq) goto loc_830C1D1C;
	// lwz r9,40(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stwx r8,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r8.u32);
loc_830C1D1C:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x830c1cec
	if (!cr0.eq) goto loc_830C1CEC;
loc_830C1D28:
	// add r28,r28,r31
	r28.u64 = r28.u64 + r31.u64;
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// ble cr6,0x830c1d38
	if (!cr6.gt) goto loc_830C1D38;
	// mr r27,r31
	r27.u64 = r31.u64;
loc_830C1D38:
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
loc_830C1D44:
	// lwz r11,56(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830c1c28
	if (cr6.lt) goto loc_830C1C28;
loc_830C1D58:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830c1d64
	if (cr6.eq) goto loc_830C1D64;
	// stw r28,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r28.u32);
loc_830C1D64:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x830c1d70
	if (cr6.eq) goto loc_830C1D70;
	// stw r27,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r27.u32);
loc_830C1D70:
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830C1D78"))) PPC_WEAK_FUNC(sub_830C1D78);
PPC_FUNC_IMPL(__imp__sub_830C1D78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// li r14,0
	r14.s64 = 0;
	// mr r18,r4
	r18.u64 = ctx.r4.u64;
	// addi r16,r4,1
	r16.s64 = ctx.r4.s64 + 1;
	// lwz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r8,52(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// lwzx r30,r11,r9
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,24(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x830c24fc
	if (!cr6.eq) goto loc_830C24FC;
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r8,20(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwzx r7,r11,r7
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r17,r11,r6
	r17.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r5,r17,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r17.u32 | (r17.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// lwzx r11,r9,r8
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
loc_830C1E10:
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// li r15,0
	r15.s64 = 0;
	// cmplw cr6,r18,r16
	cr6.compare<uint32_t>(r18.u32, r16.u32, xer);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
	// bge cr6,0x830c1efc
	if (!cr6.lt) goto loc_830C1EFC;
	// rlwinm r8,r18,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r7,r18,r16
	ctx.r7.s64 = r16.s64 - r18.s64;
loc_830C1E30:
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// ble cr6,0x830c1e90
	if (!cr6.gt) goto loc_830C1E90;
	// li r9,0
	ctx.r9.s64 = 0;
loc_830C1E5C:
	// lwz r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r4,72(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// lwzx r6,r9,r6
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwz r5,24(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 24);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r5
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// stw r4,36(r6)
	PPC_STORE_U32(ctx.r6.u32 + 36, ctx.r4.u32);
	// lwz r6,20(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// blt cr6,0x830c1e5c
	if (cr6.lt) goto loc_830C1E5C;
loc_830C1E90:
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830c1ed8
	if (!cr6.gt) goto loc_830C1ED8;
	// li r10,0
	ctx.r10.s64 = 0;
loc_830C1EA4:
	// lwz r6,32(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r4,72(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// lwzx r6,r10,r6
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r5,24(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 24);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r5
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// stw r4,36(r6)
	PPC_STORE_U32(ctx.r6.u32 + 36, ctx.r4.u32);
	// lwz r6,28(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// blt cr6,0x830c1ea4
	if (cr6.lt) goto loc_830C1EA4;
loc_830C1ED8:
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// add r15,r11,r15
	r15.u64 = r11.u64 + r15.u64;
	// bne 0x830c1e30
	if (!cr0.eq) goto loc_830C1E30;
loc_830C1EFC:
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x830c1f40
	if (cr6.eq) goto loc_830C1F40;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r11,r17
	r11.u64 = r17.u64;
loc_830C1F0C:
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,72(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r7,116(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 116);
	// stw r8,48(r9)
	PPC_STORE_U32(ctx.r9.u32 + 48, ctx.r8.u32);
	// subf r8,r30,r7
	ctx.r8.s64 = ctx.r7.s64 - r30.s64;
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// stw r8,84(r9)
	PPC_STORE_U32(ctx.r9.u32 + 84, ctx.r8.u32);
	// bne 0x830c1f0c
	if (!cr0.eq) goto loc_830C1F0C;
loc_830C1F40:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// bge cr6,0x830c1f5c
	if (!cr6.lt) goto loc_830C1F5C;
	// mr r11,r18
	r11.u64 = r18.u64;
	// mr r20,r18
	r20.u64 = r18.u64;
	// mr r19,r18
	r19.u64 = r18.u64;
	// li r23,-1
	r23.s64 = -1;
	// b 0x830c1f70
	goto loc_830C1F70;
loc_830C1F5C:
	// ble cr6,0x830c24d0
	if (!cr6.gt) goto loc_830C24D0;
	// addi r11,r16,-1
	r11.s64 = r16.s64 + -1;
	// mr r20,r16
	r20.u64 = r16.u64;
	// mr r19,r16
	r19.u64 = r16.u64;
	// li r23,1
	r23.s64 = 1;
loc_830C1F70:
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// add r27,r23,r11
	r27.u64 = r23.u64 + r11.u64;
	// li r26,0
	r26.s64 = 0;
	// li r21,0
	r21.s64 = 0;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r26.u32);
	// li r22,0
	r22.s64 = 0;
	// cmplw cr6,r27,r10
	cr6.compare<uint32_t>(r27.u32, ctx.r10.u32, xer);
	// bge cr6,0x830c214c
	if (!cr6.lt) goto loc_830C214C;
loc_830C1F90:
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// rlwinm r10,r27,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,52(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// li r25,0
	r25.s64 = 0;
	// lwzx r24,r10,r11
	r24.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r30,r24,2,0,29
	r30.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r30,r9
	r11.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830c2020
	if (!cr6.eq) goto loc_830C2020;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r11,24(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r9,20(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r25,r11,r9
	r25.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r9,24(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// b 0x830c2000
	goto loc_830C2000;
loc_830C1FE0:
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// beq cr6,0x830c2014
	if (cr6.eq) goto loc_830C2014;
	// lwz r9,20(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,20(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
loc_830C2000:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x830c1fe0
	if (!cr6.eq) goto loc_830C1FE0;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830c24d0
	if (!cr6.eq) goto loc_830C24D0;
loc_830C2014:
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x830c24d0
	if (!cr6.eq) goto loc_830C24D0;
loc_830C2020:
	// cmplw cr6,r20,r27
	cr6.compare<uint32_t>(r20.u32, r27.u32, xer);
	// ble cr6,0x830c202c
	if (!cr6.gt) goto loc_830C202C;
	// mr r20,r27
	r20.u64 = r27.u64;
loc_830C202C:
	// cmplw cr6,r19,r27
	cr6.compare<uint32_t>(r19.u32, r27.u32, xer);
	// bgt cr6,0x830c2038
	if (cr6.gt) goto loc_830C2038;
	// addi r19,r27,1
	r19.s64 = r27.s64 + 1;
loc_830C2038:
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + r11.u64;
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r11,r30,r8
	r11.u64 = PPC_LOAD_U32(r30.u32 + ctx.r8.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r30,r7
	r29.u64 = PPC_LOAD_U32(r30.u32 + ctx.r7.u32);
	// add r28,r11,r9
	r28.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r5,r29,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// lwz r9,72(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// lwz r8,40(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lwz r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwzx r11,r30,r10
	r11.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// lwzx r10,r8,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r30.u32);
	// add r26,r11,r26
	r26.u64 = r11.u64 + r26.u64;
	// lwzx r11,r7,r30
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r30.u32);
	// add r21,r10,r21
	r21.u64 = ctx.r10.u64 + r21.u64;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r26.u32);
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or r22,r11,r22
	r22.u64 = r11.u64 | r22.u64;
	// beq cr6,0x830c210c
	if (cr6.eq) goto loc_830C210C;
loc_830C20B4:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,48(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x830c20e4
	if (!cr6.eq) goto loc_830C20E4;
	// lwz r9,116(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// cmplw cr6,r24,r9
	cr6.compare<uint32_t>(r24.u32, ctx.r9.u32, xer);
	// bne cr6,0x830c2100
	if (!cr6.eq) goto loc_830C2100;
loc_830C20E4:
	// lwz r9,116(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
	// subf r10,r24,r9
	ctx.r10.s64 = ctx.r9.s64 - r24.s64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// neg r10,r10
	ctx.r10.s64 = -ctx.r10.s64;
	// stw r10,84(r11)
	PPC_STORE_U32(r11.u32 + 84, ctx.r10.u32);
loc_830C2100:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// bne 0x830c20b4
	if (!cr0.eq) goto loc_830C20B4;
loc_830C210C:
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830c213c
	if (!cr6.eq) goto loc_830C213C;
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x830c213c
	if (!cr6.eq) goto loc_830C213C;
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// beq cr6,0x830c214c
	if (cr6.eq) goto loc_830C214C;
loc_830C213C:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// add r27,r23,r27
	r27.u64 = r23.u64 + r27.u64;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x830c1f90
	if (cr6.lt) goto loc_830C1F90;
loc_830C214C:
	// cmplw cr6,r20,r19
	cr6.compare<uint32_t>(r20.u32, r19.u32, xer);
	// bge cr6,0x830c24d0
	if (!cr6.lt) goto loc_830C24D0;
	// addi r11,r20,1
	r11.s64 = r20.s64 + 1;
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// bge cr6,0x830c2174
	if (!cr6.lt) goto loc_830C2174;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c1b60
	sub_830C1B60(ctx, base);
	// lwz r26,84(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_830C2174:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// bne cr6,0x830c2224
	if (!cr6.eq) goto loc_830C2224;
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// bge cr6,0x830c21d4
	if (!cr6.lt) goto loc_830C21D4;
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830c21c8
	if (cr6.eq) goto loc_830C21C8;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
loc_830C21A0:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,84(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 84);
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// bne cr6,0x830c21bc
	if (!cr6.eq) goto loc_830C21BC;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
loc_830C21BC:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830c21a0
	if (!cr0.eq) goto loc_830C21A0;
loc_830C21C8:
	// cmpw cr6,r15,r8
	cr6.compare<int32_t>(r15.s32, ctx.r8.s32, xer);
	// ble cr6,0x830c2224
	if (!cr6.gt) goto loc_830C2224;
	// b 0x830c2220
	goto loc_830C2220;
loc_830C21D4:
	// mr r8,r15
	ctx.r8.u64 = r15.u64;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x830c2218
	if (cr6.eq) goto loc_830C2218;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
loc_830C21F0:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,84(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 84);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x830c220c
	if (!cr6.eq) goto loc_830C220C;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
loc_830C220C:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x830c21f0
	if (!cr0.eq) goto loc_830C21F0;
loc_830C2218:
	// cmpw cr6,r8,r21
	cr6.compare<int32_t>(ctx.r8.s32, r21.s32, xer);
	// bge cr6,0x830c2224
	if (!cr6.lt) goto loc_830C2224;
loc_830C2220:
	// li r22,1
	r22.s64 = 1;
loc_830C2224:
	// cmplw cr6,r18,r20
	cr6.compare<uint32_t>(r18.u32, r20.u32, xer);
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// blt cr6,0x830c2234
	if (cr6.lt) goto loc_830C2234;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
loc_830C2234:
	// cmplw cr6,r16,r19
	cr6.compare<uint32_t>(r16.u32, r19.u32, xer);
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
	// bgt cr6,0x830c2244
	if (cr6.gt) goto loc_830C2244;
	// mr r8,r19
	ctx.r8.u64 = r19.u64;
loc_830C2244:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x830c2398
	if (cr6.eq) goto loc_830C2398;
	// mr r18,r7
	r18.u64 = ctx.r7.u64;
	// mr r16,r8
	r16.u64 = ctx.r8.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x830c22a0
	if (cr6.eq) goto loc_830C22A0;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_830C2264:
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,20(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r8,84(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 84);
	// addi r8,r8,0
	ctx.r8.s64 = ctx.r8.s64 + 0;
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// stw r8,84(r9)
	PPC_STORE_U32(ctx.r9.u32 + 84, ctx.r8.u32);
	// bne 0x830c2264
	if (!cr0.eq) goto loc_830C2264;
loc_830C22A0:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r17,2,0,29
	r11.u64 = __builtin_rotateleft64(r17.u32 | (r17.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r26,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// add r11,r26,r17
	r11.u64 = r26.u64 + r17.u64;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r15,r21,r15
	r15.u64 = r21.u64 + r15.u64;
	// bl 0x830c1b60
	sub_830C1B60(ctx, base);
	// rlwinm r8,r20,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r7,r20,r19
	ctx.r7.s64 = r19.s64 - r20.s64;
loc_830C22DC:
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// ble cr6,0x830c233c
	if (!cr6.gt) goto loc_830C233C;
	// li r9,0
	ctx.r9.s64 = 0;
loc_830C2308:
	// lwz r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r4,72(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// lwzx r6,r6,r9
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwz r5,24(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 24);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r5
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// stw r4,36(r6)
	PPC_STORE_U32(ctx.r6.u32 + 36, ctx.r4.u32);
	// lwz r6,20(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// blt cr6,0x830c2308
	if (cr6.lt) goto loc_830C2308;
loc_830C233C:
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x830c2384
	if (!cr6.gt) goto loc_830C2384;
	// li r10,0
	ctx.r10.s64 = 0;
loc_830C2350:
	// lwz r6,32(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r4,72(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// lwzx r6,r6,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r5,24(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 24);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r5
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// stw r4,36(r6)
	PPC_STORE_U32(ctx.r6.u32 + 36, ctx.r4.u32);
	// lwz r6,28(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// blt cr6,0x830c2350
	if (cr6.lt) goto loc_830C2350;
loc_830C2384:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x830c22dc
	if (!cr0.eq) goto loc_830C22DC;
	// lwz r17,84(r1)
	r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// b 0x830c1f40
	goto loc_830C1F40;
loc_830C2398:
	// subf r11,r18,r16
	r11.s64 = r16.s64 - r18.s64;
	// addi r10,r16,-1
	ctx.r10.s64 = r16.s64 + -1;
	// rlwinm. r9,r11,31,1,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830c23d8
	if (cr0.eq) goto loc_830C23D8;
	// rlwinm r11,r18,2,0,29
	r11.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_830C23B0:
	// lwz r6,60(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// lwzx r5,r6,r10
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// lwzx r4,r6,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// stwx r5,r6,r11
	PPC_STORE_U32(ctx.r6.u32 + r11.u32, ctx.r5.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r6,60(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// stwx r4,r10,r6
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, ctx.r4.u32);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// bne 0x830c23b0
	if (!cr0.eq) goto loc_830C23B0;
loc_830C23D8:
	// subf r30,r20,r19
	r30.s64 = r19.s64 - r20.s64;
	// addi r10,r19,-1
	ctx.r10.s64 = r19.s64 + -1;
	// rlwinm. r9,r30,31,1,31
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 31) & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830c2418
	if (cr0.eq) goto loc_830C2418;
	// rlwinm r11,r20,2,0,29
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_830C23F0:
	// lwz r6,60(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// lwzx r5,r10,r6
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwzx r4,r11,r6
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// stwx r5,r11,r6
	PPC_STORE_U32(r11.u32 + ctx.r6.u32, ctx.r5.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r6,60(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// stwx r4,r10,r6
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, ctx.r4.u32);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// bne 0x830c23f0
	if (!cr0.eq) goto loc_830C23F0;
loc_830C2418:
	// subf r11,r7,r8
	r11.s64 = ctx.r8.s64 - ctx.r7.s64;
	// addi r10,r8,-1
	ctx.r10.s64 = ctx.r8.s64 + -1;
	// rlwinm. r9,r11,31,1,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x830c2458
	if (cr0.eq) goto loc_830C2458;
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_830C2430:
	// lwz r8,60(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// lwzx r7,r10,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwzx r6,r11,r8
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// stwx r7,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r7.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r8,60(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// stwx r6,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r6.u32);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// bne 0x830c2430
	if (!cr0.eq) goto loc_830C2430;
loc_830C2458:
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,92
	ctx.r4.s64 = ctx.r1.s64 + 92;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c1c00
	sub_830C1C00(ctx, base);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bge cr6,0x830c248c
	if (!cr6.lt) goto loc_830C248C;
	// lwz r8,76(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// ble cr6,0x830c24c8
	if (!cr6.gt) goto loc_830C24C8;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
loc_830C248C:
	// bgt cr6,0x830c249c
	if (cr6.gt) goto loc_830C249C;
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x830c24c8
	if (cr6.lt) goto loc_830C24C8;
loc_830C249C:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// bge cr6,0x830c24b4
	if (!cr6.lt) goto loc_830C24B4;
	// subf r11,r19,r20
	r11.s64 = r20.s64 - r19.s64;
	// add r18,r11,r18
	r18.u64 = r11.u64 + r18.u64;
	// add r16,r11,r16
	r16.u64 = r11.u64 + r16.u64;
	// b 0x830c24bc
	goto loc_830C24BC;
loc_830C24B4:
	// add r18,r30,r18
	r18.u64 = r30.u64 + r18.u64;
	// add r16,r30,r16
	r16.u64 = r30.u64 + r16.u64;
loc_830C24BC:
	// lwz r30,100(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// li r14,1
	r14.s64 = 1;
	// b 0x830c1e10
	goto loc_830C1E10;
loc_830C24C8:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830c2500
	goto loc_830C2500;
loc_830C24D0:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// beq cr6,0x830c24fc
	if (cr6.eq) goto loc_830C24FC;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lwz r4,64(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,60(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c1c00
	sub_830C1C00(ctx, base);
loc_830C24FC:
	// li r3,1
	ctx.r3.s64 = 1;
loc_830C2500:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82ca2c00
	return;
}

__attribute__((alias("__imp__sub_830C2508"))) PPC_WEAK_FUNC(sub_830C2508);
PPC_FUNC_IMPL(__imp__sub_830C2508) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r5,r31,76
	ctx.r5.s64 = r31.s64 + 76;
	// addi r4,r31,80
	ctx.r4.s64 = r31.s64 + 80;
	// bl 0x830c1c00
	sub_830C1C00(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c2564
	if (!cr6.gt) goto loc_830C2564;
	// li r11,0
	r11.s64 = 0;
loc_830C2538:
	// lwz r9,48(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// stwx r10,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r10.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r8,64(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// stwx r9,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x830c2538
	if (cr6.lt) goto loc_830C2538;
loc_830C2564:
	// lis r11,-31988
	r11.s64 = -2096365568;
	// lwz r5,56(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// lwz r4,48(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// addi r3,r11,6864
	ctx.r3.s64 = r11.s64 + 6864;
	// bl 0x8307b5c8
	sub_8307B5C8(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c25c4
	if (!cr6.gt) goto loc_830C25C4;
	// li r30,0
	r30.s64 = 0;
loc_830C2590:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r4,r11,r30
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// bl 0x830c1d78
	sub_830C1D78(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830c25c8
	if (cr0.lt) goto loc_830C25C8;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x830c25d0
	if (cr6.eq) goto loc_830C25D0;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830c2590
	if (cr6.lt) goto loc_830C2590;
loc_830C25C4:
	// li r3,1
	ctx.r3.s64 = 1;
loc_830C25C8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_830C25D0:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830c25c8
	goto loc_830C25C8;
}

__attribute__((alias("__imp__sub_830C25D8"))) PPC_WEAK_FUNC(sub_830C25D8);
PPC_FUNC_IMPL(__imp__sub_830C25D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r26,0
	r26.s64 = 0;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// stw r26,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r26.u32);
	// stw r26,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r26.u32);
	// stw r26,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r26.u32);
	// stw r26,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r26.u32);
	// stw r26,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r26.u32);
	// stw r26,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r26.u32);
	// stw r26,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r26.u32);
	// stw r26,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r26.u32);
	// stw r26,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r26.u32);
	// stw r26,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r26.u32);
	// stw r26,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r26.u32);
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// stw r11,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r11.u32);
	// bl 0x830832a0
	sub_830832A0(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c273c
	if (!cr6.gt) goto loc_830C273C;
	// mr r27,r26
	r27.u64 = r26.u64;
loc_830C26A0:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwzx r30,r11,r27
	r30.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830c2728
	if (cr0.eq) goto loc_830C2728;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r28,r26
	r28.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c26f0
	if (!cr6.gt) goto loc_830C26F0;
	// mr r29,r26
	r29.u64 = r26.u64;
loc_830C26CC:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r5,r29,r11
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// bl 0x830c1a40
	sub_830C1A40(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x830c26cc
	if (cr6.lt) goto loc_830C26CC;
loc_830C26F0:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r29,r26
	r29.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c2728
	if (!cr6.gt) goto loc_830C2728;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
loc_830C2704:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r5,r11,r6
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// bl 0x830c19a0
	sub_830C19A0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830c2704
	if (cr6.lt) goto loc_830C2704;
loc_830C2728:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x830c26a0
	if (cr6.lt) goto loc_830C26A0;
loc_830C273C:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// mr r30,r26
	r30.u64 = r26.u64;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c27cc
	if (!cr6.gt) goto loc_830C27CC;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_830C2790:
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r10,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r10.u32);
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// stwx r30,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, r30.u32);
	// lwz r8,28(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r7,56(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// add r30,r8,r30
	r30.u64 = ctx.r8.u64 + r30.u64;
	// blt cr6,0x830c2790
	if (cr6.lt) goto loc_830C2790;
loc_830C27CC:
	// rlwinm r29,r10,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r30,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c2908
	if (!cr6.gt) goto loc_830C2908;
	// mr r27,r26
	r27.u64 = r26.u64;
loc_830C286C:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwzx r30,r11,r27
	r30.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830c28f4
	if (cr0.eq) goto loc_830C28F4;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r29,r26
	r29.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c28bc
	if (!cr6.gt) goto loc_830C28BC;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
loc_830C2898:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r5,r11,r6
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// bl 0x830c19a0
	sub_830C19A0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830c2898
	if (cr6.lt) goto loc_830C2898;
loc_830C28BC:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r28,r26
	r28.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c28f4
	if (!cr6.gt) goto loc_830C28F4;
	// mr r29,r26
	r29.u64 = r26.u64;
loc_830C28D0:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r5,r11,r29
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// bl 0x830c1a40
	sub_830C1A40(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x830c28d0
	if (cr6.lt) goto loc_830C28D0;
loc_830C28F4:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x830c286c
	if (cr6.lt) goto loc_830C286C;
loc_830C2908:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r29,r26
	r29.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c2978
	if (!cr6.gt) goto loc_830C2978;
	// mr r30,r26
	r30.u64 = r26.u64;
loc_830C291C:
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// add r5,r30,r11
	ctx.r5.u64 = r30.u64 + r11.u64;
	// lwzx r11,r9,r30
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r30.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x830c1b60
	sub_830C1B60(ctx, base);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r5,r11,r30
	ctx.r5.u64 = r11.u64 + r30.u64;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x830c1b60
	sub_830C1B60(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830c291c
	if (cr6.lt) goto loc_830C291C;
loc_830C2978:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,60(r31)
	PPC_STORE_U32(r31.u32 + 60, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,64(r31)
	PPC_STORE_U32(r31.u32 + 64, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,68(r31)
	PPC_STORE_U32(r31.u32 + 68, ctx.r3.u32);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r29,r26
	r29.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c2a5c
	if (!cr6.gt) goto loc_830C2A5C;
	// mr r30,r26
	r30.u64 = r26.u64;
loc_830C29FC:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r10,-1
	ctx.r10.s64 = -1;
	// lwz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// stwx r29,r30,r9
	PPC_STORE_U32(r30.u32 + ctx.r9.u32, r29.u32);
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// stwx r3,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, ctx.r3.u32);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r10,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, ctx.r10.u32);
	// beq 0x830c2a3c
	if (cr0.eq) goto loc_830C2A3C;
	// bl 0x830799f8
	sub_830799F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// beq 0x830c2a40
	if (cr0.eq) goto loc_830C2A40;
loc_830C2A3C:
	// li r11,1
	r11.s64 = 1;
loc_830C2A40:
	// lwz r10,52(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// stwx r11,r10,r30
	PPC_STORE_U32(ctx.r10.u32 + r30.u32, r11.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x830c29fc
	if (cr6.lt) goto loc_830C29FC;
loc_830C2A5C:
	// stw r26,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r26.u32);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x821f4d88
	sub_821F4D88(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2b2c
	if (cr0.eq) goto loc_830C2B2C;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x830c2b24
	if (cr6.eq) goto loc_830C2B24;
	// b 0x830c2ac8
	goto loc_830C2AC8;
loc_830C2AC0:
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x830c2adc
	if (cr6.eq) goto loc_830C2ADC;
loc_830C2AC8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c2508
	sub_830C2508(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x830c2ac0
	if (!cr0.lt) goto loc_830C2AC0;
	// b 0x830c2bec
	goto loc_830C2BEC;
loc_830C2ADC:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x830c2b24
	if (!cr6.gt) goto loc_830C2B24;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_830C2AF0:
	// lwz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r8,68(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// lwz r7,4(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,24(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 24);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// stwx r9,r7,r11
	PPC_STORE_U32(ctx.r7.u32 + r11.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x830c2af0
	if (cr6.lt) goto loc_830C2AF0;
loc_830C2B24:
	// mr r30,r26
	r30.u64 = r26.u64;
	// b 0x830c2b34
	goto loc_830C2B34;
loc_830C2B2C:
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
loc_830C2B34:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,32(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,36(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,40(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,44(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,52(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,60(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_830C2BEC:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830C2BF8"))) PPC_WEAK_FUNC(sub_830C2BF8);
PPC_FUNC_IMPL(__imp__sub_830C2BF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31952
	r11.s64 = -2094006272;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,5128
	r11.s64 = r11.s64 + 5128;
	// li r28,0
	r28.s64 = 0;
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// mr r31,r11
	r31.u64 = r11.u64;
	// li r29,0
	r29.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830c2d34
	if (cr6.eq) goto loc_830C2D34;
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x830c2d34
	if (!cr6.eq) goto loc_830C2D34;
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// b 0x830c2c48
	goto loc_830C2C48;
loc_830C2C40:
	// lwz r5,12(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_830C2C48:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x830c2c40
	if (!cr6.eq) goto loc_830C2C40;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c2cc0
	if (cr6.eq) goto loc_830C2CC0;
	// lwz r5,8(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
loc_830C2C60:
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
loc_830C2C64:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r27,0(r10)
	r27.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r27,r9
	ctx.r9.s64 = ctx.r9.s64 - r27.s64;
	// beq 0x830c2c88
	if (cr0.eq) goto loc_830C2C88;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830c2c64
	if (cr6.eq) goto loc_830C2C64;
loc_830C2C88:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830c2cb0
	if (!cr0.eq) goto loc_830C2CB0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r29,1
	r29.s64 = 1;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x830c2cac
	if (cr6.lt) goto loc_830C2CAC;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// ble cr6,0x830c2cc0
	if (!cr6.gt) goto loc_830C2CC0;
loc_830C2CAC:
	// li r28,1
	r28.s64 = 1;
loc_830C2CB0:
	// addi r31,r31,24
	r31.s64 = r31.s64 + 24;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x830c2c60
	if (!cr6.eq) goto loc_830C2C60;
loc_830C2CC0:
	// clrlwi. r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830c2d10
	if (cr0.eq) goto loc_830C2D10;
	// clrlwi. r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830c2ce8
	if (cr0.eq) goto loc_830C2CE8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r7,8(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// li r5,3000
	ctx.r5.s64 = 3000;
	// addi r6,r11,-31164
	ctx.r6.s64 = r11.s64 + -31164;
	// bl 0x83097060
	sub_83097060(ctx, base);
	// b 0x830c2d34
	goto loc_830C2D34;
loc_830C2CE8:
	// lbz r11,16(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 16);
	// clrlwi r10,r6,24
	ctx.r10.u64 = ctx.r6.u32 & 0xFF;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x830c2d04
	if (cr6.eq) goto loc_830C2D04;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-31224
	ctx.r6.s64 = r11.s64 + -31224;
	// b 0x830c2d28
	goto loc_830C2D28;
loc_830C2D04:
	// stw r31,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x830c2d3c
	goto loc_830C2D3C;
loc_830C2D10:
	// clrlwi. r11,r7,24
	r11.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x830c2d20
	if (!cr0.eq) goto loc_830C2D20;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830c2d3c
	goto loc_830C2D3C;
loc_830C2D20:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-31260
	ctx.r6.s64 = r11.s64 + -31260;
loc_830C2D28:
	// li r5,3000
	ctx.r5.s64 = 3000;
	// lwz r7,8(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830C2D34:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_830C2D3C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830C2D48"))) PPC_WEAK_FUNC(sub_830C2D48);
PPC_FUNC_IMPL(__imp__sub_830C2D48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x830c2e48
	if (cr6.eq) goto loc_830C2E48;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x830c2e48
	if (!cr6.eq) goto loc_830C2E48;
	// lwz r7,24(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-31036
	r11.s64 = r11.s64 + -31036;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
loc_830C2D7C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r6,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r6.s64;
	// beq 0x830c2da0
	if (cr0.eq) goto loc_830C2DA0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830c2d7c
	if (cr6.eq) goto loc_830C2D7C;
loc_830C2DA0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830c2db4
	if (!cr0.eq) goto loc_830C2DB4;
	// li r11,4
	r11.s64 = 4;
loc_830C2DAC:
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// b 0x830c2e50
	goto loc_830C2E50;
loc_830C2DB4:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// addi r11,r11,-31068
	r11.s64 = r11.s64 + -31068;
loc_830C2DC0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r6,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r6.s64;
	// beq 0x830c2de4
	if (cr0.eq) goto loc_830C2DE4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830c2dc0
	if (cr6.eq) goto loc_830C2DC0;
loc_830C2DE4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830c2df4
	if (!cr0.eq) goto loc_830C2DF4;
	// li r11,512
	r11.s64 = 512;
	// b 0x830c2dac
	goto loc_830C2DAC;
loc_830C2DF4:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// addi r11,r11,-31104
	r11.s64 = r11.s64 + -31104;
loc_830C2E00:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r6,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r6.s64;
	// beq 0x830c2e24
	if (cr0.eq) goto loc_830C2E24;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830c2e00
	if (cr6.eq) goto loc_830C2E00;
loc_830C2E24:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x830c2e34
	if (!cr0.eq) goto loc_830C2E34;
	// li r11,1024
	r11.s64 = 1024;
	// b 0x830c2dac
	goto loc_830C2DAC;
loc_830C2E34:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,3000
	ctx.r5.s64 = 3000;
	// addi r6,r11,-31132
	ctx.r6.s64 = r11.s64 + -31132;
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830C2E48:
	// lis r8,-32768
	ctx.r8.s64 = -2147483648;
	// ori r8,r8,16389
	ctx.r8.u64 = ctx.r8.u64 | 16389;
loc_830C2E50:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C2E68"))) PPC_WEAK_FUNC(sub_830C2E68);
PPC_FUNC_IMPL(__imp__sub_830C2E68) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x830c2eb4
	if (cr6.eq) goto loc_830C2EB4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,3000
	ctx.r5.s64 = 3000;
	// addi r6,r11,-31004
	ctx.r6.s64 = r11.s64 + -31004;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
loc_830C2EA4:
	// mr r29,r28
	r29.u64 = r28.u64;
loc_830C2EA8:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
loc_830C2EB4:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2ee0
	if (cr0.eq) goto loc_830C2EE0;
	// lis r11,-32243
	r11.s64 = -2113077248;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,25408
	ctx.r6.s64 = r11.s64 + 25408;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x830c2ee4
	goto loc_830C2EE4;
loc_830C2EE0:
	// mr r29,r28
	r29.u64 = r28.u64;
loc_830C2EE4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830c2ea4
	if (cr6.eq) goto loc_830C2EA4;
	// li r3,24
	ctx.r3.s64 = 24;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2f08
	if (cr0.eq) goto loc_830C2F08;
	// bl 0x830492a8
	sub_830492A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x830c2f0c
	goto loc_830C2F0C;
loc_830C2F08:
	// mr r31,r28
	r31.u64 = r28.u64;
loc_830C2F0C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830c2ea4
	if (cr6.eq) goto loc_830C2EA4;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r5,4(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830c2bf8
	sub_830C2BF8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x830c2ea4
	if (cr0.lt) goto loc_830C2EA4;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r31,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r31.u32);
	// stw r28,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r28.u32);
	// stw r28,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r28.u32);
	// b 0x830c2ea8
	goto loc_830C2EA8;
}

__attribute__((alias("__imp__sub_830C2F60"))) PPC_WEAK_FUNC(sub_830C2F60);
PPC_FUNC_IMPL(__imp__sub_830C2F60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// li r30,0
	r30.s64 = 0;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x830c2fb8
	if (cr6.eq) goto loc_830C2FB8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,3000
	ctx.r5.s64 = 3000;
	// addi r6,r11,-31004
	ctx.r6.s64 = r11.s64 + -31004;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83096f78
	sub_83096F78(ctx, base);
	// lis r26,-32768
	r26.s64 = -2147483648;
	// ori r26,r26,16389
	r26.u64 = r26.u64 | 16389;
loc_830C2FA4:
	// li r30,0
	r30.s64 = 0;
loc_830C2FA8:
	// stw r30,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r30.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
loc_830C2FB8:
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r27,r4,16
	r27.s64 = ctx.r4.s64 + 16;
	// bl 0x830c2bf8
	sub_830C2BF8(ctx, base);
	// mr. r26,r3
	r26.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// blt 0x830c2fa4
	if (cr0.lt) goto loc_830C2FA4;
	// cmpwi cr6,r26,1
	cr6.compare<int32_t>(r26.s32, 1, xer);
	// beq cr6,0x830c2fa8
	if (cr6.eq) goto loc_830C2FA8;
	// li r3,24
	ctx.r3.s64 = 24;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c2ffc
	if (cr0.eq) goto loc_830C2FFC;
	// bl 0x830492a8
	sub_830492A8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x830c3000
	goto loc_830C3000;
loc_830C2FFC:
	// li r28,0
	r28.s64 = 0;
loc_830C3000:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x830c3014
	if (!cr6.eq) goto loc_830C3014;
loc_830C3008:
	// lis r26,-32761
	r26.s64 = -2147024896;
	// ori r26,r26,14
	r26.u64 = r26.u64 | 14;
	// b 0x830c2fa4
	goto loc_830C2FA4;
loc_830C3014:
	// lwz r29,80(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r3,80
	ctx.r3.s64 = 80;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// stw r31,20(r28)
	PPC_STORE_U32(r28.u32 + 20, r31.u32);
	// stw r11,16(r28)
	PPC_STORE_U32(r28.u32 + 16, r11.u32);
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c3058
	if (cr0.eq) goto loc_830C3058;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830493b8
	sub_830493B8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x830c305c
	goto loc_830C305C;
loc_830C3058:
	// li r30,0
	r30.s64 = 0;
loc_830C305C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x830c3008
	if (cr6.eq) goto loc_830C3008;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c3094
	if (cr0.eq) goto loc_830C3094;
	// li r9,512
	ctx.r9.s64 = 512;
	// lwz r5,20(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x83048100
	sub_83048100(ctx, base);
	// b 0x830c3098
	goto loc_830C3098;
loc_830C3094:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830C3098:
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830c3008
	if (cr6.eq) goto loc_830C3008;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c30cc
	if (cr0.eq) goto loc_830C30CC;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,25560
	ctx.r6.s64 = r11.s64 + 25560;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x830468d0
	sub_830468D0(ctx, base);
	// b 0x830c30d0
	goto loc_830C30D0;
loc_830C30CC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830C30D0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// beq cr6,0x830c3008
	if (cr6.eq) goto loc_830C3008;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x83046708
	sub_83046708(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x830c3100
	if (cr0.eq) goto loc_830C3100;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x83049848
	sub_83049848(ctx, base);
	// b 0x830c3104
	goto loc_830C3104;
loc_830C3100:
	// li r3,0
	ctx.r3.s64 = 0;
loc_830C3104:
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// beq cr6,0x830c3008
	if (cr6.eq) goto loc_830C3008;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83099758
	sub_83099758(ctx, base);
	// b 0x830c2fa8
	goto loc_830C2FA8;
}

__attribute__((alias("__imp__sub_830C3128"))) PPC_WEAK_FUNC(sub_830C3128);
PPC_FUNC_IMPL(__imp__sub_830C3128) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r10,1
	ctx.r10.s64 = 1;
	// addi r11,r11,14736
	r11.s64 = r11.s64 + 14736;
	// sth r10,6(r3)
	PPC_STORE_U16(ctx.r3.u32 + 6, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C3148"))) PPC_WEAK_FUNC(sub_830C3148);
PPC_FUNC_IMPL(__imp__sub_830C3148) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	return;
}

__attribute__((alias("__imp__sub_830C3160"))) PPC_WEAK_FUNC(sub_830C3160);
PPC_FUNC_IMPL(__imp__sub_830C3160) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r3,r11,14736
	ctx.r3.s64 = r11.s64 + 14736;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C3170"))) PPC_WEAK_FUNC(sub_830C3170);
PPC_FUNC_IMPL(__imp__sub_830C3170) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r13)
	r11.u64 = PPC_LOAD_U32(ctx.r13.u32 + 0);
	// li r10,4
	ctx.r10.s64 = 4;
	// li r5,23
	ctx.r5.s64 = 23;
	// li r4,20
	ctx.r4.s64 = 20;
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bl 0x82d4ec28
	sub_82D4EC28(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r11,27408
	r11.s64 = r11.s64 + 27408;
	// li r10,20
	ctx.r10.s64 = 20;
	// li r9,1
	ctx.r9.s64 = 1;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// sth r10,4(r31)
	PPC_STORE_U16(r31.u32 + 4, ctx.r10.u16);
	// sth r9,6(r31)
	PPC_STORE_U16(r31.u32 + 6, ctx.r9.u16);
	// bl 0x82d58b88
	sub_82D58B88(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C31D8"))) PPC_WEAK_FUNC(sub_830C31D8);
PPC_FUNC_IMPL(__imp__sub_830C31D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// bl 0x82d5a318
	sub_82D5A318(ctx, base);
	// and r11,r3,r27
	r11.u64 = ctx.r3.u64 & r27.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830c32b8
	if (!cr6.eq) goto loc_830C32B8;
loc_830C3210:
	// or r5,r3,r27
	ctx.r5.u64 = ctx.r3.u64 | r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82265bc0
	sub_82265BC0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r30,0
	r30.s64 = 0;
	// bl 0x82d4f3d8
	sub_82D4F3D8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x830c3280
	if (!cr6.gt) goto loc_830C3280;
loc_830C3234:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82d4f3e0
	sub_82D4F3E0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x82d568c0
	sub_82D568C0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830c3260
	if (cr6.eq) goto loc_830C3260;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x830c31d8
	sub_830C31D8(ctx, base);
loc_830C3260:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r26
	ctr.u64 = r26.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// bl 0x82d4f3d8
	sub_82D4F3D8(ctx, base);
	// cmpw cr6,r30,r3
	cr6.compare<int32_t>(r30.s32, ctx.r3.s32, xer);
	// blt cr6,0x830c3234
	if (cr6.lt) goto loc_830C3234;
loc_830C3280:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82d4f140
	sub_82D4F140(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830c32b8
	if (cr6.eq) goto loc_830C32B8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82d4f140
	sub_82D4F140(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82d5a318
	sub_82D5A318(ctx, base);
	// and r11,r3,r27
	r11.u64 = ctx.r3.u64 & r27.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830c3210
	if (cr6.eq) goto loc_830C3210;
loc_830C32B8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

__attribute__((alias("__imp__sub_830C32C0"))) PPC_WEAK_FUNC(sub_830C32C0);
PPC_FUNC_IMPL(__imp__sub_830C32C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,12(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,20
	cr6.compare<uint32_t>(r11.u32, 20, xer);
	// bnelr cr6
	if (!cr6.eq) return;
	// lbz r11,13(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 13);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bnelr cr6
	if (!cr6.eq) return;
	// li r11,29
	r11.s64 = 29;
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r11,12(r3)
	PPC_STORE_U8(ctx.r3.u32 + 12, r11.u8);
	// stb r10,13(r3)
	PPC_STORE_U8(ctx.r3.u32 + 13, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C32F0"))) PPC_WEAK_FUNC(sub_830C32F0);
PPC_FUNC_IMPL(__imp__sub_830C32F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82d5a318
	sub_82D5A318(ctx, base);
	// clrlwi r11,r3,31
	r11.u64 = ctx.r3.u32 & 0x1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830c3440
	if (!cr6.eq) goto loc_830C3440;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r25,0
	r25.s64 = 0;
	// addi r23,r11,17988
	r23.s64 = r11.s64 + 17988;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r24,r11,-30740
	r24.s64 = r11.s64 + -30740;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r27,r11,-21276
	r27.s64 = r11.s64 + -21276;
loc_830C333C:
	// ori r5,r3,1
	ctx.r5.u64 = ctx.r3.u64 | 1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82265bc0
	sub_82265BC0(ctx, base);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82d4f3f8
	sub_82D4F3F8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r31,r30
	r31.u64 = r30.u64;
	// lhz r28,18(r11)
	r28.u64 = PPC_LOAD_U16(r11.u32 + 18);
	// bl 0x82d4f140
	sub_82D4F140(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830c3390
	if (cr6.eq) goto loc_830C3390;
loc_830C3374:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stwx r25,r31,r28
	PPC_STORE_U32(r31.u32 + r28.u32, r25.u32);
	// bl 0x82d4f140
	sub_82D4F140(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82d4f140
	sub_82D4F140(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830c3374
	if (!cr6.eq) goto loc_830C3374;
loc_830C3390:
	// lbzx r11,r31,r28
	r11.u64 = PPC_LOAD_U8(r31.u32 + r28.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c33b8
	if (cr6.eq) goto loc_830C33B8;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82d4f3f8
	sub_82D4F3F8(ctx, base);
	// lhz r11,18(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 18);
	// lwzx r10,r11,r31
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwx r10,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r10.u32);
loc_830C33B8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stwx r25,r31,r28
	PPC_STORE_U32(r31.u32 + r28.u32, r25.u32);
	// mr r29,r25
	r29.u64 = r25.u64;
	// bl 0x82d4f3d8
	sub_82D4F3D8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x830c3408
	if (!cr6.gt) goto loc_830C3408;
loc_830C33D0:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82d4f3e0
	sub_82D4F3E0(ctx, base);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c33f4
	if (cr6.eq) goto loc_830C33F4;
	// bl 0x82d568b8
	sub_82D568B8(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x830c32f0
	sub_830C32F0(ctx, base);
loc_830C33F4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// bl 0x82d4f3d8
	sub_82D4F3D8(ctx, base);
	// cmpw cr6,r29,r3
	cr6.compare<int32_t>(r29.s32, ctx.r3.s32, xer);
	// blt cr6,0x830c33d0
	if (cr6.lt) goto loc_830C33D0;
loc_830C3408:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82d4f140
	sub_82D4F140(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830c3440
	if (cr6.eq) goto loc_830C3440;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82d4f140
	sub_82D4F140(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82d5a318
	sub_82D5A318(ctx, base);
	// clrlwi r11,r3,31
	r11.u64 = ctx.r3.u32 & 0x1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830c333c
	if (cr6.eq) goto loc_830C333C;
loc_830C3440:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c24
	return;
}

__attribute__((alias("__imp__sub_830C3448"))) PPC_WEAK_FUNC(sub_830C3448);
PPC_FUNC_IMPL(__imp__sub_830C3448) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82d5a318
	sub_82D5A318(ctx, base);
	// rlwinm r11,r3,0,29,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x4;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830c34e0
	if (!cr6.eq) goto loc_830C34E0;
	// ori r5,r3,4
	ctx.r5.u64 = ctx.r3.u64 | 4;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82265bc0
	sub_82265BC0(ctx, base);
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r30,r11,-13488
	r30.s64 = r11.s64 + -13488;
	// bl 0x82d4f130
	sub_82D4F130(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82d51730
	sub_82D51730(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830c34e0
	if (!cr6.eq) goto loc_830C34E0;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82d4f3e0
	sub_82D4F3E0(ctx, base);
	// lis r11,-31949
	r11.s64 = -2093809664;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r11,29948
	r11.s64 = r11.s64 + 29948;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x82d4f368
	sub_82D4F368(ctx, base);
	// lhz r10,18(r3)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r3.u32 + 18);
	// li r11,25
	r11.s64 = 25;
	// stbx r11,r10,r31
	PPC_STORE_U8(ctx.r10.u32 + r31.u32, r11.u8);
loc_830C34E0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C34F8"))) PPC_WEAK_FUNC(sub_830C34F8);
PPC_FUNC_IMPL(__imp__sub_830C34F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,12(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,19
	cr6.compare<uint32_t>(r11.u32, 19, xer);
	// bne cr6,0x830c3520
	if (!cr6.eq) goto loc_830C3520;
	// lbz r11,13(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 13);
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r11,12(r3)
	PPC_STORE_U8(ctx.r3.u32 + 12, r11.u8);
	// stb r10,13(r3)
	PPC_STORE_U8(ctx.r3.u32 + 13, ctx.r10.u8);
	// lhz r11,16(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 16);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// sth r11,16(r3)
	PPC_STORE_U16(ctx.r3.u32 + 16, r11.u16);
loc_830C3520:
	// lbz r11,12(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// beq cr6,0x830c3534
	if (cr6.eq) goto loc_830C3534;
	// cmplwi cr6,r11,31
	cr6.compare<uint32_t>(r11.u32, 31, xer);
	// bnelr cr6
	if (!cr6.eq) return;
loc_830C3534:
	// lhz r11,16(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 16);
	// rlwinm r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c3558
	if (cr6.eq) goto loc_830C3558;
	// li r11,4
	r11.s64 = 4;
	// stb r11,13(r3)
	PPC_STORE_U8(ctx.r3.u32 + 13, r11.u8);
	// lhz r11,16(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 16);
	// andi. r11,r11,65527
	r11.u64 = r11.u64 & 65527;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// sth r11,16(r3)
	PPC_STORE_U16(ctx.r3.u32 + 16, r11.u16);
loc_830C3558:
	// lhz r11,16(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 16);
	// rlwinm r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c357c
	if (cr6.eq) goto loc_830C357C;
	// li r11,6
	r11.s64 = 6;
	// stb r11,13(r3)
	PPC_STORE_U8(ctx.r3.u32 + 13, r11.u8);
	// lhz r11,16(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 16);
	// andi. r11,r11,65519
	r11.u64 = r11.u64 & 65519;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// sth r11,16(r3)
	PPC_STORE_U16(ctx.r3.u32 + 16, r11.u16);
loc_830C357C:
	// lhz r11,16(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 16);
	// rlwinm r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// li r11,8
	r11.s64 = 8;
	// stb r11,13(r3)
	PPC_STORE_U8(ctx.r3.u32 + 13, r11.u8);
	// lhz r11,16(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 16);
	// andi. r11,r11,65503
	r11.u64 = r11.u64 & 65503;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// sth r11,16(r3)
	PPC_STORE_U16(ctx.r3.u32 + 16, r11.u16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C35A8"))) PPC_WEAK_FUNC(sub_830C35A8);
PPC_FUNC_IMPL(__imp__sub_830C35A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// cmpwi cr6,r29,1
	cr6.compare<int32_t>(r29.s32, 1, xer);
	// bne cr6,0x830c35dc
	if (!cr6.eq) goto loc_830C35DC;
	// bl 0x830c32f0
	sub_830C32F0(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c3448
	sub_830C3448(ctx, base);
	// b 0x830c35e4
	goto loc_830C35E4;
loc_830C35DC:
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// bge cr6,0x830c35fc
	if (!cr6.lt) goto loc_830C35FC;
loc_830C35E4:
	// lis r11,-31988
	r11.s64 = -2096365568;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r6,r11,12992
	ctx.r6.s64 = r11.s64 + 12992;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c31d8
	sub_830C31D8(ctx, base);
loc_830C35FC:
	// cmpwi cr6,r29,5
	cr6.compare<int32_t>(r29.s32, 5, xer);
	// bge cr6,0x830c361c
	if (!cr6.lt) goto loc_830C361C;
	// lis r11,-31988
	r11.s64 = -2096365568;
	// li r5,8
	ctx.r5.s64 = 8;
	// addi r6,r11,13560
	ctx.r6.s64 = r11.s64 + 13560;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c31d8
	sub_830C31D8(ctx, base);
loc_830C361C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830C3628"))) PPC_WEAK_FUNC(sub_830C3628);
PPC_FUNC_IMPL(__imp__sub_830C3628) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// bl 0x82266f00
	sub_82266F00(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c36d8
	if (cr6.eq) goto loc_830C36D8;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_830C3658:
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r28,1
	cr6.compare<int32_t>(r28.s32, 1, xer);
	// bne cr6,0x830c3680
	if (!cr6.eq) goto loc_830C3680;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c32f0
	sub_830C32F0(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c3448
	sub_830C3448(ctx, base);
	// b 0x830c3688
	goto loc_830C3688;
loc_830C3680:
	// cmpwi cr6,r28,4
	cr6.compare<int32_t>(r28.s32, 4, xer);
	// bge cr6,0x830c36a0
	if (!cr6.lt) goto loc_830C36A0;
loc_830C3688:
	// lis r11,-31988
	r11.s64 = -2096365568;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r6,r11,12992
	ctx.r6.s64 = r11.s64 + 12992;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c31d8
	sub_830C31D8(ctx, base);
loc_830C36A0:
	// cmpwi cr6,r28,5
	cr6.compare<int32_t>(r28.s32, 5, xer);
	// bge cr6,0x830c36c0
	if (!cr6.lt) goto loc_830C36C0;
	// lis r11,-31988
	r11.s64 = -2096365568;
	// li r5,8
	ctx.r5.s64 = 8;
	// addi r6,r11,13560
	ctx.r6.s64 = r11.s64 + 13560;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830c31d8
	sub_830C31D8(ctx, base);
loc_830C36C0:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x830c3658
	if (!cr6.eq) goto loc_830C3658;
loc_830C36D8:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82266ec8
	sub_82266EC8(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830C36E8"))) PPC_WEAK_FUNC(sub_830C36E8);
PPC_FUNC_IMPL(__imp__sub_830C36E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C36F8"))) PPC_WEAK_FUNC(sub_830C36F8);
PPC_FUNC_IMPL(__imp__sub_830C36F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830c3724
	if (cr6.eq) goto loc_830C3724;
	// bl 0x82cbbf60
	sub_82CBBF60(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_830C3724:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C3738"))) PPC_WEAK_FUNC(sub_830C3738);
PPC_FUNC_IMPL(__imp__sub_830C3738) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// addi r8,r31,8
	ctx.r8.s64 = r31.s64 + 8;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82cbd280
	sub_82CBD280(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r10,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C3790"))) PPC_WEAK_FUNC(sub_830C3790);
PPC_FUNC_IMPL(__imp__sub_830C3790) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x830c37bc
	if (!cr6.eq) goto loc_830C37BC;
	// li r3,2
	ctx.r3.s64 = 2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_830C37BC:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82cbbd90
	sub_82CBBD90(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r11,-259
	r11.s64 = r11.s64 + -259;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C37E8"))) PPC_WEAK_FUNC(sub_830C37E8);
PPC_FUNC_IMPL(__imp__sub_830C37E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x8221ee38
	sub_8221EE38(ctx, base);
	// clrldi r3,r3,32
	ctx.r3.u64 = ctx.r3.u64 & 0xFFFFFFFF;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C3810"))) PPC_WEAK_FUNC(sub_830C3810);
PPC_FUNC_IMPL(__imp__sub_830C3810) {
	PPC_FUNC_PROLOGUE();
	// ld r3,8(r3)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C3818"))) PPC_WEAK_FUNC(sub_830C3818);
PPC_FUNC_IMPL(__imp__sub_830C3818) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C3820"))) PPC_WEAK_FUNC(sub_830C3820);
PPC_FUNC_IMPL(__imp__sub_830C3820) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830c384c
	if (cr6.eq) goto loc_830C384C;
	// bl 0x82cbbf60
	sub_82CBBF60(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_830C384C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C3860"))) PPC_WEAK_FUNC(sub_830C3860);
PPC_FUNC_IMPL(__imp__sub_830C3860) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// stfs f1,76(r5)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r5.u32 + 76, temp.u32);
	// stfs f2,92(r5)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r5.u32 + 92, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C3870"))) PPC_WEAK_FUNC(sub_830C3870);
PPC_FUNC_IMPL(__imp__sub_830C3870) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lvx128 v0,r0,r3
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r3.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r11,r31,128
	r11.s64 = r31.s64 + 128;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vsubfp v13,v0,v13
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v13.f32, _mm_sub_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// stvx128 v13,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bl 0x82d4fe98
	sub_82D4FE98(ctx, base);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// vspltisw v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_set1_epi32(int(0x0)));
	// addi r11,r31,64
	r11.s64 = r31.s64 + 64;
	// lvx128 v0,r0,r10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r10,r31,80
	ctx.r10.s64 = r31.s64 + 80;
	// vrlimi128 v0,v13,1,0
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 228), 1));
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vaddfp v13,v13,v0
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v13,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v13,r0,r10
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vaddfp v0,v13,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r0,r10
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C38F0"))) PPC_WEAK_FUNC(sub_830C38F0);
PPC_FUNC_IMPL(__imp__sub_830C38F0) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,48
	r11.s64 = 48;
	// li r28,32
	r28.s64 = 32;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lfs f0,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	f0.f64 = double(temp.f32);
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lvx128 v11,r31,r11
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// fsubs f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 - f0.f64));
	// lvx128 v12,r31,r28
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + r28.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// vaddfp v0,v12,v11
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v11.f32)));
	// lfs f13,28(r31)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vmsum4fp128 v13,v0,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// stvewx v13,r0,r10
	ea = (ctx.r10.u32) & ~0x3;
	PPC_STORE_U32(ea, ctx.v13.u32[3 - ((ea & 0xF) >> 2)]);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lfs f0,3128(r11)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3128);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,3056(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3056);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// lfs f10,3196(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3196);
	ctx.f10.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fnmsubs f0,f11,f0,f10
	f0.f64 = double(float(-(ctx.f11.f64 * f0.f64 - ctx.f10.f64)));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// fmuls f10,f11,f0
	ctx.f10.f64 = double(float(ctx.f11.f64 * f0.f64));
	// lfs f11,2708(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2708);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fnmsubs f13,f10,f13,f11
	ctx.f13.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,3080(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lvlx v13,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// lfs f13,3140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3140);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// vmulfp128 v13,v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// addi r29,r11,16912
	r29.s64 = r11.s64 + 16912;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// bge cr6,0x830c39d4
	if (!cr6.lt) goto loc_830C39D4;
	// fmuls f13,f12,f13
	ctx.fpscr.disableFlushModeUnconditional();
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v11,r0,r29
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vsubfp v11,v11,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v11.f32, _mm_sub_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v12,v11,v12
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v0,v0,v13,v12
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)), _mm_load_ps(ctx.v12.f32)));
	// b 0x830c39f8
	goto loc_830C39F8;
loc_830C39D4:
	// fmsubs f13,f12,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - f0.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v12,r0,r29
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vsubfp v12,v12,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v12.f32, _mm_sub_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v13,v12,v13
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v0,v11,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v11.f32)), _mm_load_ps(ctx.v13.f32)));
loc_830C39F8:
	// vmsum4fp128 v13,v0,v0
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stvx128 v13,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f13,112(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vmulfp128 v0,v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bl 0x82d51008
	sub_82D51008(ctx, base);
	// addi r8,r1,84
	ctx.r8.s64 = ctx.r1.s64 + 84;
	// lvx128 v13,r0,r29
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v12,r0,r31
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r9,16
	ctx.r9.s64 = 16;
	// addi r11,r30,48
	r11.s64 = r30.s64 + 48;
	// addi r10,r31,64
	ctx.r10.s64 = r31.s64 + 64;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v11,r31,r9
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vsubfp v13,v13,v0
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v13.f32, _mm_sub_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v13,v13,v12
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v0,v0,v11,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v11.f32)), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v9,v0,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v13,r0,r30
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v8,v0,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// lvx128 v12,r30,r9
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,2
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// lvx128 v11,r30,r28
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + r28.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v10,r0,r11
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmulfp128 v13,v13,v9
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v9.f32)));
	// vmaddfp v13,v12,v8,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v11,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v13.f32)));
	// vsubfp v0,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830C3AB0"))) PPC_WEAK_FUNC(sub_830C3AB0);
PPC_FUNC_IMPL(__imp__sub_830C3AB0) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,48
	r11.s64 = 48;
	// li r28,32
	r28.s64 = 32;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lfs f0,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	f0.f64 = double(temp.f32);
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// lvx128 v11,r31,r11
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// fsubs f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 - f0.f64));
	// lvx128 v12,r31,r28
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + r28.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// vaddfp v0,v12,v11
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v11.f32)));
	// lfs f13,28(r31)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f2
	f0.f64 = double(float(f0.f64 + ctx.f2.f64));
	// vmsum4fp128 v13,v0,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// fmuls f12,f0,f13
	ctx.fpscr.disableFlushModeUnconditional();
	ctx.f12.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stvewx v13,r0,r10
	ea = (ctx.r10.u32) & ~0x3;
	PPC_STORE_U32(ea, ctx.v13.u32[3 - ((ea & 0xF) >> 2)]);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lfs f0,3128(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3128);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,3056(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3056);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// lfs f10,3196(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3196);
	ctx.f10.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fnmsubs f0,f11,f0,f10
	f0.f64 = double(float(-(ctx.f11.f64 * f0.f64 - ctx.f10.f64)));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// fmuls f10,f11,f0
	ctx.f10.f64 = double(float(ctx.f11.f64 * f0.f64));
	// lfs f11,2708(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2708);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fnmsubs f13,f10,f13,f11
	ctx.f13.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,3080(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lvlx v13,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// lfs f13,3140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3140);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// vmulfp128 v13,v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// addi r29,r11,16912
	r29.s64 = r11.s64 + 16912;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// bge cr6,0x830c3b98
	if (!cr6.lt) goto loc_830C3B98;
	// fmuls f13,f12,f13
	ctx.fpscr.disableFlushModeUnconditional();
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v11,r0,r29
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vsubfp v11,v11,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v11.f32, _mm_sub_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v12,v11,v12
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v0,v0,v13,v12
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)), _mm_load_ps(ctx.v12.f32)));
	// b 0x830c3bbc
	goto loc_830C3BBC;
loc_830C3B98:
	// fmsubs f13,f12,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - f0.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v12,r0,r29
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vsubfp v12,v12,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v12.f32, _mm_sub_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v13,v12,v13
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v0,v11,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v11.f32)), _mm_load_ps(ctx.v13.f32)));
loc_830C3BBC:
	// vmsum4fp128 v13,v0,v0
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stvx128 v13,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f13,112(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vmulfp128 v0,v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bl 0x82d51008
	sub_82D51008(ctx, base);
	// addi r8,r1,84
	ctx.r8.s64 = ctx.r1.s64 + 84;
	// lvx128 v13,r0,r29
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v12,r0,r31
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r9,16
	ctx.r9.s64 = 16;
	// addi r11,r30,48
	r11.s64 = r30.s64 + 48;
	// addi r10,r31,64
	ctx.r10.s64 = r31.s64 + 64;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v11,r31,r9
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vsubfp v13,v13,v0
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v13.f32, _mm_sub_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v13,v13,v12
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v0,v0,v11,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v11.f32)), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v9,v0,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v13,r0,r30
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v8,v0,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// lvx128 v12,r30,r9
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,2
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// lvx128 v11,r30,r28
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + r28.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v10,r0,r11
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmulfp128 v13,v13,v9
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v9.f32)));
	// vmaddfp v13,v12,v8,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v11,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v13.f32)));
	// vsubfp v0,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830C3C78"))) PPC_WEAK_FUNC(sub_830C3C78);
PPC_FUNC_IMPL(__imp__sub_830C3C78) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stfs f1,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// li r11,48
	r11.s64 = 48;
	// li r28,32
	r28.s64 = 32;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lvx128 v11,r31,r11
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lvx128 v12,r31,r28
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + r28.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vaddfp v0,v12,v11
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v11.f32)));
	// vmsum4fp128 v13,v0,v0
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// stvewx v13,r0,r10
	ea = (ctx.r10.u32) & ~0x3;
	PPC_STORE_U32(ea, ctx.v13.u32[3 - ((ea & 0xF) >> 2)]);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lfs f0,3128(r11)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3128);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,3056(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3056);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f1,f13
	cr6.compare(ctx.f1.f64, ctx.f13.f64);
	// lfs f11,3196(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3196);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fnmsubs f0,f12,f0,f11
	f0.f64 = double(float(-(ctx.f12.f64 * f0.f64 - ctx.f11.f64)));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fmuls f11,f12,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 * f0.f64));
	// lfs f12,2708(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2708);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fnmsubs f13,f11,f13,f12
	ctx.f13.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,3080(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lvlx v13,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// lfs f13,3140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3140);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// vmulfp128 v13,v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// addi r29,r11,16912
	r29.s64 = r11.s64 + 16912;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// bge cr6,0x830c3d4c
	if (!cr6.lt) goto loc_830C3D4C;
	// fmuls f13,f1,f13
	ctx.fpscr.disableFlushModeUnconditional();
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v11,r0,r29
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vsubfp v11,v11,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v11.f32, _mm_sub_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v12,v11,v12
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v0,v0,v13,v12
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)), _mm_load_ps(ctx.v12.f32)));
	// b 0x830c3d70
	goto loc_830C3D70;
loc_830C3D4C:
	// fmsubs f13,f1,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 - f0.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v12,r0,r29
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vsubfp v12,v12,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v12.f32, _mm_sub_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v13,v12,v13
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v0,v11,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v11.f32)), _mm_load_ps(ctx.v13.f32)));
loc_830C3D70:
	// vmsum4fp128 v13,v0,v0
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stvx128 v13,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f13,112(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vmulfp128 v0,v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bl 0x82d51008
	sub_82D51008(ctx, base);
	// addi r8,r1,84
	ctx.r8.s64 = ctx.r1.s64 + 84;
	// lvx128 v13,r0,r29
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v12,r0,r31
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r9,16
	ctx.r9.s64 = 16;
	// addi r11,r30,48
	r11.s64 = r30.s64 + 48;
	// addi r10,r31,64
	ctx.r10.s64 = r31.s64 + 64;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v11,r31,r9
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vsubfp v13,v13,v0
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v13.f32, _mm_sub_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v13,v13,v12
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v0,v0,v11,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v11.f32)), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v9,v0,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v13,r0,r30
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v8,v0,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// lvx128 v12,r30,r9
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,2
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// lvx128 v11,r30,r28
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + r28.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v10,r0,r11
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmulfp128 v13,v13,v9
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v9.f32)));
	// vmaddfp v13,v12,v8,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v11,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v13.f32)));
	// vsubfp v0,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830C3E28"))) PPC_WEAK_FUNC(sub_830C3E28);
PPC_FUNC_IMPL(__imp__sub_830C3E28) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r28,32
	r28.s64 = 32;
	// addi r31,r30,64
	r31.s64 = r30.s64 + 64;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r11,r31,48
	r11.s64 = r31.s64 + 48;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// lfs f0,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	f0.f64 = double(temp.f32);
	// addi r8,r31,28
	ctx.r8.s64 = r31.s64 + 28;
	// fsubs f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 - f0.f64));
	// lvx128 v12,r31,r28
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + r28.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v11,r0,r11
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vaddfp v0,v12,v11
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v11.f32)));
	// lfs f13,28(r31)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f13,3120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3120);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// vmsum4fp128 v13,v0,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// fsubs f12,f0,f13
	ctx.fpscr.disableFlushModeUnconditional();
	ctx.f12.f64 = double(float(f0.f64 - ctx.f13.f64));
	// fsel f12,f12,f0,f13
	ctx.f12.f64 = ctx.f12.f64 >= 0.0 ? f0.f64 : ctx.f13.f64;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stvewx v13,r0,r9
	ea = (ctx.r9.u32) & ~0x3;
	PPC_STORE_U32(ea, ctx.v13.u32[3 - ((ea & 0xF) >> 2)]);
	// lfs f0,3128(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3128);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,3056(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3056);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// lfs f10,3196(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3196);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fnmsubs f0,f11,f0,f10
	f0.f64 = double(float(-(ctx.f11.f64 * f0.f64 - ctx.f10.f64)));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// fmuls f10,f11,f0
	ctx.f10.f64 = double(float(ctx.f11.f64 * f0.f64));
	// lfs f11,2708(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2708);
	ctx.f11.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fnmsubs f13,f10,f13,f11
	ctx.f13.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v13,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// lfs f0,3080(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3080);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// vmulfp128 v0,v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// lfs f13,3140(r10)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3140);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// addi r9,r10,16912
	ctx.r9.s64 = ctx.r10.s64 + 16912;
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bge cr6,0x830c3f20
	if (!cr6.lt) goto loc_830C3F20;
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v13,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// lvx128 v11,r0,r9
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vsubfp v11,v11,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v11.f32, _mm_sub_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v13.f32)));
	// vmulfp128 v12,v11,v12
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v0,v13,v0,v12
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v12.f32)));
	// b 0x830c3f44
	goto loc_830C3F44;
loc_830C3F20:
	// fmsubs f13,f12,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - f0.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v13,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// lvx128 v12,r0,r9
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vsubfp v12,v12,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v12.f32, _mm_sub_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v13.f32)));
	// vmulfp128 v0,v12,v0
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v0,v13,v11,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v11.f32)), _mm_load_ps(ctx.v0.f32)));
loc_830C3F44:
	// vmsum4fp128 v11,v0,v0
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v11.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r29,r31,16
	r29.s64 = r31.s64 + 16;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r10,r30,144
	ctx.r10.s64 = r30.s64 + 144;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lvlx v13,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lvlx v12,0,r6
	temp.u32 = ctx.r6.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v12,v12,0
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0xFF));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// stvx128 v11,r0,r7
	_mm_store_si128((__m128i*)(base + ((ctx.r7.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v11.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f13,96(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// lvx128 v11,r0,r7
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r7.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v11,v11,0
	_mm_store_si128((__m128i*)ctx.v11.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v11.u32), 0xFF));
	// vmulfp128 v0,v0,v11
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v11.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r9
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vsubfp v0,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// lvx128 v11,r0,r31
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v10,r0,r29
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f0,0(r8)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	f0.f64 = double(temp.f32);
	// fdivs f0,f0,f12
	f0.f64 = double(float(f0.f64 / ctx.f12.f64));
	// vmulfp128 v0,v0,v11
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v11.f32)));
	// vmaddfp v0,v13,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r0,r29
	_mm_store_si128((__m128i*)(base + ((r29.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stfs f0,0(r8)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// lvx128 v0,r0,r10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmulfp128 v0,v0,v12
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v12.f32)));
	// stvx128 v0,r0,r10
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bl 0x82d51008
	sub_82D51008(ctx, base);
	// addi r11,r31,64
	r11.s64 = r31.s64 + 64;
	// lvx128 v13,r0,r30
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r10,16
	ctx.r10.s64 = 16;
	// lvx128 v10,r30,r28
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + r28.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v12,r0,r29
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r9,48
	ctx.r9.s64 = 48;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v9,v0,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v11,r30,r10
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v8,v0,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// vspltw v0,v0,2
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// vmulfp128 v13,v13,v9
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v9.f32)));
	// vmaddfp v13,v11,v8,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v10,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v13.f32)));
	// vsubfp v0,v12,v0
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r30,r9
	_mm_store_si128((__m128i*)(base + ((r30.u32 + ctx.r9.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830C4028"))) PPC_WEAK_FUNC(sub_830C4028);
PPC_FUNC_IMPL(__imp__sub_830C4028) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r31,r30,64
	r31.s64 = r30.s64 + 64;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// addi r11,r31,48
	r11.s64 = r31.s64 + 48;
	// addi r9,r31,32
	ctx.r9.s64 = r31.s64 + 32;
	// addi r7,r31,12
	ctx.r7.s64 = r31.s64 + 12;
	// lfs f0,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	f0.f64 = double(temp.f32);
	// addi r6,r31,28
	ctx.r6.s64 = r31.s64 + 28;
	// fsubs f12,f1,f0
	ctx.f12.f64 = double(float(ctx.f1.f64 - f0.f64));
	// lfs f13,28(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// lvx128 v12,r0,r11
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v11,r0,r9
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vaddfp v0,v11,v12
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v12.f32)));
	// fsel f9,f12,f1,f0
	ctx.fpscr.disableFlushModeUnconditional();
	ctx.f9.f64 = ctx.f12.f64 >= 0.0 ? ctx.f1.f64 : f0.f64;
	// vmsum4fp128 v13,v0,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// fsubs f0,f9,f0
	ctx.fpscr.disableFlushModeUnconditional();
	f0.f64 = double(float(ctx.f9.f64 - f0.f64));
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stvewx v13,r0,r10
	ea = (ctx.r10.u32) & ~0x3;
	PPC_STORE_U32(ea, ctx.v13.u32[3 - ((ea & 0xF) >> 2)]);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,3128(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3128);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,3056(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3056);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// lfs f10,3196(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3196);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fnmsubs f0,f11,f0,f10
	f0.f64 = double(float(-(ctx.f11.f64 * f0.f64 - ctx.f10.f64)));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// fmuls f10,f11,f0
	ctx.f10.f64 = double(float(ctx.f11.f64 * f0.f64));
	// lfs f11,2708(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2708);
	ctx.f11.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fnmsubs f13,f10,f13,f11
	ctx.f13.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v13,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// lfs f0,3080(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3080);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// vmulfp128 v0,v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// lfs f13,3140(r10)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3140);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// addi r10,r10,16912
	ctx.r10.s64 = ctx.r10.s64 + 16912;
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bge cr6,0x830c411c
	if (!cr6.lt) goto loc_830C411C;
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v13,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// lvx128 v12,r0,r10
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vsubfp v12,v12,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v12.f32, _mm_sub_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v13.f32)));
	// vmulfp128 v12,v12,v11
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v11.f32)));
	// vmaddfp v0,v13,v0,v12
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v12.f32)));
	// b 0x830c4140
	goto loc_830C4140;
loc_830C411C:
	// fmsubs f13,f12,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - f0.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v13,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// lvx128 v11,r0,r10
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vsubfp v11,v11,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v11.f32, _mm_sub_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v13.f32)));
	// vmulfp128 v0,v11,v0
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v0,v13,v12,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v12.f32)), _mm_load_ps(ctx.v0.f32)));
loc_830C4140:
	// vmsum4fp128 v12,v0,v0
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v12.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r29,r31,16
	r29.s64 = r31.s64 + 16;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lfs f13,3084(r8)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 3084);
	ctx.f13.f64 = double(temp.f32);
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// lvlx v13,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// stvx128 v12,r0,r8
	_mm_store_si128((__m128i*)(base + ((ctx.r8.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fsqrts f12,f12
	ctx.f12.f64 = double(float(sqrt(ctx.f12.f64)));
	// fdivs f0,f0,f12
	f0.f64 = double(float(f0.f64 / ctx.f12.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// lvx128 v12,r0,r8
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r8.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v12,v12,0
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0xFF));
	// vmulfp128 v0,v0,v12
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v12.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r0,r9
	_mm_store_si128((__m128i*)(base + ((ctx.r9.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vsubfp v0,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// lvx128 v12,r0,r31
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v11,r0,r29
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmulfp128 v0,v0,v12
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v0,v13,v11,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v11.f32)), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r0,r29
	_mm_store_si128((__m128i*)(base + ((r29.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r0,r31
	_mm_store_si128((__m128i*)(base + ((r31.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stfs f9,0(r7)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// stfs f13,0(r6)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// bl 0x82d51008
	sub_82D51008(ctx, base);
	// addi r11,r31,64
	r11.s64 = r31.s64 + 64;
	// lvx128 v13,r0,r30
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r10,16
	ctx.r10.s64 = 16;
	// lvx128 v12,r0,r29
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r9,32
	ctx.r9.s64 = 32;
	// li r8,48
	ctx.r8.s64 = 48;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v9,v0,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v11,r30,r10
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v8,v0,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// lvx128 v10,r30,r9
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,2
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// vmulfp128 v13,v13,v9
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v9.f32)));
	// vmaddfp v13,v11,v8,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v10,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v13.f32)));
	// vsubfp v0,v12,v0
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r30,r8
	_mm_store_si128((__m128i*)(base + ((r30.u32 + ctx.r8.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830C4218"))) PPC_WEAK_FUNC(sub_830C4218);
PPC_FUNC_IMPL(__imp__sub_830C4218) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// li r27,32
	r27.s64 = 32;
	// addi r11,r30,144
	r11.s64 = r30.s64 + 144;
	// addi r31,r30,64
	r31.s64 = r30.s64 + 64;
	// li r28,48
	r28.s64 = 48;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vxor v0,v0,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_setzero_si128());
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r4
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r4.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r31,r27
	_mm_store_si128((__m128i*)(base + ((r31.u32 + r27.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r4
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r4.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r31,r28
	_mm_store_si128((__m128i*)(base + ((r31.u32 + r28.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bl 0x82d51008
	sub_82D51008(ctx, base);
	// addi r11,r31,64
	r11.s64 = r31.s64 + 64;
	// lvx128 v0,r0,r29
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r30,r28
	_mm_store_si128((__m128i*)(base + ((r30.u32 + r28.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lvx128 v13,r0,r30
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v11,r30,r27
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + r27.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v10,r0,r29
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v9,v0,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lfs f0,3084(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3084);
	f0.f64 = double(temp.f32);
	// li r10,16
	ctx.r10.s64 = 16;
	// vspltw v8,v0,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// vspltw v0,v0,2
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// lfs f13,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// vmulfp128 v13,v13,v9
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v9.f32)));
	// lvx128 v12,r30,r10
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmaddfp v13,v12,v8,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v11,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v13.f32)));
	// vaddfp v0,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r0,r31
	_mm_store_si128((__m128i*)(base + ((r31.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r31,r10
	_mm_store_si128((__m128i*)(base + ((r31.u32 + ctx.r10.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stfs f13,12(r31)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// stfs f0,28(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 28, temp.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830C42C8"))) PPC_WEAK_FUNC(sub_830C42C8);
PPC_FUNC_IMPL(__imp__sub_830C42C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r11,r29,144
	r11.s64 = r29.s64 + 144;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r31,r29,64
	r31.s64 = r29.s64 + 64;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vxor v0,v0,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_setzero_si128());
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bl 0x82d50a00
	sub_82D50A00(ctx, base);
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// lvx128 v0,r0,r30
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// stvx128 v0,r0,r29
	_mm_store_si128((__m128i*)(base + ((r29.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r30,16
	r11.s64 = r30.s64 + 16;
	// li r5,16
	ctx.r5.s64 = 16;
	// addi r10,r30,32
	ctx.r10.s64 = r30.s64 + 32;
	// li r6,32
	ctx.r6.s64 = 32;
	// lfs f0,3084(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 3084);
	f0.f64 = double(temp.f32);
	// addi r9,r30,48
	ctx.r9.s64 = r30.s64 + 48;
	// lvx128 v0,r0,r8
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r8.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r7,48
	ctx.r7.s64 = 48;
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v13,r29,r5
	_mm_store_si128((__m128i*)(base + ((r29.u32 + ctx.r5.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r8,r31,64
	ctx.r8.s64 = r31.s64 + 64;
	// lvx128 v13,r0,r10
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v13,r29,r6
	_mm_store_si128((__m128i*)(base + ((r29.u32 + ctx.r6.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v13,r0,r9
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v13,r29,r7
	_mm_store_si128((__m128i*)(base + ((r29.u32 + ctx.r7.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r31,r6
	_mm_store_si128((__m128i*)(base + ((r31.u32 + ctx.r6.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r31,r7
	_mm_store_si128((__m128i*)(base + ((r31.u32 + ctx.r7.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r8
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r8.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v9,v0,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v13,r0,r30
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v8,v0,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// lvx128 v12,r0,r11
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,2
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// lvx128 v11,r0,r10
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v10,r0,r9
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmulfp128 v13,v13,v9
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v9.f32)));
	// lfs f13,12(r31)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// vmaddfp v13,v12,v8,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v11,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v13.f32)));
	// vaddfp v0,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r0,r31
	_mm_store_si128((__m128i*)(base + ((r31.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r31,r5
	_mm_store_si128((__m128i*)(base + ((r31.u32 + ctx.r5.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stfs f13,12(r31)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// stfs f0,28(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 28, temp.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830C43A0"))) PPC_WEAK_FUNC(sub_830C43A0);
PPC_FUNC_IMPL(__imp__sub_830C43A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// addi r10,r4,144
	ctx.r10.s64 = ctx.r4.s64 + 144;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r6,48
	ctx.r6.s64 = 48;
	// li r7,16
	ctx.r7.s64 = 16;
	// li r8,32
	ctx.r8.s64 = 32;
	// lvx128 v0,r0,r10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f0,3084(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f0.f64 = double(temp.f32);
	// addi r11,r4,64
	r11.s64 = ctx.r4.s64 + 64;
	// vxor v0,v0,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_setzero_si128());
	// addi r9,r11,64
	ctx.r9.s64 = r11.s64 + 64;
	// stvx128 v0,r0,r10
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r3
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r3.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r4,r6
	_mm_store_si128((__m128i*)(base + ((ctx.r4.u32 + ctx.r6.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r9
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v13,r0,r4
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r4.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v8,v0,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// lvx128 v12,r4,r7
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r4.u32 + ctx.r7.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v11,r4,r8
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r4.u32 + ctx.r8.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v10,r0,r3
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r3.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v9,r11,r6
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32 + ctx.r6.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v9,r11,r8
	_mm_store_si128((__m128i*)(base + ((r11.u32 + ctx.r8.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v9.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v9,v0,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vspltw v0,v0,2
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// vmulfp128 v13,v13,v9
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v9.f32)));
	// vmaddfp v13,v12,v8,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v11,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v13.f32)));
	// vaddfp v0,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r11,r7
	_mm_store_si128((__m128i*)(base + ((r11.u32 + ctx.r7.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stfs f13,12(r11)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 12, temp.u32);
	// stfs f0,28(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 28, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4428"))) PPC_WEAK_FUNC(sub_830C4428);
PPC_FUNC_IMPL(__imp__sub_830C4428) {
	PPC_FUNC_PROLOGUE();
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r5,48
	ctx.r3.s64 = ctx.r5.s64 + 48;
	// b 0x830c4218
	sub_830C4218(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_830C4438"))) PPC_WEAK_FUNC(sub_830C4438);
PPC_FUNC_IMPL(__imp__sub_830C4438) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stfd f30,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f30.u64);
	// stfd f31,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r31,r30,64
	r31.s64 = r30.s64 + 64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r29,r31,16
	r29.s64 = r31.s64 + 16;
	// addi r28,r31,48
	r28.s64 = r31.s64 + 48;
	// addi r11,r31,32
	r11.s64 = r31.s64 + 32;
	// lvx128 v0,r0,r29
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v13,r0,r28
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r28.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v13,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// vpermwi128 v7,v13,135
	_mm_store_si128((__m128i*)ctx.v7.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x78));
	// stvx128 v0,r0,r31
	_mm_store_si128((__m128i*)(base + ((r31.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// vpermwi128 v6,v13,99
	_mm_store_si128((__m128i*)ctx.v6.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x9C));
	// lvx128 v0,r0,r4
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r4.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vor v8,v13,v13
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_load_si128((__m128i*)ctx.v13.u8));
	// stvx128 v0,r0,r29
	_mm_store_si128((__m128i*)(base + ((r29.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v12,v13,3
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x0));
	// lvx128 v0,r0,r5
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r5.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// stvx128 v0,r0,r28
	_mm_store_si128((__m128i*)(base + ((r28.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r5
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r5.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vpermwi128 v11,v0,99
	_mm_store_si128((__m128i*)ctx.v11.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x9C));
	// vmsum4fp128 v13,v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32), 0xFF));
	// vpermwi128 v10,v0,135
	_mm_store_si128((__m128i*)ctx.v10.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x78));
	// vspltw v9,v0,3
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x0));
	// vmulfp128 v11,v7,v11
	_mm_store_ps(ctx.v11.f32, _mm_mul_ps(_mm_load_ps(ctx.v7.f32), _mm_load_ps(ctx.v11.f32)));
	// vmulfp128 v10,v6,v10
	_mm_store_ps(ctx.v10.f32, _mm_mul_ps(_mm_load_ps(ctx.v6.f32), _mm_load_ps(ctx.v10.f32)));
	// vsubfp v11,v10,v11
	_mm_store_ps(ctx.v11.f32, _mm_sub_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v11.f32)));
	// vnmsubfp v11,v8,v9,v11
	_mm_store_ps(ctx.v11.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v9.f32)), _mm_load_ps(ctx.v11.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vmaddfp v0,v0,v12,v11
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v12.f32)), _mm_load_ps(ctx.v11.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stvewx v13,r0,r10
	ea = (ctx.r10.u32) & ~0x3;
	PPC_STORE_U32(ea, ctx.v13.u32[3 - ((ea & 0xF) >> 2)]);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fabs f0,f0
	f0.u64 = f0.u64 & ~0x8000000000000000;
	// lfs f13,3080(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,3084(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f30.f64 = double(temp.f32);
	// fmr f1,f0
	ctx.f1.f64 = f0.f64;
	// fabs f12,f1
	ctx.f12.u64 = ctx.f1.u64 & ~0x8000000000000000;
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// blt cr6,0x830c4514
	if (cr6.lt) goto loc_830C4514;
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// ble cr6,0x830c4508
	if (!cr6.gt) goto loc_830C4508;
	// fmr f13,f30
	ctx.f13.f64 = f30.f64;
	// b 0x830c451c
	goto loc_830C451C;
loc_830C4508:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,2876(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2876);
	ctx.f13.f64 = double(temp.f32);
	// b 0x830c451c
	goto loc_830C451C;
loc_830C4514:
	// bl 0x82260900
	sub_82260900(ctx, base);
	// frsp f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64));
loc_830C451C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,3140(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3140);
	f0.f64 = double(temp.f32);
	// fmuls f31,f13,f0
	f31.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f31,80(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fcmpu cr6,f31,f30
	cr6.compare(f31.f64, f30.f64);
	// beq cr6,0x830c454c
	if (cr6.eq) goto loc_830C454C;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x821db0c8
	sub_821DB0C8(ctx, base);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// b 0x830c4558
	goto loc_830C4558;
loc_830C454C:
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vxor v0,v0,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_setzero_si128());
loc_830C4558:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// li r10,144
	ctx.r10.s64 = 144;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lvlx v13,0,r11
	temp.u32 = r11.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vmulfp128 v0,v0,v13
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v0,r30,r10
	_mm_store_si128((__m128i*)(base + ((r30.u32 + ctx.r10.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stfs f31,156(r30)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r30.u32 + 156, temp.u32);
	// lfs f0,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// lfs f0,12(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,28(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 28, temp.u32);
	// bl 0x82d51008
	sub_82D51008(ctx, base);
	// addi r11,r31,64
	r11.s64 = r31.s64 + 64;
	// lvx128 v13,r0,r30
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r10,16
	ctx.r10.s64 = 16;
	// lvx128 v12,r0,r29
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r9,32
	ctx.r9.s64 = 32;
	// li r8,48
	ctx.r8.s64 = 48;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v9,v0,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v11,r30,r10
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v8,v0,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// lvx128 v10,r30,r9
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,2
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// vmulfp128 v13,v13,v9
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v9.f32)));
	// vmaddfp v13,v11,v8,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v10,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v13.f32)));
	// vsubfp v0,v12,v0
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r30,r8
	_mm_store_si128((__m128i*)(base + ((r30.u32 + ctx.r8.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f30,-64(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f31,-56(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830C45E8"))) PPC_WEAK_FUNC(sub_830C45E8);
PPC_FUNC_IMPL(__imp__sub_830C45E8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C45F0"))) PPC_WEAK_FUNC(sub_830C45F0);
PPC_FUNC_IMPL(__imp__sub_830C45F0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C45F8"))) PPC_WEAK_FUNC(sub_830C45F8);
PPC_FUNC_IMPL(__imp__sub_830C45F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// li r11,-47
	r11.s64 = -47;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4608"))) PPC_WEAK_FUNC(sub_830C4608);
PPC_FUNC_IMPL(__imp__sub_830C4608) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r11,-47
	cr6.compare<int32_t>(r11.s32, -47, xer);
	// bnelr cr6
	if (!cr6.eq) return;
	// li r11,-15
	r11.s64 = -15;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4628"))) PPC_WEAK_FUNC(sub_830C4628);
PPC_FUNC_IMPL(__imp__sub_830C4628) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r10,-47
	ctx.r10.s64 = -47;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4648"))) PPC_WEAK_FUNC(sub_830C4648);
PPC_FUNC_IMPL(__imp__sub_830C4648) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r24{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,63
	r11.s64 = r11.s64 + 63;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bgt cr6,0x830c4770
	if (cr6.gt) goto loc_830C4770;
	// lis r12,-31988
	r12.s64 = -2096365568;
	// addi r12,r12,18052
	r12.s64 = r12.s64 + 18052;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_830C4748;
	case 1:
		goto loc_830C4770;
	case 2:
		goto loc_830C4770;
	case 3:
		goto loc_830C4770;
	case 4:
		goto loc_830C4770;
	case 5:
		goto loc_830C4770;
	case 6:
		goto loc_830C4770;
	case 7:
		goto loc_830C4770;
	case 8:
		goto loc_830C4770;
	case 9:
		goto loc_830C4770;
	case 10:
		goto loc_830C4770;
	case 11:
		goto loc_830C4770;
	case 12:
		goto loc_830C4770;
	case 13:
		goto loc_830C4770;
	case 14:
		goto loc_830C4770;
	case 15:
		goto loc_830C4770;
	case 16:
		goto loc_830C47A8;
	case 17:
		goto loc_830C4770;
	case 18:
		goto loc_830C4770;
	case 19:
		goto loc_830C4770;
	case 20:
		goto loc_830C4770;
	case 21:
		goto loc_830C4770;
	case 22:
		goto loc_830C4770;
	case 23:
		goto loc_830C4770;
	case 24:
		goto loc_830C4770;
	case 25:
		goto loc_830C4770;
	case 26:
		goto loc_830C4770;
	case 27:
		goto loc_830C4770;
	case 28:
		goto loc_830C4770;
	case 29:
		goto loc_830C4770;
	case 30:
		goto loc_830C4770;
	case 31:
		goto loc_830C4770;
	case 32:
		goto loc_830C4748;
	case 33:
		goto loc_830C4770;
	case 34:
		goto loc_830C4770;
	case 35:
		goto loc_830C4770;
	case 36:
		goto loc_830C4770;
	case 37:
		goto loc_830C4770;
	case 38:
		goto loc_830C4770;
	case 39:
		goto loc_830C4770;
	case 40:
		goto loc_830C4770;
	case 41:
		goto loc_830C4770;
	case 42:
		goto loc_830C4770;
	case 43:
		goto loc_830C4770;
	case 44:
		goto loc_830C4770;
	case 45:
		goto loc_830C4770;
	case 46:
		goto loc_830C4770;
	case 47:
		goto loc_830C4770;
	case 48:
		goto loc_830C4748;
	default:
		__builtin_unreachable();
	}
	// lwz r24,18248(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18248);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18344(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18344);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18248(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18248);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18288(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18288);
	// lwz r24,18248(r12)
	r24.u64 = PPC_LOAD_U32(r12.u32 + 18248);
loc_830C4748:
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r30,r11,-20736
	r30.s64 = r11.s64 + -20736;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82184450
	sub_82184450(ctx, base);
	// cmpwi cr6,r29,1
	cr6.compare<int32_t>(r29.s32, 1, xer);
	// li r11,-31
	r11.s64 = -31;
	// beq cr6,0x830c4768
	if (cr6.eq) goto loc_830C4768;
	// li r11,-63
	r11.s64 = -63;
loc_830C4768:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x830c4780
	goto loc_830C4780;
loc_830C4770:
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r30,r11,-20736
	r30.s64 = r11.s64 + -20736;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82184450
	sub_82184450(ctx, base);
loc_830C4780:
	// lhz r11,4(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// li r10,-1
	ctx.r10.s64 = -1;
	// lhz r9,6(r31)
	ctx.r9.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rotlwi r9,r9,1
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// sth r9,6(r31)
	PPC_STORE_U16(r31.u32 + 6, ctx.r9.u16);
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// std r10,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, ctx.r10.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
loc_830C47A8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830C47B0"))) PPC_WEAK_FUNC(sub_830C47B0);
PPC_FUNC_IMPL(__imp__sub_830C47B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmpwi cr6,r11,-47
	cr6.compare<int32_t>(r11.s32, -47, xer);
	// beq cr6,0x830c482c
	if (cr6.eq) goto loc_830C482C;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// lwz r30,-20736(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + -20736);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82184450
	sub_82184450(ctx, base);
	// bl 0x830c37e8
	sub_830C37E8(ctx, base);
	// lhz r11,6(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// li r9,1
	ctx.r9.s64 = 1;
	// rotlwi r8,r11,1
	ctx.r8.u64 = __builtin_rotateleft32(r11.u32, 1);
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwimi r8,r9,0,31,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFFFFFFFFFFFF0001) | (ctx.r8.u64 & 0xFFFE);
	// rotlwi r11,r3,0
	r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// cmpwi cr6,r7,-15
	cr6.compare<int32_t>(ctx.r7.s32, -15, xer);
	// sth r10,4(r31)
	PPC_STORE_U16(r31.u32 + 4, ctx.r10.u16);
	// sth r8,6(r31)
	PPC_STORE_U16(r31.u32 + 6, ctx.r8.u16);
	// bne cr6,0x830c481c
	if (!cr6.eq) goto loc_830C481C;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_830C481C:
	// li r11,-1
	r11.s64 = -1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// std r11,32(r30)
	PPC_STORE_U64(r30.u32 + 32, r11.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
loc_830C482C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4848"))) PPC_WEAK_FUNC(sub_830C4848);
PPC_FUNC_IMPL(__imp__sub_830C4848) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,-47
	cr6.compare<int32_t>(r11.s32, -47, xer);
	// beq cr6,0x830c48a0
	if (cr6.eq) goto loc_830C48A0;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// lwz r31,-20736(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + -20736);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82184450
	sub_82184450(ctx, base);
	// bl 0x830c37e8
	sub_830C37E8(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rotlwi r11,r3,0
	r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// li r11,-1
	r11.s64 = -1;
	// std r11,32(r31)
	PPC_STORE_U64(r31.u32 + 32, r11.u64);
	// bne cr6,0x830c48a8
	if (!cr6.eq) goto loc_830C48A8;
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
loc_830C48A0:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x830c48b0
	goto loc_830C48B0;
loc_830C48A8:
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_830C48B0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C48C8"))) PPC_WEAK_FUNC(sub_830C48C8);
PPC_FUNC_IMPL(__imp__sub_830C48C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmpwi cr6,r11,-47
	cr6.compare<int32_t>(r11.s32, -47, xer);
	// beq cr6,0x830c4938
	if (cr6.eq) goto loc_830C4938;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// lwz r30,-20736(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + -20736);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82184450
	sub_82184450(ctx, base);
	// lhz r11,4(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// lhz r10,6(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// sth r10,6(r31)
	PPC_STORE_U16(r31.u32 + 6, ctx.r10.u16);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// bne cr6,0x830c4928
	if (!cr6.eq) goto loc_830C4928;
	// li r11,-15
	r11.s64 = -15;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_830C4928:
	// li r11,-1
	r11.s64 = -1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// std r11,32(r30)
	PPC_STORE_U64(r30.u32 + 32, r11.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
loc_830C4938:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4950"))) PPC_WEAK_FUNC(sub_830C4950);
PPC_FUNC_IMPL(__imp__sub_830C4950) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmpwi cr6,r11,-47
	cr6.compare<int32_t>(r11.s32, -47, xer);
	// beq cr6,0x830c49c0
	if (cr6.eq) goto loc_830C49C0;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// lwz r30,-20736(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + -20736);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82184450
	sub_82184450(ctx, base);
	// lhz r11,4(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// lhz r10,6(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// sth r10,6(r31)
	PPC_STORE_U16(r31.u32 + 6, ctx.r10.u16);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// bne cr6,0x830c49b0
	if (!cr6.eq) goto loc_830C49B0;
	// li r11,-15
	r11.s64 = -15;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_830C49B0:
	// li r11,-1
	r11.s64 = -1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// std r11,32(r30)
	PPC_STORE_U64(r30.u32 + 32, r11.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
loc_830C49C0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C49D8"))) PPC_WEAK_FUNC(sub_830C49D8);
PPC_FUNC_IMPL(__imp__sub_830C49D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r13)
	r11.u64 = PPC_LOAD_U32(ctx.r13.u32 + 0);
	// li r10,4
	ctx.r10.s64 = 4;
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r29,96(r3)
	r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 96);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830c4a14
	if (cr6.eq) goto loc_830C4A14;
	// lwz r11,100(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 100);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,100(r3)
	PPC_STORE_U32(ctx.r3.u32 + 100, r11.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r11,96(r3)
	PPC_STORE_U32(ctx.r3.u32 + 96, r11.u32);
	// b 0x830c4a20
	goto loc_830C4A20;
loc_830C4A14:
	// li r4,5
	ctx.r4.s64 = 5;
	// bl 0x82d4ea30
	sub_82D4EA30(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
loc_830C4A20:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x830c4aa4
	if (cr6.eq) goto loc_830C4AA4;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r31,r29,40
	r31.s64 = r29.s64 + 40;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,1000
	ctx.r9.s64 = 1000;
	// addi r30,r11,-20792
	r30.s64 = r11.s64 + -20792;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
	// bl 0x82184450
	sub_82184450(ctx, base);
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c4a68
	if (cr6.eq) goto loc_830C4A68;
	// stw r29,44(r11)
	PPC_STORE_U32(r11.u32 + 44, r29.u32);
loc_830C4A68:
	// li r11,-1
	r11.s64 = -1;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r29,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r29.u32);
	// std r11,32(r30)
	PPC_STORE_U64(r30.u32 + 32, r11.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// li r4,1000
	ctx.r4.s64 = 1000;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x832b259c
	__imp__RtlInitializeCriticalSectionAndSpinCount(ctx, base);
	// li r11,-1
	r11.s64 = -1;
	// std r11,32(r29)
	PPC_STORE_U64(r29.u32 + 32, r11.u64);
	// lis r11,-31946
	r11.s64 = -2093613056;
	// stw r29,-20736(r11)
	PPC_STORE_U32(r11.u32 + -20736, r29.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_830C4AA4:
	// lis r10,-31946
	ctx.r10.s64 = -2093613056;
	// li r11,0
	r11.s64 = 0;
	// stw r11,-20736(r10)
	PPC_STORE_U32(ctx.r10.u32 + -20736, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830C4AB8"))) PPC_WEAK_FUNC(sub_830C4AB8);
PPC_FUNC_IMPL(__imp__sub_830C4AB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-31946
	r31.s64 = -2093613056;
	// lwz r3,-20736(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + -20736);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830c4ae8
	if (cr6.eq) goto loc_830C4AE8;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82d79ec0
	sub_82D79EC0(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,-20736(r31)
	PPC_STORE_U32(r31.u32 + -20736, r11.u32);
loc_830C4AE8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4B00"))) PPC_WEAK_FUNC(sub_830C4B00);
PPC_FUNC_IMPL(__imp__sub_830C4B00) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4B08"))) PPC_WEAK_FUNC(sub_830C4B08);
PPC_FUNC_IMPL(__imp__sub_830C4B08) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4B10"))) PPC_WEAK_FUNC(sub_830C4B10);
PPC_FUNC_IMPL(__imp__sub_830C4B10) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4B18"))) PPC_WEAK_FUNC(sub_830C4B18);
PPC_FUNC_IMPL(__imp__sub_830C4B18) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4B20"))) PPC_WEAK_FUNC(sub_830C4B20);
PPC_FUNC_IMPL(__imp__sub_830C4B20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// vspltisw v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_set1_epi32(int(0x0)));
	// lvx128 v13,r0,r4
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r4.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r10,16
	ctx.r10.s64 = 16;
	// li r9,32
	ctx.r9.s64 = 32;
	// li r8,48
	ctx.r8.s64 = 48;
	// vrlimi128 v13,v0,1,0
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 228), 1));
	// addi r11,r3,64
	r11.s64 = ctx.r3.s64 + 64;
	// stvx128 v13,r0,r3
	_mm_store_si128((__m128i*)(base + ((ctx.r3.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v13,r0,r4
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r4.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vrlimi128 v13,v0,1,0
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 228), 1));
	// stvx128 v13,r3,r10
	_mm_store_si128((__m128i*)(base + ((ctx.r3.u32 + ctx.r10.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r5
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r5.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r3,r9
	_mm_store_si128((__m128i*)(base + ((ctx.r3.u32 + ctx.r9.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r5
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r5.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r3,r8
	_mm_store_si128((__m128i*)(base + ((ctx.r3.u32 + ctx.r8.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vxor v0,v0,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_setzero_si128());
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4B70"))) PPC_WEAK_FUNC(sub_830C4B70);
PPC_FUNC_IMPL(__imp__sub_830C4B70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCVRegister v127{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// li r12,-64
	r12.s64 = -64;
	// stvx128 v127,r1,r12
	_mm_store_si128((__m128i*)(base + ((ctx.r1.u32 + r12.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)v127.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r28,32
	r28.s64 = 32;
	// addi r29,r11,16912
	r29.s64 = r11.s64 + 16912;
	// lfs f0,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	f0.f64 = double(temp.f32);
	// li r11,48
	r11.s64 = 48;
	// fsubs f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 - f0.f64));
	// lfs f13,28(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lvx128 v12,r31,r28
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + r28.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lvx128 v0,r0,r29
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lvx128 v11,r31,r11
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v13,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vspltw128 v127,v13,0
	_mm_store_si128((__m128i*)v127.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vsubfp128 v0,v0,v127
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(v127.f32)));
	// vmulfp128 v0,v0,v12
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp128 v0,v127,v11,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(v127.f32), _mm_load_ps(ctx.v11.f32)), _mm_load_ps(ctx.v0.f32)));
	// vmsum4fp128 v13,v0,v0
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// stvx128 v13,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,112(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// fsqrts f13,f0
	ctx.f13.f64 = double(float(sqrt(f0.f64)));
	// lfs f0,3080(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	f0.f64 = double(temp.f32);
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vmulfp128 v0,v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bl 0x82d51008
	sub_82D51008(ctx, base);
	// lvx128 v0,r0,r29
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r29.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r9,16
	ctx.r9.s64 = 16;
	// vsubfp128 v0,v0,v127
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(v127.f32)));
	// lvx128 v13,r0,r31
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r30,48
	r11.s64 = r30.s64 + 48;
	// addi r10,r31,64
	ctx.r10.s64 = r31.s64 + 64;
	// lvx128 v12,r31,r9
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r31.u32 + ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmulfp128 v0,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp128 v0,v127,v12,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(v127.f32), _mm_load_ps(ctx.v12.f32)), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v9,v0,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// lvx128 v13,r0,r30
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v8,v0,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// lvx128 v12,r30,r9
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,2
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// lvx128 v11,r30,r28
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32 + r28.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v10,r0,r11
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmulfp128 v13,v13,v9
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v9.f32)));
	// vmaddfp v13,v12,v8,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v0,v11,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v13.f32)));
	// vsubfp v0,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// li r0,-64
	r0.s64 = -64;
	// lvx128 v127,r1,r0
	_mm_store_si128((__m128i*)v127.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r1.u32 + r0.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// b 0x82ca2c38
	return;
}

__attribute__((alias("__imp__sub_830C4C98"))) PPC_WEAK_FUNC(sub_830C4C98);
PPC_FUNC_IMPL(__imp__sub_830C4C98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r3,r31,64
	ctx.r3.s64 = r31.s64 + 64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x830c4b20
	sub_830C4B20(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82d51008
	sub_82D51008(ctx, base);
	// li r9,48
	ctx.r9.s64 = 48;
	// addi r11,r31,144
	r11.s64 = r31.s64 + 144;
	// lvx128 v0,r0,r30
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r30.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stvx128 v0,r31,r9
	_mm_store_si128((__m128i*)(base + ((r31.u32 + ctx.r9.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vxor v0,v0,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_setzero_si128());
	// lfs f0,3080(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3080);
	f0.f64 = double(temp.f32);
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stfs f0,160(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 160, temp.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

__attribute__((alias("__imp__sub_830C4CF8"))) PPC_WEAK_FUNC(sub_830C4CF8);
PPC_FUNC_IMPL(__imp__sub_830C4CF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// li r11,-1
	r11.s64 = -1;
	// std r11,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, r11.u64);
	// b 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_830C4D08"))) PPC_WEAK_FUNC(sub_830C4D08);
PPC_FUNC_IMPL(__imp__sub_830C4D08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	r11.s64 = 0;
	// lwz r31,4(r4)
	r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, r11.u32);
	// ble cr6,0x830c4d4c
	if (!cr6.gt) goto loc_830C4D4C;
loc_830C4D34:
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,80(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// bl 0x830c5a10
	sub_830C5A10(ctx, base);
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bgt cr6,0x830c4d34
	if (cr6.gt) goto loc_830C4D34;
loc_830C4D4C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4D68"))) PPC_WEAK_FUNC(sub_830C4D68);
PPC_FUNC_IMPL(__imp__sub_830C4D68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// li r9,0
	ctx.r9.s64 = 0;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r11,2
	r11.s64 = 2;
	// stb r9,61(r3)
	PPC_STORE_U8(ctx.r3.u32 + 61, ctx.r9.u8);
	// stb r10,62(r3)
	PPC_STORE_U8(ctx.r3.u32 + 62, ctx.r10.u8);
	// stb r11,60(r3)
	PPC_STORE_U8(ctx.r3.u32 + 60, r11.u8);
	// stb r10,64(r3)
	PPC_STORE_U8(ctx.r3.u32 + 64, ctx.r10.u8);
	// stb r9,65(r3)
	PPC_STORE_U8(ctx.r3.u32 + 65, ctx.r9.u8);
	// stb r11,63(r3)
	PPC_STORE_U8(ctx.r3.u32 + 63, r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4D90"))) PPC_WEAK_FUNC(sub_830C4D90);
PPC_FUNC_IMPL(__imp__sub_830C4D90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82184450
	sub_82184450(ctx, base);
	// lwz r3,56(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4DC0"))) PPC_WEAK_FUNC(sub_830C4DC0);
PPC_FUNC_IMPL(__imp__sub_830C4DC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lwz r10,48(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	// lwz r9,28(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 28);
	// add. r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beqlr 
	if (cr0.eq) return;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r11,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, r11.u32);
	// lwz r3,80(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 80);
	// b 0x830c5a10
	sub_830C5A10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_830C4DF0"))) PPC_WEAK_FUNC(sub_830C4DF0);
PPC_FUNC_IMPL(__imp__sub_830C4DF0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4DF8"))) PPC_WEAK_FUNC(sub_830C4DF8);
PPC_FUNC_IMPL(__imp__sub_830C4DF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82184450
	sub_82184450(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r11,32
	ctx.r3.s64 = r11.s64 + 32;
	// bl 0x82da6ef8
	sub_82DA6EF8(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// bl 0x82da6ef8
	sub_82DA6EF8(ctx, base);
	// li r11,-1
	r11.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// std r11,32(r31)
	PPC_STORE_U64(r31.u32 + 32, r11.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C4E60"))) PPC_WEAK_FUNC(sub_830C4E60);
PPC_FUNC_IMPL(__imp__sub_830C4E60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r29,r31,40
	r29.s64 = r31.s64 + 40;
	// li r30,0
	r30.s64 = 0;
	// addi r28,r11,-20792
	r28.s64 = r11.s64 + -20792;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// stw r30,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r30.u32);
	// stw r30,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r30.u32);
	// stw r30,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r30.u32);
	// bl 0x82184450
	sub_82184450(ctx, base);
	// lwz r11,48(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c4eb8
	if (cr6.eq) goto loc_830C4EB8;
	// stw r31,44(r11)
	PPC_STORE_U32(r11.u32 + 44, r31.u32);
loc_830C4EB8:
	// li r11,-1
	r11.s64 = -1;
	// stw r28,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r28.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r31,48(r28)
	PPC_STORE_U32(r28.u32 + 48, r31.u32);
	// std r11,32(r28)
	PPC_STORE_U64(r28.u32 + 32, r11.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x832b259c
	__imp__RtlInitializeCriticalSectionAndSpinCount(ctx, base);
	// li r9,-1
	ctx.r9.s64 = -1;
	// lwz r11,0(r13)
	r11.u64 = PPC_LOAD_U32(ctx.r13.u32 + 0);
	// li r10,4
	ctx.r10.s64 = 4;
	// std r9,32(r31)
	PPC_STORE_U64(r31.u32 + 32, ctx.r9.u64);
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,104(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 104);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c4f14
	if (cr6.eq) goto loc_830C4F14;
	// lwz r10,108(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 108);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,108(r3)
	PPC_STORE_U32(ctx.r3.u32 + 108, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r10,104(r3)
	PPC_STORE_U32(ctx.r3.u32 + 104, ctx.r10.u32);
	// b 0x830c4f20
	goto loc_830C4F20;
loc_830C4F14:
	// li r4,6
	ctx.r4.s64 = 6;
	// bl 0x82d4ea30
	sub_82D4EA30(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_830C4F20:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c4f7c
	if (cr6.eq) goto loc_830C4F7C;
	// stw r30,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r30.u32);
	// stw r30,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r30.u32);
	// stw r30,20(r11)
	PPC_STORE_U32(r11.u32 + 20, r30.u32);
	// stw r30,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r30.u32);
	// stw r30,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r30.u32);
	// stw r30,32(r11)
	PPC_STORE_U32(r11.u32 + 32, r30.u32);
	// stw r30,36(r11)
	PPC_STORE_U32(r11.u32 + 36, r30.u32);
	// stw r30,40(r11)
	PPC_STORE_U32(r11.u32 + 40, r30.u32);
	// stw r30,44(r11)
	PPC_STORE_U32(r11.u32 + 44, r30.u32);
	// stw r30,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r30.u32);
	// stw r30,52(r11)
	PPC_STORE_U32(r11.u32 + 52, r30.u32);
	// stw r30,56(r11)
	PPC_STORE_U32(r11.u32 + 56, r30.u32);
	// stw r30,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r30.u32);
	// stw r30,64(r11)
	PPC_STORE_U32(r11.u32 + 64, r30.u32);
	// stw r30,68(r11)
	PPC_STORE_U32(r11.u32 + 68, r30.u32);
	// stw r30,72(r11)
	PPC_STORE_U32(r11.u32 + 72, r30.u32);
	// stw r30,76(r11)
	PPC_STORE_U32(r11.u32 + 76, r30.u32);
	// stw r30,80(r11)
	PPC_STORE_U32(r11.u32 + 80, r30.u32);
	// stw r30,84(r11)
	PPC_STORE_U32(r11.u32 + 84, r30.u32);
	// stw r30,88(r11)
	PPC_STORE_U32(r11.u32 + 88, r30.u32);
	// b 0x830c4f80
	goto loc_830C4F80;
loc_830C4F7C:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_830C4F80:
	// stw r11,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r11.u32);
	// li r4,128
	ctx.r4.s64 = 128;
	// stw r27,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r27.u32);
	// stw r26,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r26.u32);
	// stw r25,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r25.u32);
	// stw r30,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r30.u32);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// stw r30,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r30.u32);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// bl 0x82da6ef8
	sub_82DA6EF8(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r4,128
	ctx.r4.s64 = 128;
	// addi r3,r11,32
	ctx.r3.s64 = r11.s64 + 32;
	// bl 0x82da6ef8
	sub_82DA6EF8(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r4,128
	ctx.r4.s64 = 128;
	// addi r3,r11,52
	ctx.r3.s64 = r11.s64 + 52;
	// bl 0x82da6ef8
	sub_82DA6EF8(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r4,128
	ctx.r4.s64 = 128;
	// addi r3,r11,72
	ctx.r3.s64 = r11.s64 + 72;
	// bl 0x82da6ef8
	sub_82DA6EF8(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r11,2
	r11.s64 = 2;
	// stb r30,61(r31)
	PPC_STORE_U8(r31.u32 + 61, r30.u8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stb r30,65(r31)
	PPC_STORE_U8(r31.u32 + 65, r30.u8);
	// stb r10,62(r31)
	PPC_STORE_U8(r31.u32 + 62, ctx.r10.u8);
	// stb r11,60(r31)
	PPC_STORE_U8(r31.u32 + 60, r11.u8);
	// stb r10,64(r31)
	PPC_STORE_U8(r31.u32 + 64, ctx.r10.u8);
	// stb r11,63(r31)
	PPC_STORE_U8(r31.u32 + 63, r11.u8);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

__attribute__((alias("__imp__sub_830C5010"))) PPC_WEAK_FUNC(sub_830C5010);
PPC_FUNC_IMPL(__imp__sub_830C5010) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// bl 0x82184450
	sub_82184450(ctx, base);
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r30,56(r27)
	r30.u64 = PPC_LOAD_U32(r27.u32 + 56);
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// bne cr6,0x830c505c
	if (!cr6.eq) goto loc_830C505C;
	// bl 0x82da6fe8
	sub_82DA6FE8(ctx, base);
	// b 0x830c5060
	goto loc_830C5060;
loc_830C505C:
	// bl 0x830c5848
	sub_830C5848(ctx, base);
loc_830C5060:
	// lwz r9,4(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830c5090
	if (cr6.eq) goto loc_830C5090;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// add. r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830c5090
	if (cr0.eq) goto loc_830C5090;
	// addi r11,r9,-1
	r11.s64 = ctx.r9.s64 + -1;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// lwz r3,80(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 80);
	// bl 0x830c5a10
	sub_830C5A10(ctx, base);
loc_830C5090:
	// li r11,-1
	r11.s64 = -1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// std r11,32(r27)
	PPC_STORE_U64(r27.u32 + 32, r11.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

__attribute__((alias("__imp__sub_830C50A8"))) PPC_WEAK_FUNC(sub_830C50A8);
PPC_FUNC_IMPL(__imp__sub_830C50A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stwu r1,-464(r1)
	ea = -464 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r26,0(r13)
	r26.u64 = PPC_LOAD_U32(ctx.r13.u32 + 0);
	// li r27,8
	r27.s64 = 8;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r21,r6
	r21.u64 = ctx.r6.u64;
	// lwzx r11,r27,r26
	r11.u64 = PPC_LOAD_U32(r27.u32 + r26.u32);
	// mr r22,r8
	r22.u64 = ctx.r8.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c5100
	if (!cr6.lt) goto loc_830C5100;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r9,r9,-27864
	ctx.r9.s64 = ctx.r9.s64 + -27864;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// mftb r9
	ctx.r9.u64 = __rdtsc();
	// addi r8,r10,12
	ctx.r8.s64 = ctx.r10.s64 + 12;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
loc_830C5100:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r23,-1
	r23.s64 = -1;
	// addi r20,r11,25692
	r20.s64 = r11.s64 + 25692;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r24,r11,20120
	r24.s64 = r11.s64 + 20120;
loc_830C5114:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82184450
	sub_82184450(ctx, base);
	// lwz r31,56(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 56);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x830c5198
	if (cr6.eq) goto loc_830C5198;
	// lwz r11,72(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 72);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x830c5180
	if (!cr6.eq) goto loc_830C5180;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// bne cr6,0x830c517c
	if (!cr6.eq) goto loc_830C517C;
	// bl 0x82da6fe8
	sub_82DA6FE8(ctx, base);
	// b 0x830c5180
	goto loc_830C5180;
loc_830C517C:
	// bl 0x830c5848
	sub_830C5848(ctx, base);
loc_830C5180:
	// cmpwi cr6,r25,-1
	cr6.compare<int32_t>(r25.s32, -1, xer);
	// beq cr6,0x830c538c
	if (cr6.eq) goto loc_830C538C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r28,0
	r28.s64 = 0;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_830C5198:
	// addi r11,r25,20
	r11.s64 = r25.s64 + 20;
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// ble cr6,0x830c51ec
	if (!cr6.gt) goto loc_830C51EC;
	// addi r8,r11,1
	ctx.r8.s64 = r11.s64 + 1;
loc_830C51BC:
	// lbzx r11,r8,r10
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r10.u32);
	// rotlwi r9,r11,2
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 2);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r30,r11,12
	r30.s64 = r11.s64 + 12;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830c5284
	if (!cr6.eq) goto loc_830C5284;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r10,r7
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r7.s32, xer);
	// blt cr6,0x830c51bc
	if (cr6.lt) goto loc_830C51BC;
loc_830C51EC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830c5208
	if (!cr6.eq) goto loc_830C5208;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// add. r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830c53fc
	if (cr0.eq) goto loc_830C53FC;
loc_830C5208:
	// cmpwi cr6,r22,1
	cr6.compare<int32_t>(r22.s32, 1, xer);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// beq cr6,0x830c53c0
	if (cr6.eq) goto loc_830C53C0;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// std r23,32(r29)
	PPC_STORE_U64(r29.u32 + 32, r23.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// lwzx r11,r27,r26
	r11.u64 = PPC_LOAD_U32(r27.u32 + r26.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c5250
	if (!cr6.lt) goto loc_830C5250;
	// stw r24,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r24.u32);
	// mftb r9
	ctx.r9.u64 = __rdtsc();
	// addi r8,r10,12
	ctx.r8.s64 = ctx.r10.s64 + 12;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
loc_830C5250:
	// lwz r3,80(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 80);
	// bl 0x830c59e0
	sub_830C59E0(ctx, base);
	// lwzx r10,r27,r26
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + r26.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c5114
	if (!cr6.lt) goto loc_830C5114;
	// stw r20,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r20.u32);
	// mftb r9
	ctx.r9.u64 = __rdtsc();
	// addi r8,r11,12
	ctx.r8.s64 = r11.s64 + 12;
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// b 0x830c5114
	goto loc_830C5114;
loc_830C5284:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r10,r1,224
	ctx.r10.s64 = ctx.r1.s64 + 224;
	// lwz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r9,16
	ctx.r9.s64 = 16;
	// rlwinm r11,r11,7,0,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 7) & 0xFFFFFF80;
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_830C52A0:
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// bdnz 0x830c52a0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_830C52A0;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// bne cr6,0x830c52d4
	if (!cr6.eq) goto loc_830C52D4;
	// li r11,0
	r11.s64 = 0;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
loc_830C52D4:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// lwz r11,68(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 68);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x830c5310
	if (!cr6.eq) goto loc_830C5310;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82da6fe8
	sub_82DA6FE8(ctx, base);
loc_830C5310:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq cr6,0x830c534c
	if (cr6.eq) goto loc_830C534C;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// add. r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830c534c
	if (cr0.eq) goto loc_830C534C;
	// addi r11,r9,-1
	r11.s64 = ctx.r9.s64 + -1;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// lwz r3,80(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 80);
	// bl 0x830c5a10
	sub_830C5A10(ctx, base);
loc_830C534C:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// std r23,32(r29)
	PPC_STORE_U64(r29.u32 + 32, r23.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// lwzx r11,r27,r26
	r11.u64 = PPC_LOAD_U32(r27.u32 + r26.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c5380
	if (!cr6.lt) goto loc_830C5380;
	// stw r20,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r20.u32);
	// mftb r9
	ctx.r9.u64 = __rdtsc();
	// addi r8,r10,12
	ctx.r8.s64 = ctx.r10.s64 + 12;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
loc_830C5380:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,464
	ctx.r1.s64 = ctx.r1.s64 + 464;
	// b 0x82ca2c18
	return;
loc_830C538C:
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830c53bc
	if (cr6.eq) goto loc_830C53BC;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// add. r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830c53bc
	if (cr0.eq) goto loc_830C53BC;
	// addi r11,r9,-1
	r11.s64 = ctx.r9.s64 + -1;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// lwz r3,80(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 80);
	// bl 0x830c5a10
	sub_830C5A10(ctx, base);
loc_830C53BC:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_830C53C0:
	// std r23,32(r29)
	PPC_STORE_U64(r29.u32 + 32, r23.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// lwzx r11,r27,r26
	r11.u64 = PPC_LOAD_U32(r27.u32 + r26.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c53f0
	if (!cr6.lt) goto loc_830C53F0;
	// stw r20,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r20.u32);
	// mftb r9
	ctx.r9.u64 = __rdtsc();
	// addi r8,r10,12
	ctx.r8.s64 = ctx.r10.s64 + 12;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
loc_830C53F0:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,464
	ctx.r1.s64 = ctx.r1.s64 + 464;
	// b 0x82ca2c18
	return;
loc_830C53FC:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830c4d08
	sub_830C4D08(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// std r23,32(r29)
	PPC_STORE_U64(r29.u32 + 32, r23.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// lwzx r11,r27,r26
	r11.u64 = PPC_LOAD_U32(r27.u32 + r26.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c543c
	if (!cr6.lt) goto loc_830C543C;
	// stw r20,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r20.u32);
	// mftb r9
	ctx.r9.u64 = __rdtsc();
	// addi r8,r10,12
	ctx.r8.s64 = ctx.r10.s64 + 12;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
loc_830C543C:
	// li r3,3
	ctx.r3.s64 = 3;
	// addi r1,r1,464
	ctx.r1.s64 = ctx.r1.s64 + 464;
	// b 0x82ca2c18
	return;
}

__attribute__((alias("__imp__sub_830C5448"))) PPC_WEAK_FUNC(sub_830C5448);
PPC_FUNC_IMPL(__imp__sub_830C5448) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc0
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r25,0(r13)
	r25.u64 = PPC_LOAD_U32(ctx.r13.u32 + 0);
	// li r26,8
	r26.s64 = 8;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r19,r5
	r19.u64 = ctx.r5.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// lwzx r11,r26,r25
	r11.u64 = PPC_LOAD_U32(r26.u32 + r25.u32);
	// mr r18,r8
	r18.u64 = ctx.r8.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c54a0
	if (!cr6.lt) goto loc_830C54A0;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r9,r9,-27864
	ctx.r9.s64 = ctx.r9.s64 + -27864;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// mftb r9
	ctx.r9.u64 = __rdtsc();
	// addi r8,r10,12
	ctx.r8.s64 = ctx.r10.s64 + 12;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
loc_830C54A0:
	// addi r11,r6,20
	r11.s64 = ctx.r6.s64 + 20;
	// li r31,1
	r31.s64 = 1;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// li r23,0
	r23.s64 = 0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// li r24,-1
	r24.s64 = -1;
	// add r22,r11,r29
	r22.u64 = r11.u64 + r29.u64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r21,r11,20120
	r21.s64 = r11.s64 + 20120;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r20,r11,25692
	r20.s64 = r11.s64 + 25692;
loc_830C54CC:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82184450
	sub_82184450(ctx, base);
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// lwz r30,56(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c551c
	if (cr6.eq) goto loc_830C551C;
	// rlwinm r11,r28,2,0,29
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpwi cr6,r19,0
	cr6.compare<int32_t>(r19.s32, 0, xer);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// bne cr6,0x830c550c
	if (!cr6.eq) goto loc_830C550C;
	// bl 0x82da6fe8
	sub_82DA6FE8(ctx, base);
	// b 0x830c5510
	goto loc_830C5510;
loc_830C550C:
	// bl 0x830c5848
	sub_830C5848(ctx, base);
loc_830C5510:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_830C551C:
	// lbz r7,0(r22)
	ctx.r7.u64 = PPC_LOAD_U8(r22.u32 + 0);
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// ble cr6,0x830c5560
	if (!cr6.gt) goto loc_830C5560;
	// addi r8,r22,1
	ctx.r8.s64 = r22.s64 + 1;
loc_830C5530:
	// lbzx r11,r8,r9
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r9.u32);
	// rotlwi r10,r11,2
	ctx.r10.u64 = __builtin_rotateleft32(r11.u32, 2);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// addi r31,r11,12
	r31.s64 = r11.s64 + 12;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830c5608
	if (!cr6.eq) goto loc_830C5608;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r9,r7
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r7.s32, xer);
	// blt cr6,0x830c5530
	if (cr6.lt) goto loc_830C5530;
loc_830C5560:
	// li r11,1
	r11.s64 = 1;
loc_830C5564:
	// mr r31,r23
	r31.u64 = r23.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830c56a4
	if (cr6.eq) goto loc_830C56A4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x830c558c
	if (!cr6.eq) goto loc_830C558C;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// add. r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830c5714
	if (cr0.eq) goto loc_830C5714;
loc_830C558C:
	// cmpwi cr6,r18,1
	cr6.compare<int32_t>(r18.s32, 1, xer);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// beq cr6,0x830c5760
	if (cr6.eq) goto loc_830C5760;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// std r24,32(r29)
	PPC_STORE_U64(r29.u32 + 32, r24.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// lwzx r11,r26,r25
	r11.u64 = PPC_LOAD_U32(r26.u32 + r25.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c55d4
	if (!cr6.lt) goto loc_830C55D4;
	// stw r21,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r21.u32);
	// mftb r9
	ctx.r9.u64 = __rdtsc();
	// addi r8,r10,12
	ctx.r8.s64 = ctx.r10.s64 + 12;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
loc_830C55D4:
	// lwz r3,80(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 80);
	// bl 0x830c59e0
	sub_830C59E0(ctx, base);
	// lwzx r10,r26,r25
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + r25.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c54cc
	if (!cr6.lt) goto loc_830C54CC;
	// stw r20,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r20.u32);
	// mftb r9
	ctx.r9.u64 = __rdtsc();
	// addi r8,r11,12
	ctx.r8.s64 = r11.s64 + 12;
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// b 0x830c54cc
	goto loc_830C54CC;
loc_830C5608:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r9,16
	ctx.r9.s64 = 16;
	// rlwinm r11,r11,7,0,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 7) & 0xFFFFFF80;
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_830C5624:
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// bdnz 0x830c5624
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_830C5624;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// bne cr6,0x830c5654
	if (!cr6.eq) goto loc_830C5654;
	// stw r23,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r23.u32);
loc_830C5654:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,68(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 68);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x830c5690
	if (!cr6.eq) goto loc_830C5690;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82da6fe8
	sub_82DA6FE8(ctx, base);
loc_830C5690:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r11,r23
	r11.u64 = r23.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// b 0x830c5564
	goto loc_830C5564;
loc_830C56A4:
	// lwz r9,4(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x830c56d4
	if (cr6.eq) goto loc_830C56D4;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// add. r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x830c56d4
	if (cr0.eq) goto loc_830C56D4;
	// addi r11,r9,-1
	r11.s64 = ctx.r9.s64 + -1;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// lwz r3,80(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 80);
	// bl 0x830c5a10
	sub_830C5A10(ctx, base);
loc_830C56D4:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// std r24,32(r29)
	PPC_STORE_U64(r29.u32 + 32, r24.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// lwzx r11,r26,r25
	r11.u64 = PPC_LOAD_U32(r26.u32 + r25.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c5708
	if (!cr6.lt) goto loc_830C5708;
	// stw r20,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r20.u32);
	// mftb r9
	ctx.r9.u64 = __rdtsc();
	// addi r8,r10,12
	ctx.r8.s64 = ctx.r10.s64 + 12;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
loc_830C5708:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// b 0x82ca2c10
	return;
loc_830C5714:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830c4d08
	sub_830C4D08(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// std r24,32(r29)
	PPC_STORE_U64(r29.u32 + 32, r24.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// lwzx r11,r26,r25
	r11.u64 = PPC_LOAD_U32(r26.u32 + r25.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x830c5754
	if (!cr6.lt) goto loc_830C5754;
	// stw r20,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r20.u32);
	// mftb r9
	ctx.r9.u64 = __rdtsc();
	// addi r8,r10,12
	ctx.r8.s64 = ctx.r10.s64 + 12;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
loc_830C5754:
	// li r3,3
	ctx.r3.s64 = 3;
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// b 0x82ca2c10
	return;
loc_830C5760:
	// std r24,32(r29)
	PPC_STORE_U64(r29.u32 + 32, r24.u64);
	// bl 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// b 0x82ca2c10
	return;
}

__attribute__((alias("__imp__sub_830C5778"))) PPC_WEAK_FUNC(sub_830C5778);
PPC_FUNC_IMPL(__imp__sub_830C5778) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,56(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x830c57a0
	if (cr6.eq) goto loc_830C57A0;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x830c5900
	sub_830C5900(ctx, base);
loc_830C57A0:
	// addi r3,r31,40
	ctx.r3.s64 = r31.s64 + 40;
	// bl 0x82d79db0
	sub_82D79DB0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C57C0"))) PPC_WEAK_FUNC(sub_830C57C0);
PPC_FUNC_IMPL(__imp__sub_830C57C0) {
	PPC_FUNC_PROLOGUE();
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// b 0x830c50a8
	sub_830C50A8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_830C57D8"))) PPC_WEAK_FUNC(sub_830C57D8);
PPC_FUNC_IMPL(__imp__sub_830C57D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r31,r3,92
	r31.s64 = ctx.r3.s64 + 92;
	// li r30,3
	r30.s64 = 3;
loc_830C57F4:
	// addi r31,r31,-20
	r31.s64 = r31.s64 + -20;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x830c5820
	if (cr6.eq) goto loc_830C5820;
	// lwz r10,0(r13)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r13.u32 + 0);
	// li r9,4
	ctx.r9.s64 = 4;
	// li r6,22
	ctx.r6.s64 = 22;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r5,r11,7,0,24
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 7) & 0xFFFFFF80;
	// lwzx r3,r9,r10
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// bl 0x82d4eca8
	sub_82D4ECA8(ctx, base);
loc_830C5820:
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bge cr6,0x830c57f4
	if (!cr6.lt) goto loc_830C57F4;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C5848"))) PPC_WEAK_FUNC(sub_830C5848);
PPC_FUNC_IMPL(__imp__sub_830C5848) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// blt cr6,0x830c5888
	if (cr6.lt) goto loc_830C5888;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// li r4,8
	ctx.r4.s64 = 8;
	// beq cr6,0x830c5884
	if (cr6.eq) goto loc_830C5884;
	// rlwinm r4,r11,1,0,30
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
loc_830C5884:
	// bl 0x82da6ef8
	sub_82DA6EF8(ctx, base);
loc_830C5888:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x830c58a0
	if (!cr6.eq) goto loc_830C58A0;
	// li r11,0
	r11.s64 = 0;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_830C58A0:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r11,r30
	r11.u64 = r30.u64;
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r9,16
	ctx.r9.s64 = 16;
	// rlwinm r10,r10,7,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0xFFFFFF80;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_830C58BC:
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// bdnz 0x830c58bc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_830C58BC;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r10,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r10.u32);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C5900"))) PPC_WEAK_FUNC(sub_830C5900);
PPC_FUNC_IMPL(__imp__sub_830C5900) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x830c57d8
	sub_830C57D8(ctx, base);
	// clrlwi r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x830c597c
	if (cr6.eq) goto loc_830C597C;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x830c597c
	if (cr6.eq) goto loc_830C597C;
	// lwz r11,0(r13)
	r11.u64 = PPC_LOAD_U32(ctx.r13.u32 + 0);
	// li r10,4
	ctx.r10.s64 = 4;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,108(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// lwz r9,52(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// blt cr6,0x830c5964
	if (cr6.lt) goto loc_830C5964;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,6
	ctx.r4.s64 = 6;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x82d4eb08
	sub_82D4EB08(ctx, base);
	// b 0x830c597c
	goto loc_830C597C;
loc_830C5964:
	// lwz r10,108(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// lwz r9,104(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 104);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r10.u32);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// stw r31,104(r11)
	PPC_STORE_U32(r11.u32 + 104, r31.u32);
loc_830C597C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C5998"))) PPC_WEAK_FUNC(sub_830C5998);
PPC_FUNC_IMPL(__imp__sub_830C5998) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82cc0658
	sub_82CC0658(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_830C59D8"))) PPC_WEAK_FUNC(sub_830C59D8);
PPC_FUNC_IMPL(__imp__sub_830C59D8) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// b 0x82cbbf60
	sub_82CBBF60(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_830C59E0"))) PPC_WEAK_FUNC(sub_830C59E0);
PPC_FUNC_IMPL(__imp__sub_830C59E0) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,-1
	ctx.r4.s64 = -1;
	// b 0x82196c58
	sub_82196C58(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_830C59F0"))) PPC_WEAK_FUNC(sub_830C59F0);
PPC_FUNC_IMPL(__imp__sub_830C59F0) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// b 0x82cc06f0
	sub_82CC06F0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_830C5A00"))) PPC_WEAK_FUNC(sub_830C5A00);
PPC_FUNC_IMPL(__imp__sub_830C5A00) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,-1
	ctx.r4.s64 = -1;
	// b 0x82196c58
	sub_82196C58(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_830C5A10"))) PPC_WEAK_FUNC(sub_830C5A10);
PPC_FUNC_IMPL(__imp__sub_830C5A10) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// b 0x82cc06f0
	sub_82CC06F0(ctx, base);
	return;
}

