#include "ppc_recomp_shared.h"

PPC_FUNC_IMPL(__imp__sub_831CD310) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// lwz r30,16(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// rlwinm. r11,r24,0,28,28
	r11.u64 = rotl64(r24.u32 | (r24.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cd3a8
	if (cr0.eq) goto loc_831CD3A8;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r10,28(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x831cd358
	if (cr6.eq) goto loc_831CD358;
loc_831CD350:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831cd66c
	goto loc_831CD66C;
loc_831CD358:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831cb5f0
	sub_831CB5F0(ctx, base);
	// lwz r29,0(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
loc_831CD368:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831cd3a8
	if (cr6.eq) goto loc_831CD3A8;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm. r10,r11,0,4,6
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831cd384
	if (cr0.eq) goto loc_831CD384;
	// rlwinm. r11,r11,0,28,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831cd38c
	if (!cr0.eq) goto loc_831CD38C;
loc_831CD384:
	// lwz r29,4(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// b 0x831cd368
	goto loc_831CD368;
loc_831CD38C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831cb5f0
	sub_831CB5F0(ctx, base);
	// cmplw cr6,r3,r28
	cr6.compare<uint32_t>(ctx.r3.u32, r28.u32, xer);
	// bne cr6,0x831cd3a0
	if (!cr6.eq) goto loc_831CD3A0;
	// li r29,0
	r29.s64 = 0;
loc_831CD3A0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x831cd350
	if (!cr6.eq) goto loc_831CD350;
loc_831CD3A8:
	// rlwinm. r11,r24,0,27,27
	r11.u64 = rotl64(r24.u32 | (r24.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cd3d0
	if (cr0.eq) goto loc_831CD3D0;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// beq cr6,0x831cd350
	if (cr6.eq) goto loc_831CD350;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r10,28(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 28);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x831cd350
	if (!cr6.eq) goto loc_831CD350;
loc_831CD3D0:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r29,r11,25,25,31
	r29.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r29,112
	cr6.compare<uint32_t>(r29.u32, 112, xer);
	// bne cr6,0x831cd40c
	if (!cr6.eq) goto loc_831CD40C;
	// lwz r11,28(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 28);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// bne cr6,0x831cd40c
	if (!cr6.eq) goto loc_831CD40C;
	// lwz r10,28(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// bne cr6,0x831cd350
	if (!cr6.eq) goto loc_831CD350;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// beq cr6,0x831cd350
	if (cr6.eq) goto loc_831CD350;
loc_831CD40C:
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83168a00
	sub_83168A00(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cd350
	if (cr0.eq) goto loc_831CD350;
	// cmplwi cr6,r29,112
	cr6.compare<uint32_t>(r29.u32, 112, xer);
	// bne cr6,0x831cd544
	if (!cr6.eq) goto loc_831CD544;
	// lwz r4,28(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 28);
	// lwz r11,28(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// cmpw cr6,r11,r4
	cr6.compare<int32_t>(r11.s32, ctx.r4.s32, xer);
	// beq cr6,0x831cd544
	if (cr6.eq) goto loc_831CD544;
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831cd44c
	if (cr0.eq) goto loc_831CD44C;
	// li r11,0
	r11.s64 = 0;
loc_831CD44C:
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// beq cr6,0x831cd350
	if (cr6.eq) goto loc_831CD350;
	// lwz r10,40(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 40);
	// rlwinm. r11,r10,0,17,17
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cd488
	if (cr0.eq) goto loc_831CD488;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,125
	cr6.compare<uint32_t>(r11.u32, 125, xer);
	// beq cr6,0x831cd47c
	if (cr6.eq) goto loc_831CD47C;
	// cmplwi cr6,r11,124
	cr6.compare<uint32_t>(r11.u32, 124, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x831cd480
	if (!cr6.eq) goto loc_831CD480;
loc_831CD47C:
	// li r11,1
	r11.s64 = 1;
loc_831CD480:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831cd350
	if (!cr0.eq) goto loc_831CD350;
loc_831CD488:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r9,8(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm r11,r11,28,29,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x6;
	// rlwinm r9,r9,0,18,24
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x3F80;
	// srw r11,r25,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r25.u32 >> (r11.u8 & 0x3F));
	// clrlwi r6,r11,30
	ctx.r6.u64 = r11.u32 & 0x3;
	// cmplwi cr6,r9,14336
	cr6.compare<uint32_t>(ctx.r9.u32, 14336, xer);
	// bne cr6,0x831cd4e0
	if (!cr6.eq) goto loc_831CD4E0;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x831cd4e0
	if (!cr6.eq) goto loc_831CD4E0;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r9,r27
	cr6.compare<uint32_t>(ctx.r9.u32, r27.u32, xer);
	// bne cr6,0x831cd4e0
	if (!cr6.eq) goto loc_831CD4E0;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r11,27,30,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x3;
	// cmpw cr6,r9,r6
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r6.s32, xer);
	// bne cr6,0x831cd4e0
	if (!cr6.eq) goto loc_831CD4E0;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// beq cr6,0x831cd350
	if (cr6.eq) goto loc_831CD350;
loc_831CD4E0:
	// rlwinm r8,r10,18,31,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x1;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x83161630
	sub_83161630(ctx, base);
	// cmplw cr6,r26,r3
	cr6.compare<uint32_t>(r26.u32, ctx.r3.u32, xer);
	// beq cr6,0x831cd350
	if (cr6.eq) goto loc_831CD350;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x831cd514
	goto loc_831CD514;
loc_831CD50C:
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_831CD514:
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bne cr6,0x831cd50c
	if (!cr6.eq) goto loc_831CD50C;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r9,57
	ctx.r9.s64 = 57;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r31.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwimi r11,r9,7,19,26
	r11.u64 = (rotl32(ctx.r9.u32, 7) & 0x1FE0) | (r11.u64 & 0xFFFFFFFFFFFFE01F);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// b 0x831cd664
	goto loc_831CD664;
loc_831CD544:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r10,r24,0,27,28
	ctx.r10.u64 = rotl64(r24.u32 | (r24.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// beq 0x831cd564
	if (cr0.eq) goto loc_831CD564;
	// rlwinm. r10,r11,0,27,28
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831cd564
	if (cr0.eq) goto loc_831CD564;
loc_831CD55C:
	// li r11,0
	r11.s64 = 0;
	// b 0x831cd58c
	goto loc_831CD58C;
loc_831CD564:
	// rlwinm. r10,r24,0,30,30
	ctx.r10.u64 = rotl64(r24.u32 | (r24.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831cd574
	if (cr0.eq) goto loc_831CD574;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831cd55c
	if (!cr0.eq) goto loc_831CD55C;
loc_831CD574:
	// rlwinm. r10,r24,0,29,29
	ctx.r10.u64 = rotl64(r24.u32 | (r24.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831cd588
	if (cr0.eq) goto loc_831CD588;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// bne 0x831cd58c
	if (!cr0.eq) goto loc_831CD58C;
loc_831CD588:
	// li r11,1
	r11.s64 = 1;
loc_831CD58C:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cd350
	if (cr0.eq) goto loc_831CD350;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x831cd5ac
	goto loc_831CD5AC;
loc_831CD5A4:
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_831CD5AC:
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bne cr6,0x831cd5a4
	if (!cr6.eq) goto loc_831CD5A4;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r8,r24,0,29,29
	ctx.r8.u64 = rotl64(r24.u32 | (r24.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r31,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r31.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// rlwinm r9,r9,27,24,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0xFF;
	// stw r27,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r27.u32);
	// rlwinm r11,r11,0,27,18
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// rlwinm r8,r9,27,29,30
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x6;
	// rlwinm r7,r9,29,29,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x6;
	// srw r8,r25,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (r25.u32 >> (ctx.r8.u8 & 0x3F));
	// srw r7,r25,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (r25.u32 >> (ctx.r7.u8 & 0x3F));
	// rlwimi r7,r8,2,28,29
	ctx.r7.u64 = (rotl32(ctx.r8.u32, 2) & 0xC) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFFF3);
	// rlwinm r8,r9,31,29,30
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x6;
	// rlwinm r9,r9,1,29,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x6;
	// clrlwi r7,r7,28
	ctx.r7.u64 = ctx.r7.u32 & 0xF;
	// srw r8,r25,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (r25.u32 >> (ctx.r8.u8 & 0x3F));
	// srw r9,r25,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r25.u32 >> (ctx.r9.u8 & 0x3F));
	// rlwimi r8,r7,2,0,29
	ctx.r8.u64 = (rotl32(ctx.r7.u32, 2) & 0xFFFFFFFC) | (ctx.r8.u64 & 0xFFFFFFFF00000003);
	// rlwimi r9,r8,2,0,29
	ctx.r9.u64 = (rotl32(ctx.r8.u32, 2) & 0xFFFFFFFC) | (ctx.r9.u64 & 0xFFFFFFFF00000003);
	// rlwinm r9,r9,5,0,26
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// or r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 | r11.u64;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// clrlwi r11,r9,27
	r11.u64 = ctx.r9.u32 & 0x1F;
	// beq 0x831cd634
	if (cr0.eq) goto loc_831CD634;
	// rlwinm. r8,r11,0,30,30
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x831cd634
	if (cr0.eq) goto loc_831CD634;
	// addi r10,r24,-4
	ctx.r10.s64 = r24.s64 + -4;
loc_831CD634:
	// and r8,r10,r11
	ctx.r8.u64 = ctx.r10.u64 & r11.u64;
	// rlwinm. r8,r8,0,29,29
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x831cd648
	if (cr0.eq) goto loc_831CD648;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_831CD648:
	// clrlwi. r8,r10,31
	ctx.r8.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x831cd65c
	if (cr0.eq) goto loc_831CD65C;
	// rlwinm. r8,r11,0,30,30
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x831cd65c
	if (cr0.eq) goto loc_831CD65C;
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
loc_831CD65C:
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// rlwimi r11,r9,0,0,26
	r11.u64 = (rotl32(ctx.r9.u32, 0) & 0xFFFFFFE0) | (r11.u64 & 0xFFFFFFFF0000001F);
loc_831CD664:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// li r3,1
	ctx.r3.s64 = 1;
loc_831CD66C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_831CD310) {
	__imp__sub_831CD310(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CD678) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// rlwimi r8,r7,5,24,26
	ctx.r8.u64 = (rotl32(ctx.r7.u32, 5) & 0xE0) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFF1F);
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// andi. r10,r8,231
	ctx.r10.u64 = ctx.r8.u64 & 231;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwimi r9,r10,7,0,24
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 7) & 0xFFFFFF80) | (ctx.r9.u64 & 0xFFFFFFFF0000007F);
	// addi r10,r6,-5
	ctx.r10.s64 = ctx.r6.s64 + -5;
	// stw r5,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r5.u32);
	// rlwinm r11,r11,0,25,14
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFE007F;
	// rlwinm r9,r9,7,0,24
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0xFFFFFF80;
	// rlwinm r11,r11,0,13,9
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFC7FFFF;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// cmplwi cr6,r10,97
	cr6.compare<uint32_t>(ctx.r10.u32, 97, xer);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// bgt cr6,0x831cd818
	if (cr6.gt) goto loc_831CD818;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,15784
	r12.s64 = r12.s64 + 15784;
	// lbzx r0,r12,r10
	r0.u64 = PPC_LOAD_U8(r12.u32 + ctx.r10.u32);
	// rlwinm r0,r0,2,0,29
	r0.u64 = rotl64(r0.u32 | (r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-31971
	r12.s64 = -2095251456;
	// addi r12,r12,-10512
	r12.s64 = r12.s64 + -10512;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_831CD6F0;
	case 1:
		goto loc_831CD6F0;
	case 2:
		goto loc_831CD6F0;
	case 3:
		goto loc_831CD6F0;
	case 4:
		goto loc_831CD818;
	case 5:
		goto loc_831CD70C;
	case 6:
		goto loc_831CD70C;
	case 7:
		goto loc_831CD818;
	case 8:
		goto loc_831CD818;
	case 9:
		goto loc_831CD818;
	case 10:
		goto loc_831CD818;
	case 11:
		goto loc_831CD818;
	case 12:
		goto loc_831CD818;
	case 13:
		goto loc_831CD818;
	case 14:
		goto loc_831CD818;
	case 15:
		goto loc_831CD818;
	case 16:
		goto loc_831CD724;
	case 17:
		goto loc_831CD724;
	case 18:
		goto loc_831CD724;
	case 19:
		goto loc_831CD724;
	case 20:
		goto loc_831CD6F0;
	case 21:
		goto loc_831CD6F0;
	case 22:
		goto loc_831CD6F0;
	case 23:
		goto loc_831CD6F0;
	case 24:
		goto loc_831CD744;
	case 25:
		goto loc_831CD75C;
	case 26:
		goto loc_831CD818;
	case 27:
		goto loc_831CD818;
	case 28:
		goto loc_831CD818;
	case 29:
		goto loc_831CD818;
	case 30:
		goto loc_831CD818;
	case 31:
		goto loc_831CD818;
	case 32:
		goto loc_831CD818;
	case 33:
		goto loc_831CD818;
	case 34:
		goto loc_831CD6F0;
	case 35:
		goto loc_831CD6F0;
	case 36:
		goto loc_831CD6F0;
	case 37:
		goto loc_831CD6F0;
	case 38:
		goto loc_831CD818;
	case 39:
		goto loc_831CD70C;
	case 40:
		goto loc_831CD70C;
	case 41:
		goto loc_831CD818;
	case 42:
		goto loc_831CD818;
	case 43:
		goto loc_831CD818;
	case 44:
		goto loc_831CD818;
	case 45:
		goto loc_831CD818;
	case 46:
		goto loc_831CD818;
	case 47:
		goto loc_831CD77C;
	case 48:
		goto loc_831CD77C;
	case 49:
		goto loc_831CD77C;
	case 50:
		goto loc_831CD75C;
	case 51:
		goto loc_831CD75C;
	case 52:
		goto loc_831CD818;
	case 53:
		goto loc_831CD818;
	case 54:
		goto loc_831CD724;
	case 55:
		goto loc_831CD724;
	case 56:
		goto loc_831CD724;
	case 57:
		goto loc_831CD724;
	case 58:
		goto loc_831CD724;
	case 59:
		goto loc_831CD724;
	case 60:
		goto loc_831CD724;
	case 61:
		goto loc_831CD724;
	case 62:
		goto loc_831CD6F0;
	case 63:
		goto loc_831CD6F0;
	case 64:
		goto loc_831CD6F0;
	case 65:
		goto loc_831CD6F0;
	case 66:
		goto loc_831CD6F0;
	case 67:
		goto loc_831CD77C;
	case 68:
		goto loc_831CD818;
	case 69:
		goto loc_831CD818;
	case 70:
		goto loc_831CD818;
	case 71:
		goto loc_831CD818;
	case 72:
		goto loc_831CD818;
	case 73:
		goto loc_831CD818;
	case 74:
		goto loc_831CD818;
	case 75:
		goto loc_831CD818;
	case 76:
		goto loc_831CD818;
	case 77:
		goto loc_831CD818;
	case 78:
		goto loc_831CD818;
	case 79:
		goto loc_831CD818;
	case 80:
		goto loc_831CD818;
	case 81:
		goto loc_831CD794;
	case 82:
		goto loc_831CD794;
	case 83:
		goto loc_831CD818;
	case 84:
		goto loc_831CD818;
	case 85:
		goto loc_831CD818;
	case 86:
		goto loc_831CD810;
	case 87:
		goto loc_831CD810;
	case 88:
		goto loc_831CD810;
	case 89:
		goto loc_831CD810;
	case 90:
		goto loc_831CD818;
	case 91:
		goto loc_831CD7A4;
	case 92:
		goto loc_831CD7D0;
	case 93:
		goto loc_831CD810;
	case 94:
		goto loc_831CD7D0;
	case 95:
		goto loc_831CD7D0;
	case 96:
		goto loc_831CD810;
	case 97:
		goto loc_831CD810;
	default:
		__builtin_unreachable();
	}
loc_831CD6F0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r10,r11,61166
	ctx.r10.u64 = r11.u64 & 61166;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,61166
	cr6.compare<uint32_t>(ctx.r10.u32, 61166, xer);
	// beq cr6,0x831cd818
	if (cr6.eq) goto loc_831CD818;
	// ori r11,r11,61166
	r11.u64 = r11.u64 | 61166;
loc_831CD704:
	// sth r11,14(r31)
	PPC_STORE_U16(r31.u32 + 14, r11.u16);
	// b 0x831cd818
	goto loc_831CD818;
loc_831CD70C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r10,r11,17476
	ctx.r10.u64 = r11.u64 & 17476;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,17476
	cr6.compare<uint32_t>(ctx.r10.u32, 17476, xer);
	// beq cr6,0x831cd818
	if (cr6.eq) goto loc_831CD818;
	// ori r11,r11,17476
	r11.u64 = r11.u64 | 17476;
	// b 0x831cd704
	goto loc_831CD704;
loc_831CD724:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// andi. r9,r10,61166
	ctx.r9.u64 = ctx.r10.u64 & 61166;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// cmplwi cr6,r9,61166
	cr6.compare<uint32_t>(ctx.r9.u32, 61166, xer);
	// beq cr6,0x831cd818
	if (cr6.eq) goto loc_831CD818;
	// ori r11,r10,61166
	r11.u64 = ctx.r10.u64 | 61166;
	// b 0x831cd704
	goto loc_831CD704;
loc_831CD744:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r10,r11,0,28,30
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE;
	// cmplwi cr6,r10,14
	cr6.compare<uint32_t>(ctx.r10.u32, 14, xer);
	// beq cr6,0x831cd818
	if (cr6.eq) goto loc_831CD818;
	// ori r11,r11,14
	r11.u64 = r11.u64 | 14;
	// b 0x831cd704
	goto loc_831CD704;
loc_831CD75C:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// rlwinm r9,r10,0,28,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xC;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// cmplwi cr6,r9,12
	cr6.compare<uint32_t>(ctx.r9.u32, 12, xer);
	// beq cr6,0x831cd818
	if (cr6.eq) goto loc_831CD818;
	// ori r11,r10,12
	r11.u64 = ctx.r10.u64 | 12;
	// b 0x831cd704
	goto loc_831CD704;
loc_831CD77C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r10,r11,8738
	ctx.r10.u64 = r11.u64 & 8738;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,8738
	cr6.compare<uint32_t>(ctx.r10.u32, 8738, xer);
	// beq cr6,0x831cd818
	if (cr6.eq) goto loc_831CD818;
	// ori r11,r11,8738
	r11.u64 = r11.u64 | 8738;
	// b 0x831cd704
	goto loc_831CD704;
loc_831CD794:
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// b 0x831cd818
	goto loc_831CD818;
loc_831CD7A4:
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-20
	r11.s64 = r31.s64 + -20;
	// li r10,57
	ctx.r10.s64 = 57;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwimi r9,r10,19,7,14
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 19) & 0x1FE0000) | (ctx.r9.u64 & 0xFFFFFFFFFE01FFFF);
	// stw r9,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r9.u32);
	// b 0x831cd818
	goto loc_831CD818;
loc_831CD7D0:
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-24
	r11.s64 = r31.s64 + -24;
	// li r10,228
	ctx.r10.s64 = 228;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stb r10,14(r11)
	PPC_STORE_U8(r11.u32 + 14, ctx.r10.u8);
	// oris r10,r8,3871
	ctx.r10.u64 = ctx.r8.u64 | 253689856;
	// oris r9,r9,8
	ctx.r9.u64 = ctx.r9.u64 | 524288;
	// ori r10,r10,61440
	ctx.r10.u64 = ctx.r10.u64 | 61440;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// b 0x831cd818
	goto loc_831CD818;
loc_831CD810:
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
loc_831CD818:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831CD678) {
	__imp__sub_831CD678(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CD830) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// addi r11,r11,-83
	r11.s64 = r11.s64 + -83;
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// bgt cr6,0x831cdadc
	if (cr6.gt) goto loc_831CDADC;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,15888
	r12.s64 = r12.s64 + 15888;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// rlwinm r0,r0,2,0,29
	r0.u64 = rotl64(r0.u32 | (r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-31971
	r12.s64 = -2095251456;
	// addi r12,r12,-10108
	r12.s64 = r12.s64 + -10108;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_831CD884;
	case 1:
		goto loc_831CD9E8;
	case 2:
		goto loc_831CDA28;
	case 3:
		goto loc_831CD93C;
	case 4:
		goto loc_831CD93C;
	case 5:
		goto loc_831CD974;
	case 6:
		goto loc_831CD890;
	case 7:
		goto loc_831CD890;
	case 8:
		goto loc_831CD998;
	case 9:
		goto loc_831CD984;
	case 10:
		goto loc_831CD984;
	case 11:
		goto loc_831CD9AC;
	case 12:
		goto loc_831CDAC8;
	default:
		__builtin_unreachable();
	}
loc_831CD884:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831CD890:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r11,r11,0,18,16
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFBFFF;
	// ori r11,r11,45056
	r11.u64 = r11.u64 | 45056;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwimi r10,r11,24,21,21
	ctx.r10.u64 = (rotl32(r11.u32, 24) & 0x400) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFBFF);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,11392
	cr6.compare<uint32_t>(r11.u32, 11392, xer);
	// bne cr6,0x831cd8cc
	if (!cr6.eq) goto loc_831CD8CC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_831CD8C4:
	// ori r11,r11,8192
	r11.u64 = r11.u64 | 8192;
	// b 0x831cd92c
	goto loc_831CD92C;
loc_831CD8CC:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm. r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cd924
	if (cr0.eq) goto loc_831CD924;
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// lwz r30,12(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8310f980
	sub_8310F980(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831cd924
	if (!cr0.eq) goto loc_831CD924;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
loc_831CD8F4:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831cd910
	if (cr6.eq) goto loc_831CD910;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r10,0,4,6
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831cd910
	if (!cr0.eq) goto loc_831CD910;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831cd8f4
	goto loc_831CD8F4;
loc_831CD910:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwimi r10,r11,17,22,29
	ctx.r10.u64 = (rotl32(r11.u32, 17) & 0x3FC) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFC03);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// b 0x831cd930
	goto loc_831CD930;
loc_831CD924:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_831CD928:
	// ori r11,r11,16384
	r11.u64 = r11.u64 | 16384;
loc_831CD92C:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_831CD930:
	// li r3,1
	ctx.r3.s64 = 1;
loc_831CD934:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_831CD93C:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r11,r11,0,19,16
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFF9FFF;
	// ori r11,r11,36864
	r11.u64 = r11.u64 | 36864;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwimi r10,r11,24,21,21
	ctx.r10.u64 = (rotl32(r11.u32, 24) & 0x400) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFBFF);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,11008
	cr6.compare<uint32_t>(r11.u32, 11008, xer);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bne cr6,0x831cd928
	if (!cr6.eq) goto loc_831CD928;
	// b 0x831cd8c4
	goto loc_831CD8C4;
loc_831CD974:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r10,5
	ctx.r10.s64 = 5;
	// rlwimi r11,r10,13,16,19
	r11.u64 = (rotl32(ctx.r10.u32, 13) & 0xF000) | (r11.u64 & 0xFFFFFFFFFFFF0FFF);
	// b 0x831cdad0
	goto loc_831CDAD0;
loc_831CD984:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r11,r11,0,23,21
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFDFF;
	// rlwinm r11,r11,0,20,17
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFCFFF;
	// ori r11,r11,50176
	r11.u64 = r11.u64 | 50176;
	// b 0x831cdad0
	goto loc_831CDAD0;
loc_831CD998:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r11,r11,0,22,20
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFBFF;
	// rlwinm r11,r11,0,20,17
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFCFFF;
	// ori r11,r11,49664
	r11.u64 = r11.u64 | 49664;
	// b 0x831cdad0
	goto loc_831CDAD0;
loc_831CD9AC:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r11,r11,0,20,17
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFCFFF;
	// li r4,94
	ctx.r4.s64 = 94;
	// ori r11,r11,50688
	r11.u64 = r11.u64 | 50688;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-12
	r11.s64 = r30.s64 + -12;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// rlwimi r11,r10,0,0,28
	r11.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFF8) | (r11.u64 & 0xFFFFFFFF00000007);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x831cdad4
	goto loc_831CDAD4;
loc_831CD9E8:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r10,7
	ctx.r10.s64 = 7;
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwimi r11,r10,12,16,19
	r11.u64 = (rotl32(ctx.r10.u32, 12) & 0xF000) | (r11.u64 & 0xFFFFFFFFFFFF0FFF);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,84
	ctx.r4.s64 = 84;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-20
	r11.s64 = r30.s64 + -20;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// rlwimi r10,r11,16,11,15
	ctx.r10.u64 = (rotl32(r11.u32, 16) & 0x1F0000) | (ctx.r10.u64 & 0xFFFFFFFFFFE0FFFF);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// b 0x831cd934
	goto loc_831CD934;
loc_831CDA28:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,85
	ctx.r4.s64 = 85;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-20
	r11.s64 = r30.s64 + -20;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r9,1
	ctx.r9.s64 = 1;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// rlwimi r10,r9,15,16,19
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 15) & 0xF000) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0FFF);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r4,84
	ctx.r4.s64 = 84;
	// lwz r29,0(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r9,0,0,29
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r28,28(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r29,-20
	r11.s64 = r29.s64 + -20;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// rlwimi r10,r11,16,11,15
	ctx.r10.u64 = (rotl32(r11.u32, 16) & 0x1F0000) | (ctx.r10.u64 & 0xFFFFFFFFFFE0FFFF);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// bl 0x83110668
	sub_83110668(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwimi r11,r3,0,19,31
	r11.u64 = (rotl32(ctx.r3.u32, 0) & 0x1FFF) | (r11.u64 & 0xFFFFFFFFFFFFE000);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwimi r9,r11,4,10,10
	ctx.r9.u64 = (rotl32(r11.u32, 4) & 0x200000) | (ctx.r9.u64 & 0xFFFFFFFFFFDFFFFF);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwimi r10,r11,24,21,21
	ctx.r10.u64 = (rotl32(r11.u32, 24) & 0x400) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFBFF);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// b 0x831cdad4
	goto loc_831CDAD4;
loc_831CDAC8:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// ori r11,r11,61440
	r11.u64 = r11.u64 | 61440;
loc_831CDAD0:
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_831CDAD4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831cd934
	goto loc_831CD934;
loc_831CDADC:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,16136
	ctx.r5.s64 = r11.s64 + 16136;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831CD830) {
	__imp__sub_831CD830(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CDAF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// clrlwi r11,r5,30
	r11.u64 = ctx.r5.u32 & 0x3;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831cdbc8
	if (cr6.lt) goto loc_831CDBC8;
	// beq cr6,0x831cdb8c
	if (cr6.eq) goto loc_831CDB8C;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x831cdb50
	if (cr6.lt) goto loc_831CDB50;
	// beq cr6,0x831cdb14
	if (cr6.eq) goto loc_831CDB14;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_831CDB14:
	// rlwinm r10,r5,0,0,29
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r9,r10,-36
	ctx.r9.s64 = ctx.r10.s64 + -36;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// ori r8,r9,1
	ctx.r8.u64 = ctx.r9.u64 | 1;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r11,-36
	ctx.r6.s64 = r11.s64 + -36;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_831CDB50:
	// rlwinm r10,r5,0,0,29
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// ori r8,r9,1
	ctx.r8.u64 = ctx.r9.u64 | 1;
	// lwz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// addi r6,r11,-36
	ctx.r6.s64 = r11.s64 + -36;
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// lwz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,36(r7)
	PPC_STORE_U32(ctx.r7.u32 + 36, ctx.r9.u32);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// blr 
	return;
loc_831CDB8C:
	// rlwinm r11,r5,0,0,29
	r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r10,r4,0,0,30
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// addi r8,r10,4
	ctx.r8.s64 = ctx.r10.s64 + 4;
	// addi r7,r10,-36
	ctx.r7.s64 = ctx.r10.s64 + -36;
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r8,36(r6)
	PPC_STORE_U32(ctx.r6.u32 + 36, ctx.r8.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// blr 
	return;
loc_831CDBC8:
	// rlwinm r11,r5,0,0,29
	r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r10,r4,0,0,30
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r7,r10,-36
	ctx.r7.s64 = ctx.r10.s64 + -36;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r6,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r6.u32);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r7,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r7.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831CDAF0) {
	__imp__sub_831CDAF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CDC08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// addi r10,r11,-104
	ctx.r10.s64 = r11.s64 + -104;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// rlwinm r7,r10,27,31,31
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// lwz r8,212(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r27,r9
	r27.u64 = ctx.r9.u64;
	// bl 0x831cd678
	sub_831CD678(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r10,r31,-8
	ctx.r10.s64 = r31.s64 + -8;
	// lwz r11,220(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// add r10,r3,r10
	ctx.r10.u64 = ctx.r3.u64 + ctx.r10.u64;
	// rlwimi r28,r11,14,16,17
	r28.u64 = (rotl32(r11.u32, 14) & 0xC000) | (r28.u64 & 0xFFFFFFFFFFFF3FFF);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwimi r9,r28,15,1,16
	ctx.r9.u64 = (rotl32(r28.u32, 15) & 0x7FFF8000) | (ctx.r9.u64 & 0xFFFFFFFF80007FFF);
	// rlwimi r8,r27,0,28,31
	ctx.r8.u64 = (rotl32(r27.u32, 0) & 0xF) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFF0);
	// rlwimi r9,r29,0,17,31
	ctx.r9.u64 = (rotl32(r29.u32, 0) & 0x7FFF) | (ctx.r9.u64 & 0xFFFFFFFFFFFF8000);
	// oris r8,r8,16
	ctx.r8.u64 = ctx.r8.u64 | 1048576;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// beq cr6,0x831cdcd8
	if (cr6.eq) goto loc_831CDCD8;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x831cdcc0
	if (cr6.eq) goto loc_831CDCC0;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x831cdcf0
	if (!cr6.eq) goto loc_831CDCF0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r10,r11,26214
	ctx.r10.u64 = r11.u64 & 26214;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,26214
	cr6.compare<uint32_t>(ctx.r10.u32, 26214, xer);
	// beq cr6,0x831cdcf0
	if (cr6.eq) goto loc_831CDCF0;
	// ori r11,r11,26214
	r11.u64 = r11.u64 | 26214;
	// b 0x831cdcec
	goto loc_831CDCEC;
loc_831CDCC0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r10,r11,17476
	ctx.r10.u64 = r11.u64 & 17476;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,17476
	cr6.compare<uint32_t>(ctx.r10.u32, 17476, xer);
	// beq cr6,0x831cdcf0
	if (cr6.eq) goto loc_831CDCF0;
	// ori r11,r11,17476
	r11.u64 = r11.u64 | 17476;
	// b 0x831cdcec
	goto loc_831CDCEC;
loc_831CDCD8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r10,r11,61166
	ctx.r10.u64 = r11.u64 & 61166;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,61166
	cr6.compare<uint32_t>(ctx.r10.u32, 61166, xer);
	// beq cr6,0x831cdcf0
	if (cr6.eq) goto loc_831CDCF0;
	// ori r11,r11,61166
	r11.u64 = r11.u64 | 61166;
loc_831CDCEC:
	// sth r11,14(r31)
	PPC_STORE_U16(r31.u32 + 14, r11.u16);
loc_831CDCF0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831CDC08) {
	__imp__sub_831CDC08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CDCF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// mr r25,r8
	r25.u64 = ctx.r8.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r5,35
	ctx.r5.s64 = 35;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831cd678
	sub_831CD678(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831cdd94
	if (cr6.eq) goto loc_831CDD94;
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r31,-36
	ctx.r10.s64 = r31.s64 + -36;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// ori r8,r10,1
	ctx.r8.u64 = ctx.r10.u64 | 1;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
loc_831CDD94:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831CDCF8) {
	__imp__sub_831CDCF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CDDA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,112
	ctx.r4.s64 = 112;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r5,35
	ctx.r5.s64 = 35;
	// addi r4,r29,4
	ctx.r4.s64 = r29.s64 + 4;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// addi r31,r3,4
	r31.s64 = ctx.r3.s64 + 4;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,112
	ctx.r6.s64 = 112;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x831cd678
	sub_831CD678(ctx, base);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r6,16(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r10,r30,16
	ctx.r10.s64 = r30.s64 + 16;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r10,r10,-36
	ctx.r10.s64 = ctx.r10.s64 + -36;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// ori r7,r10,1
	ctx.r7.u64 = ctx.r10.u64 | 1;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r6,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r6.u32);
	// add r9,r29,r31
	ctx.r9.u64 = r29.u64 + r31.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// lwz r6,16(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// stw r10,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r10.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// oris r11,r11,128
	r11.u64 = r11.u64 | 8388608;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,104(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 104);
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// stw r9,104(r28)
	PPC_STORE_U32(r28.u32 + 104, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831CDDA0) {
	__imp__sub_831CDDA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CDE60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r4,110
	ctx.r4.s64 = 110;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r5,35
	ctx.r5.s64 = 35;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// li r6,110
	ctx.r6.s64 = 110;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831cd678
	sub_831CD678(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831cdef4
	if (cr6.eq) goto loc_831CDEF4;
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r31,-36
	ctx.r10.s64 = r31.s64 + -36;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// ori r8,r10,1
	ctx.r8.u64 = ctx.r10.u64 | 1;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
loc_831CDEF4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831CDE60) {
	__imp__sub_831CDE60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CDF00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// bne cr6,0x831cdf44
	if (!cr6.eq) goto loc_831CDF44;
	// addi r4,r28,4
	ctx.r4.s64 = r28.s64 + 4;
loc_831CDF44:
	// li r5,35
	ctx.r5.s64 = 35;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// bne cr6,0x831cdf68
	if (!cr6.eq) goto loc_831CDF68;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_831CDF68:
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r27,0
	r27.s64 = 0;
	// rlwinm r11,r11,0,10,8
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFBFFFFF;
	// stw r27,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r27.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r27,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r27.u32);
	// sth r27,14(r31)
	PPC_STORE_U16(r31.u32 + 14, r27.u16);
	// stw r27,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r27.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,18,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ce038
	if (cr0.eq) goto loc_831CE038;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// b 0x831cdfc8
	goto loc_831CDFC8;
loc_831CDFB4:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x831cdfc4
	if (cr6.eq) goto loc_831CDFC4;
	// li r10,1
	ctx.r10.s64 = 1;
loc_831CDFC4:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
loc_831CDFC8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831cdfb4
	if (!cr6.eq) goto loc_831CDFB4;
	// clrlwi. r11,r10,24
	r11.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ce038
	if (cr0.eq) goto loc_831CE038;
	// stw r27,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r27.u32);
	// lwz r28,16(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// b 0x831ce030
	goto loc_831CE030;
loc_831CDFE4:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831cdffc
	if (cr6.lt) goto loc_831CDFFC;
	// bne cr6,0x831ce0c4
	if (!cr6.eq) goto loc_831CE0C4;
	// li r26,72
	r26.s64 = 72;
	// b 0x831ce000
	goto loc_831CE000;
loc_831CDFFC:
	// li r26,12
	r26.s64 = 12;
loc_831CE000:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r11,4(r25)
	PPC_STORE_U32(r25.u32 + 4, r11.u32);
	// stw r25,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r25.u32);
	// lwz r28,4(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 4);
loc_831CE030:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x831cdfe4
	if (!cr6.eq) goto loc_831CDFE4;
loc_831CE038:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// rlwinm r5,r11,15,27,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x1C;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,112
	cr6.compare<uint32_t>(r11.u32, 112, xer);
	// bne cr6,0x831ce0d0
	if (!cr6.eq) goto loc_831CE0D0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,112
	ctx.r4.s64 = 112;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// add r11,r3,r31
	r11.u64 = ctx.r3.u64 + r31.u64;
	// lwz r7,104(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 104);
	// add r10,r3,r29
	ctx.r10.u64 = ctx.r3.u64 + r29.u64;
	// addi r9,r11,-8
	ctx.r9.s64 = r11.s64 + -8;
	// addi r8,r10,-8
	ctx.r8.s64 = ctx.r10.s64 + -8;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// stw r31,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r31.u32);
	// stw r9,104(r30)
	PPC_STORE_U32(r30.u32 + 104, ctx.r9.u32);
	// stw r27,-4(r11)
	PPC_STORE_U32(r11.u32 + -4, r27.u32);
	// lwz r8,-8(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + -8);
	// lwz r9,-8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + -8);
	// rlwimi r9,r8,0,17,31
	ctx.r9.u64 = (rotl32(ctx.r8.u32, 0) & 0x7FFF) | (ctx.r9.u64 & 0xFFFFFFFFFFFF8000);
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// stw r9,-8(r11)
	PPC_STORE_U32(r11.u32 + -8, ctx.r9.u32);
	// lwz r9,-8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -8);
	// rlwimi r8,r9,0,3,16
	ctx.r8.u64 = (rotl32(ctx.r9.u32, 0) & 0x1FFF8000) | (ctx.r8.u64 & 0xFFFFFFFFE0007FFF);
	// stw r8,-8(r11)
	PPC_STORE_U32(r11.u32 + -8, ctx.r8.u32);
	// lwz r10,-8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -8);
	// rlwimi r10,r8,0,3,1
	ctx.r10.u64 = (rotl32(ctx.r8.u32, 0) & 0xFFFFFFFFDFFFFFFF) | (ctx.r10.u64 & 0x20000000);
	// stw r10,-8(r11)
	PPC_STORE_U32(r11.u32 + -8, ctx.r10.u32);
	// b 0x831ce200
	goto loc_831CE200;
loc_831CE0C4:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831CE0D0:
	// cmplwi cr6,r11,119
	cr6.compare<uint32_t>(r11.u32, 119, xer);
	// bne cr6,0x831ce110
	if (!cr6.eq) goto loc_831CE110;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,119
	ctx.r4.s64 = 119;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-12
	r11.s64 = r31.s64 + -12;
	// li r5,0
	ctx.r5.s64 = 0;
	// add r29,r3,r11
	r29.u64 = ctx.r3.u64 + r11.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// stw r3,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r3.u32);
	// b 0x831ce200
	goto loc_831CE200;
loc_831CE110:
	// cmplwi cr6,r11,97
	cr6.compare<uint32_t>(r11.u32, 97, xer);
	// beq cr6,0x831ce128
	if (cr6.eq) goto loc_831CE128;
	// cmplwi cr6,r11,99
	cr6.compare<uint32_t>(r11.u32, 99, xer);
	// beq cr6,0x831ce128
	if (cr6.eq) goto loc_831CE128;
	// cmplwi cr6,r11,100
	cr6.compare<uint32_t>(r11.u32, 100, xer);
	// bne cr6,0x831ce12c
	if (!cr6.eq) goto loc_831CE12C;
loc_831CE128:
	// li r27,1
	r27.s64 = 1;
loc_831CE12C:
	// clrlwi. r10,r27,24
	ctx.r10.u64 = r27.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831ce180
	if (cr0.eq) goto loc_831CE180;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r29,-24
	r11.s64 = r29.s64 + -24;
	// add r28,r3,r11
	r28.u64 = ctx.r3.u64 + r11.u64;
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ce200
	if (cr6.eq) goto loc_831CE200;
	// lwz r29,4(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r11,r29,2
	r11.s64 = r29.s64 + 2;
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// b 0x831ce1d0
	goto loc_831CE1D0;
loc_831CE180:
	// cmplwi cr6,r11,96
	cr6.compare<uint32_t>(r11.u32, 96, xer);
	// bne cr6,0x831ce200
	if (!cr6.eq) goto loc_831CE200;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r29,-20
	r11.s64 = r29.s64 + -20;
	// add r28,r3,r11
	r28.u64 = ctx.r3.u64 + r11.u64;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ce200
	if (cr6.eq) goto loc_831CE200;
	// lwz r29,4(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r11,r29,2
	r11.s64 = r29.s64 + 2;
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
loc_831CE1D0:
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r29,4(r28)
	PPC_STORE_U32(r28.u32 + 4, r29.u32);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-4
	r11.s64 = r31.s64 + -4;
	// stwx r28,r3,r11
	PPC_STORE_U32(ctx.r3.u32 + r11.u32, r28.u32);
loc_831CE200:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831CDF00) {
	__imp__sub_831CDF00(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CE210) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r29,12(r28)
	r29.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,15872
	cr6.compare<uint32_t>(r11.u32, 15872, xer);
	// bne cr6,0x831ce320
	if (!cr6.eq) goto loc_831CE320;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r10,r29,-8
	ctx.r10.s64 = r29.s64 + -8;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwzx r10,r3,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r10.u32);
	// clrlwi r10,r10,17
	ctx.r10.u64 = ctx.r10.u32 & 0x7FFF;
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,0,25,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x70;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bne cr6,0x831ce320
	if (!cr6.eq) goto loc_831CE320;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdf00
	sub_831CDF00(ctx, base);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r7,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// lwz r29,0(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 0);
loc_831CE2E0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831ce314
	if (cr6.eq) goto loc_831CE314;
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// beq cr6,0x831ce30c
	if (cr6.eq) goto loc_831CE30C;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// beq cr6,0x831ce30c
	if (cr6.eq) goto loc_831CE30C;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
loc_831CE30C:
	// lwz r29,4(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// b 0x831ce2e0
	goto loc_831CE2E0;
loc_831CE314:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_831CE320:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831CE210) {
	__imp__sub_831CE210(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CE330) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// std r4,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, ctx.r4.u64);
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// lwz r27,212(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// clrlwi r23,r27,27
	r23.u64 = r27.u32 & 0x1F;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r5,216(r1)
	PPC_STORE_U64(ctx.r1.u32 + 216, ctx.r5.u64);
	// li r26,1
	r26.s64 = 1;
	// mr r28,r25
	r28.u64 = r25.u64;
	// rlwinm r24,r27,27,28,31
	r24.u64 = rotl64(r27.u32 | (r27.u64 << 32), 27) & 0xF;
	// mr r30,r23
	r30.u64 = r23.u64;
	// li r22,0
	r22.s64 = 0;
	// cmplwi cr6,r23,16
	cr6.compare<uint32_t>(r23.u32, 16, xer);
	// beq cr6,0x831ce394
	if (cr6.eq) goto loc_831CE394;
	// cmplwi cr6,r23,14
	cr6.compare<uint32_t>(r23.u32, 14, xer);
	// beq cr6,0x831ce394
	if (cr6.eq) goto loc_831CE394;
	// cmplwi cr6,r23,15
	cr6.compare<uint32_t>(r23.u32, 15, xer);
	// beq cr6,0x831ce394
	if (cr6.eq) goto loc_831CE394;
	// cmplwi cr6,r23,18
	cr6.compare<uint32_t>(r23.u32, 18, xer);
	// beq cr6,0x831ce394
	if (cr6.eq) goto loc_831CE394;
	// li r30,16
	r30.s64 = 16;
	// mr r28,r26
	r28.u64 = r26.u64;
	// mr r22,r26
	r22.u64 = r26.u64;
loc_831CE394:
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// ble cr6,0x831ce3a8
	if (!cr6.gt) goto loc_831CE3A8;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831CE3A8:
	// lwz r10,536(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x831ce3f8
	if (!cr6.gt) goto loc_831CE3F8;
	// addi r10,r31,348
	ctx.r10.s64 = r31.s64 + 348;
loc_831CE3BC:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// cmplw cr6,r30,r9
	cr6.compare<uint32_t>(r30.u32, ctx.r9.u32, xer);
	// beq cr6,0x831ce3e4
	if (cr6.eq) goto loc_831CE3E4;
	// lwz r9,536(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x831ce3bc
	if (cr6.lt) goto loc_831CE3BC;
	// b 0x831ce3f8
	goto loc_831CE3F8;
loc_831CE3E4:
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lwz r29,352(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 352);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x831ce5a0
	if (!cr6.eq) goto loc_831CE5A0;
loc_831CE3F8:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,113
	ctx.r4.s64 = 113;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,35
	ctx.r5.s64 = 35;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831ce430
	if (cr0.eq) goto loc_831CE430;
	// li r11,0
	r11.s64 = 0;
loc_831CE430:
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,113
	ctx.r6.s64 = 113;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831cd678
	sub_831CD678(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// oris r11,r11,128
	r11.u64 = r11.u64 | 8388608;
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r11,r10,31
	r11.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ce468
	if (cr0.eq) goto loc_831CE468;
	// li r10,0
	ctx.r10.s64 = 0;
loc_831CE468:
	// rlwinm r11,r29,0,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// addi r9,r10,16
	ctx.r9.s64 = ctx.r10.s64 + 16;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r9,r9,-36
	ctx.r9.s64 = ctx.r9.s64 + -36;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// ori r6,r9,1
	ctx.r6.u64 = ctx.r9.u64 | 1;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// rlwinm r8,r8,0,0,30
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, ctx.r9.u32);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// oris r10,r10,2048
	ctx.r10.u64 = ctx.r10.u64 | 134217728;
	// andi. r9,r11,34952
	ctx.r9.u64 = r11.u64 & 34952;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// stw r10,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r10.u32);
	// cmplwi cr6,r9,34952
	cr6.compare<uint32_t>(ctx.r9.u32, 34952, xer);
	// beq cr6,0x831ce4c4
	if (cr6.eq) goto loc_831CE4C4;
	// ori r11,r11,34952
	r11.u64 = r11.u64 | 34952;
	// sth r11,14(r29)
	PPC_STORE_U16(r29.u32 + 14, r11.u16);
loc_831CE4C4:
	// lwz r11,536(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// bne cr6,0x831ce4dc
	if (!cr6.eq) goto loc_831CE4DC;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831CE4DC:
	// cmplw cr6,r30,r23
	cr6.compare<uint32_t>(r30.u32, r23.u32, xer);
	// bne cr6,0x831ce4f8
	if (!cr6.eq) goto loc_831CE4F8;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831ce4f8
	if (cr6.eq) goto loc_831CE4F8;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831CE4F8:
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// cmplwi cr6,r30,16
	cr6.compare<uint32_t>(r30.u32, 16, xer);
	// stw r29,352(r11)
	PPC_STORE_U32(r11.u32 + 352, r29.u32);
	// slw r11,r26,r28
	r11.u64 = r28.u8 & 0x20 ? 0 : (r26.u32 << (r28.u8 & 0x3F));
	// addi r10,r11,-1
	ctx.r10.s64 = r11.s64 + -1;
	// lwz r11,536(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// addi r11,r11,29
	r11.s64 = r11.s64 + 29;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// lwzx r9,r11,r31
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// rlwimi r9,r30,0,27,31
	ctx.r9.u64 = (rotl32(r30.u32, 0) & 0x1F) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFE0);
	// stwx r9,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r9.u32);
	// lwz r11,536(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// addi r11,r11,29
	r11.s64 = r11.s64 + 29;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// lwzx r9,r11,r31
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// rlwinm r9,r9,0,27,22
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFFE1F;
	// stwx r9,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r9.u32);
	// lwz r11,536(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// addi r11,r11,29
	r11.s64 = r11.s64 + 29;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// lwzx r9,r11,r31
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// rlwimi r9,r10,9,19,22
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 9) & 0x1E00) | (ctx.r9.u64 & 0xFFFFFFFFFFFFE1FF);
	// stwx r9,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r9.u32);
	// lwz r11,536(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// addi r11,r11,29
	r11.s64 = r11.s64 + 29;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// lwzx r10,r11,r31
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// rlwimi r10,r27,0,18,18
	ctx.r10.u64 = (rotl32(r27.u32, 0) & 0x2000) | (ctx.r10.u64 & 0xFFFFFFFFFFFFDFFF);
	// stwx r10,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r10.u32);
	// lwz r11,536(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// bne cr6,0x831ce58c
	if (!cr6.eq) goto loc_831CE58C;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r10,r10,1728
	ctx.r10.s64 = ctx.r10.s64 + 1728;
	// b 0x831ce590
	goto loc_831CE590;
loc_831CE58C:
	// lwz r10,208(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 208);
loc_831CE590:
	// stw r10,344(r11)
	PPC_STORE_U32(r11.u32 + 344, ctx.r10.u32);
	// lwz r11,536(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,536(r31)
	PPC_STORE_U32(r31.u32 + 536, r11.u32);
loc_831CE5A0:
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ce5c0
	if (!cr0.eq) goto loc_831CE5C0;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r30,r29
	r30.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ce6a8
	if (cr6.eq) goto loc_831CE6A8;
	// stw r26,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r26.u32);
	// b 0x831ce6a8
	goto loc_831CE6A8;
loc_831CE5C0:
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,96
	ctx.r4.s64 = 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,35
	ctx.r5.s64 = 35;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// clrlwi. r11,r5,31
	r11.u64 = ctx.r5.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ce5f8
	if (cr0.eq) goto loc_831CE5F8;
	// li r5,0
	ctx.r5.s64 = 0;
loc_831CE5F8:
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,96
	ctx.r6.s64 = 96;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831cd678
	sub_831CD678(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-20
	r11.s64 = r30.s64 + -20;
	// rlwimi r24,r23,4,0,27
	r24.u64 = (rotl32(r23.u32, 4) & 0xFFFFFFF0) | (r24.u64 & 0xFFFFFFFF0000000F);
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stb r24,15(r11)
	PPC_STORE_U8(r11.u32 + 15, r24.u8);
	// oris r10,r9,8
	ctx.r10.u64 = ctx.r9.u64 | 524288;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r11,r10,31
	r11.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ce670
	if (cr0.eq) goto loc_831CE670;
	// li r10,0
	ctx.r10.s64 = 0;
loc_831CE670:
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r8,24(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// addi r9,r10,24
	ctx.r9.s64 = ctx.r10.s64 + 24;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r9,r9,-36
	ctx.r9.s64 = ctx.r9.s64 + -36;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// ori r6,r9,1
	ctx.r6.u64 = ctx.r9.u64 | 1;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// lwz r8,24(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// rlwinm r8,r8,0,0,30
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,24(r10)
	PPC_STORE_U32(ctx.r10.u32 + 24, ctx.r9.u32);
loc_831CE6A8:
	// cmplwi cr6,r23,14
	cr6.compare<uint32_t>(r23.u32, 14, xer);
	// beq cr6,0x831ce700
	if (cr6.eq) goto loc_831CE700;
	// cmplwi cr6,r23,15
	cr6.compare<uint32_t>(r23.u32, 15, xer);
	// beq cr6,0x831ce6dc
	if (cr6.eq) goto loc_831CE6DC;
	// cmplwi cr6,r23,18
	cr6.compare<uint32_t>(r23.u32, 18, xer);
	// bne cr6,0x831ce738
	if (!cr6.eq) goto loc_831CE738;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// andi. r10,r11,61166
	ctx.r10.u64 = r11.u64 & 61166;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,61166
	cr6.compare<uint32_t>(ctx.r10.u32, 61166, xer);
	// beq cr6,0x831ce738
	if (cr6.eq) goto loc_831CE738;
	// ori r11,r11,61166
	r11.u64 = r11.u64 | 61166;
	// sth r11,14(r30)
	PPC_STORE_U16(r30.u32 + 14, r11.u16);
	// b 0x831ce738
	goto loc_831CE738;
loc_831CE6DC:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// andi. r10,r11,61166
	ctx.r10.u64 = r11.u64 & 61166;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,61166
	cr6.compare<uint32_t>(ctx.r10.u32, 61166, xer);
	// beq cr6,0x831ce6f4
	if (cr6.eq) goto loc_831CE6F4;
	// ori r11,r11,61166
	r11.u64 = r11.u64 | 61166;
	// sth r11,14(r30)
	PPC_STORE_U16(r30.u32 + 14, r11.u16);
loc_831CE6F4:
	// lis r11,-32240
	r11.s64 = -2112880640;
	// lfd f2,2576(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(r11.u32 + 2576);
	// b 0x831ce720
	goto loc_831CE720;
loc_831CE700:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// andi. r10,r11,43690
	ctx.r10.u64 = r11.u64 & 43690;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,43690
	cr6.compare<uint32_t>(ctx.r10.u32, 43690, xer);
	// beq cr6,0x831ce718
	if (cr6.eq) goto loc_831CE718;
	// ori r11,r11,43690
	r11.u64 = r11.u64 | 43690;
	// sth r11,14(r30)
	PPC_STORE_U16(r30.u32 + 14, r11.u16);
loc_831CE718:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f2,3248(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(r11.u32 + 3248);
loc_831CE720:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lfd f1,3376(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3376);
	// bl 0x831cbf40
	sub_831CBF40(ctx, base);
loc_831CE738:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_831CE330) {
	__imp__sub_831CE330(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CE748) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mulli r11,r24,40
	r11.s64 = r24.s64 * 40;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r29,r11,r10
	r29.u64 = r11.u64 + ctx.r10.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// mr r23,r8
	r23.u64 = ctx.r8.u64;
	// mr r22,r9
	r22.u64 = ctx.r9.u64;
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831ce78c
	if (!cr6.eq) goto loc_831CE78C;
	// bl 0x831387b8
	sub_831387B8(ctx, base);
loc_831CE78C:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// clrlwi. r7,r28,24
	ctx.r7.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// mr r25,r30
	r25.u64 = r30.u64;
	// rlwinm r8,r11,29,18,31
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// beq 0x831ce7b0
	if (cr0.eq) goto loc_831CE7B0;
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// rlwinm r10,r30,3,0,28
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r25,r11,28,18,31
	r25.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x3FFF;
loc_831CE7B0:
	// li r28,-1
	r28.s64 = -1;
	// li r27,0
	r27.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x831ce80c
	if (cr6.eq) goto loc_831CE80C;
	// lwz r9,28(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 28);
loc_831CE7CC:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r6,r10,28,18,31
	ctx.r6.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0x3FFF;
	// cmplw cr6,r6,r25
	cr6.compare<uint32_t>(ctx.r6.u32, r25.u32, xer);
	// bne cr6,0x831ce7f4
	if (!cr6.eq) goto loc_831CE7F4;
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// or r27,r10,r27
	r27.u64 = ctx.r10.u64 | r27.u64;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bge cr6,0x831ce7f4
	if (!cr6.lt) goto loc_831CE7F4;
	// mr r28,r11
	r28.u64 = r11.u64;
loc_831CE7F4:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,8
	ctx.r9.s64 = ctx.r9.s64 + 8;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x831ce7cc
	if (cr6.lt) goto loc_831CE7CC;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x831ce828
	if (!cr6.eq) goto loc_831CE828;
loc_831CE80C:
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x831ce81c
	if (!cr6.eq) goto loc_831CE81C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831ce8d0
	goto loc_831CE8D0;
loc_831CE81C:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831CE828:
	// addi r11,r26,-104
	r11.s64 = r26.s64 + -104;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r5,r11,27,31,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,35
	ctx.r5.s64 = 35;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// rlwinm r8,r28,3,0,28
	ctx.r8.u64 = rotl64(r28.u32 | (r28.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// rlwinm r11,r11,14,30,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 14) & 0x3;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// bl 0x831cdc08
	sub_831CDC08(ctx, base);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdaf0
	sub_831CDAF0(ctx, base);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwinm. r11,r11,28,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x7;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ce8b8
	if (!cr0.eq) goto loc_831CE8B8;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// b 0x831ce8c8
	goto loc_831CE8C8;
loc_831CE8B8:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x831ce8cc
	if (!cr6.eq) goto loc_831CE8CC;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
loc_831CE8C8:
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
loc_831CE8CC:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_831CE8D0:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_831CE748) {
	__imp__sub_831CE748(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CE8D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// addi r30,r29,812
	r30.s64 = r29.s64 + 812;
	// lwz r27,16(r29)
	r27.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// addi r25,r27,1
	r25.s64 = r27.s64 + 1;
	// mulli r4,r25,40
	ctx.r4.s64 = r25.s64 * 40;
	// cmplwi cr6,r4,132
	cr6.compare<uint32_t>(ctx.r4.u32, 132, xer);
	// ble cr6,0x831ce918
	if (!cr6.gt) goto loc_831CE918;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83110758
	sub_83110758(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x831ce984
	goto loc_831CE984;
loc_831CE918:
	// lwz r10,140(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 140);
	// lwz r11,144(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 144);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// addi r10,r10,4096
	ctx.r10.s64 = ctx.r10.s64 + 4096;
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// blt cr6,0x831ce93c
	if (cr6.lt) goto loc_831CE93C;
	// add r10,r11,r4
	ctx.r10.u64 = r11.u64 + ctx.r4.u64;
	// stw r10,144(r30)
	PPC_STORE_U32(r30.u32 + 144, ctx.r10.u32);
	// b 0x831ce980
	goto loc_831CE980;
loc_831CE93C:
	// rlwinm r11,r4,30,2,31
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r30
	r31.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831ce974
	if (cr6.eq) goto loc_831CE974;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stwx r10,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, ctx.r10.u32);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// mr r11,r31
	r11.u64 = r31.u64;
	// b 0x831ce980
	goto loc_831CE980;
loc_831CE974:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8310fe28
	sub_8310FE28(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831CE980:
	// mr r28,r11
	r28.u64 = r11.u64;
loc_831CE984:
	// mulli r5,r27,40
	ctx.r5.s64 = r27.s64 * 40;
	// lwz r4,12(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// add r31,r5,r28
	r31.u64 = ctx.r5.u64 + r28.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// li r5,40
	ctx.r5.s64 = 40;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// cmplwi cr6,r10,132
	cr6.compare<uint32_t>(ctx.r10.u32, 132, xer);
	// ble cr6,0x831ce9f0
	if (!cr6.gt) goto loc_831CE9F0;
	// addi r3,r11,-12
	ctx.r3.s64 = r11.s64 + -12;
	// lis r4,24973
	ctx.r4.s64 = 1636630528;
	// rlwinm r11,r3,0,0,30
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// b 0x831cea08
	goto loc_831CEA08;
loc_831CE9F0:
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r30
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// stwx r11,r10,r30
	PPC_STORE_U32(ctx.r10.u32 + r30.u32, r11.u32);
loc_831CEA08:
	// stw r25,16(r29)
	PPC_STORE_U32(r29.u32 + 16, r25.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r28,12(r29)
	PPC_STORE_U32(r29.u32 + 12, r28.u32);
	// stw r25,20(r29)
	PPC_STORE_U32(r29.u32 + 20, r25.u32);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwimi r10,r24,4,25,27
	ctx.r10.u64 = (rotl32(r24.u32, 4) & 0x70) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFF8F);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// beq cr6,0x831cea50
	if (cr6.eq) goto loc_831CEA50;
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// li r11,40
	r11.s64 = 40;
	// lwz r10,12(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// subf r10,r10,r31
	ctx.r10.s64 = r31.s64 - ctx.r10.s64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// divw r4,r10,r11
	ctx.r4.s32 = ctx.r10.s32 / r11.s32;
	// bl 0x831387b8
	sub_831387B8(ctx, base);
loc_831CEA50:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_831CE8D8) {
	__imp__sub_831CE8D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CEA60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// addi r31,r25,812
	r31.s64 = r25.s64 + 812;
	// lwz r29,20(r25)
	r29.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// addi r28,r29,1
	r28.s64 = r29.s64 + 1;
	// mulli r4,r28,40
	ctx.r4.s64 = r28.s64 * 40;
	// cmplwi cr6,r4,132
	cr6.compare<uint32_t>(ctx.r4.u32, 132, xer);
	// ble cr6,0x831ceaa0
	if (!cr6.gt) goto loc_831CEAA0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83110758
	sub_83110758(ctx, base);
	// b 0x831ceb04
	goto loc_831CEB04;
loc_831CEAA0:
	// lwz r10,140(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 140);
	// lwz r11,144(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 144);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// addi r10,r10,4096
	ctx.r10.s64 = ctx.r10.s64 + 4096;
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// blt cr6,0x831ceac8
	if (cr6.lt) goto loc_831CEAC8;
	// add r10,r11,r4
	ctx.r10.u64 = r11.u64 + ctx.r4.u64;
	// mr r30,r11
	r30.u64 = r11.u64;
	// stw r10,144(r31)
	PPC_STORE_U32(r31.u32 + 144, ctx.r10.u32);
	// b 0x831ceb08
	goto loc_831CEB08;
loc_831CEAC8:
	// rlwinm r11,r4,30,2,31
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r31
	r30.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831ceafc
	if (cr6.eq) goto loc_831CEAFC;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stwx r10,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r10.u32);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// b 0x831ceb08
	goto loc_831CEB08;
loc_831CEAFC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fe28
	sub_8310FE28(ctx, base);
loc_831CEB04:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_831CEB08:
	// mulli r5,r29,40
	ctx.r5.s64 = r29.s64 * 40;
	// lwz r4,12(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// add r29,r5,r30
	r29.u64 = ctx.r5.u64 + r30.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// cmplwi cr6,r10,132
	cr6.compare<uint32_t>(ctx.r10.u32, 132, xer);
	// ble cr6,0x831ceb64
	if (!cr6.gt) goto loc_831CEB64;
	// addi r3,r11,-12
	ctx.r3.s64 = r11.s64 + -12;
	// lis r4,24973
	ctx.r4.s64 = 1636630528;
	// rlwinm r11,r3,0,0,30
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x821f5f18
	sub_821F5F18(ctx, base);
	// b 0x831ceb7c
	goto loc_831CEB7C;
loc_831CEB64:
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r31
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r31.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// stwx r11,r10,r31
	PPC_STORE_U32(ctx.r10.u32 + r31.u32, r11.u32);
loc_831CEB7C:
	// rlwimi r27,r26,3,15,28
	r27.u64 = (rotl32(r26.u32, 3) & 0x1FFF8) | (r27.u64 & 0xFFFFFFFFFFFE0007);
	// stw r30,12(r25)
	PPC_STORE_U32(r25.u32 + 12, r30.u32);
	// stw r28,20(r25)
	PPC_STORE_U32(r25.u32 + 20, r28.u32);
	// rlwinm r4,r26,3,0,28
	ctx.r4.u64 = rotl64(r26.u32 | (r26.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r28,16(r25)
	PPC_STORE_U32(r25.u32 + 16, r28.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwimi r27,r11,0,0,14
	r27.u64 = (rotl32(r11.u32, 0) & 0xFFFE0000) | (r27.u64 & 0xFFFFFFFF0001FFFF);
	// cmplwi cr6,r4,132
	cr6.compare<uint32_t>(ctx.r4.u32, 132, xer);
	// stw r27,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r27.u32);
	// ble cr6,0x831cebb0
	if (!cr6.gt) goto loc_831CEBB0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83110758
	sub_83110758(ctx, base);
	// b 0x831cec14
	goto loc_831CEC14;
loc_831CEBB0:
	// lwz r10,140(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 140);
	// lwz r11,144(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 144);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// addi r10,r10,4096
	ctx.r10.s64 = ctx.r10.s64 + 4096;
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// blt cr6,0x831cebd4
	if (cr6.lt) goto loc_831CEBD4;
	// add r10,r11,r4
	ctx.r10.u64 = r11.u64 + ctx.r4.u64;
	// stw r10,144(r31)
	PPC_STORE_U32(r31.u32 + 144, ctx.r10.u32);
	// b 0x831cec18
	goto loc_831CEC18;
loc_831CEBD4:
	// rlwinm r11,r4,30,2,31
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r31
	r30.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831cec0c
	if (cr6.eq) goto loc_831CEC0C;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stwx r10,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r10.u32);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// mr r11,r30
	r11.u64 = r30.u64;
	// b 0x831cec18
	goto loc_831CEC18;
loc_831CEC0C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fe28
	sub_8310FE28(ctx, base);
loc_831CEC14:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831CEC18:
	// stw r11,28(r29)
	PPC_STORE_U32(r29.u32 + 28, r11.u32);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831ced3c
	if (cr6.eq) goto loc_831CED3C;
loc_831CEC24:
	// li r30,0
	r30.s64 = 0;
loc_831CEC28:
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bge cr6,0x831ced28
	if (!cr6.lt) goto loc_831CED28;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831959b0
	sub_831959B0(ctx, base);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831cec58
	if (cr0.eq) goto loc_831CEC58;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// b 0x831cec28
	goto loc_831CEC28;
loc_831CEC58:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_831CEC5C:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831cec5c
	if (!cr6.eq) goto loc_831CEC5C;
	// subf r11,r24,r11
	r11.s64 = r11.s64 - r24.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// addi r4,r11,2
	ctx.r4.s64 = r11.s64 + 2;
	// cmplwi cr6,r4,132
	cr6.compare<uint32_t>(ctx.r4.u32, 132, xer);
	// ble cr6,0x831cec90
	if (!cr6.gt) goto loc_831CEC90;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83110758
	sub_83110758(ctx, base);
	// b 0x831cecf8
	goto loc_831CECF8;
loc_831CEC90:
	// lwz r10,140(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 140);
	// lwz r11,144(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 144);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// addi r10,r10,4096
	ctx.r10.s64 = ctx.r10.s64 + 4096;
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// blt cr6,0x831cecb8
	if (cr6.lt) goto loc_831CECB8;
	// add r10,r11,r4
	ctx.r10.u64 = r11.u64 + ctx.r4.u64;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// stw r10,144(r31)
	PPC_STORE_U32(r31.u32 + 144, ctx.r10.u32);
	// b 0x831cecf8
	goto loc_831CECF8;
loc_831CECB8:
	// rlwinm r11,r4,30,2,31
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r31
	r30.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831cecf0
	if (cr6.eq) goto loc_831CECF0;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stwx r10,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r10.u32);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x831cecf8
	goto loc_831CECF8;
loc_831CECF0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fe28
	sub_8310FE28(ctx, base);
loc_831CECF8:
	// li r11,36
	r11.s64 = 36;
	// subf r10,r24,r3
	ctx.r10.s64 = ctx.r3.s64 - r24.s64;
	// stb r11,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, r11.u8);
	// mr r11,r24
	r11.u64 = r24.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
loc_831CED0C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// stbx r9,r10,r11
	PPC_STORE_U8(ctx.r10.u32 + r11.u32, ctx.r9.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne 0x831ced0c
	if (!cr0.eq) goto loc_831CED0C;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// b 0x831cec24
	goto loc_831CEC24;
loc_831CED28:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83195e78
	sub_83195E78(ctx, base);
	// stw r3,12(r29)
	PPC_STORE_U32(r29.u32 + 12, ctx.r3.u32);
loc_831CED3C:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_831CEA60) {
	__imp__sub_831CEA60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CED48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// bl 0x83199928
	sub_83199928(ctx, base);
	// rlwinm r24,r26,3,0,28
	r24.u64 = rotl64(r26.u32 | (r26.u64 << 32), 3) & 0xFFFFFFF8;
	// add r23,r24,r3
	r23.u64 = r24.u64 + ctx.r3.u64;
	// lwzx r11,r24,r3
	r11.u64 = PPC_LOAD_U32(r24.u32 + ctx.r3.u32);
	// lwz r10,4(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// stw r10,4(r25)
	PPC_STORE_U32(r25.u32 + 4, ctx.r10.u32);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831cede8
	if (!cr6.eq) goto loc_831CEDE8;
	// lwz r31,0(r25)
	r31.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// bne cr6,0x831cede8
	if (!cr6.eq) goto loc_831CEDE8;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,112
	ctx.r4.s64 = 112;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-8
	r11.s64 = r31.s64 + -8;
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// clrlwi r10,r11,17
	ctx.r10.u64 = r11.u32 & 0x7FFF;
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// bne cr6,0x831cede8
	if (!cr6.eq) goto loc_831CEDE8;
	// rlwinm r11,r11,17,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 17) & 0x3FFF;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// beq cr6,0x831cf010
	if (cr6.eq) goto loc_831CF010;
loc_831CEDE8:
	// lwz r31,20(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// addi r29,r27,16
	r29.s64 = r27.s64 + 16;
	// clrlwi. r11,r31,31
	r11.u64 = r31.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831cee68
	if (!cr0.eq) goto loc_831CEE68;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x831cee68
	if (cr0.eq) goto loc_831CEE68;
loc_831CEE00:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// bne cr6,0x831cee44
	if (!cr6.eq) goto loc_831CEE44;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,112
	ctx.r4.s64 = 112;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-8
	r11.s64 = r31.s64 + -8;
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// clrlwi r10,r11,17
	ctx.r10.u64 = r11.u32 & 0x7FFF;
	// cmplw cr6,r10,r28
	cr6.compare<uint32_t>(ctx.r10.u32, r28.u32, xer);
	// bne cr6,0x831cee44
	if (!cr6.eq) goto loc_831CEE44;
	// rlwinm r11,r11,17,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 17) & 0x3FFF;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// beq cr6,0x831cee60
	if (cr6.eq) goto loc_831CEE60;
loc_831CEE44:
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r31,40(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// clrlwi. r11,r31,31
	r11.u64 = r31.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831cee68
	if (!cr0.eq) goto loc_831CEE68;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831cee00
	if (!cr6.eq) goto loc_831CEE00;
	// b 0x831cee68
	goto loc_831CEE68;
loc_831CEE60:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831cefd4
	if (!cr6.eq) goto loc_831CEFD4;
loc_831CEE68:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831cee78
	if (cr0.eq) goto loc_831CEE78;
	// li r11,0
	r11.s64 = 0;
loc_831CEE78:
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bne cr6,0x831cef04
	if (!cr6.eq) goto loc_831CEF04;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,116
	ctx.r6.s64 = 116;
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r29,4
	r11.s64 = r29.s64 + 4;
	// lwz r9,4(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r8,r11,1
	ctx.r8.u64 = r11.u64 | 1;
	// addi r11,r10,36
	r11.s64 = ctx.r10.s64 + 36;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// li r4,116
	ctx.r4.s64 = 116;
	// lwz r9,4(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,36(r9)
	PPC_STORE_U32(ctx.r9.u32 + 36, ctx.r10.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// stw r7,4(r29)
	PPC_STORE_U32(r29.u32 + 4, ctx.r7.u32);
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-4
	r11.s64 = r31.s64 + -4;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r26,15,3,16
	ctx.r10.u64 = (rotl32(r26.u32, 15) & 0x1FFF8000) | (ctx.r10.u64 & 0xFFFFFFFFE0007FFF);
	// rlwimi r10,r28,0,17,31
	ctx.r10.u64 = (rotl32(r28.u32, 0) & 0x7FFF) | (ctx.r10.u64 & 0xFFFFFFFFFFFF8000);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x831cefd4
	goto loc_831CEFD4;
loc_831CEF04:
	// bl 0x831cdda0
	sub_831CDDA0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,112
	ctx.r4.s64 = 112;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-8
	r11.s64 = r31.s64 + -8;
	// lis r10,8192
	ctx.r10.s64 = 536870912;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// rlwimi r10,r26,15,3,16
	ctx.r10.u64 = (rotl32(r26.u32, 15) & 0x1FFF8000) | (ctx.r10.u64 & 0xFFFFFFFFE0007FFF);
	// clrlwi r9,r28,17
	ctx.r9.u64 = r28.u32 & 0x7FFF;
	// mulli r29,r28,40
	r29.s64 = r28.s64 * 40;
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r8,0,0,2
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xE0000000;
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r29,r11
	r11.u64 = r29.u64 + r11.u64;
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831cef78
	if (!cr6.eq) goto loc_831CEF78;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,5,5
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cef78
	if (cr0.eq) goto loc_831CEF78;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831387b8
	sub_831387B8(ctx, base);
loc_831CEF78:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r29,r11
	r11.u64 = r29.u64 + r11.u64;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831cefd4
	if (cr6.eq) goto loc_831CEFD4;
	// lwzx r11,r11,r24
	r11.u64 = PPC_LOAD_U32(r11.u32 + r24.u32);
	// rlwinm r11,r11,14,30,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 14) & 0x3;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x831cefbc
	if (cr6.eq) goto loc_831CEFBC;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x831cefd4
	if (!cr6.eq) goto loc_831CEFD4;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r10,r11,0,29,30
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x6;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// beq cr6,0x831cefd4
	if (cr6.eq) goto loc_831CEFD4;
	// ori r11,r11,6
	r11.u64 = r11.u64 | 6;
	// b 0x831cefd0
	goto loc_831CEFD0;
loc_831CEFBC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r10,r11,0,29,29
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// beq cr6,0x831cefd4
	if (cr6.eq) goto loc_831CEFD4;
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
loc_831CEFD0:
	// sth r11,14(r31)
	PPC_STORE_U16(r31.u32 + 14, r11.u16);
loc_831CEFD4:
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831ceff0
	if (cr6.eq) goto loc_831CEFF0;
	// lwz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// clrlwi. r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831cf000
	if (!cr0.eq) goto loc_831CF000;
loc_831CEFF0:
	// lwz r10,4(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// stw r31,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r31.u32);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r23)
	PPC_STORE_U32(r23.u32 + 4, ctx.r10.u32);
loc_831CF000:
	// lwz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// stw r31,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r31.u32);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r25)
	PPC_STORE_U32(r25.u32 + 4, ctx.r10.u32);
loc_831CF010:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_831CED48) {
	__imp__sub_831CED48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF020) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r22,r4
	r22.u64 = ctx.r4.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// lwz r10,8(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwz r11,8(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// xor r11,r11,r10
	r11.u64 = r11.u64 ^ ctx.r10.u64;
	// rlwinm. r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cf054
	if (cr0.eq) goto loc_831CF054;
loc_831CF04C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831cf288
	goto loc_831CF288;
loc_831CF054:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// li r23,0
	r23.s64 = 0;
loc_831CF05C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831cf070
	if (cr6.eq) goto loc_831CF070;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// b 0x831cf05c
	goto loc_831CF05C;
loc_831CF070:
	// lis r11,-31980
	r11.s64 = -2095841280;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// addi r5,r11,6976
	ctx.r5.s64 = r11.s64 + 6976;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83140f90
	sub_83140F90(ctx, base);
	// lwz r29,0(r22)
	r29.u64 = PPC_LOAD_U32(r22.u32 + 0);
loc_831CF088:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831cf154
	if (cr6.eq) goto loc_831CF154;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// li r28,0
	r28.s64 = 0;
	// lwz r25,12(r29)
	r25.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// li r30,1
	r30.s64 = 1;
	// lwz r31,0(r24)
	r31.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// rlwinm r27,r11,2,31,31
	r27.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
	// rlwinm r26,r11,7,29,31
	r26.u64 = rotl64(r11.u32 | (r11.u64 << 32), 7) & 0x7;
loc_831CF0AC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831cf144
	if (cr6.eq) goto loc_831CF144;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// clrlwi r10,r27,24
	ctx.r10.u64 = r27.u32 & 0xFF;
	// rlwinm r9,r11,2,31,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x831cf138
	if (!cr6.eq) goto loc_831CF138;
	// rlwinm r11,r11,7,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 7) & 0x7;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bne cr6,0x831cf138
	if (!cr6.eq) goto loc_831CF138;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831cf0f4
	if (cr6.eq) goto loc_831CF0F4;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb500
	sub_831CB500(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831cf100
	if (!cr0.eq) goto loc_831CF100;
	// b 0x831cf138
	goto loc_831CF138;
loc_831CF0F4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x831cf138
	if (!cr6.eq) goto loc_831CF138;
loc_831CF100:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// not r10,r11
	ctx.r10.u64 = ~r11.u64;
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// bne 0x831cf118
	if (!cr0.eq) goto loc_831CF118;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
loc_831CF118:
	// rlwinm r11,r30,29,3,29
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 29) & 0x1FFFFFFC;
	// li r8,1
	ctx.r8.s64 = 1;
	// clrlwi r9,r30,27
	ctx.r9.u64 = r30.u32 & 0x1F;
	// li r28,1
	r28.s64 = 1;
	// slw r9,r8,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r9.u8 & 0x3F));
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_831CF138:
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// b 0x831cf0ac
	goto loc_831CF0AC;
loc_831CF144:
	// clrlwi. r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cf04c
	if (cr0.eq) goto loc_831CF04C;
	// lwz r29,4(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// b 0x831cf088
	goto loc_831CF088;
loc_831CF154:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x831cf284
	if (cr6.eq) goto loc_831CF284;
	// addi r5,r23,-1
	ctx.r5.s64 = r23.s64 + -1;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x831ccca0
	sub_831CCCA0(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831cf04c
	if (!cr0.eq) goto loc_831CF04C;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// li r31,0
	r31.s64 = 0;
	// rlwinm. r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cf1b4
	if (cr0.eq) goto loc_831CF1B4;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// ble cr6,0x831cf1ac
	if (!cr6.gt) goto loc_831CF1AC;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// beq cr6,0x831cf1ac
	if (cr6.eq) goto loc_831CF1AC;
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// beq cr6,0x831cf1ac
	if (cr6.eq) goto loc_831CF1AC;
	// cmplwi cr6,r11,15
	cr6.compare<uint32_t>(r11.u32, 15, xer);
	// ble cr6,0x831cf1b4
	if (!cr6.gt) goto loc_831CF1B4;
	// cmplwi cr6,r11,18
	cr6.compare<uint32_t>(r11.u32, 18, xer);
	// bgt cr6,0x831cf1b4
	if (cr6.gt) goto loc_831CF1B4;
loc_831CF1AC:
	// li r11,1
	r11.s64 = 1;
	// b 0x831cf1b8
	goto loc_831CF1B8;
loc_831CF1B4:
	// li r11,0
	r11.s64 = 0;
loc_831CF1B8:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cf214
	if (cr0.eq) goto loc_831CF214;
	// lwz r4,44(r22)
	ctx.r4.u64 = PPC_LOAD_U32(r22.u32 + 44);
	// li r31,2
	r31.s64 = 2;
	// lwz r3,44(r24)
	ctx.r3.u64 = PPC_LOAD_U32(r24.u32 + 44);
	// bl 0x831cb500
	sub_831CB500(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cf1ec
	if (cr0.eq) goto loc_831CF1EC;
	// lwz r4,48(r22)
	ctx.r4.u64 = PPC_LOAD_U32(r22.u32 + 48);
	// lwz r3,48(r24)
	ctx.r3.u64 = PPC_LOAD_U32(r24.u32 + 48);
	// bl 0x831cb500
	sub_831CB500(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831cf214
	if (!cr0.eq) goto loc_831CF214;
loc_831CF1EC:
	// lwz r4,44(r22)
	ctx.r4.u64 = PPC_LOAD_U32(r22.u32 + 44);
	// lwz r3,48(r24)
	ctx.r3.u64 = PPC_LOAD_U32(r24.u32 + 48);
	// bl 0x831cb500
	sub_831CB500(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cf04c
	if (cr0.eq) goto loc_831CF04C;
	// lwz r4,48(r22)
	ctx.r4.u64 = PPC_LOAD_U32(r22.u32 + 48);
	// lwz r3,44(r24)
	ctx.r3.u64 = PPC_LOAD_U32(r24.u32 + 44);
	// bl 0x831cb500
	sub_831CB500(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cf04c
	if (cr0.eq) goto loc_831CF04C;
loc_831CF214:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// mr r29,r31
	r29.u64 = r31.u64;
	// rlwinm r11,r11,13,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bge cr6,0x831cf284
	if (!cr6.lt) goto loc_831CF284;
	// addi r11,r31,11
	r11.s64 = r31.s64 + 11;
	// subf r30,r22,r24
	r30.s64 = r24.s64 - r22.s64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r11,r22
	r31.u64 = r11.u64 + r22.u64;
loc_831CF238:
	// lwzx r3,r30,r31
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cf25c
	if (cr0.eq) goto loc_831CF25C;
	// bl 0x831cb500
	sub_831CB500(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cf04c
	if (cr0.eq) goto loc_831CF04C;
	// b 0x831cf26c
	goto loc_831CF26C;
loc_831CF25C:
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r10,12(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x831cf04c
	if (!cr6.eq) goto loc_831CF04C;
loc_831CF26C:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// rlwinm r11,r11,13,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x831cf238
	if (cr6.lt) goto loc_831CF238;
loc_831CF284:
	// li r3,1
	ctx.r3.s64 = 1;
loc_831CF288:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_831CF020) {
	__imp__sub_831CF020(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF290) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// li r29,0
	r29.s64 = 0;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
loc_831CF2AC:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831cf2cc
	if (cr6.eq) goto loc_831CF2CC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r10,0,4,6
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831cf2c4
	if (!cr0.eq) goto loc_831CF2C4;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
loc_831CF2C4:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// b 0x831cf2ac
	goto loc_831CF2AC;
loc_831CF2CC:
	// rlwinm r11,r30,0,0,19
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFF000;
	// lis r10,-31980
	ctx.r10.s64 = -2095841280;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r5,r10,6976
	ctx.r5.s64 = ctx.r10.s64 + 6976;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r6,148(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x83140f90
	sub_83140F90(ctx, base);
	// lwz r6,0(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_831CF2F0:
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x831cf390
	if (cr6.eq) goto loc_831CF390;
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831cf380
	if (!cr0.eq) goto loc_831CF380;
	// lwz r5,12(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r9,1
	ctx.r9.s64 = 1;
loc_831CF314:
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x831cf378
	if (cr6.eq) goto loc_831CF378;
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831cf370
	if (!cr0.eq) goto loc_831CF370;
	// lwz r11,12(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x831cf36c
	if (!cr6.eq) goto loc_831CF36C;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// not r10,r11
	ctx.r10.u64 = ~r11.u64;
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// bne 0x831cf34c
	if (!cr0.eq) goto loc_831CF34C;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
loc_831CF34C:
	// rlwinm r11,r9,29,3,29
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFC;
	// li r3,1
	ctx.r3.s64 = 1;
	// clrlwi r4,r9,27
	ctx.r4.u64 = ctx.r9.u32 & 0x1F;
	// li r8,1
	ctx.r8.s64 = 1;
	// slw r4,r3,r4
	ctx.r4.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r3.u32 << (ctx.r4.u8 & 0x3F));
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// or r4,r4,r3
	ctx.r4.u64 = ctx.r4.u64 | ctx.r3.u64;
	// stwx r4,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r4.u32);
loc_831CF36C:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
loc_831CF370:
	// lwz r7,4(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// b 0x831cf314
	goto loc_831CF314;
loc_831CF378:
	// clrlwi. r11,r8,24
	r11.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cf388
	if (cr0.eq) goto loc_831CF388;
loc_831CF380:
	// lwz r6,4(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// b 0x831cf2f0
	goto loc_831CF2F0;
loc_831CF388:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831cf3bc
	goto loc_831CF3BC;
loc_831CF390:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831cf3b4
	if (cr6.eq) goto loc_831CF3B4;
	// addi r5,r29,-1
	ctx.r5.s64 = r29.s64 + -1;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x831ccca0
	sub_831CCCA0(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// bne 0x831cf3b8
	if (!cr0.eq) goto loc_831CF3B8;
loc_831CF3B4:
	// li r11,1
	r11.s64 = 1;
loc_831CF3B8:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
loc_831CF3BC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831CF290) {
	__imp__sub_831CF290(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF3C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831CF3CC:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831cf3f8
	if (!cr0.eq) goto loc_831CF3F8;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-40
	xer.ca = r11.u32 > 39;
	r11.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cf3f8
	if (cr0.eq) goto loc_831CF3F8;
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// bne cr6,0x831cf3cc
	if (!cr6.eq) goto loc_831CF3CC;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_831CF3F8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831CF3C8) {
	__imp__sub_831CF3C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF400) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,49
	ctx.r6.s64 = 49;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831cf450
	if (cr6.eq) goto loc_831CF450;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831CF450:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r10,r10,-36
	ctx.r10.s64 = ctx.r10.s64 + -36;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// ori r7,r10,1
	ctx.r7.u64 = ctx.r10.u64 | 1;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831CF400) {
	__imp__sub_831CF400(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF4A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,59
	ctx.r6.s64 = 59;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831cf4f0
	if (cr6.eq) goto loc_831CF4F0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831CF4F0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r10,r10,-36
	ctx.r10.s64 = ctx.r10.s64 + -36;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// ori r7,r10,1
	ctx.r7.u64 = ctx.r10.u64 | 1;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831CF4A0) {
	__imp__sub_831CF4A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF540) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,60
	ctx.r6.s64 = 60;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831cf590
	if (cr6.eq) goto loc_831CF590;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831CF590:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r10,r10,-36
	ctx.r10.s64 = ctx.r10.s64 + -36;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// ori r7,r10,1
	ctx.r7.u64 = ctx.r10.u64 | 1;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831CF540) {
	__imp__sub_831CF540(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF5E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,61
	ctx.r6.s64 = 61;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831cf630
	if (cr6.eq) goto loc_831CF630;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831CF630:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r10,r10,-36
	ctx.r10.s64 = ctx.r10.s64 + -36;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// ori r7,r10,1
	ctx.r7.u64 = ctx.r10.u64 | 1;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831CF5E0) {
	__imp__sub_831CF5E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF680) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,62
	ctx.r6.s64 = 62;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831cf6d0
	if (cr6.eq) goto loc_831CF6D0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831CF6D0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r10,r10,-36
	ctx.r10.s64 = ctx.r10.s64 + -36;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// ori r7,r10,1
	ctx.r7.u64 = ctx.r10.u64 | 1;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831CF680) {
	__imp__sub_831CF680(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF720) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,97
	ctx.r6.s64 = 97;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// beq cr6,0x831cf774
	if (cr6.eq) goto loc_831CF774;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,12(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831CF774:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// beq cr6,0x831cf7a0
	if (cr6.eq) goto loc_831CF7A0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,12(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831CF7A0:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r29)
	PPC_STORE_U32(r29.u32 + 48, ctx.r3.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831cf7e8
	if (cr6.eq) goto loc_831CF7E8;
	// rlwinm r11,r29,0,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r10,r30,-36
	ctx.r10.s64 = r30.s64 + -36;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// ori r8,r10,1
	ctx.r8.u64 = ctx.r10.u64 | 1;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
loc_831CF7E8:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831CF720) {
	__imp__sub_831CF720(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF7F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831cf868
	if (cr6.eq) goto loc_831CF868;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831CF868:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r9,44(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r10,r30,24
	ctx.r10.s64 = r30.s64 + 24;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r10,r10,-36
	ctx.r10.s64 = ctx.r10.s64 + -36;
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r9,r9,7,29,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0x7;
	// rlwimi r8,r9,14,15,17
	ctx.r8.u64 = (rotl32(ctx.r9.u32, 14) & 0x1C000) | (ctx.r8.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r9,r11,-36
	ctx.r9.s64 = r11.s64 + -36;
	// stw r8,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r8.u32);
	// ori r8,r10,1
	ctx.r8.u64 = ctx.r10.u64 | 1;
	// lwz r7,24(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r7,24(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r10.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831CF7F8) {
	__imp__sub_831CF7F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF8D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// std r6,168(r1)
	PPC_STORE_U64(ctx.r1.u32 + 168, ctx.r6.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// addi r4,r1,168
	ctx.r4.s64 = ctx.r1.s64 + 168;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r9,44(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r8,8(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r10,r10,-36
	ctx.r10.s64 = ctx.r10.s64 + -36;
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r9,r9,7,29,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0x7;
	// rlwimi r8,r9,14,15,17
	ctx.r8.u64 = (rotl32(ctx.r9.u32, 14) & 0x1C000) | (ctx.r8.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r9,r11,-36
	ctx.r9.s64 = r11.s64 + -36;
	// stw r8,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r8.u32);
	// ori r8,r10,1
	ctx.r8.u64 = ctx.r10.u64 | 1;
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831CF8D0) {
	__imp__sub_831CF8D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CF998) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// std r6,168(r1)
	PPC_STORE_U64(ctx.r1.u32 + 168, ctx.r6.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,7
	ctx.r6.s64 = 7;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// addi r4,r1,168
	ctx.r4.s64 = ctx.r1.s64 + 168;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r9,44(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r8,8(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r10,r10,-36
	ctx.r10.s64 = ctx.r10.s64 + -36;
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r9,r9,7,29,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0x7;
	// rlwimi r8,r9,14,15,17
	ctx.r8.u64 = (rotl32(ctx.r9.u32, 14) & 0x1C000) | (ctx.r8.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r9,r11,-36
	ctx.r9.s64 = r11.s64 + -36;
	// stw r8,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r8.u32);
	// ori r8,r10,1
	ctx.r8.u64 = ctx.r10.u64 | 1;
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831CF998) {
	__imp__sub_831CF998(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CFA60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// rlwinm r4,r31,30,30,31
	ctx.r4.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x3;
	// clrlwi r3,r31,30
	ctx.r3.u64 = r31.u32 & 0x3;
	// bl 0x83168560
	sub_83168560(ctx, base);
	// rlwinm r4,r31,28,30,31
	ctx.r4.u64 = rotl64(r31.u32 | (r31.u64 << 32), 28) & 0x3;
	// bl 0x83168560
	sub_83168560(ctx, base);
	// rlwinm r4,r31,26,30,31
	ctx.r4.u64 = rotl64(r31.u32 | (r31.u64 << 32), 26) & 0x3;
	// bl 0x83168560
	sub_83168560(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831CFA60) {
	__imp__sub_831CFA60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CFAA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// rlwinm. r10,r11,0,27,28
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831cfae0
	if (cr0.eq) goto loc_831CFAE0;
	// rlwinm. r10,r30,0,27,28
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831cfae0
	if (cr0.eq) goto loc_831CFAE0;
loc_831CFAD8:
	// li r11,0
	r11.s64 = 0;
	// b 0x831cfb08
	goto loc_831CFB08;
loc_831CFAE0:
	// rlwinm. r10,r11,0,30,30
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831cfaf0
	if (cr0.eq) goto loc_831CFAF0;
	// clrlwi. r10,r30,31
	ctx.r10.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831cfad8
	if (!cr0.eq) goto loc_831CFAD8;
loc_831CFAF0:
	// rlwinm. r11,r11,0,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cfb04
	if (cr0.eq) goto loc_831CFB04;
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// bne 0x831cfb08
	if (!cr0.eq) goto loc_831CFB08;
loc_831CFB04:
	// li r11,1
	r11.s64 = 1;
loc_831CFB08:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831cfb40
	if (!cr0.eq) goto loc_831CFB40;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831972a0
	sub_831972A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// rlwimi r10,r11,0,4,6
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
loc_831CFB40:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// rlwinm. r8,r10,0,29,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// clrlwi r11,r10,27
	r11.u64 = ctx.r10.u32 & 0x1F;
	// beq 0x831cfb60
	if (cr0.eq) goto loc_831CFB60;
	// rlwinm. r8,r30,0,30,30
	ctx.r8.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x831cfb60
	if (cr0.eq) goto loc_831CFB60;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_831CFB60:
	// and r8,r11,r30
	ctx.r8.u64 = r11.u64 & r30.u64;
	// rlwinm. r8,r8,0,29,29
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x831cfb74
	if (cr0.eq) goto loc_831CFB74;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// addi r9,r30,-4
	ctx.r9.s64 = r30.s64 + -4;
loc_831CFB74:
	// clrlwi. r8,r11,31
	ctx.r8.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x831cfb88
	if (cr0.eq) goto loc_831CFB88;
	// rlwinm. r8,r9,0,30,30
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x831cfb88
	if (cr0.eq) goto loc_831CFB88;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
loc_831CFB88:
	// rlwinm r7,r10,27,24,31
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0xFF;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r5,r10,7,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// or r6,r11,r9
	ctx.r6.u64 = r11.u64 | ctx.r9.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831CFAA8) {
	__imp__sub_831CFAA8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CFBA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// clrlwi. r11,r7,24
	r11.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r27,12(r29)
	r27.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// beq 0x831cfc48
	if (cr0.eq) goto loc_831CFC48;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x83125268
	sub_83125268(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r8,0(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r27,r30
	r27.u64 = r30.u64;
	// rlwimi r10,r8,0,7,3
	ctx.r10.u64 = (rotl32(ctx.r8.u32, 0) & 0xFFFFFFFFF1FFFFFF) | (ctx.r10.u64 & 0xE000000);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r8,0,0,30
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
loc_831CFC48:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lis r10,-28311
	ctx.r10.s64 = -1855389696;
	// lis r9,0
	ctx.r9.s64 = 0;
	// ori r8,r11,32
	ctx.r8.u64 = r11.u64 | 32;
	// li r11,1
	r11.s64 = 1;
	// stw r8,8(r27)
	PPC_STORE_U32(r27.u32 + 8, ctx.r8.u32);
	// ori r10,r10,5192
	ctx.r10.u64 = ctx.r10.u64 | 5192;
	// lwz r7,0(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r7,r7,7,29,31
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 7) & 0x7;
	// slw r11,r11,r7
	r11.u64 = ctx.r7.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r7.u8 & 0x3F));
	// ori r9,r9,36262
	ctx.r9.u64 = ctx.r9.u64 | 36262;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rldimi r10,r9,32,0
	ctx.r10.u64 = (rotl64(ctx.r9.u64, 32) & 0xFFFFFFFF00000000) | (ctx.r10.u64 & 0xFFFFFFFF);
	// clrldi r9,r11,32
	ctx.r9.u64 = r11.u64 & 0xFFFFFFFF;
	// li r5,228
	ctx.r5.s64 = 228;
	// srd r10,r10,r9
	ctx.r10.u64 = ctx.r9.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r9.u8 & 0x7F));
	// srd r10,r10,r9
	ctx.r10.u64 = ctx.r9.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r9.u8 & 0x7F));
	// srd r10,r10,r9
	ctx.r10.u64 = ctx.r9.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r9.u8 & 0x7F));
	// rotlwi r10,r10,0
	ctx.r10.u64 = rotl32(ctx.r10.u32, 0);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// rlwimi r11,r10,13,16,18
	r11.u64 = (rotl32(ctx.r10.u32, 13) & 0xE000) | (r11.u64 & 0xFFFFFFFFFFFF1FFF);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// rlwimi r8,r11,1,27,30
	ctx.r8.u64 = (rotl32(r11.u32, 1) & 0x1E) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFE1);
	// rlwimi r8,r11,1,15,17
	ctx.r8.u64 = (rotl32(r11.u32, 1) & 0x1C000) | (ctx.r8.u64 & 0xFFFFFFFFFFFE3FFF);
	// stw r8,8(r27)
	PPC_STORE_U32(r27.u32 + 8, ctx.r8.u32);
	// bl 0x831cb948
	sub_831CB948(ctx, base);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lis r11,-1
	r11.s64 = -65536;
	// rlwinm r10,r10,0,0,15
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x831cfd9c
	if (!cr6.eq) goto loc_831CFD9C;
	// rlwinm r10,r28,28,4,31
	ctx.r10.u64 = rotl64(r28.u32 | (r28.u64 << 32), 28) & 0xFFFFFFF;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,61
	cr6.compare<uint32_t>(ctx.r10.u32, 61, xer);
	// bne cr6,0x831cfce4
	if (!cr6.eq) goto loc_831CFCE4;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
	// b 0x831cfcec
	goto loc_831CFCEC;
loc_831CFCE4:
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bgt cr6,0x831cfcf0
	if (cr6.gt) goto loc_831CFCF0;
loc_831CFCEC:
	// li r11,1
	r11.s64 = 1;
loc_831CFCF0:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cfd9c
	if (cr0.eq) goto loc_831CFD9C;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r30,92(r4)
	r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 92);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831cfd8c
	if (!cr6.eq) goto loc_831CFD8C;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r30,0,0,30
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// ori r8,r9,1
	ctx.r8.u64 = ctx.r9.u64 | 1;
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r7.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,36(r7)
	PPC_STORE_U32(ctx.r7.u32 + 36, ctx.r9.u32);
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// lwz r28,564(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r5,92(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 92);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831cfd7c
	if (cr6.eq) goto loc_831CFD7C;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83123db0
	sub_83123DB0(ctx, base);
loc_831CFD7C:
	// stw r30,92(r28)
	PPC_STORE_U32(r28.u32 + 92, r30.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
loc_831CFD8C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831236f0
	sub_831236F0(ctx, base);
loc_831CFD9C:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831CFBA8) {
	__imp__sub_831CFBA8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CFDB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// stw r29,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, r29.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,125
	ctx.r4.s64 = 125;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r5,35
	ctx.r5.s64 = 35;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831cfe10
	if (cr0.eq) goto loc_831CFE10;
	// li r11,0
	r11.s64 = 0;
loc_831CFE10:
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,125
	ctx.r6.s64 = 125;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831cd678
	sub_831CD678(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831cfe58
	if (cr6.eq) goto loc_831CFE58;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// addi r9,r27,44
	ctx.r9.s64 = r27.s64 + 44;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_831CFE40:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stfs f0,0(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x831cfe40
	if (!cr0.eq) goto loc_831CFE40;
loc_831CFE58:
	// clrlwi. r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cfe6c
	if (cr0.eq) goto loc_831CFE6C;
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// rlwimi r10,r11,2,22,29
	ctx.r10.u64 = (rotl32(r11.u32, 2) & 0x3FC) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFC03);
	// stw r10,20(r27)
	PPC_STORE_U32(r27.u32 + 20, ctx.r10.u32);
loc_831CFE6C:
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r11,r10,31
	r11.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cfe7c
	if (cr0.eq) goto loc_831CFE7C;
	// li r10,0
	ctx.r10.s64 = 0;
loc_831CFE7C:
	// rlwinm r11,r27,0,0,30
	r11.u64 = rotl64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// addi r9,r10,16
	ctx.r9.s64 = ctx.r10.s64 + 16;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r9,r9,-36
	ctx.r9.s64 = ctx.r9.s64 + -36;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// ori r6,r9,1
	ctx.r6.u64 = ctx.r9.u64 | 1;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// rlwinm r8,r8,0,0,30
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, ctx.r9.u32);
	// beq cr6,0x831cffd8
	if (cr6.eq) goto loc_831CFFD8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r29,0
	r29.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// lfs f31,3084(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f31.f64 = double(temp.f32);
loc_831CFECC:
	// addi r11,r28,1
	r11.s64 = r28.s64 + 1;
	// addi r9,r1,204
	ctx.r9.s64 = ctx.r1.s64 + 204;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// rlwinm r10,r28,29,3,29
	ctx.r10.u64 = rotl64(r28.u32 | (r28.u64 << 32), 29) & 0x1FFFFFFC;
	// li r8,2
	ctx.r8.s64 = 2;
	// clrlwi r7,r28,27
	ctx.r7.u64 = r28.u32 & 0x1F;
	// slw r11,r8,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r8.u32 << (r11.u8 & 0x3F));
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// li r9,-1
	ctx.r9.s64 = -1;
	// and r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	// slw r10,r9,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r7.u8 & 0x3F));
	// and r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	// li r30,0
	r30.s64 = 0;
	// srw. r11,r11,r7
	r11.u64 = ctx.r7.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r7.u8 & 0x3F));
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831cff48
	if (cr0.eq) goto loc_831CFF48;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// lwzx r11,r29,r26
	r11.u64 = PPC_LOAD_U32(r29.u32 + r26.u32);
	// li r30,12
	r30.s64 = 12;
	// bne cr6,0x831cff34
	if (!cr6.eq) goto loc_831CFF34;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x831cff2c
	if (cr6.lt) goto loc_831CFF2C;
	// li r30,14
	r30.s64 = 14;
	// bgt cr6,0x831cffa8
	if (cr6.gt) goto loc_831CFFA8;
loc_831CFF2C:
	// ori r30,r30,1
	r30.u64 = r30.u64 | 1;
	// b 0x831cffa8
	goto loc_831CFFA8;
loc_831CFF34:
	// li r30,14
	r30.s64 = 14;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831cffa8
	if (!cr6.eq) goto loc_831CFFA8;
	// li r30,15
	r30.s64 = 15;
	// b 0x831cffa8
	goto loc_831CFFA8;
loc_831CFF48:
	// lfsx f1,r29,r26
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + r26.u32);
	ctx.f1.f64 = double(temp.f32);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// blt cr6,0x831cff58
	if (cr6.lt) goto loc_831CFF58;
	// li r30,2
	r30.s64 = 2;
loc_831CFF58:
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f31.f64);
	// bgt cr6,0x831cff64
	if (cr6.gt) goto loc_831CFF64;
	// ori r30,r30,1
	r30.u64 = r30.u64 | 1;
loc_831CFF64:
	// lfsx f0,r29,r26
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + r26.u32);
	f0.f64 = double(temp.f32);
	// fctiwz f13,f0
	ctx.f13.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
	// stfd f13,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f13.u64);
	// lwa r11,84(r1)
	r11.s64 = int32_t(PPC_LOAD_U32(ctx.r1.u32 + 84));
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x831cff90
	if (!cr6.eq) goto loc_831CFF90;
	// ori r30,r30,4
	r30.u64 = r30.u64 | 4;
loc_831CFF90:
	// bl 0x82ca3de0
	sub_82CA3DE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble 0x831cffa4
	if (!cr0.gt) goto loc_831CFFA4;
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// ble cr6,0x831cffa8
	if (!cr6.gt) goto loc_831CFFA8;
loc_831CFFA4:
	// ori r30,r30,8
	r30.u64 = r30.u64 | 8;
loc_831CFFA8:
	// lwz r10,12(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// slw r11,r30,r29
	r11.u64 = r29.u8 & 0x20 ? 0 : (r30.u32 << (r29.u8 & 0x3F));
	// and r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 & r11.u64;
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x831cffc8
	if (cr6.eq) goto loc_831CFFC8;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// sth r11,14(r27)
	PPC_STORE_U16(r27.u32 + 14, r11.u16);
loc_831CFFC8:
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// addi r28,r28,2
	r28.s64 = r28.s64 + 2;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// bne 0x831cfecc
	if (!cr0.eq) goto loc_831CFECC;
loc_831CFFD8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831CFDB8) {
	__imp__sub_831CFDB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831CFFE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// clrlwi. r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d0044
	if (cr0.eq) goto loc_831D0044;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mulli r31,r25,40
	r31.s64 = r25.s64 * 40;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d0028
	if (!cr6.eq) goto loc_831D0028;
	// bl 0x831387b8
	sub_831387B8(ctx, base);
loc_831D0028:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// rlwinm r10,r26,3,0,28
	ctx.r10.u64 = rotl64(r26.u32 | (r26.u64 << 32), 3) & 0xFFFFFFF8;
	// li r28,0
	r28.s64 = 0;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r26,r11,28,18,31
	r26.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x3FFF;
loc_831D0044:
	// lwz r29,4(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r11,0
	r11.s64 = 0;
	// clrlwi. r27,r29,31
	r27.u64 = r29.u32 & 0x1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// bne 0x831d0058
	if (!cr0.eq) goto loc_831D0058;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_831D0058:
	// lwz r31,20(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// clrlwi. r11,r31,31
	r11.u64 = r31.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d00cc
	if (!cr0.eq) goto loc_831D00CC;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x831d00cc
	if (cr0.eq) goto loc_831D00CC;
loc_831D006C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,15872
	cr6.compare<uint32_t>(r11.u32, 15872, xer);
	// bne cr6,0x831d00b4
	if (!cr6.eq) goto loc_831D00B4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-8
	r11.s64 = r31.s64 + -8;
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// clrlwi r10,r11,17
	ctx.r10.u64 = r11.u32 & 0x7FFF;
	// cmplw cr6,r10,r25
	cr6.compare<uint32_t>(ctx.r10.u32, r25.u32, xer);
	// bne cr6,0x831d00b4
	if (!cr6.eq) goto loc_831D00B4;
	// rlwinm r11,r11,17,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 17) & 0x3FFF;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// beq cr6,0x831d0114
	if (cr6.eq) goto loc_831D0114;
loc_831D00B4:
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r31,40(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// clrlwi. r11,r31,31
	r11.u64 = r31.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d00cc
	if (!cr0.eq) goto loc_831D00CC;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d006c
	if (!cr6.eq) goto loc_831D006C;
loc_831D00CC:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x831d00dc
	if (!cr6.eq) goto loc_831D00DC;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_831D00DC:
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// ori r9,r11,3
	ctx.r9.u64 = r11.u64 | 3;
	// li r8,0
	ctx.r8.s64 = 0;
	// bne cr6,0x831d00f4
	if (!cr6.eq) goto loc_831D00F4;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
loc_831D00F4:
	// li r7,124
	ctx.r7.s64 = 124;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831ce748
	sub_831CE748(ctx, base);
loc_831D010C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_831D0114:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x831d010c
	goto loc_831D010C;
}

PPC_WEAK_FUNC(sub_831CFFE8) {
	__imp__sub_831CFFE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D0120) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// stfs f2,244(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lwz r9,244(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// stfs f3,252(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lwz r11,252(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// stfs f4,260(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lwz r10,260(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// stfs f1,236(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lwz r10,236(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// li r8,7
	ctx.r8.s64 = 7;
	// stfs f1,96(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stfs f3,104(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// divwu r10,r11,r8
	ctx.r10.u32 = r11.u32 / ctx.r8.u32;
	// stfs f2,100(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// stfs f4,108(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// mulli r10,r10,7
	ctx.r10.s64 = ctx.r10.s64 * 7;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r11,r11,15
	r11.s64 = r11.s64 + 15;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// rlwinm r28,r11,2,0,29
	r28.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r28,r31
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + r31.u32);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831d024c
	if (cr6.eq) goto loc_831D024C;
	// li r26,1
	r26.s64 = 1;
loc_831D019C:
	// lwz r11,20(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// rlwinm. r11,r11,0,22,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3FC;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d0240
	if (!cr0.eq) goto loc_831D0240;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm r3,r11,18,29,31
	ctx.r3.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// cmplw cr6,r3,r29
	cr6.compare<uint32_t>(ctx.r3.u32, r29.u32, xer);
	// blt cr6,0x831d0240
	if (cr6.lt) goto loc_831D0240;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831d022c
	if (cr6.eq) goto loc_831D022C;
	// addi r6,r4,44
	ctx.r6.s64 = ctx.r4.s64 + 44;
loc_831D01D0:
	// lwz r5,0(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
loc_831D01E0:
	// lwz r25,0(r9)
	r25.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpw cr6,r5,r25
	cr6.compare<int32_t>(ctx.r5.s32, r25.s32, xer);
	// bne cr6,0x831d0208
	if (!cr6.eq) goto loc_831D0208;
	// li r25,3
	r25.s64 = 3;
	// slw r24,r26,r10
	r24.u64 = ctx.r10.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r10.u8 & 0x3F));
	// slw r25,r25,r11
	r25.u64 = r11.u8 & 0x20 ? 0 : (r25.u32 << (r11.u8 & 0x3F));
	// andc r30,r30,r25
	r30.u64 = r30.u64 & ~r25.u64;
	// slw r25,r8,r11
	r25.u64 = r11.u8 & 0x20 ? 0 : (ctx.r8.u32 << (r11.u8 & 0x3F));
	// or r7,r24,r7
	ctx.r7.u64 = r24.u64 | ctx.r7.u64;
	// or r30,r30,r25
	r30.u64 = r30.u64 | r25.u64;
loc_831D0208:
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// blt cr6,0x831d01e0
	if (cr6.lt) goto loc_831D01E0;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r8,r3
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r3.u32, xer);
	// blt cr6,0x831d01d0
	if (cr6.lt) goto loc_831D01D0;
loc_831D022C:
	// slw r11,r26,r29
	r11.u64 = r29.u8 & 0x20 ? 0 : (r26.u32 << (r29.u8 & 0x3F));
	// addi r10,r7,1
	ctx.r10.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// and. r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d02b0
	if (cr0.eq) goto loc_831D02B0;
loc_831D0240:
	// lwz r4,32(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x831d019c
	if (!cr6.eq) goto loc_831D019C;
loc_831D024C:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x831cfdb8
	sub_831CFDB8(ctx, base);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lwzx r9,r28,r31
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + r31.u32);
	// rlwinm r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// ld r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// stw r9,32(r10)
	PPC_STORE_U32(ctx.r10.u32 + 32, ctx.r9.u32);
	// stwx r10,r28,r31
	PPC_STORE_U32(r28.u32 + r31.u32, ctx.r10.u32);
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// std r8,0(r27)
	PPC_STORE_U64(r27.u32 + 0, ctx.r8.u64);
	// stw r11,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r11.u32);
loc_831D02A4:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	return;
loc_831D02B0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// clrlwi r8,r30,24
	ctx.r8.u64 = r30.u32 & 0xFF;
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r10,r29,20,9,11
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 20) & 0x700000;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// rlwinm r9,r9,0,15,15
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10000;
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r9,r9,2
	ctx.r9.u64 = ctx.r9.u64 | 2;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r8,r8,0,27,18
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// ld r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// rlwinm r8,r8,0,7,3
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// std r9,0(r27)
	PPC_STORE_U64(r27.u32 + 0, ctx.r9.u64);
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x831d02a4
	goto loc_831D02A4;
}

PPC_WEAK_FUNC(sub_831D0120) {
	__imp__sub_831D0120(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D0300) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// clrlwi r11,r24,24
	r11.u64 = r24.u32 & 0xFF;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d0344
	if (cr6.eq) goto loc_831D0344;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
loc_831D0330:
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// add r11,r8,r11
	r11.u64 = ctx.r8.u64 + r11.u64;
	// bne 0x831d0330
	if (!cr0.eq) goto loc_831D0330;
loc_831D0344:
	// li r10,7
	ctx.r10.s64 = 7;
	// divwu r10,r11,r10
	ctx.r10.u32 = r11.u32 / ctx.r10.u32;
	// mulli r10,r10,7
	ctx.r10.s64 = ctx.r10.s64 * 7;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,15
	r11.s64 = r11.s64 + 15;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r11,r30
	r28.u64 = r11.u64 + r30.u64;
	// mr r29,r28
	r29.u64 = r28.u64;
	// lwzx r31,r11,r30
	r31.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d044c
	if (cr6.eq) goto loc_831D044C;
	// clrlwi r25,r24,24
	r25.u64 = r24.u32 & 0xFF;
loc_831D0374:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r10,r11,0,18,24
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r10,14720
	cr6.compare<uint32_t>(ctx.r10.u32, 14720, xer);
	// bne cr6,0x831d03d8
	if (!cr6.eq) goto loc_831D03D8;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// rlwinm. r11,r11,0,19,19
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d03a8
	if (cr0.eq) goto loc_831D03A8;
	// lwz r11,540(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 540);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// stw r31,540(r30)
	PPC_STORE_U32(r30.u32 + 540, r31.u32);
	// b 0x831d0440
	goto loc_831D0440;
loc_831D03A8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,35
	ctx.r6.s64 = 35;
	// bl 0x831104e0
	sub_831104E0(ctx, base);
	// b 0x831d0440
	goto loc_831D0440;
loc_831D03D8:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r10,30,24,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0xFF;
	// cmplw cr6,r25,r10
	cr6.compare<uint32_t>(r25.u32, ctx.r10.u32, xer);
	// bne cr6,0x831d043c
	if (!cr6.eq) goto loc_831D043C;
	// rlwinm r11,r11,18,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// blt cr6,0x831d043c
	if (cr6.lt) goto loc_831D043C;
	// li r8,1
	ctx.r8.s64 = 1;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d0434
	if (cr6.eq) goto loc_831D0434;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// addi r10,r31,44
	ctx.r10.s64 = r31.s64 + 44;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_831D040C:
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// subf r7,r7,r6
	ctx.r7.s64 = ctx.r6.s64 - ctx.r7.s64;
	// cntlzw r7,r7
	ctx.r7.u64 = ctx.r7.u32 == 0 ? 32 : __builtin_clz(ctx.r7.u32);
	// rlwinm r7,r7,27,31,31
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x1;
	// and r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 & ctx.r8.u64;
	// bne 0x831d040c
	if (!cr0.eq) goto loc_831D040C;
loc_831D0434:
	// clrlwi. r11,r8,24
	r11.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d047c
	if (!cr0.eq) goto loc_831D047C;
loc_831D043C:
	// addi r29,r31,32
	r29.s64 = r31.s64 + 32;
loc_831D0440:
	// lwz r31,0(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d0374
	if (!cr6.eq) goto loc_831D0374;
loc_831D044C:
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831cfdb8
	sub_831CFDB8(ctx, base);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r3,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r3.u32);
	// lwz r11,88(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 88);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,88(r30)
	PPC_STORE_U32(r30.u32 + 88, r11.u32);
	// b 0x831d0480
	goto loc_831D0480;
loc_831D047C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_831D0480:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_831D0300) {
	__imp__sub_831D0300(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D0488) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// li r11,0
	r11.s64 = 0;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// beq cr6,0x831d04f4
	if (cr6.eq) goto loc_831D04F4;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
loc_831D04B8:
	// rlwinm r7,r11,29,3,29
	ctx.r7.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFC;
	// lwz r5,4(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// clrlwi r31,r11,27
	r31.u64 = r11.u32 & 0x1F;
	// stfs f0,0(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// slw r5,r5,r31
	ctx.r5.u64 = r31.u8 & 0x20 ? 0 : (ctx.r5.u32 << (r31.u8 & 0x3F));
	// lwzx r31,r7,r6
	r31.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// or r5,r5,r31
	ctx.r5.u64 = ctx.r5.u64 | r31.u64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// stwx r5,r7,r6
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, ctx.r5.u32);
	// bne 0x831d04b8
	if (!cr0.eq) goto loc_831D04B8;
loc_831D04F4:
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x831d0300
	sub_831D0300(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D0488) {
	__imp__sub_831D0488(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D0518) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// stw r6,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r6.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831d05d4
	if (cr6.eq) goto loc_831D05D4;
	// li r11,0
	r11.s64 = 0;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
loc_831D0548:
	// addi r8,r11,1
	ctx.r8.s64 = r11.s64 + 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// clrlwi r8,r8,27
	ctx.r8.u64 = ctx.r8.u32 & 0x1F;
	// rlwinm r31,r11,29,3,29
	r31.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r1,172
	r30.s64 = ctx.r1.s64 + 172;
	// slw r8,r5,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r31,r30
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + r30.u32);
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// clrlwi r31,r11,27
	r31.u64 = r11.u32 & 0x1F;
	// li r30,-1
	r30.s64 = -1;
	// and r8,r8,r5
	ctx.r8.u64 = ctx.r8.u64 & ctx.r5.u64;
	// slw r5,r30,r31
	ctx.r5.u64 = r31.u8 & 0x20 ? 0 : (r30.u32 << (r31.u8 & 0x3F));
	// and r8,r8,r5
	ctx.r8.u64 = ctx.r8.u64 & ctx.r5.u64;
	// srw r8,r8,r31
	ctx.r8.u64 = r31.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (r31.u8 & 0x3F));
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// blt cr6,0x831d05b0
	if (cr6.lt) goto loc_831D05B0;
	// beq cr6,0x831d05a0
	if (cr6.eq) goto loc_831D05A0;
	// cmplwi cr6,r8,3
	cr6.compare<uint32_t>(ctx.r8.u32, 3, xer);
	// bge cr6,0x831d05f4
	if (!cr6.lt) goto loc_831D05F4;
	// lfd f0,0(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// b 0x831d05a8
	goto loc_831D05A8;
loc_831D05A0:
	// lfd f0,0(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fctiwz f0,f0
	f0.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
loc_831D05A8:
	// stfiwx f0,0,r9
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U32(ctx.r9.u32, f0.u32);
	// b 0x831d05bc
	goto loc_831D05BC;
loc_831D05B0:
	// lfd f0,0(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,0(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
loc_831D05BC:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r7,r4
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r4.u32, xer);
	// blt cr6,0x831d0548
	if (cr6.lt) goto loc_831D0548;
loc_831D05D4:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// bl 0x831d0300
	sub_831D0300(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_831D05F4:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831D0518) {
	__imp__sub_831D0518(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D0600) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// rlwinm r10,r5,30,3,29
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 30) & 0x1FFFFFFC;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// rlwinm r6,r5,1,27,30
	ctx.r6.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 1) & 0x1E;
	// rlwinm r8,r11,30,24,31
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0xFF;
	// rlwinm r11,r5,1,0,30
	r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// slw r11,r7,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 << (r11.u8 & 0x3F));
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// li r7,-1
	ctx.r7.s64 = -1;
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// slw r8,r7,r6
	ctx.r8.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// and r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	// and r11,r11,r8
	r11.u64 = r11.u64 & ctx.r8.u64;
	// srw r11,r11,r6
	r11.u64 = ctx.r6.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r6.u8 & 0x3F));
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// bne cr6,0x831d0690
	if (!cr6.eq) goto loc_831D0690;
	// addi r11,r5,11
	r11.s64 = ctx.r5.s64 + 11;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f0,r11,r30
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + r30.u32);
	f0.f64 = double(temp.f32);
	// b 0x831d0700
	goto loc_831D0700;
loc_831D0690:
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83167de0
	sub_83167DE0(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x831ca960
	sub_831CA960(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831d06fc
	if (cr6.lt) goto loc_831D06FC;
	// beq cr6,0x831d06e4
	if (cr6.eq) goto loc_831D06E4;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x831d06d4
	if (cr6.lt) goto loc_831D06D4;
	// rlwinm r11,r30,0,0,19
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFF000;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D06D4:
	// fctidz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f1.f64);
	// stfd f0,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, f0.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// b 0x831d06f0
	goto loc_831D06F0;
loc_831D06E4:
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.u64 = uint64_t(int32_t(std::trunc(ctx.f1.f64)));
	// stfd f0,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, f0.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_831D06F0:
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// b 0x831d0700
	goto loc_831D0700;
loc_831D06FC:
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
loc_831D0700:
	// stfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831D0600) {
	__imp__sub_831D0600(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D0710) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -176, f29.u64);
	// stfd f30,-168(r1)
	PPC_STORE_U64(ctx.r1.u32 + -168, f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-448(r1)
	ea = -448 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r16,r4
	r16.u64 = ctx.r4.u64;
	// li r31,0
	r31.s64 = 0;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// li r5,128
	ctx.r5.s64 = 128;
	// std r31,0(r16)
	PPC_STORE_U64(r16.u32 + 0, r31.u64);
	// li r4,0
	ctx.r4.s64 = 0;
	// std r31,8(r16)
	PPC_STORE_U64(r16.u32 + 8, r31.u64);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// std r31,16(r16)
	PPC_STORE_U64(r16.u32 + 16, r31.u64);
	// mr r27,r31
	r27.u64 = r31.u64;
	// std r31,24(r16)
	PPC_STORE_U64(r16.u32 + 24, r31.u64);
	// stw r31,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r31.u32);
	// stw r21,468(r1)
	PPC_STORE_U32(ctx.r1.u32 + 468, r21.u32);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lwz r10,8(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r14,r21,44
	r14.s64 = r21.s64 + 44;
	// mr r20,r31
	r20.u64 = r31.u64;
	// mr r22,r31
	r22.u64 = r31.u64;
	// mr r18,r14
	r18.u64 = r14.u64;
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// rlwinm r15,r10,13,29,31
	r15.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 13) & 0x7;
	// li r28,1
	r28.s64 = 1;
	// li r26,2
	r26.s64 = 2;
	// li r30,-1
	r30.s64 = -1;
loc_831D0790:
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// rlwinm r11,r11,13,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// cmplw cr6,r20,r11
	cr6.compare<uint32_t>(r20.u32, r11.u32, xer);
	// bge cr6,0x831d08e4
	if (!cr6.lt) goto loc_831D08E4;
	// lwz r17,0(r18)
	r17.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// lwz r11,0(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 0);
	// rlwinm. r19,r11,7,29,31
	r19.u64 = rotl64(r11.u32 | (r11.u64 << 32), 7) & 0x7;
	cr0.compare<int32_t>(r19.s32, 0, xer);
	// beq 0x831d2510
	if (cr0.eq) goto loc_831D2510;
	// mr r23,r31
	r23.u64 = r31.u64;
	// cmplwi r19,0
	cr0.compare<uint32_t>(r19.u32, 0, xer);
	// beq 0x831d08d4
	if (cr0.eq) goto loc_831D08D4;
	// mr r25,r31
	r25.u64 = r31.u64;
loc_831D07C0:
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// addi r5,r1,132
	ctx.r5.s64 = ctx.r1.s64 + 132;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x831cc840
	sub_831CC840(ctx, base);
	// lwz r21,96(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm. r11,r21,0,27,28
	r11.u64 = rotl64(r21.u32 | (r21.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d2510
	if (!cr0.eq) goto loc_831D2510;
	// lwz r3,132(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,16000
	cr6.compare<uint32_t>(r11.u32, 16000, xer);
	// bne cr6,0x831d08c0
	if (!cr6.eq) goto loc_831D08C0;
	// rlwinm r9,r3,0,0,19
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFF000;
	// lwz r4,128(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// rlwinm r10,r22,29,3,29
	ctx.r10.u64 = rotl64(r22.u32 | (r22.u64 << 32), 29) & 0x1FFFFFFC;
	// slw r7,r28,r23
	ctx.r7.u64 = r23.u8 & 0x20 ? 0 : (r28.u32 << (r23.u8 & 0x3F));
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// clrlwi r8,r22,27
	ctx.r8.u64 = r22.u32 & 0x1F;
	// slw r8,r7,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r9,148(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 148);
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// stwx r8,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r8.u32);
	// lwz r9,40(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 40);
	// not r11,r9
	r11.u64 = ~ctx.r9.u64;
	// rlwinm. r11,r11,18,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d084c
	if (!cr0.eq) goto loc_831D084C;
	// mr r24,r31
	r24.u64 = r31.u64;
	// b 0x831d0860
	goto loc_831D0860;
loc_831D084C:
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r10,r4,1,0,30
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r11,r11,30,24,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0xFF;
	// srw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi r24,r11,30
	r24.u64 = r11.u32 & 0x3;
loc_831D0860:
	// rlwinm r11,r25,27,5,31
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r25,1
	ctx.r10.s64 = r25.s64 + 1;
	// add r9,r11,r20
	ctx.r9.u64 = r11.u64 + r20.u64;
	// clrlwi r8,r10,27
	ctx.r8.u64 = ctx.r10.u32 & 0x1F;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// slw r9,r26,r8
	ctx.r9.u64 = ctx.r8.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r8.u8 & 0x3F));
	// clrlwi r7,r25,27
	ctx.r7.u64 = r25.u32 & 0x1F;
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// slw r6,r30,r7
	ctx.r6.u64 = ctx.r7.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r7.u8 & 0x3F));
	// and r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 & ctx.r6.u64;
	// slw r7,r24,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (r24.u32 << (ctx.r7.u8 & 0x3F));
	// andc r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 & ~ctx.r9.u64;
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// bl 0x83167de0
	sub_83167DE0(ctx, base);
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x831ca960
	sub_831CA960(ctx, base);
	// add r11,r22,r23
	r11.u64 = r22.u64 + r23.u64;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// stfdx f1,r11,r10
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + ctx.r10.u32, ctx.f1.u64);
loc_831D08C0:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// lwz r21,468(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	// addi r25,r25,2
	r25.s64 = r25.s64 + 2;
	// cmplw cr6,r23,r19
	cr6.compare<uint32_t>(r23.u32, r19.u32, xer);
	// blt cr6,0x831d07c0
	if (cr6.lt) goto loc_831D07C0;
loc_831D08D4:
	// addi r20,r20,1
	r20.s64 = r20.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// addi r18,r18,4
	r18.s64 = r18.s64 + 4;
	// b 0x831d0790
	goto loc_831D0790;
loc_831D08E4:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8311c250
	sub_8311C250(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d1090
	if (cr0.eq) goto loc_831D1090;
	// lwz r10,0(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// clrlwi r24,r11,28
	r24.u64 = r11.u32 & 0xF;
	// rlwinm r23,r11,28,28,31
	r23.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0xF;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r22,r11,7,29,31
	r22.u64 = rotl64(r11.u32 | (r11.u64 << 32), 7) & 0x7;
	cr0.compare<int32_t>(r22.s32, 0, xer);
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfd f30,3248(r11)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(r11.u32 + 3248);
	// lfd f31,3376(r10)
	f31.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3376);
loc_831D0920:
	// lwz r10,8(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// and r11,r28,r24
	r11.u64 = r28.u64 & r24.u64;
	// and r9,r28,r23
	ctx.r9.u64 = r28.u64 & r23.u64;
	// rlwinm r10,r10,25,25,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x7F;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// cmplwi cr6,r10,27
	cr6.compare<uint32_t>(ctx.r10.u32, 27, xer);
	// bgt cr6,0x831d102c
	if (cr6.gt) goto loc_831D102C;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,16032
	r12.s64 = r12.s64 + 16032;
	// rlwinm r0,r10,1,0,30
	r0.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31971
	r12.s64 = -2095251456;
	// addi r12,r12,2404
	r12.s64 = r12.s64 + 2404;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_831D0964;
	case 1:
		goto loc_831D0A18;
	case 2:
		goto loc_831D0AE8;
	case 3:
		goto loc_831D0AAC;
	case 4:
		goto loc_831D0B18;
	case 5:
		goto loc_831D0B5C;
	case 6:
		goto loc_831D0C2C;
	case 7:
		goto loc_831D0CB8;
	case 8:
		goto loc_831D0CE8;
	case 9:
		goto loc_831D0D64;
	case 10:
		goto loc_831D0D8C;
	case 11:
		goto loc_831D0DA8;
	case 12:
		goto loc_831D0EC0;
	case 13:
		goto loc_831D1040;
	case 14:
		goto loc_831D1060;
	case 15:
		goto loc_831D102C;
	case 16:
		goto loc_831D102C;
	case 17:
		goto loc_831D102C;
	case 18:
		goto loc_831D102C;
	case 19:
		goto loc_831D102C;
	case 20:
		goto loc_831D102C;
	case 21:
		goto loc_831D102C;
	case 22:
		goto loc_831D102C;
	case 23:
		goto loc_831D102C;
	case 24:
		goto loc_831D0B18;
	case 25:
		goto loc_831D0B5C;
	case 26:
		goto loc_831D0C2C;
	case 27:
		goto loc_831D0CB8;
	default:
		__builtin_unreachable();
	}
loc_831D0964:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// rlwinm r25,r31,3,0,28
	r25.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r11,r1,176
	r11.s64 = ctx.r1.s64 + 176;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// lfdx f0,r25,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r25.u32 + r11.u32);
	// lfdx f13,r25,r10
	ctx.f13.u64 = PPC_LOAD_U64(r25.u32 + ctx.r10.u32);
	// fadd f1,f0,f13
	ctx.f1.f64 = f0.f64 + ctx.f13.f64;
loc_831D098C:
	// bl 0x83167d20
	sub_83167D20(ctx, base);
loc_831D0990:
	// stfdx f1,r25,r16
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r25.u32 + r16.u32, ctx.f1.u64);
loc_831D0994:
	// rlwinm r11,r31,1,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r8,r1,116
	ctx.r8.s64 = ctx.r1.s64 + 116;
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// rlwinm r9,r31,30,3,29
	ctx.r9.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// clrlwi r7,r11,27
	ctx.r7.u64 = r11.u32 & 0x1F;
	// rlwinm r6,r31,30,3,29
	ctx.r6.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// slw r11,r26,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r10.u8 & 0x3F));
	// slw r10,r26,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r7.u8 & 0x3F));
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwzx r8,r6,r5
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rlwinm r7,r31,1,27,30
	ctx.r7.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// rlwinm r6,r31,1,27,30
	ctx.r6.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// and r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	// and r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	// slw r9,r30,r7
	ctx.r9.u64 = ctx.r7.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r7.u8 & 0x3F));
	// slw r8,r30,r6
	ctx.r8.u64 = ctx.r6.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r6.u8 & 0x3F));
	// and r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	// and r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	// srw r4,r11,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r7.u8 & 0x3F));
	// srw r3,r10,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r6.u8 & 0x3F));
	// or r27,r28,r27
	r27.u64 = r28.u64 | r27.u64;
loc_831D09FC:
	// bl 0x83168560
	sub_83168560(ctx, base);
	// rlwinm r11,r31,30,3,29
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// rlwinm r10,r31,1,27,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// slw r10,r3,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r3.u32 << (ctx.r10.u8 & 0x3F));
	// lwzx r9,r11,r29
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// b 0x831d1028
	goto loc_831D1028;
loc_831D0A18:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d0a5c
	if (cr6.eq) goto loc_831D0A5C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d0a64
	if (cr6.eq) goto loc_831D0A64;
	// rlwinm r25,r31,3,0,28
	r25.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lfdx f13,r25,r11
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r25.u32 + r11.u32);
	// lfdx f0,r25,r10
	f0.u64 = PPC_LOAD_U64(r25.u32 + ctx.r10.u32);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x831d0a54
	if (cr6.eq) goto loc_831D0A54;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d0a54
	if (cr6.eq) goto loc_831D0A54;
	// fmul f1,f13,f0
	ctx.f1.f64 = ctx.f13.f64 * f0.f64;
	// b 0x831d098c
	goto loc_831D098C;
loc_831D0A54:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// b 0x831d0990
	goto loc_831D0990;
loc_831D0A5C:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
loc_831D0A64:
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// rlwinm r11,r11,29,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x4;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lfdx f1,r11,r10
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + ctx.r10.u32);
	// bl 0x82ca3de0
	sub_82CA3DE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble 0x831d102c
	if (!cr0.gt) goto loc_831D102C;
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bgt cr6,0x831d102c
	if (cr6.gt) goto loc_831D102C;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// lis r10,-64
	ctx.r10.s64 = -4194304;
	// or r27,r28,r27
	r27.u64 = r28.u64 | r27.u64;
	// stw r10,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r10.u32);
	// lfs f0,132(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	f0.f64 = double(temp.f32);
	// stfdx f0,r11,r16
	PPC_STORE_U64(r11.u32 + r16.u32, f0.u64);
	// b 0x831d102c
	goto loc_831D102C;
loc_831D0AAC:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lfdx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r10.u32);
	// lfdx f13,r11,r9
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r9.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x831d0ae0
	if (!cr6.lt) goto loc_831D0AE0;
loc_831D0AD8:
	// stfdx f0,r11,r16
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + r16.u32, f0.u64);
	// b 0x831d0994
	goto loc_831D0994;
loc_831D0AE0:
	// stfdx f13,r11,r16
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + r16.u32, ctx.f13.u64);
	// b 0x831d0994
	goto loc_831D0994;
loc_831D0AE8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lfdx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r10.u32);
	// lfdx f13,r11,r9
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r9.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x831d0ae0
	if (cr6.lt) goto loc_831D0AE0;
	// b 0x831d0ad8
	goto loc_831D0AD8;
loc_831D0B18:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lfdx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r10.u32);
	// lfdx f13,r11,r9
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r9.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x831d0b4c
	if (!cr6.eq) goto loc_831D0B4C;
loc_831D0B44:
	// stfdx f30,r11,r16
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + r16.u32, f30.u64);
	// b 0x831d0b50
	goto loc_831D0B50;
loc_831D0B4C:
	// stfdx f31,r11,r16
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + r16.u32, f31.u64);
loc_831D0B50:
	// addi r8,r1,116
	ctx.r8.s64 = ctx.r1.s64 + 116;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// b 0x831d0fb0
	goto loc_831D0FB0;
loc_831D0B5C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d0b8c
	if (cr6.eq) goto loc_831D0B8C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lfdx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r10.u32);
	// lfdx f13,r11,r9
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r9.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x831d0b4c
	if (!cr6.gt) goto loc_831D0B4C;
	// b 0x831d0b44
	goto loc_831D0B44;
loc_831D0B8C:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// rlwinm r25,r31,3,0,28
	r25.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r11,r1,176
	r11.s64 = ctx.r1.s64 + 176;
	// lfdx f0,r25,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r25.u32 + r11.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x831d102c
	if (!cr6.eq) goto loc_831D102C;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r3,0(r14)
	ctx.r3.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// addi r5,r1,136
	ctx.r5.s64 = ctx.r1.s64 + 136;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x831cc840
	sub_831CC840(ctx, base);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r11,r11,0,27,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1E;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x831d102c
	if (!cr6.eq) goto loc_831D102C;
	// lwz r3,136(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stfdx f31,r25,r16
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r25.u32 + r16.u32, f31.u64);
loc_831D0BE4:
	// rlwinm r11,r31,1,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r4,128(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r9,r1,116
	ctx.r9.s64 = ctx.r1.s64 + 116;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r10,r31,30,3,29
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// rlwinm r8,r31,1,27,30
	ctx.r8.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// slw r11,r26,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r26.u32 << (r11.u8 & 0x3F));
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// slw r9,r30,r8
	ctx.r9.u64 = ctx.r8.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r8.u8 & 0x3F));
	// and r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	// or r27,r28,r27
	r27.u64 = r28.u64 | r27.u64;
	// and r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	// srw r25,r11,r8
	r25.u64 = ctx.r8.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r8.u8 & 0x3F));
	// bl 0x831684d0
	sub_831684D0(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// b 0x831d1010
	goto loc_831D1010;
loc_831D0C2C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d0c5c
	if (cr6.eq) goto loc_831D0C5C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lfdx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r10.u32);
	// lfdx f13,r11,r9
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r9.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x831d0b4c
	if (cr6.lt) goto loc_831D0B4C;
	// b 0x831d0b44
	goto loc_831D0B44;
loc_831D0C5C:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// rlwinm r25,r31,3,0,28
	r25.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r11,r1,176
	r11.s64 = ctx.r1.s64 + 176;
	// lfdx f0,r25,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r25.u32 + r11.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x831d102c
	if (!cr6.eq) goto loc_831D102C;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r3,0(r14)
	ctx.r3.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x831cc840
	sub_831CC840(ctx, base);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r11,r11,0,27,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1E;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x831d102c
	if (!cr6.eq) goto loc_831D102C;
	// lwz r3,104(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// stfdx f30,r25,r16
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r25.u32 + r16.u32, f30.u64);
	// b 0x831d0be4
	goto loc_831D0BE4;
loc_831D0CB8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lfdx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r10.u32);
	// lfdx f13,r11,r9
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r9.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x831d0b4c
	if (cr6.eq) goto loc_831D0B4C;
	// b 0x831d0b44
	goto loc_831D0B44;
loc_831D0CE8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// rlwinm r25,r31,3,0,28
	r25.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// lfdx f29,r25,r11
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(r25.u32 + r11.u32);
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// bl 0x83167d70
	sub_83167D70(ctx, base);
	// bl 0x82ca3db0
	sub_82CA3DB0(ctx, base);
	// fadd f1,f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f1.f64 + f29.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
loc_831D0D10:
	// stfdx f1,r25,r16
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r25.u32 + r16.u32, ctx.f1.u64);
loc_831D0D14:
	// rlwinm r11,r31,1,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r10,r31,30,3,29
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// rlwinm r8,r31,1,27,30
	ctx.r8.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// slw r11,r26,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r26.u32 << (r11.u8 & 0x3F));
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// slw r9,r30,r8
	ctx.r9.u64 = ctx.r8.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r8.u8 & 0x3F));
	// and r10,r11,r10
	ctx.r10.u64 = r11.u64 & ctx.r10.u64;
	// rlwinm r11,r31,30,3,29
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// and r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 & ctx.r9.u64;
	// rlwinm r9,r31,1,27,30
	ctx.r9.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// srw r10,r10,r8
	ctx.r10.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r8.u8 & 0x3F));
	// lwzx r8,r11,r29
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// slw r10,r10,r9
	ctx.r10.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r9.u8 & 0x3F));
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// or r27,r28,r27
	r27.u64 = r28.u64 | r27.u64;
	// b 0x831d1028
	goto loc_831D1028;
loc_831D0D64:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// rlwinm r25,r31,3,0,28
	r25.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// lfdx f1,r25,r11
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r25.u32 + r11.u32);
	// bl 0x82ca8c58
	sub_82CA8C58(ctx, base);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// stfdx f0,r25,r16
	PPC_STORE_U64(r25.u32 + r16.u32, f0.u64);
	// b 0x831d0d14
	goto loc_831D0D14;
loc_831D0D8C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// rlwinm r25,r31,3,0,28
	r25.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// lfdx f1,r25,r11
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r25.u32 + r11.u32);
	// bl 0x83167d70
	sub_83167D70(ctx, base);
	// b 0x831d0d10
	goto loc_831D0D10;
loc_831D0DA8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// addi r11,r31,8
	r11.s64 = r31.s64 + 8;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// rlwinm r9,r11,29,3,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// srw r11,r10,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (r11.u8 & 0x3F));
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d102c
	if (cr0.eq) goto loc_831D102C;
	// rlwinm r25,r31,3,0,28
	r25.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// lfdx f13,r25,r11
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r25.u32 + r11.u32);
	// lfdx f0,r25,r10
	f0.u64 = PPC_LOAD_U64(r25.u32 + ctx.r10.u32);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x831d0e08
	if (cr6.eq) goto loc_831D0E08;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d0e08
	if (cr6.eq) goto loc_831D0E08;
	// fmul f1,f0,f13
	ctx.f1.f64 = f0.f64 * ctx.f13.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// b 0x831d0e0c
	goto loc_831D0E0C;
loc_831D0E08:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
loc_831D0E0C:
	// addi r11,r1,208
	r11.s64 = ctx.r1.s64 + 208;
	// lfdx f0,r25,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r25.u32 + r11.u32);
	// fadd f1,f0,f1
	ctx.f1.f64 = f0.f64 + ctx.f1.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// rlwinm r11,r31,1,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// stfdx f1,r25,r16
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r25.u32 + r16.u32, ctx.f1.u64);
	// rlwinm r10,r31,30,3,29
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// addi r7,r1,116
	ctx.r7.s64 = ctx.r1.s64 + 116;
	// addi r8,r11,1
	ctx.r8.s64 = r11.s64 + 1;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// rlwinm r6,r31,30,3,29
	ctx.r6.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// clrlwi r8,r8,27
	ctx.r8.u64 = ctx.r8.u32 & 0x1F;
	// slw r11,r26,r9
	r11.u64 = ctx.r9.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r9.u8 & 0x3F));
	// lwzx r9,r10,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// slw r10,r26,r8
	ctx.r10.u64 = ctx.r8.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r8,r6,r5
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// rlwinm r6,r31,30,3,29
	ctx.r6.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// addi r4,r11,-1
	ctx.r4.s64 = r11.s64 + -1;
	// rlwinm r3,r31,1,27,30
	ctx.r3.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rlwinm r25,r31,1,27,30
	r25.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// slw r11,r26,r7
	r11.u64 = ctx.r7.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r7.u8 & 0x3F));
	// lwzx r7,r6,r5
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// and r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	// and r9,r4,r9
	ctx.r9.u64 = ctx.r4.u64 & ctx.r9.u64;
	// slw r6,r30,r3
	ctx.r6.u64 = ctx.r3.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r3.u8 & 0x3F));
	// slw r8,r30,r25
	ctx.r8.u64 = r25.u8 & 0x20 ? 0 : (r30.u32 << (r25.u8 & 0x3F));
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// and r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 & ctx.r6.u64;
	// rlwinm r20,r31,1,27,30
	r20.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// and r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	// and r11,r11,r7
	r11.u64 = r11.u64 & ctx.r7.u64;
	// slw r8,r30,r20
	ctx.r8.u64 = r20.u8 & 0x20 ? 0 : (r30.u32 << (r20.u8 & 0x3F));
	// srw r4,r9,r3
	ctx.r4.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r3.u8 & 0x3F));
	// srw r3,r10,r25
	ctx.r3.u64 = r25.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (r25.u8 & 0x3F));
	// or r27,r28,r27
	r27.u64 = r28.u64 | r27.u64;
	// and r25,r11,r8
	r25.u64 = r11.u64 & ctx.r8.u64;
	// bl 0x83168560
	sub_83168560(ctx, base);
	// srw r4,r25,r20
	ctx.r4.u64 = r20.u8 & 0x20 ? 0 : (r25.u32 >> (r20.u8 & 0x3F));
	// b 0x831d09fc
	goto loc_831D09FC;
loc_831D0EC0:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d0f58
	if (cr6.eq) goto loc_831D0F58;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// lfdx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r10.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d107c
	if (cr6.eq) goto loc_831D107C;
loc_831D0EDC:
	// addi r10,r31,8
	ctx.r10.s64 = r31.s64 + 8;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// rlwinm r7,r10,29,3,29
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// srw r10,r8,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d0f58
	if (cr0.eq) goto loc_831D0F58;
	// addi r8,r1,208
	ctx.r8.s64 = ctx.r1.s64 + 208;
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
loc_831D0F04:
	// rlwinm r10,r31,1,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lfdx f0,r11,r8
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r8.u32);
	// stfdx f0,r11,r16
	PPC_STORE_U64(r11.u32 + r16.u32, f0.u64);
	// rlwinm r7,r31,30,3,29
	ctx.r7.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r8,r31,1,27,30
	ctx.r8.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// or r27,r28,r27
	r27.u64 = r28.u64 | r27.u64;
	// slw r11,r26,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r10.u8 & 0x3F));
	// lwzx r10,r7,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// slw r7,r30,r8
	ctx.r7.u64 = ctx.r8.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r8.u8 & 0x3F));
	// and r10,r11,r10
	ctx.r10.u64 = r11.u64 & ctx.r10.u64;
	// rlwinm r11,r31,30,3,29
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// and r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 & ctx.r7.u64;
	// rlwinm r7,r31,1,27,30
	ctx.r7.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// srw r10,r10,r8
	ctx.r10.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r8.u8 & 0x3F));
	// lwzx r8,r11,r29
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// slw r10,r10,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r7.u8 & 0x3F));
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// stwx r10,r11,r29
	PPC_STORE_U32(r11.u32 + r29.u32, ctx.r10.u32);
loc_831D0F58:
	// and. r11,r28,r27
	r11.u64 = r28.u64 & r27.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d102c
	if (!cr0.eq) goto loc_831D102C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d102c
	if (cr6.eq) goto loc_831D102C;
	// addi r11,r31,8
	r11.s64 = r31.s64 + 8;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// rlwinm r9,r11,29,3,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// srw r11,r10,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (r11.u8 & 0x3F));
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d102c
	if (cr0.eq) goto loc_831D102C;
	// rlwinm r10,r31,3,0,28
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r11,r1,176
	r11.s64 = ctx.r1.s64 + 176;
	// addi r9,r1,208
	ctx.r9.s64 = ctx.r1.s64 + 208;
	// lfdx f0,r10,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + r11.u32);
	// lfdx f13,r10,r9
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + ctx.r9.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x831d102c
	if (!cr6.eq) goto loc_831D102C;
	// stfdx f0,r10,r16
	PPC_STORE_U64(ctx.r10.u32 + r16.u32, f0.u64);
	// addi r8,r1,120
	ctx.r8.s64 = ctx.r1.s64 + 120;
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
loc_831D0FB0:
	// rlwinm r11,r31,1,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r9,r31,30,3,29
	ctx.r9.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// clrlwi r7,r11,27
	ctx.r7.u64 = r11.u32 & 0x1F;
	// rlwinm r6,r31,30,3,29
	ctx.r6.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// slw r11,r26,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r10.u8 & 0x3F));
	// slw r10,r26,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r7.u8 & 0x3F));
	// lwzx r8,r6,r5
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rlwinm r7,r31,1,27,30
	ctx.r7.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// rlwinm r6,r31,1,27,30
	ctx.r6.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// and r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	// and r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	// slw r9,r30,r7
	ctx.r9.u64 = ctx.r7.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r7.u8 & 0x3F));
	// slw r8,r30,r6
	ctx.r8.u64 = ctx.r6.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r6.u8 & 0x3F));
	// and r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	// and r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	// or r27,r28,r27
	r27.u64 = r28.u64 | r27.u64;
	// srw r4,r11,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r7.u8 & 0x3F));
	// srw r3,r10,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r6.u8 & 0x3F));
loc_831D1010:
	// bl 0x83168560
	sub_83168560(ctx, base);
	// rlwinm r11,r31,30,3,29
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// rlwinm r10,r31,1,27,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// slw r10,r3,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r3.u32 << (ctx.r10.u8 & 0x3F));
	// lwzx r9,r11,r29
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
loc_831D1028:
	// stwx r10,r11,r29
	PPC_STORE_U32(r11.u32 + r29.u32, ctx.r10.u32);
loc_831D102C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// rlwinm r28,r28,1,0,30
	r28.u64 = rotl64(r28.u32 | (r28.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r31,r22
	cr6.compare<uint32_t>(r31.u32, r22.u32, xer);
	// blt cr6,0x831d0920
	if (cr6.lt) goto loc_831D0920;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D1040:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d0f58
	if (cr6.eq) goto loc_831D0F58;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// lfdx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r10.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x831d107c
	if (!cr6.lt) goto loc_831D107C;
	// b 0x831d0edc
	goto loc_831D0EDC;
loc_831D1060:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d0f58
	if (cr6.eq) goto loc_831D0F58;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// lfdx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r10.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x831d0edc
	if (!cr6.gt) goto loc_831D0EDC;
loc_831D107C:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d0f58
	if (cr6.eq) goto loc_831D0F58;
	// addi r8,r1,176
	ctx.r8.s64 = ctx.r1.s64 + 176;
	// addi r6,r1,116
	ctx.r6.s64 = ctx.r1.s64 + 116;
	// b 0x831d0f04
	goto loc_831D0F04;
loc_831D1090:
	// lwz r25,8(r21)
	r25.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// rlwinm r11,r25,25,25,31
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831d10ac
	if (cr6.lt) goto loc_831D10AC;
	// cmplwi cr6,r11,31
	cr6.compare<uint32_t>(r11.u32, 31, xer);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// ble cr6,0x831d10b0
	if (!cr6.gt) goto loc_831D10B0;
loc_831D10AC:
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_831D10B0:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d14a0
	if (cr0.eq) goto loc_831D14A0;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// beq cr6,0x831d1398
	if (cr6.eq) goto loc_831D1398;
	// cmplwi cr6,r11,17
	cr6.compare<uint32_t>(r11.u32, 17, xer);
	// beq cr6,0x831d12dc
	if (cr6.eq) goto loc_831D12DC;
	// cmplwi cr6,r11,18
	cr6.compare<uint32_t>(r11.u32, 18, xer);
	// beq cr6,0x831d121c
	if (cr6.eq) goto loc_831D121C;
	// cmplwi cr6,r11,19
	cr6.compare<uint32_t>(r11.u32, 19, xer);
	// beq cr6,0x831d2510
	if (cr6.eq) goto loc_831D2510;
	// cmplwi cr6,r11,20
	cr6.compare<uint32_t>(r11.u32, 20, xer);
	// beq cr6,0x831d11ac
	if (cr6.eq) goto loc_831D11AC;
	// cmplwi cr6,r11,29
	cr6.compare<uint32_t>(r11.u32, 29, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm. r10,r11,25,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d1114
	if (cr0.eq) goto loc_831D1114;
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lfd f0,200(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// stfd f0,24(r16)
	PPC_STORE_U64(r16.u32 + 24, f0.u64);
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r10,r10,0,24,25
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xC0;
	// li r27,8
	r27.s64 = 8;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
loc_831D1114:
	// rlwinm. r10,r11,30,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d113c
	if (cr0.eq) goto loc_831D113C;
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lfd f0,160(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// stfd f0,16(r16)
	PPC_STORE_U64(r16.u32 + 16, f0.u64);
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r10,r10,0,26,27
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x30;
	// ori r27,r27,4
	r27.u64 = r27.u64 | 4;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
loc_831D113C:
	// rlwinm. r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d11a4
	if (cr0.eq) goto loc_831D11A4;
	// rlwinm. r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d11a4
	if (cr0.eq) goto loc_831D11A4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f12,152(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// lfd f0,3376(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// beq cr6,0x831d1178
	if (cr6.eq) goto loc_831D1178;
	// lfd f13,184(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// beq cr6,0x831d1178
	if (cr6.eq) goto loc_831D1178;
	// fmul f1,f12,f13
	ctx.f1.f64 = ctx.f12.f64 * ctx.f13.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
loc_831D1178:
	// stfd f0,8(r16)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r16.u32 + 8, f0.u64);
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// ori r27,r27,2
	r27.u64 = r27.u64 | 2;
	// rlwinm r4,r11,30,30,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x3;
	// rlwinm r3,r10,30,30,31
	ctx.r3.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3;
	// bl 0x83168560
	sub_83168560(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D11A4:
	// ori r27,r27,1
	r27.u64 = r27.u64 | 1;
	// b 0x831d18e4
	goto loc_831D18E4;
loc_831D11AC:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
	// cmplwi cr6,r11,15
	cr6.compare<uint32_t>(r11.u32, 15, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// lfd f0,160(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// lfd f13,168(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 168);
	// lfd f12,152(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x831d11d8
	if (cr6.lt) goto loc_831D11D8;
	// fmr f13,f0
	ctx.f13.f64 = f0.f64;
	// b 0x831d11dc
	goto loc_831D11DC;
loc_831D11D8:
	// fmr f0,f13
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f13.f64;
loc_831D11DC:
	// fcmpu cr6,f12,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f12.f64, f0.f64);
	// blt cr6,0x831d11ec
	if (cr6.lt) goto loc_831D11EC;
	// fmr f13,f12
	ctx.f13.f64 = ctx.f12.f64;
	// b 0x831d11f0
	goto loc_831D11F0;
loc_831D11EC:
	// fmr f12,f0
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = f0.f64;
loc_831D11F0:
	// lfd f0,144(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x831d1200
	if (cr6.lt) goto loc_831D1200;
	// fmr f13,f0
	ctx.f13.f64 = f0.f64;
loc_831D1200:
	// stfd f13,0(r16)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r16.u32 + 0, ctx.f13.u64);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r27,r28
	r27.u64 = r28.u64;
	// bl 0x831cfa60
	sub_831CFA60(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// or r11,r11,r3
	r11.u64 = r11.u64 | ctx.r3.u64;
	// b 0x831d2430
	goto loc_831D2430;
loc_831D121C:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// clrlwi r10,r11,28
	ctx.r10.u64 = r11.u32 & 0xF;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// rlwinm r10,r11,0,24,27
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xF0;
	// cmplwi cr6,r10,48
	cr6.compare<uint32_t>(ctx.r10.u32, 48, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// rlwinm r11,r11,0,20,23
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xF00;
	// cmplwi cr6,r11,256
	cr6.compare<uint32_t>(r11.u32, 256, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,152(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// lfd f31,3376(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x831d1270
	if (cr6.eq) goto loc_831D1270;
	// lfd f0,184(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d1270
	if (cr6.eq) goto loc_831D1270;
	// fmul f1,f13,f0
	ctx.f1.f64 = ctx.f13.f64 * f0.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// b 0x831d1274
	goto loc_831D1274;
loc_831D1270:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
loc_831D1274:
	// lfd f0,208(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 208);
	// fadd f1,f1,f0
	ctx.f1.f64 = ctx.f1.f64 + f0.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// lfd f13,144(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fmr f30,f1
	f30.f64 = ctx.f1.f64;
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x831d12a8
	if (cr6.eq) goto loc_831D12A8;
	// lfd f0,176(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d12a8
	if (cr6.eq) goto loc_831D12A8;
	// fmul f1,f13,f0
	ctx.f1.f64 = ctx.f13.f64 * f0.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// b 0x831d12ac
	goto loc_831D12AC;
loc_831D12A8:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
loc_831D12AC:
	// fadd f1,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f1.f64 + f30.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// stfd f1,0(r16)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r16.u32 + 0, ctx.f1.u64);
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// li r4,2
	ctx.r4.s64 = 2;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// mr r27,r28
	r27.u64 = r28.u64;
	// clrlwi r31,r11,30
	r31.u64 = r11.u32 & 0x3;
	// bl 0x83174720
	sub_83174720(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x83168560
	sub_83168560(ctx, base);
	// b 0x831d1494
	goto loc_831D1494;
loc_831D12DC:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// clrlwi r10,r11,28
	ctx.r10.u64 = r11.u32 & 0xF;
	// cmplwi cr6,r10,7
	cr6.compare<uint32_t>(ctx.r10.u32, 7, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// rlwinm r11,r11,0,24,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xF0;
	// cmplwi cr6,r11,112
	cr6.compare<uint32_t>(r11.u32, 112, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,160(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// lfd f31,3376(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x831d1328
	if (cr6.eq) goto loc_831D1328;
	// lfd f0,192(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d1328
	if (cr6.eq) goto loc_831D1328;
	// fmul f1,f13,f0
	ctx.f1.f64 = ctx.f13.f64 * f0.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// b 0x831d132c
	goto loc_831D132C;
loc_831D1328:
	// fmr f30,f31
	ctx.fpscr.disableFlushMode();
	f30.f64 = f31.f64;
loc_831D132C:
	// lfd f13,152(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x831d1350
	if (cr6.eq) goto loc_831D1350;
	// lfd f0,184(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d1350
	if (cr6.eq) goto loc_831D1350;
	// fmul f1,f13,f0
	ctx.f1.f64 = ctx.f13.f64 * f0.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// b 0x831d1354
	goto loc_831D1354;
loc_831D1350:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
loc_831D1354:
	// fadd f1,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f1.f64 + f30.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// lfd f0,144(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fmr f30,f1
	f30.f64 = ctx.f1.f64;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d1384
	if (cr6.eq) goto loc_831D1384;
	// lfd f13,176(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x831d1384
	if (cr6.eq) goto loc_831D1384;
	// fmul f1,f0,f13
	ctx.f1.f64 = f0.f64 * ctx.f13.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// b 0x831d1388
	goto loc_831D1388;
loc_831D1384:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
loc_831D1388:
	// fadd f1,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f1.f64 + f30.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x831d1484
	goto loc_831D1484;
loc_831D1398:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// clrlwi r10,r11,28
	ctx.r10.u64 = r11.u32 & 0xF;
	// cmplwi cr6,r10,15
	cr6.compare<uint32_t>(ctx.r10.u32, 15, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// rlwinm r11,r11,0,24,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xF0;
	// cmplwi cr6,r11,240
	cr6.compare<uint32_t>(r11.u32, 240, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,168(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 168);
	// lfd f31,3376(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x831d13e4
	if (cr6.eq) goto loc_831D13E4;
	// lfd f0,200(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d13e4
	if (cr6.eq) goto loc_831D13E4;
	// fmul f1,f13,f0
	ctx.f1.f64 = ctx.f13.f64 * f0.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// b 0x831d13e8
	goto loc_831D13E8;
loc_831D13E4:
	// fmr f30,f31
	ctx.fpscr.disableFlushMode();
	f30.f64 = f31.f64;
loc_831D13E8:
	// lfd f13,160(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x831d140c
	if (cr6.eq) goto loc_831D140C;
	// lfd f0,192(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d140c
	if (cr6.eq) goto loc_831D140C;
	// fmul f1,f13,f0
	ctx.f1.f64 = ctx.f13.f64 * f0.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// b 0x831d1410
	goto loc_831D1410;
loc_831D140C:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
loc_831D1410:
	// fadd f1,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f1.f64 + f30.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// lfd f0,152(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// fmr f30,f1
	f30.f64 = ctx.f1.f64;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d1440
	if (cr6.eq) goto loc_831D1440;
	// lfd f13,184(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x831d1440
	if (cr6.eq) goto loc_831D1440;
	// fmul f1,f0,f13
	ctx.f1.f64 = f0.f64 * ctx.f13.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// b 0x831d1444
	goto loc_831D1444;
loc_831D1440:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
loc_831D1444:
	// fadd f1,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f1.f64 + f30.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// lfd f0,144(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fmr f30,f1
	f30.f64 = ctx.f1.f64;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d1474
	if (cr6.eq) goto loc_831D1474;
	// lfd f13,176(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x831d1474
	if (cr6.eq) goto loc_831D1474;
	// fmul f1,f0,f13
	ctx.f1.f64 = f0.f64 * ctx.f13.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// b 0x831d1478
	goto loc_831D1478;
loc_831D1474:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
loc_831D1478:
	// fadd f1,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f1.f64 + f30.f64;
	// bl 0x83167d20
	sub_83167D20(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
loc_831D1484:
	// stfd f1,0(r16)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r16.u32 + 0, ctx.f1.u64);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// mr r27,r28
	r27.u64 = r28.u64;
	// bl 0x83174720
	sub_83174720(ctx, base);
loc_831D1494:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// or r11,r3,r11
	r11.u64 = ctx.r3.u64 | r11.u64;
	// b 0x831d2430
	goto loc_831D2430;
loc_831D14A0:
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// blt cr6,0x831d14b4
	if (cr6.lt) goto loc_831D14B4;
	// cmplwi cr6,r11,82
	cr6.compare<uint32_t>(r11.u32, 82, xer);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// ble cr6,0x831d14b8
	if (!cr6.gt) goto loc_831D14B8;
loc_831D14B4:
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_831D14B8:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d18f4
	if (cr0.eq) goto loc_831D18F4;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// clrlwi. r10,r9,31
	ctx.r10.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d1894
	if (cr0.eq) goto loc_831D1894;
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lfd f1,144(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// clrlwi r3,r10,30
	ctx.r3.u64 = ctx.r10.u32 & 0x3;
	// mr r27,r28
	r27.u64 = r28.u64;
	// or r11,r3,r11
	r11.u64 = ctx.r3.u64 | r11.u64;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// addi r11,r11,-37
	r11.s64 = r11.s64 + -37;
	// cmplwi cr6,r11,44
	cr6.compare<uint32_t>(r11.u32, 44, xer);
	// bgt cr6,0x831d2510
	if (cr6.gt) goto loc_831D2510;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,15936
	r12.s64 = r12.s64 + 15936;
	// rlwinm r0,r11,1,0,30
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31971
	r12.s64 = -2095251456;
	// addi r12,r12,5416
	r12.s64 = r12.s64 + 5416;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_831D1858;
	case 1:
		goto loc_831D2510;
	case 2:
		goto loc_831D1768;
	case 3:
		goto loc_831D17B8;
	case 4:
		goto loc_831D17CC;
	case 5:
		goto loc_831D17A8;
	case 6:
		goto loc_831D2510;
	case 7:
		goto loc_831D2510;
	case 8:
		goto loc_831D2510;
	case 9:
		goto loc_831D1528;
	case 10:
		goto loc_831D1554;
	case 11:
		goto loc_831D15A4;
	case 12:
		goto loc_831D15D4;
	case 13:
		goto loc_831D1614;
	case 14:
		goto loc_831D1664;
	case 15:
		goto loc_831D1698;
	case 16:
		goto loc_831D16B8;
	case 17:
		goto loc_831D16FC;
	case 18:
		goto loc_831D17FC;
	case 19:
		goto loc_831D2510;
	case 20:
		goto loc_831D2510;
	case 21:
		goto loc_831D2510;
	case 22:
		goto loc_831D174C;
	case 23:
		goto loc_831D1768;
	case 24:
		goto loc_831D177C;
	case 25:
		goto loc_831D1790;
	case 26:
		goto loc_831D2510;
	case 27:
		goto loc_831D2510;
	case 28:
		goto loc_831D2510;
	case 29:
		goto loc_831D2510;
	case 30:
		goto loc_831D1768;
	case 31:
		goto loc_831D17B8;
	case 32:
		goto loc_831D17CC;
	case 33:
		goto loc_831D17A8;
	case 34:
		goto loc_831D17E0;
	case 35:
		goto loc_831D171C;
	case 36:
		goto loc_831D2510;
	case 37:
		goto loc_831D2510;
	case 38:
		goto loc_831D2510;
	case 39:
		goto loc_831D2510;
	case 40:
		goto loc_831D2510;
	case 41:
		goto loc_831D2510;
	case 42:
		goto loc_831D2510;
	case 43:
		goto loc_831D173C;
	case 44:
		goto loc_831D1744;
	default:
		__builtin_unreachable();
	}
loc_831D1528:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,3376(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// beq cr6,0x831d175c
	if (cr6.eq) goto loc_831D175C;
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bge cr6,0x831d1548
	if (!cr6.lt) goto loc_831D1548;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D1548:
	// bl 0x831c9ed0
	sub_831C9ED0(ctx, base);
loc_831D154C:
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// b 0x831d188c
	goto loc_831D188C;
loc_831D1554:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,3248(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3248);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// beq cr6,0x831d17f4
	if (cr6.eq) goto loc_831D17F4;
	// lfd f0,3376(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bgt cr6,0x831d157c
	if (cr6.gt) goto loc_831D157C;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D157C:
	// bl 0x831c9f58
	sub_831C9F58(ctx, base);
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x82ca3de0
	sub_82CA3DE0(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// bne cr6,0x831d188c
	if (!cr6.eq) goto loc_831D188C;
loc_831D1590:
	// lis r11,-32240
	r11.s64 = -2112880640;
	// lfd f31,2400(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 2400);
loc_831D1598:
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
	// b 0x831d188c
	goto loc_831D188C;
loc_831D15A4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,3248(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3248);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// beq cr6,0x831d17f4
	if (cr6.eq) goto loc_831D17F4;
	// lfd f0,3376(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bgt cr6,0x831d15cc
	if (cr6.gt) goto loc_831D15CC;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D15CC:
	// bl 0x831c9f58
	sub_831C9F58(ctx, base);
	// b 0x831d154c
	goto loc_831D154C;
loc_831D15D4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,3376(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bne cr6,0x831d15ec
	if (!cr6.eq) goto loc_831D15EC;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D15EC:
	// bl 0x831ca220
	sub_831CA220(ctx, base);
loc_831D15F0:
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x82ca3de0
	sub_82CA3DE0(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// beq cr6,0x831d1590
	if (cr6.eq) goto loc_831D1590;
	// cmpwi cr6,r3,512
	cr6.compare<int32_t>(ctx.r3.s32, 512, xer);
	// bne cr6,0x831d188c
	if (!cr6.eq) goto loc_831D188C;
	// lis r11,-32240
	r11.s64 = -2112880640;
	// lfd f31,744(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 744);
	// b 0x831d1598
	goto loc_831D1598;
loc_831D1614:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f30,3376(r11)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f30
	cr6.compare(ctx.f1.f64, f30.f64);
	// bne cr6,0x831d162c
	if (!cr6.eq) goto loc_831D162C;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D162C:
	// bl 0x831ca220
	sub_831CA220(ctx, base);
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x82ca3de0
	sub_82CA3DE0(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// beq cr6,0x831d1650
	if (cr6.eq) goto loc_831D1650;
loc_831D1640:
	// cmpwi cr6,r3,512
	cr6.compare<int32_t>(ctx.r3.s32, 512, xer);
	// bne cr6,0x831d188c
	if (!cr6.eq) goto loc_831D188C;
	// fmr f31,f30
	ctx.fpscr.disableFlushMode();
	f31.f64 = f30.f64;
	// b 0x831d188c
	goto loc_831D188C;
loc_831D1650:
	// lis r10,-32768
	ctx.r10.s64 = -2147483648;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r10,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r10.u32);
	// lfs f31,104(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	f31.f64 = double(temp.f32);
	// b 0x831d1888
	goto loc_831D1888;
loc_831D1664:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,20(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lfd f0,3376(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3376);
	// bne 0x831d1680
	if (!cr0.eq) goto loc_831D1680;
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// beq cr6,0x831d188c
	if (cr6.eq) goto loc_831D188C;
loc_831D1680:
	// fcmpu cr6,f1,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f0.f64);
	// bne cr6,0x831d1690
	if (!cr6.eq) goto loc_831D1690;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D1690:
	// bl 0x831ca220
	sub_831CA220(ctx, base);
	// b 0x831d154c
	goto loc_831D154C;
loc_831D1698:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,3376(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bgt cr6,0x831d16b0
	if (cr6.gt) goto loc_831D16B0;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D16B0:
	// bl 0x831ca150
	sub_831CA150(ctx, base);
	// b 0x831d15f0
	goto loc_831D15F0;
loc_831D16B8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f30,3376(r11)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f30
	cr6.compare(ctx.f1.f64, f30.f64);
	// bgt cr6,0x831d16d0
	if (cr6.gt) goto loc_831D16D0;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D16D0:
	// bl 0x831ca150
	sub_831CA150(ctx, base);
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x82ca3de0
	sub_82CA3DE0(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// bne cr6,0x831d1640
	if (!cr6.eq) goto loc_831D1640;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lis r11,-32768
	r11.s64 = -2147483648;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// lfs f31,104(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	f31.f64 = double(temp.f32);
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
	// b 0x831d188c
	goto loc_831D188C;
loc_831D16FC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,3376(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bgt cr6,0x831d1714
	if (cr6.gt) goto loc_831D1714;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D1714:
	// bl 0x831ca150
	sub_831CA150(ctx, base);
	// b 0x831d154c
	goto loc_831D154C;
loc_831D171C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,3376(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bgt cr6,0x831d1734
	if (cr6.gt) goto loc_831D1734;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D1734:
	// bl 0x831ca0c0
	sub_831CA0C0(ctx, base);
	// b 0x831d154c
	goto loc_831D154C;
loc_831D173C:
	// bl 0x831c9ff0
	sub_831C9FF0(ctx, base);
	// b 0x831d154c
	goto loc_831D154C;
loc_831D1744:
	// bl 0x831ca058
	sub_831CA058(ctx, base);
	// b 0x831d154c
	goto loc_831D154C;
loc_831D174C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,3376(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
loc_831D1758:
	// beq cr6,0x831d188c
	if (cr6.eq) goto loc_831D188C;
loc_831D175C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f31,3248(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3248);
	// b 0x831d188c
	goto loc_831D188C;
loc_831D1768:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// bne cr6,0x831d188c
	if (!cr6.eq) goto loc_831D188C;
	// b 0x831d175c
	goto loc_831D175C;
loc_831D177C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// bgt cr6,0x831d188c
	if (cr6.gt) goto loc_831D188C;
	// b 0x831d175c
	goto loc_831D175C;
loc_831D1790:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfd f0,3376(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// lfd f13,3248(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3248);
loc_831D17A0:
	// fsel f31,f1,f0,f13
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64 >= 0.0 ? f0.f64 : ctx.f13.f64;
	// b 0x831d188c
	goto loc_831D188C;
loc_831D17A8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// b 0x831d1758
	goto loc_831D1758;
loc_831D17B8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// ble cr6,0x831d188c
	if (!cr6.gt) goto loc_831D188C;
	// b 0x831d175c
	goto loc_831D175C;
loc_831D17CC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfd f0,3248(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3248);
	// lfd f13,3376(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3376);
	// b 0x831d17a0
	goto loc_831D17A0;
loc_831D17E0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f31,3248(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3248);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// beq cr6,0x831d188c
	if (cr6.eq) goto loc_831D188C;
	// lis r11,-32256
	r11.s64 = -2113929216;
loc_831D17F4:
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// b 0x831d188c
	goto loc_831D188C;
loc_831D17FC:
	// rlwinm. r11,r9,31,31,31
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d188c
	if (cr0.eq) goto loc_831D188C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f30,3368(r11)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(r11.u32 + 3368);
	// fadd f1,f1,f30
	ctx.f1.f64 = ctx.f1.f64 + f30.f64;
	// bl 0x83167d70
	sub_83167D70(ctx, base);
	// lfd f0,152(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// fadd f1,f0,f30
	ctx.f1.f64 = f0.f64 + f30.f64;
	// bl 0x83167d70
	sub_83167D70(ctx, base);
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f31.f64);
	// ble cr6,0x831d1830
	if (!cr6.gt) goto loc_831D1830;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
loc_831D1830:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lfd f13,16168(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 16168);
	// fcmpu cr6,f31,f13
	cr6.compare(f31.f64, ctx.f13.f64);
	// blt cr6,0x831d1850
	if (cr6.lt) goto loc_831D1850;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lfd f0,-4872(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + -4872);
	// fcmpu cr6,f31,f0
	cr6.compare(f31.f64, f0.f64);
	// ble cr6,0x831d188c
	if (!cr6.gt) goto loc_831D188C;
loc_831D1850:
	// fmr f31,f13
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f13.f64;
	// b 0x831d188c
	goto loc_831D188C;
loc_831D1858:
	// rlwinm. r11,r9,31,31,31
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d188c
	if (cr0.eq) goto loc_831D188C;
	// lfd f0,152(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// blt cr6,0x831d1874
	if (cr6.lt) goto loc_831D1874;
	// stfd f0,0(r16)
	PPC_STORE_U64(r16.u32 + 0, f0.u64);
	// b 0x831d1878
	goto loc_831D1878;
loc_831D1874:
	// stfd f1,0(r16)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r16.u32 + 0, ctx.f1.u64);
loc_831D1878:
	// rlwinm r4,r10,30,30,31
	ctx.r4.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3;
	// bl 0x83168560
	sub_83168560(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// or r11,r3,r11
	r11.u64 = ctx.r3.u64 | r11.u64;
loc_831D1888:
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_831D188C:
	// stfd f31,0(r16)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r16.u32 + 0, f31.u64);
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D1894:
	// cmplwi cr6,r11,41
	cr6.compare<uint32_t>(r11.u32, 41, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// lwz r11,0(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,27,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1E;
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// lwz r3,12(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,15360
	cr6.compare<uint32_t>(r11.u32, 15360, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// rlwinm r11,r21,0,0,19
	r11.u64 = rotl64(r21.u32 | (r21.u64 << 32), 0) & 0xFFFFF000;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r4,148(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x83140ff8
	sub_83140FF8(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// mr r27,r28
	r27.u64 = r28.u64;
loc_831D18E4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,3248(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3248);
	// stfd f0,0(r16)
	PPC_STORE_U64(r16.u32 + 0, f0.u64);
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D18F4:
	// cmplwi cr6,r11,107
	cr6.compare<uint32_t>(r11.u32, 107, xer);
	// bgt cr6,0x831d23a8
	if (cr6.gt) goto loc_831D23A8;
	// beq cr6,0x831d2338
	if (cr6.eq) goto loc_831D2338;
	// cmplwi cr6,r11,96
	cr6.compare<uint32_t>(r11.u32, 96, xer);
	// beq cr6,0x831d2284
	if (cr6.eq) goto loc_831D2284;
	// cmplwi cr6,r11,97
	cr6.compare<uint32_t>(r11.u32, 97, xer);
	// beq cr6,0x831d2218
	if (cr6.eq) goto loc_831D2218;
	// cmplwi cr6,r11,100
	cr6.compare<uint32_t>(r11.u32, 100, xer);
	// beq cr6,0x831d21bc
	if (cr6.eq) goto loc_831D21BC;
	// cmplwi cr6,r11,103
	cr6.compare<uint32_t>(r11.u32, 103, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// rlwinm r24,r21,0,0,19
	r24.u64 = rotl64(r21.u32 | (r21.u64 << 32), 0) & 0xFFFFF000;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// lwz r4,148(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x83168800
	sub_83168800(ctx, base);
	// cmplwi cr6,r3,14
	cr6.compare<uint32_t>(ctx.r3.u32, 14, xer);
	// bgt cr6,0x831d25b8
	if (cr6.gt) goto loc_831D25B8;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,15904
	r12.s64 = r12.s64 + 15904;
	// rlwinm r0,r3,1,0,30
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31971
	r12.s64 = -2095251456;
	// addi r12,r12,6500
	r12.s64 = r12.s64 + 6500;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_831D1964;
	case 1:
		goto loc_831D1A04;
	case 2:
		goto loc_831D1AA4;
	case 3:
		goto loc_831D1B40;
	case 4:
		goto loc_831D1BDC;
	case 5:
		goto loc_831D1C78;
	case 6:
		goto loc_831D1D14;
	case 7:
		goto loc_831D1F24;
	case 8:
		goto loc_831D1E04;
	case 9:
		goto loc_831D1F24;
	case 10:
		goto loc_831D1F24;
	case 11:
		goto loc_831D1F24;
	case 12:
		goto loc_831D2064;
	case 13:
		goto loc_831D2064;
	case 14:
		goto loc_831D2064;
	default:
		__builtin_unreachable();
	}
loc_831D1964:
	// rlwinm. r11,r25,0,15,17
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0x1C000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r11,r16
	r11.u64 = r16.u64;
	// subf r7,r16,r9
	ctx.r7.s64 = ctx.r9.s64 - r16.s64;
loc_831D1980:
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// clrlwi r5,r8,27
	ctx.r5.u64 = ctx.r8.u32 & 0x1F;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// srw r9,r9,r5
	ctx.r9.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r5.u8 & 0x3F));
	// clrlwi. r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d19e4
	if (cr0.eq) goto loc_831D19E4;
	// lfdx f0,r7,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r7.u32 + r11.u32);
	// slw r5,r28,r8
	ctx.r5.u64 = ctx.r8.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r8.u8 & 0x3F));
	// fctiwz f0,f0
	f0.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// or r27,r5,r27
	r27.u64 = ctx.r5.u64 | r27.u64;
	// rlwinm r9,r10,29,3,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r6,r10,27
	ctx.r6.u64 = ctx.r10.u32 & 0x1F;
	// slw r6,r31,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r6.u8 & 0x3F));
	// lwa r4,92(r1)
	ctx.r4.s64 = int32_t(PPC_LOAD_U32(ctx.r1.u32 + 92));
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// std r5,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r5.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfd f0,0(r11)
	PPC_STORE_U64(r11.u32 + 0, f0.u64);
	// lwzx r5,r9,r29
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// or r6,r6,r5
	ctx.r6.u64 = ctx.r6.u64 | ctx.r5.u64;
	// stwx r6,r9,r29
	PPC_STORE_U32(ctx.r9.u32 + r29.u32, ctx.r6.u32);
loc_831D19E4:
	// lwz r9,8(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// rlwinm r9,r9,18,29,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 18) & 0x7;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x831d1980
	if (cr6.lt) goto loc_831D1980;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D1A04:
	// rlwinm. r11,r25,0,15,17
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0x1C000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r11,r16
	r11.u64 = r16.u64;
	// subf r7,r16,r9
	ctx.r7.s64 = ctx.r9.s64 - r16.s64;
loc_831D1A20:
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// clrlwi r5,r8,27
	ctx.r5.u64 = ctx.r8.u32 & 0x1F;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// srw r9,r9,r5
	ctx.r9.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r5.u8 & 0x3F));
	// clrlwi. r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d1a84
	if (cr0.eq) goto loc_831D1A84;
	// lfdx f0,r11,r7
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r7.u32);
	// slw r5,r28,r8
	ctx.r5.u64 = ctx.r8.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r8.u8 & 0x3F));
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// or r27,r5,r27
	r27.u64 = ctx.r5.u64 | r27.u64;
	// rlwinm r9,r10,29,3,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r6,r10,27
	ctx.r6.u64 = ctx.r10.u32 & 0x1F;
	// slw r6,r31,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r6.u8 & 0x3F));
	// lwz r4,92(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// std r5,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r5.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfd f0,0(r11)
	PPC_STORE_U64(r11.u32 + 0, f0.u64);
	// lwzx r5,r9,r29
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// or r6,r6,r5
	ctx.r6.u64 = ctx.r6.u64 | ctx.r5.u64;
	// stwx r6,r9,r29
	PPC_STORE_U32(ctx.r9.u32 + r29.u32, ctx.r6.u32);
loc_831D1A84:
	// lwz r9,8(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// rlwinm r9,r9,18,29,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 18) & 0x7;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x831d1a20
	if (cr6.lt) goto loc_831D1A20;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D1AA4:
	// rlwinm. r11,r25,0,15,17
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0x1C000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r11,r16
	r11.u64 = r16.u64;
	// subf r7,r16,r9
	ctx.r7.s64 = ctx.r9.s64 - r16.s64;
loc_831D1AC0:
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// clrlwi r5,r8,27
	ctx.r5.u64 = ctx.r8.u32 & 0x1F;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// srw r9,r9,r5
	ctx.r9.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r5.u8 & 0x3F));
	// clrlwi. r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d1b20
	if (cr0.eq) goto loc_831D1B20;
	// lfdx f0,r11,r7
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r7.u32);
	// slw r5,r28,r8
	ctx.r5.u64 = ctx.r8.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r8.u8 & 0x3F));
	// fctiwz f0,f0
	f0.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// or r27,r5,r27
	r27.u64 = ctx.r5.u64 | r27.u64;
	// rlwinm r9,r10,29,3,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r6,r10,27
	ctx.r6.u64 = ctx.r10.u32 & 0x1F;
	// slw r6,r26,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r6.u8 & 0x3F));
	// lwz r4,92(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// std r5,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r5.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// stfd f0,0(r11)
	PPC_STORE_U64(r11.u32 + 0, f0.u64);
	// lwzx r5,r9,r29
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// or r6,r6,r5
	ctx.r6.u64 = ctx.r6.u64 | ctx.r5.u64;
	// stwx r6,r9,r29
	PPC_STORE_U32(ctx.r9.u32 + r29.u32, ctx.r6.u32);
loc_831D1B20:
	// lwz r9,8(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// rlwinm r9,r9,18,29,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 18) & 0x7;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x831d1ac0
	if (cr6.lt) goto loc_831D1AC0;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D1B40:
	// rlwinm. r11,r25,0,15,17
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0x1C000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r11,r16
	r11.u64 = r16.u64;
	// subf r7,r16,r9
	ctx.r7.s64 = ctx.r9.s64 - r16.s64;
loc_831D1B5C:
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// clrlwi r5,r8,27
	ctx.r5.u64 = ctx.r8.u32 & 0x1F;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// srw r9,r9,r5
	ctx.r9.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r5.u8 & 0x3F));
	// clrlwi. r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d1bbc
	if (cr0.eq) goto loc_831D1BBC;
	// lfdx f0,r11,r7
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r7.u32);
	// slw r5,r28,r8
	ctx.r5.u64 = ctx.r8.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r8.u8 & 0x3F));
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// or r27,r5,r27
	r27.u64 = ctx.r5.u64 | r27.u64;
	// rlwinm r9,r10,29,3,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r6,r10,27
	ctx.r6.u64 = ctx.r10.u32 & 0x1F;
	// slw r6,r28,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r6.u8 & 0x3F));
	// lwa r4,92(r1)
	ctx.r4.s64 = int32_t(PPC_LOAD_U32(ctx.r1.u32 + 92));
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// std r5,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r5.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// stfd f0,0(r11)
	PPC_STORE_U64(r11.u32 + 0, f0.u64);
	// lwzx r5,r9,r29
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// or r6,r6,r5
	ctx.r6.u64 = ctx.r6.u64 | ctx.r5.u64;
	// stwx r6,r9,r29
	PPC_STORE_U32(ctx.r9.u32 + r29.u32, ctx.r6.u32);
loc_831D1BBC:
	// lwz r9,8(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// rlwinm r9,r9,18,29,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 18) & 0x7;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x831d1b5c
	if (cr6.lt) goto loc_831D1B5C;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D1BDC:
	// rlwinm. r11,r25,0,15,17
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0x1C000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r11,r16
	r11.u64 = r16.u64;
	// subf r7,r16,r9
	ctx.r7.s64 = ctx.r9.s64 - r16.s64;
loc_831D1BF8:
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// clrlwi r5,r8,27
	ctx.r5.u64 = ctx.r8.u32 & 0x1F;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// srw r9,r9,r5
	ctx.r9.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r5.u8 & 0x3F));
	// clrlwi. r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d1c58
	if (cr0.eq) goto loc_831D1C58;
	// lfdx f0,r11,r7
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r7.u32);
	// slw r5,r28,r8
	ctx.r5.u64 = ctx.r8.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r8.u8 & 0x3F));
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// or r27,r5,r27
	r27.u64 = ctx.r5.u64 | r27.u64;
	// rlwinm r9,r10,29,3,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r6,r10,27
	ctx.r6.u64 = ctx.r10.u32 & 0x1F;
	// slw r6,r28,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r6.u8 & 0x3F));
	// fctiwz f0,f0
	f0.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwa r5,92(r1)
	ctx.r5.s64 = int32_t(PPC_LOAD_U32(ctx.r1.u32 + 92));
	// std r5,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r5.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// stfd f0,0(r11)
	PPC_STORE_U64(r11.u32 + 0, f0.u64);
	// lwzx r5,r9,r29
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// or r6,r6,r5
	ctx.r6.u64 = ctx.r6.u64 | ctx.r5.u64;
	// stwx r6,r9,r29
	PPC_STORE_U32(ctx.r9.u32 + r29.u32, ctx.r6.u32);
loc_831D1C58:
	// lwz r9,8(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// rlwinm r9,r9,18,29,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 18) & 0x7;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x831d1bf8
	if (cr6.lt) goto loc_831D1BF8;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D1C78:
	// rlwinm. r11,r25,0,15,17
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0x1C000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r11,r16
	r11.u64 = r16.u64;
	// subf r7,r16,r9
	ctx.r7.s64 = ctx.r9.s64 - r16.s64;
loc_831D1C94:
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// clrlwi r5,r8,27
	ctx.r5.u64 = ctx.r8.u32 & 0x1F;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// srw r9,r9,r5
	ctx.r9.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r5.u8 & 0x3F));
	// clrlwi. r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d1cf4
	if (cr0.eq) goto loc_831D1CF4;
	// lfdx f0,r11,r7
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r7.u32);
	// slw r5,r28,r8
	ctx.r5.u64 = ctx.r8.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r8.u8 & 0x3F));
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// or r27,r5,r27
	r27.u64 = ctx.r5.u64 | r27.u64;
	// rlwinm r9,r10,29,3,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r6,r10,27
	ctx.r6.u64 = ctx.r10.u32 & 0x1F;
	// slw r6,r26,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r6.u8 & 0x3F));
	// fctiwz f0,f0
	f0.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r5,92(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// std r5,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r5.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// stfd f0,0(r11)
	PPC_STORE_U64(r11.u32 + 0, f0.u64);
	// lwzx r5,r9,r29
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// or r6,r6,r5
	ctx.r6.u64 = ctx.r6.u64 | ctx.r5.u64;
	// stwx r6,r9,r29
	PPC_STORE_U32(ctx.r9.u32 + r29.u32, ctx.r6.u32);
loc_831D1CF4:
	// lwz r9,8(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// rlwinm r9,r9,18,29,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 18) & 0x7;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x831d1c94
	if (cr6.lt) goto loc_831D1C94;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D1D14:
	// rlwinm. r11,r25,0,15,17
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0x1C000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// subf r5,r16,r11
	ctx.r5.s64 = r11.s64 - r16.s64;
loc_831D1D30:
	// rlwinm r11,r7,29,3,29
	r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// clrlwi r8,r7,27
	ctx.r8.u64 = ctx.r7.u32 & 0x1F;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// srw r11,r11,r8
	r11.u64 = ctx.r8.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r8.u8 & 0x3F));
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d1de4
	if (cr0.eq) goto loc_831D1DE4;
	// addi r10,r9,1
	ctx.r10.s64 = ctx.r9.s64 + 1;
	// lfdx f0,r6,r5
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r6.u32 + ctx.r5.u32);
	// rlwinm r11,r9,29,3,29
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// slw r8,r26,r10
	ctx.r8.u64 = ctx.r10.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r10.u8 & 0x3F));
	// lwzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// clrlwi r10,r9,27
	ctx.r10.u64 = ctx.r9.u32 & 0x1F;
	// and r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 & ctx.r4.u64;
	// slw r3,r30,r10
	ctx.r3.u64 = ctx.r10.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r10.u8 & 0x3F));
	// and r8,r8,r3
	ctx.r8.u64 = ctx.r8.u64 & ctx.r3.u64;
	// srw r8,r8,r10
	ctx.r8.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r10.u8 & 0x3F));
	// cmplwi cr6,r8,2
	cr6.compare<uint32_t>(ctx.r8.u32, 2, xer);
	// bne cr6,0x831d1da8
	if (!cr6.eq) goto loc_831D1DA8;
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r4,92(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// not r4,r4
	ctx.r4.u64 = ~ctx.r4.u64;
	// clrldi r4,r4,32
	ctx.r4.u64 = ctx.r4.u64 & 0xFFFFFFFF;
	// std r4,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r4.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// b 0x831d1dc4
	goto loc_831D1DC4;
loc_831D1DA8:
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	f0.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r4,92(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// not r4,r4
	ctx.r4.u64 = ~ctx.r4.u64;
	// extsw r4,r4
	ctx.r4.s64 = ctx.r4.s32;
	// std r4,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r4.u64);
	// lfd f0,136(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
loc_831D1DC4:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(f0.s64);
	// stfd f0,0(r6)
	PPC_STORE_U64(ctx.r6.u32 + 0, f0.u64);
	// slw r10,r8,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r10.u8 & 0x3F));
	// slw r8,r28,r7
	ctx.r8.u64 = ctx.r7.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r7.u8 & 0x3F));
	// lwzx r4,r11,r29
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// or r27,r8,r27
	r27.u64 = ctx.r8.u64 | r27.u64;
	// or r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 | ctx.r4.u64;
	// stwx r10,r11,r29
	PPC_STORE_U32(r11.u32 + r29.u32, ctx.r10.u32);
loc_831D1DE4:
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,8
	ctx.r6.s64 = ctx.r6.s64 + 8;
	// rlwinm r11,r11,18,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x831d1d30
	if (cr6.lt) goto loc_831D1D30;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D1E04:
	// rlwinm. r11,r25,0,15,17
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0x1C000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// subf r4,r11,r16
	ctx.r4.s64 = r16.s64 - r11.s64;
loc_831D1E20:
	// rlwinm r11,r5,29,3,29
	r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// clrlwi r7,r5,27
	ctx.r7.u64 = ctx.r5.u32 & 0x1F;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// srw r11,r11,r7
	r11.u64 = ctx.r7.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r7.u8 & 0x3F));
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d1f04
	if (cr0.eq) goto loc_831D1F04;
	// addi r11,r5,4
	r11.s64 = ctx.r5.s64 + 4;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// rlwinm r7,r11,29,3,29
	ctx.r7.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// srw r11,r10,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (r11.u8 & 0x3F));
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d1f04
	if (cr0.eq) goto loc_831D1F04;
	// lfd f0,32(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 32);
	// addi r11,r8,1
	r11.s64 = ctx.r8.s64 + 1;
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lfd f0,0(r9)
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// rlwinm r10,r8,29,3,29
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// slw r7,r26,r11
	ctx.r7.u64 = r11.u8 & 0x20 ? 0 : (r26.u32 << (r11.u8 & 0x3F));
	// lwzx r3,r10,r6
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
	// clrlwi r11,r8,27
	r11.u64 = ctx.r8.u32 & 0x1F;
	// lwz r6,92(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// and r7,r7,r3
	ctx.r7.u64 = ctx.r7.u64 & ctx.r3.u64;
	// slw r31,r30,r11
	r31.u64 = r11.u8 & 0x20 ? 0 : (r30.u32 << (r11.u8 & 0x3F));
	// and r7,r7,r31
	ctx.r7.u64 = ctx.r7.u64 & r31.u64;
	// srw r7,r7,r11
	ctx.r7.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 >> (r11.u8 & 0x3F));
	// cmplwi cr6,r7,2
	cr6.compare<uint32_t>(ctx.r7.u32, 2, xer);
	// bne cr6,0x831d1ec8
	if (!cr6.eq) goto loc_831D1EC8;
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r3,92(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// srw r6,r3,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r3.u32 >> (ctx.r6.u8 & 0x3F));
	// clrldi r6,r6,32
	ctx.r6.u64 = ctx.r6.u64 & 0xFFFFFFFF;
	// std r6,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r6.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// b 0x831d1ee4
	goto loc_831D1EE4;
loc_831D1EC8:
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	f0.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r3,92(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// sraw r6,r3,r6
	temp.u32 = ctx.r6.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	xer.ca = (ctx.r3.s32 < 0) & (((ctx.r3.s32 >> temp.u32) << temp.u32) != ctx.r3.s32);
	ctx.r6.s64 = ctx.r3.s32 >> temp.u32;
	// extsw r6,r6
	ctx.r6.s64 = ctx.r6.s32;
	// std r6,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r6.u64);
	// lfd f0,136(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
loc_831D1EE4:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(f0.s64);
	// stfdx f0,r4,r9
	PPC_STORE_U64(ctx.r4.u32 + ctx.r9.u32, f0.u64);
	// slw r11,r7,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 << (r11.u8 & 0x3F));
	// slw r7,r28,r5
	ctx.r7.u64 = ctx.r5.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r5.u8 & 0x3F));
	// lwzx r6,r10,r29
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + r29.u32);
	// or r27,r7,r27
	r27.u64 = ctx.r7.u64 | r27.u64;
	// or r11,r11,r6
	r11.u64 = r11.u64 | ctx.r6.u64;
	// stwx r11,r10,r29
	PPC_STORE_U32(ctx.r10.u32 + r29.u32, r11.u32);
loc_831D1F04:
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r9,r9,8
	ctx.r9.s64 = ctx.r9.s64 + 8;
	// rlwinm r11,r11,18,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x831d1e20
	if (cr6.lt) goto loc_831D1E20;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D1F24:
	// rlwinm. r11,r25,0,15,17
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0x1C000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// mr r11,r31
	r11.u64 = r31.u64;
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// subf r6,r10,r16
	ctx.r6.s64 = r16.s64 - ctx.r10.s64;
loc_831D1F40:
	// rlwinm r10,r7,29,3,29
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// clrlwi r5,r7,27
	ctx.r5.u64 = ctx.r7.u32 & 0x1F;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// srw r10,r10,r5
	ctx.r10.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r5.u8 & 0x3F));
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d2034
	if (cr0.eq) goto loc_831D2034;
	// addi r10,r7,4
	ctx.r10.s64 = ctx.r7.s64 + 4;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// rlwinm r5,r10,29,3,29
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// lwzx r8,r5,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r8.u32);
	// srw r10,r8,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d2034
	if (cr0.eq) goto loc_831D2034;
	// lfd f0,-32(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + -32);
	// cmpwi cr6,r3,7
	cr6.compare<int32_t>(ctx.r3.s32, 7, xer);
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f0,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, f0.u64);
	// lfd f0,0(r9)
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r10,108(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// beq cr6,0x831d1fd4
	if (cr6.eq) goto loc_831D1FD4;
	// cmpwi cr6,r3,9
	cr6.compare<int32_t>(ctx.r3.s32, 9, xer);
	// beq cr6,0x831d1fcc
	if (cr6.eq) goto loc_831D1FCC;
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// beq cr6,0x831d1fc4
	if (cr6.eq) goto loc_831D1FC4;
	// cmpwi cr6,r3,11
	cr6.compare<int32_t>(ctx.r3.s32, 11, xer);
	// bne cr6,0x831d2054
	if (!cr6.eq) goto loc_831D2054;
	// xor r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 ^ ctx.r10.u64;
	// b 0x831d1fd8
	goto loc_831D1FD8;
loc_831D1FC4:
	// or r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 | ctx.r10.u64;
	// b 0x831d1fd8
	goto loc_831D1FD8;
loc_831D1FCC:
	// and r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 & ctx.r10.u64;
	// b 0x831d1fd8
	goto loc_831D1FD8;
loc_831D1FD4:
	// slw r10,r10,r8
	ctx.r10.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
loc_831D1FD8:
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// addi r8,r11,1
	ctx.r8.s64 = r11.s64 + 1;
	// std r10,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r10.u64);
	// rlwinm r5,r11,29,3,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r10,r8,27
	ctx.r10.u64 = ctx.r8.u32 & 0x1F;
	// addi r8,r1,112
	ctx.r8.s64 = ctx.r1.s64 + 112;
	// slw r10,r26,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r10.u8 & 0x3F));
	// lwzx r8,r5,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r8.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// lfd f0,136(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// clrlwi r4,r11,27
	ctx.r4.u64 = r11.u32 & 0x1F;
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// stfdx f0,r6,r9
	PPC_STORE_U64(ctx.r6.u32 + ctx.r9.u32, f0.u64);
	// and r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	// slw r8,r30,r4
	ctx.r8.u64 = ctx.r4.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r4.u8 & 0x3F));
	// and r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	// slw r8,r28,r7
	ctx.r8.u64 = ctx.r7.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r7.u8 & 0x3F));
	// srw r10,r10,r4
	ctx.r10.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r4.u8 & 0x3F));
	// lwzx r31,r5,r29
	r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + r29.u32);
	// slw r10,r10,r4
	ctx.r10.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r4.u8 & 0x3F));
	// or r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 | r31.u64;
	// or r27,r8,r27
	r27.u64 = ctx.r8.u64 | r27.u64;
	// stwx r10,r5,r29
	PPC_STORE_U32(ctx.r5.u32 + r29.u32, ctx.r10.u32);
loc_831D2034:
	// lwz r10,8(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r9,r9,8
	ctx.r9.s64 = ctx.r9.s64 + 8;
	// rlwinm r10,r10,18,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// blt cr6,0x831d1f40
	if (cr6.lt) goto loc_831D1F40;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D2054:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// li r4,4800
	ctx.r4.s64 = 4800;
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D2064:
	// rlwinm. r11,r25,0,15,17
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0x1C000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// subf r6,r16,r11
	ctx.r6.s64 = r11.s64 - r16.s64;
loc_831D2080:
	// rlwinm r11,r5,29,3,29
	r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// clrlwi r8,r5,27
	ctx.r8.u64 = ctx.r5.u32 & 0x1F;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// srw r11,r11,r8
	r11.u64 = ctx.r8.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r8.u8 & 0x3F));
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d217c
	if (cr0.eq) goto loc_831D217C;
	// addi r9,r7,1
	ctx.r9.s64 = ctx.r7.s64 + 1;
	// rlwinm r11,r7,29,3,29
	r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// slw r8,r26,r9
	ctx.r8.u64 = ctx.r9.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r9.u8 & 0x3F));
	// lwzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// clrlwi r9,r7,27
	ctx.r9.u64 = ctx.r7.u32 & 0x1F;
	// and r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 & ctx.r4.u64;
	// slw r25,r30,r9
	r25.u64 = ctx.r9.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r9.u8 & 0x3F));
	// and r8,r8,r25
	ctx.r8.u64 = ctx.r8.u64 & r25.u64;
	// srw r8,r8,r9
	ctx.r8.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r9.u8 & 0x3F));
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// blt cr6,0x831d210c
	if (cr6.lt) goto loc_831D210C;
	// beq cr6,0x831d20f4
	if (cr6.eq) goto loc_831D20F4;
	// cmplwi cr6,r8,3
	cr6.compare<uint32_t>(ctx.r8.u32, 3, xer);
	// bge cr6,0x831d219c
	if (!cr6.lt) goto loc_831D219C;
	// lfdx f0,r6,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r6.u32 + ctx.r10.u32);
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// b 0x831d2104
	goto loc_831D2104;
loc_831D20F4:
	// lfdx f0,r6,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r6.u32 + ctx.r10.u32);
	// fctiwz f0,f0
	f0.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
loc_831D2104:
	// stw r8,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r8.u32);
	// b 0x831d211c
	goto loc_831D211C;
loc_831D210C:
	// lfdx f0,r6,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r6.u32 + ctx.r10.u32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lwz r8,96(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_831D211C:
	// cmpwi cr6,r3,12
	cr6.compare<int32_t>(ctx.r3.s32, 12, xer);
	// beq cr6,0x831d2164
	if (cr6.eq) goto loc_831D2164;
	// cmpwi cr6,r3,13
	cr6.compare<int32_t>(ctx.r3.s32, 13, xer);
	// beq cr6,0x831d2150
	if (cr6.eq) goto loc_831D2150;
	// cmpwi cr6,r3,14
	cr6.compare<int32_t>(ctx.r3.s32, 14, xer);
	// bne cr6,0x831d21ac
	if (!cr6.eq) goto loc_831D21AC;
	// clrldi r8,r8,32
	ctx.r8.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// slw r9,r26,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r9.u8 & 0x3F));
	// std r8,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r8.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
loc_831D2144:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(f0.s64);
	// stfd f0,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, f0.u64);
	// b 0x831d2170
	goto loc_831D2170;
loc_831D2150:
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// slw r9,r28,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r9.u8 & 0x3F));
	// std r8,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r8.u64);
	// lfd f0,136(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// b 0x831d2144
	goto loc_831D2144;
loc_831D2164:
	// lfs f0,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	f0.f64 = double(temp.f32);
	// slw r9,r31,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r9.u8 & 0x3F));
	// stfd f0,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, f0.u64);
loc_831D2170:
	// lwzx r8,r11,r29
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// stwx r9,r11,r29
	PPC_STORE_U32(r11.u32 + r29.u32, ctx.r9.u32);
loc_831D217C:
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// rlwinm r11,r11,18,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// addi r7,r7,2
	ctx.r7.s64 = ctx.r7.s64 + 2;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x831d2080
	if (cr6.lt) goto loc_831D2080;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D219C:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// li r4,4800
	ctx.r4.s64 = 4800;
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D21AC:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// li r4,4800
	ctx.r4.s64 = 4800;
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D21BC:
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// mr r11,r31
	r11.u64 = r31.u64;
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// lfd f0,3376(r8)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + 3376);
loc_831D21D0:
	// rlwinm r8,r9,29,3,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// clrlwi r6,r9,27
	ctx.r6.u64 = ctx.r9.u32 & 0x1F;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// srw r8,r8,r6
	ctx.r8.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r6.u8 & 0x3F));
	// clrlwi. r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x831d2200
	if (cr0.eq) goto loc_831D2200;
	// li r8,3
	ctx.r8.s64 = 3;
	// stfd f0,0(r10)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r10.u32 + 0, f0.u64);
	// stfd f0,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, f0.u64);
	// slw r8,r8,r11
	ctx.r8.u64 = r11.u8 & 0x20 ? 0 : (ctx.r8.u32 << (r11.u8 & 0x3F));
	// or r27,r8,r27
	r27.u64 = ctx.r8.u64 | r27.u64;
loc_831D2200:
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x831d21d0
	if (cr6.lt) goto loc_831D21D0;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D2218:
	// rlwinm r11,r21,0,0,19
	r11.u64 = rotl64(r21.u32 | (r21.u64 << 32), 0) & 0xFFFFF000;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r30,148(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 148);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831233b0
	sub_831233B0(ctx, base);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,18,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r11,r10,28,28,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xF;
	// bne 0x831d2254
	if (!cr0.eq) goto loc_831D2254;
	// rlwinm r10,r25,31,1,31
	ctx.r10.u64 = rotl64(r25.u32 | (r25.u64 << 32), 31) & 0x7FFFFFFF;
	// and r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
loc_831D2254:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d2278
	if (cr6.eq) goto loc_831D2278;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// subfic r10,r10,31
	xer.ca = ctx.r10.u32 <= 31;
	ctx.r10.s64 = 31 - ctx.r10.s64;
	// mr r27,r11
	r27.u64 = r11.u64;
	// rlwinm r11,r10,3,0,28
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// lfd f0,3248(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 3248);
	// stfdx f0,r11,r16
	PPC_STORE_U64(r11.u32 + r16.u32, f0.u64);
loc_831D2278:
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
	// b 0x831d22ec
	goto loc_831D22EC;
loc_831D2284:
	// rlwinm r11,r21,0,0,19
	r11.u64 = rotl64(r21.u32 | (r21.u64 << 32), 0) & 0xFFFFF000;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r30,148(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 148);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8310ff30
	sub_8310FF30(ctx, base);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,18,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r11,r10,20,28,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xF;
	// bne 0x831d22c0
	if (!cr0.eq) goto loc_831D22C0;
	// rlwinm r10,r25,31,1,31
	ctx.r10.u64 = rotl64(r25.u32 | (r25.u64 << 32), 31) & 0x7FFFFFFF;
	// and r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
loc_831D22C0:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d22e4
	if (cr6.eq) goto loc_831D22E4;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// subfic r10,r10,31
	xer.ca = ctx.r10.u32 <= 31;
	ctx.r10.s64 = 31 - ctx.r10.s64;
	// mr r27,r11
	r27.u64 = r11.u64;
	// rlwinm r11,r10,3,0,28
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// lfd f0,3248(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 3248);
	// stfdx f0,r11,r16
	PPC_STORE_U64(r11.u32 + r16.u32, f0.u64);
loc_831D22E4:
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// rlwinm r11,r11,24,28,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 24) & 0xF;
loc_831D22EC:
	// lwz r10,148(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 148);
	// lwz r10,40(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// not r10,r10
	ctx.r10.u64 = ~ctx.r10.u64;
	// rlwinm. r10,r10,18,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d2310
	if (!cr0.eq) goto loc_831D2310;
	// lwz r10,8(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// and r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
loc_831D2310:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d25b8
	if (cr6.eq) goto loc_831D25B8;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// subfic r10,r10,31
	xer.ca = ctx.r10.u32 <= 31;
	ctx.r10.s64 = 31 - ctx.r10.s64;
	// or r27,r11,r27
	r27.u64 = r11.u64 | r27.u64;
	// rlwinm r11,r10,3,0,28
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// lfd f0,3376(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 3376);
	// stfdx f0,r11,r16
	PPC_STORE_U64(r11.u32 + r16.u32, f0.u64);
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D2338:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm. r10,r11,28,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfd f2,176(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// lfd f0,3376(r10)
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3376);
	// fcmpu cr6,f2,f0
	cr6.compare(ctx.f2.f64, f0.f64);
	// bne cr6,0x831d237c
	if (!cr6.eq) goto loc_831D237C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// mr r27,r28
	r27.u64 = r28.u64;
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// lfd f0,3248(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3248);
	// stfd f0,0(r16)
	PPC_STORE_U64(r16.u32 + 0, f0.u64);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// b 0x831d2430
	goto loc_831D2430;
loc_831D237C:
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// lfd f1,144(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// blt cr6,0x831d25b8
	if (cr6.lt) goto loc_831D25B8;
	// bl 0x821fe378
	sub_821FE378(ctx, base);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stfd f1,0(r16)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r16.u32 + 0, ctx.f1.u64);
	// mr r27,r28
	r27.u64 = r28.u64;
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// b 0x831d2428
	goto loc_831D2428;
loc_831D23A8:
	// cmplwi cr6,r11,110
	cr6.compare<uint32_t>(r11.u32, 110, xer);
	// beq cr6,0x831d2530
	if (cr6.eq) goto loc_831D2530;
	// cmplwi cr6,r11,112
	cr6.compare<uint32_t>(r11.u32, 112, xer);
	// beq cr6,0x831d2438
	if (cr6.eq) goto loc_831D2438;
	// cmplwi cr6,r11,125
	cr6.compare<uint32_t>(r11.u32, 125, xer);
	// bne cr6,0x831d25b8
	if (!cr6.eq) goto loc_831D25B8;
	// rlwinm. r11,r25,0,15,17
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0x1C000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d23f4
	if (cr0.eq) goto loc_831D23F4;
	// mr r30,r16
	r30.u64 = r16.u64;
loc_831D23CC:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83167de0
	sub_83167DE0(ctx, base);
	// stfd f1,0(r30)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r30.u32 + 0, ctx.f1.u64);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// rlwinm r11,r11,18,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x831d23cc
	if (cr6.lt) goto loc_831D23CC;
loc_831D23F4:
	// rlwinm r10,r21,0,0,19
	ctx.r10.u64 = rotl64(r21.u32 | (r21.u64 << 32), 0) & 0xFFFFF000;
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// rlwinm r11,r11,18,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// slw r11,r28,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r28.u32 << (r11.u8 & 0x3F));
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r27,r11,-1
	r27.s64 = r11.s64 + -1;
	// lwz r11,148(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 148);
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,18,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d25b8
	if (cr0.eq) goto loc_831D25B8;
	// lwz r11,20(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// rlwinm r11,r11,30,24,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0xFF;
loc_831D2428:
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
loc_831D2430:
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D2438:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r27,0(r21)
	r27.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// mr r24,r31
	r24.u64 = r31.u64;
	// mr r25,r31
	r25.u64 = r31.u64;
	// lfd f31,3376(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 3376);
loc_831D244C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d2508
	if (cr6.eq) goto loc_831D2508;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// addi r5,r1,132
	ctx.r5.s64 = ctx.r1.s64 + 132;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831cc840
	sub_831CC840(ctx, base);
	// lwz r30,132(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,16000
	cr6.compare<uint32_t>(r11.u32, 16000, xer);
	// bne cr6,0x831d2510
	if (!cr6.eq) goto loc_831D2510;
	// lwz r26,128(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x831cab88
	sub_831CAB88(ctx, base);
	// rlwinm r11,r30,0,0,19
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFF000;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,148(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,18,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d24c4
	if (!cr0.eq) goto loc_831D24C4;
	// mr r11,r31
	r11.u64 = r31.u64;
	// b 0x831d24d8
	goto loc_831D24D8;
loc_831D24C4:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r10,r26,1,0,30
	ctx.r10.u64 = rotl64(r26.u32 | (r26.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r11,r11,30,24,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0xFF;
	// srw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
loc_831D24D8:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x831d24f0
	if (!cr6.eq) goto loc_831D24F0;
	// mr r24,r27
	r24.u64 = r27.u64;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// mr r25,r11
	r25.u64 = r11.u64;
	// b 0x831d2500
	goto loc_831D2500;
loc_831D24F0:
	// fcmpu cr6,f31,f1
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, ctx.f1.f64);
	// bne cr6,0x831d2510
	if (!cr6.eq) goto loc_831D2510;
	// cmpw cr6,r25,r11
	cr6.compare<int32_t>(r25.s32, r11.s32, xer);
	// bne cr6,0x831d2510
	if (!cr6.eq) goto loc_831D2510;
loc_831D2500:
	// lwz r27,4(r27)
	r27.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// b 0x831d244c
	goto loc_831D244C;
loc_831D2508:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x831d2518
	if (!cr6.eq) goto loc_831D2518;
loc_831D2510:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d25bc
	goto loc_831D25BC;
loc_831D2518:
	// stfd f31,0(r16)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r16.u32 + 0, f31.u64);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// or r11,r25,r11
	r11.u64 = r25.u64 | r11.u64;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// mr r27,r28
	r27.u64 = r28.u64;
	// b 0x831d25b8
	goto loc_831D25B8;
loc_831D2530:
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x831d25b8
	if (cr6.eq) goto loc_831D25B8;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r11,r31
	r11.u64 = r31.u64;
	// mr r7,r16
	ctx.r7.u64 = r16.u64;
	// addi r8,r1,144
	ctx.r8.s64 = ctx.r1.s64 + 144;
loc_831D254C:
	// rlwinm r9,r10,29,3,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// clrlwi r4,r10,27
	ctx.r4.u64 = ctx.r10.u32 & 0x1F;
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// srw r9,r9,r4
	ctx.r9.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r4.u8 & 0x3F));
	// clrlwi. r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d259c
	if (cr0.eq) goto loc_831D259C;
	// lfd f0,0(r8)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + 0);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// stfd f0,0(r7)
	PPC_STORE_U64(ctx.r7.u32 + 0, f0.u64);
	// rlwinm r9,r11,29,3,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFC;
	// slw r3,r28,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r5,r10,r5
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// clrlwi r4,r11,27
	ctx.r4.u64 = r11.u32 & 0x1F;
	// or r27,r3,r27
	r27.u64 = ctx.r3.u64 | r27.u64;
	// clrlwi r5,r5,30
	ctx.r5.u64 = ctx.r5.u32 & 0x3;
	// lwzx r3,r9,r29
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// slw r5,r5,r4
	ctx.r5.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r4.u8 & 0x3F));
	// or r5,r5,r3
	ctx.r5.u64 = ctx.r5.u64 | ctx.r3.u64;
	// stwx r5,r9,r29
	PPC_STORE_U32(ctx.r9.u32 + r29.u32, ctx.r5.u32);
loc_831D259C:
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r8,r8,32
	ctx.r8.s64 = ctx.r8.s64 + 32;
	// addi r7,r7,8
	ctx.r7.s64 = ctx.r7.s64 + 8;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r6,r15
	cr6.compare<uint32_t>(ctx.r6.u32, r15.u32, xer);
	// blt cr6,0x831d254c
	if (cr6.lt) goto loc_831D254C;
loc_831D25B8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_831D25BC:
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// lfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -176);
	// lfd f30,-168(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82ca2c00
	return;
}

PPC_WEAK_FUNC(sub_831D0710) {
	__imp__sub_831D0710(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D25D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r29,0
	r29.s64 = 0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,59
	cr6.compare<uint32_t>(r11.u32, 59, xer);
	// beq cr6,0x831d2684
	if (cr6.eq) goto loc_831D2684;
	// cmplwi cr6,r11,60
	cr6.compare<uint32_t>(r11.u32, 60, xer);
	// beq cr6,0x831d2670
	if (cr6.eq) goto loc_831D2670;
	// cmplwi cr6,r11,61
	cr6.compare<uint32_t>(r11.u32, 61, xer);
	// beq cr6,0x831d2640
	if (cr6.eq) goto loc_831D2640;
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// bne cr6,0x831d2698
	if (!cr6.eq) goto loc_831D2698;
	// lwz r4,44(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// bl 0x831cf5e0
	sub_831CF5E0(ctx, base);
	// b 0x831d2694
	goto loc_831D2694;
loc_831D2640:
	// lwz r4,44(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// bl 0x831cf680
	sub_831CF680(ctx, base);
	// b 0x831d2694
	goto loc_831D2694;
loc_831D2670:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,44(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// bl 0x831cf4a0
	sub_831CF4A0(ctx, base);
	// b 0x831d2694
	goto loc_831D2694;
loc_831D2684:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,44(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// bl 0x831cf540
	sub_831CF540(ctx, base);
loc_831D2694:
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
loc_831D2698:
	// lwz r31,0(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_831D269C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d26c4
	if (cr6.eq) goto loc_831D26C4;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d26bc
	if (!cr0.eq) goto loc_831D26BC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
loc_831D26BC:
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// b 0x831d269c
	goto loc_831D269C;
loc_831D26C4:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831D25D0) {
	__imp__sub_831D25D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D26D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm. r11,r11,15,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2714
	if (cr0.eq) goto loc_831D2714;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// oris r11,r11,4096
	r11.u64 = r11.u64 | 268435456;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwimi r10,r11,9,4,4
	ctx.r10.u64 = (rotl32(r11.u32, 9) & 0x8000000) | (ctx.r10.u64 & 0xFFFFFFFFF7FFFFFF);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// b 0x831d2754
	goto loc_831D2754;
loc_831D2714:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8310fa10
	sub_8310FA10(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d2754
	if (!cr0.eq) goto loc_831D2754;
	// lwz r11,28(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 28);
	// lwz r11,76(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 76);
	// rlwinm. r11,r11,10,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 10) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2754
	if (cr0.eq) goto loc_831D2754;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// oris r11,r11,4096
	r11.u64 = r11.u64 | 268435456;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// lwz r10,28(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 28);
	// lwz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 76);
	// rlwinm r10,r10,9,24,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 9) & 0xFF;
	// rlwimi r11,r10,27,4,4
	r11.u64 = (rotl32(ctx.r10.u32, 27) & 0x8000000) | (r11.u64 & 0xFFFFFFFFF7FFFFFF);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_831D2754:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm. r11,r10,0,3,3
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d27a8
	if (cr0.eq) goto loc_831D27A8;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm. r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d27a8
	if (cr0.eq) goto loc_831D27A8;
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
loc_831D2770:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d278c
	if (cr6.eq) goto loc_831D278C;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r9,r9,0,4,6
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831d278c
	if (!cr0.eq) goto loc_831D278C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831d2770
	goto loc_831D2770;
loc_831D278C:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lis r9,64
	ctx.r9.s64 = 4194304;
	// rlwinm r11,r11,0,7,14
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1FE0000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x831d27a8
	if (!cr6.eq) goto loc_831D27A8;
	// rlwinm r11,r10,0,5,2
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFE7FFFFFF;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_831D27A8:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// li r28,0
	r28.s64 = 0;
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831d27c8
	if (cr6.lt) goto loc_831D27C8;
	// cmplwi cr6,r11,31
	cr6.compare<uint32_t>(r11.u32, 31, xer);
	// li r11,1
	r11.s64 = 1;
	// ble cr6,0x831d27cc
	if (!cr6.gt) goto loc_831D27CC;
loc_831D27C8:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_831D27CC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2ab0
	if (cr0.eq) goto loc_831D2AB0;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,25,7,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x1FFFFFF;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// clrlwi r10,r10,6
	ctx.r10.u64 = ctx.r10.u32 & 0x3FFFFFF;
	// addi r8,r11,-1
	ctx.r8.s64 = r11.s64 + -1;
	// oris r11,r10,51200
	r11.u64 = ctx.r10.u64 | 3355443200;
	// rlwimi r9,r8,24,3,7
	ctx.r9.u64 = (rotl32(ctx.r8.u32, 24) & 0x1F000000) | (ctx.r9.u64 & 0xFFFFFFFFE0FFFFFF);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d2810
	if (cr0.eq) goto loc_831D2810;
	// oris r11,r11,256
	r11.u64 = r11.u64 | 16777216;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_831D2810:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwimi r10,r11,15,12,15
	ctx.r10.u64 = (rotl32(r11.u32, 15) & 0xF0000) | (ctx.r10.u64 & 0xFFFFFFFFFFF0FFFF);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
loc_831D2824:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d288c
	if (cr6.eq) goto loc_831D288C;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831d2844
	if (cr6.eq) goto loc_831D2844;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r10,0,4,6
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d284c
	if (!cr0.eq) goto loc_831D284C;
loc_831D2844:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831d2824
	goto loc_831D2824;
loc_831D284C:
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm. r10,r10,27,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d2864
	if (cr0.eq) goto loc_831D2864;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// ori r10,r10,32768
	ctx.r10.u64 = ctx.r10.u64 | 32768;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
loc_831D2864:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r10,0,27,27
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d287c
	if (cr0.eq) goto loc_831D287C;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// ori r10,r10,64
	ctx.r10.u64 = ctx.r10.u64 | 64;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
loc_831D287C:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwimi r10,r11,15,26,31
	ctx.r10.u64 = (rotl32(r11.u32, 15) & 0x3F) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
loc_831D288C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lis r10,8
	ctx.r10.s64 = 524288;
	// mr r30,r28
	r30.u64 = r28.u64;
	// oris r11,r11,57344
	r11.u64 = r11.u64 | 3758096384;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x831d2908
	if (cr6.lt) goto loc_831D2908;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831cb198
	sub_831CB198(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// rlwinm r9,r11,31,24,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0xFF;
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwimi r10,r11,26,5,5
	ctx.r10.u64 = (rotl32(r11.u32, 26) & 0x4000000) | (ctx.r10.u64 & 0xFFFFFFFFFBFFFFFF);
	// rlwimi r8,r11,21,0,0
	ctx.r8.u64 = (rotl32(r11.u32, 21) & 0x80000000) | (ctx.r8.u64 & 0xFFFFFFFF7FFFFFFF);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// rlwinm r10,r11,21,24,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 21) & 0xFF;
	// stb r9,5(r31)
	PPC_STORE_U8(r31.u32 + 5, ctx.r9.u8);
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwimi r9,r11,22,0,0
	ctx.r9.u64 = (rotl32(r11.u32, 22) & 0x80000000) | (ctx.r9.u64 & 0xFFFFFFFF7FFFFFFF);
	// stw r8,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r8.u32);
	// stb r10,9(r31)
	PPC_STORE_U8(r31.u32 + 9, ctx.r10.u8);
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
loc_831D2908:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lis r10,16
	ctx.r10.s64 = 1048576;
	// rlwinm r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x831d298c
	if (cr6.lt) goto loc_831D298C;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831cb198
	sub_831CB198(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r8,r11,31,24,31
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0xFF;
	// rlwimi r10,r11,25,6,6
	ctx.r10.u64 = (rotl32(r11.u32, 25) & 0x2000000) | (ctx.r10.u64 & 0xFFFFFFFFFDFFFFFF);
	// rlwimi r9,r11,20,1,1
	ctx.r9.u64 = (rotl32(r11.u32, 20) & 0x40000000) | (ctx.r9.u64 & 0xFFFFFFFFBFFFFFFF);
	// rlwinm r7,r11,21,24,31
	ctx.r7.u64 = rotl64(r11.u32 | (r11.u64 << 32), 21) & 0xFF;
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// stb r8,6(r31)
	PPC_STORE_U8(r31.u32 + 6, ctx.r8.u8);
	// stb r7,10(r31)
	PPC_STORE_U8(r31.u32 + 10, ctx.r7.u8);
	// beq 0x831d2988
	if (cr0.eq) goto loc_831D2988;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d2980
	if (cr6.eq) goto loc_831D2980;
	// rlwimi r10,r11,21,1,1
	ctx.r10.u64 = (rotl32(r11.u32, 21) & 0x40000000) | (ctx.r10.u64 & 0xFFFFFFFFBFFFFFFF);
	// b 0x831d2984
	goto loc_831D2984;
loc_831D2980:
	// rlwimi r10,r11,22,0,0
	ctx.r10.u64 = (rotl32(r11.u32, 22) & 0x80000000) | (ctx.r10.u64 & 0xFFFFFFFF7FFFFFFF);
loc_831D2984:
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
loc_831D2988:
	// add r30,r3,r30
	r30.u64 = ctx.r3.u64 + r30.u64;
loc_831D298C:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lis r10,24
	ctx.r10.s64 = 1572864;
	// rlwinm r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x831d2a0c
	if (cr6.lt) goto loc_831D2A0C;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831cb198
	sub_831CB198(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r8,r11,31,24,31
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0xFF;
	// rlwimi r10,r11,24,7,7
	ctx.r10.u64 = (rotl32(r11.u32, 24) & 0x1000000) | (ctx.r10.u64 & 0xFFFFFFFFFEFFFFFF);
	// rlwimi r9,r11,19,2,2
	ctx.r9.u64 = (rotl32(r11.u32, 19) & 0x20000000) | (ctx.r9.u64 & 0xFFFFFFFFDFFFFFFF);
	// rlwinm r7,r11,21,24,31
	ctx.r7.u64 = rotl64(r11.u32 | (r11.u64 << 32), 21) & 0xFF;
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// stb r8,7(r31)
	PPC_STORE_U8(r31.u32 + 7, ctx.r8.u8);
	// stb r7,11(r31)
	PPC_STORE_U8(r31.u32 + 11, ctx.r7.u8);
	// beq 0x831d2a0c
	if (cr0.eq) goto loc_831D2A0C;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d2a04
	if (cr6.eq) goto loc_831D2A04;
	// rlwimi r10,r11,21,1,1
	ctx.r10.u64 = (rotl32(r11.u32, 21) & 0x40000000) | (ctx.r10.u64 & 0xFFFFFFFFBFFFFFFF);
	// b 0x831d2a08
	goto loc_831D2A08;
loc_831D2A04:
	// rlwimi r10,r11,22,0,0
	ctx.r10.u64 = (rotl32(r11.u32, 22) & 0x80000000) | (ctx.r10.u64 & 0xFFFFFFFF7FFFFFFF);
loc_831D2A08:
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
loc_831D2A0C:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm. r10,r11,0,2,2
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d2a3c
	if (cr0.eq) goto loc_831D2A3C;
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d2a3c
	if (!cr0.eq) goto loc_831D2A3C;
	// rlwinm. r11,r11,0,1,1
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d2a3c
	if (!cr0.eq) goto loc_831D2A3C;
	// rlwinm r11,r26,0,0,19
	r11.u64 = rotl64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFF000;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D2A3C:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// blt cr6,0x831d2e30
	if (cr6.lt) goto loc_831D2E30;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x831d2e30
	if (cr6.gt) goto loc_831D2E30;
	// lbz r11,5(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 5);
	// lbz r10,6(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 6);
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// addi r9,r11,-2
	ctx.r9.s64 = r11.s64 + -2;
	// addi r8,r11,-1
	ctx.r8.s64 = r11.s64 + -1;
	// addi r7,r10,-2
	ctx.r7.s64 = ctx.r10.s64 + -2;
	// addi r6,r10,-1
	ctx.r6.s64 = ctx.r10.s64 + -1;
	// rlwimi r8,r9,2,28,29
	ctx.r8.u64 = (rotl32(ctx.r9.u32, 2) & 0xC) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFF3);
	// rlwimi r6,r7,2,28,29
	ctx.r6.u64 = (rotl32(ctx.r7.u32, 2) & 0xC) | (ctx.r6.u64 & 0xFFFFFFFFFFFFFFF3);
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r8,r8,2,26,29
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0x3C;
	// rlwinm r9,r9,6,24,25
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0xC0;
	// rlwinm r6,r6,2,26,29
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0x3C;
	// rlwinm r7,r7,6,24,25
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xC0;
	// or r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 | ctx.r9.u64;
	// or r8,r6,r7
	ctx.r8.u64 = ctx.r6.u64 | ctx.r7.u64;
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// or r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 | ctx.r10.u64;
	// stb r11,5(r31)
	PPC_STORE_U8(r31.u32 + 5, r11.u8);
	// stb r10,6(r31)
	PPC_STORE_U8(r31.u32 + 6, ctx.r10.u8);
	// b 0x831d2e30
	goto loc_831D2E30;
loc_831D2AB0:
	// clrlwi. r27,r25,24
	r27.u64 = r25.u32 & 0xFF;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// bne 0x831d2ac8
	if (!cr0.eq) goto loc_831D2AC8;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r10,113
	ctx.r10.s64 = 113;
	// rlwimi r11,r10,25,0,7
	r11.u64 = (rotl32(ctx.r10.u32, 25) & 0xFF000000) | (r11.u64 & 0xFFFFFFFF00FFFFFF);
	// b 0x831d2b10
	goto loc_831D2B10;
loc_831D2AC8:
	// rlwinm r11,r26,0,0,30
	r11.u64 = rotl64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d2ae0
	if (cr0.eq) goto loc_831D2AE0;
	// mr r11,r28
	r11.u64 = r28.u64;
	// b 0x831d2ae8
	goto loc_831D2AE8;
loc_831D2AE0:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-40
	r11.s64 = r11.s64 + -40;
loc_831D2AE8:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm. r11,r11,13,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d2b00
	if (!cr0.eq) goto loc_831D2B00;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// oris r10,r10,32768
	ctx.r10.u64 = ctx.r10.u64 | 2147483648;
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
loc_831D2B00:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x831d2b14
	if (!cr6.eq) goto loc_831D2B14;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// oris r11,r11,16384
	r11.u64 = r11.u64 | 1073741824;
loc_831D2B10:
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
loc_831D2B14:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,25,7,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x1FFFFFF;
	// addi r11,r11,-32
	r11.s64 = r11.s64 + -32;
	// rlwimi r10,r11,26,0,5
	ctx.r10.u64 = (rotl32(r11.u32, 26) & 0xFC000000) | (ctx.r10.u64 & 0xFFFFFFFF03FFFFFF);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2b44
	if (cr0.eq) goto loc_831D2B44;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_831D2B44:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,19,0,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0xFFF80000;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// rlwimi r11,r10,0,12,7
	r11.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFFFFF0FFFFF) | (r11.u64 & 0xF00000);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// lwz r10,4(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 4);
loc_831D2B60:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831d2bd0
	if (cr6.eq) goto loc_831D2BD0;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d2b80
	if (cr6.eq) goto loc_831D2B80;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r9,r9,0,4,6
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831d2b88
	if (!cr0.eq) goto loc_831D2B88;
loc_831D2B80:
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// b 0x831d2b60
	goto loc_831D2B60;
loc_831D2B88:
	// lwz r9,8(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm. r9,r9,27,31,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d2ba8
	if (cr0.eq) goto loc_831D2BA8;
	// ori r11,r11,32768
	r11.u64 = r11.u64 | 32768;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwimi r11,r10,15,26,31
	r11.u64 = (rotl32(ctx.r10.u32, 15) & 0x3F) | (r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// b 0x831d2c28
	goto loc_831D2C28;
loc_831D2BA8:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r9,r9,0,27,27
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d2bbc
	if (cr0.eq) goto loc_831D2BBC;
	// ori r11,r11,16384
	r11.u64 = r11.u64 | 16384;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_831D2BBC:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwimi r10,r11,23,18,23
	ctx.r10.u64 = (rotl32(r11.u32, 23) & 0x3F00) | (ctx.r10.u64 & 0xFFFFFFFFFFFFC0FF);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// b 0x831d2c2c
	goto loc_831D2C2C;
loc_831D2BD0:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8310fa10
	sub_8310FA10(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2c2c
	if (cr0.eq) goto loc_831D2C2C;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm. r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2ca0
	if (cr0.eq) goto loc_831D2CA0;
	// lwz r30,44(r26)
	r30.u64 = PPC_LOAD_U32(r26.u32 + 44);
loc_831D2BF0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83110068
	sub_83110068(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2c2c
	if (cr0.eq) goto loc_831D2C2C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,19,20,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0xFFF;
	// rlwinm r10,r10,0,24,17
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFC0FF;
	// rlwinm r9,r11,16,12,15
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 16) & 0xF0000;
	// rlwinm r11,r11,0,22,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F0;
	// rlwinm r10,r10,0,12,7
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFF0FFFFF;
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// rlwinm r11,r11,4,0,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
loc_831D2C28:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_831D2C2C:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm. r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2e30
	if (cr0.eq) goto loc_831D2E30;
	// mr r29,r28
	r29.u64 = r28.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d2c60
	if (cr6.eq) goto loc_831D2C60;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d2c54
	if (!cr0.eq) goto loc_831D2C54;
	// li r29,1
	r29.s64 = 1;
loc_831D2C54:
	// rlwinm. r11,r11,0,1,1
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d2c60
	if (!cr0.eq) goto loc_831D2C60;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
loc_831D2C60:
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831cb198
	sub_831CB198(ctx, base);
	// lwz r30,80(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r6,r3,r29
	ctx.r6.u64 = ctx.r3.u64 + r29.u64;
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x831d2cdc
	if (cr0.eq) goto loc_831D2CDC;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r6,2
	cr6.compare<uint32_t>(ctx.r6.u32, 2, xer);
	// bne cr6,0x831d2cd4
	if (!cr6.eq) goto loc_831D2CD4;
	// rlwimi r11,r30,21,1,1
	r11.u64 = (rotl32(r30.u32, 21) & 0x40000000) | (r11.u64 & 0xFFFFFFFFBFFFFFFF);
	// b 0x831d2cd8
	goto loc_831D2CD8;
loc_831D2CA0:
	// lwz r30,0(r26)
	r30.u64 = PPC_LOAD_U32(r26.u32 + 0);
loc_831D2CA4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d2cc0
	if (cr6.eq) goto loc_831D2CC0;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d2bf0
	if (!cr0.eq) goto loc_831D2BF0;
	// lwz r30,4(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// b 0x831d2ca4
	goto loc_831D2CA4;
loc_831D2CC0:
	// rlwinm r11,r26,0,0,19
	r11.u64 = rotl64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFF000;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D2CD4:
	// rlwimi r11,r30,22,0,0
	r11.u64 = (rotl32(r30.u32, 22) & 0x80000000) | (r11.u64 & 0xFFFFFFFF7FFFFFFF);
loc_831D2CD8:
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_831D2CDC:
	// rlwinm r11,r30,21,24,31
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 21) & 0xFF;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lis r4,16
	ctx.r4.s64 = 1048576;
	// stb r11,11(r31)
	PPC_STORE_U8(r31.u32 + 11, r11.u8);
	// rlwimi r5,r30,24,7,7
	ctx.r5.u64 = (rotl32(r30.u32, 24) & 0x1000000) | (ctx.r5.u64 & 0xFFFFFFFFFEFFFFFF);
	// stw r5,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r5.u32);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// blt cr6,0x831d2d78
	if (cr6.lt) goto loc_831D2D78;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831cb198
	sub_831CB198(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm. r9,r10,21,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 21) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// rlwinm r11,r10,21,24,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 21) & 0xFF;
	// beq 0x831d2d40
	if (cr0.eq) goto loc_831D2D40;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r8,r9,0,0,5
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFC000000;
	// addis r8,r8,1024
	ctx.r8.s64 = ctx.r8.s64 + 67108864;
	// rlwimi r8,r9,0,6,31
	ctx.r8.u64 = (rotl32(ctx.r9.u32, 0) & 0x3FFFFFF) | (ctx.r8.u64 & 0xFFFFFFFFFC000000);
	// stw r8,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r8.u32);
loc_831D2D40:
	// rlwinm r7,r11,30,28,29
	ctx.r7.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0xC;
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r6,r11,30,30,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x3;
	// rlwinm r9,r30,31,30,31
	ctx.r9.u64 = rotl64(r30.u32 | (r30.u64 << 32), 31) & 0x3;
	// or r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 | ctx.r6.u64;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,6,24,25
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0xC0;
	// rlwimi r8,r11,28,2,2
	ctx.r8.u64 = (rotl32(r11.u32, 28) & 0x20000000) | (ctx.r8.u64 & 0xFFFFFFFFDFFFFFFF);
	// rlwinm r10,r10,31,30,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x3;
	// or r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 | ctx.r9.u64;
	// stw r8,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r8.u32);
	// or r11,r9,r10
	r11.u64 = ctx.r9.u64 | ctx.r10.u64;
	// b 0x831d2e2c
	goto loc_831D2E2C;
loc_831D2D78:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r3,r30,31,24,31
	ctx.r3.u64 = rotl64(r30.u32 | (r30.u64 << 32), 31) & 0xFF;
	// rlwimi r11,r30,19,2,2
	r11.u64 = (rotl32(r30.u32, 19) & 0x20000000) | (r11.u64 & 0xFFFFFFFFDFFFFFFF);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// bl 0x831cb150
	sub_831CB150(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d2e04
	if (cr6.eq) goto loc_831D2E04;
	// rlwinm r11,r26,0,0,30
	r11.u64 = rotl64(r26.u32 | (r26.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d2db0
	if (cr0.eq) goto loc_831D2DB0;
	// mr r11,r28
	r11.u64 = r28.u64;
	// b 0x831d2db8
	goto loc_831D2DB8;
loc_831D2DB0:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-40
	r11.s64 = r11.s64 + -40;
loc_831D2DB8:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// ble cr6,0x831d2e04
	if (!cr6.gt) goto loc_831D2E04;
	// clrlwi r3,r5,24
	ctx.r3.u64 = ctx.r5.u32 & 0xFF;
	// bl 0x831cb150
	sub_831CB150(ctx, base);
	// rlwinm r11,r6,30,2,31
	r11.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFFF;
	// rlwinm r10,r3,30,2,31
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// clrlwi r9,r6,30
	ctx.r9.u64 = ctx.r6.u32 & 0x3;
	// rlwimi r10,r11,2,28,29
	ctx.r10.u64 = (rotl32(r11.u32, 2) & 0xC) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFF3);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// rlwinm r10,r10,2,26,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x3C;
	// rlwinm r11,r9,6,24,25
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0xC0;
	// clrlwi r9,r3,30
	ctx.r9.u64 = ctx.r3.u32 & 0x3;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// or r11,r11,r9
	r11.u64 = r11.u64 | ctx.r9.u64;
	// b 0x831d2e2c
	goto loc_831D2E2C;
loc_831D2E04:
	// clrlwi r11,r6,30
	r11.u64 = ctx.r6.u32 & 0x3;
	// rlwinm r10,r6,30,30,31
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3;
	// addi r9,r11,-2
	ctx.r9.s64 = r11.s64 + -2;
	// addi r8,r10,-1
	ctx.r8.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwimi r8,r9,2,28,29
	ctx.r8.u64 = (rotl32(ctx.r9.u32, 2) & 0xC) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFF3);
	// rlwinm r11,r11,6,24,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0xC0;
	// rlwinm r9,r8,2,26,29
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0x3C;
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
loc_831D2E2C:
	// stb r11,7(r31)
	PPC_STORE_U8(r31.u32 + 7, r11.u8);
loc_831D2E30:
	// clrlwi. r11,r25,24
	r11.u64 = r25.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d2ee4
	if (!cr0.eq) goto loc_831D2EE4;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm. r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2ee4
	if (cr0.eq) goto loc_831D2EE4;
	// lwz r27,4(r26)
	r27.u64 = PPC_LOAD_U32(r26.u32 + 4);
loc_831D2E48:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d2e70
	if (cr6.eq) goto loc_831D2E70;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d2e68
	if (cr6.eq) goto loc_831D2E68;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d2e70
	if (!cr0.eq) goto loc_831D2E70;
loc_831D2E68:
	// lwz r27,8(r27)
	r27.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// b 0x831d2e48
	goto loc_831D2E48;
loc_831D2E70:
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// mr r29,r28
	r29.u64 = r28.u64;
	// lwz r30,0(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 0);
loc_831D2E7C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d2f08
	if (cr6.eq) goto loc_831D2F08;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r10,0,4,6
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2f00
	if (cr0.eq) goto loc_831D2F00;
	// lwz r3,12(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm. r9,r11,27,31,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d2f00
	if (cr0.eq) goto loc_831D2F00;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r10,r10,15,17,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0x7FFF;
	// clrlwi r9,r9,26
	ctx.r9.u64 = ctx.r9.u32 & 0x3F;
	// xor r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 ^ ctx.r9.u64;
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d2f00
	if (!cr0.eq) goto loc_831D2F00;
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,121
	cr6.compare<uint32_t>(r11.u32, 121, xer);
	// beq cr6,0x831d2eec
	if (cr6.eq) goto loc_831D2EEC;
	// cmplwi cr6,r11,122
	cr6.compare<uint32_t>(r11.u32, 122, xer);
	// beq cr6,0x831d2eec
	if (cr6.eq) goto loc_831D2EEC;
	// cmplw cr6,r3,r26
	cr6.compare<uint32_t>(ctx.r3.u32, r26.u32, xer);
	// beq cr6,0x831d2f00
	if (cr6.eq) goto loc_831D2F00;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8311cd58
	sub_8311CD58(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2f00
	if (cr0.eq) goto loc_831D2F00;
loc_831D2EE4:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c2c
	return;
loc_831D2EEC:
	// addi r11,r11,-122
	r11.s64 = r11.s64 + -122;
	// li r28,1
	r28.s64 = 1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or r29,r11,r29
	r29.u64 = r11.u64 | r29.u64;
loc_831D2F00:
	// lwz r30,4(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// b 0x831d2e7c
	goto loc_831D2E7C;
loc_831D2F08:
	// clrlwi. r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2ee4
	if (cr0.eq) goto loc_831D2EE4;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// clrlwi. r10,r29,24
	ctx.r10.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// ori r11,r11,16384
	r11.u64 = r11.u64 | 16384;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq 0x831d2ee4
	if (cr0.eq) goto loc_831D2EE4;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
loc_831D2F2C:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d2ee4
	if (cr6.eq) goto loc_831D2EE4;
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm. r11,r10,0,4,6
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2f88
	if (cr0.eq) goto loc_831D2F88;
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,15616
	cr6.compare<uint32_t>(r11.u32, 15616, xer);
	// bne cr6,0x831d2f88
	if (!cr6.eq) goto loc_831D2F88;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r8,r10,15,24,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0xFF;
	// rlwinm r10,r10,19,20,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 19) & 0xFFF;
	// clrlwi r7,r11,26
	ctx.r7.u64 = r11.u32 & 0x3F;
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x831d2f88
	if (!cr6.eq) goto loc_831D2F88;
	// rlwinm r8,r10,20,8,11
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xF00000;
	// rlwinm r10,r10,16,12,15
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xF0000;
	// or r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 | r11.u64;
	// rlwimi r8,r11,0,12,7
	ctx.r8.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFF0FFFFF) | (ctx.r8.u64 & 0xF00000);
	// or r11,r10,r8
	r11.u64 = ctx.r10.u64 | ctx.r8.u64;
	// rlwimi r11,r8,0,16,11
	r11.u64 = (rotl32(ctx.r8.u32, 0) & 0xFFFFFFFFFFF0FFFF) | (r11.u64 & 0xF0000);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_831D2F88:
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// b 0x831d2f2c
	goto loc_831D2F2C;
}

PPC_WEAK_FUNC(sub_831D26D0) {
	__imp__sub_831D26D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D2F90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// bl 0x8311ccf8
	sub_8311CCF8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d2fc0
	if (!cr0.eq) goto loc_831D2FC0;
loc_831D2FB8:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d3040
	goto loc_831D3040;
loc_831D2FC0:
	// clrlwi r11,r31,30
	r11.u64 = r31.u32 & 0x3;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831d3014
	if (cr6.lt) goto loc_831D3014;
	// beq cr6,0x831d2ff0
	if (cr6.eq) goto loc_831D2FF0;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x831d2fe8
	if (cr6.lt) goto loc_831D2FE8;
	// beq cr6,0x831d2fb8
	if (cr6.eq) goto loc_831D2FB8;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D2FE8:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d3040
	goto loc_831D3040;
loc_831D2FF0:
	// rlwinm r29,r31,0,0,29
	r29.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFC;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8311ccf8
	sub_8311CCF8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2fe8
	if (cr0.eq) goto loc_831D2FE8;
	// rlwinm r11,r31,0,0,29
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFC;
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x831d3034
	if (!cr6.eq) goto loc_831D3034;
	// b 0x831d2fb8
	goto loc_831D2FB8;
loc_831D3014:
	// rlwinm r29,r31,0,0,29
	r29.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFC;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8311ccf8
	sub_8311CCF8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d2fe8
	if (cr0.eq) goto loc_831D2FE8;
	// rlwinm r11,r31,0,0,29
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFC;
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// beq cr6,0x831d2fe8
	if (cr6.eq) goto loc_831D2FE8;
loc_831D3034:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8311cd58
	sub_8311CD58(ctx, base);
loc_831D3040:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831D2F90) {
	__imp__sub_831D2F90(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D3048) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r22,r4
	r22.u64 = ctx.r4.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// lwz r5,12(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// rlwinm. r9,r10,0,4,6
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d30b4
	if (cr0.eq) goto loc_831D30B4;
	// rotlwi r7,r10,0
	ctx.r7.u64 = rotl32(ctx.r10.u32, 0);
	// rlwinm r8,r10,27,24,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0xFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r10,r7,7,29,31
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 7) & 0x7;
loc_831D3094:
	// srw r7,r8,r9
	ctx.r7.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r9.u8 & 0x3F));
	// clrlwi r7,r7,30
	ctx.r7.u64 = ctx.r7.u32 & 0x3;
	// li r6,1
	ctx.r6.s64 = 1;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// slw r7,r6,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r7.u8 & 0x3F));
	// or r11,r7,r11
	r11.u64 = ctx.r7.u64 | r11.u64;
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// bne 0x831d3094
	if (!cr0.eq) goto loc_831D3094;
loc_831D30B4:
	// lis r10,-28311
	ctx.r10.s64 = -1855389696;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r8,0
	ctx.r8.s64 = 0;
	// ori r10,r10,5192
	ctx.r10.u64 = ctx.r10.u64 | 5192;
	// ori r8,r8,36262
	ctx.r8.u64 = ctx.r8.u64 | 36262;
	// clrldi r7,r11,32
	ctx.r7.u64 = r11.u64 & 0xFFFFFFFF;
	// rldimi r10,r8,32,0
	ctx.r10.u64 = (rotl64(ctx.r8.u64, 32) & 0xFFFFFFFF00000000) | (ctx.r10.u64 & 0xFFFFFFFF);
	// li r26,3
	r26.s64 = 3;
	// srd r10,r10,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r7.u8 & 0x7F));
	// srd r10,r10,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r7.u8 & 0x7F));
	// srd r10,r10,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r7.u8 & 0x7F));
	// rotlwi r10,r10,0
	ctx.r10.u64 = rotl32(ctx.r10.u32, 0);
	// li r27,0
	r27.s64 = 0;
	// rlwimi r9,r10,25,4,6
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 25) & 0xE000000) | (ctx.r9.u64 & 0xFFFFFFFFF1FFFFFF);
	// li r28,0
	r28.s64 = 0;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d3148
	if (cr6.eq) goto loc_831D3148;
	// li r10,0
	ctx.r10.s64 = 0;
loc_831D3104:
	// addi r8,r11,-1
	ctx.r8.s64 = r11.s64 + -1;
	// slw r7,r26,r10
	ctx.r7.u64 = ctx.r10.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r10.u8 & 0x3F));
	// andc r8,r11,r8
	ctx.r8.u64 = r11.u64 & ~ctx.r8.u64;
	// andc r7,r27,r7
	ctx.r7.u64 = r27.u64 & ~ctx.r7.u64;
	// cntlzw r6,r8
	ctx.r6.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// subf. r11,r8,r11
	r11.s64 = r11.s64 - ctx.r8.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// subfic r8,r6,31
	xer.ca = ctx.r6.u32 <= 31;
	ctx.r8.s64 = 31 - ctx.r6.s64;
	// rlwinm r6,r8,1,0,30
	ctx.r6.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// slw r8,r8,r10
	ctx.r8.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r10.u8 & 0x3F));
	// slw r5,r26,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r6.u8 & 0x3F));
	// slw r6,r9,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r6.u8 & 0x3F));
	// andc r5,r28,r5
	ctx.r5.u64 = r28.u64 & ~ctx.r5.u64;
	// or r27,r7,r8
	r27.u64 = ctx.r7.u64 | ctx.r8.u64;
	// or r28,r5,r6
	r28.u64 = ctx.r5.u64 | ctx.r6.u64;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// bne 0x831d3104
	if (!cr0.eq) goto loc_831D3104;
loc_831D3148:
	// lwz r11,40(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 40);
	// lwz r24,12(r30)
	r24.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// rlwinm. r11,r11,0,12,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x80000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d328c
	if (cr0.eq) goto loc_831D328C;
	// lwz r11,28(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 28);
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// bne cr6,0x831d328c
	if (!cr6.eq) goto loc_831D328C;
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
loc_831D3168:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d31a0
	if (cr6.eq) goto loc_831D31A0;
	// lwz r29,16(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d3198
	if (cr6.eq) goto loc_831D3198;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r10,r10,0,18,24
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r10,14080
	cr6.compare<uint32_t>(ctx.r10.u32, 14080, xer);
	// bne cr6,0x831d3198
	if (!cr6.eq) goto loc_831D3198;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r10,0,4,6
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d31a4
	if (!cr0.eq) goto loc_831D31A4;
loc_831D3198:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831d3168
	goto loc_831D3168;
loc_831D31A0:
	// li r29,0
	r29.s64 = 0;
loc_831D31A4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d328c
	if (cr6.eq) goto loc_831D328C;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831d2f90
	sub_831D2F90(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d328c
	if (cr0.eq) goto loc_831D328C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d3248
	if (cr0.eq) goto loc_831D3248;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r6,r29,44
	ctx.r6.s64 = r29.s64 + 44;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r11,0
	r11.s64 = 0;
	// rlwinm r5,r10,13,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 13) & 0x7;
	// rlwinm r7,r9,7,29,31
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0x7;
loc_831D31E8:
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
loc_831D31F0:
	// cmplw cr6,r9,r5
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r5.u32, xer);
	// bge cr6,0x831d323c
	if (!cr6.lt) goto loc_831D323C;
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r4,12(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r4,r24
	cr6.compare<uint32_t>(ctx.r4.u32, r24.u32, xer);
	// bne cr6,0x831d3220
	if (!cr6.eq) goto loc_831D3220;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// srw r4,r27,r11
	ctx.r4.u64 = r11.u8 & 0x20 ? 0 : (r27.u32 >> (r11.u8 & 0x3F));
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// xor r10,r4,r10
	ctx.r10.u64 = ctx.r4.u64 ^ ctx.r10.u64;
	// clrlwi. r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d322c
	if (cr0.eq) goto loc_831D322C;
loc_831D3220:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// b 0x831d31f0
	goto loc_831D31F0;
loc_831D322C:
	// slw r10,r26,r11
	ctx.r10.u64 = r11.u8 & 0x20 ? 0 : (r26.u32 << (r11.u8 & 0x3F));
	// slw r9,r9,r11
	ctx.r9.u64 = r11.u8 & 0x20 ? 0 : (ctx.r9.u32 << (r11.u8 & 0x3F));
	// andc r10,r27,r10
	ctx.r10.u64 = r27.u64 & ~ctx.r10.u64;
	// or r27,r10,r9
	r27.u64 = ctx.r10.u64 | ctx.r9.u64;
loc_831D323C:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// bne 0x831d31e8
	if (!cr0.eq) goto loc_831D31E8;
loc_831D3248:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x831d3260
	goto loc_831D3260;
loc_831D3258:
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_831D3260:
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bne cr6,0x831d3258
	if (!cr6.eq) goto loc_831D3258;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r31,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r31.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r29,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r29.u32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_831D328C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// rlwimi r11,r27,5,19,26
	r11.u64 = (rotl32(r27.u32, 5) & 0x1FE0) | (r11.u64 & 0xFFFFFFFFFFFFE01F);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83125268
	sub_83125268(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831cdaf0
	sub_831CDAF0(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// rlwinm r10,r10,0,0,26
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r9,r10,22,29,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 22) & 0x6;
	// rlwinm r8,r10,24,29,30
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0x6;
	// srw r9,r28,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r28.u32 >> (ctx.r9.u8 & 0x3F));
	// srw r8,r28,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (r28.u32 >> (ctx.r8.u8 & 0x3F));
	// rlwimi r8,r9,2,28,29
	ctx.r8.u64 = (rotl32(ctx.r9.u32, 2) & 0xC) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFF3);
	// rlwinm r9,r10,26,29,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x6;
	// clrlwi r8,r8,28
	ctx.r8.u64 = ctx.r8.u32 & 0xF;
	// srw r9,r28,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r28.u32 >> (ctx.r9.u8 & 0x3F));
	// rlwinm r7,r10,28,29,30
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0x6;
	// rlwimi r9,r8,2,0,29
	ctx.r9.u64 = (rotl32(ctx.r8.u32, 2) & 0xFFFFFFFC) | (ctx.r9.u64 & 0xFFFFFFFF00000003);
	// srw r8,r28,r7
	ctx.r8.u64 = ctx.r7.u8 & 0x20 ? 0 : (r28.u32 >> (ctx.r7.u8 & 0x3F));
	// rlwimi r8,r9,2,0,29
	ctx.r8.u64 = (rotl32(ctx.r9.u32, 2) & 0xFFFFFFFC) | (ctx.r8.u64 & 0xFFFFFFFF00000003);
	// rlwinm r10,r10,0,27,18
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// rlwinm r9,r8,5,0,26
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x831d3324
	goto loc_831D3324;
loc_831D331C:
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_831D3324:
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x831d331c
	if (!cr6.eq) goto loc_831D331C;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// stw r31,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r31.u32);
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm. r11,r11,0,27,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1E;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d3358
	if (cr0.eq) goto loc_831D3358;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831237d8
	sub_831237D8(ctx, base);
loc_831D3358:
	// lbz r11,8(r24)
	r11.u64 = PPC_LOAD_U8(r24.u32 + 8);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d3378
	if (cr0.eq) goto loc_831D3378;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8313a800
	sub_8313A800(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// oris r11,r11,256
	r11.u64 = r11.u64 | 16777216;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
loc_831D3378:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_831D3048) {
	__imp__sub_831D3048(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D3380) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x831d3048
	sub_831D3048(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D3380) {
	__imp__sub_831D3380(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D33A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// std r4,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, ctx.r4.u64);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r28,212(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// clrlwi r11,r28,27
	r11.u64 = r28.u32 & 0x1F;
	// std r5,216(r1)
	PPC_STORE_U64(ctx.r1.u32 + 216, ctx.r5.u64);
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r26,r8
	r26.u64 = ctx.r8.u64;
	// mr r24,r9
	r24.u64 = ctx.r9.u64;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,17
	cr6.compare<uint32_t>(r11.u32, 17, xer);
	// bne cr6,0x831d3444
	if (!cr6.eq) goto loc_831D3444;
	// lwz r10,536(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x831d3444
	if (!cr6.gt) goto loc_831D3444;
	// addi r10,r31,348
	ctx.r10.s64 = r31.s64 + 348;
loc_831D33F8:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// cmplwi cr6,r9,17
	cr6.compare<uint32_t>(ctx.r9.u32, 17, xer);
	// beq cr6,0x831d3420
	if (cr6.eq) goto loc_831D3420;
	// lwz r9,536(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x831d33f8
	if (cr6.lt) goto loc_831D33F8;
	// b 0x831d3444
	goto loc_831D3444;
loc_831D3420:
	// addi r9,r11,29
	ctx.r9.s64 = r11.s64 + 29;
	// mulli r10,r11,12
	ctx.r10.s64 = r11.s64 * 12;
	// mulli r11,r9,12
	r11.s64 = ctx.r9.s64 * 12;
	// lwzx r9,r11,r31
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// rlwinm r8,r28,0,15,15
	ctx.r8.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0x10000;
	// or r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 | ctx.r9.u64;
	// lwz r30,352(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 352);
	// stwx r9,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r9.u32);
loc_831D3444:
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x831d3454
	if (cr6.eq) goto loc_831D3454;
	// li r27,4
	r27.s64 = 4;
loc_831D3454:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831d35bc
	if (!cr6.eq) goto loc_831D35BC;
	// lwz r11,536(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// bne cr6,0x831d3474
	if (!cr6.eq) goto loc_831D3474;
	// li r4,3530
	ctx.r4.s64 = 3530;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D3474:
	// lwz r30,216(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// rldicr r5,r30,32,63
	ctx.r5.u64 = rotl64(r30.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// bl 0x831ca7d0
	sub_831CA7D0(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d349c
	if (cr0.eq) goto loc_831D349C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d37f8
	goto loc_831D37F8;
loc_831D349C:
	// lwz r11,536(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r9,208(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	// li r5,0
	ctx.r5.s64 = 0;
	// mulli r10,r11,12
	ctx.r10.s64 = r11.s64 * 12;
	// add r29,r10,r31
	r29.u64 = ctx.r10.u64 + r31.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// li r4,113
	ctx.r4.s64 = 113;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,536(r31)
	PPC_STORE_U32(r31.u32 + 536, r11.u32);
	// stw r9,344(r29)
	PPC_STORE_U32(r29.u32 + 344, ctx.r9.u32);
	// stw r28,348(r29)
	PPC_STORE_U32(r29.u32 + 348, r28.u32);
	// stw r30,352(r29)
	PPC_STORE_U32(r29.u32 + 352, r30.u32);
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,35
	ctx.r5.s64 = 35;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d34f8
	if (cr0.eq) goto loc_831D34F8;
	// li r11,0
	r11.s64 = 0;
loc_831D34F8:
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,113
	ctx.r6.s64 = 113;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831cd678
	sub_831CD678(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,128
	r11.u64 = r11.u64 | 8388608;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r11,r10,31
	r11.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d3530
	if (cr0.eq) goto loc_831D3530;
	// li r10,0
	ctx.r10.s64 = 0;
loc_831D3530:
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// addi r9,r10,16
	ctx.r9.s64 = ctx.r10.s64 + 16;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r9,r9,-36
	ctx.r9.s64 = ctx.r9.s64 + -36;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// ori r6,r9,1
	ctx.r6.u64 = ctx.r9.u64 | 1;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// clrlwi. r8,r26,24
	ctx.r8.u64 = r26.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// lwz r5,16(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// rlwinm r5,r5,0,0,30
	ctx.r5.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r7,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r7.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, ctx.r9.u32);
	// stw r30,352(r29)
	PPC_STORE_U32(r29.u32 + 352, r30.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,2048
	r11.u64 = r11.u64 | 134217728;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// beq 0x831d35bc
	if (cr0.eq) goto loc_831D35BC;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x831d35bc
	if (!cr6.eq) goto loc_831D35BC;
	// clrlwi. r11,r24,24
	r11.u64 = r24.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// beq 0x831d35a8
	if (cr0.eq) goto loc_831D35A8;
	// andi. r10,r11,17476
	ctx.r10.u64 = r11.u64 & 17476;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,17476
	cr6.compare<uint32_t>(ctx.r10.u32, 17476, xer);
	// beq cr6,0x831d35bc
	if (cr6.eq) goto loc_831D35BC;
	// ori r11,r11,17476
	r11.u64 = r11.u64 | 17476;
	// b 0x831d35b8
	goto loc_831D35B8;
loc_831D35A8:
	// andi. r10,r11,26214
	ctx.r10.u64 = r11.u64 & 26214;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,26214
	cr6.compare<uint32_t>(ctx.r10.u32, 26214, xer);
	// beq cr6,0x831d35bc
	if (cr6.eq) goto loc_831D35BC;
	// ori r11,r11,26214
	r11.u64 = r11.u64 | 26214;
loc_831D35B8:
	// sth r11,14(r30)
	PPC_STORE_U16(r30.u32 + 14, r11.u16);
loc_831D35BC:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,1
	cr6.compare<int32_t>(r25.s32, 1, xer);
	// beq cr6,0x831d37b8
	if (cr6.eq) goto loc_831D37B8;
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// beq cr6,0x831d377c
	if (cr6.eq) goto loc_831D377C;
	// cmpwi cr6,r25,3
	cr6.compare<int32_t>(r25.s32, 3, xer);
	// beq cr6,0x831d3658
	if (cr6.eq) goto loc_831D3658;
	// cmpwi cr6,r25,4
	cr6.compare<int32_t>(r25.s32, 4, xer);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x831d3614
	if (cr6.eq) goto loc_831D3614;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d360c
	if (cr0.eq) goto loc_831D360C;
	// li r11,0
	r11.s64 = 0;
loc_831D360C:
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// b 0x831d37ec
	goto loc_831D37EC;
loc_831D3614:
	// bl 0x83123458
	sub_83123458(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d362c
	if (cr0.eq) goto loc_831D362C;
	// li r11,0
	r11.s64 = 0;
loc_831D362C:
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83161bb8
	sub_83161BB8(ctx, base);
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// andi. r10,r11,61166
	ctx.r10.u64 = r11.u64 & 61166;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,61166
	cr6.compare<uint32_t>(ctx.r10.u32, 61166, xer);
	// beq cr6,0x831d37f8
	if (cr6.eq) goto loc_831D37F8;
	// ori r11,r11,61166
	r11.u64 = r11.u64 | 61166;
	// sth r11,14(r3)
	PPC_STORE_U16(ctx.r3.u32 + 14, r11.u16);
	// b 0x831d37f8
	goto loc_831D37F8;
loc_831D3658:
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r11,r4,31
	r11.u64 = ctx.r4.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d3668
	if (cr0.eq) goto loc_831D3668;
	// li r4,0
	ctx.r4.s64 = 0;
loc_831D3668:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cf400
	sub_831CF400(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f31,3084(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f31.f64 = double(temp.f32);
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d36ac
	if (cr0.eq) goto loc_831D36AC;
	// li r11,0
	r11.s64 = 0;
loc_831D36AC:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// ld r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cf998
	sub_831CF998(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f1,3140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3140);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d36f8
	if (cr0.eq) goto loc_831D36F8;
	// li r11,0
	r11.s64 = 0;
loc_831D36F8:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// ld r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cf8d0
	sub_831CF8D0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f1,3080(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d3764
	if (cr0.eq) goto loc_831D3764;
	// li r11,0
	r11.s64 = 0;
loc_831D3764:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cf7f8
	sub_831CF7F8(ctx, base);
	// b 0x831d37f8
	goto loc_831D37F8;
loc_831D377C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r11,1
	r11.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwimi r10,r11,26,4,6
	ctx.r10.u64 = (rotl32(r11.u32, 26) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r11,119
	r11.s64 = 119;
	// rlwimi r10,r11,6,19,26
	ctx.r10.u64 = (rotl32(r11.u32, 6) & 0x1FE0) | (ctx.r10.u64 & 0xFFFFFFFFFFFFE01F);
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// b 0x831d37c8
	goto loc_831D37C8;
loc_831D37B8:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_831D37C8:
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d37e4
	if (cr0.eq) goto loc_831D37E4;
	// li r11,0
	r11.s64 = 0;
loc_831D37E4:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
loc_831D37EC:
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83161bb8
	sub_83161BB8(ctx, base);
loc_831D37F8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_831D33A8) {
	__imp__sub_831D33A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D3808) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mulli r22,r28,40
	r22.s64 = r28.s64 * 40;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r30,r22,r11
	r30.u64 = r22.u64 + r11.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d3860
	if (cr6.eq) goto loc_831D3860;
	// rlwinm r10,r29,3,0,28
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 3) & 0xFFFFFFF8;
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r10,4(r24)
	PPC_STORE_U32(r24.u32 + 4, ctx.r10.u32);
	// bne cr6,0x831d3a60
	if (!cr6.eq) goto loc_831D3A60;
loc_831D3860:
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r9,r1,104
	ctx.r9.s64 = ctx.r1.s64 + 104;
	// addi r8,r1,108
	ctx.r8.s64 = ctx.r1.s64 + 108;
	// addi r7,r1,100
	ctx.r7.s64 = ctx.r1.s64 + 100;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ca5c8
	sub_831CA5C8(ctx, base);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// rlwinm r23,r29,3,0,28
	r23.u64 = rotl64(r29.u32 | (r29.u64 << 32), 3) & 0xFFFFFFF8;
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r11,2
	r11.s64 = 2;
	// lwz r4,20(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,60(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// lwzx r10,r23,r10
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + ctx.r10.u32);
	// rlwinm r10,r10,14,30,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 14) & 0x3;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// subfc r11,r11,r10
	xer.ca = ctx.r10.u32 >= r11.u32;
	r11.s64 = ctx.r10.s64 - r11.s64;
	// cntlzw r10,r9
	ctx.r10.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// rlwinm r25,r10,27,31,31
	r25.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// addi r26,r11,1
	r26.s64 = r11.s64 + 1;
	// bl 0x831385c0
	sub_831385C0(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x831ca2e0
	sub_831CA2E0(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831a0430
	sub_831A0430(ctx, base);
	// lwz r5,8(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// bne cr6,0x831d3914
	if (!cr6.eq) goto loc_831D3914;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x831959b0
	sub_831959B0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ae8
	sub_83194AE8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,3502
	ctx.r4.s64 = 3502;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D3914:
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwzx r6,r23,r11
	ctx.r6.u64 = PPC_LOAD_U32(r23.u32 + r11.u32);
	// rlwinm. r11,r6,0,5,5
	r11.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d393c
	if (!cr0.eq) goto loc_831D393C;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// bl 0x83194f88
	sub_83194F88(ctx, base);
	// lwz r5,24(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// li r4,4502
	ctx.r4.s64 = 4502;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D393C:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r6,r6,5,28,31
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xF;
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// li r11,0
	r11.s64 = 0;
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// beq cr6,0x831d3a6c
	if (cr6.eq) goto loc_831D3A6C;
	// addi r8,r1,124
	ctx.r8.s64 = ctx.r1.s64 + 124;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// lis r9,-31951
	ctx.r9.s64 = -2093940736;
	// addi r10,r1,100
	ctx.r10.s64 = ctx.r1.s64 + 100;
	// addi r7,r9,2568
	ctx.r7.s64 = ctx.r9.s64 + 2568;
	// addi r9,r1,120
	ctx.r9.s64 = ctx.r1.s64 + 120;
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// stw r11,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, r11.u32);
	// li r8,21
	ctx.r8.s64 = 21;
	// bl 0x831cd040
	sub_831CD040(ctx, base);
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,96(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rldicr r5,r11,32,63
	ctx.r5.u64 = rotl64(r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// ld r4,120(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// bl 0x831ce330
	sub_831CE330(ctx, base);
	// clrlwi. r11,r26,24
	r11.u64 = r26.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// beq 0x831d39e0
	if (cr0.eq) goto loc_831D39E0;
	// clrlwi. r11,r25,24
	r11.u64 = r25.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// beq 0x831d39cc
	if (cr0.eq) goto loc_831D39CC;
	// andi. r10,r11,17476
	ctx.r10.u64 = r11.u64 & 17476;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,17476
	cr6.compare<uint32_t>(ctx.r10.u32, 17476, xer);
	// beq cr6,0x831d39e0
	if (cr6.eq) goto loc_831D39E0;
	// ori r11,r11,17476
	r11.u64 = r11.u64 | 17476;
	// b 0x831d39dc
	goto loc_831D39DC;
loc_831D39CC:
	// andi. r10,r11,26214
	ctx.r10.u64 = r11.u64 & 26214;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,26214
	cr6.compare<uint32_t>(ctx.r10.u32, 26214, xer);
	// beq cr6,0x831d39e0
	if (cr6.eq) goto loc_831D39E0;
	// ori r11,r11,26214
	r11.u64 = r11.u64 | 26214;
loc_831D39DC:
	// sth r11,14(r28)
	PPC_STORE_U16(r28.u32 + 14, r11.u16);
loc_831D39E0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r11,r22,r11
	r11.u64 = r22.u64 + r11.u64;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831d3a14
	if (!cr6.eq) goto loc_831D3A14;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r4,r11,0,15,28
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1FFF8;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r11,r22,r11
	r11.u64 = r22.u64 + r11.u64;
	// stw r3,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r3.u32);
loc_831D3A14:
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// lwz r7,104(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r6,108(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,112(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// bl 0x831ca710
	sub_831CA710(ctx, base);
	// addi r11,r31,972
	r11.s64 = r31.s64 + 972;
	// lwz r10,1004(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1004);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r11,r22,r11
	r11.u64 = r22.u64 + r11.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// add r9,r11,r23
	ctx.r9.u64 = r11.u64 + r23.u64;
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// stw r10,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r10.u32);
	// stw r27,1004(r31)
	PPC_STORE_U32(r31.u32 + 1004, r27.u32);
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
	// stw r9,4(r24)
	PPC_STORE_U32(r24.u32 + 4, ctx.r9.u32);
loc_831D3A60:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c20
	return;
loc_831D3A6C:
	// addi r10,r1,124
	ctx.r10.s64 = ctx.r1.s64 + 124;
	// addi r8,r1,100
	ctx.r8.s64 = ctx.r1.s64 + 100;
	// addi r7,r1,120
	ctx.r7.s64 = ctx.r1.s64 + 120;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// bl 0x831cd1c0
	sub_831CD1C0(ctx, base);
	// lwz r11,124(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// lwz r7,100(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// rlwimi r11,r10,20,14,14
	r11.u64 = (rotl32(ctx.r10.u32, 20) & 0x20000) | (r11.u64 & 0xFFFFFFFFFFFDFFFF);
	// lwz r6,96(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r11.u32);
	// lwz r26,128(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// ld r25,120(r1)
	r25.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// rldicr r5,r26,32,63
	ctx.r5.u64 = rotl64(r26.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// bl 0x831d33a8
	sub_831D33A8(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// bne 0x831d39e0
	if (!cr0.eq) goto loc_831D39E0;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// rldicr r5,r26,32,31
	ctx.r5.u64 = rotl64(r26.u64, 32) & 0xFFFFFFFF00000000;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ca7d0
	sub_831CA7D0(ctx, base);
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831D3808) {
	__imp__sub_831D3808(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D3AF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// beq cr6,0x831d3b74
	if (cr6.eq) goto loc_831D3B74;
	// lwz r7,536(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x831d3b74
	if (cr6.eq) goto loc_831D3B74;
	// addi r10,r31,348
	ctx.r10.s64 = r31.s64 + 348;
loc_831D3B30:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// clrlwi r5,r9,27
	ctx.r5.u64 = ctx.r9.u32 & 0x1F;
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// bne cr6,0x831d3b4c
	if (!cr6.eq) goto loc_831D3B4C;
	// rlwinm r9,r9,27,28,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0xF;
	// cmplw cr6,r29,r9
	cr6.compare<uint32_t>(r29.u32, ctx.r9.u32, xer);
	// beq cr6,0x831d3b60
	if (cr6.eq) goto loc_831D3B60;
loc_831D3B4C:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// blt cr6,0x831d3b30
	if (cr6.lt) goto loc_831D3B30;
	// b 0x831d3b74
	goto loc_831D3B74;
loc_831D3B60:
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lwz r3,352(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 352);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x831d3d20
	if (!cr6.eq) goto loc_831D3D20;
loc_831D3B74:
	// clrlwi. r11,r8,24
	r11.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d3d20
	if (cr0.eq) goto loc_831D3D20;
	// addi r11,r1,108
	r11.s64 = ctx.r1.s64 + 108;
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lis r28,-1
	r28.s64 = -65536;
	// stw r6,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r6.u32);
	// rlwinm r10,r10,0,0,15
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFF0000;
	// stb r6,96(r1)
	PPC_STORE_U8(ctx.r1.u32 + 96, ctx.r6.u8);
	// cmplw cr6,r10,r28
	cr6.compare<uint32_t>(ctx.r10.u32, r28.u32, xer);
	// stw r6,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r6.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// beq cr6,0x831d3bb4
	if (cr6.eq) goto loc_831D3BB4;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// li r7,21
	ctx.r7.s64 = 21;
	// addi r6,r11,2568
	ctx.r6.s64 = r11.s64 + 2568;
	// b 0x831d3bc0
	goto loc_831D3BC0;
loc_831D3BB4:
	// lis r11,-31951
	r11.s64 = -2093940736;
	// li r7,20
	ctx.r7.s64 = 20;
	// addi r6,r11,2824
	ctx.r6.s64 = r11.s64 + 2824;
loc_831D3BC0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d3c08
	if (cr6.eq) goto loc_831D3C08;
	// addi r8,r1,100
	ctx.r8.s64 = ctx.r1.s64 + 100;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// addi r10,r1,104
	ctx.r10.s64 = ctx.r1.s64 + 104;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb708
	sub_831CB708(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d3cf8
	if (!cr0.eq) goto loc_831D3CF8;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D3C08:
	// mulli r11,r7,12
	r11.s64 = ctx.r7.s64 * 12;
	// add r11,r11,r6
	r11.u64 = r11.u64 + ctx.r6.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// bge cr6,0x831d3c38
	if (!cr6.lt) goto loc_831D3C38;
loc_831D3C1C:
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r10,r10,9,27,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 9) & 0x1F;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// beq cr6,0x831d3c38
	if (cr6.eq) goto loc_831D3C38;
	// addi r30,r30,12
	r30.s64 = r30.s64 + 12;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x831d3c1c
	if (cr6.lt) goto loc_831D3C1C;
loc_831D3C38:
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x831d3c4c
	if (cr6.lt) goto loc_831D3C4C;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D3C4C:
	// lwz r6,0(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d3ccc
	if (cr6.eq) goto loc_831D3CCC;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r5,r11,1876
	ctx.r5.s64 = r11.s64 + 1876;
	// li r4,100
	ctx.r4.s64 = 100;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_831D3C78:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x831d3c78
	if (!cr6.eq) goto loc_831D3C78;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r4,r11,0,0,29
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFC;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// subf r10,r10,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r10.s64;
loc_831D3CB8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// stbx r9,r10,r11
	PPC_STORE_U8(ctx.r10.u32 + r11.u32, ctx.r9.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne 0x831d3cb8
	if (!cr0.eq) goto loc_831D3CB8;
loc_831D3CCC:
	// addi r8,r1,100
	ctx.r8.s64 = ctx.r1.s64 + 100;
	// addi r7,r1,104
	ctx.r7.s64 = ctx.r1.s64 + 104;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ca360
	sub_831CA360(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d3cf8
	if (!cr0.eq) goto loc_831D3CF8;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D3CF8:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// ld r4,104(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// rldicr r5,r11,32,63
	ctx.r5.u64 = rotl64(r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// beq cr6,0x831d3d28
	if (cr6.eq) goto loc_831D3D28;
	// bl 0x831ce330
	sub_831CE330(ctx, base);
loc_831D3D20:
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// b 0x82ca2c34
	return;
loc_831D3D28:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r7,100(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x831d33a8
	sub_831D33A8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831d3d20
	if (!cr0.eq) goto loc_831D3D20;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831D3AF0) {
	__imp__sub_831D3AF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D3D50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,648(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 648);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d3e1c
	if (!cr6.eq) goto loc_831D3E1C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r6,r11,16176
	ctx.r6.s64 = r11.s64 + 16176;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831cea60
	sub_831CEA60(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r11,1
	r11.s64 = 1;
	// li r6,3
	ctx.r6.s64 = 3;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,10
	ctx.r4.s64 = 10;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwimi r10,r11,5,25,27
	ctx.r10.u64 = (rotl32(r11.u32, 5) & 0x70) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFF8F);
	// lwz r8,28(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// oris r9,r9,8
	ctx.r9.u64 = ctx.r9.u64 | 524288;
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// rlwimi r10,r11,16,7,15
	ctx.r10.u64 = (rotl32(r11.u32, 16) & 0x1FF0000) | (ctx.r10.u64 & 0xFFFFFFFFFE00FFFF);
	// stw r9,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r9.u32);
	// lwz r7,56(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lhz r7,64(r7)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r7.u32 + 64);
	// rlwimi r9,r7,20,3,11
	ctx.r9.u64 = (rotl32(ctx.r7.u32, 20) & 0x1FF00000) | (ctx.r9.u64 & 0xFFFFFFFFE00FFFFF);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// stw r9,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwimi r10,r11,0,28,31
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xF) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFF0);
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwimi r9,r11,1,28,31
	ctx.r9.u64 = (rotl32(r11.u32, 1) & 0xF) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFF0);
	// stw r9,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r9.u32);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// rlwimi r9,r11,2,28,31
	ctx.r9.u64 = (rotl32(r11.u32, 2) & 0xF) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFF0);
	// stw r9,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, ctx.r9.u32);
	// bl 0x831965b8
	sub_831965B8(ctx, base);
	// stw r3,20(r30)
	PPC_STORE_U32(r30.u32 + 20, ctx.r3.u32);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// subf r11,r11,r30
	r11.s64 = r30.s64 - r11.s64;
	// li r10,40
	ctx.r10.s64 = 40;
	// divw r11,r11,r10
	r11.s32 = r11.s32 / ctx.r10.s32;
	// stw r11,648(r31)
	PPC_STORE_U32(r31.u32 + 648, r11.u32);
loc_831D3E1C:
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r4,648(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 648);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cffe8
	sub_831CFFE8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D3D50) {
	__imp__sub_831D3D50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D3E48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// stw r4,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// lfs f0,156(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	f0.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lfs f0,3084(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 3084);
	f0.f64 = double(temp.f32);
	// clrlwi r8,r5,24
	ctx.r8.u64 = ctx.r5.u32 & 0xFF;
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// cntlzw r11,r8
	r11.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// or r6,r11,r10
	ctx.r6.u64 = r11.u64 | ctx.r10.u64;
	// bl 0x831d0300
	sub_831D0300(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D3E48) {
	__imp__sub_831D3E48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D3EB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// bl 0x831d3e48
	sub_831D3E48(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwimi r11,r10,0,16,14
	r11.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D3EB8) {
	__imp__sub_831D3EB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D3F08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// stfs f1,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stfs f2,100(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f3,104(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// stfs f4,108(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x831d0300
	sub_831D0300(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D3F08) {
	__imp__sub_831D3F08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D3F50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// blt cr6,0x831d3fa4
	if (cr6.lt) goto loc_831D3FA4;
	// beq cr6,0x831d3f8c
	if (cr6.eq) goto loc_831D3F8C;
	// cmplwi cr6,r5,3
	cr6.compare<uint32_t>(ctx.r5.u32, 3, xer);
	// blt cr6,0x831d3f78
	if (cr6.lt) goto loc_831D3F78;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D3F78:
	// fctidz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f1.f64);
	// stfd f0,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, f0.u64);
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r5,0
	ctx.r5.s64 = 0;
	// b 0x831d3f9c
	goto loc_831D3F9C;
loc_831D3F8C:
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.u64 = uint64_t(int32_t(std::trunc(ctx.f1.f64)));
	// stfd f0,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, f0.u64);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_831D3F9C:
	// bl 0x831d3e48
	sub_831D3E48(ctx, base);
	// b 0x831d4018
	goto loc_831D4018;
loc_831D3FA4:
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// clrlwi. r10,r11,1
	ctx.r10.u64 = r11.u32 & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d3fc8
	if (cr0.eq) goto loc_831D3FC8;
	// rlwinm. r11,r11,0,1,8
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x7F800000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// beq 0x831d3fcc
	if (cr0.eq) goto loc_831D3FCC;
loc_831D3FC8:
	// li r11,1
	r11.s64 = 1;
loc_831D3FCC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d3fe4
	if (!cr0.eq) goto loc_831D3FE4;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,0,0,0
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
loc_831D3FE4:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// stfs f0,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lfs f0,3084(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3084);
	f0.f64 = double(temp.f32);
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x831d0300
	sub_831D0300(ctx, base);
loc_831D4018:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D3F50) {
	__imp__sub_831D3F50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D4028) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r7,4(r6)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// addi r25,r6,4
	r25.s64 = ctx.r6.s64 + 4;
	// li r30,0
	r30.s64 = 0;
loc_831D404C:
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x831d40ac
	if (cr6.eq) goto loc_831D40AC;
	// lwz r11,16(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d40a4
	if (cr6.eq) goto loc_831D40A4;
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r11,r10,7,29,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d40a4
	if (cr0.eq) goto loc_831D40A4;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d40a0
	if (cr6.eq) goto loc_831D40A0;
	// rlwinm r9,r10,27,24,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0xFF;
	// li r10,0
	ctx.r10.s64 = 0;
loc_831D4080:
	// srw r5,r9,r10
	ctx.r5.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi r5,r5,30
	ctx.r5.u64 = ctx.r5.u32 & 0x3;
	// li r4,1
	ctx.r4.s64 = 1;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// slw r5,r4,r5
	ctx.r5.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r4.u32 << (ctx.r5.u8 & 0x3F));
	// or r8,r5,r8
	ctx.r8.u64 = ctx.r5.u64 | ctx.r8.u64;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// bne 0x831d4080
	if (!cr0.eq) goto loc_831D4080;
loc_831D40A0:
	// or r30,r8,r30
	r30.u64 = ctx.r8.u64 | r30.u64;
loc_831D40A4:
	// lwz r7,8(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// b 0x831d404c
	goto loc_831D404C;
loc_831D40AC:
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// lis r11,-28311
	r11.s64 = -1855389696;
	// lis r10,0
	ctx.r10.s64 = 0;
	// ori r11,r11,5192
	r11.u64 = r11.u64 | 5192;
	// ori r10,r10,36262
	ctx.r10.u64 = ctx.r10.u64 | 36262;
	// clrldi r9,r30,32
	ctx.r9.u64 = r30.u64 & 0xFFFFFFFF;
	// rldimi r11,r10,32,0
	r11.u64 = (rotl64(ctx.r10.u64, 32) & 0xFFFFFFFF00000000) | (r11.u64 & 0xFFFFFFFF);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// srd r11,r11,r9
	r11.u64 = ctx.r9.u8 & 0x40 ? 0 : (r11.u64 >> (ctx.r9.u8 & 0x7F));
	// srd r11,r11,r9
	r11.u64 = ctx.r9.u8 & 0x40 ? 0 : (r11.u64 >> (ctx.r9.u8 & 0x7F));
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// srd r11,r11,r9
	r11.u64 = ctx.r9.u8 & 0x40 ? 0 : (r11.u64 >> (ctx.r9.u8 & 0x7F));
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwimi r8,r11,25,4,6
	ctx.r8.u64 = (rotl32(r11.u32, 25) & 0xE000000) | (ctx.r8.u64 & 0xFFFFFFFFF1FFFFFF);
	// li r29,0
	r29.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r8,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r8.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d4150
	if (cr6.eq) goto loc_831D4150;
	// li r11,0
	r11.s64 = 0;
	// li r7,3
	ctx.r7.s64 = 3;
loc_831D410C:
	// addi r8,r30,-1
	ctx.r8.s64 = r30.s64 + -1;
	// slw r6,r7,r11
	ctx.r6.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 << (r11.u8 & 0x3F));
	// andc r8,r30,r8
	ctx.r8.u64 = r30.u64 & ~ctx.r8.u64;
	// andc r10,r10,r6
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r6.u64;
	// cntlzw r6,r8
	ctx.r6.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// subf. r30,r8,r30
	r30.s64 = r30.s64 - ctx.r8.s64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// subfic r8,r6,31
	xer.ca = ctx.r6.u32 <= 31;
	ctx.r8.s64 = 31 - ctx.r6.s64;
	// rlwinm r6,r8,1,0,30
	ctx.r6.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// slw r8,r8,r11
	ctx.r8.u64 = r11.u8 & 0x20 ? 0 : (ctx.r8.u32 << (r11.u8 & 0x3F));
	// slw r5,r7,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r6.u8 & 0x3F));
	// slw r6,r9,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r6.u8 & 0x3F));
	// andc r5,r29,r5
	ctx.r5.u64 = r29.u64 & ~ctx.r5.u64;
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// or r29,r5,r6
	r29.u64 = ctx.r5.u64 | ctx.r6.u64;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// bne 0x831d410c
	if (!cr0.eq) goto loc_831D410C;
loc_831D4150:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// rlwimi r11,r10,5,19,26
	r11.u64 = (rotl32(ctx.r10.u32, 5) & 0x1FE0) | (r11.u64 & 0xFFFFFFFFFFFFE01F);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831d3048
	sub_831D3048(ctx, base);
	// lwz r28,12(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r28,4
	r30.s64 = r28.s64 + 4;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// b 0x831d418c
	goto loc_831D418C;
loc_831D4184:
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_831D418C:
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d4184
	if (!cr6.eq) goto loc_831D4184;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r6,26
	ctx.r6.s64 = 26;
	// li r5,20
	ctx.r5.s64 = 20;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// bl 0x831104e0
	sub_831104E0(ctx, base);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
loc_831D41B4:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d426c
	if (cr6.eq) goto loc_831D426C;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d4258
	if (cr6.eq) goto loc_831D4258;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r7,r10,0,4,6
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x831d4258
	if (cr0.eq) goto loc_831D4258;
	// cmplw cr6,r9,r28
	cr6.compare<uint32_t>(ctx.r9.u32, r28.u32, xer);
	// beq cr6,0x831d4258
	if (cr6.eq) goto loc_831D4258;
	// rlwinm r7,r10,22,29,30
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 22) & 0x6;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwinm r6,r10,24,29,30
	ctx.r6.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0x6;
	// srw r7,r29,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (r29.u32 >> (ctx.r7.u8 & 0x3F));
	// srw r6,r29,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (r29.u32 >> (ctx.r6.u8 & 0x3F));
	// rlwimi r6,r7,2,28,29
	ctx.r6.u64 = (rotl32(ctx.r7.u32, 2) & 0xC) | (ctx.r6.u64 & 0xFFFFFFFFFFFFFFF3);
	// rlwinm r5,r10,26,29,30
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x6;
	// rlwinm r7,r10,28,29,30
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0x6;
	// clrlwi r6,r6,28
	ctx.r6.u64 = ctx.r6.u32 & 0xF;
	// srw r5,r29,r5
	ctx.r5.u64 = ctx.r5.u8 & 0x20 ? 0 : (r29.u32 >> (ctx.r5.u8 & 0x3F));
	// srw r7,r29,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (r29.u32 >> (ctx.r7.u8 & 0x3F));
	// rlwimi r5,r6,2,0,29
	ctx.r5.u64 = (rotl32(ctx.r6.u32, 2) & 0xFFFFFFFC) | (ctx.r5.u64 & 0xFFFFFFFF00000003);
	// rlwinm r6,r10,0,27,18
	ctx.r6.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// rlwimi r7,r5,2,0,29
	ctx.r7.u64 = (rotl32(ctx.r5.u32, 2) & 0xFFFFFFFC) | (ctx.r7.u64 & 0xFFFFFFFF00000003);
	// addi r10,r9,4
	ctx.r10.s64 = ctx.r9.s64 + 4;
	// rlwinm r7,r7,5,0,26
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// or r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 | ctx.r6.u64;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// b 0x831d4238
	goto loc_831D4238;
loc_831D4230:
	// addi r10,r9,8
	ctx.r10.s64 = ctx.r9.s64 + 8;
	// lwz r9,8(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
loc_831D4238:
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x831d4230
	if (!cr6.eq) goto loc_831D4230;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// stw r28,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r28.u32);
loc_831D4258:
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x831d41b4
	if (!cr6.eq) goto loc_831D41B4;
	// addi r8,r11,8
	ctx.r8.s64 = r11.s64 + 8;
	// b 0x831d41b4
	goto loc_831D41B4;
loc_831D426C:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831D4028) {
	__imp__sub_831D4028(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D4278) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831d3048
	sub_831D3048(ctx, base);
	// lwz r29,12(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r10,r29,4
	ctx.r10.s64 = r29.s64 + 4;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// b 0x831d42cc
	goto loc_831D42CC;
loc_831D42C4:
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_831D42CC:
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d42c4
	if (!cr6.eq) goto loc_831D42C4;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r6,26
	ctx.r6.s64 = 26;
	// li r5,20
	ctx.r5.s64 = 20;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// bl 0x831104e0
	sub_831104E0(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D4278) {
	__imp__sub_831D4278(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D4300) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mulli r10,r26,40
	ctx.r10.s64 = r26.s64 * 40;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r30,r10,r11
	r30.u64 = ctx.r10.u64 + r11.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d435c
	if (cr6.eq) goto loc_831D435C;
	// rlwinm r10,r25,3,0,28
	ctx.r10.u64 = rotl64(r25.u32 | (r25.u64 << 32), 3) & 0xFFFFFFF8;
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// stw r10,4(r27)
	PPC_STORE_U32(r27.u32 + 4, ctx.r10.u32);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831d46b4
	if (cr6.eq) goto loc_831D46B4;
loc_831D435C:
	// addi r10,r1,104
	ctx.r10.s64 = ctx.r1.s64 + 104;
	// addi r9,r1,120
	ctx.r9.s64 = ctx.r1.s64 + 120;
	// addi r8,r1,108
	ctx.r8.s64 = ctx.r1.s64 + 108;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// addi r6,r1,100
	ctx.r6.s64 = ctx.r1.s64 + 100;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ca5c8
	sub_831CA5C8(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// rlwinm r11,r11,29,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831d43a8
	if (!cr6.eq) goto loc_831D43A8;
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r4,r11,3,0,28
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// stw r3,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r3.u32);
loc_831D43A8:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm. r11,r11,0,0,0
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d44dc
	if (!cr0.eq) goto loc_831D44DC;
	// lwz r24,104(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,124
	ctx.r4.s64 = 124;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,35
	ctx.r5.s64 = 35;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// clrlwi. r11,r6,31
	r11.u64 = ctx.r6.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d43f0
	if (cr0.eq) goto loc_831D43F0;
	// li r6,0
	ctx.r6.s64 = 0;
loc_831D43F0:
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// rlwinm r28,r25,3,0,28
	r28.u64 = rotl64(r25.u32 | (r25.u64 << 32), 3) & 0xFFFFFFF8;
	// lwz r25,108(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// lwz r23,100(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// li r5,124
	ctx.r5.s64 = 124;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// stw r24,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r24.u32);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// rlwinm r11,r11,14,30,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 14) & 0x3;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// bl 0x831cdc08
	sub_831CDC08(ctx, base);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r11,r10,31
	r11.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d4440
	if (cr0.eq) goto loc_831D4440;
	// li r10,0
	ctx.r10.s64 = 0;
loc_831D4440:
	// rlwinm r11,r29,0,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// addi r9,r10,16
	ctx.r9.s64 = ctx.r10.s64 + 16;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r9,r9,-36
	ctx.r9.s64 = ctx.r9.s64 + -36;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// ori r6,r9,1
	ctx.r6.u64 = ctx.r9.u64 | 1;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// rlwinm r8,r8,0,0,30
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, ctx.r9.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,28,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x7;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d4490
	if (!cr0.eq) goto loc_831D4490;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// b 0x831d44a0
	goto loc_831D44A0;
loc_831D4490:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x831d44a4
	if (!cr6.eq) goto loc_831D44A4;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
loc_831D44A0:
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
loc_831D44A4:
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// lwz r7,120(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ca710
	sub_831CA710(ctx, base);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// add r10,r28,r11
	ctx.r10.u64 = r28.u64 + r11.u64;
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// stw r10,4(r27)
	PPC_STORE_U32(r27.u32 + 4, ctx.r10.u32);
	// b 0x831d46b4
	goto loc_831D46B4;
loc_831D44DC:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x831d4500
	if (!cr6.eq) goto loc_831D4500;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// li r4,3619
	ctx.r4.s64 = 3619;
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D4500:
	// li r5,18
	ctx.r5.s64 = 18;
	// bl 0x83194b80
	sub_83194B80(ctx, base);
	// lwz r29,20(r3)
	r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x831d4524
	if (cr6.eq) goto loc_831D4524;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D4524:
	// li r11,0
	r11.s64 = 0;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// stb r11,96(r1)
	PPC_STORE_U8(ctx.r1.u32 + 96, r11.u8);
	// addi r7,r1,120
	ctx.r7.s64 = ctx.r1.s64 + 120;
	// addi r6,r1,108
	ctx.r6.s64 = ctx.r1.s64 + 108;
	// li r5,3
	ctx.r5.s64 = 3;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x83136350
	sub_83136350(ctx, base);
	// lbz r11,96(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 96);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d4560
	if (cr0.eq) goto loc_831D4560;
	// li r4,4509
	ctx.r4.s64 = 4509;
	// lwz r5,24(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D4560:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r4,16
	ctx.r5.s64 = ctx.r4.s64 + 16;
	// li r6,120
	ctx.r6.s64 = 120;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r28,1
	r28.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwimi r10,r28,1,27,30
	ctx.r10.u64 = (rotl32(r28.u32, 1) & 0x1E) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFE1);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r25,r25,3,0,28
	r25.u64 = rotl64(r25.u32 | (r25.u64 << 32), 3) & 0xFFFFFFF8;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lwz r8,0(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// oris r11,r8,16384
	r11.u64 = ctx.r8.u64 | 1073741824;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lfs f0,3084(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 3084);
	f0.f64 = double(temp.f32);
	// rlwimi r10,r11,17,7,14
	ctx.r10.u64 = (rotl32(r11.u32, 17) & 0x1FE0000) | (ctx.r10.u64 & 0xFFFFFFFFFE01FFFF);
	// stfs f0,132(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// rlwimi r10,r28,13,15,18
	ctx.r10.u64 = (rotl32(r28.u32, 13) & 0x1E000) | (ctx.r10.u64 & 0xFFFFFFFFFFFE1FFF);
	// lwz r6,112(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
	// stfs f0,140(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// rlwinm r11,r11,28,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x3FFF;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// bl 0x831d0300
	sub_831D0300(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cf720
	sub_831CF720(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r29,-24
	r11.s64 = r29.s64 + -24;
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// stw r29,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r29.u32);
	// lwz r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwimi r8,r10,15,3,16
	ctx.r8.u64 = (rotl32(ctx.r10.u32, 15) & 0x1FFF8000) | (ctx.r8.u64 & 0xFFFFFFFFE0007FFF);
	// rlwimi r9,r28,0,27,31
	ctx.r9.u64 = (rotl32(r28.u32, 0) & 0x1F) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFE0);
	// oris r10,r7,2
	ctx.r10.u64 = ctx.r7.u64 | 131072;
	// rlwimi r8,r26,0,17,31
	ctx.r8.u64 = (rotl32(r26.u32, 0) & 0x7FFF) | (ctx.r8.u64 & 0xFFFFFFFFFFFF8000);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// stw r8,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r8.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r9,4(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subfic r11,r11,31
	xer.ca = r11.u32 <= 31;
	r11.s64 = 31 - r11.s64;
	// rlwimi r9,r11,2,16,29
	ctx.r9.u64 = (rotl32(r11.u32, 2) & 0xFFFC) | (ctx.r9.u64 & 0xFFFFFFFFFFFF0003);
	// rlwimi r9,r28,0,30,14
	ctx.r9.u64 = (rotl32(r28.u32, 0) & 0xFFFFFFFFFFFE0003) | (ctx.r9.u64 & 0x1FFFC);
	// stw r9,4(r27)
	PPC_STORE_U32(r27.u32 + 4, ctx.r9.u32);
loc_831D46B4:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_831D4300) {
	__imp__sub_831D4300(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D46C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// mulli r9,r11,40
	ctx.r9.s64 = r11.s64 * 40;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// clrlwi r10,r10,29
	ctx.r10.u64 = ctx.r10.u32 & 0x7;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x831d4744
	if (cr6.eq) goto loc_831D4744;
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// beq cr6,0x831d4728
	if (cr6.eq) goto loc_831D4728;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// beq cr6,0x831d4714
	if (cr6.eq) goto loc_831D4714;
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// beq cr6,0x831d4728
	if (cr6.eq) goto loc_831D4728;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D4714:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831d3808
	sub_831D3808(ctx, base);
	// b 0x831d4754
	goto loc_831D4754;
loc_831D4728:
	// lwz r5,564(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 564);
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ced48
	sub_831CED48(ctx, base);
	// b 0x831d4754
	goto loc_831D4754;
loc_831D4744:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831d4300
	sub_831D4300(ctx, base);
loc_831D4754:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D46C0) {
	__imp__sub_831D46C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D4770) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,16000
	cr6.compare<uint32_t>(r11.u32, 16000, xer);
	// bne cr6,0x831d47a8
	if (!cr6.eq) goto loc_831D47A8;
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// rlwinm. r11,r11,0,12,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x80000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d49f0
	if (!cr0.eq) goto loc_831D49F0;
loc_831D47A8:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831d47cc
	if (cr6.eq) goto loc_831D47CC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83141828
	sub_83141828(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831ccdb0
	sub_831CCDB0(ctx, base);
loc_831D47CC:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm. r11,r11,7,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 7) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d4880
	if (cr0.eq) goto loc_831D4880;
loc_831D47D8:
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
loc_831D47DC:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d4848
	if (cr6.eq) goto loc_831D4848;
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm. r11,r10,0,1,1
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d47fc
	if (!cr0.eq) goto loc_831D47FC;
	// rlwinm. r11,r10,0,4,6
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x831d4800
	if (cr0.eq) goto loc_831D4800;
loc_831D47FC:
	// li r11,0
	r11.s64 = 0;
loc_831D4800:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d4814
	if (cr0.eq) goto loc_831D4814;
	// rlwinm. r11,r10,0,7,18
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1FFE000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne 0x831d4818
	if (!cr0.eq) goto loc_831D4818;
loc_831D4814:
	// li r11,0
	r11.s64 = 0;
loc_831D4818:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d4828
	if (!cr0.eq) goto loc_831D4828;
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// b 0x831d47dc
	goto loc_831D47DC;
loc_831D4828:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r3,28(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// rlwinm r11,r11,19,20,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0xFFF;
	// addi r4,r11,-1
	ctx.r4.s64 = r11.s64 + -1;
	// bl 0x831d8f60
	sub_831D8F60(ctx, base);
	// b 0x831d47d8
	goto loc_831D47D8;
loc_831D4848:
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// li r10,4
	ctx.r10.s64 = 4;
	// addi r11,r11,92
	r11.s64 = r11.s64 + 92;
loc_831D4854:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r9,r30
	cr6.compare<uint32_t>(ctx.r9.u32, r30.u32, xer);
	// bne cr6,0x831d4868
	if (!cr6.eq) goto loc_831D4868;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
loc_831D4868:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x831d4854
	if (!cr0.eq) goto loc_831D4854;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,7,5
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFDFFFFFF;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
loc_831D4880:
	// lwz r31,0(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d48ec
	if (!cr6.eq) goto loc_831D48EC;
	// clrlwi. r11,r26,24
	r11.u64 = r26.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d48bc
	if (cr0.eq) goto loc_831D48BC;
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,36(r10)
	PPC_STORE_U32(ctx.r10.u32 + 36, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_831D48BC:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmpwi cr6,r4,112
	cr6.compare<int32_t>(ctx.r4.s32, 112, xer);
	// blt cr6,0x831d49a4
	if (cr6.lt) goto loc_831D49A4;
	// cmpwi cr6,r4,113
	cr6.compare<int32_t>(ctx.r4.s32, 113, xer);
	// ble cr6,0x831d48dc
	if (!cr6.gt) goto loc_831D48DC;
	// cmpwi cr6,r4,125
	cr6.compare<int32_t>(ctx.r4.s32, 125, xer);
	// bne cr6,0x831d49a4
	if (!cr6.eq) goto loc_831D49A4;
loc_831D48DC:
	// li r10,115
	ctx.r10.s64 = 115;
	// rlwimi r11,r10,7,18,24
	r11.u64 = (rotl32(ctx.r10.u32, 7) & 0x3F80) | (r11.u64 & 0xFFFFFFFFFFFFC07F);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// b 0x831d49f0
	goto loc_831D49F0;
loc_831D48EC:
	// lwz r29,12(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d4908
	if (cr6.eq) goto loc_831D4908;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83176848
	sub_83176848(ctx, base);
loc_831D4908:
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123d48
	sub_83123D48(ctx, base);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d4880
	if (cr6.eq) goto loc_831D4880;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14080
	cr6.compare<uint32_t>(r11.u32, 14080, xer);
	// bne cr6,0x831d4880
	if (!cr6.eq) goto loc_831D4880;
	// lwz r31,4(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// mr r11,r31
	r11.u64 = r31.u64;
loc_831D4938:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d4970
	if (cr6.eq) goto loc_831D4970;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831d4968
	if (cr6.eq) goto loc_831D4968;
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r9,r9,0,18,24
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r9,14080
	cr6.compare<uint32_t>(ctx.r9.u32, 14080, xer);
	// bne cr6,0x831d4968
	if (!cr6.eq) goto loc_831D4968;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r9,r9,0,4,6
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831d4974
	if (!cr0.eq) goto loc_831D4974;
loc_831D4968:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831d4938
	goto loc_831D4938;
loc_831D4970:
	// li r10,0
	ctx.r10.s64 = 0;
loc_831D4974:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831d4880
	if (!cr6.eq) goto loc_831D4880;
loc_831D497C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d4880
	if (cr6.eq) goto loc_831D4880;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831d499c
	if (cr6.eq) goto loc_831D499C;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83176848
	sub_83176848(ctx, base);
loc_831D499C:
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// b 0x831d497c
	goto loc_831D497C;
loc_831D49A4:
	// lwz r10,40(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 40);
	// rlwinm. r10,r10,0,19,19
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d49cc
	if (cr0.eq) goto loc_831D49CC;
	// li r10,115
	ctx.r10.s64 = 115;
	// rlwimi r11,r10,7,18,24
	r11.u64 = (rotl32(ctx.r10.u32, 7) & 0x3F80) | (r11.u64 & 0xFFFFFFFFFFFFC07F);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// lwz r11,540(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 540);
	// stw r11,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r11.u32);
	// stw r30,540(r28)
	PPC_STORE_U32(r28.u32 + 540, r30.u32);
	// b 0x831d49f0
	goto loc_831D49F0;
loc_831D49CC:
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// li r6,35
	ctx.r6.s64 = 35;
	// bl 0x831104e0
	sub_831104E0(ctx, base);
loc_831D49F0:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831D4770) {
	__imp__sub_831D4770(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D49F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// li r5,38
	ctx.r5.s64 = 38;
	// li r4,8
	ctx.r4.s64 = 8;
	// lwz r11,40(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 40);
	// ori r10,r11,4096
	ctx.r10.u64 = r11.u64 | 4096;
	// rlwinm r25,r11,20,31,31
	r25.u64 = rotl64(r11.u32 | (r11.u64 << 32), 20) & 0x1;
	// stw r10,40(r28)
	PPC_STORE_U32(r28.u32 + 40, ctx.r10.u32);
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r26,r30,4
	r26.s64 = r30.s64 + 4;
	// ori r11,r30,1
	r11.u64 = r30.u64 | 1;
	// ori r10,r26,1
	ctx.r10.u64 = r26.u64 | 1;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
loc_831D4A40:
	// lwz r31,0(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 0);
loc_831D4A44:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d4aac
	if (cr6.eq) goto loc_831D4AAC;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// lwz r29,12(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d4a80
	if (!cr0.eq) goto loc_831D4A80;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d4a80
	if (cr0.eq) goto loc_831D4A80;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d4a8c
	if (!cr6.gt) goto loc_831D4A8C;
loc_831D4A80:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D4A8C:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r29,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r29.u32);
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// b 0x831d4a44
	goto loc_831D4A44;
loc_831D4AAC:
	// lwz r29,4(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 4);
loc_831D4AB0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d4b44
	if (cr6.eq) goto loc_831D4B44;
	// lwz r31,16(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d4b3c
	if (cr6.eq) goto loc_831D4B3C;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d4adc
	if (!cr0.eq) goto loc_831D4ADC;
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x831d4ae0
	if (cr0.eq) goto loc_831D4AE0;
loc_831D4ADC:
	// li r11,0
	r11.s64 = 0;
loc_831D4AE0:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d4b3c
	if (cr0.eq) goto loc_831D4B3C;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d4b18
	if (!cr0.eq) goto loc_831D4B18;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d4b18
	if (cr0.eq) goto loc_831D4B18;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d4b24
	if (!cr6.gt) goto loc_831D4B24;
loc_831D4B18:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D4B24:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831D4B3C:
	// lwz r29,8(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// b 0x831d4ab0
	goto loc_831D4AB0;
loc_831D4B44:
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831d4770
	sub_831D4770(ctx, base);
loc_831D4B58:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d4bf4
	if (!cr0.eq) goto loc_831D4BF4;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d4bf4
	if (cr0.eq) goto loc_831D4BF4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r4
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831d4bcc
	if (!cr0.eq) goto loc_831D4BCC;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831D4BCC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r27,r31
	r27.u64 = r31.u64;
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14720
	cr6.compare<uint32_t>(r11.u32, 14720, xer);
	// beq cr6,0x831d4b58
	if (cr6.eq) goto loc_831D4B58;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831101b8
	sub_831101B8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d4b58
	if (cr0.eq) goto loc_831D4B58;
	// b 0x831d4a40
	goto loc_831D4A40;
loc_831D4BF4:
	// lwz r10,976(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 976);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r11,r28,972
	r11.s64 = r28.s64 + 972;
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// stw r30,976(r28)
	PPC_STORE_U32(r28.u32 + 976, r30.u32);
	// bl 0x83110538
	sub_83110538(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831D49F8) {
	__imp__sub_831D49F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D4C18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r10,r11,25,25,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r10,117
	cr6.compare<uint32_t>(ctx.r10.u32, 117, xer);
	// beq cr6,0x831d4dd0
	if (cr6.eq) goto loc_831D4DD0;
	// rlwinm r11,r11,14,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 14) & 0x1;
	// clrlwi r9,r6,24
	ctx.r9.u64 = ctx.r6.u32 & 0xFF;
	// li r25,0
	r25.s64 = 0;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x831d4d4c
	if (!cr6.eq) goto loc_831D4D4C;
	// cmpwi cr6,r10,87
	cr6.compare<int32_t>(ctx.r10.s32, 87, xer);
	// beq cr6,0x831d4cd4
	if (cr6.eq) goto loc_831D4CD4;
	// cmpwi cr6,r10,90
	cr6.compare<int32_t>(ctx.r10.s32, 90, xer);
	// beq cr6,0x831d4c70
	if (cr6.eq) goto loc_831D4C70;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3428
	ctx.r5.s64 = r11.s64 + 3428;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D4C70:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// lwz r27,28(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// addi r11,r31,-16
	r11.s64 = r31.s64 + -16;
	// addi r28,r27,12
	r28.s64 = r27.s64 + 12;
	// lwz r29,12(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// lwzx r26,r3,r11
	r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
loc_831D4C98:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d4da4
	if (cr6.eq) goto loc_831D4DA4;
	// lwz r5,0(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplw cr6,r5,r26
	cr6.compare<uint32_t>(ctx.r5.u32, r26.u32, xer);
	// beq cr6,0x831d4cbc
	if (cr6.eq) goto loc_831D4CBC;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83169948
	sub_83169948(ctx, base);
	// li r25,1
	r25.s64 = 1;
loc_831D4CBC:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bne cr6,0x831d4ccc
	if (!cr6.eq) goto loc_831D4CCC;
	// addi r28,r29,8
	r28.s64 = r29.s64 + 8;
loc_831D4CCC:
	// lwz r29,0(r28)
	r29.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// b 0x831d4c98
	goto loc_831D4C98;
loc_831D4CD4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-16
	r11.s64 = r31.s64 + -16;
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r29,28(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwzx r28,r3,r11
	r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831d4770
	sub_831D4770(ctx, base);
	// addi r5,r29,32
	ctx.r5.s64 = r29.s64 + 32;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,86
	ctx.r6.s64 = 86;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-16
	r11.s64 = r31.s64 + -16;
	// stwx r28,r3,r11
	PPC_STORE_U32(ctx.r3.u32 + r11.u32, r28.u32);
	// b 0x831d4db8
	goto loc_831D4DB8;
loc_831D4D4C:
	// cmpwi cr6,r10,85
	cr6.compare<int32_t>(ctx.r10.s32, 85, xer);
	// beq cr6,0x831d4dd0
	if (cr6.eq) goto loc_831D4DD0;
	// cmpwi cr6,r10,87
	cr6.compare<int32_t>(ctx.r10.s32, 87, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// beq cr6,0x831d4dc0
	if (cr6.eq) goto loc_831D4DC0;
	// cmpwi cr6,r10,90
	cr6.compare<int32_t>(ctx.r10.s32, 90, xer);
	// beq cr6,0x831d4d78
	if (cr6.eq) goto loc_831D4D78;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3428
	ctx.r5.s64 = r11.s64 + 3428;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D4D78:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-16
	r11.s64 = r31.s64 + -16;
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwzx r5,r3,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83169948
	sub_83169948(ctx, base);
	// li r25,1
	r25.s64 = 1;
loc_831D4DA4:
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831d4770
	sub_831D4770(ctx, base);
loc_831D4DB8:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// b 0x831d4dd4
	goto loc_831D4DD4;
loc_831D4DC0:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,16192
	ctx.r5.s64 = r11.s64 + 16192;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D4DD0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D4DD4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831D4C18) {
	__imp__sub_831D4C18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D4DE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r21,r4
	r21.u64 = ctx.r4.u64;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// li r5,38
	ctx.r5.s64 = 38;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r20,r6
	r20.u64 = ctx.r6.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r5,38
	ctx.r5.s64 = 38;
	// addi r27,r31,4
	r27.s64 = r31.s64 + 4;
	// ori r11,r31,1
	r11.u64 = r31.u64 | 1;
	// ori r10,r27,1
	ctx.r10.u64 = r27.u64 | 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r11,r24
	r11.u64 = r24.u64;
	// addi r26,r30,4
	r26.s64 = r30.s64 + 4;
	// ori r10,r30,1
	ctx.r10.u64 = r30.u64 | 1;
	// ori r9,r26,1
	ctx.r9.u64 = r26.u64 | 1;
	// li r19,0
	r19.s64 = 0;
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// stw r9,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r9.u32);
	// li r22,0
	r22.s64 = 0;
loc_831D4E5C:
	// lwz r25,0(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 0);
loc_831D4E60:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831d4f98
	if (cr6.eq) goto loc_831D4F98;
	// lwz r29,12(r25)
	r29.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// cmplw cr6,r29,r21
	cr6.compare<uint32_t>(r29.u32, r21.u32, xer);
	// beq cr6,0x831d5028
	if (cr6.eq) goto loc_831D5028;
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x831d4eb0
	if (cr6.eq) goto loc_831D4EB0;
	// lwz r10,48(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 48);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r8,40(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// clrlwi r7,r10,13
	ctx.r7.u64 = ctx.r10.u32 & 0x7FFFF;
	// rlwinm r10,r7,27,5,31
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r7,27
	ctx.r7.u64 = ctx.r7.u32 & 0x1F;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// slw r9,r9,r7
	ctx.r9.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r7.u8 & 0x3F));
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// and. r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 & ctx.r9.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d4f90
	if (cr0.eq) goto loc_831D4F90;
loc_831D4EB0:
	// clrlwi. r10,r20,24
	ctx.r10.u64 = r20.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d4ed4
	if (cr0.eq) goto loc_831D4ED4;
	// lwz r10,28(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 28);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x831d4f90
	if (!cr6.eq) goto loc_831D4F90;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// beq cr6,0x831d4f90
	if (cr6.eq) goto loc_831D4F90;
loc_831D4ED4:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm. r10,r11,0,2,2
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d4f90
	if (!cr0.eq) goto loc_831D4F90;
	// oris r11,r11,8192
	r11.u64 = r11.u64 | 536870912;
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d4f18
	if (!cr0.eq) goto loc_831D4F18;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d4f18
	if (cr0.eq) goto loc_831D4F18;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d4f24
	if (!cr6.gt) goto loc_831D4F24;
loc_831D4F18:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D4F24:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r29,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r29.u32);
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d4f6c
	if (!cr0.eq) goto loc_831D4F6C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d4f6c
	if (cr0.eq) goto loc_831D4F6C;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d4f78
	if (!cr6.gt) goto loc_831D4F78;
loc_831D4F6C:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D4F78:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r29,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r29.u32);
loc_831D4F90:
	// lwz r25,4(r25)
	r25.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// b 0x831d4e60
	goto loc_831D4E60;
loc_831D4F98:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d5034
	if (!cr0.eq) goto loc_831D5034;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d5034
	if (cr0.eq) goto loc_831D5034;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r10,r4
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831d500c
	if (!cr0.eq) goto loc_831D500C;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831D500C:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// mr r11,r29
	r11.u64 = r29.u64;
	// cmplwi cr6,r22,40000
	cr6.compare<uint32_t>(r22.u32, 40000, xer);
	// ble cr6,0x831d4e5c
	if (!cr6.gt) goto loc_831D4E5C;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D5028:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r19,1
	r19.s64 = 1;
	// bl 0x83171fa0
	sub_83171FA0(ctx, base);
loc_831D5034:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d50b8
	if (!cr0.eq) goto loc_831D50B8;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d50b8
	if (cr0.eq) goto loc_831D50B8;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r10,r4
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831d50a8
	if (!cr0.eq) goto loc_831D50A8;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831D50A8:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r11,r11,0,3,1
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFDFFFFFFF;
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// b 0x831d5034
	goto loc_831D5034;
loc_831D50B8:
	// lwz r10,976(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 976);
	// addi r11,r28,972
	r11.s64 = r28.s64 + 972;
	// rotlwi r11,r30,0
	r11.u64 = rotl32(r30.u32, 0);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// stw r30,976(r28)
	PPC_STORE_U32(r28.u32 + 976, r30.u32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r31,976(r28)
	PPC_STORE_U32(r28.u32 + 976, r31.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c14
	return;
}

PPC_WEAK_FUNC(sub_831D4DE0) {
	__imp__sub_831D4DE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D50E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bbc
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// li r5,38
	ctx.r5.s64 = 38;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r20,28(r25)
	r20.u64 = PPC_LOAD_U32(r25.u32 + 28);
	// mr r19,r6
	r19.u64 = ctx.r6.u64;
	// mr r18,r7
	r18.u64 = ctx.r7.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r5,38
	ctx.r5.s64 = 38;
	// addi r26,r31,4
	r26.s64 = r31.s64 + 4;
	// ori r11,r31,1
	r11.u64 = r31.u64 | 1;
	// ori r10,r26,1
	ctx.r10.u64 = r26.u64 | 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r25
	r29.u64 = r25.u64;
	// addi r24,r30,4
	r24.s64 = r30.s64 + 4;
	// ori r11,r30,1
	r11.u64 = r30.u64 | 1;
	// ori r10,r24,1
	ctx.r10.u64 = r24.u64 | 1;
	// li r17,1
	r17.s64 = 1;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// li r21,0
	r21.s64 = 0;
loc_831D515C:
	// lwz r22,0(r29)
	r22.u64 = PPC_LOAD_U32(r29.u32 + 0);
loc_831D5160:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x831d5348
	if (cr6.eq) goto loc_831D5348;
	// lwz r28,12(r22)
	r28.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// cmplw cr6,r28,r23
	cr6.compare<uint32_t>(r28.u32, r23.u32, xer);
	// bne cr6,0x831d5214
	if (!cr6.eq) goto loc_831D5214;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// bne cr6,0x831d5184
	if (!cr6.eq) goto loc_831D5184;
	// clrlwi. r11,r19,24
	r11.u64 = r19.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5338
	if (cr0.eq) goto loc_831D5338;
loc_831D5184:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r17,0
	r17.s64 = 0;
	// bl 0x83171fa0
	sub_83171FA0(ctx, base);
loc_831D5190:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d53d4
	if (!cr0.eq) goto loc_831D53D4;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d53d4
	if (cr0.eq) goto loc_831D53D4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r10,r4
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831d5204
	if (!cr0.eq) goto loc_831D5204;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831D5204:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r11,r11,0,3,1
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFDFFFFFFF;
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// b 0x831d5190
	goto loc_831D5190;
loc_831D5214:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8313c7b8
	sub_8313C7B8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5338
	if (cr0.eq) goto loc_831D5338;
	// lwz r11,28(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// bne cr6,0x831d5338
	if (!cr6.eq) goto loc_831D5338;
	// clrlwi. r11,r18,24
	r11.u64 = r18.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5248
	if (cr0.eq) goto loc_831D5248;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83145c60
	sub_83145C60(ctx, base);
	// b 0x831d5274
	goto loc_831D5274;
loc_831D5248:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_831D524C:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d5340
	if (!cr0.eq) goto loc_831D5340;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-40
	xer.ca = r11.u32 > 39;
	r11.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5340
	if (cr0.eq) goto loc_831D5340;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// bne cr6,0x831d524c
	if (!cr6.eq) goto loc_831D524C;
	// li r3,1
	ctx.r3.s64 = 1;
loc_831D5274:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5338
	if (cr0.eq) goto loc_831D5338;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// rlwinm. r10,r11,0,2,2
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d5338
	if (!cr0.eq) goto loc_831D5338;
	// oris r11,r11,8192
	r11.u64 = r11.u64 | 536870912;
	// stw r11,8(r28)
	PPC_STORE_U32(r28.u32 + 8, r11.u32);
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d52c0
	if (!cr0.eq) goto loc_831D52C0;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d52c0
	if (cr0.eq) goto loc_831D52C0;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d52cc
	if (!cr6.gt) goto loc_831D52CC;
loc_831D52C0:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D52CC:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r28,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r28.u32);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d5314
	if (!cr0.eq) goto loc_831D5314;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d5314
	if (cr0.eq) goto loc_831D5314;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d5320
	if (!cr6.gt) goto loc_831D5320;
loc_831D5314:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D5320:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r28,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r28.u32);
loc_831D5338:
	// lwz r22,4(r22)
	r22.u64 = PPC_LOAD_U32(r22.u32 + 4);
	// b 0x831d5160
	goto loc_831D5160;
loc_831D5340:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d5274
	goto loc_831D5274;
loc_831D5348:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d5190
	if (!cr0.eq) goto loc_831D5190;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d5190
	if (cr0.eq) goto loc_831D5190;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r10,r4
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831d53bc
	if (!cr0.eq) goto loc_831D53BC;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831D53BC:
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// cmplwi cr6,r21,10000
	cr6.compare<uint32_t>(r21.u32, 10000, xer);
	// ble cr6,0x831d515c
	if (!cr6.gt) goto loc_831D515C;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D53D4:
	// lwz r10,976(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 976);
	// addi r11,r27,972
	r11.s64 = r27.s64 + 972;
	// rotlwi r11,r30,0
	r11.u64 = rotl32(r30.u32, 0);
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// stw r30,976(r27)
	PPC_STORE_U32(r27.u32 + 976, r30.u32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r31,976(r27)
	PPC_STORE_U32(r27.u32 + 976, r31.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c0c
	return;
}

PPC_WEAK_FUNC(sub_831D50E0) {
	__imp__sub_831D50E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D5400) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// li r5,38
	ctx.r5.s64 = 38;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// lwz r21,28(r24)
	r21.u64 = PPC_LOAD_U32(r24.u32 + 28);
	// mr r22,r6
	r22.u64 = ctx.r6.u64;
	// mr r20,r7
	r20.u64 = ctx.r7.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r27,r24
	r27.u64 = r24.u64;
	// addi r26,r30,4
	r26.s64 = r30.s64 + 4;
	// ori r10,r30,1
	ctx.r10.u64 = r30.u64 | 1;
	// ori r11,r26,1
	r11.u64 = r26.u64 | 1;
	// clrlwi. r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bne 0x831d5474
	if (!cr0.eq) goto loc_831D5474;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d5474
	if (cr0.eq) goto loc_831D5474;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d5480
	if (!cr6.gt) goto loc_831D5480;
loc_831D5474:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D5480:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r24,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r24.u32);
loc_831D5498:
	// lwz r29,0(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// li r28,0
	r28.s64 = 0;
loc_831D54A0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d5608
	if (cr6.eq) goto loc_831D5608;
	// lwz r31,12(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplw cr6,r31,r25
	cr6.compare<uint32_t>(r31.u32, r25.u32, xer);
	// bne cr6,0x831d54d0
	if (!cr6.eq) goto loc_831D54D0;
	// cmplw cr6,r27,r24
	cr6.compare<uint32_t>(r27.u32, r24.u32, xer);
	// bne cr6,0x831d54c4
	if (!cr6.eq) goto loc_831D54C4;
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d55f8
	if (cr0.eq) goto loc_831D55F8;
loc_831D54C4:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D54D0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8313c7b8
	sub_8313C7B8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d55f8
	if (cr0.eq) goto loc_831D55F8;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bne cr6,0x831d55f8
	if (!cr6.eq) goto loc_831D55F8;
	// clrlwi. r11,r20,24
	r11.u64 = r20.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5504
	if (cr0.eq) goto loc_831D5504;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83145c60
	sub_83145C60(ctx, base);
	// b 0x831d5530
	goto loc_831D5530;
loc_831D5504:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_831D5508:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d5600
	if (!cr0.eq) goto loc_831D5600;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-40
	xer.ca = r11.u32 > 39;
	r11.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5600
	if (cr0.eq) goto loc_831D5600;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x831d5508
	if (!cr6.eq) goto loc_831D5508;
	// li r3,1
	ctx.r3.s64 = 1;
loc_831D5530:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d55f8
	if (cr0.eq) goto loc_831D55F8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// li r28,1
	r28.s64 = 1;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
loc_831D5548:
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d5578
	if (!cr6.eq) goto loc_831D5578;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d5568
	if (cr0.eq) goto loc_831D5568;
	// li r11,0
	r11.s64 = 0;
loc_831D5568:
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// li r11,1
	r11.s64 = 1;
	// beq cr6,0x831d557c
	if (cr6.eq) goto loc_831D557C;
loc_831D5578:
	// li r11,0
	r11.s64 = 0;
loc_831D557C:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d55a4
	if (!cr0.eq) goto loc_831D55A4;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83149918
	sub_83149918(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d5548
	if (!cr6.eq) goto loc_831D5548;
	// ori r11,r31,1
	r11.u64 = r31.u64 | 1;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_831D55A4:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d55d4
	if (!cr0.eq) goto loc_831D55D4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d55d4
	if (cr0.eq) goto loc_831D55D4;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d55e0
	if (!cr6.gt) goto loc_831D55E0;
loc_831D55D4:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D55E0:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831D55F8:
	// lwz r29,4(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// b 0x831d54a0
	goto loc_831D54A0;
loc_831D5600:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d5530
	goto loc_831D5530;
loc_831D5608:
	// clrlwi. r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d56dc
	if (!cr0.eq) goto loc_831D56DC;
	// rlwinm r11,r27,0,0,30
	r11.u64 = rotl64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFE;
	// rlwinm r10,r25,0,0,30
	ctx.r10.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r7,r10,-36
	ctx.r7.s64 = ctx.r10.s64 + -36;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r5,36(r6)
	PPC_STORE_U32(ctx.r6.u32 + 36, ctx.r5.u32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r5,r5,0,0,30
	ctx.r5.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r6,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r6.u32);
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r6,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r6.u32);
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwinm r11,r11,0,2,0
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r11,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r11.u32);
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5688
	if (cr0.eq) goto loc_831D5688;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x831d5694
	goto loc_831D5694;
loc_831D5688:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_831D5694:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831d56dc
	if (!cr0.eq) goto loc_831D56DC;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_831D56C8:
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831D56DC:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d5750
	if (!cr0.eq) goto loc_831D5750;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d5750
	if (cr0.eq) goto loc_831D5750;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r4
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d574c
	if (cr0.eq) goto loc_831D574C;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831d56dc
	if (!cr0.eq) goto loc_831D56DC;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// b 0x831d56c8
	goto loc_831D56C8;
loc_831D574C:
	// mr r27,r11
	r27.u64 = r11.u64;
loc_831D5750:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d5764
	if (!cr0.eq) goto loc_831D5764;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x831d5498
	if (!cr0.eq) goto loc_831D5498;
loc_831D5764:
	// rlwinm r11,r24,0,0,30
	r11.u64 = rotl64(r24.u32 | (r24.u64 << 32), 0) & 0xFFFFFFFE;
	// clrlwi. r10,r22,24
	ctx.r10.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,36(r10)
	PPC_STORE_U32(ctx.r10.u32 + 36, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// rlwinm r10,r25,0,0,30
	ctx.r10.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// beq 0x831d57c8
	if (cr0.eq) goto loc_831D57C8;
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r7,r10,-36
	ctx.r7.s64 = ctx.r10.s64 + -36;
	// stw r6,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r6.u32);
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// b 0x831d57ec
	goto loc_831D57EC;
loc_831D57C8:
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// addi r8,r10,4
	ctx.r8.s64 = ctx.r10.s64 + 4;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,36(r6)
	PPC_STORE_U32(ctx.r6.u32 + 36, ctx.r9.u32);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// stw r7,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r7.u32);
loc_831D57EC:
	// lwz r10,8(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// addi r11,r23,972
	r11.s64 = r23.s64 + 972;
	// rlwinm r11,r10,0,2,0
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r11,8(r24)
	PPC_STORE_U32(r24.u32 + 8, r11.u32);
	// lwz r11,976(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 976);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// stw r30,976(r23)
	PPC_STORE_U32(r23.u32 + 976, r30.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c18
	return;
}

PPC_WEAK_FUNC(sub_831D5400) {
	__imp__sub_831D5400(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D5810) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x831d5844
	if (cr6.eq) goto loc_831D5844;
loc_831D583C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d58d0
	goto loc_831D58D0;
loc_831D5844:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8313c7b8
	sub_8313C7B8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d583c
	if (cr0.eq) goto loc_831D583C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8313c7b8
	sub_8313C7B8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d586c
	if (!cr0.eq) goto loc_831D586C;
loc_831D5864:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d58d0
	goto loc_831D58D0;
loc_831D586C:
	// clrlwi. r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5884
	if (cr0.eq) goto loc_831D5884;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83145c60
	sub_83145C60(ctx, base);
	// b 0x831d58b0
	goto loc_831D58B0;
loc_831D5884:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_831D5888:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d58d8
	if (!cr0.eq) goto loc_831D58D8;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-40
	xer.ca = r11.u32 > 39;
	r11.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d58d8
	if (cr0.eq) goto loc_831D58D8;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d5888
	if (!cr6.eq) goto loc_831D5888;
	// li r3,1
	ctx.r3.s64 = 1;
loc_831D58B0:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d5864
	if (!cr0.eq) goto loc_831D5864;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831d50e0
	sub_831D50E0(ctx, base);
loc_831D58D0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_831D58D8:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d58b0
	goto loc_831D58B0;
}

PPC_WEAK_FUNC(sub_831D5810) {
	__imp__sub_831D5810(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D58E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,28(r4)
	r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// lwz r29,64(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 64);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d5bac
	if (cr6.eq) goto loc_831D5BAC;
	// li r26,1
	r26.s64 = 1;
loc_831D590C:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831d5958
	if (cr6.eq) goto loc_831D5958;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// beq cr6,0x831d594c
	if (cr6.eq) goto loc_831D594C;
	// lwz r11,48(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// lwz r10,40(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 40);
	// clrlwi r9,r11,13
	ctx.r9.u64 = r11.u32 & 0x7FFFF;
	// rlwinm r11,r9,27,5,31
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// slw r9,r26,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r9.u8 & 0x3F));
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// and. r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// bne 0x831d5950
	if (!cr0.eq) goto loc_831D5950;
loc_831D594C:
	// li r11,0
	r11.s64 = 0;
loc_831D5950:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d5bac
	if (!cr0.eq) goto loc_831D5BAC;
loc_831D5958:
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// rlwinm. r11,r11,10,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 10) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d59d8
	if (cr0.eq) goto loc_831D59D8;
	// lwz r11,112(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 112);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// rlwinm. r10,r10,10,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d59a0
	if (cr0.eq) goto loc_831D59A0;
	// b 0x831d5984
	goto loc_831D5984;
loc_831D5978:
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// rlwinm. r10,r10,0,9,9
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d5990
	if (cr0.eq) goto loc_831D5990;
loc_831D5984:
	// lwz r11,80(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d5978
	if (!cr6.eq) goto loc_831D5978;
loc_831D5990:
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// rlwinm. r10,r10,10,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d5984
	if (!cr0.eq) goto loc_831D5984;
	// stw r11,112(r30)
	PPC_STORE_U32(r30.u32 + 112, r11.u32);
loc_831D59A0:
	// lwz r31,112(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 112);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x83123cb8
	sub_83123CB8(ctx, base);
	// mr. r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x831d59f8
	if (cr0.eq) goto loc_831D59F8;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm. r10,r11,15,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d59f8
	if (cr0.eq) goto loc_831D59F8;
	// rlwinm. r11,r11,6,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d59d8
	if (!cr0.eq) goto loc_831D59D8;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831d7c10
	sub_831D7C10(ctx, base);
loc_831D59D8:
	// lbz r11,76(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 76);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5aec
	if (cr0.eq) goto loc_831D5AEC;
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// rlwinm. r10,r10,10,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d5ac4
	if (cr0.eq) goto loc_831D5AC4;
	// b 0x831d5aa8
	goto loc_831D5AA8;
loc_831D59F8:
	// lwz r31,96(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d59d8
	if (cr6.eq) goto loc_831D59D8;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,6,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d59d8
	if (!cr0.eq) goto loc_831D59D8;
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// beq cr6,0x831d5a78
	if (cr6.eq) goto loc_831D5A78;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d5a50
	if (!cr0.eq) goto loc_831D5A50;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d5a50
	if (cr0.eq) goto loc_831D5A50;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d5a5c
	if (!cr6.gt) goto loc_831D5A5C;
loc_831D5A50:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D5A5C:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
	// b 0x831d59d8
	goto loc_831D59D8;
loc_831D5A78:
	// lwz r31,0(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_831D5A7C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d59d8
	if (cr6.eq) goto loc_831D59D8;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831d7110
	sub_831D7110(ctx, base);
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// b 0x831d5a7c
	goto loc_831D5A7C;
loc_831D5A9C:
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// rlwinm. r10,r10,0,9,9
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d5ab4
	if (cr0.eq) goto loc_831D5AB4;
loc_831D5AA8:
	// lwz r11,80(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d5a9c
	if (!cr6.eq) goto loc_831D5A9C;
loc_831D5AB4:
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// rlwinm. r10,r10,10,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d5aa8
	if (!cr0.eq) goto loc_831D5AA8;
	// stw r11,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r11.u32);
loc_831D5AC4:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r4,108(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// bl 0x83123cb8
	sub_83123CB8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm. r11,r11,6,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d5aec
	if (!cr0.eq) goto loc_831D5AEC;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831d7c10
	sub_831D7C10(ctx, base);
loc_831D5AEC:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d5b08
	if (cr6.eq) goto loc_831D5B08;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// bne cr6,0x831d5b0c
	if (!cr6.eq) goto loc_831D5B0C;
loc_831D5B08:
	// li r11,0
	r11.s64 = 0;
loc_831D5B0C:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5b60
	if (cr0.eq) goto loc_831D5B60;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123cb8
	sub_83123CB8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm r11,r10,25,25,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,86
	cr6.compare<uint32_t>(r11.u32, 86, xer);
	// beq cr6,0x831d5b40
	if (cr6.eq) goto loc_831D5B40;
	// cmplwi cr6,r11,87
	cr6.compare<uint32_t>(r11.u32, 87, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x831d5b44
	if (!cr6.eq) goto loc_831D5B44;
loc_831D5B40:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_831D5B44:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d5b60
	if (!cr0.eq) goto loc_831D5B60;
	// rlwinm. r11,r10,6,31,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d5b60
	if (!cr0.eq) goto loc_831D5B60;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831d7c10
	sub_831D7C10(ctx, base);
loc_831D5B60:
	// lwz r11,52(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 52);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d5bac
	if (cr6.eq) goto loc_831D5BAC;
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// lwz r9,40(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 40);
	// clrlwi r8,r10,13
	ctx.r8.u64 = ctx.r10.u32 & 0x7FFFF;
	// rlwinm r10,r8,27,5,31
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r8,r8,27
	ctx.r8.u64 = ctx.r8.u32 & 0x1F;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// slw r8,r26,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r8.u8 & 0x3F));
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// and. r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d5b9c
	if (cr0.eq) goto loc_831D5B9C;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_831D5B9C:
	// lwz r29,64(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x831d590c
	if (!cr6.eq) goto loc_831D590C;
loc_831D5BAC:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831D58E0) {
	__imp__sub_831D58E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D5BB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stfd f30,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, f30.u64);
	// stfd f31,-112(r1)
	PPC_STORE_U64(ctx.r1.u32 + -112, f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// bl 0x831d0710
	sub_831D0710(ctx, base);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// li r20,1
	r20.s64 = 1;
	// rlwinm r11,r11,31,1,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	// and r11,r11,r3
	r11.u64 = r11.u64 & ctx.r3.u64;
	// clrlwi. r28,r11,28
	r28.u64 = r11.u32 & 0xF;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x831d5c84
	if (cr0.eq) goto loc_831D5C84;
	// li r29,0
	r29.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// addi r30,r1,96
	r30.s64 = ctx.r1.s64 + 96;
loc_831D5C14:
	// slw r11,r20,r29
	r11.u64 = r29.u8 & 0x20 ? 0 : (r20.u32 << (r29.u8 & 0x3F));
	// and. r11,r11,r28
	r11.u64 = r11.u64 & r28.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d5c70
	if (cr0.eq) goto loc_831D5C70;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// lfd f1,0(r30)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// rlwinm r9,r31,29,3,29
	ctx.r9.u64 = rotl64(r31.u32 | (r31.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// slw r11,r10,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (r11.u8 & 0x3F));
	// lwzx r10,r9,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// clrlwi r9,r31,27
	ctx.r9.u64 = r31.u32 & 0x1F;
	// li r8,-1
	ctx.r8.s64 = -1;
	// and r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	// slw r10,r8,r9
	ctx.r10.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r9.u8 & 0x3F));
	// and r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// srw r4,r11,r9
	ctx.r4.u64 = ctx.r9.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r9.u8 & 0x3F));
	// bl 0x831ca960
	sub_831CA960(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x831d5d88
	if (cr6.eq) goto loc_831D5D88;
loc_831D5C70:
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// cmplwi cr6,r31,8
	cr6.compare<uint32_t>(r31.u32, 8, xer);
	// blt cr6,0x831d5c14
	if (cr6.lt) goto loc_831D5C14;
loc_831D5C84:
	// clrlwi. r11,r26,24
	r11.u64 = r26.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d64b8
	if (cr0.eq) goto loc_831D64B8;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x831d64b8
	if (!cr6.eq) goto loc_831D64B8;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// not r10,r11
	ctx.r10.u64 = ~r11.u64;
	// rlwinm. r29,r10,31,28,31
	r29.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0xF;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x831d64b8
	if (cr0.eq) goto loc_831D64B8;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f0,3080(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3080);
	f0.f64 = double(temp.f32);
	// lfs f30,3084(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 3084);
	f30.f64 = double(temp.f32);
	// fcmpu cr6,f31,f0
	cr6.compare(f31.f64, f0.f64);
	// beq cr6,0x831d5cc4
	if (cr6.eq) goto loc_831D5CC4;
	// fcmpu cr6,f31,f30
	cr6.compare(f31.f64, f30.f64);
	// bne cr6,0x831d5cd8
	if (!cr6.eq) goto loc_831D5CD8;
loc_831D5CC4:
	// rlwinm r10,r11,25,25,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r10,97
	cr6.compare<uint32_t>(ctx.r10.u32, 97, xer);
	// beq cr6,0x831d5d4c
	if (cr6.eq) goto loc_831D5D4C;
	// cmplwi cr6,r10,96
	cr6.compare<uint32_t>(ctx.r10.u32, 96, xer);
	// beq cr6,0x831d5d4c
	if (cr6.eq) goto loc_831D5D4C;
loc_831D5CD8:
	// rlwinm r10,r11,25,25,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r10,13
	cr6.compare<uint32_t>(ctx.r10.u32, 13, xer);
	// beq cr6,0x831d5cf4
	if (cr6.eq) goto loc_831D5CF4;
	// cmplwi cr6,r10,14
	cr6.compare<uint32_t>(ctx.r10.u32, 14, xer);
	// beq cr6,0x831d5cf4
	if (cr6.eq) goto loc_831D5CF4;
	// cmplwi cr6,r10,15
	cr6.compare<uint32_t>(ctx.r10.u32, 15, xer);
	// bne cr6,0x831d64b8
	if (!cr6.eq) goto loc_831D64B8;
loc_831D5CF4:
	// rlwinm. r11,r11,9,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 9) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d64b8
	if (!cr0.eq) goto loc_831D64B8;
	// lwz r10,48(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,16000
	cr6.compare<uint32_t>(r11.u32, 16000, xer);
	// bne cr6,0x831d64b8
	if (!cr6.eq) goto loc_831D64B8;
	// lwz r11,52(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 52);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r9,8(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// rlwinm r9,r9,0,18,24
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r9,16000
	cr6.compare<uint32_t>(ctx.r9.u32, 16000, xer);
	// bne cr6,0x831d64b8
	if (!cr6.eq) goto loc_831D64B8;
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// bge cr6,0x831d5d4c
	if (!cr6.lt) goto loc_831D5D4C;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r10,r10,31,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d64b8
	if (!cr0.eq) goto loc_831D64B8;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,31,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d64b8
	if (!cr0.eq) goto loc_831D64B8;
loc_831D5D4C:
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
loc_831D5D50:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d5d98
	if (cr6.eq) goto loc_831D5D98;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831d5d80
	if (cr6.eq) goto loc_831D5D80;
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r9,r9,0,18,24
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r9,14080
	cr6.compare<uint32_t>(ctx.r9.u32, 14080, xer);
	// bne cr6,0x831d5d80
	if (!cr6.eq) goto loc_831D5D80;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r9,r9,0,4,6
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831d5d90
	if (!cr0.eq) goto loc_831D5D90;
loc_831D5D80:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831d5d50
	goto loc_831D5D50;
loc_831D5D88:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x831d64bc
	goto loc_831D64BC;
loc_831D5D90:
	// mr r21,r10
	r21.u64 = ctx.r10.u64;
	// b 0x831d5d9c
	goto loc_831D5D9C;
loc_831D5D98:
	// li r21,0
	r21.s64 = 0;
loc_831D5D9C:
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x831d5e40
	if (cr6.eq) goto loc_831D5E40;
	// li r30,0
	r30.s64 = 0;
	// addi r31,r21,44
	r31.s64 = r21.s64 + 44;
loc_831D5DB0:
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// rlwinm r11,r11,13,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bge cr6,0x831d5e1c
	if (!cr6.lt) goto loc_831D5E1C;
	// lwz r24,0(r31)
	r24.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x831cc840
	sub_831CC840(ctx, base);
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,16000
	cr6.compare<uint32_t>(r11.u32, 16000, xer);
	// bne cr6,0x831d5e10
	if (!cr6.eq) goto loc_831D5E10;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// bl 0x831cab88
	sub_831CAB88(ctx, base);
	// fcmpu cr6,f31,f1
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, ctx.f1.f64);
	// beq cr6,0x831d5e24
	if (cr6.eq) goto loc_831D5E24;
loc_831D5E10:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// b 0x831d5db0
	goto loc_831D5DB0;
loc_831D5E1C:
	// li r24,0
	r24.s64 = 0;
	// b 0x831d5e2c
	goto loc_831D5E2C;
loc_831D5E24:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x831d5e40
	if (!cr6.eq) goto loc_831D5E40;
loc_831D5E2C:
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// lis r10,32
	ctx.r10.s64 = 2097152;
	// rlwinm r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x831d64b8
	if (cr6.eq) goto loc_831D64B8;
loc_831D5E40:
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r4,97
	cr6.compare<uint32_t>(ctx.r4.u32, 97, xer);
	// beq cr6,0x831d606c
	if (cr6.eq) goto loc_831D606C;
	// cmplwi cr6,r4,96
	cr6.compare<uint32_t>(ctx.r4.u32, 96, xer);
	// beq cr6,0x831d606c
	if (cr6.eq) goto loc_831D606C;
	// addi r10,r29,-1
	ctx.r10.s64 = r29.s64 + -1;
	// andc r10,r29,r10
	ctx.r10.u64 = r29.u64 & ~ctx.r10.u64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// subfic r23,r10,31
	xer.ca = ctx.r10.u32 <= 31;
	r23.s64 = 31 - ctx.r10.s64;
	// slw r10,r20,r23
	ctx.r10.u64 = r23.u8 & 0x20 ? 0 : (r20.u32 << (r23.u8 & 0x3F));
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// rlwimi r10,r11,0,31,26
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFFFFE1) | (ctx.r10.u64 & 0x1E);
	// rlwinm r11,r10,0,0,17
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFC000;
	// addi r11,r11,16384
	r11.s64 = r11.s64 + 16384;
	// rlwimi r11,r10,0,18,14
	r11.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFFFFFFE3FFF) | (r11.u64 & 0x1C000);
	// stw r11,8(r25)
	PPC_STORE_U32(r25.u32 + 8, r11.u32);
	// lwz r11,44(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 44);
	// lwz r31,48(r25)
	r31.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// lwz r30,52(r25)
	r30.u64 = PPC_LOAD_U32(r25.u32 + 52);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r10,7,29,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// cmplw cr6,r23,r9
	cr6.compare<uint32_t>(r23.u32, ctx.r9.u32, xer);
	// blt cr6,0x831d5ee0
	if (cr6.lt) goto loc_831D5EE0;
	// lis r9,512
	ctx.r9.s64 = 33554432;
	// rlwinm r8,r10,0,0,6
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFE000000;
	// add r8,r8,r9
	ctx.r8.u64 = ctx.r8.u64 + ctx.r9.u64;
	// rlwimi r8,r10,0,7,3
	ctx.r8.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFFFF1FFFFFF) | (ctx.r8.u64 & 0xE000000);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r8,r10,0,0,6
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFE000000;
	// add r8,r8,r9
	ctx.r8.u64 = ctx.r8.u64 + ctx.r9.u64;
	// rlwimi r8,r10,0,7,3
	ctx.r8.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFFFF1FFFFFF) | (ctx.r8.u64 & 0xE000000);
	// stw r8,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r8.u32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r8,r10,0,0,6
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFE000000;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// rlwimi r9,r10,0,7,3
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFFFF1FFFFFF) | (ctx.r9.u64 & 0xE000000);
	// stw r9,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r9.u32);
loc_831D5EE0:
	// not r10,r29
	ctx.r10.u64 = ~r29.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r23,1,0,30
	ctx.r8.u64 = rotl64(r23.u32 | (r23.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r7,r10,-1
	ctx.r7.s64 = ctx.r10.s64 + -1;
	// rlwinm r6,r9,27,24,31
	ctx.r6.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0xFF;
	// andc r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r7.u64;
	// li r7,3
	ctx.r7.s64 = 3;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// slw r7,r7,r8
	ctx.r7.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r8.u8 & 0x3F));
	// subfic r10,r10,31
	xer.ca = ctx.r10.u32 <= 31;
	ctx.r10.s64 = 31 - ctx.r10.s64;
	// not r7,r7
	ctx.r7.u64 = ~ctx.r7.u64;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r7,r7,5,0,26
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// srw r10,r6,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r6.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// and r7,r7,r9
	ctx.r7.u64 = ctx.r7.u64 & ctx.r9.u64;
	// slw r10,r10,r8
	ctx.r10.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r10,r9,0,27,18
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 0) & 0xFFFFFFFFFFFFE01F) | (ctx.r10.u64 & 0x1FE0);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// bl 0x831499c8
	sub_831499C8(ctx, base);
	// rlwinm r28,r23,3,0,28
	r28.u64 = rotl64(r23.u32 | (r23.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r29,r1,96
	r29.s64 = ctx.r1.s64 + 96;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r27,88(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// rlwinm r4,r11,7,29,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 7) & 0x7;
	// stfdx f31,r28,r29
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r28.u32 + r29.u32, f31.u64);
	// bl 0x831d0518
	sub_831D0518(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// b 0x831d5f90
	goto loc_831D5F90;
loc_831D5F88:
	// addi r10,r9,8
	ctx.r10.s64 = ctx.r9.s64 + 8;
	// lwz r9,8(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
loc_831D5F90:
	// cmplw cr6,r9,r31
	cr6.compare<uint32_t>(ctx.r9.u32, r31.u32, xer);
	// bne cr6,0x831d5f88
	if (!cr6.eq) goto loc_831D5F88;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r26,57
	r26.s64 = 57;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
	// stw r31,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r31.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwimi r10,r8,7,29,29
	ctx.r10.u64 = (rotl32(ctx.r8.u32, 7) & 0x4) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFFB);
	// rlwimi r10,r8,7,19,26
	ctx.r10.u64 = (rotl32(ctx.r8.u32, 7) & 0x1FE0) | (ctx.r10.u64 & 0xFFFFFFFFFFFFE01F);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// bl 0x831499c8
	sub_831499C8(ctx, base);
	// stfdx f31,r28,r29
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r28.u32 + r29.u32, f31.u64);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// rlwinm r4,r11,7,29,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 7) & 0x7;
	// bl 0x831d0518
	sub_831D0518(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x831d6008
	goto loc_831D6008;
loc_831D6000:
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_831D6008:
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x831d6000
	if (!cr6.eq) goto loc_831D6000;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r30.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwimi r11,r26,7,29,29
	r11.u64 = (rotl32(r26.u32, 7) & 0x4) | (r11.u64 & 0xFFFFFFFFFFFFFFFB);
	// rlwimi r11,r26,7,19,26
	r11.u64 = (rotl32(r26.u32, 7) & 0x1FE0) | (r11.u64 & 0xFFFFFFFFFFFFE01F);
	// stw r3,12(r30)
	PPC_STORE_U32(r30.u32 + 12, ctx.r3.u32);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83141040
	sub_83141040(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// oris r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 16777216;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r3,12(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// bl 0x83141040
	sub_83141040(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// oris r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 16777216;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// b 0x831d6164
	goto loc_831D6164;
loc_831D606C:
	// addi r10,r29,-1
	ctx.r10.s64 = r29.s64 + -1;
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// andc r31,r29,r10
	r31.u64 = r29.u64 & ~ctx.r10.u64;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bne cr6,0x831d60e8
	if (!cr6.eq) goto loc_831D60E8;
	// cmplwi cr6,r4,97
	cr6.compare<uint32_t>(ctx.r4.u32, 97, xer);
	// bne cr6,0x831d60bc
	if (!cr6.eq) goto loc_831D60BC;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r25,-24
	r11.s64 = r25.s64 + -24;
	// not r9,r31
	ctx.r9.u64 = ~r31.u64;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// li r8,-241
	ctx.r8.s64 = -241;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// rlwimi r8,r9,4,24,27
	ctx.r8.u64 = (rotl32(ctx.r9.u32, 4) & 0xF0) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFF0F);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwimi r10,r9,0,0,27
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 0) & 0xFFFFFFF0) | (ctx.r10.u64 & 0xFFFFFFFF0000000F);
	// and r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	// b 0x831d6138
	goto loc_831D6138;
loc_831D60BC:
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r25,-20
	r11.s64 = r25.s64 + -20;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// not r9,r31
	ctx.r9.u64 = ~r31.u64;
	// ori r10,r10,4095
	ctx.r10.u64 = ctx.r10.u64 | 4095;
	// rlwimi r10,r9,12,16,19
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 12) & 0xF000) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0FFF);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwimi r9,r31,8,20,23
	ctx.r9.u64 = (rotl32(r31.u32, 8) & 0xF00) | (ctx.r9.u64 & 0xFFFFFFFFFFFFF0FF);
loc_831D60E0:
	// and r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ctx.r10.u64;
	// b 0x831d6138
	goto loc_831D6138;
loc_831D60E8:
	// cmplwi cr6,r4,97
	cr6.compare<uint32_t>(ctx.r4.u32, 97, xer);
	// bne cr6,0x831d6114
	if (!cr6.eq) goto loc_831D6114;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r25,-24
	r11.s64 = r25.s64 + -24;
	// li r9,-16
	ctx.r9.s64 = -16;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// not r10,r31
	ctx.r10.u64 = ~r31.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwimi r9,r31,4,24,27
	ctx.r9.u64 = (rotl32(r31.u32, 4) & 0xF0) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFF0F);
	// b 0x831d60e0
	goto loc_831D60E0;
loc_831D6114:
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r25,-20
	r11.s64 = r25.s64 + -20;
	// not r10,r31
	ctx.r10.u64 = ~r31.u64;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// li r9,-3841
	ctx.r9.s64 = -3841;
	// rlwimi r9,r10,8,20,23
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 8) & 0xF00) | (ctx.r9.u64 & 0xFFFFFFFFFFFFF0FF);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwimi r10,r31,12,16,19
	ctx.r10.u64 = (rotl32(r31.u32, 12) & 0xF000) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0FFF);
	// and r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 & ctx.r9.u64;
loc_831D6138:
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// rlwinm r10,r31,1,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// cntlzw r9,r31
	ctx.r9.u64 = r31.u32 == 0 ? 32 : __builtin_clz(r31.u32);
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// rlwimi r10,r11,0,31,26
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFFFFE1) | (ctx.r10.u64 & 0x1E);
	// subfic r23,r9,31
	xer.ca = ctx.r9.u32 <= 31;
	r23.s64 = 31 - ctx.r9.s64;
	// rlwinm r11,r10,0,0,17
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFC000;
	// addi r11,r11,16384
	r11.s64 = r11.s64 + 16384;
	// rlwimi r11,r10,0,18,14
	r11.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFFFFFFE3FFF) | (r11.u64 & 0x1C000);
	// stw r11,8(r25)
	PPC_STORE_U32(r25.u32 + 8, r11.u32);
loc_831D6164:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831d61d4
	if (cr6.eq) goto loc_831D61D4;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// lwz r4,12(r24)
	ctx.r4.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// bl 0x8314b470
	sub_8314B470(ctx, base);
	// lwz r11,12(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x831d6190
	goto loc_831D6190;
loc_831D6188:
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_831D6190:
	// cmplw cr6,r10,r24
	cr6.compare<uint32_t>(ctx.r10.u32, r24.u32, xer);
	// bne cr6,0x831d6188
	if (!cr6.eq) goto loc_831D6188;
	// lwz r10,8(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r9,r23,5,22,26
	ctx.r9.u64 = rotl64(r23.u32 | (r23.u64 << 32), 5) & 0x3E0;
	// rlwinm r9,r9,0,25,23
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
	// ori r9,r9,7296
	ctx.r9.u64 = ctx.r9.u64 | 7296;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// stw r11,8(r24)
	PPC_STORE_U32(r24.u32 + 8, r11.u32);
	// stw r24,4(r25)
	PPC_STORE_U32(r25.u32 + 4, r24.u32);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// rlwinm r11,r11,0,0,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// rlwinm r11,r11,0,24,21
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFCFF;
	// stw r25,12(r24)
	PPC_STORE_U32(r24.u32 + 12, r25.u32);
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
	// b 0x831d62b4
	goto loc_831D62B4;
loc_831D61D4:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x831d62b4
	if (cr6.eq) goto loc_831D62B4;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x83161178
	sub_83161178(ctx, base);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x831618d0
	sub_831618D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x83161178
	sub_83161178(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// oris r11,r11,256
	r11.u64 = r11.u64 | 16777216;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// rlwinm. r11,r11,9,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 9) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d62a0
	if (cr0.eq) goto loc_831D62A0;
	// lwz r3,660(r22)
	ctx.r3.u64 = PPC_LOAD_U32(r22.u32 + 660);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831d6294
	if (cr6.eq) goto loc_831D6294;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d6258
	if (!cr0.eq) goto loc_831D6258;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6258
	if (cr0.eq) goto loc_831D6258;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831d6264
	if (!cr6.gt) goto loc_831D6264;
loc_831D6258:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831D6264:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r31,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r31.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// oris r11,r11,128
	r11.u64 = r11.u64 | 8388608;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,16(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// sth r11,18(r31)
	PPC_STORE_U16(r31.u32 + 18, r11.u16);
	// b 0x831d62a0
	goto loc_831D62A0;
loc_831D6294:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x831617e8
	sub_831617E8(ctx, base);
loc_831D62A0:
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x831d4770
	sub_831D4770(ctx, base);
loc_831D62B4:
	// lwz r10,708(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 708);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831d64b0
	if (cr6.eq) goto loc_831D64B0;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// rlwinm. r11,r11,9,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 9) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d64b0
	if (cr0.eq) goto loc_831D64B0;
	// lhz r11,18(r25)
	r11.u64 = PPC_LOAD_U16(r25.u32 + 18);
	// li r31,0
	r31.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// add r30,r11,r23
	r30.u64 = r11.u64 + r23.u64;
	// rlwinm r11,r30,2,0,29
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r25,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r25.u32);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// rlwinm r27,r11,31,28,31
	r27.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0xF;
loc_831D62EC:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d6314
	if (cr6.eq) goto loc_831D6314;
	// addi r11,r27,-1
	r11.s64 = r27.s64 + -1;
	// lhz r10,18(r25)
	ctx.r10.u64 = PPC_LOAD_U16(r25.u32 + 18);
	// andc r11,r27,r11
	r11.u64 = r27.u64 & ~r11.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// addi r4,r11,31
	ctx.r4.s64 = r11.s64 + 31;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// b 0x831d631c
	goto loc_831D631C;
loc_831D6314:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r11,0
	r11.s64 = 0;
loc_831D631C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d6398
	if (cr6.eq) goto loc_831D6398;
	// cmplw cr6,r30,r4
	cr6.compare<uint32_t>(r30.u32, ctx.r4.u32, xer);
	// beq cr6,0x831d6388
	if (cr6.eq) goto loc_831D6388;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x8312ea08
	sub_8312EA08(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d6350
	if (!cr6.eq) goto loc_831D6350;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x8312eed0
	sub_8312EED0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_831D6350:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x8312ee20
	sub_8312EE20(ctx, base);
	// addi r11,r3,4
	r11.s64 = ctx.r3.s64 + 4;
	// rlwinm r10,r30,29,3,28
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 29) & 0x1FFFFFF8;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// clrldi r9,r30,58
	ctx.r9.u64 = r30.u64 & 0x3F;
	// slw r8,r20,r3
	ctx.r8.u64 = ctx.r3.u8 & 0x20 ? 0 : (r20.u32 << (ctx.r3.u8 & 0x3F));
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// sld r9,r20,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x40 ? 0 : (r20.u64 << (ctx.r9.u8 & 0x7F));
	// ldx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r10.u32 + r11.u32);
	// or r28,r8,r28
	r28.u64 = ctx.r8.u64 | r28.u64;
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// stdx r9,r10,r11
	PPC_STORE_U64(ctx.r10.u32 + r11.u32, ctx.r9.u64);
loc_831D6388:
	// addi r11,r27,-1
	r11.s64 = r27.s64 + -1;
	// andc r11,r27,r11
	r11.u64 = r27.u64 & ~r11.u64;
	// subf r27,r11,r27
	r27.s64 = r27.s64 - r11.s64;
	// b 0x831d62ec
	goto loc_831D62EC;
loc_831D6398:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d63ac
	if (!cr6.eq) goto loc_831D63AC;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D63AC:
	// not r11,r28
	r11.u64 = ~r28.u64;
	// lwz r10,192(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// addi r9,r11,-1
	ctx.r9.s64 = r11.s64 + -1;
	// clrlwi r10,r10,29
	ctx.r10.u64 = ctx.r10.u32 & 0x7;
	// andc r11,r11,r9
	r11.u64 = r11.u64 & ~ctx.r9.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subfic r29,r11,31
	xer.ca = r11.u32 <= 31;
	r29.s64 = 31 - r11.s64;
	// cmplw cr6,r29,r10
	cr6.compare<uint32_t>(r29.u32, ctx.r10.u32, xer);
	// blt cr6,0x831d6400
	if (cr6.lt) goto loc_831D6400;
	// lwz r11,672(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 672);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// rlwinm r4,r11,3,0,28
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x83110880
	sub_83110880(ctx, base);
	// lwz r11,192(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// rlwinm r11,r11,2,27,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0x1C;
	// stwx r3,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r3.u32);
	// lwz r11,192(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// rlwimi r10,r11,0,0,28
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFF8) | (ctx.r10.u64 & 0xFFFFFFFF00000007);
	// stw r10,192(r31)
	PPC_STORE_U32(r31.u32 + 192, ctx.r10.u32);
loc_831D6400:
	// rlwinm r11,r29,2,0,29
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r30,29,3,28
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 29) & 0x1FFFFFF8;
	// clrldi r9,r30,58
	ctx.r9.u64 = r30.u64 & 0x3F;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// sld r9,r20,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x40 ? 0 : (r20.u64 << (ctx.r9.u8 & 0x7F));
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// ldx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r10.u32 + r11.u32);
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// stdx r9,r10,r11
	PPC_STORE_U64(ctx.r10.u32 + r11.u32, ctx.r9.u64);
	// bl 0x8312ee68
	sub_8312EE68(ctx, base);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// rlwinm r9,r11,31,28,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0xF;
loc_831D643C:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d6464
	if (cr6.eq) goto loc_831D6464;
	// addi r11,r9,-1
	r11.s64 = ctx.r9.s64 + -1;
	// lhz r10,18(r25)
	ctx.r10.u64 = PPC_LOAD_U16(r25.u32 + 18);
	// andc r11,r9,r11
	r11.u64 = ctx.r9.u64 & ~r11.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// addi r11,r11,31
	r11.s64 = r11.s64 + 31;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// b 0x831d646c
	goto loc_831D646C;
loc_831D6464:
	// li r11,0
	r11.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
loc_831D646C:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831d64b0
	if (cr6.eq) goto loc_831D64B0;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// beq cr6,0x831d64a0
	if (cr6.eq) goto loc_831D64A0;
	// addi r8,r29,4
	ctx.r8.s64 = r29.s64 + 4;
	// rlwinm r10,r11,29,3,28
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFF8;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// clrldi r11,r11,58
	r11.u64 = r11.u64 & 0x3F;
	// sld r7,r20,r11
	ctx.r7.u64 = r11.u8 & 0x40 ? 0 : (r20.u64 << (r11.u8 & 0x7F));
	// lwzx r11,r8,r31
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r31.u32);
	// ldx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r10.u32 + r11.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stdx r8,r10,r11
	PPC_STORE_U64(ctx.r10.u32 + r11.u32, ctx.r8.u64);
loc_831D64A0:
	// addi r11,r9,-1
	r11.s64 = ctx.r9.s64 + -1;
	// andc r11,r9,r11
	r11.u64 = ctx.r9.u64 & ~r11.u64;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
	// b 0x831d643c
	goto loc_831D643C;
loc_831D64B0:
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// b 0x831d64bc
	goto loc_831D64BC;
loc_831D64B8:
	// li r3,4
	ctx.r3.s64 = 4;
loc_831D64BC:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f30,-120(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// lfd f31,-112(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// b 0x82ca2c18
	return;
}

PPC_WEAK_FUNC(sub_831D5BB8) {
	__imp__sub_831D5BB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D64D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
loc_831D64E8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d6528
	if (cr6.eq) goto loc_831D6528;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831d6518
	if (cr6.eq) goto loc_831D6518;
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r9,r9,0,18,24
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r9,14080
	cr6.compare<uint32_t>(ctx.r9.u32, 14080, xer);
	// bne cr6,0x831d6518
	if (!cr6.eq) goto loc_831D6518;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r9,r9,0,4,6
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831d6520
	if (!cr0.eq) goto loc_831D6520;
loc_831D6518:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831d64e8
	goto loc_831D64E8;
loc_831D6520:
	// mr r30,r10
	r30.u64 = ctx.r10.u64;
	// b 0x831d652c
	goto loc_831D652C;
loc_831D6528:
	// li r30,0
	r30.s64 = 0;
loc_831D652C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d6694
	if (cr6.eq) goto loc_831D6694;
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
loc_831D6540:
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x831d659c
	if (cr6.eq) goto loc_831D659C;
	// lwz r11,16(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d6594
	if (cr6.eq) goto loc_831D6594;
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r11,r10,7,29,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6594
	if (cr0.eq) goto loc_831D6594;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d6590
	if (cr6.eq) goto loc_831D6590;
	// rlwinm r9,r10,27,24,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0xFF;
	// li r10,0
	ctx.r10.s64 = 0;
loc_831D6574:
	// srw r3,r9,r10
	ctx.r3.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi r3,r3,30
	ctx.r3.u64 = ctx.r3.u32 & 0x3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// slw r3,r6,r3
	ctx.r3.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r3.u8 & 0x3F));
	// or r8,r3,r8
	ctx.r8.u64 = ctx.r3.u64 | ctx.r8.u64;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// bne 0x831d6574
	if (!cr0.eq) goto loc_831D6574;
loc_831D6590:
	// or r4,r8,r4
	ctx.r4.u64 = ctx.r8.u64 | ctx.r4.u64;
loc_831D6594:
	// lwz r7,8(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// b 0x831d6540
	goto loc_831D6540;
loc_831D659C:
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r11,0
	r11.s64 = 0;
	// addi r10,r30,44
	ctx.r10.s64 = r30.s64 + 44;
	// rlwinm r8,r9,13,29,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 13) & 0x7;
loc_831D65AC:
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bge cr6,0x831d6694
	if (!cr6.lt) goto loc_831D6694;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r7,12(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r7,r28
	cr6.compare<uint32_t>(ctx.r7.u32, r28.u32, xer);
	// bne cr6,0x831d65d4
	if (!cr6.eq) goto loc_831D65D4;
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r9,r9,27,30,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x3;
	// cmpw cr6,r9,r5
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r5.s32, xer);
	// beq cr6,0x831d65e0
	if (cr6.eq) goto loc_831D65E0;
loc_831D65D4:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x831d65ac
	goto loc_831D65AC;
loc_831D65E0:
	// slw r11,r6,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r6.u32 << (r11.u8 & 0x3F));
	// and. r11,r11,r4
	r11.u64 = r11.u64 & ctx.r4.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d66a4
	if (!cr0.eq) goto loc_831D66A4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r5,652(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 652);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83176bb0
	sub_83176BB0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x831d6694
	if (cr0.eq) goto loc_831D6694;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm. r11,r11,9,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 9) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6680
	if (cr0.eq) goto loc_831D6680;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// oris r11,r11,128
	r11.u64 = r11.u64 | 8388608;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// bl 0x8312e990
	sub_8312E990(ctx, base);
	// sth r3,18(r31)
	PPC_STORE_U16(r31.u32 + 18, ctx.r3.u16);
	// lwz r3,660(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 660);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d665c
	if (!cr0.eq) goto loc_831D665C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d665c
	if (cr0.eq) goto loc_831D665C;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831d6668
	if (!cr6.gt) goto loc_831D6668;
loc_831D665C:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831D6668:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r31,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r31.u32);
loc_831D6680:
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r5,652(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 652);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831d4770
	sub_831D4770(ctx, base);
loc_831D6694:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r5,660(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 660);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83167c98
	sub_83167C98(ctx, base);
loc_831D66A4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D64D0) {
	__imp__sub_831D64D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D66B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r22,r4
	r22.u64 = ctx.r4.u64;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// addi r25,r22,4
	r25.s64 = r22.s64 + 4;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// mr r23,r8
	r23.u64 = ctx.r8.u64;
	// li r21,0
	r21.s64 = 0;
	// mr r29,r25
	r29.u64 = r25.u64;
loc_831D66E0:
	// lwz r31,0(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d6918
	if (cr6.eq) goto loc_831D6918;
	// lwz r30,16(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d68f8
	if (cr6.eq) goto loc_831D68F8;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r10,r11,0,4,6
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d68a8
	if (!cr0.eq) goto loc_831D68A8;
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r9,28(r22)
	ctx.r9.u64 = PPC_LOAD_U32(r22.u32 + 28);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// bne cr6,0x831d68f8
	if (!cr6.eq) goto loc_831D68F8;
	// rlwinm r10,r11,2,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r9,r9,27,31,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// xori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 ^ 1;
	// clrlwi. r9,r9,24
	ctx.r9.u64 = ctx.r9.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d681c
	if (cr0.eq) goto loc_831D681C;
	// rlwinm r11,r11,19,20,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0xFFF;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831d67c8
	if (cr6.lt) goto loc_831D67C8;
	// beq cr6,0x831d67b0
	if (cr6.eq) goto loc_831D67B0;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x831d67a0
	if (cr6.lt) goto loc_831D67A0;
	// beq cr6,0x831d6790
	if (cr6.eq) goto loc_831D6790;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// blt cr6,0x831d67d4
	if (cr6.lt) goto loc_831D67D4;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// beq cr6,0x831d676c
	if (cr6.eq) goto loc_831D676C;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bne cr6,0x831d690c
	if (!cr6.eq) goto loc_831D690C;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8310f980
	sub_8310F980(ctx, base);
	// b 0x831d6804
	goto loc_831D6804;
loc_831D676C:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// blt cr6,0x831d6788
	if (cr6.lt) goto loc_831D6788;
	// cmplwi cr6,r11,82
	cr6.compare<uint32_t>(r11.u32, 82, xer);
	// li r11,1
	r11.s64 = 1;
	// ble cr6,0x831d6800
	if (!cr6.gt) goto loc_831D6800;
loc_831D6788:
	// li r11,0
	r11.s64 = 0;
	// b 0x831d6800
	goto loc_831D6800;
loc_831D6790:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// addi r11,r11,-13056
	r11.s64 = r11.s64 + -13056;
	// b 0x831d67bc
	goto loc_831D67BC;
loc_831D67A0:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// addi r11,r11,-12928
	r11.s64 = r11.s64 + -12928;
	// b 0x831d67bc
	goto loc_831D67BC;
loc_831D67B0:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// addi r11,r11,-12544
	r11.s64 = r11.s64 + -12544;
loc_831D67BC:
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x831d6804
	goto loc_831D6804;
loc_831D67C8:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm. r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d67dc
	if (!cr0.eq) goto loc_831D67DC;
loc_831D67D4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d6804
	goto loc_831D6804;
loc_831D67DC:
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,30
	cr6.compare<uint32_t>(r11.u32, 30, xer);
	// beq cr6,0x831d67fc
	if (cr6.eq) goto loc_831D67FC;
	// cmplwi cr6,r11,55
	cr6.compare<uint32_t>(r11.u32, 55, xer);
	// beq cr6,0x831d67fc
	if (cr6.eq) goto loc_831D67FC;
	// cmplwi cr6,r11,56
	cr6.compare<uint32_t>(r11.u32, 56, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x831d6800
	if (!cr6.eq) goto loc_831D6800;
loc_831D67FC:
	// li r11,1
	r11.s64 = 1;
loc_831D6800:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
loc_831D6804:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d68f8
	if (cr0.eq) goto loc_831D68F8;
loc_831D680C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x831d6884
	goto loc_831D6884;
loc_831D681C:
	// cntlzw r11,r10
	r11.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm. r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d680c
	if (cr0.eq) goto loc_831D680C;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm r10,r11,25,25,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// blt cr6,0x831d6844
	if (cr6.lt) goto loc_831D6844;
	// cmplwi cr6,r10,102
	cr6.compare<uint32_t>(ctx.r10.u32, 102, xer);
	// li r11,1
	r11.s64 = 1;
	// ble cr6,0x831d6848
	if (!cr6.gt) goto loc_831D6848;
loc_831D6844:
	// li r11,0
	r11.s64 = 0;
loc_831D6848:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d680c
	if (!cr0.eq) goto loc_831D680C;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14976
	cr6.compare<uint32_t>(r11.u32, 14976, xer);
	// bne cr6,0x831d6868
	if (!cr6.eq) goto loc_831D6868;
	// cmplwi cr6,r10,113
	cr6.compare<uint32_t>(ctx.r10.u32, 113, xer);
	// beq cr6,0x831d680c
	if (cr6.eq) goto loc_831D680C;
loc_831D6868:
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123d48
	sub_83123D48(ctx, base);
	// b 0x831d68f8
	goto loc_831D68F8;
loc_831D687C:
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_831D6884:
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bne cr6,0x831d687c
	if (!cr6.eq) goto loc_831D687C;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r31,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r31.u32);
	// stw r26,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r26.u32);
	// b 0x831d68cc
	goto loc_831D68CC;
loc_831D68A8:
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x831cd310
	sub_831CD310(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d68f8
	if (cr0.eq) goto loc_831D68F8;
loc_831D68CC:
	// li r21,1
	r21.s64 = 1;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x831d68ec
	if (cr6.eq) goto loc_831D68EC;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83176848
	sub_83176848(ctx, base);
	// b 0x831d68f8
	goto loc_831D68F8;
loc_831D68EC:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,6,4
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFBFFFFFF;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
loc_831D68F8:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d66e0
	if (!cr6.eq) goto loc_831D66E0;
	// addi r29,r31,8
	r29.s64 = r31.s64 + 8;
	// b 0x831d66e0
	goto loc_831D66E0;
loc_831D690C:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D6918:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x831d694c
	if (cr6.eq) goto loc_831D694C;
	// clrlwi. r11,r21,24
	r11.u64 = r21.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d694c
	if (cr0.eq) goto loc_831D694C;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831101b8
	sub_831101B8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6958
	if (cr0.eq) goto loc_831D6958;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x831d4770
	sub_831D4770(ctx, base);
loc_831D694C:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c1c
	return;
loc_831D6958:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// rlwinm. r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d696c
	if (!cr0.eq) goto loc_831D696C;
	// li r11,0
	r11.s64 = 0;
	// b 0x831d6994
	goto loc_831D6994;
loc_831D696C:
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,30
	cr6.compare<uint32_t>(r11.u32, 30, xer);
	// beq cr6,0x831d698c
	if (cr6.eq) goto loc_831D698C;
	// cmplwi cr6,r11,55
	cr6.compare<uint32_t>(r11.u32, 55, xer);
	// beq cr6,0x831d698c
	if (cr6.eq) goto loc_831D698C;
	// cmplwi cr6,r11,56
	cr6.compare<uint32_t>(r11.u32, 56, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x831d6990
	if (!cr6.eq) goto loc_831D6990;
loc_831D698C:
	// li r11,1
	r11.s64 = 1;
loc_831D6990:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
loc_831D6994:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6a7c
	if (cr0.eq) goto loc_831D6A7C;
	// lwz r30,4(r26)
	r30.u64 = PPC_LOAD_U32(r26.u32 + 4);
loc_831D69A0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d6a0c
	if (cr6.eq) goto loc_831D6A0C;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831d6a04
	if (cr6.eq) goto loc_831D6A04;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r9,r11,0,1,1
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d69cc
	if (cr0.eq) goto loc_831D69CC;
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x831d69d0
	if (cr0.eq) goto loc_831D69D0;
loc_831D69CC:
	// li r11,0
	r11.s64 = 0;
loc_831D69D0:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6a04
	if (cr0.eq) goto loc_831D6A04;
	// lwz r31,4(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
loc_831D69DC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d6a04
	if (cr6.eq) goto loc_831D6A04;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831d69fc
	if (cr6.eq) goto loc_831D69FC;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83176848
	sub_83176848(ctx, base);
loc_831D69FC:
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// b 0x831d69dc
	goto loc_831D69DC;
loc_831D6A04:
	// lwz r30,8(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// b 0x831d69a0
	goto loc_831D69A0;
loc_831D6A0C:
	// lwz r30,0(r25)
	r30.u64 = PPC_LOAD_U32(r25.u32 + 0);
loc_831D6A10:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d6a7c
	if (cr6.eq) goto loc_831D6A7C;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831d6a74
	if (cr6.eq) goto loc_831D6A74;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r9,r11,0,1,1
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d6a3c
	if (cr0.eq) goto loc_831D6A3C;
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x831d6a40
	if (cr0.eq) goto loc_831D6A40;
loc_831D6A3C:
	// li r11,0
	r11.s64 = 0;
loc_831D6A40:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6a74
	if (cr0.eq) goto loc_831D6A74;
	// lwz r31,4(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
loc_831D6A4C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d6a74
	if (cr6.eq) goto loc_831D6A74;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831d6a6c
	if (cr6.eq) goto loc_831D6A6C;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83176848
	sub_83176848(ctx, base);
loc_831D6A6C:
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// b 0x831d6a4c
	goto loc_831D6A4C;
loc_831D6A74:
	// lwz r30,8(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// b 0x831d6a10
	goto loc_831D6A10;
loc_831D6A7C:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8310f980
	sub_8310F980(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6b40
	if (cr0.eq) goto loc_831D6B40;
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// lwz r29,28(r26)
	r29.u64 = PPC_LOAD_U32(r26.u32 + 28);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d6b40
	if (!cr0.eq) goto loc_831D6B40;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d6b40
	if (cr0.eq) goto loc_831D6B40;
loc_831D6AA8:
	// lwz r11,48(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r9,40(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// clrlwi r8,r11,13
	ctx.r8.u64 = r11.u32 & 0x7FFFF;
	// rlwinm r11,r8,27,5,31
	r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r8,r8,27
	ctx.r8.u64 = ctx.r8.u32 & 0x1F;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// slw r10,r10,r8
	ctx.r10.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// and. r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6b24
	if (cr0.eq) goto loc_831D6B24;
	// lwz r31,20(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// clrlwi. r11,r31,31
	r11.u64 = r31.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d6b24
	if (!cr0.eq) goto loc_831D6B24;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x831d6b24
	if (cr0.eq) goto loc_831D6B24;
loc_831D6AEC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// bne cr6,0x831d6b0c
	if (!cr6.eq) goto loc_831D6B0C;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83176848
	sub_83176848(ctx, base);
loc_831D6B0C:
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r31,40(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// clrlwi. r11,r31,31
	r11.u64 = r31.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d6b24
	if (!cr0.eq) goto loc_831D6B24;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d6aec
	if (!cr6.eq) goto loc_831D6AEC;
loc_831D6B24:
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d6b40
	if (!cr0.eq) goto loc_831D6B40;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d6aa8
	if (!cr6.eq) goto loc_831D6AA8;
loc_831D6B40:
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83176848
	sub_83176848(ctx, base);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x831101b8
	sub_831101B8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d694c
	if (cr0.eq) goto loc_831D694C;
	// li r31,0
	r31.s64 = 0;
	// addi r30,r22,44
	r30.s64 = r22.s64 + 44;
loc_831D6B68:
	// lwz r11,8(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// rlwinm r11,r11,13,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bge cr6,0x831d694c
	if (!cr6.lt) goto loc_831D694C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r4,12(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// bl 0x83176848
	sub_83176848(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// b 0x831d6b68
	goto loc_831D6B68;
}

PPC_WEAK_FUNC(sub_831D66B0) {
	__imp__sub_831D66B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D6B98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc0
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,112(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r20,r5
	r20.u64 = ctx.r5.u64;
	// addi r29,r11,1
	r29.s64 = r11.s64 + 1;
	// li r5,38
	ctx.r5.s64 = 38;
	// stw r29,112(r3)
	PPC_STORE_U32(ctx.r3.u32 + 112, r29.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r29,-4(r31)
	PPC_STORE_U32(r31.u32 + -4, r29.u32);
	// mr r19,r6
	r19.u64 = ctx.r6.u64;
	// mr r18,r7
	r18.u64 = ctx.r7.u64;
	// mr r21,r8
	r21.u64 = ctx.r8.u64;
	// mr r23,r9
	r23.u64 = ctx.r9.u64;
	// mr r22,r31
	r22.u64 = r31.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r27,0
	r27.s64 = 0;
	// addi r28,r30,4
	r28.s64 = r30.s64 + 4;
	// ori r11,r30,1
	r11.u64 = r30.u64 | 1;
	// ori r10,r28,1
	ctx.r10.u64 = r28.u64 | 1;
	// li r25,4
	r25.s64 = 4;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// li r26,0
	r26.s64 = 0;
loc_831D6C00:
	// cmplw cr6,r31,r23
	cr6.compare<uint32_t>(r31.u32, r23.u32, xer);
	// beq cr6,0x831d6d70
	if (cr6.eq) goto loc_831D6D70;
	// lwz r24,0(r31)
	r24.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_831D6C0C:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831d6d70
	if (cr6.eq) goto loc_831D6D70;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x831cc840
	sub_831CC840(ctx, base);
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r31,84(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bne cr6,0x831d6cc8
	if (!cr6.eq) goto loc_831D6CC8;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r10,r10,0,18,24
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r10,14336
	cr6.compare<uint32_t>(ctx.r10.u32, 14336, xer);
	// bne cr6,0x831d6cc8
	if (!cr6.eq) goto loc_831D6CC8;
	// cmplw cr6,r31,r23
	cr6.compare<uint32_t>(r31.u32, r23.u32, xer);
	// beq cr6,0x831d6cc8
	if (cr6.eq) goto loc_831D6CC8;
	// lwz r11,-4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -4);
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// beq cr6,0x831d6d68
	if (cr6.eq) goto loc_831D6D68;
	// stw r29,-4(r31)
	PPC_STORE_U32(r31.u32 + -4, r29.u32);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d6ca0
	if (!cr0.eq) goto loc_831D6CA0;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d6ca0
	if (cr0.eq) goto loc_831D6CA0;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d6cac
	if (!cr6.gt) goto loc_831D6CAC;
loc_831D6CA0:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D6CAC:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
	// b 0x831d6d68
	goto loc_831D6D68;
loc_831D6CC8:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d6d5c
	if (cr6.eq) goto loc_831D6D5C;
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// bne cr6,0x831d6cec
	if (!cr6.eq) goto loc_831D6CEC;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bne cr6,0x831d6cec
	if (!cr6.eq) goto loc_831D6CEC;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r11,r25
	cr6.compare<int32_t>(r11.s32, r25.s32, xer);
	// beq cr6,0x831d6d68
	if (cr6.eq) goto loc_831D6D68;
loc_831D6CEC:
	// lwz r31,0(r22)
	r31.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// li r27,0
	r27.s64 = 0;
	// li r25,4
	r25.s64 = 4;
	// li r26,0
	r26.s64 = 0;
loc_831D6CFC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d6dfc
	if (cr6.eq) goto loc_831D6DFC;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cc840
	sub_831CC840(ctx, base);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d6de8
	if (cr6.eq) goto loc_831D6DE8;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x831d6d54
	if (!cr6.eq) goto loc_831D6D54;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bne cr6,0x831d6d54
	if (!cr6.eq) goto loc_831D6D54;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpw cr6,r11,r25
	cr6.compare<int32_t>(r11.s32, r25.s32, xer);
	// beq cr6,0x831d6df4
	if (cr6.eq) goto loc_831D6DF4;
loc_831D6D54:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d6e0c
	goto loc_831D6E0C;
loc_831D6D5C:
	// lwz r25,80(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r27,r31
	r27.u64 = r31.u64;
	// mr r26,r11
	r26.u64 = r11.u64;
loc_831D6D68:
	// lwz r24,4(r24)
	r24.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// b 0x831d6c0c
	goto loc_831D6C0C;
loc_831D6D70:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d6dfc
	if (!cr0.eq) goto loc_831D6DFC;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d6dfc
	if (cr0.eq) goto loc_831D6DFC;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r4
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831d6c00
	if (!cr0.eq) goto loc_831D6C00;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
	// b 0x831d6c00
	goto loc_831D6C00;
loc_831D6DE8:
	// lwz r27,80(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r25,84(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r26,88(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_831D6DF4:
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// b 0x831d6cfc
	goto loc_831D6CFC;
loc_831D6DFC:
	// stw r27,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r27.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r25,0(r19)
	PPC_STORE_U32(r19.u32 + 0, r25.u32);
	// stw r26,0(r18)
	PPC_STORE_U32(r18.u32 + 0, r26.u32);
loc_831D6E0C:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c10
	return;
}

PPC_WEAK_FUNC(sub_831D6B98) {
	__imp__sub_831D6B98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D6E18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// b 0x831d6ef8
	goto loc_831D6EF8;
loc_831D6E44:
	// cmplwi cr6,r11,125
	cr6.compare<uint32_t>(r11.u32, 125, xer);
	// beq cr6,0x831d6e58
	if (cr6.eq) goto loc_831D6E58;
	// cmplwi cr6,r11,124
	cr6.compare<uint32_t>(r11.u32, 124, xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// bne cr6,0x831d6e5c
	if (!cr6.eq) goto loc_831D6E5C;
loc_831D6E58:
	// li r10,1
	ctx.r10.s64 = 1;
loc_831D6E5C:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d6f00
	if (!cr0.eq) goto loc_831D6F00;
	// cmplwi cr6,r11,113
	cr6.compare<uint32_t>(r11.u32, 113, xer);
	// beq cr6,0x831d6f00
	if (cr6.eq) goto loc_831D6F00;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// beq cr6,0x831d6f00
	if (cr6.eq) goto loc_831D6F00;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x831d6f00
	if (!cr6.eq) goto loc_831D6F00;
	// clrlwi. r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6ea4
	if (cr0.eq) goto loc_831D6EA4;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83145c60
	sub_83145C60(ctx, base);
	// b 0x831d6ed0
	goto loc_831D6ED0;
loc_831D6EA4:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_831D6EA8:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d6f0c
	if (!cr0.eq) goto loc_831D6F0C;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-40
	xer.ca = r11.u32 > 39;
	r11.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6f0c
	if (cr0.eq) goto loc_831D6F0C;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d6ea8
	if (!cr6.eq) goto loc_831D6EA8;
	// li r3,1
	ctx.r3.s64 = 1;
loc_831D6ED0:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6f14
	if (cr0.eq) goto loc_831D6F14;
	// mr r11,r31
	r11.u64 = r31.u64;
	// mr r31,r30
	r31.u64 = r30.u64;
	// clrlwi r10,r29,24
	ctx.r10.u64 = r29.u32 & 0xFF;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cntlzw r11,r10
	r11.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r29,r11,27,31,31
	r29.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// rlwinm r11,r10,25,25,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x7F;
loc_831D6EF8:
	// cmplwi cr6,r11,112
	cr6.compare<uint32_t>(r11.u32, 112, xer);
	// bne cr6,0x831d6e44
	if (!cr6.eq) goto loc_831D6E44;
loc_831D6F00:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D6F04:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_831D6F0C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d6ed0
	goto loc_831D6ED0;
loc_831D6F14:
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831d50e0
	sub_831D50E0(ctx, base);
	// b 0x831d6f04
	goto loc_831D6F04;
}

PPC_WEAK_FUNC(sub_831D6E18) {
	__imp__sub_831D6E18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D6F30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// clrlwi r26,r28,24
	r26.u64 = r28.u32 & 0xFF;
loc_831D6F54:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831d6f6c
	if (cr6.eq) goto loc_831D6F6C;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83145c60
	sub_83145C60(ctx, base);
	// b 0x831d6f98
	goto loc_831D6F98;
loc_831D6F6C:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_831D6F70:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d6fbc
	if (!cr0.eq) goto loc_831D6FBC;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-40
	xer.ca = r11.u32 > 39;
	r11.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6fbc
	if (cr0.eq) goto loc_831D6FBC;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d6f70
	if (!cr6.eq) goto loc_831D6F70;
	// li r3,1
	ctx.r3.s64 = 1;
loc_831D6F98:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d6fc4
	if (cr0.eq) goto loc_831D6FC4;
	// clrlwi r10,r29,24
	ctx.r10.u64 = r29.u32 & 0xFF;
	// mr r11,r31
	r11.u64 = r31.u64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// mr r31,r30
	r31.u64 = r30.u64;
	// rlwinm r29,r10,27,31,31
	r29.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// mr r30,r11
	r30.u64 = r11.u64;
	// b 0x831d6f54
	goto loc_831D6F54;
loc_831D6FBC:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d6f98
	goto loc_831D6F98;
loc_831D6FC4:
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831d5400
	sub_831D5400(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831D6F30) {
	__imp__sub_831D6F30(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D6FE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// bl 0x8313c7b8
	sub_8313C7B8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d7078
	if (cr0.eq) goto loc_831D7078;
	// clrlwi. r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d702c
	if (cr0.eq) goto loc_831D702C;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83145c60
	sub_83145C60(ctx, base);
	// b 0x831d7058
	goto loc_831D7058;
loc_831D702C:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_831D7030:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7080
	if (!cr0.eq) goto loc_831D7080;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-40
	xer.ca = r11.u32 > 39;
	r11.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d7080
	if (cr0.eq) goto loc_831D7080;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d7030
	if (!cr6.eq) goto loc_831D7030;
	// li r3,1
	ctx.r3.s64 = 1;
loc_831D7058:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7078
	if (!cr0.eq) goto loc_831D7078;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831d6f30
	sub_831D6F30(ctx, base);
loc_831D7078:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_831D7080:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831d7058
	goto loc_831D7058;
}

PPC_WEAK_FUNC(sub_831D6FE8) {
	__imp__sub_831D6FE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D7088) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,112
	cr6.compare<uint32_t>(r11.u32, 112, xer);
	// beq cr6,0x831d70f4
	if (cr6.eq) goto loc_831D70F4;
	// cmplwi cr6,r11,125
	cr6.compare<uint32_t>(r11.u32, 125, xer);
	// beq cr6,0x831d70bc
	if (cr6.eq) goto loc_831D70BC;
	// cmplwi cr6,r11,124
	cr6.compare<uint32_t>(r11.u32, 124, xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// bne cr6,0x831d70c0
	if (!cr6.eq) goto loc_831D70C0;
loc_831D70BC:
	// li r10,1
	ctx.r10.s64 = 1;
loc_831D70C0:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d70f4
	if (!cr0.eq) goto loc_831D70F4;
	// cmplwi cr6,r11,113
	cr6.compare<uint32_t>(r11.u32, 113, xer);
	// beq cr6,0x831d70f4
	if (cr6.eq) goto loc_831D70F4;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x831d5810
	sub_831D5810(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x831d7100
	goto loc_831D7100;
loc_831D70F4:
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x831d4de0
	sub_831D4DE0(ctx, base);
loc_831D7100:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D7088) {
	__imp__sub_831D7088(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D7110) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r22,r5
	r22.u64 = ctx.r5.u64;
	// li r5,38
	ctx.r5.s64 = 38;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r23,1
	r23.s64 = 1;
	// addi r24,r26,4
	r24.s64 = r26.s64 + 4;
	// ori r11,r26,1
	r11.u64 = r26.u64 | 1;
	// ori r10,r24,1
	ctx.r10.u64 = r24.u64 | 1;
	// stw r11,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r11.u32);
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// lwz r28,12(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// stw r11,8(r28)
	PPC_STORE_U32(r28.u32 + 8, r11.u32);
loc_831D7160:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// bne cr6,0x831d7570
	if (!cr6.eq) goto loc_831D7570;
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d73bc
	if (cr0.eq) goto loc_831D73BC;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831d73d8
	if (cr6.eq) goto loc_831D73D8;
	// lwz r8,28(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// lwz r10,48(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	// rlwinm. r10,r10,11,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 11) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d73bc
	if (cr0.eq) goto loc_831D73BC;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r27,28(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwz r11,48(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// rlwinm. r10,r11,13,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d71dc
	if (!cr0.eq) goto loc_831D71DC;
	// lwz r9,40(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 40);
loc_831D71AC:
	// rlwinm r10,r11,27,18,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x3FFF;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// slw r11,r23,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r23.u32 << (r11.u8 & 0x3F));
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// and. r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d71dc
	if (!cr0.eq) goto loc_831D71DC;
	// lwz r27,52(r27)
	r27.u64 = PPC_LOAD_U32(r27.u32 + 52);
	// lwz r11,48(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// rlwinm. r10,r11,13,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d71ac
	if (cr0.eq) goto loc_831D71AC;
loc_831D71DC:
	// lwz r11,48(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// rlwinm. r10,r11,13,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d73bc
	if (cr0.eq) goto loc_831D73BC;
	// rlwinm r10,r11,27,18,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x3FFF;
	// lwz r9,40(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 40);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// slw r11,r23,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r23.u32 << (r11.u8 & 0x3F));
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// and. r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d73bc
	if (!cr0.eq) goto loc_831D73BC;
	// lwz r28,8(r8)
	r28.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
loc_831D7210:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d79a0
	if (cr6.eq) goto loc_831D79A0;
	// lwz r29,4(r28)
	r29.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
loc_831D7220:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d7244
	if (cr6.eq) goto loc_831D7244;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r27,r10
	cr6.compare<uint32_t>(r27.u32, ctx.r10.u32, xer);
	// beq cr6,0x831d723c
	if (cr6.eq) goto loc_831D723C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831d7220
	goto loc_831D7220;
loc_831D723C:
	// mr r11,r23
	r11.u64 = r23.u64;
	// b 0x831d7248
	goto loc_831D7248;
loc_831D7244:
	// li r11,0
	r11.s64 = 0;
loc_831D7248:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d73b4
	if (cr0.eq) goto loc_831D73B4;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83123cb8
	sub_83123CB8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r10,25,25,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,86
	cr6.compare<uint32_t>(r11.u32, 86, xer);
	// beq cr6,0x831d727c
	if (cr6.eq) goto loc_831D727C;
	// cmplwi cr6,r11,87
	cr6.compare<uint32_t>(r11.u32, 87, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x831d7280
	if (!cr6.eq) goto loc_831D7280;
loc_831D727C:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_831D7280:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d7a1c
	if (cr0.eq) goto loc_831D7A1C;
	// rlwinm. r11,r10,6,31,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d72ec
	if (!cr0.eq) goto loc_831D72EC;
	// oris r11,r10,1024
	r11.u64 = ctx.r10.u64 | 67108864;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d72c8
	if (!cr0.eq) goto loc_831D72C8;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d72c8
	if (cr0.eq) goto loc_831D72C8;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d72d4
	if (!cr6.gt) goto loc_831D72D4;
loc_831D72C8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D72D4:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831D72EC:
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d73b4
	if (!cr0.eq) goto loc_831D73B4;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d73b4
	if (cr0.eq) goto loc_831D73B4;
loc_831D7304:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// bne cr6,0x831d7398
	if (!cr6.eq) goto loc_831D7398;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831914e0
	sub_831914E0(ctx, base);
	// lwz r31,12(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,6,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7398
	if (!cr0.eq) goto loc_831D7398;
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7374
	if (!cr0.eq) goto loc_831D7374;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d7374
	if (cr0.eq) goto loc_831D7374;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d7380
	if (!cr6.gt) goto loc_831D7380;
loc_831D7374:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D7380:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831D7398:
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d73b4
	if (!cr0.eq) goto loc_831D73B4;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d7304
	if (!cr6.eq) goto loc_831D7304;
loc_831D73B4:
	// lwz r28,12(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// b 0x831d7210
	goto loc_831D7210;
loc_831D73BC:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d73d8
	if (cr6.eq) goto loc_831D73D8;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r11,r23
	r11.u64 = r23.u64;
	// bne cr6,0x831d73dc
	if (!cr6.eq) goto loc_831D73DC;
loc_831D73D8:
	// li r11,0
	r11.s64 = 0;
loc_831D73DC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d7570
	if (cr0.eq) goto loc_831D7570;
	// lwz r4,28(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// lwz r31,8(r4)
	r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// mr r11,r31
	r11.u64 = r31.u64;
loc_831D73F0:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d761c
	if (cr6.eq) goto loc_831D761C;
	// lwz r10,48(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 48);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi r8,r10,13
	ctx.r8.u64 = ctx.r10.u32 & 0x7FFFF;
	// rlwinm r10,r8,27,5,31
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r8,r8,27
	ctx.r8.u64 = ctx.r8.u32 & 0x1F;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r9,40(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 40);
	// slw r8,r23,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (r23.u32 << (ctx.r8.u8 & 0x3F));
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// and. r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7430
	if (!cr0.eq) goto loc_831D7430;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// b 0x831d73f0
	goto loc_831D73F0;
loc_831D7430:
	// lwz r11,40(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 40);
	// rlwinm. r11,r11,0,28,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7448
	if (!cr0.eq) goto loc_831D7448;
	// li r5,16
	ctx.r5.s64 = 16;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8317a200
	sub_8317A200(ctx, base);
loc_831D7448:
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7524
	if (!cr0.eq) goto loc_831D7524;
	// mr r31,r11
	r31.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d7524
	if (cr0.eq) goto loc_831D7524;
loc_831D7460:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm. r11,r11,2,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d7508
	if (cr0.eq) goto loc_831D7508;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_831D7470:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d7508
	if (cr6.eq) goto loc_831D7508;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm. r9,r10,2,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831d7490
	if (!cr0.eq) goto loc_831D7490;
	// rlwinm. r10,r10,13,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 13) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d7498
	if (cr0.eq) goto loc_831D7498;
loc_831D7490:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831d7470
	goto loc_831D7470;
loc_831D7498:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83123cb8
	sub_83123CB8(ctx, base);
	// mr. r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x831d7508
	if (cr0.eq) goto loc_831D7508;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm. r10,r11,6,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7508
	if (!cr0.eq) goto loc_831D7508;
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,86
	cr6.compare<uint32_t>(r11.u32, 86, xer);
	// beq cr6,0x831d74f0
	if (cr6.eq) goto loc_831D74F0;
	// cmplwi cr6,r11,87
	cr6.compare<uint32_t>(r11.u32, 87, xer);
	// beq cr6,0x831d74f0
	if (cr6.eq) goto loc_831D74F0;
	// cmplwi cr6,r11,89
	cr6.compare<uint32_t>(r11.u32, 89, xer);
	// beq cr6,0x831d74f0
	if (cr6.eq) goto loc_831D74F0;
	// cmplwi cr6,r11,90
	cr6.compare<uint32_t>(r11.u32, 90, xer);
	// beq cr6,0x831d74f0
	if (cr6.eq) goto loc_831D74F0;
	// cmplwi cr6,r11,84
	cr6.compare<uint32_t>(r11.u32, 84, xer);
	// beq cr6,0x831d74f0
	if (cr6.eq) goto loc_831D74F0;
	// cmplwi cr6,r11,85
	cr6.compare<uint32_t>(r11.u32, 85, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x831d74f4
	if (!cr6.eq) goto loc_831D74F4;
loc_831D74F0:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_831D74F4:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d7508
	if (cr0.eq) goto loc_831D7508;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831d7c10
	sub_831D7C10(ctx, base);
loc_831D7508:
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7524
	if (!cr0.eq) goto loc_831D7524;
	// mr r31,r11
	r31.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d7460
	if (!cr6.eq) goto loc_831D7460;
loc_831D7524:
	// lwz r11,40(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 40);
	// rlwinm. r11,r11,0,28,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7570
	if (!cr0.eq) goto loc_831D7570;
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7570
	if (!cr0.eq) goto loc_831D7570;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d7570
	if (cr0.eq) goto loc_831D7570;
loc_831D7544:
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// rlwinm. r9,r10,2,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d7558
	if (cr0.eq) goto loc_831D7558;
	// rlwinm r10,r10,0,2,0
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
loc_831D7558:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7570
	if (!cr0.eq) goto loc_831D7570;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d7544
	if (!cr6.eq) goto loc_831D7544;
loc_831D7570:
	// lwz r29,0(r28)
	r29.u64 = PPC_LOAD_U32(r28.u32 + 0);
loc_831D7574:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d7840
	if (cr6.eq) goto loc_831D7840;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm. r11,r10,0,1,1
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7594
	if (!cr0.eq) goto loc_831D7594;
	// rlwinm. r11,r10,0,4,6
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// beq 0x831d7598
	if (cr0.eq) goto loc_831D7598;
loc_831D7594:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_831D7598:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d7838
	if (cr0.eq) goto loc_831D7838;
	// rlwinm. r11,r10,0,4,6
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d77cc
	if (cr0.eq) goto loc_831D77CC;
	// rlwinm. r11,r10,0,27,27
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d77cc
	if (cr0.eq) goto loc_831D77CC;
	// lwz r31,28(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 28);
loc_831D75B4:
	// lwz r31,52(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x83123cb8
	sub_83123CB8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x831d75b4
	if (cr0.eq) goto loc_831D75B4;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,10752
	cr6.compare<uint32_t>(r11.u32, 10752, xer);
	// bne cr6,0x831d75b4
	if (!cr6.eq) goto loc_831D75B4;
	// lwz r31,8(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm. r11,r31,6,31,31
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d77cc
	if (!cr0.eq) goto loc_831D77CC;
	// rlwinm r6,r31,18,29,31
	ctx.r6.u64 = rotl64(r31.u32 | (r31.u64 << 32), 18) & 0x7;
	// rlwinm r5,r31,13,29,31
	ctx.r5.u64 = rotl64(r31.u32 | (r31.u64 << 32), 13) & 0x7;
	// rlwinm r4,r31,25,25,31
	ctx.r4.u64 = rotl64(r31.u32 | (r31.u64 << 32), 25) & 0x7F;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-16
	r11.s64 = r30.s64 + -16;
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d76fc
	if (cr0.eq) goto loc_831D76FC;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x831d7704
	goto loc_831D7704;
loc_831D761C:
	// lwz r11,48(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 48);
	// rlwinm. r11,r11,13,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d76b4
	if (cr0.eq) goto loc_831D76B4;
	// mr r30,r31
	r30.u64 = r31.u64;
loc_831D762C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d7570
	if (cr6.eq) goto loc_831D7570;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x83123cb8
	sub_83123CB8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,6,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d76ac
	if (!cr0.eq) goto loc_831D76AC;
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7688
	if (!cr0.eq) goto loc_831D7688;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d7688
	if (cr0.eq) goto loc_831D7688;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d7694
	if (!cr6.gt) goto loc_831D7694;
loc_831D7688:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D7694:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831D76AC:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// b 0x831d762c
	goto loc_831D762C;
loc_831D76B4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d7570
	if (cr6.eq) goto loc_831D7570;
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831914e0
	sub_831914E0(ctx, base);
	// mr. r11,r3
	r11.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d76f4
	if (cr0.eq) goto loc_831D76F4;
	// lwz r10,28(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwz r4,12(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r5,52(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 52);
	// bl 0x831d58e0
	sub_831D58E0(ctx, base);
loc_831D76F4:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// b 0x831d76b4
	goto loc_831D76B4;
loc_831D76FC:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_831D7704:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83123cb8
	sub_83123CB8(ctx, base);
	// oris r11,r31,1024
	r11.u64 = r31.u64 | 67108864;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7748
	if (!cr0.eq) goto loc_831D7748;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d7748
	if (cr0.eq) goto loc_831D7748;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d7754
	if (!cr6.gt) goto loc_831D7754;
loc_831D7748:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D7754:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d77a8
	if (!cr0.eq) goto loc_831D77A8;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d77a8
	if (cr0.eq) goto loc_831D77A8;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d77b4
	if (!cr6.gt) goto loc_831D77B4;
loc_831D77A8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D77B4:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831D77CC:
	// lwz r31,12(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,6,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7838
	if (!cr0.eq) goto loc_831D7838;
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7814
	if (!cr0.eq) goto loc_831D7814;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d7814
	if (cr0.eq) goto loc_831D7814;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d7820
	if (!cr6.gt) goto loc_831D7820;
loc_831D7814:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D7820:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831D7838:
	// lwz r29,4(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// b 0x831d7574
	goto loc_831D7574;
loc_831D7840:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// blt cr6,0x831d785c
	if (cr6.lt) goto loc_831D785C;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// mr r11,r23
	r11.u64 = r23.u64;
	// ble cr6,0x831d7860
	if (!cr6.gt) goto loc_831D7860;
loc_831D785C:
	// li r11,0
	r11.s64 = 0;
loc_831D7860:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d79a0
	if (cr0.eq) goto loc_831D79A0;
	// lwz r30,4(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 4);
loc_831D786C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d79a0
	if (cr6.eq) goto loc_831D79A0;
	// lwz r31,16(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d7998
	if (cr6.eq) goto loc_831D7998;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r10,r11,0,4,6
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d78e4
	if (cr0.eq) goto loc_831D78E4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// blt cr6,0x831d78a8
	if (cr6.lt) goto loc_831D78A8;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// mr r11,r23
	r11.u64 = r23.u64;
	// ble cr6,0x831d78ac
	if (!cr6.gt) goto loc_831D78AC;
loc_831D78A8:
	// li r11,0
	r11.s64 = 0;
loc_831D78AC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7998
	if (!cr0.eq) goto loc_831D7998;
	// b 0x831d78c0
	goto loc_831D78C0;
loc_831D78B8:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r31,16(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_831D78C0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// beq cr6,0x831d78b8
	if (cr6.eq) goto loc_831D78B8;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,6,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7998
	if (!cr0.eq) goto loc_831D7998;
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// b 0x831d7940
	goto loc_831D7940;
loc_831D78E4:
	// rlwinm. r11,r11,2,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d7998
	if (cr0.eq) goto loc_831D7998;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r10,25,25,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,86
	cr6.compare<uint32_t>(r11.u32, 86, xer);
	// beq cr6,0x831d7928
	if (cr6.eq) goto loc_831D7928;
	// cmplwi cr6,r11,87
	cr6.compare<uint32_t>(r11.u32, 87, xer);
	// beq cr6,0x831d7928
	if (cr6.eq) goto loc_831D7928;
	// cmplwi cr6,r11,89
	cr6.compare<uint32_t>(r11.u32, 89, xer);
	// beq cr6,0x831d7928
	if (cr6.eq) goto loc_831D7928;
	// cmplwi cr6,r11,90
	cr6.compare<uint32_t>(r11.u32, 90, xer);
	// beq cr6,0x831d7928
	if (cr6.eq) goto loc_831D7928;
	// cmplwi cr6,r11,84
	cr6.compare<uint32_t>(r11.u32, 84, xer);
	// beq cr6,0x831d7928
	if (cr6.eq) goto loc_831D7928;
	// cmplwi cr6,r11,85
	cr6.compare<uint32_t>(r11.u32, 85, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x831d792c
	if (!cr6.eq) goto loc_831D792C;
loc_831D7928:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_831D792C:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d7998
	if (cr0.eq) goto loc_831D7998;
	// rlwinm. r11,r10,6,31,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7998
	if (!cr0.eq) goto loc_831D7998;
	// oris r11,r10,1024
	r11.u64 = ctx.r10.u64 | 67108864;
loc_831D7940:
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7974
	if (!cr0.eq) goto loc_831D7974;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d7974
	if (cr0.eq) goto loc_831D7974;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d7980
	if (!cr6.gt) goto loc_831D7980;
loc_831D7974:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D7980:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831D7998:
	// lwz r30,8(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// b 0x831d786c
	goto loc_831D786C;
loc_831D79A0:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7a28
	if (!cr0.eq) goto loc_831D7A28;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d7a28
	if (cr0.eq) goto loc_831D7A28;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r4
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831d7a14
	if (!cr0.eq) goto loc_831D7A14;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831D7A14:
	// mr r28,r31
	r28.u64 = r31.u64;
	// b 0x831d7160
	goto loc_831D7160;
loc_831D7A1C:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D7A28:
	// lwz r10,976(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 976);
	// addi r11,r25,972
	r11.s64 = r25.s64 + 972;
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// stw r26,976(r25)
	PPC_STORE_U32(r25.u32 + 976, r26.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_831D7110) {
	__imp__sub_831D7110(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D7A40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// li r5,38
	ctx.r5.s64 = 38;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r28,r29,4
	r28.s64 = r29.s64 + 4;
	// ori r11,r29,1
	r11.u64 = r29.u64 | 1;
	// ori r10,r28,1
	ctx.r10.u64 = r28.u64 | 1;
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
	// lwz r31,16(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
loc_831D7A88:
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_831D7A8C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d7ad0
	if (cr6.eq) goto loc_831D7AD0;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7aac
	if (!cr0.eq) goto loc_831D7AAC;
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// beq 0x831d7ab0
	if (cr0.eq) goto loc_831D7AB0;
loc_831D7AAC:
	// li r11,1
	r11.s64 = 1;
loc_831D7AB0:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d7ac8
	if (cr0.eq) goto loc_831D7AC8;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831d7110
	sub_831D7110(ctx, base);
loc_831D7AC8:
	// lwz r30,4(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// b 0x831d7a8c
	goto loc_831D7A8C;
loc_831D7AD0:
	// lwz r30,4(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 4);
loc_831D7AD4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d7b7c
	if (cr6.eq) goto loc_831D7B7C;
	// lwz r31,16(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d7b74
	if (cr6.eq) goto loc_831D7B74;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7b00
	if (!cr0.eq) goto loc_831D7B00;
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// beq 0x831d7b04
	if (cr0.eq) goto loc_831D7B04;
loc_831D7B00:
	// li r11,1
	r11.s64 = 1;
loc_831D7B04:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d7b74
	if (cr0.eq) goto loc_831D7B74;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,6,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7b74
	if (!cr0.eq) goto loc_831D7B74;
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7b50
	if (!cr0.eq) goto loc_831D7B50;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d7b50
	if (cr0.eq) goto loc_831D7B50;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d7b5c
	if (!cr6.gt) goto loc_831D7B5C;
loc_831D7B50:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D7B5C:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831D7B74:
	// lwz r30,8(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// b 0x831d7ad4
	goto loc_831D7AD4;
loc_831D7B7C:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7bf4
	if (!cr0.eq) goto loc_831D7BF4;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831d7bf4
	if (cr0.eq) goto loc_831D7BF4;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r4
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831d7a88
	if (!cr0.eq) goto loc_831D7A88;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
	// b 0x831d7a88
	goto loc_831D7A88;
loc_831D7BF4:
	// lwz r10,976(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 976);
	// addi r11,r27,972
	r11.s64 = r27.s64 + 972;
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
	// stw r29,976(r27)
	PPC_STORE_U32(r27.u32 + 976, r29.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831D7A40) {
	__imp__sub_831D7A40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D7C10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r29,0
	r29.s64 = 0;
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r30,25,25,31
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,84
	cr6.compare<uint32_t>(r11.u32, 84, xer);
	// bne cr6,0x831d7c84
	if (!cr6.eq) goto loc_831D7C84;
	// rlwinm r6,r30,18,29,31
	ctx.r6.u64 = rotl64(r30.u32 | (r30.u64 << 32), 18) & 0x7;
	// rlwinm r5,r30,13,29,31
	ctx.r5.u64 = rotl64(r30.u32 | (r30.u64 << 32), 13) & 0x7;
	// li r4,84
	ctx.r4.s64 = 84;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-16
	r11.s64 = r31.s64 + -16;
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d7c6c
	if (cr0.eq) goto loc_831D7C6C;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x831d7c74
	goto loc_831D7C74;
loc_831D7C6C:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_831D7C74:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83123cb8
	sub_83123CB8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x831d7ca8
	goto loc_831D7CA8;
loc_831D7C84:
	// cmplwi cr6,r11,85
	cr6.compare<uint32_t>(r11.u32, 85, xer);
	// bne cr6,0x831d7ca8
	if (!cr6.eq) goto loc_831D7CA8;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,85
	ctx.r4.s64 = 85;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-20
	r11.s64 = r31.s64 + -20;
	// lwzx r29,r3,r11
	r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
loc_831D7CA8:
	// oris r11,r30,1024
	r11.u64 = r30.u64 | 67108864;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// beq cr6,0x831d7d8c
	if (cr6.eq) goto loc_831D7D8C;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7ce8
	if (!cr0.eq) goto loc_831D7CE8;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d7ce8
	if (cr0.eq) goto loc_831D7CE8;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d7cf4
	if (!cr6.gt) goto loc_831D7CF4;
loc_831D7CE8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D7CF4:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831D7D0C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d7d84
	if (cr6.eq) goto loc_831D7D84;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm. r10,r11,6,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d7d84
	if (!cr0.eq) goto loc_831D7D84;
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// beq cr6,0x831d7db0
	if (cr6.eq) goto loc_831D7DB0;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7d60
	if (!cr0.eq) goto loc_831D7D60;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831d7d60
	if (cr0.eq) goto loc_831D7D60;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831d7d6c
	if (!cr6.gt) goto loc_831D7D6C;
loc_831D7D60:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831D7D6C:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r29,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r29.u32);
loc_831D7D84:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_831D7D8C:
	// lwz r31,0(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_831D7D90:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d7d0c
	if (cr6.eq) goto loc_831D7D0C;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831d7110
	sub_831D7110(ctx, base);
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// b 0x831d7d90
	goto loc_831D7D90;
loc_831D7DB0:
	// lwz r31,0(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 0);
loc_831D7DB4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d7d84
	if (cr6.eq) goto loc_831D7D84;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831d7110
	sub_831D7110(ctx, base);
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// b 0x831d7db4
	goto loc_831D7DB4;
}

PPC_WEAK_FUNC(sub_831D7C10) {
	__imp__sub_831D7C10(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D7DD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb8
	// stfd f31,-144(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -144, f31.u64);
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,100
	r11.s64 = ctx.r1.s64 + 100;
	// li r17,0
	r17.s64 = 0;
	// mr r22,r9
	r22.u64 = ctx.r9.u64;
	// stw r17,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r17.u32);
	// mr r16,r3
	r16.u64 = ctx.r3.u64;
	// mr r21,r4
	r21.u64 = ctx.r4.u64;
	// stw r22,340(r1)
	PPC_STORE_U32(ctx.r1.u32 + 340, r22.u32);
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// stw r17,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r17.u32);
	// mr r24,r7
	r24.u64 = ctx.r7.u64;
	// mr r19,r8
	r19.u64 = ctx.r8.u64;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// mr r20,r17
	r20.u64 = r17.u64;
	// mr r18,r17
	r18.u64 = r17.u64;
	// beq cr6,0x831d7fbc
	if (cr6.eq) goto loc_831D7FBC;
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmpwi cr6,r11,55
	cr6.compare<int32_t>(r11.s32, 55, xer);
	// beq cr6,0x831d8020
	if (cr6.eq) goto loc_831D8020;
	// cmpwi cr6,r11,58
	cr6.compare<int32_t>(r11.s32, 58, xer);
	// ble cr6,0x831d7fbc
	if (!cr6.gt) goto loc_831D7FBC;
	// cmpwi cr6,r11,62
	cr6.compare<int32_t>(r11.s32, 62, xer);
	// ble cr6,0x831d7f98
	if (!cr6.gt) goto loc_831D7F98;
	// cmpwi cr6,r11,112
	cr6.compare<int32_t>(r11.s32, 112, xer);
	// bne cr6,0x831d7fbc
	if (!cr6.eq) goto loc_831D7FBC;
	// addi r25,r23,4
	r25.s64 = r23.s64 + 4;
loc_831D7E50:
	// lwz r26,0(r25)
	r26.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831d7fbc
	if (cr6.eq) goto loc_831D7FBC;
	// lwz r28,16(r26)
	r28.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d7f84
	if (cr6.eq) goto loc_831D7F84;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14336
	cr6.compare<uint32_t>(r11.u32, 14336, xer);
	// bne cr6,0x831d7f84
	if (!cr6.eq) goto loc_831D7F84;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi r27,r22,30
	r27.u64 = r22.u32 & 0x3;
	// lfd f1,0(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r24.u32 + 0);
	// clrlwi r5,r11,27
	ctx.r5.u64 = r11.u32 & 0x1F;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x831ca960
	sub_831CA960(ctx, base);
	// lwz r29,0(r28)
	r29.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
loc_831D7E98:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d7f4c
	if (cr6.eq) goto loc_831D7F4C;
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r10,r10,0,18,24
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r10,14336
	cr6.compare<uint32_t>(ctx.r10.u32, 14336, xer);
	// bne cr6,0x831d7f84
	if (!cr6.eq) goto loc_831D7F84;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d7f84
	if (cr6.eq) goto loc_831D7F84;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x831d7f84
	if (!cr6.eq) goto loc_831D7F84;
	// lwz r31,12(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r10,r10,0,18,24
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r10,16000
	cr6.compare<uint32_t>(ctx.r10.u32, 16000, xer);
	// bne cr6,0x831d7f84
	if (!cr6.eq) goto loc_831D7F84;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r30,r11,27,30,31
	r30.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x3;
	// clrlwi r5,r11,27
	ctx.r5.u64 = r11.u32 & 0x1F;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831cab88
	sub_831CAB88(ctx, base);
	// rlwinm r11,r31,0,0,19
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFF000;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// clrlwi r5,r10,27
	ctx.r5.u64 = ctx.r10.u32 & 0x1F;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,148(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,18,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d7f24
	if (!cr0.eq) goto loc_831D7F24;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// b 0x831d7f38
	goto loc_831D7F38;
loc_831D7F24:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r30,1,0,30
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r11,r11,30,24,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0xFF;
	// srw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi r4,r11,30
	ctx.r4.u64 = r11.u32 & 0x3;
loc_831D7F38:
	// bl 0x831ca960
	sub_831CA960(ctx, base);
	// fcmpu cr6,f31,f1
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, ctx.f1.f64);
	// bne cr6,0x831d7f84
	if (!cr6.eq) goto loc_831D7F84;
	// lwz r29,4(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// b 0x831d7e98
	goto loc_831D7E98;
loc_831D7F4C:
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831ccd60
	sub_831CCD60(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x831d3f50
	sub_831D3F50(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
loc_831D7F84:
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bne cr6,0x831d7e50
	if (!cr6.eq) goto loc_831D7E50;
	// addi r25,r26,8
	r25.s64 = r26.s64 + 8;
	// b 0x831d7e50
	goto loc_831D7E50;
loc_831D7F98:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,0(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r24.u32 + 0);
	// li r20,1
	r20.s64 = 1;
	// lfd f0,3376(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// li r11,1
	r11.s64 = 1;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// beq cr6,0x831d7fb8
	if (cr6.eq) goto loc_831D7FB8;
	// mr r11,r17
	r11.u64 = r17.u64;
loc_831D7FB8:
	// clrlwi r18,r11,24
	r18.u64 = r11.u32 & 0xFF;
loc_831D7FBC:
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// addi r8,r1,112
	ctx.r8.s64 = ctx.r1.s64 + 112;
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
loc_831D7FC8:
	// addi r11,r10,1
	r11.s64 = ctx.r10.s64 + 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// rlwinm r6,r10,29,3,29
	ctx.r6.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r5,r1,340
	ctx.r5.s64 = ctx.r1.s64 + 340;
	// slw r11,r7,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 << (r11.u8 & 0x3F));
	// lwzx r7,r6,r5
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// clrlwi r6,r10,27
	ctx.r6.u64 = ctx.r10.u32 & 0x1F;
	// li r5,-1
	ctx.r5.s64 = -1;
	// and r11,r11,r7
	r11.u64 = r11.u64 & ctx.r7.u64;
	// slw r7,r5,r6
	ctx.r7.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r6.u8 & 0x3F));
	// and r11,r11,r7
	r11.u64 = r11.u64 & ctx.r7.u64;
	// srw r11,r11,r6
	r11.u64 = ctx.r6.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r6.u8 & 0x3F));
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831d8178
	if (cr6.lt) goto loc_831D8178;
	// beq cr6,0x831d8168
	if (cr6.eq) goto loc_831D8168;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bge cr6,0x831d8294
	if (!cr6.lt) goto loc_831D8294;
	// lfd f0,0(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// b 0x831d8170
	goto loc_831D8170;
loc_831D8020:
	// lwz r26,4(r23)
	r26.u64 = PPC_LOAD_U32(r23.u32 + 4);
loc_831D8024:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831d82a8
	if (cr6.eq) goto loc_831D82A8;
	// lwz r29,16(r26)
	r29.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d8160
	if (cr6.eq) goto loc_831D8160;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,15104
	cr6.compare<uint32_t>(r11.u32, 15104, xer);
	// bne cr6,0x831d8160
	if (!cr6.eq) goto loc_831D8160;
	// lwz r27,44(r29)
	r27.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// lwz r31,12(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,15872
	cr6.compare<uint32_t>(r11.u32, 15872, xer);
	// bne cr6,0x831d8160
	if (!cr6.eq) goto loc_831D8160;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lfd f31,0(r24)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r24.u32 + 0);
	// addi r30,r31,-8
	r30.s64 = r31.s64 + -8;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r10,r3,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + r30.u32);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// rlwinm r31,r10,17,18,31
	r31.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0x3FFF;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// lwzx r10,r3,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + r30.u32);
	// fctidz f0,f31
	ctx.fpscr.disableFlushMode();
	f0.s64 = (f31.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f31.f64);
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// li r6,0
	ctx.r6.s64 = 0;
	// clrlwi r4,r10,17
	ctx.r4.u64 = ctx.r10.u32 & 0x7FFF;
	// add r5,r11,r31
	ctx.r5.u64 = r11.u64 + r31.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x831cffe8
	sub_831CFFE8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x831d8160
	if (cr0.eq) goto loc_831D8160;
	// addi r28,r29,4
	r28.s64 = r29.s64 + 4;
loc_831D80D0:
	// lwz r31,0(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d8160
	if (cr6.eq) goto loc_831D8160;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831d814c
	if (cr6.eq) goto loc_831D814C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d8100
	if (!cr0.eq) goto loc_831D8100;
	// rlwinm. r10,r11,0,4,6
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// beq 0x831d8104
	if (cr0.eq) goto loc_831D8104;
loc_831D8100:
	// li r10,1
	ctx.r10.s64 = 1;
loc_831D8104:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d814c
	if (cr0.eq) goto loc_831D814C;
	// addi r10,r11,-8
	ctx.r10.s64 = r11.s64 + -8;
	// li r8,0
	ctx.r8.s64 = 0;
	// rlwimi r10,r11,0,0,26
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFE0) | (ctx.r10.u64 & 0xFFFFFFFF0000001F);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm r7,r11,27,24,31
	ctx.r7.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0xFF;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x831cd310
	sub_831CD310(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d814c
	if (!cr0.eq) goto loc_831D814C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_831D814C:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d80d0
	if (!cr6.eq) goto loc_831D80D0;
	// addi r28,r31,8
	r28.s64 = r31.s64 + 8;
	// b 0x831d80d0
	goto loc_831D80D0;
loc_831D8160:
	// lwz r26,8(r26)
	r26.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// b 0x831d8024
	goto loc_831D8024;
loc_831D8168:
	// lfd f0,0(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// fctiwz f0,f0
	f0.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
loc_831D8170:
	// stfiwx f0,0,r8
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U32(ctx.r8.u32, f0.u32);
	// b 0x831d81c0
	goto loc_831D81C0;
loc_831D8178:
	// lfd f0,0(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// clrlwi. r7,r11,1
	ctx.r7.u64 = r11.u32 & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x831d81a0
	if (cr0.eq) goto loc_831D81A0;
	// rlwinm. r11,r11,0,1,8
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x7F800000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r17
	r11.u64 = r17.u64;
	// beq 0x831d81a4
	if (cr0.eq) goto loc_831D81A4;
loc_831D81A0:
	// li r11,1
	r11.s64 = 1;
loc_831D81A4:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d81bc
	if (!cr0.eq) goto loc_831D81BC;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r11,r11,0,0,0
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// lfs f0,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
loc_831D81BC:
	// stfs f0,0(r8)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
loc_831D81C0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,8
	ctx.r9.s64 = ctx.r9.s64 + 8;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplwi cr6,r10,8
	cr6.compare<uint32_t>(ctx.r10.u32, 8, xer);
	// blt cr6,0x831d7fc8
	if (cr6.lt) goto loc_831D7FC8;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x831d0300
	sub_831D0300(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// stb r17,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, r17.u8);
	// mr r8,r19
	ctx.r8.u64 = r19.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x831d66b0
	sub_831D66B0(ctx, base);
	// lwz r30,100(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// clrlwi. r11,r20,24
	r11.u64 = r20.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// beq 0x831d82a4
	if (cr0.eq) goto loc_831D82A4;
	// addi r28,r23,4
	r28.s64 = r23.s64 + 4;
loc_831D8224:
	// lwz r31,0(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d82a0
	if (cr6.eq) goto loc_831D82A0;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831d8280
	if (cr6.eq) goto loc_831D8280;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d8254
	if (cr0.eq) goto loc_831D8254;
	// rlwinm. r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x831d8258
	if (cr0.eq) goto loc_831D8258;
loc_831D8254:
	// mr r11,r17
	r11.u64 = r17.u64;
loc_831D8258:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8280
	if (cr0.eq) goto loc_831D8280;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x831d4c18
	sub_831D4C18(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// or r11,r11,r30
	r11.u64 = r11.u64 | r30.u64;
	// rlwimi r11,r30,0,0,30
	r11.u64 = (rotl32(r30.u32, 0) & 0xFFFFFFFE) | (r11.u64 & 0xFFFFFFFF00000001);
	// mr r30,r11
	r30.u64 = r11.u64;
loc_831D8280:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d8224
	if (!cr6.eq) goto loc_831D8224;
	// addi r28,r31,8
	r28.s64 = r31.s64 + 8;
	// b 0x831d8224
	goto loc_831D8224;
loc_831D8294:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D82A0:
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
loc_831D82A4:
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
loc_831D82A8:
	// ld r11,96(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// std r11,0(r16)
	PPC_STORE_U64(r16.u32 + 0, r11.u64);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f31,-144(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// b 0x82ca2c08
	return;
}

PPC_WEAK_FUNC(sub_831D7DD8) {
	__imp__sub_831D7DD8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D82C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// mr r23,r6
	r23.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r28,12(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// rlwinm r29,r11,27,24,31
	r29.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0xFF;
	// clrlwi r30,r11,27
	r30.u64 = r11.u32 & 0x1F;
loc_831D82F0:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x831d848c
	if (cr6.eq) goto loc_831D848C;
	// cmpwi cr6,r11,104
	cr6.compare<int32_t>(r11.s32, 104, xer);
	// beq cr6,0x831d8400
	if (cr6.eq) goto loc_831D8400;
	// cmpwi cr6,r11,112
	cr6.compare<int32_t>(r11.s32, 112, xer);
	// bne cr6,0x831d8478
	if (!cr6.eq) goto loc_831D8478;
	// rlwinm r11,r27,0,0,19
	r11.u64 = rotl64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFF000;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x831d6b98
	sub_831D6B98(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8478
	if (cr0.eq) goto loc_831D8478;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d8478
	if (cr6.eq) goto loc_831D8478;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm. r11,r10,0,27,28
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8368
	if (cr0.eq) goto loc_831D8368;
	// rlwinm. r11,r30,0,27,28
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8368
	if (cr0.eq) goto loc_831D8368;
loc_831D8360:
	// li r11,0
	r11.s64 = 0;
	// b 0x831d8390
	goto loc_831D8390;
loc_831D8368:
	// rlwinm. r11,r10,0,30,30
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8378
	if (cr0.eq) goto loc_831D8378;
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d8360
	if (!cr0.eq) goto loc_831D8360;
loc_831D8378:
	// rlwinm. r11,r10,0,29,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d838c
	if (cr0.eq) goto loc_831D838C;
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// bne 0x831d8390
	if (!cr0.eq) goto loc_831D8390;
loc_831D838C:
	// li r11,1
	r11.s64 = 1;
loc_831D8390:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8478
	if (cr0.eq) goto loc_831D8478;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// rlwinm. r8,r10,0,29,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r28,r9
	r28.u64 = ctx.r9.u64;
	// or r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 | r11.u64;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// or r8,r7,r11
	ctx.r8.u64 = ctx.r7.u64 | r11.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// or r29,r8,r11
	r29.u64 = ctx.r8.u64 | r11.u64;
	// beq 0x831d83d0
	if (cr0.eq) goto loc_831D83D0;
	// rlwinm. r11,r30,0,30,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d83d0
	if (cr0.eq) goto loc_831D83D0;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
loc_831D83D0:
	// and r11,r10,r30
	r11.u64 = ctx.r10.u64 & r30.u64;
	// rlwinm. r11,r11,0,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d83e4
	if (cr0.eq) goto loc_831D83E4;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// addi r9,r30,-4
	ctx.r9.s64 = r30.s64 + -4;
loc_831D83E4:
	// clrlwi. r11,r10,31
	r11.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d83f8
	if (cr0.eq) goto loc_831D83F8;
	// rlwinm. r11,r9,0,30,30
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d83f8
	if (cr0.eq) goto loc_831D83F8;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
loc_831D83F8:
	// or r30,r10,r9
	r30.u64 = ctx.r10.u64 | ctx.r9.u64;
	// b 0x831d82f0
	goto loc_831D82F0;
loc_831D8400:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x831d8478
	if (!cr6.eq) goto loc_831D8478;
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwinm. r11,r9,0,27,28
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d8478
	if (!cr0.eq) goto loc_831D8478;
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,15104
	cr6.compare<uint32_t>(r11.u32, 15104, xer);
	// beq cr6,0x831d8478
	if (cr6.eq) goto loc_831D8478;
	// rlwinm. r10,r9,0,27,28
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// clrlwi r11,r9,27
	r11.u64 = ctx.r9.u32 & 0x1F;
	// beq 0x831d8448
	if (cr0.eq) goto loc_831D8448;
	// rlwinm. r10,r30,0,27,28
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d8448
	if (cr0.eq) goto loc_831D8448;
loc_831D8440:
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x831d8470
	goto loc_831D8470;
loc_831D8448:
	// rlwinm. r10,r11,0,30,30
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d8458
	if (cr0.eq) goto loc_831D8458;
	// clrlwi. r10,r30,31
	ctx.r10.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d8440
	if (!cr0.eq) goto loc_831D8440;
loc_831D8458:
	// rlwinm. r10,r11,0,29,29
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d846c
	if (cr0.eq) goto loc_831D846C;
	// clrlwi. r10,r30,31
	ctx.r10.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// bne 0x831d8470
	if (!cr0.eq) goto loc_831D8470;
loc_831D846C:
	// li r10,1
	ctx.r10.s64 = 1;
loc_831D8470:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d8534
	if (!cr0.eq) goto loc_831D8534;
loc_831D8478:
	// stw r28,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r28.u32);
	// stw r29,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r29.u32);
	// stw r30,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r30.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	return;
loc_831D848C:
	// lwz r31,44(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// lwz r4,48(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fb10
	sub_8310FB10(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8478
	if (cr0.eq) goto loc_831D8478;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm. r11,r9,0,27,28
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d8478
	if (!cr0.eq) goto loc_831D8478;
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,15104
	cr6.compare<uint32_t>(r11.u32, 15104, xer);
	// beq cr6,0x831d8478
	if (cr6.eq) goto loc_831D8478;
	// rlwinm. r10,r9,0,27,28
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// clrlwi r11,r9,27
	r11.u64 = ctx.r9.u32 & 0x1F;
	// beq 0x831d84e0
	if (cr0.eq) goto loc_831D84E0;
	// rlwinm. r10,r30,0,27,28
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d84e0
	if (cr0.eq) goto loc_831D84E0;
loc_831D84D8:
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x831d8508
	goto loc_831D8508;
loc_831D84E0:
	// rlwinm. r10,r11,0,30,30
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d84f0
	if (cr0.eq) goto loc_831D84F0;
	// clrlwi. r10,r30,31
	ctx.r10.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d84d8
	if (!cr0.eq) goto loc_831D84D8;
loc_831D84F0:
	// rlwinm. r10,r11,0,29,29
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d8504
	if (cr0.eq) goto loc_831D8504;
	// clrlwi. r10,r30,31
	ctx.r10.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// bne 0x831d8508
	if (!cr0.eq) goto loc_831D8508;
loc_831D8504:
	// li r10,1
	ctx.r10.s64 = 1;
loc_831D8508:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831d8478
	if (cr0.eq) goto loc_831D8478;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831d8534
	if (cr6.eq) goto loc_831D8534;
	// lwz r10,28(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 28);
	// lwz r7,28(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 28);
	// lwz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 76);
	// lwz r7,76(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 76);
	// xor r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 ^ ctx.r7.u64;
	// clrlwi. r10,r10,13
	ctx.r10.u64 = ctx.r10.u32 & 0x7FFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d8478
	if (!cr0.eq) goto loc_831D8478;
loc_831D8534:
	// rlwinm r10,r9,27,24,31
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0xFF;
	// rlwinm r9,r29,27,29,30
	ctx.r9.u64 = rotl64(r29.u32 | (r29.u64 << 32), 27) & 0x6;
	// rlwinm r7,r29,29,29,30
	ctx.r7.u64 = rotl64(r29.u32 | (r29.u64 << 32), 29) & 0x6;
	// srw r9,r10,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r9.u8 & 0x3F));
	// srw r7,r10,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r7.u8 & 0x3F));
	// rlwimi r7,r9,2,28,29
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 2) & 0xC) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFFF3);
	// rlwinm r6,r29,31,29,30
	ctx.r6.u64 = rotl64(r29.u32 | (r29.u64 << 32), 31) & 0x6;
	// rlwinm r9,r29,1,29,30
	ctx.r9.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0x6;
	// srw r6,r10,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r6.u8 & 0x3F));
	// clrlwi r7,r7,28
	ctx.r7.u64 = ctx.r7.u32 & 0xF;
	// srw r29,r10,r9
	r29.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r9.u8 & 0x3F));
	// rlwimi r6,r7,2,0,29
	ctx.r6.u64 = (rotl32(ctx.r7.u32, 2) & 0xFFFFFFFC) | (ctx.r6.u64 & 0xFFFFFFFF00000003);
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// rlwimi r29,r6,2,0,29
	r29.u64 = (rotl32(ctx.r6.u32, 2) & 0xFFFFFFFC) | (r29.u64 & 0xFFFFFFFF00000003);
	// rlwinm. r9,r11,0,29,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d8584
	if (cr0.eq) goto loc_831D8584;
	// rlwinm. r9,r30,0,30,30
	ctx.r9.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d8584
	if (cr0.eq) goto loc_831D8584;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_831D8584:
	// and r9,r11,r30
	ctx.r9.u64 = r11.u64 & r30.u64;
	// rlwinm. r9,r9,0,29,29
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d8598
	if (cr0.eq) goto loc_831D8598;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// addi r10,r30,-4
	ctx.r10.s64 = r30.s64 + -4;
loc_831D8598:
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d85ac
	if (cr0.eq) goto loc_831D85AC;
	// rlwinm. r9,r10,0,30,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d85ac
	if (cr0.eq) goto loc_831D85AC;
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
loc_831D85AC:
	// or r30,r11,r10
	r30.u64 = r11.u64 | ctx.r10.u64;
	// b 0x831d82f0
	goto loc_831D82F0;
}

PPC_WEAK_FUNC(sub_831D82C0) {
	__imp__sub_831D82C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D85B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// addi r9,r1,92
	ctx.r9.s64 = ctx.r1.s64 + 92;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// rlwinm. r8,r11,27,31,31
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x831d8674
	if (!cr0.eq) goto loc_831D8674;
	// rlwinm. r9,r11,7,31,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 7) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831d8674
	if (!cr0.eq) goto loc_831D8674;
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,83
	cr6.compare<uint32_t>(r11.u32, 83, xer);
	// blt cr6,0x831d8610
	if (cr6.lt) goto loc_831D8610;
	// cmplwi cr6,r11,95
	cr6.compare<uint32_t>(r11.u32, 95, xer);
	// bgt cr6,0x831d8610
	if (cr6.gt) goto loc_831D8610;
	// li r10,1
	ctx.r10.s64 = 1;
loc_831D8610:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d8674
	if (!cr0.eq) goto loc_831D8674;
	// cmplwi cr6,r11,125
	cr6.compare<uint32_t>(r11.u32, 125, xer);
	// beq cr6,0x831d8674
	if (cr6.eq) goto loc_831D8674;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831d0710
	sub_831D0710(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwinm r11,r11,18,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// slw r11,r10,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (r11.u8 & 0x3F));
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// bne cr6,0x831d8678
	if (!cr6.eq) goto loc_831D8678;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x831d7dd8
	sub_831D7DD8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x831d8680
	goto loc_831D8680;
loc_831D8674:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_831D8678:
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,0(r30)
	PPC_STORE_U64(r30.u32 + 0, r11.u64);
loc_831D8680:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D85B8) {
	__imp__sub_831D85B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D8688) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// stw r3,372(r1)
	PPC_STORE_U32(ctx.r1.u32 + 372, ctx.r3.u32);
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// stw r31,380(r1)
	PPC_STORE_U32(ctx.r1.u32 + 380, r31.u32);
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// stw r27,388(r1)
	PPC_STORE_U32(ctx.r1.u32 + 388, r27.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r5,396(r1)
	PPC_STORE_U32(ctx.r1.u32 + 396, ctx.r5.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r6,404(r1)
	PPC_STORE_U32(ctx.r1.u32 + 404, ctx.r6.u32);
	// rlwinm r11,r11,7,29,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 7) & 0x7;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// bl 0x831d82c0
	sub_831D82C0(ctx, base);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14080
	cr6.compare<uint32_t>(r11.u32, 14080, xer);
	// bne cr6,0x831d8c04
	if (!cr6.eq) goto loc_831D8C04;
	// li r14,2
	r14.s64 = 2;
	// li r19,-1
	r19.s64 = -1;
	// b 0x831d86fc
	goto loc_831D86FC;
loc_831D86F4:
	// lwz r27,388(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// lwz r31,380(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
loc_831D86FC:
	// lwz r11,396(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r4,404(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r15,0(r27)
	r15.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// lwz r16,0(r11)
	r16.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r4)
	r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// clrlwi r11,r16,30
	r11.u64 = r16.u32 & 0x3;
	// addi r11,r11,11
	r11.s64 = r11.s64 + 11;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// lwzx r3,r11,r15
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + r15.u32);
	// bl 0x831cc840
	sub_831CC840(ctx, base);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// li r25,1
	r25.s64 = 1;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r22,88(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r28,80(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// ori r21,r11,228
	r21.u64 = r11.u64 | 228;
	// ble cr6,0x831d8aa8
	if (!cr6.gt) goto loc_831D8AA8;
	// mr r24,r14
	r24.u64 = r14.u64;
	// addi r17,r1,136
	r17.s64 = ctx.r1.s64 + 136;
loc_831D876C:
	// srw r11,r16,r24
	r11.u64 = r24.u8 & 0x20 ? 0 : (r16.u32 >> (r24.u8 & 0x3F));
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,11
	r11.s64 = r11.s64 + 11;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,124
	ctx.r7.s64 = ctx.r1.s64 + 124;
	// addi r6,r1,116
	ctx.r6.s64 = ctx.r1.s64 + 116;
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwzx r3,r11,r15
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + r15.u32);
	// bl 0x831cc840
	sub_831CC840(ctx, base);
	// li r11,3
	r11.s64 = 3;
	// slw r11,r11,r24
	r11.u64 = r24.u8 & 0x20 ? 0 : (r11.u32 << (r24.u8 & 0x3F));
	// andc r11,r21,r11
	r11.u64 = r21.u64 & ~r11.u64;
	// lwz r29,116(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r20,120(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// slw r10,r29,r24
	ctx.r10.u64 = r24.u8 & 0x20 ? 0 : (r29.u32 << (r24.u8 & 0x3F));
	// lwz r18,124(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// cmplw cr6,r28,r20
	cr6.compare<uint32_t>(r28.u32, r20.u32, xer);
	// or r21,r11,r10
	r21.u64 = r11.u64 | ctx.r10.u64;
	// beq cr6,0x831d8904
	if (cr6.eq) goto loc_831D8904;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,16000
	cr6.compare<uint32_t>(r11.u32, 16000, xer);
	// beq cr6,0x831d88fc
	if (cr6.eq) goto loc_831D88FC;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831d0710
	sub_831D0710(ctx, base);
	// addi r11,r1,100
	r11.s64 = ctx.r1.s64 + 100;
	// li r26,0
	r26.s64 = 0;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// stw r26,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r26.u32);
	// beq cr6,0x831d88d8
	if (cr6.eq) goto loc_831D88D8;
	// mr r30,r26
	r30.u64 = r26.u64;
	// addi r27,r1,160
	r27.s64 = ctx.r1.s64 + 160;
loc_831D8808:
	// srw r11,r21,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (r21.u32 >> (r30.u8 & 0x3F));
	// clrlwi r31,r11,30
	r31.u64 = r11.u32 & 0x3;
	// li r11,1
	r11.s64 = 1;
	// slw r11,r11,r31
	r11.u64 = r31.u8 & 0x20 ? 0 : (r11.u32 << (r31.u8 & 0x3F));
	// and. r11,r11,r23
	r11.u64 = r11.u64 & r23.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8c00
	if (cr0.eq) goto loc_831D8C00;
	// rlwinm r28,r31,1,0,30
	r28.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r11,r28,1
	r11.s64 = r28.s64 + 1;
	// rlwinm r10,r31,30,3,29
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// rlwinm r8,r31,1,27,30
	ctx.r8.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// slw r11,r14,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r14.u32 << (r11.u8 & 0x3F));
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// slw r9,r19,r8
	ctx.r9.u64 = ctx.r8.u8 & 0x20 ? 0 : (r19.u32 << (ctx.r8.u8 & 0x3F));
	// and r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	// rlwinm r10,r31,3,0,28
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r7,r1,128
	ctx.r7.s64 = ctx.r1.s64 + 128;
	// and r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// srw r4,r11,r8
	ctx.r4.u64 = ctx.r8.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r8.u8 & 0x3F));
	// lfdx f1,r10,r7
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + ctx.r7.u32);
	// bl 0x831ca960
	sub_831CA960(ctx, base);
	// addi r11,r28,1
	r11.s64 = r28.s64 + 1;
	// stfd f1,0(r27)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r27.u32 + 0, ctx.f1.u64);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// rlwinm r10,r31,30,3,29
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 30) & 0x1FFFFFFC;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// slw r11,r14,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r14.u32 << (r11.u8 & 0x3F));
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// rlwinm r9,r31,1,27,30
	ctx.r9.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x1E;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// slw r8,r19,r9
	ctx.r8.u64 = ctx.r9.u8 & 0x20 ? 0 : (r19.u32 << (ctx.r9.u8 & 0x3F));
	// and r7,r11,r10
	ctx.r7.u64 = r11.u64 & ctx.r10.u64;
	// rlwinm r10,r30,29,3,29
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 29) & 0x1FFFFFFC;
	// and r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 & ctx.r8.u64;
	// addi r11,r1,100
	r11.s64 = ctx.r1.s64 + 100;
	// srw r9,r8,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r9.u8 & 0x3F));
	// clrlwi r7,r30,27
	ctx.r7.u64 = r30.u32 & 0x1F;
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r27,r27,8
	r27.s64 = r27.s64 + 8;
	// slw r9,r9,r7
	ctx.r9.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r7.u8 & 0x3F));
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// addi r30,r30,2
	r30.s64 = r30.s64 + 2;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// blt cr6,0x831d8808
	if (cr6.lt) goto loc_831D8808;
	// lwz r27,388(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// lwz r31,380(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// lwz r30,108(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
loc_831D88D8:
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// lwz r6,100(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r3,372(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// bl 0x831d0518
	sub_831D0518(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r21,228
	r21.s64 = 228;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// li r22,0
	r22.s64 = 0;
loc_831D88FC:
	// cmplw cr6,r28,r20
	cr6.compare<uint32_t>(r28.u32, r20.u32, xer);
	// bne cr6,0x831d890c
	if (!cr6.eq) goto loc_831D890C;
loc_831D8904:
	// cmplw cr6,r22,r18
	cr6.compare<uint32_t>(r22.u32, r18.u32, xer);
	// beq cr6,0x831d8a90
	if (cr6.eq) goto loc_831D8A90;
loc_831D890C:
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x831d0710
	sub_831D0710(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// slw r11,r11,r29
	r11.u64 = r29.u8 & 0x20 ? 0 : (r11.u32 << (r29.u8 & 0x3F));
	// and. r11,r3,r11
	r11.u64 = ctx.r3.u64 & r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8c04
	if (cr0.eq) goto loc_831D8C04;
	// addi r11,r1,84
	r11.s64 = ctx.r1.s64 + 84;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// beq cr6,0x831d89c8
	if (cr6.eq) goto loc_831D89C8;
	// rlwinm r23,r28,0,0,19
	r23.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFF000;
	// addi r30,r1,128
	r30.s64 = ctx.r1.s64 + 128;
	// mr r26,r25
	r26.u64 = r25.u64;
loc_831D894C:
	// srw r11,r21,r31
	r11.u64 = r31.u8 & 0x20 ? 0 : (r21.u32 >> (r31.u8 & 0x3F));
	// clrlwi r27,r11,30
	r27.u64 = r11.u32 & 0x3;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831cab88
	sub_831CAB88(ctx, base);
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// stfd f1,0(r30)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r30.u32 + 0, ctx.f1.u64);
	// lwz r11,148(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,18,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d8988
	if (!cr0.eq) goto loc_831D8988;
	// li r9,0
	ctx.r9.s64 = 0;
	// b 0x831d899c
	goto loc_831D899C;
loc_831D8988:
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r10,r27,1,0,30
	ctx.r10.u64 = rotl64(r27.u32 | (r27.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r11,r11,30,24,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0xFF;
	// srw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi r9,r11,30
	ctx.r9.u64 = r11.u32 & 0x3;
loc_831D899C:
	// rlwinm r10,r31,29,3,29
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r11,r1,84
	r11.s64 = ctx.r1.s64 + 84;
	// clrlwi r8,r31,27
	ctx.r8.u64 = r31.u32 & 0x1F;
	// addic. r26,r26,-1
	xer.ca = r26.u32 > 0;
	r26.s64 = r26.s64 + -1;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// slw r9,r9,r8
	ctx.r9.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// bne 0x831d894c
	if (!cr0.eq) goto loc_831D894C;
loc_831D89C8:
	// rlwinm r31,r29,1,0,30
	r31.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r1,104
	ctx.r9.s64 = ctx.r1.s64 + 104;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// rlwinm r10,r29,30,3,29
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 30) & 0x1FFFFFFC;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// rlwinm r8,r29,1,27,30
	ctx.r8.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0x1E;
	// slw r11,r14,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r14.u32 << (r11.u8 & 0x3F));
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// slw r9,r19,r8
	ctx.r9.u64 = ctx.r8.u8 & 0x20 ? 0 : (r19.u32 << (ctx.r8.u8 & 0x3F));
	// and r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	// rlwinm r10,r29,3,0,28
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// and r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// srw r4,r11,r8
	ctx.r4.u64 = ctx.r8.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r8.u8 & 0x3F));
	// lfdx f1,r10,r7
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + ctx.r7.u32);
	// bl 0x831ca960
	sub_831CA960(ctx, base);
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// stfd f1,0(r17)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r17.u32 + 0, ctx.f1.u64);
	// addi r9,r1,104
	ctx.r9.s64 = ctx.r1.s64 + 104;
	// lwz r3,372(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// rlwinm r10,r29,30,3,29
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 30) & 0x1FFFFFFC;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// slw r11,r14,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r14.u32 << (r11.u8 & 0x3F));
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rlwinm r9,r29,1,27,30
	ctx.r9.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0x1E;
	// and r8,r11,r10
	ctx.r8.u64 = r11.u64 & ctx.r10.u64;
	// slw r7,r19,r9
	ctx.r7.u64 = ctx.r9.u8 & 0x20 ? 0 : (r19.u32 << (ctx.r9.u8 & 0x3F));
	// and r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 & ctx.r7.u64;
	// rlwinm r11,r24,29,3,29
	r11.u64 = rotl64(r24.u32 | (r24.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r10,r1,84
	ctx.r10.s64 = ctx.r1.s64 + 84;
	// srw r9,r8,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r9.u8 & 0x3F));
	// clrlwi r7,r24,27
	ctx.r7.u64 = r24.u32 & 0x1F;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r4,r25,1
	ctx.r4.s64 = r25.s64 + 1;
	// slw r9,r9,r7
	ctx.r9.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r7.u8 & 0x3F));
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x831d0518
	sub_831D0518(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r27,388(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// lwz r31,380(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// li r21,228
	r21.s64 = 228;
	// lwz r30,108(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// li r22,0
	r22.s64 = 0;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
loc_831D8A90:
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r17,r17,8
	r17.s64 = r17.s64 + 8;
	// addi r24,r24,2
	r24.s64 = r24.s64 + 2;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// blt cr6,0x831d876c
	if (cr6.lt) goto loc_831D876C;
loc_831D8AA8:
	// rlwinm. r11,r22,0,27,28
	r11.u64 = rotl64(r22.u32 | (r22.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8ac0
	if (cr0.eq) goto loc_831D8AC0;
	// rlwinm. r11,r30,0,27,28
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8ac0
	if (cr0.eq) goto loc_831D8AC0;
loc_831D8AB8:
	// li r11,0
	r11.s64 = 0;
	// b 0x831d8ae8
	goto loc_831D8AE8;
loc_831D8AC0:
	// rlwinm. r11,r22,0,30,30
	r11.u64 = rotl64(r22.u32 | (r22.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8ad0
	if (cr0.eq) goto loc_831D8AD0;
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d8ab8
	if (!cr0.eq) goto loc_831D8AB8;
loc_831D8AD0:
	// rlwinm. r11,r22,0,29,29
	r11.u64 = rotl64(r22.u32 | (r22.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8ae4
	if (cr0.eq) goto loc_831D8AE4;
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// bne 0x831d8ae8
	if (!cr0.eq) goto loc_831D8AE8;
loc_831D8AE4:
	// li r11,1
	r11.s64 = 1;
loc_831D8AE8:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8c04
	if (cr0.eq) goto loc_831D8C04;
	// rlwinm. r9,r22,0,29,29
	ctx.r9.u64 = rotl64(r22.u32 | (r22.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// mr r11,r22
	r11.u64 = r22.u64;
	// beq 0x831d8b0c
	if (cr0.eq) goto loc_831D8B0C;
	// rlwinm. r9,r30,0,30,30
	ctx.r9.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d8b0c
	if (cr0.eq) goto loc_831D8B0C;
	// addi r11,r22,-4
	r11.s64 = r22.s64 + -4;
loc_831D8B0C:
	// and r9,r11,r30
	ctx.r9.u64 = r11.u64 & r30.u64;
	// rlwinm. r9,r9,0,29,29
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d8b20
	if (cr0.eq) goto loc_831D8B20;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// addi r10,r30,-4
	ctx.r10.s64 = r30.s64 + -4;
loc_831D8B20:
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d8b34
	if (cr0.eq) goto loc_831D8B34;
	// rlwinm. r9,r10,0,30,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831d8b34
	if (cr0.eq) goto loc_831D8B34;
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
loc_831D8B34:
	// lwz r9,396(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// or r30,r11,r10
	r30.u64 = r11.u64 | ctx.r10.u64;
	// lwz r11,404(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	// stw r28,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r28.u32);
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r30.u32);
	// stw r21,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r21.u32);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d8b98
	if (!cr6.eq) goto loc_831D8B98;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// b 0x831d8b74
	goto loc_831D8B74;
loc_831D8B6C:
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_831D8B74:
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d8b6c
	if (!cr6.eq) goto loc_831D8B6C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r6,26
	ctx.r6.s64 = 26;
	// li r5,20
	ctx.r5.s64 = 20;
	// lwz r3,372(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// bl 0x831104e0
	sub_831104E0(ctx, base);
loc_831D8B98:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r3,372(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwimi r10,r11,25,4,6
	ctx.r10.u64 = (rotl32(r11.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r30,388(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r11,r21,5,19,26
	r11.u64 = (rotl32(r21.u32, 5) & 0x1FE0) | (r11.u64 & 0xFFFFFFFFFFFFE01F);
	// lwz r6,404(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r5,396(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r31,380(r1)
	PPC_STORE_U32(ctx.r1.u32 + 380, r31.u32);
	// bl 0x831d82c0
	sub_831D82C0(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14080
	cr6.compare<uint32_t>(r11.u32, 14080, xer);
	// beq cr6,0x831d86f4
	if (cr6.eq) goto loc_831D86F4;
loc_831D8C00:
	// lwz r31,380(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
loc_831D8C04:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d8c4c
	if (!cr6.eq) goto loc_831D8C4C;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// b 0x831d8c28
	goto loc_831D8C28;
loc_831D8C20:
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_831D8C28:
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d8c20
	if (!cr6.eq) goto loc_831D8C20;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r6,26
	ctx.r6.s64 = 26;
	// li r5,20
	ctx.r5.s64 = 20;
	// lwz r3,372(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// bl 0x831104e0
	sub_831104E0(ctx, base);
loc_831D8C4C:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// b 0x82ca2c00
	return;
}

PPC_WEAK_FUNC(sub_831D8688) {
	__imp__sub_831D8688(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D8C58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
loc_831D8C5C:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831d8ca8
	if (cr6.eq) goto loc_831D8CA8;
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm. r11,r10,0,1,1
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d8c7c
	if (!cr0.eq) goto loc_831D8C7C;
	// rlwinm. r11,r10,0,4,6
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x831d8c80
	if (cr0.eq) goto loc_831D8C80;
loc_831D8C7C:
	// li r11,0
	r11.s64 = 0;
loc_831D8C80:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d8c94
	if (cr0.eq) goto loc_831D8C94;
	// rlwinm. r11,r10,0,7,18
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1FFE000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne 0x831d8c98
	if (!cr0.eq) goto loc_831D8C98;
loc_831D8C94:
	// li r11,0
	r11.s64 = 0;
loc_831D8C98:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bnelr 
	if (!cr0.eq) return;
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// b 0x831d8c5c
	goto loc_831D8C5C;
loc_831D8CA8:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm r11,r11,0,7,5
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFDFFFFFF;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D8C58) {
	__imp__sub_831D8C58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D8CB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// b 0x831d8ccc
	goto loc_831D8CCC;
loc_831D8CC4:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
loc_831D8CCC:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// bne cr6,0x831d8cc4
	if (!cr6.eq) goto loc_831D8CC4;
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// stw r5,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r5.u32);
	// lwz r11,12(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// stw r4,12(r5)
	PPC_STORE_U32(ctx.r5.u32 + 12, ctx.r4.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D8CB8) {
	__imp__sub_831D8CB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D8CF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// b 0x831d8d0c
	goto loc_831D8D0C;
loc_831D8D04:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
loc_831D8D0C:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// bne cr6,0x831d8d04
	if (!cr6.eq) goto loc_831D8D04;
	// lwz r10,12(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// stw r5,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r5.u32);
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// stw r11,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, r11.u32);
	// stw r4,8(r5)
	PPC_STORE_U32(ctx.r5.u32 + 8, ctx.r4.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D8CF8) {
	__imp__sub_831D8CF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D8D38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r10,r3,12
	ctx.r10.s64 = ctx.r3.s64 + 12;
	// b 0x831d8d4c
	goto loc_831D8D4C;
loc_831D8D44:
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_831D8D4C:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r9,r4
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r4.u32, xer);
	// bne cr6,0x831d8d44
	if (!cr6.eq) goto loc_831D8D44;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r4,8
	ctx.r10.s64 = ctx.r4.s64 + 8;
	// lwz r9,8(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// b 0x831d8d78
	goto loc_831D8D78;
loc_831D8D6C:
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
loc_831D8D78:
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x831d8d6c
	if (!cr6.eq) goto loc_831D8D6C;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D8D38) {
	__imp__sub_831D8D38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D8D90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r11,0
	r11.s64 = 0;
	// stw r4,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r4.u32);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// stb r11,25(r3)
	PPC_STORE_U8(ctx.r3.u32 + 25, r11.u8);
	// beqlr cr6
	if (cr6.eq) return;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// rlwinm. r11,r11,13,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bnelr 
	if (!cr0.eq) return;
	// lwz r9,4(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
loc_831D8DBC:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,48(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm. r8,r8,13,31,31
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 13) & 0x1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x831d8ddc
	if (!cr0.eq) goto loc_831D8DDC;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831d8dbc
	goto loc_831D8DBC;
loc_831D8DDC:
	// lwz r11,116(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 116);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// stw r10,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r10.u32);
	// stw r9,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r9.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// b 0x831d8e28
	goto loc_831D8E28;
loc_831D8E00:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm. r9,r10,10,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831d8e1c
	if (!cr0.eq) goto loc_831D8E1C;
	// rlwinm. r10,r10,12,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831d8e30
	if (!cr0.eq) goto loc_831D8E30;
loc_831D8E1C:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
loc_831D8E28:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831d8e00
	if (!cr6.eq) goto loc_831D8E00;
loc_831D8E30:
	// lbz r11,24(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 24);
	// stb r11,25(r3)
	PPC_STORE_U8(ctx.r3.u32 + 25, r11.u8);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D8D90) {
	__imp__sub_831D8D90(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D8E40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// li r5,24
	ctx.r5.s64 = 24;
	// li r4,20
	ctx.r4.s64 = 20;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r30.u32);
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// li r11,1
	r11.s64 = 1;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r3,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r3.u32);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r3,12(r30)
	PPC_STORE_U32(r30.u32 + 12, ctx.r3.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D8E40) {
	__imp__sub_831D8E40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D8EB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// li r5,24
	ctx.r5.s64 = 24;
	// li r4,20
	ctx.r4.s64 = 20;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r31.u32);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
	// li r11,1
	r11.s64 = 1;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r3,8(r30)
	PPC_STORE_U32(r30.u32 + 8, ctx.r3.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D8EB0) {
	__imp__sub_831D8EB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D8F20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r10,40(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 40);
loc_831D8F24:
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// li r9,1
	ctx.r9.s64 = 1;
	// clrlwi r8,r11,13
	ctx.r8.u64 = r11.u32 & 0x7FFFF;
	// rlwinm r11,r8,27,5,31
	r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r8,r8,27
	ctx.r8.u64 = ctx.r8.u32 & 0x1F;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// slw r9,r9,r8
	ctx.r9.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// and. r11,r9,r11
	r11.u64 = ctx.r9.u64 & r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bnelr 
	if (!cr0.eq) return;
	// lwz r3,52(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x831d8f24
	if (!cr6.eq) goto loc_831D8F24;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D8F20) {
	__imp__sub_831D8F20(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D8F60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r11,r24,23
	r11.s64 = r24.s64 + 23;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// rlwinm r27,r11,2,0,29
	r27.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r23,r6
	r23.u64 = ctx.r6.u64;
	// li r29,0
	r29.s64 = 0;
	// lwzx r3,r27,r28
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + r28.u32);
	// b 0x831d8fac
	goto loc_831D8FAC;
loc_831D8F90:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831d9050
	if (cr6.eq) goto loc_831D9050;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x83123778
	sub_83123778(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x831d905c
	if (cr0.eq) goto loc_831D905C;
	// lwz r3,12(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 12);
loc_831D8FAC:
	// cmplw cr6,r3,r25
	cr6.compare<uint32_t>(ctx.r3.u32, r25.u32, xer);
	// bne cr6,0x831d8f90
	if (!cr6.eq) goto loc_831D8F90;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83123778
	sub_83123778(ctx, base);
	// mr. r26,r3
	r26.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// beq 0x831d9068
	if (cr0.eq) goto loc_831D9068;
	// mr r30,r25
	r30.u64 = r25.u64;
loc_831D8FCC:
	// lwz r31,0(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d9068
	if (cr6.eq) goto loc_831D9068;
	// cmplw cr6,r31,r26
	cr6.compare<uint32_t>(r31.u32, r26.u32, xer);
	// beq cr6,0x831d903c
	if (cr6.eq) goto loc_831D903C;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r11,r10,0,1,1
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d8ff8
	if (!cr0.eq) goto loc_831D8FF8;
	// rlwinm. r11,r10,0,4,6
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x831d8ffc
	if (cr0.eq) goto loc_831D8FFC;
loc_831D8FF8:
	// li r11,0
	r11.s64 = 0;
loc_831D8FFC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d9010
	if (cr0.eq) goto loc_831D9010;
	// rlwinm. r11,r10,0,7,18
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1FFE000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne 0x831d9014
	if (!cr0.eq) goto loc_831D9014;
loc_831D9010:
	// li r11,0
	r11.s64 = 0;
loc_831D9014:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d903c
	if (cr0.eq) goto loc_831D903C;
	// rlwinm r11,r10,19,20,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 19) & 0xFFF;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmpw cr6,r11,r24
	cr6.compare<int32_t>(r11.s32, r24.s32, xer);
	// bne cr6,0x831d903c
	if (!cr6.eq) goto loc_831D903C;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83123d48
	sub_83123D48(ctx, base);
loc_831D903C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d8fcc
	if (!cr6.eq) goto loc_831D8FCC;
	// addi r30,r31,4
	r30.s64 = r31.s64 + 4;
	// b 0x831d8fcc
	goto loc_831D8FCC;
loc_831D9050:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D905C:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831D9068:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d915c
	if (cr6.eq) goto loc_831D915C;
	// addi r30,r25,4
	r30.s64 = r25.s64 + 4;
loc_831D9074:
	// lwz r31,0(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d9100
	if (cr6.eq) goto loc_831D9100;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831d90ec
	if (cr6.eq) goto loc_831D90EC;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// beq cr6,0x831d90ec
	if (cr6.eq) goto loc_831D90EC;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r11,r10,0,1,1
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831d90ac
	if (!cr0.eq) goto loc_831D90AC;
	// rlwinm. r11,r10,0,4,6
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x831d90b0
	if (cr0.eq) goto loc_831D90B0;
loc_831D90AC:
	// li r11,0
	r11.s64 = 0;
loc_831D90B0:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d90c4
	if (cr0.eq) goto loc_831D90C4;
	// rlwinm. r11,r10,0,7,18
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1FFE000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne 0x831d90c8
	if (!cr0.eq) goto loc_831D90C8;
loc_831D90C4:
	// li r11,0
	r11.s64 = 0;
loc_831D90C8:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d90ec
	if (cr0.eq) goto loc_831D90EC;
	// rlwinm r11,r10,19,20,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 19) & 0xFFF;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmpw cr6,r11,r24
	cr6.compare<int32_t>(r11.s32, r24.s32, xer);
	// bne cr6,0x831d90ec
	if (!cr6.eq) goto loc_831D90EC;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x83123d48
	sub_83123D48(ctx, base);
loc_831D90EC:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x831d9074
	if (!cr6.eq) goto loc_831D9074;
	// addi r30,r31,8
	r30.s64 = r31.s64 + 8;
	// b 0x831d9074
	goto loc_831D9074;
loc_831D9100:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831d9148
	if (cr6.eq) goto loc_831D9148;
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lwz r9,12(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x831d9124
	goto loc_831D9124;
loc_831D911C:
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_831D9124:
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// bne cr6,0x831d911c
	if (!cr6.eq) goto loc_831D911C;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// stw r29,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, r29.u32);
	// stw r9,12(r29)
	PPC_STORE_U32(r29.u32 + 12, ctx.r9.u32);
	// b 0x831d9174
	goto loc_831D9174;
loc_831D9148:
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// lwz r3,16(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x83123d48
	sub_83123D48(ctx, base);
	// b 0x831d9174
	goto loc_831D9174;
loc_831D915C:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831d916c
	if (cr6.eq) goto loc_831D916C;
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// b 0x831d9170
	goto loc_831D9170;
loc_831D916C:
	// li r11,0
	r11.s64 = 0;
loc_831D9170:
	// stwx r11,r27,r28
	PPC_STORE_U32(r27.u32 + r28.u32, r11.u32);
loc_831D9174:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831d918c
	if (cr6.eq) goto loc_831D918C;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83123d48
	sub_83123D48(ctx, base);
loc_831D918C:
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831d8c58
	sub_831D8C58(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_831D8F60) {
	__imp__sub_831D8F60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D91A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r10,r10,13
	ctx.r10.u64 = ctx.r10.u32 & 0x7FFFF;
	// addi r10,r10,31
	ctx.r10.s64 = ctx.r10.s64 + 31;
	// rlwinm r10,r10,29,3,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
loc_831D91C0:
	// lwz r11,48(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 48);
	// li r9,2
	ctx.r9.s64 = 2;
	// li r8,-1
	ctx.r8.s64 = -1;
	// clrlwi r7,r11,13
	ctx.r7.u64 = r11.u32 & 0x7FFFF;
	// rlwinm r11,r7,1,0,30
	r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r6,r7,30,3,29
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 30) & 0x1FFFFFFC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r7,r7,1,27,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0x1E;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// slw r8,r8,r7
	ctx.r8.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r7.u8 & 0x3F));
	// slw r11,r9,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r9.u32 << (r11.u8 & 0x3F));
	// lwzx r9,r6,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// and r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	// and r11,r11,r8
	r11.u64 = r11.u64 & ctx.r8.u64;
	// srw. r11,r11,r7
	r11.u64 = ctx.r7.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r7.u8 & 0x3F));
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831d9220
	if (cr0.eq) goto loc_831D9220;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x831d9220
	if (cr6.eq) goto loc_831D9220;
	// lwz r4,64(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 64);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x831d91c0
	if (!cr6.eq) goto loc_831D91C0;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_831D9220:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D91A0) {
	__imp__sub_831D91A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9228) {
	PPC_FUNC_PROLOGUE();
	// b 0x82ca3190
	sub_82CA3190(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_831D9228) {
	__imp__sub_831D9228(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9230) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, f30.u64);
	// stfd f31,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// lfs f0,3084(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// blt cr6,0x831d9260
	if (cr6.lt) goto loc_831D9260;
	// li r27,43
	r27.s64 = 43;
	// b 0x831d9268
	goto loc_831D9268;
loc_831D9260:
	// li r27,45
	r27.s64 = 45;
	// fneg f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = ctx.f1.u64 ^ 0x8000000000000000;
loc_831D9268:
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.u64 = uint64_t(int32_t(std::trunc(ctx.f1.f64)));
	// stfd f0,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, f0.u64);
	// lwz r28,84(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// extsw r11,r28
	r11.s64 = r28.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,27524(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 27524);
	f30.f64 = double(temp.f32);
	// li r31,0
	r31.s64 = 0;
	// addi r29,r11,2864
	r29.s64 = r11.s64 + 2864;
	// fsubs f31,f1,f0
	f31.f64 = static_cast<float>(ctx.f1.f64 - f0.f64);
	// fctiwz f0,f31
	f0.u64 = uint64_t(int32_t(std::trunc(f31.f64)));
	// stfd f0,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, f0.u64);
	// lwz r30,84(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_831D92AC:
	// extsw r10,r30
	ctx.r10.s64 = r30.s32;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// fsubs f0,f31,f0
	f0.f64 = static_cast<float>(f31.f64 - f0.f64);
	// fmuls f31,f0,f30
	f31.f64 = double(float(f0.f64 * f30.f64));
	// fctiwz f0,f31
	f0.u64 = uint64_t(int32_t(std::trunc(f31.f64)));
	// stfd f0,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, f0.u64);
	// lwz r30,92(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x8223f888
	sub_8223F888(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmpwi cr6,r31,9
	cr6.compare<int32_t>(r31.s32, 9, xer);
	// blt cr6,0x831d92ac
	if (cr6.lt) goto loc_831D92AC;
	// li r11,0
	r11.s64 = 0;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// stb r11,105(r1)
	PPC_STORE_U8(ctx.r1.u32 + 105, r11.u8);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r4,r10,20720
	ctx.r4.s64 = ctx.r10.s64 + 20720;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// extsb r5,r27
	ctx.r5.s64 = r27.s8;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8223f888
	sub_8223F888(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831D9230) {
	__imp__sub_831D9230(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9328) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d936c
	if (!cr6.eq) goto loc_831D936C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,733
	ctx.r7.s64 = 733;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831D936C:
	// li r4,127
	ctx.r4.s64 = 127;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831d93dc
	if (!cr6.eq) goto loc_831D93DC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d939c
	if (cr6.eq) goto loc_831D939C;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D939C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d93d4
	if (cr6.eq) goto loc_831D93D4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d93d4
	if (cr6.eq) goto loc_831D93D4;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D93D4:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d9434
	goto loc_831D9434;
loc_831D93DC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d93f8
	if (cr6.eq) goto loc_831D93F8;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D93F8:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9430
	if (cr6.eq) goto loc_831D9430;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9430
	if (cr6.eq) goto loc_831D9430;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9430:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D9434:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D9328) {
	__imp__sub_831D9328(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9440) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d9484
	if (!cr6.eq) goto loc_831D9484;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,817
	ctx.r7.s64 = 817;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831D9484:
	// li r4,163
	ctx.r4.s64 = 163;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r4,165
	ctx.r4.s64 = 165;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d950c
	if (cr6.eq) goto loc_831D950C;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x831d950c
	if (!cr6.eq) goto loc_831D950C;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d94cc
	if (cr6.eq) goto loc_831D94CC;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,5
	ctx.r4.s64 = 5;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D94CC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9504
	if (cr6.eq) goto loc_831D9504;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9504
	if (cr6.eq) goto loc_831D9504;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,7
	ctx.r6.s64 = 7;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,28(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9504:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d9564
	goto loc_831D9564;
loc_831D950C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d9528
	if (cr6.eq) goto loc_831D9528;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,5
	ctx.r4.s64 = 5;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9528:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9560
	if (cr6.eq) goto loc_831D9560;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9560
	if (cr6.eq) goto loc_831D9560;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,7
	ctx.r6.s64 = 7;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,28(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9560:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D9564:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831D9440) {
	__imp__sub_831D9440(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9570) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831d95a8
	if (cr6.eq) goto loc_831D95A8;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,6
	ctx.r4.s64 = 6;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D95A8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d95e0
	if (cr6.eq) goto loc_831D95E0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d95e0
	if (cr6.eq) goto loc_831D95E0;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,8
	ctx.r6.s64 = 8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,32(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// mtctr r31
	ctr.u64 = r31.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D95E0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831D9570) {
	__imp__sub_831D9570(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9600) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831d9634
	if (cr6.eq) goto loc_831D9634;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,7
	ctx.r4.s64 = 7;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9634:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d9670
	if (cr6.eq) goto loc_831D9670;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9670
	if (cr6.eq) goto loc_831D9670;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,10
	ctx.r6.s64 = 10;
	// lwz r5,40(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9670:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831D9600) {
	__imp__sub_831D9600(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9680) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x831d96c4
	if (!cr6.eq) goto loc_831D96C4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,988
	ctx.r7.s64 = 988;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831D96C4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831d96e0
	if (cr6.eq) goto loc_831D96E0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,38
	ctx.r4.s64 = 38;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D96E0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d971c
	if (cr6.eq) goto loc_831D971C;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d971c
	if (cr6.eq) goto loc_831D971C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// li r6,63
	ctx.r6.s64 = 63;
	// lwz r5,252(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 252);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D971C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D9680) {
	__imp__sub_831D9680(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9728) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831d97b8
	if (!cr6.eq) goto loc_831D97B8;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d9774
	if (cr6.eq) goto loc_831D9774;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9774:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d97b0
	if (cr6.eq) goto loc_831D97B0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d97b0
	if (cr6.eq) goto loc_831D97B0;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,14
	ctx.r6.s64 = 14;
	// lwz r5,56(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D97B0:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d9814
	goto loc_831D9814;
loc_831D97B8:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d97d4
	if (cr6.eq) goto loc_831D97D4;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D97D4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9810
	if (cr6.eq) goto loc_831D9810;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9810
	if (cr6.eq) goto loc_831D9810;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,14
	ctx.r6.s64 = 14;
	// lwz r5,56(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9810:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D9814:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D9728) {
	__imp__sub_831D9728(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9820) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d9864
	if (!cr6.eq) goto loc_831D9864;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1097
	ctx.r7.s64 = 1097;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831D9864:
	// li r4,163
	ctx.r4.s64 = 163;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r4,165
	ctx.r4.s64 = 165;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831d98ec
	if (cr6.eq) goto loc_831D98EC;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831d98ec
	if (cr6.eq) goto loc_831D98EC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d98ac
	if (cr6.eq) goto loc_831D98AC;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,9
	ctx.r4.s64 = 9;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D98AC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d98e4
	if (cr6.eq) goto loc_831D98E4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d98e4
	if (cr6.eq) goto loc_831D98E4;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,15
	ctx.r6.s64 = 15;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,60(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D98E4:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d9944
	goto loc_831D9944;
loc_831D98EC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d9908
	if (cr6.eq) goto loc_831D9908;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,9
	ctx.r4.s64 = 9;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9908:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9940
	if (cr6.eq) goto loc_831D9940;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9940
	if (cr6.eq) goto loc_831D9940;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,15
	ctx.r6.s64 = 15;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,60(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9940:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D9944:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831D9820) {
	__imp__sub_831D9820(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9950) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d9994
	if (!cr6.eq) goto loc_831D9994;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1154
	ctx.r7.s64 = 1154;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831D9994:
	// li r4,934
	ctx.r4.s64 = 934;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x831d9a04
	if (cr0.eq) goto loc_831D9A04;
	// beq cr6,0x831d99c4
	if (cr6.eq) goto loc_831D99C4;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,10
	ctx.r4.s64 = 10;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D99C4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d99fc
	if (cr6.eq) goto loc_831D99FC;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d99fc
	if (cr6.eq) goto loc_831D99FC;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,16
	ctx.r6.s64 = 16;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,64(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D99FC:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d9a58
	goto loc_831D9A58;
loc_831D9A04:
	// beq cr6,0x831d9a1c
	if (cr6.eq) goto loc_831D9A1C;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,10
	ctx.r4.s64 = 10;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9A1C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9a54
	if (cr6.eq) goto loc_831D9A54;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9a54
	if (cr6.eq) goto loc_831D9A54;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,16
	ctx.r6.s64 = 16;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,64(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9A54:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D9A58:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D9950) {
	__imp__sub_831D9950(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9A60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d9aa4
	if (!cr6.eq) goto loc_831D9AA4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1208
	ctx.r7.s64 = 1208;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831D9AA4:
	// li r4,935
	ctx.r4.s64 = 935;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x831d9b14
	if (cr0.eq) goto loc_831D9B14;
	// beq cr6,0x831d9ad4
	if (cr6.eq) goto loc_831D9AD4;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,11
	ctx.r4.s64 = 11;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9AD4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9b0c
	if (cr6.eq) goto loc_831D9B0C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9b0c
	if (cr6.eq) goto loc_831D9B0C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,17
	ctx.r6.s64 = 17;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,68(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9B0C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d9b68
	goto loc_831D9B68;
loc_831D9B14:
	// beq cr6,0x831d9b2c
	if (cr6.eq) goto loc_831D9B2C;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,11
	ctx.r4.s64 = 11;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9B2C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9b64
	if (cr6.eq) goto loc_831D9B64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9b64
	if (cr6.eq) goto loc_831D9B64;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,17
	ctx.r6.s64 = 17;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,68(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9B64:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D9B68:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D9A60) {
	__imp__sub_831D9A60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9B70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d9bb4
	if (!cr6.eq) goto loc_831D9BB4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1262
	ctx.r7.s64 = 1262;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831D9BB4:
	// li r4,170
	ctx.r4.s64 = 170;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,2
	cr6.compare<uint32_t>(ctx.r3.u32, 2, xer);
	// bne cr6,0x831d9c24
	if (!cr6.eq) goto loc_831D9C24;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d9be4
	if (cr6.eq) goto loc_831D9BE4;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,12
	ctx.r4.s64 = 12;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9BE4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9c1c
	if (cr6.eq) goto loc_831D9C1C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9c1c
	if (cr6.eq) goto loc_831D9C1C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,18
	ctx.r6.s64 = 18;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,72(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9C1C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d9c7c
	goto loc_831D9C7C;
loc_831D9C24:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d9c40
	if (cr6.eq) goto loc_831D9C40;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,12
	ctx.r4.s64 = 12;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9C40:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9c78
	if (cr6.eq) goto loc_831D9C78;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9c78
	if (cr6.eq) goto loc_831D9C78;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,18
	ctx.r6.s64 = 18;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,72(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9C78:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D9C7C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D9B70) {
	__imp__sub_831D9B70(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9C88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d9ccc
	if (!cr6.eq) goto loc_831D9CCC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1316
	ctx.r7.s64 = 1316;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831D9CCC:
	// li r4,170
	ctx.r4.s64 = 170;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne 0x831d9d3c
	if (!cr0.eq) goto loc_831D9D3C;
	// beq cr6,0x831d9cfc
	if (cr6.eq) goto loc_831D9CFC;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9CFC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9d34
	if (cr6.eq) goto loc_831D9D34;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9d34
	if (cr6.eq) goto loc_831D9D34;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,19
	ctx.r6.s64 = 19;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,76(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 76);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9D34:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d9d90
	goto loc_831D9D90;
loc_831D9D3C:
	// beq cr6,0x831d9d54
	if (cr6.eq) goto loc_831D9D54;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9D54:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9d8c
	if (cr6.eq) goto loc_831D9D8C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9d8c
	if (cr6.eq) goto loc_831D9D8C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,19
	ctx.r6.s64 = 19;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,76(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 76);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9D8C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D9D90:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D9C88) {
	__imp__sub_831D9C88(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9D98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d9ddc
	if (!cr6.eq) goto loc_831D9DDC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1367
	ctx.r7.s64 = 1367;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831D9DDC:
	// li r4,170
	ctx.r4.s64 = 170;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831d9e4c
	if (!cr6.eq) goto loc_831D9E4C;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d9e0c
	if (cr6.eq) goto loc_831D9E0C;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,14
	ctx.r4.s64 = 14;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9E0C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9e44
	if (cr6.eq) goto loc_831D9E44;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9e44
	if (cr6.eq) goto loc_831D9E44;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,20
	ctx.r6.s64 = 20;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,80(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9E44:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d9ea4
	goto loc_831D9EA4;
loc_831D9E4C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d9e68
	if (cr6.eq) goto loc_831D9E68;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,14
	ctx.r4.s64 = 14;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9E68:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9ea0
	if (cr6.eq) goto loc_831D9EA0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9ea0
	if (cr6.eq) goto loc_831D9EA0;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,20
	ctx.r6.s64 = 20;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,80(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9EA0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D9EA4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D9D98) {
	__imp__sub_831D9D98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9EB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831d9ef4
	if (!cr6.eq) goto loc_831D9EF4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1421
	ctx.r7.s64 = 1421;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831D9EF4:
	// li r4,171
	ctx.r4.s64 = 171;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831d9f64
	if (!cr6.eq) goto loc_831D9F64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d9f24
	if (cr6.eq) goto loc_831D9F24;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,40
	ctx.r4.s64 = 40;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9F24:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9f5c
	if (cr6.eq) goto loc_831D9F5C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9f5c
	if (cr6.eq) goto loc_831D9F5C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,92
	ctx.r6.s64 = 92;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,368(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 368);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9F5C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831d9fbc
	goto loc_831D9FBC;
loc_831D9F64:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831d9f80
	if (cr6.eq) goto loc_831D9F80;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,40
	ctx.r4.s64 = 40;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831D9F80:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831d9fb8
	if (cr6.eq) goto loc_831D9FB8;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831d9fb8
	if (cr6.eq) goto loc_831D9FB8;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,92
	ctx.r6.s64 = 92;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,368(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 368);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831D9FB8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831D9FBC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D9EB0) {
	__imp__sub_831D9EB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831D9FC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831da00c
	if (!cr6.eq) goto loc_831DA00C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1471
	ctx.r7.s64 = 1471;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DA00C:
	// li r4,165
	ctx.r4.s64 = 165;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,3
	cr6.compare<uint32_t>(ctx.r3.u32, 3, xer);
	// bne cr6,0x831da07c
	if (!cr6.eq) goto loc_831DA07C;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831da03c
	if (cr6.eq) goto loc_831DA03C;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,15
	ctx.r4.s64 = 15;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA03C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da074
	if (cr6.eq) goto loc_831DA074;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da074
	if (cr6.eq) goto loc_831DA074;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,21
	ctx.r6.s64 = 21;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,84(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA074:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831da0d4
	goto loc_831DA0D4;
loc_831DA07C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831da098
	if (cr6.eq) goto loc_831DA098;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,15
	ctx.r4.s64 = 15;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA098:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da0d0
	if (cr6.eq) goto loc_831DA0D0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da0d0
	if (cr6.eq) goto loc_831DA0D0;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,21
	ctx.r6.s64 = 21;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,84(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA0D0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DA0D4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831D9FC8) {
	__imp__sub_831D9FC8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DA0E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831da124
	if (!cr6.eq) goto loc_831DA124;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1521
	ctx.r7.s64 = 1521;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DA124:
	// li r4,165
	ctx.r4.s64 = 165;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831da194
	if (!cr6.eq) goto loc_831DA194;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831da154
	if (cr6.eq) goto loc_831DA154;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA154:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da18c
	if (cr6.eq) goto loc_831DA18C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da18c
	if (cr6.eq) goto loc_831DA18C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,22
	ctx.r6.s64 = 22;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,88(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA18C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831da1ec
	goto loc_831DA1EC;
loc_831DA194:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831da1b0
	if (cr6.eq) goto loc_831DA1B0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA1B0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da1e8
	if (cr6.eq) goto loc_831DA1E8;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da1e8
	if (cr6.eq) goto loc_831DA1E8;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,22
	ctx.r6.s64 = 22;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,88(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA1E8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DA1EC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DA0E0) {
	__imp__sub_831DA0E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DA1F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831da23c
	if (!cr6.eq) goto loc_831DA23C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1571
	ctx.r7.s64 = 1571;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DA23C:
	// li r4,165
	ctx.r4.s64 = 165;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,2
	cr6.compare<uint32_t>(ctx.r3.u32, 2, xer);
	// bne cr6,0x831da2ac
	if (!cr6.eq) goto loc_831DA2AC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831da26c
	if (cr6.eq) goto loc_831DA26C;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,17
	ctx.r4.s64 = 17;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA26C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da2a4
	if (cr6.eq) goto loc_831DA2A4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da2a4
	if (cr6.eq) goto loc_831DA2A4;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,23
	ctx.r6.s64 = 23;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,92(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 92);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA2A4:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831da304
	goto loc_831DA304;
loc_831DA2AC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831da2c8
	if (cr6.eq) goto loc_831DA2C8;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,17
	ctx.r4.s64 = 17;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA2C8:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da300
	if (cr6.eq) goto loc_831DA300;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da300
	if (cr6.eq) goto loc_831DA300;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,23
	ctx.r6.s64 = 23;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,92(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 92);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA300:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DA304:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DA1F8) {
	__imp__sub_831DA1F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DA310) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831da354
	if (!cr6.eq) goto loc_831DA354;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1622
	ctx.r7.s64 = 1622;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DA354:
	// li r4,615
	ctx.r4.s64 = 615;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831da3c4
	if (!cr6.eq) goto loc_831DA3C4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831da384
	if (cr6.eq) goto loc_831DA384;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,18
	ctx.r4.s64 = 18;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA384:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da3bc
	if (cr6.eq) goto loc_831DA3BC;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da3bc
	if (cr6.eq) goto loc_831DA3BC;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,32
	ctx.r6.s64 = 32;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,128(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 128);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA3BC:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831da41c
	goto loc_831DA41C;
loc_831DA3C4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831da3e0
	if (cr6.eq) goto loc_831DA3E0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,18
	ctx.r4.s64 = 18;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA3E0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da418
	if (cr6.eq) goto loc_831DA418;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da418
	if (cr6.eq) goto loc_831DA418;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,32
	ctx.r6.s64 = 32;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,128(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 128);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA418:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DA41C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DA310) {
	__imp__sub_831DA310(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DA428) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831da470
	if (!cr6.eq) goto loc_831DA470;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1676
	ctx.r7.s64 = 1676;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DA470:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,14
	ctx.r4.s64 = 14;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831da4e8
	if (!cr6.eq) goto loc_831DA4E8;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da4a4
	if (cr6.eq) goto loc_831DA4A4;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,19
	ctx.r4.s64 = 19;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA4A4:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da4e0
	if (cr6.eq) goto loc_831DA4E0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831da4e0
	if (cr6.eq) goto loc_831DA4E0;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,33
	ctx.r6.s64 = 33;
	// lwz r5,132(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 132);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA4E0:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831da544
	goto loc_831DA544;
loc_831DA4E8:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da504
	if (cr6.eq) goto loc_831DA504;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,19
	ctx.r4.s64 = 19;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA504:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da540
	if (cr6.eq) goto loc_831DA540;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831da540
	if (cr6.eq) goto loc_831DA540;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,33
	ctx.r6.s64 = 33;
	// lwz r5,132(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 132);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA540:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DA544:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DA428) {
	__imp__sub_831DA428(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DA550) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831da598
	if (!cr6.eq) goto loc_831DA598;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1726
	ctx.r7.s64 = 1726;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DA598:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,14
	ctx.r4.s64 = 14;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,2
	cr6.compare<uint32_t>(ctx.r3.u32, 2, xer);
	// bne cr6,0x831da610
	if (!cr6.eq) goto loc_831DA610;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da5cc
	if (cr6.eq) goto loc_831DA5CC;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,20
	ctx.r4.s64 = 20;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA5CC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da608
	if (cr6.eq) goto loc_831DA608;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831da608
	if (cr6.eq) goto loc_831DA608;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,34
	ctx.r6.s64 = 34;
	// lwz r5,136(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 136);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA608:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831da66c
	goto loc_831DA66C;
loc_831DA610:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da62c
	if (cr6.eq) goto loc_831DA62C;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,20
	ctx.r4.s64 = 20;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA62C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da668
	if (cr6.eq) goto loc_831DA668;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831da668
	if (cr6.eq) goto loc_831DA668;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,34
	ctx.r6.s64 = 34;
	// lwz r5,136(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 136);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA668:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DA66C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DA550) {
	__imp__sub_831DA550(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DA678) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831da6c0
	if (!cr6.eq) goto loc_831DA6C0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1777
	ctx.r7.s64 = 1777;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DA6C0:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,14
	ctx.r4.s64 = 14;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,3
	cr6.compare<uint32_t>(ctx.r3.u32, 3, xer);
	// bne cr6,0x831da738
	if (!cr6.eq) goto loc_831DA738;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da6f4
	if (cr6.eq) goto loc_831DA6F4;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,21
	ctx.r4.s64 = 21;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA6F4:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da730
	if (cr6.eq) goto loc_831DA730;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831da730
	if (cr6.eq) goto loc_831DA730;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,35
	ctx.r6.s64 = 35;
	// lwz r5,140(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 140);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA730:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831da794
	goto loc_831DA794;
loc_831DA738:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da754
	if (cr6.eq) goto loc_831DA754;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,21
	ctx.r4.s64 = 21;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA754:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da790
	if (cr6.eq) goto loc_831DA790;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831da790
	if (cr6.eq) goto loc_831DA790;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,35
	ctx.r6.s64 = 35;
	// lwz r5,140(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 140);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA790:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DA794:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DA678) {
	__imp__sub_831DA678(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DA7A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831da7e4
	if (!cr6.eq) goto loc_831DA7E4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1828
	ctx.r7.s64 = 1828;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DA7E4:
	// li r4,582
	ctx.r4.s64 = 582;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831da854
	if (!cr6.eq) goto loc_831DA854;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831da814
	if (cr6.eq) goto loc_831DA814;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,23
	ctx.r4.s64 = 23;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA814:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da84c
	if (cr6.eq) goto loc_831DA84C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da84c
	if (cr6.eq) goto loc_831DA84C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,38
	ctx.r6.s64 = 38;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,152(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 152);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA84C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831da8ac
	goto loc_831DA8AC;
loc_831DA854:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831da870
	if (cr6.eq) goto loc_831DA870;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,23
	ctx.r4.s64 = 23;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA870:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da8a8
	if (cr6.eq) goto loc_831DA8A8;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da8a8
	if (cr6.eq) goto loc_831DA8A8;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,38
	ctx.r6.s64 = 38;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,152(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 152);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA8A8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DA8AC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DA7A0) {
	__imp__sub_831DA7A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DA8B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x831da8fc
	if (!cr6.eq) goto loc_831DA8FC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1877
	ctx.r7.s64 = 1877;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DA8FC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831da918
	if (cr6.eq) goto loc_831DA918;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,24
	ctx.r4.s64 = 24;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA918:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da954
	if (cr6.eq) goto loc_831DA954;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831da954
	if (cr6.eq) goto loc_831DA954;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,39
	ctx.r6.s64 = 39;
	// lwz r5,156(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 156);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DA954:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DA8B8) {
	__imp__sub_831DA8B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DA960) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831da9a8
	if (!cr6.eq) goto loc_831DA9A8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1932
	ctx.r7.s64 = 1932;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DA9A8:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,20
	ctx.r4.s64 = 20;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,23
	ctx.r4.s64 = 23;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831daa3c
	if (!cr6.eq) goto loc_831DAA3C;
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// bne cr6,0x831daa3c
	if (!cr6.eq) goto loc_831DAA3C;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831da9f8
	if (cr6.eq) goto loc_831DA9F8;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,25
	ctx.r4.s64 = 25;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DA9F8:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831daa34
	if (cr6.eq) goto loc_831DAA34;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831daa34
	if (cr6.eq) goto loc_831DAA34;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,44
	ctx.r6.s64 = 44;
	// lwz r5,176(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 176);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mtctr r27
	ctr.u64 = r27.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DAA34:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831daa98
	goto loc_831DAA98;
loc_831DAA3C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831daa58
	if (cr6.eq) goto loc_831DAA58;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,25
	ctx.r4.s64 = 25;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DAA58:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831daa94
	if (cr6.eq) goto loc_831DAA94;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831daa94
	if (cr6.eq) goto loc_831DAA94;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,44
	ctx.r6.s64 = 44;
	// lwz r5,176(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 176);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mtctr r27
	ctr.u64 = r27.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DAA94:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DAA98:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831DA960) {
	__imp__sub_831DA960(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DAAA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831daae8
	if (!cr6.eq) goto loc_831DAAE8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1991
	ctx.r7.s64 = 1991;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DAAE8:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,20
	ctx.r4.s64 = 20;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,21
	ctx.r4.s64 = 21;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831dab7c
	if (!cr0.eq) goto loc_831DAB7C;
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// bne cr6,0x831dab7c
	if (!cr6.eq) goto loc_831DAB7C;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dab38
	if (cr6.eq) goto loc_831DAB38;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,26
	ctx.r4.s64 = 26;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DAB38:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dab74
	if (cr6.eq) goto loc_831DAB74;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831dab74
	if (cr6.eq) goto loc_831DAB74;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,45
	ctx.r6.s64 = 45;
	// lwz r5,180(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 180);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mtctr r27
	ctr.u64 = r27.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DAB74:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831dabd8
	goto loc_831DABD8;
loc_831DAB7C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dab98
	if (cr6.eq) goto loc_831DAB98;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,26
	ctx.r4.s64 = 26;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DAB98:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dabd4
	if (cr6.eq) goto loc_831DABD4;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831dabd4
	if (cr6.eq) goto loc_831DABD4;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,45
	ctx.r6.s64 = 45;
	// lwz r5,180(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 180);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mtctr r27
	ctr.u64 = r27.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DABD4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DABD8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831DAAA0) {
	__imp__sub_831DAAA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DABE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dac28
	if (!cr6.eq) goto loc_831DAC28;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2047
	ctx.r7.s64 = 2047;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DAC28:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,23
	ctx.r4.s64 = 23;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne 0x831daca0
	if (!cr0.eq) goto loc_831DACA0;
	// beq cr6,0x831dac5c
	if (cr6.eq) goto loc_831DAC5C;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DAC5C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dac98
	if (cr6.eq) goto loc_831DAC98;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dac98
	if (cr6.eq) goto loc_831DAC98;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,46
	ctx.r6.s64 = 46;
	// lwz r5,184(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 184);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DAC98:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831dacf8
	goto loc_831DACF8;
loc_831DACA0:
	// beq cr6,0x831dacb8
	if (cr6.eq) goto loc_831DACB8;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DACB8:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dacf4
	if (cr6.eq) goto loc_831DACF4;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dacf4
	if (cr6.eq) goto loc_831DACF4;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,46
	ctx.r6.s64 = 46;
	// lwz r5,184(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 184);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DACF4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DACF8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DABE0) {
	__imp__sub_831DABE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DAD00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dad48
	if (!cr6.eq) goto loc_831DAD48;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2102
	ctx.r7.s64 = 2102;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DAD48:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,23
	ctx.r4.s64 = 23;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831dadc0
	if (!cr6.eq) goto loc_831DADC0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dad7c
	if (cr6.eq) goto loc_831DAD7C;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,28
	ctx.r4.s64 = 28;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DAD7C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dadb8
	if (cr6.eq) goto loc_831DADB8;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dadb8
	if (cr6.eq) goto loc_831DADB8;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,47
	ctx.r6.s64 = 47;
	// lwz r5,188(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 188);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DADB8:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831dae1c
	goto loc_831DAE1C;
loc_831DADC0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831daddc
	if (cr6.eq) goto loc_831DADDC;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,28
	ctx.r4.s64 = 28;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DADDC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dae18
	if (cr6.eq) goto loc_831DAE18;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dae18
	if (cr6.eq) goto loc_831DAE18;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,47
	ctx.r6.s64 = 47;
	// lwz r5,188(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 188);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DAE18:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DAE1C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DAD00) {
	__imp__sub_831DAD00(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DAE28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dae70
	if (!cr6.eq) goto loc_831DAE70;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2155
	ctx.r7.s64 = 2155;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DAE70:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,22
	ctx.r4.s64 = 22;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831daee8
	if (!cr6.eq) goto loc_831DAEE8;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831daea4
	if (cr6.eq) goto loc_831DAEA4;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,29
	ctx.r4.s64 = 29;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DAEA4:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831daee0
	if (cr6.eq) goto loc_831DAEE0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831daee0
	if (cr6.eq) goto loc_831DAEE0;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,48
	ctx.r6.s64 = 48;
	// lwz r5,192(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 192);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DAEE0:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831daf44
	goto loc_831DAF44;
loc_831DAEE8:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831daf04
	if (cr6.eq) goto loc_831DAF04;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,29
	ctx.r4.s64 = 29;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DAF04:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831daf40
	if (cr6.eq) goto loc_831DAF40;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831daf40
	if (cr6.eq) goto loc_831DAF40;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,48
	ctx.r6.s64 = 48;
	// lwz r5,192(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 192);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DAF40:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DAF44:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DAE28) {
	__imp__sub_831DAE28(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DAF50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831daf98
	if (!cr6.eq) goto loc_831DAF98;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2208
	ctx.r7.s64 = 2208;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DAF98:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,22
	ctx.r4.s64 = 22;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,2
	cr6.compare<uint32_t>(ctx.r3.u32, 2, xer);
	// bne cr6,0x831db010
	if (!cr6.eq) goto loc_831DB010;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dafcc
	if (cr6.eq) goto loc_831DAFCC;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,30
	ctx.r4.s64 = 30;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DAFCC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db008
	if (cr6.eq) goto loc_831DB008;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db008
	if (cr6.eq) goto loc_831DB008;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,49
	ctx.r6.s64 = 49;
	// lwz r5,196(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 196);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB008:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831db06c
	goto loc_831DB06C;
loc_831DB010:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db02c
	if (cr6.eq) goto loc_831DB02C;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,30
	ctx.r4.s64 = 30;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB02C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db068
	if (cr6.eq) goto loc_831DB068;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db068
	if (cr6.eq) goto loc_831DB068;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,49
	ctx.r6.s64 = 49;
	// lwz r5,196(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 196);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB068:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DB06C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DAF50) {
	__imp__sub_831DAF50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DB078) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831db0c0
	if (!cr6.eq) goto loc_831DB0C0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2261
	ctx.r7.s64 = 2261;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DB0C0:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,22
	ctx.r4.s64 = 22;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne 0x831db138
	if (!cr0.eq) goto loc_831DB138;
	// beq cr6,0x831db0f4
	if (cr6.eq) goto loc_831DB0F4;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,30
	ctx.r4.s64 = 30;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB0F4:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db130
	if (cr6.eq) goto loc_831DB130;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db130
	if (cr6.eq) goto loc_831DB130;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,49
	ctx.r6.s64 = 49;
	// lwz r5,196(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 196);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB130:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831db190
	goto loc_831DB190;
loc_831DB138:
	// beq cr6,0x831db150
	if (cr6.eq) goto loc_831DB150;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,30
	ctx.r4.s64 = 30;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB150:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db18c
	if (cr6.eq) goto loc_831DB18C;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db18c
	if (cr6.eq) goto loc_831DB18C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,49
	ctx.r6.s64 = 49;
	// lwz r5,196(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 196);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB18C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DB190:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DB078) {
	__imp__sub_831DB078(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DB198) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831db1e0
	if (!cr6.eq) goto loc_831DB1E0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2316
	ctx.r7.s64 = 2316;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DB1E0:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,37
	ctx.r4.s64 = 37;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne 0x831db258
	if (!cr0.eq) goto loc_831DB258;
	// beq cr6,0x831db214
	if (cr6.eq) goto loc_831DB214;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,34
	ctx.r4.s64 = 34;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB214:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db250
	if (cr6.eq) goto loc_831DB250;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db250
	if (cr6.eq) goto loc_831DB250;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,57
	ctx.r6.s64 = 57;
	// lwz r5,228(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 228);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB250:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831db2b0
	goto loc_831DB2B0;
loc_831DB258:
	// beq cr6,0x831db270
	if (cr6.eq) goto loc_831DB270;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,34
	ctx.r4.s64 = 34;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB270:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db2ac
	if (cr6.eq) goto loc_831DB2AC;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db2ac
	if (cr6.eq) goto loc_831DB2AC;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,57
	ctx.r6.s64 = 57;
	// lwz r5,228(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 228);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB2AC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DB2B0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DB198) {
	__imp__sub_831DB198(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DB2B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831db300
	if (!cr6.eq) goto loc_831DB300;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2371
	ctx.r7.s64 = 2371;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DB300:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,37
	ctx.r4.s64 = 37;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831db378
	if (!cr6.eq) goto loc_831DB378;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db334
	if (cr6.eq) goto loc_831DB334;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,35
	ctx.r4.s64 = 35;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB334:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db370
	if (cr6.eq) goto loc_831DB370;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db370
	if (cr6.eq) goto loc_831DB370;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,58
	ctx.r6.s64 = 58;
	// lwz r5,232(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 232);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB370:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831db3d4
	goto loc_831DB3D4;
loc_831DB378:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db394
	if (cr6.eq) goto loc_831DB394;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,35
	ctx.r4.s64 = 35;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB394:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db3d0
	if (cr6.eq) goto loc_831DB3D0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db3d0
	if (cr6.eq) goto loc_831DB3D0;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,58
	ctx.r6.s64 = 58;
	// lwz r5,232(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 232);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB3D0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DB3D4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DB2B8) {
	__imp__sub_831DB2B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DB3E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831db428
	if (!cr6.eq) goto loc_831DB428;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2426
	ctx.r7.s64 = 2426;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DB428:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,37
	ctx.r4.s64 = 37;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,2
	cr6.compare<uint32_t>(ctx.r3.u32, 2, xer);
	// bne cr6,0x831db4a0
	if (!cr6.eq) goto loc_831DB4A0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db45c
	if (cr6.eq) goto loc_831DB45C;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,36
	ctx.r4.s64 = 36;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB45C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db498
	if (cr6.eq) goto loc_831DB498;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db498
	if (cr6.eq) goto loc_831DB498;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,59
	ctx.r6.s64 = 59;
	// lwz r5,236(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 236);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB498:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831db4fc
	goto loc_831DB4FC;
loc_831DB4A0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db4bc
	if (cr6.eq) goto loc_831DB4BC;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,36
	ctx.r4.s64 = 36;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB4BC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db4f8
	if (cr6.eq) goto loc_831DB4F8;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db4f8
	if (cr6.eq) goto loc_831DB4F8;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,59
	ctx.r6.s64 = 59;
	// lwz r5,236(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 236);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB4F8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DB4FC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DB3E0) {
	__imp__sub_831DB3E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DB508) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,971
	ctx.r4.s64 = 971;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831db58c
	if (!cr6.eq) goto loc_831DB58C;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831db54c
	if (cr6.eq) goto loc_831DB54C;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,37
	ctx.r4.s64 = 37;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB54C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831db584
	if (cr6.eq) goto loc_831DB584;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db584
	if (cr6.eq) goto loc_831DB584;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,60
	ctx.r6.s64 = 60;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r5,240(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 240);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB584:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831db5e4
	goto loc_831DB5E4;
loc_831DB58C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831db5a8
	if (cr6.eq) goto loc_831DB5A8;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,37
	ctx.r4.s64 = 37;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB5A8:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831db5e0
	if (cr6.eq) goto loc_831DB5E0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db5e0
	if (cr6.eq) goto loc_831DB5E0;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,60
	ctx.r6.s64 = 60;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r5,240(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 240);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB5E0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DB5E4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831DB508) {
	__imp__sub_831DB508(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DB5F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831db634
	if (!cr6.eq) goto loc_831DB634;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2527
	ctx.r7.s64 = 2527;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DB634:
	// li r4,926
	ctx.r4.s64 = 926;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831db6a4
	if (!cr6.eq) goto loc_831DB6A4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831db664
	if (cr6.eq) goto loc_831DB664;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,22
	ctx.r4.s64 = 22;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB664:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db69c
	if (cr6.eq) goto loc_831DB69C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db69c
	if (cr6.eq) goto loc_831DB69C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,36
	ctx.r6.s64 = 36;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,144(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 144);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB69C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831db6fc
	goto loc_831DB6FC;
loc_831DB6A4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831db6c0
	if (cr6.eq) goto loc_831DB6C0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,22
	ctx.r4.s64 = 22;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB6C0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db6f8
	if (cr6.eq) goto loc_831DB6F8;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db6f8
	if (cr6.eq) goto loc_831DB6F8;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,36
	ctx.r6.s64 = 36;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,144(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 144);
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB6F8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DB6FC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DB5F0) {
	__imp__sub_831DB5F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DB708) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x831db74c
	if (!cr6.eq) goto loc_831DB74C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2576
	ctx.r7.s64 = 2576;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DB74C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831db768
	if (cr6.eq) goto loc_831DB768;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,32
	ctx.r4.s64 = 32;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB768:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831db7a4
	if (cr6.eq) goto loc_831DB7A4;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db7a4
	if (cr6.eq) goto loc_831DB7A4;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// li r6,52
	ctx.r6.s64 = 52;
	// lwz r5,208(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 208);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB7A4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DB708) {
	__imp__sub_831DB708(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DB7B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831db7f8
	if (!cr6.eq) goto loc_831DB7F8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2631
	ctx.r7.s64 = 2631;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DB7F8:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,48
	ctx.r4.s64 = 48;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bgt cr6,0x831db870
	if (cr6.gt) goto loc_831DB870;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db82c
	if (cr6.eq) goto loc_831DB82C;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,33
	ctx.r4.s64 = 33;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB82C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db868
	if (cr6.eq) goto loc_831DB868;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db868
	if (cr6.eq) goto loc_831DB868;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,53
	ctx.r6.s64 = 53;
	// lwz r5,212(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 212);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB868:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831db8cc
	goto loc_831DB8CC;
loc_831DB870:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db88c
	if (cr6.eq) goto loc_831DB88C;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,33
	ctx.r4.s64 = 33;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB88C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db8c8
	if (cr6.eq) goto loc_831DB8C8;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831db8c8
	if (cr6.eq) goto loc_831DB8C8;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,53
	ctx.r6.s64 = 53;
	// lwz r5,212(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 212);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB8C8:
	// li r3,1
	ctx.r3.s64 = 1;
loc_831DB8CC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DB7B0) {
	__imp__sub_831DB7B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DB8D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831db920
	if (!cr6.eq) goto loc_831DB920;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2690
	ctx.r7.s64 = 2690;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DB920:
	// li r4,157
	ctx.r4.s64 = 157;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831db994
	if (!cr6.eq) goto loc_831DB994;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831db950
	if (cr6.eq) goto loc_831DB950;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,39
	ctx.r4.s64 = 39;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB950:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db98c
	if (cr6.eq) goto loc_831DB98C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db98c
	if (cr6.eq) goto loc_831DB98C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// li r6,91
	ctx.r6.s64 = 91;
	// lwz r5,364(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 364);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB98C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831db9f0
	goto loc_831DB9F0;
loc_831DB994:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831db9b0
	if (cr6.eq) goto loc_831DB9B0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,39
	ctx.r4.s64 = 39;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DB9B0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831db9ec
	if (cr6.eq) goto loc_831DB9EC;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831db9ec
	if (cr6.eq) goto loc_831DB9EC;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// li r6,91
	ctx.r6.s64 = 91;
	// lwz r5,364(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 364);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DB9EC:
	// li r3,1
	ctx.r3.s64 = 1;
loc_831DB9F0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DB8D8) {
	__imp__sub_831DB8D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DB9F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x831dba3c
	if (!cr6.eq) goto loc_831DBA3C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2744
	ctx.r7.s64 = 2744;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DBA3C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831dba58
	if (cr6.eq) goto loc_831DBA58;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,41
	ctx.r4.s64 = 41;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DBA58:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dba94
	if (cr6.eq) goto loc_831DBA94;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dba94
	if (cr6.eq) goto loc_831DBA94;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// li r6,101
	ctx.r6.s64 = 101;
	// lwz r5,404(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 404);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DBA94:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DB9F8) {
	__imp__sub_831DB9F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DBAA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// li r4,567
	ctx.r4.s64 = 567;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r4,974
	ctx.r4.s64 = 974;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r27,2
	cr6.compare<uint32_t>(r27.u32, 2, xer);
	// bne cr6,0x831dbb20
	if (!cr6.eq) goto loc_831DBB20;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x831dbaec
	if (!cr6.eq) goto loc_831DBAEC;
	// li r11,2
	r11.s64 = 2;
	// b 0x831dbb18
	goto loc_831DBB18;
loc_831DBAEC:
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831dbafc
	if (!cr6.eq) goto loc_831DBAFC;
	// li r11,5
	r11.s64 = 5;
	// b 0x831dbb18
	goto loc_831DBB18;
loc_831DBAFC:
	// cmplwi cr6,r3,3
	cr6.compare<uint32_t>(ctx.r3.u32, 3, xer);
	// bne cr6,0x831dbb0c
	if (!cr6.eq) goto loc_831DBB0C;
	// li r11,8
	r11.s64 = 8;
	// b 0x831dbb18
	goto loc_831DBB18;
loc_831DBB0C:
	// cmplwi cr6,r3,2
	cr6.compare<uint32_t>(ctx.r3.u32, 2, xer);
	// bne cr6,0x831dbb20
	if (!cr6.eq) goto loc_831DBB20;
	// li r11,11
	r11.s64 = 11;
loc_831DBB18:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x831dbb44
	goto loc_831DBB44;
loc_831DBB20:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-10856
	ctx.r5.s64 = ctx.r10.s64 + -10856;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2816
	ctx.r7.s64 = 2816;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DBB44:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dbb7c
	if (cr6.eq) goto loc_831DBB7C;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dbb7c
	if (cr6.eq) goto loc_831DBB7C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20728
	ctx.r4.s64 = ctx.r10.s64 + 20728;
	// li r6,61
	ctx.r6.s64 = 61;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r5,244(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 244);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DBB7C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DBAA0) {
	__imp__sub_831DBAA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DBB88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// rlwinm r11,r4,4,0,27
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 4) & 0xFFFFFFF0;
	// li r3,1
	ctx.r3.s64 = 1;
	// add r11,r11,r5
	r11.u64 = r11.u64 + ctx.r5.u64;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DBB88) {
	__imp__sub_831DBB88(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DBBA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// rlwinm r11,r4,7,0,24
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 7) & 0xFFFFFF80;
	// li r3,1
	ctx.r3.s64 = 1;
	// add r11,r11,r5
	r11.u64 = r11.u64 + ctx.r5.u64;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DBBA0) {
	__imp__sub_831DBBA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DBBB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// li r11,-1
	r11.s64 = -1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DBBB8) {
	__imp__sub_831DBBB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DBBC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831dbc10
	if (!cr6.eq) goto loc_831DBC10;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2877
	ctx.r7.s64 = 2877;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DBC10:
	// cmplwi cr6,r29,16
	cr6.compare<uint32_t>(r29.u32, 16, xer);
	// bge cr6,0x831dbc38
	if (!cr6.lt) goto loc_831DBC38;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x831dbc38
	if (cr6.eq) goto loc_831DBC38;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,15
	ctx.r4.s64 = 15;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// b 0x831dbc3c
	goto loc_831DBC3C;
loc_831DBC38:
	// li r8,0
	ctx.r8.s64 = 0;
loc_831DBC3C:
	// li r11,3
	r11.s64 = 3;
	// stw r8,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r8.u32);
	// li r10,7
	ctx.r10.s64 = 7;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// li r7,1
	ctx.r7.s64 = 1;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// stw r10,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r10.u32);
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// stw r7,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r7.u32);
	// beq cr6,0x831dbcac
	if (cr6.eq) goto loc_831DBCAC;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dbcac
	if (cr6.eq) goto loc_831DBCAC;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r6,31
	ctx.r6.s64 = 31;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,124(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 124);
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DBCAC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DBBC8) {
	__imp__sub_831DBBC8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DBCB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bbc
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r22,r6
	r22.u64 = ctx.r6.u64;
	// mr r21,r7
	r21.u64 = ctx.r7.u64;
	// mr r19,r8
	r19.u64 = ctx.r8.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// addi r18,r11,-18548
	r18.s64 = r11.s64 + -18548;
	// addi r17,r10,20744
	r17.s64 = ctx.r10.s64 + 20744;
	// bne cr6,0x831dbd10
	if (!cr6.eq) goto loc_831DBD10;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// addi r5,r11,-18224
	ctx.r5.s64 = r11.s64 + -18224;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// li r7,2967
	ctx.r7.s64 = 2967;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DBD10:
	// li r20,0
	r20.s64 = 0;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bne cr6,0x831dbd50
	if (!cr6.eq) goto loc_831DBD50;
	// li r4,928
	ctx.r4.s64 = 928;
	// li r28,23
	r28.s64 = 23;
	// mr r27,r20
	r27.u64 = r20.u64;
	// mr r23,r20
	r23.u64 = r20.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r4,927
	ctx.r4.s64 = 927;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r24,-1
	r24.s64 = -1;
	// b 0x831dbdc4
	goto loc_831DBDC4;
loc_831DBD50:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,43
	ctx.r4.s64 = 43;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,45
	ctx.r4.s64 = 45;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,46
	ctx.r4.s64 = 46;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,42
	ctx.r4.s64 = 42;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,41
	ctx.r4.s64 = 41;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,40
	ctx.r4.s64 = 40;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
loc_831DBDC4:
	// cmplwi cr6,r22,1
	cr6.compare<uint32_t>(r22.u32, 1, xer);
	// ble cr6,0x831dbde0
	if (!cr6.gt) goto loc_831DBDE0;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x831b3138
	sub_831B3138(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// b 0x831dbde4
	goto loc_831DBDE4;
loc_831DBDE0:
	// li r22,1
	r22.s64 = 1;
loc_831DBDE4:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// beq cr6,0x831dbdfc
	if (cr6.eq) goto loc_831DBDFC;
	// addi r11,r11,20144
	r11.s64 = r11.s64 + 20144;
	// addi r10,r11,-576
	ctx.r10.s64 = r11.s64 + -576;
	// b 0x831dbe00
	goto loc_831DBE00;
loc_831DBDFC:
	// addi r10,r11,20144
	ctx.r10.s64 = r11.s64 + 20144;
loc_831DBE00:
	// mulli r11,r28,24
	r11.s64 = r28.s64 * 24;
	// add r28,r11,r10
	r28.u64 = r11.u64 + ctx.r10.u64;
	// li r11,1
	r11.s64 = 1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// bne cr6,0x831dbe30
	if (!cr6.eq) goto loc_831DBE30;
	// addi r11,r27,-1
	r11.s64 = r27.s64 + -1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_831DBE30:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// bne cr6,0x831dbe4c
	if (!cr6.eq) goto loc_831DBE4C;
	// cntlzw r11,r23
	r11.u64 = r23.u32 == 0 ? 32 : __builtin_clz(r23.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
loc_831DBE4C:
	// stw r20,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r20.u32);
	// stw r20,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r20.u32);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// bne cr6,0x831dbe84
	if (!cr6.eq) goto loc_831DBE84;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,44
	ctx.r4.s64 = 44;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
loc_831DBE84:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x831dbeac
	if (!cr6.eq) goto loc_831DBEAC;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// addi r5,r11,-10856
	ctx.r5.s64 = r11.s64 + -10856;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// li r7,3048
	ctx.r7.s64 = 3048;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DBEAC:
	// stw r26,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r26.u32);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// stw r25,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r25.u32);
	// stw r20,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r20.u32);
	// stw r24,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r24.u32);
	// beq cr6,0x831dbf48
	if (cr6.eq) goto loc_831DBF48;
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x831dbf48
	if (cr6.eq) goto loc_831DBF48;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lwz r30,20(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r28,16(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lis r8,-32248
	ctx.r8.s64 = -2113404928;
	// addi r27,r11,3160
	r27.s64 = r11.s64 + 3160;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r4,r8,20860
	ctx.r4.s64 = ctx.r8.s64 + 20860;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,30
	ctx.r6.s64 = 30;
	// stw r24,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r24.u32);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r5,120(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 120);
	// stw r25,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r25.u32);
	// stw r26,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r26.u32);
	// stw r20,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r20.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mtctr r21
	ctr.u64 = r21.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r5,396(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 396);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// addi r4,r11,20728
	ctx.r4.s64 = r11.s64 + 20728;
	// li r6,99
	ctx.r6.s64 = 99;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// mtctr r21
	ctr.u64 = r21.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DBF48:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x82ca2c0c
	return;
}

PPC_WEAK_FUNC(sub_831DBCB8) {
	__imp__sub_831DBCB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DBF58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r20,r5
	r20.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// mr r21,r9
	r21.u64 = ctx.r9.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// addi r25,r11,-18548
	r25.s64 = r11.s64 + -18548;
	// addi r24,r10,20744
	r24.s64 = ctx.r10.s64 + 20744;
	// bne cr6,0x831dbfb4
	if (!cr6.eq) goto loc_831DBFB4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// addi r5,r11,-18224
	ctx.r5.s64 = r11.s64 + -18224;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// li r7,3110
	ctx.r7.s64 = 3110;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DBFB4:
	// cmpwi cr6,r26,-1
	cr6.compare<int32_t>(r26.s32, -1, xer);
	// bne cr6,0x831dbfc8
	if (!cr6.eq) goto loc_831DBFC8;
	// li r27,23
	r27.s64 = 23;
	// li r23,1
	r23.s64 = 1;
	// b 0x831dbff0
	goto loc_831DBFF0;
loc_831DBFC8:
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,43
	ctx.r4.s64 = 43;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,44
	ctx.r4.s64 = 44;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
loc_831DBFF0:
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// ble cr6,0x831dc00c
	if (!cr6.gt) goto loc_831DC00C;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831b3138
	sub_831B3138(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// b 0x831dc010
	goto loc_831DC010;
loc_831DC00C:
	// li r22,1
	r22.s64 = 1;
loc_831DC010:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// beq cr6,0x831dc028
	if (cr6.eq) goto loc_831DC028;
	// addi r11,r11,20144
	r11.s64 = r11.s64 + 20144;
	// addi r30,r11,-576
	r30.s64 = r11.s64 + -576;
	// b 0x831dc02c
	goto loc_831DC02C;
loc_831DC028:
	// addi r30,r11,20144
	r30.s64 = r11.s64 + 20144;
loc_831DC02C:
	// mulli r11,r27,24
	r11.s64 = r27.s64 * 24;
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// bne cr6,0x831dc0dc
	if (!cr6.eq) goto loc_831DC0DC;
	// addi r11,r27,-17
	r11.s64 = r27.s64 + -17;
	// lis r10,-31951
	ctx.r10.s64 = -2093940736;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,3584
	ctx.r10.s64 = ctx.r10.s64 + 3584;
	// lwzx r31,r11,r10
	r31.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dc078
	if (!cr6.eq) goto loc_831DC078;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// addi r5,r11,20992
	ctx.r5.s64 = r11.s64 + 20992;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// li r7,3140
	ctx.r7.s64 = 3140;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC078:
	// rlwinm r11,r23,2,0,29
	r11.u64 = rotl64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r31
	r31.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// blt cr6,0x831dc090
	if (cr6.lt) goto loc_831DC090;
	// cmpwi cr6,r31,24
	cr6.compare<int32_t>(r31.s32, 24, xer);
	// blt cr6,0x831dc0ac
	if (cr6.lt) goto loc_831DC0AC;
loc_831DC090:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// addi r5,r11,20952
	ctx.r5.s64 = r11.s64 + 20952;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// li r7,3142
	ctx.r7.s64 = 3142;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC0AC:
	// mulli r11,r31,24
	r11.s64 = r31.s64 * 24;
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// bne cr6,0x831dc0dc
	if (!cr6.eq) goto loc_831DC0DC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// addi r5,r11,20940
	ctx.r5.s64 = r11.s64 + 20940;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// li r7,3144
	ctx.r7.s64 = 3144;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC0DC:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r10,r20,2,0,29
	ctx.r10.u64 = rotl64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// beq cr6,0x831dc14c
	if (cr6.eq) goto loc_831DC14C;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x831dc14c
	if (cr6.eq) goto loc_831DC14C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r31,r11,3160
	r31.s64 = r11.s64 + 3160;
	// addi r4,r10,20916
	ctx.r4.s64 = ctx.r10.s64 + 20916;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// lwz r5,116(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// li r6,29
	ctx.r6.s64 = 29;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r5,396(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 396);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// addi r4,r11,20728
	ctx.r4.s64 = r11.s64 + 20728;
	// li r6,99
	ctx.r6.s64 = 99;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DC14C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	return;
}

PPC_WEAK_FUNC(sub_831DBF58) {
	__imp__sub_831DBF58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC158) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r23,r7
	r23.u64 = ctx.r7.u64;
	// mr r22,r8
	r22.u64 = ctx.r8.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// addi r25,r11,-18548
	r25.s64 = r11.s64 + -18548;
	// addi r24,r10,20744
	r24.s64 = ctx.r10.s64 + 20744;
	// bne cr6,0x831dc1b0
	if (!cr6.eq) goto loc_831DC1B0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// addi r5,r11,-18224
	ctx.r5.s64 = r11.s64 + -18224;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// li r7,3188
	ctx.r7.s64 = 3188;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC1B0:
	// cmpwi cr6,r26,-1
	cr6.compare<int32_t>(r26.s32, -1, xer);
	// bne cr6,0x831dc1c4
	if (!cr6.eq) goto loc_831DC1C4;
	// li r30,23
	r30.s64 = 23;
	// li r28,1
	r28.s64 = 1;
	// b 0x831dc1ec
	goto loc_831DC1EC;
loc_831DC1C4:
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,43
	ctx.r4.s64 = 43;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,44
	ctx.r4.s64 = 44;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
loc_831DC1EC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dc204
	if (cr6.eq) goto loc_831DC204;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831b3138
	sub_831B3138(ctx, base);
	// b 0x831dc208
	goto loc_831DC208;
loc_831DC204:
	// li r3,1
	ctx.r3.s64 = 1;
loc_831DC208:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// beq cr6,0x831dc220
	if (cr6.eq) goto loc_831DC220;
	// addi r11,r11,20144
	r11.s64 = r11.s64 + 20144;
	// addi r29,r11,-576
	r29.s64 = r11.s64 + -576;
	// b 0x831dc224
	goto loc_831DC224;
loc_831DC220:
	// addi r29,r11,20144
	r29.s64 = r11.s64 + 20144;
loc_831DC224:
	// mulli r11,r30,24
	r11.s64 = r30.s64 * 24;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lhz r10,6(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 6);
	// stw r10,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r10.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831dc2e0
	if (!cr6.eq) goto loc_831DC2E0;
	// addi r11,r30,-17
	r11.s64 = r30.s64 + -17;
	// lis r10,-31951
	ctx.r10.s64 = -2093940736;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,3584
	ctx.r10.s64 = ctx.r10.s64 + 3584;
	// lwzx r31,r11,r10
	r31.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dc278
	if (!cr6.eq) goto loc_831DC278;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// addi r5,r11,20992
	ctx.r5.s64 = r11.s64 + 20992;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// li r7,3219
	ctx.r7.s64 = 3219;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC278:
	// rlwinm r11,r28,2,0,29
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r31
	r31.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// blt cr6,0x831dc290
	if (cr6.lt) goto loc_831DC290;
	// cmpwi cr6,r31,24
	cr6.compare<int32_t>(r31.s32, 24, xer);
	// blt cr6,0x831dc2ac
	if (cr6.lt) goto loc_831DC2AC;
loc_831DC290:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// addi r5,r11,20952
	ctx.r5.s64 = r11.s64 + 20952;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// li r7,3221
	ctx.r7.s64 = 3221;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC2AC:
	// mulli r11,r31,24
	r11.s64 = r31.s64 * 24;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lhz r11,6(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 6);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// bne 0x831dc2e0
	if (!cr0.eq) goto loc_831DC2E0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// addi r5,r11,21008
	ctx.r5.s64 = r11.s64 + 21008;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// li r7,3223
	ctx.r7.s64 = 3223;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC2E0:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x831dc31c
	if (cr6.eq) goto loc_831DC31C;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x831dc31c
	if (cr6.eq) goto loc_831DC31C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lwz r8,0(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// li r6,100
	ctx.r6.s64 = 100;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// lwz r5,400(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 400);
	// mtctr r23
	ctr.u64 = r23.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DC31C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_831DC158) {
	__imp__sub_831DC158(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC328) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dc374
	if (!cr6.eq) goto loc_831DC374;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3264
	ctx.r7.s64 = 3264;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC374:
	// cmpwi cr6,r27,-1
	cr6.compare<int32_t>(r27.s32, -1, xer);
	// bne cr6,0x831dc388
	if (!cr6.eq) goto loc_831DC388;
	// li r30,23
	r30.s64 = 23;
	// li r26,1
	r26.s64 = 1;
	// b 0x831dc3b0
	goto loc_831DC3B0;
loc_831DC388:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,43
	ctx.r4.s64 = 43;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,44
	ctx.r4.s64 = 44;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
loc_831DC3B0:
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// ble cr6,0x831dc3cc
	if (!cr6.gt) goto loc_831DC3CC;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831b3138
	sub_831B3138(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x831dc3d0
	goto loc_831DC3D0;
loc_831DC3CC:
	// li r31,1
	r31.s64 = 1;
loc_831DC3D0:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// addi r11,r11,20144
	r11.s64 = r11.s64 + 20144;
	// beq cr6,0x831dc400
	if (cr6.eq) goto loc_831DC400;
	// addi r10,r11,-576
	ctx.r10.s64 = r11.s64 + -576;
	// mulli r9,r30,24
	ctx.r9.s64 = r30.s64 * 24;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r11,r11,-576
	r11.s64 = r11.s64 + -576;
	// lhzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + ctx.r10.u32);
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// b 0x831dc414
	goto loc_831DC414;
loc_831DC400:
	// mulli r10,r30,24
	ctx.r10.s64 = r30.s64 * 24;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lhzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + ctx.r9.u32);
	// stw r9,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r9.u32);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_831DC414:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831dc434
	if (!cr6.eq) goto loc_831DC434;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831dc430
	if (cr6.eq) goto loc_831DC430;
	// li r11,1
	r11.s64 = 1;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// b 0x831dc434
	goto loc_831DC434;
loc_831DC430:
	// stw r26,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r26.u32);
loc_831DC434:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831dc490
	if (cr6.eq) goto loc_831DC490;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831dc490
	if (cr6.eq) goto loc_831DC490;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lwz r8,0(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r30,r11,3160
	r30.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// li r6,28
	ctx.r6.s64 = 28;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r5,112(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 112);
	// mtctr r25
	ctr.u64 = r25.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r5,396(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 396);
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// addi r4,r11,20728
	ctx.r4.s64 = r11.s64 + 20728;
	// li r6,99
	ctx.r6.s64 = 99;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// mtctr r25
	ctr.u64 = r25.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DC490:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_831DC328) {
	__imp__sub_831DC328(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC4A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,82
	ctx.r4.s64 = 82;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// mr r27,r9
	r27.u64 = ctx.r9.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// li r4,83
	ctx.r4.s64 = 83;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,84
	ctx.r4.s64 = 84;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// stw r24,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r24.u32);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// stw r23,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r23.u32);
	// stw r10,0(r25)
	PPC_STORE_U32(r25.u32 + 0, ctx.r10.u32);
	// beq cr6,0x831dc54c
	if (cr6.eq) goto loc_831DC54C;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dc54c
	if (cr6.eq) goto loc_831DC54C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lis r7,-32248
	ctx.r7.s64 = -2113404928;
	// lwz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r7,21036
	ctx.r4.s64 = ctx.r7.s64 + 21036;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,12
	ctx.r6.s64 = 12;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,48(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DC54C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_831DC4A0) {
	__imp__sub_831DC4A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC558) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dc59c
	if (!cr6.eq) goto loc_831DC59C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3379
	ctx.r7.s64 = 3379;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC59C:
	// li r4,130
	ctx.r4.s64 = 130;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// stfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dc5ec
	if (cr6.eq) goto loc_831DC5EC;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dc5ec
	if (cr6.eq) goto loc_831DC5EC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,103
	ctx.r6.s64 = 103;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,412(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 412);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DC5EC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DC558) {
	__imp__sub_831DC558(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC5F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dc63c
	if (!cr6.eq) goto loc_831DC63C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3411
	ctx.r7.s64 = 3411;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC63C:
	// li r4,129
	ctx.r4.s64 = 129;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// stfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dc68c
	if (cr6.eq) goto loc_831DC68C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dc68c
	if (cr6.eq) goto loc_831DC68C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,104
	ctx.r6.s64 = 104;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,416(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 416);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DC68C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DC5F8) {
	__imp__sub_831DC5F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC698) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,21080(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 21080);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DC698) {
	__imp__sub_831DC698(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC6B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dc6f4
	if (!cr6.eq) goto loc_831DC6F4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3457
	ctx.r7.s64 = 3457;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC6F4:
	// li r4,580
	ctx.r4.s64 = 580;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r4,581
	ctx.r4.s64 = 581;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831dc740
	if (!cr6.eq) goto loc_831DC740;
	// addi r11,r29,-1
	r11.s64 = r29.s64 + -1;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,21084(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 21084);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// b 0x831dc748
	goto loc_831DC748;
loc_831DC740:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lfs f0,21080(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 21080);
	f0.f64 = double(temp.f32);
loc_831DC748:
	// stfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dc790
	if (cr6.eq) goto loc_831DC790;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dc790
	if (cr6.eq) goto loc_831DC790;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// fmr f1,f0
	ctx.f1.f64 = f0.f64;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// li r6,67
	ctx.r6.s64 = 67;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,268(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 268);
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DC790:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DC6B0) {
	__imp__sub_831DC6B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC7A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,21088(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 21088);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DC7A0) {
	__imp__sub_831DC7A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC7B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dc7fc
	if (!cr6.eq) goto loc_831DC7FC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3516
	ctx.r7.s64 = 3516;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC7FC:
	// li r4,1000
	ctx.r4.s64 = 1000;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// stfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dc84c
	if (cr6.eq) goto loc_831DC84C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dc84c
	if (cr6.eq) goto loc_831DC84C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,9
	ctx.r6.s64 = 9;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,36(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DC84C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DC7B8) {
	__imp__sub_831DC7B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC858) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dc89c
	if (!cr6.eq) goto loc_831DC89C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3546
	ctx.r7.s64 = 3546;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC89C:
	// li r4,1001
	ctx.r4.s64 = 1001;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// stfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dc8ec
	if (cr6.eq) goto loc_831DC8EC;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dc8ec
	if (cr6.eq) goto loc_831DC8EC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,69
	ctx.r6.s64 = 69;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,276(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 276);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DC8EC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DC858) {
	__imp__sub_831DC858(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC8F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dc93c
	if (!cr6.eq) goto loc_831DC93C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3577
	ctx.r7.s64 = 3577;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC93C:
	// li r4,1002
	ctx.r4.s64 = 1002;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// stfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dc98c
	if (cr6.eq) goto loc_831DC98C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dc98c
	if (cr6.eq) goto loc_831DC98C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,70
	ctx.r6.s64 = 70;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,280(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 280);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DC98C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DC8F8) {
	__imp__sub_831DC8F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC998) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,3080(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DC998) {
	__imp__sub_831DC998(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DC9B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dc9f8
	if (!cr6.eq) goto loc_831DC9F8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3620
	ctx.r7.s64 = 3620;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DC9F8:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b88c0
	sub_831B88C0(ctx, base);
	// stfs f1,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dca50
	if (cr6.eq) goto loc_831DCA50;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dca50
	if (cr6.eq) goto loc_831DCA50;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,11
	ctx.r6.s64 = 11;
	// lwz r5,44(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DCA50:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DC9B0) {
	__imp__sub_831DC9B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DCA60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dcaa8
	if (!cr6.eq) goto loc_831DCAA8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3654
	ctx.r7.s64 = 3654;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DCAA8:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,17
	ctx.r4.s64 = 17;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b88c0
	sub_831B88C0(ctx, base);
	// stfs f1,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dcb00
	if (cr6.eq) goto loc_831DCB00;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dcb00
	if (cr6.eq) goto loc_831DCB00;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,72
	ctx.r6.s64 = 72;
	// lwz r5,288(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 288);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DCB00:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DCA60) {
	__imp__sub_831DCA60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DCB10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dcb58
	if (!cr6.eq) goto loc_831DCB58;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3688
	ctx.r7.s64 = 3688;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DCB58:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,18
	ctx.r4.s64 = 18;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b88c0
	sub_831B88C0(ctx, base);
	// stfs f1,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dcbb0
	if (cr6.eq) goto loc_831DCBB0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dcbb0
	if (cr6.eq) goto loc_831DCBB0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,73
	ctx.r6.s64 = 73;
	// lwz r5,292(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 292);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DCBB0:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DCB10) {
	__imp__sub_831DCB10(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DCBC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dcc08
	if (!cr6.eq) goto loc_831DCC08;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3721
	ctx.r7.s64 = 3721;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DCC08:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,19
	ctx.r4.s64 = 19;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b88c0
	sub_831B88C0(ctx, base);
	// stfs f1,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dcc60
	if (cr6.eq) goto loc_831DCC60;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dcc60
	if (cr6.eq) goto loc_831DCC60;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,74
	ctx.r6.s64 = 74;
	// lwz r5,296(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 296);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DCC60:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DCBC0) {
	__imp__sub_831DCBC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DCC70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// addi r29,r11,-18548
	r29.s64 = r11.s64 + -18548;
	// addi r28,r10,20744
	r28.s64 = ctx.r10.s64 + 20744;
	// bne cr6,0x831dccc0
	if (!cr6.eq) goto loc_831DCCC0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,-18224
	ctx.r5.s64 = r11.s64 + -18224;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,3754
	ctx.r7.s64 = 3754;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DCCC0:
	// li r4,165
	ctx.r4.s64 = 165;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,3
	cr6.compare<uint32_t>(ctx.r3.u32, 3, xer);
	// bne cr6,0x831dcce8
	if (!cr6.eq) goto loc_831DCCE8;
	// li r4,166
	ctx.r4.s64 = 166;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// stfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
	// b 0x831dccf4
	goto loc_831DCCF4;
loc_831DCCE8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,3084(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
loc_831DCCF4:
	// li r4,170
	ctx.r4.s64 = 170;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// beq cr6,0x831dcd24
	if (cr6.eq) goto loc_831DCD24;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,21112
	ctx.r5.s64 = r11.s64 + 21112;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,3767
	ctx.r7.s64 = 3767;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DCD24:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dcd68
	if (cr6.eq) goto loc_831DCD68;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831dcd68
	if (cr6.eq) goto loc_831DCD68;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,26
	ctx.r6.s64 = 26;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r5,104(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 104);
	// mtctr r27
	ctr.u64 = r27.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DCD68:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831DCC70) {
	__imp__sub_831DCC70(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DCD78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// addi r29,r11,-18548
	r29.s64 = r11.s64 + -18548;
	// addi r28,r10,20744
	r28.s64 = ctx.r10.s64 + 20744;
	// bne cr6,0x831dcdcc
	if (!cr6.eq) goto loc_831DCDCC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,-18224
	ctx.r5.s64 = r11.s64 + -18224;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,3800
	ctx.r7.s64 = 3800;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DCDCC:
	// li r4,165
	ctx.r4.s64 = 165;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,3
	cr6.compare<uint32_t>(ctx.r3.u32, 3, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x831dce30
	if (!cr6.eq) goto loc_831DCE30;
	// li r4,166
	ctx.r4.s64 = 166;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// li r4,167
	ctx.r4.s64 = 167;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// fsubs f0,f1,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = static_cast<float>(ctx.f1.f64 - f31.f64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,3084(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x831dce20
	if (!cr6.eq) goto loc_831DCE20;
	// lis r11,32639
	r11.s64 = 2139029504;
	// ori r11,r11,65535
	r11.u64 = r11.u64 | 65535;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// b 0x831dce54
	goto loc_831DCE54;
loc_831DCE20:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,3080(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 / f0.f64));
	// b 0x831dce50
	goto loc_831DCE50;
loc_831DCE30:
	// li r4,168
	ctx.r4.s64 = 168;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,8976(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8976);
	f0.f64 = double(temp.f32);
	// fdivs f13,f0,f1
	ctx.f13.f64 = double(float(f0.f64 / ctx.f1.f64));
	// lfs f0,3080(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3080);
	f0.f64 = double(temp.f32);
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
loc_831DCE50:
	// stfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
loc_831DCE54:
	// li r4,170
	ctx.r4.s64 = 170;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// beq cr6,0x831dce84
	if (cr6.eq) goto loc_831DCE84;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,21256
	ctx.r5.s64 = r11.s64 + 21256;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,3827
	ctx.r7.s64 = 3827;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DCE84:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dcec8
	if (cr6.eq) goto loc_831DCEC8;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831dcec8
	if (cr6.eq) goto loc_831DCEC8;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,27
	ctx.r6.s64 = 27;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r5,108(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// mtctr r27
	ctr.u64 = r27.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DCEC8:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831DCD78) {
	__imp__sub_831DCD78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DCED8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dcf1c
	if (!cr6.eq) goto loc_831DCF1C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3857
	ctx.r7.s64 = 3857;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DCF1C:
	// li r4,998
	ctx.r4.s64 = 998;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// stfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dcf6c
	if (cr6.eq) goto loc_831DCF6C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dcf6c
	if (cr6.eq) goto loc_831DCF6C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,93
	ctx.r6.s64 = 93;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,372(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 372);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DCF6C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DCED8) {
	__imp__sub_831DCED8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DCF78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dcfbc
	if (!cr6.eq) goto loc_831DCFBC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,3889
	ctx.r7.s64 = 3889;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DCFBC:
	// li r4,999
	ctx.r4.s64 = 999;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// stfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dd00c
	if (cr6.eq) goto loc_831DD00C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dd00c
	if (cr6.eq) goto loc_831DD00C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,94
	ctx.r6.s64 = 94;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,376(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 376);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD00C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DCF78) {
	__imp__sub_831DCF78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD018) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,10976(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 10976);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DD018) {
	__imp__sub_831DD018(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD030) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,10972(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 10972);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DD030) {
	__imp__sub_831DD030(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD048) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,10968(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 10968);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DD048) {
	__imp__sub_831DD048(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD060) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,-12860(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -12860);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DD060) {
	__imp__sub_831DD060(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD078) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,10964(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 10964);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DD078) {
	__imp__sub_831DD078(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD090) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,-12848(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -12848);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DD090) {
	__imp__sub_831DD090(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD0A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,-12864(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -12864);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DD0A8) {
	__imp__sub_831DD0A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD0C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,10960(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 10960);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DD0C0) {
	__imp__sub_831DD0C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD0D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,3084(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DD0D8) {
	__imp__sub_831DD0D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD0F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dd138
	if (!cr6.eq) goto loc_831DD138;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,4098
	ctx.r7.s64 = 4098;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD138:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,86
	ctx.r4.s64 = 86;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b88c0
	sub_831B88C0(ctx, base);
	// stfs f1,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dd190
	if (cr6.eq) goto loc_831DD190;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dd190
	if (cr6.eq) goto loc_831DD190;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,51
	ctx.r6.s64 = 51;
	// lwz r5,204(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 204);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD190:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DD0F0) {
	__imp__sub_831DD0F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD1A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dd1e8
	if (!cr6.eq) goto loc_831DD1E8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,4133
	ctx.r7.s64 = 4133;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD1E8:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,48
	ctx.r4.s64 = 48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// clrldi r11,r3,32
	r11.u64 = ctx.r3.u64 & 0xFFFFFFFF;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// stfs f1,0(r28)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// beq cr6,0x831dd250
	if (cr6.eq) goto loc_831DD250;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dd250
	if (cr6.eq) goto loc_831DD250;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// li r6,54
	ctx.r6.s64 = 54;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,216(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 216);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD250:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DD1A0) {
	__imp__sub_831DD1A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD260) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dd2a4
	if (!cr6.eq) goto loc_831DD2A4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,4163
	ctx.r7.s64 = 4163;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD2A4:
	// li r4,166
	ctx.r4.s64 = 166;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// stfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dd2f4
	if (cr6.eq) goto loc_831DD2F4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dd2f4
	if (cr6.eq) goto loc_831DD2F4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,24
	ctx.r6.s64 = 24;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,96(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD2F4:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DD260) {
	__imp__sub_831DD260(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD300) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dd344
	if (!cr6.eq) goto loc_831DD344;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,4195
	ctx.r7.s64 = 4195;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD344:
	// li r4,167
	ctx.r4.s64 = 167;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// stfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dd394
	if (cr6.eq) goto loc_831DD394;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dd394
	if (cr6.eq) goto loc_831DD394;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,75
	ctx.r6.s64 = 75;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,300(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 300);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD394:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DD300) {
	__imp__sub_831DD300(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD3A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dd3e4
	if (!cr6.eq) goto loc_831DD3E4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,4225
	ctx.r7.s64 = 4225;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD3E4:
	// li r4,168
	ctx.r4.s64 = 168;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b78f0
	sub_831B78F0(ctx, base);
	// stfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dd434
	if (cr6.eq) goto loc_831DD434;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dd434
	if (cr6.eq) goto loc_831DD434;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21064
	ctx.r4.s64 = ctx.r10.s64 + 21064;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,25
	ctx.r6.s64 = 25;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,100(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 100);
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD434:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DD3A0) {
	__imp__sub_831DD3A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD440) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x831dd484
	if (!cr6.eq) goto loc_831DD484;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,4257
	ctx.r7.s64 = 4257;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD484:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// lfs f1,3084(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,0(r29)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// beq cr6,0x831dd4d4
	if (cr6.eq) goto loc_831DD4D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dd4d4
	if (cr6.eq) goto loc_831DD4D4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// li r6,64
	ctx.r6.s64 = 64;
	// lwz r5,256(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 256);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r31
	ctr.u64 = r31.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD4D4:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DD440) {
	__imp__sub_831DD440(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD4E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dd528
	if (!cr6.eq) goto loc_831DD528;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,4293
	ctx.r7.s64 = 4293;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD528:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,26
	ctx.r4.s64 = 26;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b88c0
	sub_831B88C0(ctx, base);
	// stfs f1,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dd580
	if (cr6.eq) goto loc_831DD580;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dd580
	if (cr6.eq) goto loc_831DD580;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,65
	ctx.r6.s64 = 65;
	// lwz r5,260(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 260);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD580:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DD4E0) {
	__imp__sub_831DD4E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD590) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dd5d8
	if (!cr6.eq) goto loc_831DD5D8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,4327
	ctx.r7.s64 = 4327;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD5D8:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,25
	ctx.r4.s64 = 25;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b88c0
	sub_831B88C0(ctx, base);
	// stfs f1,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dd630
	if (cr6.eq) goto loc_831DD630;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dd630
	if (cr6.eq) goto loc_831DD630;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,66
	ctx.r6.s64 = 66;
	// lwz r5,264(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 264);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r29
	ctr.u64 = r29.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD630:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DD590) {
	__imp__sub_831DD590(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD640) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dd688
	if (!cr6.eq) goto loc_831DD688;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,4363
	ctx.r7.s64 = 4363;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD688:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,89
	ctx.r4.s64 = 89;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// lis r11,16384
	r11.s64 = 1073741824;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// rlwimi r11,r3,30,2,31
	r11.u64 = (rotl32(ctx.r3.u32, 30) & 0x3FFFFFFF) | (r11.u64 & 0xFFFFFFFFC0000000);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// beq cr6,0x831dd6ec
	if (cr6.eq) goto loc_831DD6EC;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dd6ec
	if (cr6.eq) goto loc_831DD6EC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,62
	ctx.r6.s64 = 62;
	// lwz r5,248(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 248);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD6EC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DD640) {
	__imp__sub_831DD640(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD6F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// lis r11,19200
	r11.s64 = 1258291200;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831dd760
	if (cr6.eq) goto loc_831DD760;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dd760
	if (cr6.eq) goto loc_831DD760;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r6,88
	ctx.r6.s64 = 88;
	// lwz r5,352(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 352);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r31
	ctr.u64 = r31.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD760:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831DD6F8) {
	__imp__sub_831DD6F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD770) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// mr r24,r7
	r24.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// addi r28,r11,-18548
	r28.s64 = r11.s64 + -18548;
	// addi r27,r10,20744
	r27.s64 = ctx.r10.s64 + 20744;
	// bne cr6,0x831dd7c4
	if (!cr6.eq) goto loc_831DD7C4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r11,-18224
	ctx.r5.s64 = r11.s64 + -18224;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,4437
	ctx.r7.s64 = 4437;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD7C4:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,91
	ctx.r4.s64 = 91;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,92
	ctx.r4.s64 = 92;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// rlwinm r11,r30,2,0,29
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-31951
	ctx.r10.s64 = -2093940736;
	// add r9,r11,r3
	ctx.r9.u64 = r11.u64 + ctx.r3.u64;
	// addi r11,r10,3608
	r11.s64 = ctx.r10.s64 + 3608;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r30,2
	cr6.compare<uint32_t>(r30.u32, 2, xer);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r31,-4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// beq cr6,0x831dd848
	if (cr6.eq) goto loc_831DD848;
	// cmplwi cr6,r30,3
	cr6.compare<uint32_t>(r30.u32, 3, xer);
	// beq cr6,0x831dd848
	if (cr6.eq) goto loc_831DD848;
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// beq cr6,0x831dd840
	if (cr6.eq) goto loc_831DD840;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831dd840
	if (cr6.eq) goto loc_831DD840;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r11,16216
	ctx.r5.s64 = r11.s64 + 16216;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,4450
	ctx.r7.s64 = 4450;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD840:
	// li r11,7
	r11.s64 = 7;
	// b 0x831dd84c
	goto loc_831DD84C;
loc_831DD848:
	// li r11,2
	r11.s64 = 2;
loc_831DD84C:
	// rlwinm r11,r11,8,0,23
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 8) & 0xFFFFFF00;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// oris r11,r11,75
	r11.u64 = r11.u64 | 4915200;
	// or r11,r11,r31
	r11.u64 = r11.u64 | r31.u64;
	// rlwinm r11,r11,8,0,23
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 8) & 0xFFFFFF00;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// beq cr6,0x831dd8a8
	if (cr6.eq) goto loc_831DD8A8;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831dd8a8
	if (cr6.eq) goto loc_831DD8A8;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,0(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r26.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r6,89
	ctx.r6.s64 = 89;
	// lwz r5,356(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 356);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// mtctr r25
	ctr.u64 = r25.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD8A8:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_831DD770) {
	__imp__sub_831DD770(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD8B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dd900
	if (!cr6.eq) goto loc_831DD900;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,4490
	ctx.r7.s64 = 4490;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD900:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,90
	ctx.r4.s64 = 90;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// oris r11,r3,19200
	r11.u64 = ctx.r3.u64 | 1258291200;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// beq cr6,0x831dd960
	if (cr6.eq) goto loc_831DD960;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dd960
	if (cr6.eq) goto loc_831DD960;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d9230
	sub_831D9230(ctx, base);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,21092
	ctx.r4.s64 = ctx.r10.s64 + 21092;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,90
	ctx.r6.s64 = 90;
	// lwz r5,360(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 360);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DD960:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DD8B8) {
	__imp__sub_831DD8B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DD970) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831dd9b8
	if (!cr6.eq) goto loc_831DD9B8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,20744
	ctx.r6.s64 = r11.s64 + 20744;
	// addi r5,r10,-18224
	ctx.r5.s64 = ctx.r10.s64 + -18224;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,447
	ctx.r7.s64 = 447;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DD9B8:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,7
	ctx.r4.s64 = 7;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831dda30
	if (!cr6.eq) goto loc_831DDA30;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dd9ec
	if (cr6.eq) goto loc_831DD9EC;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,43
	ctx.r4.s64 = 43;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DD9EC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dda28
	if (cr6.eq) goto loc_831DDA28;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dda28
	if (cr6.eq) goto loc_831DDA28;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,105
	ctx.r6.s64 = 105;
	// lwz r5,420(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 420);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DDA28:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831dda8c
	goto loc_831DDA8C;
loc_831DDA30:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831dda4c
	if (cr6.eq) goto loc_831DDA4C;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DDA4C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831dda88
	if (cr6.eq) goto loc_831DDA88;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dda88
	if (cr6.eq) goto loc_831DDA88;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,105
	ctx.r6.s64 = 105;
	// lwz r5,420(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 420);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DDA88:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DDA8C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DD970) {
	__imp__sub_831DD970(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DDA98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// addi r30,r11,-18548
	r30.s64 = r11.s64 + -18548;
	// addi r29,r10,20744
	r29.s64 = ctx.r10.s64 + 20744;
	// bne cr6,0x831ddaec
	if (!cr6.eq) goto loc_831DDAEC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r11,-18224
	ctx.r5.s64 = r11.s64 + -18224;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r7,504
	ctx.r7.s64 = 504;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDAEC:
	// cmpwi cr6,r31,16
	cr6.compare<int32_t>(r31.s32, 16, xer);
	// blt cr6,0x831ddb10
	if (cr6.lt) goto loc_831DDB10;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r11,21412
	ctx.r5.s64 = r11.s64 + 21412;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r7,505
	ctx.r7.s64 = 505;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDB10:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bge cr6,0x831ddb34
	if (!cr6.lt) goto loc_831DDB34;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r11,21400
	ctx.r5.s64 = r11.s64 + 21400;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r7,506
	ctx.r7.s64 = 506;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDB34:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,12
	ctx.r4.s64 = 12;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// beq cr6,0x831ddba8
	if (cr6.eq) goto loc_831DDBA8;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831ddb68
	if (cr6.eq) goto loc_831DDB68;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DDB68:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831ddba0
	if (cr6.eq) goto loc_831DDBA0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831ddba0
	if (cr6.eq) goto loc_831DDBA0;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// lwz r5,3160(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 3160);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mtctr r26
	ctr.u64 = r26.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DDBA0:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831ddc00
	goto loc_831DDC00;
loc_831DDBA8:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831ddbc4
	if (cr6.eq) goto loc_831DDBC4;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DDBC4:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831ddbfc
	if (cr6.eq) goto loc_831DDBFC;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831ddbfc
	if (cr6.eq) goto loc_831DDBFC;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// lwz r5,3160(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 3160);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mtctr r26
	ctr.u64 = r26.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DDBFC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DDC00:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831DDA98) {
	__imp__sub_831DDA98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DDC08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// addi r29,r11,-18548
	r29.s64 = r11.s64 + -18548;
	// addi r28,r10,20744
	r28.s64 = ctx.r10.s64 + 20744;
	// bne cr6,0x831ddc5c
	if (!cr6.eq) goto loc_831DDC5C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,-18224
	ctx.r5.s64 = r11.s64 + -18224;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,561
	ctx.r7.s64 = 561;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDC5C:
	// cmpwi cr6,r30,16
	cr6.compare<int32_t>(r30.s32, 16, xer);
	// blt cr6,0x831ddc80
	if (cr6.lt) goto loc_831DDC80;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,21412
	ctx.r5.s64 = r11.s64 + 21412;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,562
	ctx.r7.s64 = 562;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDC80:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bge cr6,0x831ddca4
	if (!cr6.lt) goto loc_831DDCA4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,21400
	ctx.r5.s64 = r11.s64 + 21400;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,563
	ctx.r7.s64 = 563;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDCA4:
	// li r4,135
	ctx.r4.s64 = 135;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,12
	ctx.r4.s64 = 12;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831ddd34
	if (!cr6.eq) goto loc_831DDD34;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x831ddd34
	if (!cr6.eq) goto loc_831DDD34;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831ddcf0
	if (cr6.eq) goto loc_831DDCF0;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DDCF0:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831ddd2c
	if (cr6.eq) goto loc_831DDD2C;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831ddd2c
	if (cr6.eq) goto loc_831DDD2C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mtctr r26
	ctr.u64 = r26.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DDD2C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831ddd90
	goto loc_831DDD90;
loc_831DDD34:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831ddd50
	if (cr6.eq) goto loc_831DDD50;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DDD50:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831ddd8c
	if (cr6.eq) goto loc_831DDD8C;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831ddd8c
	if (cr6.eq) goto loc_831DDD8C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mtctr r26
	ctr.u64 = r26.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DDD8C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DDD90:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831DDC08) {
	__imp__sub_831DDC08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DDD98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// addi r29,r11,-18548
	r29.s64 = r11.s64 + -18548;
	// addi r28,r10,20744
	r28.s64 = ctx.r10.s64 + 20744;
	// bne cr6,0x831dddec
	if (!cr6.eq) goto loc_831DDDEC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,-18224
	ctx.r5.s64 = r11.s64 + -18224;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,619
	ctx.r7.s64 = 619;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDDEC:
	// cmpwi cr6,r30,16
	cr6.compare<int32_t>(r30.s32, 16, xer);
	// blt cr6,0x831dde10
	if (cr6.lt) goto loc_831DDE10;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,21412
	ctx.r5.s64 = r11.s64 + 21412;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,620
	ctx.r7.s64 = 620;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDE10:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bge cr6,0x831dde34
	if (!cr6.lt) goto loc_831DDE34;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,21400
	ctx.r5.s64 = r11.s64 + 21400;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,621
	ctx.r7.s64 = 621;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDE34:
	// li r4,135
	ctx.r4.s64 = 135;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,12
	ctx.r4.s64 = 12;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831ddec4
	if (!cr6.eq) goto loc_831DDEC4;
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// bne cr6,0x831ddec4
	if (!cr6.eq) goto loc_831DDEC4;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831dde80
	if (cr6.eq) goto loc_831DDE80;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DDE80:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831ddebc
	if (cr6.eq) goto loc_831DDEBC;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831ddebc
	if (cr6.eq) goto loc_831DDEBC;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mtctr r26
	ctr.u64 = r26.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DDEBC:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831ddf20
	goto loc_831DDF20;
loc_831DDEC4:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831ddee0
	if (cr6.eq) goto loc_831DDEE0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DDEE0:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831ddf1c
	if (cr6.eq) goto loc_831DDF1C;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831ddf1c
	if (cr6.eq) goto loc_831DDF1C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mtctr r26
	ctr.u64 = r26.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DDF1C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DDF20:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831DDD98) {
	__imp__sub_831DDD98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DDF28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// addi r29,r11,-18548
	r29.s64 = r11.s64 + -18548;
	// addi r28,r10,20744
	r28.s64 = ctx.r10.s64 + 20744;
	// bne cr6,0x831ddf7c
	if (!cr6.eq) goto loc_831DDF7C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,-18224
	ctx.r5.s64 = r11.s64 + -18224;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,677
	ctx.r7.s64 = 677;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDF7C:
	// cmpwi cr6,r30,16
	cr6.compare<int32_t>(r30.s32, 16, xer);
	// blt cr6,0x831ddfa0
	if (cr6.lt) goto loc_831DDFA0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,21412
	ctx.r5.s64 = r11.s64 + 21412;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,678
	ctx.r7.s64 = 678;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDFA0:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bge cr6,0x831ddfc4
	if (!cr6.lt) goto loc_831DDFC4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,21400
	ctx.r5.s64 = r11.s64 + 21400;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,679
	ctx.r7.s64 = 679;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DDFC4:
	// li r4,135
	ctx.r4.s64 = 135;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,12
	ctx.r4.s64 = 12;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831de054
	if (!cr6.eq) goto loc_831DE054;
	// cmplwi cr6,r29,2
	cr6.compare<uint32_t>(r29.u32, 2, xer);
	// bne cr6,0x831de054
	if (!cr6.eq) goto loc_831DE054;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831de010
	if (cr6.eq) goto loc_831DE010;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DE010:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831de04c
	if (cr6.eq) goto loc_831DE04C;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831de04c
	if (cr6.eq) goto loc_831DE04C;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,3
	ctx.r6.s64 = 3;
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mtctr r26
	ctr.u64 = r26.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DE04C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831de0b0
	goto loc_831DE0B0;
loc_831DE054:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831de070
	if (cr6.eq) goto loc_831DE070;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831093f0
	sub_831093F0(ctx, base);
loc_831DE070:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831de0ac
	if (cr6.eq) goto loc_831DE0AC;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831de0ac
	if (cr6.eq) goto loc_831DE0AC;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,3160
	r11.s64 = r11.s64 + 3160;
	// addi r4,r10,20840
	ctx.r4.s64 = ctx.r10.s64 + 20840;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,3
	ctx.r6.s64 = 3;
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mtctr r26
	ctr.u64 = r26.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DE0AC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DE0B0:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831DDF28) {
	__imp__sub_831DDF28(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DE0B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// li r27,0
	r27.s64 = 0;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831de104
	if (!cr6.eq) goto loc_831DE104;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,21432
	ctx.r6.s64 = r11.s64 + 21432;
	// addi r5,r10,21424
	ctx.r5.s64 = ctx.r10.s64 + 21424;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,683
	ctx.r7.s64 = 683;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE104:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831de118
	if (!cr6.eq) goto loc_831DE118;
loc_831DE110:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831de154
	goto loc_831DE154;
loc_831DE118:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831de110
	if (cr6.eq) goto loc_831DE110;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
loc_831DE124:
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x831de15c
	if (!cr6.eq) goto loc_831DE15C;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r29,r28
	cr6.compare<uint32_t>(r29.u32, r28.u32, xer);
	// bne cr6,0x831de16c
	if (!cr6.eq) goto loc_831DE16C;
	// li r27,1
	r27.s64 = 1;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
loc_831DE150:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_831DE154:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_831DE15C:
	// bge cr6,0x831de168
	if (!cr6.lt) goto loc_831DE168;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// b 0x831de16c
	goto loc_831DE16C;
loc_831DE168:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_831DE16C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831de124
	if (!cr6.eq) goto loc_831DE124;
	// b 0x831de150
	goto loc_831DE150;
}

PPC_WEAK_FUNC(sub_831DE0B8) {
	__imp__sub_831DE0B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DE178) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831de188
	if (cr6.eq) goto loc_831DE188;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// blr 
	return;
loc_831DE188:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DE178) {
	__imp__sub_831DE178(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DE190) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,16(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x831b48e0
	sub_831B48E0(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// stw r30,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r30.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DE190) {
	__imp__sub_831DE190(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DE1E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// addi r27,r11,-18548
	r27.s64 = r11.s64 + -18548;
	// addi r26,r10,21432
	r26.s64 = ctx.r10.s64 + 21432;
	// bne cr6,0x831de238
	if (!cr6.eq) goto loc_831DE238;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,-3704
	ctx.r5.s64 = r11.s64 + -3704;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,66
	ctx.r7.s64 = 66;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE238:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x831de25c
	if (!cr6.eq) goto loc_831DE25C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,-3716
	ctx.r5.s64 = r11.s64 + -3716;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,67
	ctx.r7.s64 = 67;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE25C:
	// li r4,28
	ctx.r4.s64 = 28;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r30
	ctr.u64 = r30.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x831de290
	if (!cr0.eq) goto loc_831DE290;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,21536
	ctx.r5.s64 = r11.s64 + 21536;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,70
	ctx.r7.s64 = 70;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE290:
	// li r11,0
	r11.s64 = 0;
	// stw r29,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r29.u32);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// li r4,20
	ctx.r4.s64 = 20;
	// stw r28,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r28.u32);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831b47b0
	sub_831B47B0(ctx, base);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831de2e8
	if (!cr0.eq) goto loc_831DE2E8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,21512
	ctx.r5.s64 = r11.s64 + 21512;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,88
	ctx.r7.s64 = 88;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE2E8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831DE1E8) {
	__imp__sub_831DE1E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DE2F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// li r26,0
	r26.s64 = 0;
	// lwz r24,20(r31)
	r24.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r28,1
	r28.s64 = 1;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831de464
	if (cr6.eq) goto loc_831DE464;
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831de354
	if (!cr6.eq) goto loc_831DE354;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// bl 0x831de190
	sub_831DE190(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r30,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r30.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
loc_831DE354:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831de41c
	if (cr6.eq) goto loc_831DE41C;
loc_831DE35C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// bne cr6,0x831de3b0
	if (!cr6.eq) goto loc_831DE3B0;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r26,r27
	cr6.compare<uint32_t>(r26.u32, r27.u32, xer);
	// beq cr6,0x831de41c
	if (cr6.eq) goto loc_831DE41C;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831de3a8
	if (!cr6.eq) goto loc_831DE3A8;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831de190
	sub_831DE190(ctx, base);
	// stw r3,12(r30)
	PPC_STORE_U32(r30.u32 + 12, ctx.r3.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
loc_831DE3A8:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// b 0x831de410
	goto loc_831DE410;
loc_831DE3B0:
	// bge cr6,0x831de3e4
	if (!cr6.lt) goto loc_831DE3E4;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831de3dc
	if (!cr6.eq) goto loc_831DE3DC;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831de190
	sub_831DE190(ctx, base);
	// stw r3,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r3.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
loc_831DE3DC:
	// lwz r30,4(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// b 0x831de410
	goto loc_831DE410;
loc_831DE3E4:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831de40c
	if (!cr6.eq) goto loc_831DE40C;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831de190
	sub_831DE190(ctx, base);
	// stw r3,8(r30)
	PPC_STORE_U32(r30.u32 + 8, ctx.r3.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
loc_831DE40C:
	// lwz r30,8(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 8);
loc_831DE410:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplw cr6,r26,r27
	cr6.compare<uint32_t>(r26.u32, r27.u32, xer);
	// blt cr6,0x831de35c
	if (cr6.lt) goto loc_831DE35C;
loc_831DE41C:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// bge cr6,0x831de464
	if (!cr6.lt) goto loc_831DE464;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831de190
	sub_831DE190(ctx, base);
	// stw r3,12(r30)
	PPC_STORE_U32(r30.u32 + 12, ctx.r3.u32);
	// addi r11,r28,1
	r11.s64 = r28.s64 + 1;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r10.u32);
	// ble cr6,0x831de45c
	if (!cr6.gt) goto loc_831DE45C;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
loc_831DE45C:
	// lwz r3,12(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// b 0x831de468
	goto loc_831DE468;
loc_831DE464:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831DE468:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_831DE2F8) {
	__imp__sub_831DE2F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DE470) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// addi r26,r10,-18548
	r26.s64 = ctx.r10.s64 + -18548;
	// addi r25,r11,21432
	r25.s64 = r11.s64 + 21432;
	// bne cr6,0x831de4b4
	if (!cr6.eq) goto loc_831DE4B4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// addi r5,r11,21424
	ctx.r5.s64 = r11.s64 + 21424;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// li r7,572
	ctx.r7.s64 = 572;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE4B4:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// li r28,0
	r28.s64 = 0;
	// lwz r31,0(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831de574
	if (cr6.lt) goto loc_831DE574;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r27,r11,21548
	r27.s64 = r11.s64 + 21548;
loc_831DE4D0:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831de4f4
	if (!cr6.eq) goto loc_831DE4F4;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831de4f4
	if (!cr6.eq) goto loc_831DE4F4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831de4fc
	if (cr6.eq) goto loc_831DE4FC;
loc_831DE4F4:
	// mr r31,r11
	r31.u64 = r11.u64;
	// b 0x831de4d0
	goto loc_831DE4D0;
loc_831DE4FC:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,16(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// bl 0x831b49e0
	sub_831B49E0(ctx, base);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,20(r29)
	PPC_STORE_U32(r29.u32 + 20, r11.u32);
	// beq 0x831de570
	if (cr0.eq) goto loc_831DE570;
	// mr r30,r31
	r30.u64 = r31.u64;
	// lwz r31,16(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831de540
	if (!cr6.eq) goto loc_831DE540;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// li r7,616
	ctx.r7.s64 = 616;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE540:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bne cr6,0x831de554
	if (!cr6.eq) goto loc_831DE554;
	// stw r28,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r28.u32);
	// b 0x831de4d0
	goto loc_831DE4D0;
loc_831DE554:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bne cr6,0x831de568
	if (!cr6.eq) goto loc_831DE568;
	// stw r28,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r28.u32);
	// b 0x831de4d0
	goto loc_831DE4D0;
loc_831DE568:
	// stw r28,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r28.u32);
	// b 0x831de4d0
	goto loc_831DE4D0;
loc_831DE570:
	// stw r28,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r28.u32);
loc_831DE574:
	// stw r28,24(r29)
	PPC_STORE_U32(r29.u32 + 24, r28.u32);
	// stw r28,20(r29)
	PPC_STORE_U32(r29.u32 + 20, r28.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831DE470) {
	__imp__sub_831DE470(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DE588) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831de5c4
	if (!cr6.eq) goto loc_831DE5C4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,21432
	ctx.r6.s64 = r11.s64 + 21432;
	// addi r5,r10,21424
	ctx.r5.s64 = ctx.r10.s64 + 21424;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,109
	ctx.r7.s64 = 109;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE5C4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831de470
	sub_831DE470(ctx, base);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x831b4870
	sub_831B4870(ctx, base);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DE588) {
	__imp__sub_831DE588(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DE600) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r31{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// lis r11,-25033
	r11.s64 = -1640562688;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// ori r9,r11,31161
	ctx.r9.u64 = r11.u64 | 31161;
	// mr r7,r4
	ctx.r7.u64 = ctx.r4.u64;
	// cmplwi cr6,r4,3
	cr6.compare<uint32_t>(ctx.r4.u32, 3, xer);
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// blt cr6,0x831de6e0
	if (cr6.lt) goto loc_831DE6E0;
	// li r8,3
	ctx.r8.s64 = 3;
	// divwu r8,r4,r8
	ctx.r8.u32 = ctx.r4.u32 / ctx.r8.u32;
loc_831DE628:
	// lwz r6,8(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// lwz r5,4(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r7,r7,-3
	ctx.r7.s64 = ctx.r7.s64 + -3;
	// add r10,r6,r10
	ctx.r10.u64 = ctx.r6.u64 + ctx.r10.u64;
	// lwz r31,0(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// add r9,r5,r9
	ctx.r9.u64 = ctx.r5.u64 + ctx.r9.u64;
	// subf r6,r10,r31
	ctx.r6.s64 = r31.s64 - ctx.r10.s64;
	// rlwinm r5,r10,19,13,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 19) & 0x7FFFF;
	// subf r6,r9,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r9.s64;
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// add r11,r6,r11
	r11.u64 = ctx.r6.u64 + r11.u64;
	// addi r3,r3,12
	ctx.r3.s64 = ctx.r3.s64 + 12;
	// xor r11,r11,r5
	r11.u64 = r11.u64 ^ ctx.r5.u64;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
	// rlwinm r6,r11,8,0,23
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 8) & 0xFFFFFF00;
	// xor r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r6.u64;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// rlwinm r6,r9,19,13,31
	ctx.r6.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 19) & 0x7FFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// xor r10,r10,r6
	ctx.r10.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// rlwinm r6,r10,20,12,31
	ctx.r6.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xFFFFF;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// xor r11,r11,r6
	r11.u64 = r11.u64 ^ ctx.r6.u64;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
	// rlwinm r6,r11,16,0,15
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF0000;
	// xor r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r6.u64;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// rlwinm r6,r9,27,5,31
	ctx.r6.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x7FFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// xor r10,r10,r6
	ctx.r10.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// rlwinm r6,r10,29,3,31
	ctx.r6.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// xor r11,r11,r6
	r11.u64 = r11.u64 ^ ctx.r6.u64;
	// rlwinm r6,r11,10,0,21
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 10) & 0xFFFFFC00;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
	// xor r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r6.u64;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// rlwinm r6,r9,17,15,31
	ctx.r6.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 17) & 0x1FFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// xor r10,r10,r6
	ctx.r10.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x831de628
	if (!cr0.eq) goto loc_831DE628;
loc_831DE6E0:
	// rlwinm r8,r4,2,0,29
	ctx.r8.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// beq cr6,0x831de700
	if (cr6.eq) goto loc_831DE700;
	// cmplwi cr6,r7,2
	cr6.compare<uint32_t>(ctx.r7.u32, 2, xer);
	// bne cr6,0x831de708
	if (!cr6.eq) goto loc_831DE708;
	// lwz r8,4(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
loc_831DE700:
	// lwz r8,0(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// add r11,r8,r11
	r11.u64 = ctx.r8.u64 + r11.u64;
loc_831DE708:
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// rlwinm r8,r10,19,13,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 19) & 0x7FFFF;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// xor r11,r11,r8
	r11.u64 = r11.u64 ^ ctx.r8.u64;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
	// rlwinm r8,r11,8,0,23
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 8) & 0xFFFFFF00;
	// xor r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// rlwinm r8,r9,19,13,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 19) & 0x7FFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// xor r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// rlwinm r8,r10,20,12,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xFFFFF;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// xor r11,r11,r8
	r11.u64 = r11.u64 ^ ctx.r8.u64;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
	// rlwinm r8,r11,16,0,15
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF0000;
	// xor r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// rlwinm r8,r9,27,5,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x7FFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// xor r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// rlwinm r8,r10,29,3,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// xor r11,r11,r8
	r11.u64 = r11.u64 ^ ctx.r8.u64;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
	// rlwinm r8,r11,10,0,21
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 10) & 0xFFFFFC00;
	// xor r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// rlwinm r9,r9,17,15,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 17) & 0x1FFFF;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// xor r3,r11,r9
	ctx.r3.u64 = r11.u64 ^ ctx.r9.u64;
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DE600) {
	__imp__sub_831DE600(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DE7A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-31951
	ctx.r10.s64 = -2093940736;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r9,r10,496
	ctx.r9.s64 = ctx.r10.s64 + 496;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r28,8(r9)
	r28.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// addi r27,r11,-18548
	r27.s64 = r11.s64 + -18548;
	// addi r26,r10,22656
	r26.s64 = ctx.r10.s64 + 22656;
	// bne cr6,0x831de7f8
	if (!cr6.eq) goto loc_831DE7F8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,8088
	ctx.r5.s64 = r11.s64 + 8088;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,1690
	ctx.r7.s64 = 1690;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE7F8:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831c9040
	sub_831C9040(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831de824
	if (!cr0.eq) goto loc_831DE824;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,22748
	ctx.r5.s64 = r11.s64 + 22748;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,1691
	ctx.r7.s64 = 1691;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE824:
	// rlwinm r11,r31,4,0,27
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// add r31,r11,r28
	r31.u64 = r11.u64 + r28.u64;
	// lwzx r4,r11,r28
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// bl 0x831c9040
	sub_831C9040(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// andc r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ~ctx.r10.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x831c9040
	sub_831C9040(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r10,r29,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (r29.u32 << (ctx.r10.u8 & 0x3F));
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// and r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 & ctx.r9.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831DE7A0) {
	__imp__sub_831DE7A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DE898) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// mr r21,r7
	r21.u64 = ctx.r7.u64;
	// mr r20,r8
	r20.u64 = ctx.r8.u64;
	// bl 0x831fbac8
	sub_831FBAC8(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr. r19,r3
	r19.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r19.s32, 0, xer);
	// addi r24,r11,-18548
	r24.s64 = r11.s64 + -18548;
	// addi r23,r10,22656
	r23.s64 = ctx.r10.s64 + 22656;
	// bne 0x831de8f8
	if (!cr0.eq) goto loc_831DE8F8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// addi r5,r11,22788
	ctx.r5.s64 = r11.s64 + 22788;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1730
	ctx.r7.s64 = 1730;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE8F8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,3084(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x831de938
	if (!cr6.eq) goto loc_831DE938;
	// lfs f13,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x831de938
	if (!cr6.eq) goto loc_831DE938;
	// lfs f13,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x831de938
	if (!cr6.eq) goto loc_831DE938;
	// lfs f13,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x831de938
	if (!cr6.eq) goto loc_831DE938;
	// li r11,0
	r11.s64 = 0;
	// b 0x831dea5c
	goto loc_831DEA5C;
loc_831DE938:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x831fbd28
	sub_831FBD28(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r22,r11,22768
	r22.s64 = r11.s64 + 22768;
	// bgt 0x831de96c
	if (cr0.gt) goto loc_831DE96C;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1750
	ctx.r7.s64 = 1750;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE96C:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// ble cr6,0x831de9a8
	if (!cr6.gt) goto loc_831DE9A8;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// subf r27,r31,r11
	r27.s64 = r11.s64 - r31.s64;
	// subf r26,r31,r10
	r26.s64 = ctx.r10.s64 - r31.s64;
loc_831DE984:
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// lwzx r5,r27,r31
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + r31.u32);
	// li r4,128
	ctx.r4.s64 = 128;
	// lfs f1,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831fc1b0
	sub_831FC1B0(ctx, base);
	// stwx r3,r26,r31
	PPC_STORE_U32(r26.u32 + r31.u32, ctx.r3.u32);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// bne 0x831de984
	if (!cr0.eq) goto loc_831DE984;
loc_831DE9A8:
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x831fc048
	sub_831FC048(ctx, base);
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x831fc010
	sub_831FC010(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bgt 0x831de9ec
	if (cr0.gt) goto loc_831DE9EC;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1763
	ctx.r7.s64 = 1763;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DE9EC:
	// cmplwi cr6,r19,1
	cr6.compare<uint32_t>(r19.u32, 1, xer);
	// beq cr6,0x831dea3c
	if (cr6.eq) goto loc_831DEA3C;
	// cmplwi cr6,r19,2
	cr6.compare<uint32_t>(r19.u32, 2, xer);
	// beq cr6,0x831dea24
	if (cr6.eq) goto loc_831DEA24;
	// cmplwi cr6,r19,4
	cr6.compare<uint32_t>(r19.u32, 4, xer);
	// beq cr6,0x831dea1c
	if (cr6.eq) goto loc_831DEA1C;
	// cmplwi cr6,r19,8
	cr6.compare<uint32_t>(r19.u32, 8, xer);
	// bne cr6,0x831dea6c
	if (!cr6.eq) goto loc_831DEA6C;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// stw r10,12(r28)
	PPC_STORE_U32(r28.u32 + 12, ctx.r10.u32);
	// b 0x831dea68
	goto loc_831DEA68;
loc_831DEA1C:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// b 0x831dea60
	goto loc_831DEA60;
loc_831DEA24:
	// li r11,0
	r11.s64 = 0;
	// sth r11,0(r28)
	PPC_STORE_U16(r28.u32 + 0, r11.u16);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// rlwinm r10,r10,16,0,15
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// b 0x831dea58
	goto loc_831DEA58;
loc_831DEA3C:
	// lbz r11,3(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 3);
	// rotlwi r10,r11,8
	ctx.r10.u64 = rotl32(r11.u32, 8);
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// rlwinm r10,r10,8,0,23
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// rlwinm r10,r10,8,0,23
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
loc_831DEA58:
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
loc_831DEA5C:
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
loc_831DEA60:
	// stw r11,12(r28)
	PPC_STORE_U32(r28.u32 + 12, r11.u32);
	// stw r11,4(r28)
	PPC_STORE_U32(r28.u32 + 4, r11.u32);
loc_831DEA68:
	// stw r11,8(r28)
	PPC_STORE_U32(r28.u32 + 8, r11.u32);
loc_831DEA6C:
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c14
	return;
}

PPC_WEAK_FUNC(sub_831DE898) {
	__imp__sub_831DE898(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DEA78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x831dead4
	if (cr6.eq) goto loc_831DEAD4;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,34
	ctx.r4.s64 = 34;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,35
	ctx.r4.s64 = 35;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,36
	ctx.r4.s64 = 36;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// b 0x831deaf8
	goto loc_831DEAF8;
loc_831DEAD4:
	// li r4,960
	ctx.r4.s64 = 960;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r4,961
	ctx.r4.s64 = 961;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83108de0
	sub_83108DE0(ctx, base);
	// lis r24,770
	r24.s64 = 50462720;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// ori r24,r24,256
	r24.u64 = r24.u64 | 256;
loc_831DEAF8:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// addi r27,r11,-18548
	r27.s64 = r11.s64 + -18548;
	// addi r26,r10,22656
	r26.s64 = ctx.r10.s64 + 22656;
	// beq cr6,0x831deb18
	if (cr6.eq) goto loc_831DEB18;
	// cmplwi cr6,r30,17
	cr6.compare<uint32_t>(r30.u32, 17, xer);
	// blt cr6,0x831deb34
	if (cr6.lt) goto loc_831DEB34;
loc_831DEB18:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,24712
	ctx.r5.s64 = r11.s64 + 24712;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,321
	ctx.r7.s64 = 321;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEB34:
	// clrlwi r29,r28,24
	r29.u64 = r28.u32 & 0xFF;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// cmplwi cr6,r29,64
	cr6.compare<uint32_t>(r29.u32, 64, xer);
	// mulli r30,r30,12
	r30.s64 = r30.s64 * 12;
	// addi r31,r11,21560
	r31.s64 = r11.s64 + 21560;
	// bne cr6,0x831deb90
	if (!cr6.eq) goto loc_831DEB90;
	// addi r11,r31,4
	r11.s64 = r31.s64 + 4;
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// stw r11,4(r25)
	PPC_STORE_U32(r25.u32 + 4, r11.u32);
	// bne cr6,0x831deb7c
	if (!cr6.eq) goto loc_831DEB7C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,24684
	ctx.r5.s64 = r11.s64 + 24684;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,331
	ctx.r7.s64 = 331;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEB7C:
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x831debac
	if (!cr6.eq) goto loc_831DEBAC;
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// b 0x831deba8
	goto loc_831DEBA8;
loc_831DEB90:
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// stw r11,4(r25)
	PPC_STORE_U32(r25.u32 + 4, r11.u32);
	// bne cr6,0x831debac
	if (!cr6.eq) goto loc_831DEBAC;
	// addi r11,r31,4
	r11.s64 = r31.s64 + 4;
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
loc_831DEBA8:
	// stw r11,4(r25)
	PPC_STORE_U32(r25.u32 + 4, r11.u32);
loc_831DEBAC:
	// addi r11,r31,8
	r11.s64 = r31.s64 + 8;
	// lwzx r30,r30,r11
	r30.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi cr6,r30,2
	cr6.compare<uint32_t>(r30.u32, 2, xer);
	// blt cr6,0x831debe4
	if (cr6.lt) goto loc_831DEBE4;
	// rlwinm r11,r28,24,24,31
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 24) & 0xFF;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// beq cr6,0x831debe4
	if (cr6.eq) goto loc_831DEBE4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,24568
	ctx.r5.s64 = r11.s64 + 24568;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,369
	ctx.r7.s64 = 369;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEBE4:
	// cmplwi cr6,r30,3
	cr6.compare<uint32_t>(r30.u32, 3, xer);
	// blt cr6,0x831dec14
	if (cr6.lt) goto loc_831DEC14;
	// rlwinm r11,r28,16,24,31
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 16) & 0xFF;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// beq cr6,0x831dec14
	if (cr6.eq) goto loc_831DEC14;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,24448
	ctx.r5.s64 = r11.s64 + 24448;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,372
	ctx.r7.s64 = 372;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEC14:
	// cmplwi cr6,r30,4
	cr6.compare<uint32_t>(r30.u32, 4, xer);
	// blt cr6,0x831dec44
	if (cr6.lt) goto loc_831DEC44;
	// rlwinm r11,r28,8,24,31
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 8) & 0xFF;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// beq cr6,0x831dec44
	if (cr6.eq) goto loc_831DEC44;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,24328
	ctx.r5.s64 = r11.s64 + 24328;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,375
	ctx.r7.s64 = 375;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEC44:
	// cmplwi cr6,r29,34
	cr6.compare<uint32_t>(r29.u32, 34, xer);
	// bne cr6,0x831dec68
	if (!cr6.eq) goto loc_831DEC68;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,24248
	ctx.r5.s64 = r11.s64 + 24248;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,383
	ctx.r7.s64 = 383;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEC68:
	// cmplwi cr6,r29,35
	cr6.compare<uint32_t>(r29.u32, 35, xer);
	// bne cr6,0x831dec8c
	if (!cr6.eq) goto loc_831DEC8C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,24168
	ctx.r5.s64 = r11.s64 + 24168;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,385
	ctx.r7.s64 = 385;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEC8C:
	// cmplwi cr6,r29,17
	cr6.compare<uint32_t>(r29.u32, 17, xer);
	// bne cr6,0x831decb0
	if (!cr6.eq) goto loc_831DECB0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,24088
	ctx.r5.s64 = r11.s64 + 24088;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,387
	ctx.r7.s64 = 387;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DECB0:
	// cmplwi cr6,r29,2
	cr6.compare<uint32_t>(r29.u32, 2, xer);
	// bne cr6,0x831decd4
	if (!cr6.eq) goto loc_831DECD4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,24000
	ctx.r5.s64 = r11.s64 + 24000;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,389
	ctx.r7.s64 = 389;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DECD4:
	// cmplwi cr6,r29,18
	cr6.compare<uint32_t>(r29.u32, 18, xer);
	// bne cr6,0x831decf8
	if (!cr6.eq) goto loc_831DECF8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,23912
	ctx.r5.s64 = r11.s64 + 23912;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,391
	ctx.r7.s64 = 391;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DECF8:
	// li r31,1
	r31.s64 = 1;
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// blt cr6,0x831ded50
	if (cr6.lt) goto loc_831DED50;
	// beq cr6,0x831ded48
	if (cr6.eq) goto loc_831DED48;
	// cmplwi cr6,r29,3
	cr6.compare<uint32_t>(r29.u32, 3, xer);
	// beq cr6,0x831ded40
	if (cr6.eq) goto loc_831DED40;
	// cmplwi cr6,r29,32
	cr6.compare<uint32_t>(r29.u32, 32, xer);
	// beq cr6,0x831ded38
	if (cr6.eq) goto loc_831DED38;
	// cmplwi cr6,r29,33
	cr6.compare<uint32_t>(r29.u32, 33, xer);
	// beq cr6,0x831ded30
	if (cr6.eq) goto loc_831DED30;
	// cmplwi cr6,r29,64
	cr6.compare<uint32_t>(r29.u32, 64, xer);
	// bne cr6,0x831ded50
	if (!cr6.eq) goto loc_831DED50;
	// li r11,7
	r11.s64 = 7;
	// b 0x831ded54
	goto loc_831DED54;
loc_831DED30:
	// li r11,3
	r11.s64 = 3;
	// b 0x831ded54
	goto loc_831DED54;
loc_831DED38:
	// li r11,2
	r11.s64 = 2;
	// b 0x831ded54
	goto loc_831DED54;
loc_831DED40:
	// li r11,4
	r11.s64 = 4;
	// b 0x831ded54
	goto loc_831DED54;
loc_831DED48:
	// stw r31,8(r25)
	PPC_STORE_U32(r25.u32 + 8, r31.u32);
	// b 0x831ded58
	goto loc_831DED58;
loc_831DED50:
	// li r11,0
	r11.s64 = 0;
loc_831DED54:
	// stw r11,8(r25)
	PPC_STORE_U32(r25.u32 + 8, r11.u32);
loc_831DED58:
	// clrlwi. r11,r24,24
	r11.u64 = r24.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831dee0c
	if (!cr0.eq) goto loc_831DEE0C;
	// cmplwi cr6,r30,2
	cr6.compare<uint32_t>(r30.u32, 2, xer);
	// blt cr6,0x831deda0
	if (cr6.lt) goto loc_831DEDA0;
	// rlwinm r11,r24,24,24,31
	r11.u64 = rotl64(r24.u32 | (r24.u64 << 32), 24) & 0xFF;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x831deda0
	if (cr6.eq) goto loc_831DEDA0;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x831deda0
	if (cr6.eq) goto loc_831DEDA0;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// beq cr6,0x831deda0
	if (cr6.eq) goto loc_831DEDA0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,23656
	ctx.r5.s64 = r11.s64 + 23656;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,450
	ctx.r7.s64 = 450;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEDA0:
	// cmplwi cr6,r30,3
	cr6.compare<uint32_t>(r30.u32, 3, xer);
	// blt cr6,0x831dede0
	if (cr6.lt) goto loc_831DEDE0;
	// rlwinm r11,r24,16,24,31
	r11.u64 = rotl64(r24.u32 | (r24.u64 << 32), 16) & 0xFF;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x831dede0
	if (cr6.eq) goto loc_831DEDE0;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x831dede0
	if (cr6.eq) goto loc_831DEDE0;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// beq cr6,0x831dede0
	if (cr6.eq) goto loc_831DEDE0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,23400
	ctx.r5.s64 = r11.s64 + 23400;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,454
	ctx.r7.s64 = 454;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEDE0:
	// cmplwi cr6,r30,4
	cr6.compare<uint32_t>(r30.u32, 4, xer);
	// blt cr6,0x831deeec
	if (cr6.lt) goto loc_831DEEEC;
	// rlwinm r11,r24,8,24,31
	r11.u64 = rotl64(r24.u32 | (r24.u64 << 32), 8) & 0xFF;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x831deeec
	if (cr6.eq) goto loc_831DEEEC;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x831deeec
	if (cr6.eq) goto loc_831DEEEC;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// beq cr6,0x831deeec
	if (cr6.eq) goto loc_831DEEEC;
	// li r7,458
	ctx.r7.s64 = 458;
	// b 0x831deed4
	goto loc_831DEED4;
loc_831DEE0C:
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x831dee30
	if (cr6.eq) goto loc_831DEE30;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,23320
	ctx.r5.s64 = r11.s64 + 23320;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,466
	ctx.r7.s64 = 466;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEE30:
	// cmplwi cr6,r30,2
	cr6.compare<uint32_t>(r30.u32, 2, xer);
	// blt cr6,0x831dee70
	if (cr6.lt) goto loc_831DEE70;
	// rlwinm r11,r24,24,24,31
	r11.u64 = rotl64(r24.u32 | (r24.u64 << 32), 24) & 0xFF;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x831dee70
	if (cr6.eq) goto loc_831DEE70;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x831dee70
	if (cr6.eq) goto loc_831DEE70;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// beq cr6,0x831dee70
	if (cr6.eq) goto loc_831DEE70;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,23656
	ctx.r5.s64 = r11.s64 + 23656;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,472
	ctx.r7.s64 = 472;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEE70:
	// cmplwi cr6,r30,3
	cr6.compare<uint32_t>(r30.u32, 3, xer);
	// blt cr6,0x831deeac
	if (cr6.lt) goto loc_831DEEAC;
	// rlwinm. r11,r24,16,24,31
	r11.u64 = rotl64(r24.u32 | (r24.u64 << 32), 16) & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831deeac
	if (cr0.eq) goto loc_831DEEAC;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x831deeac
	if (cr6.eq) goto loc_831DEEAC;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// beq cr6,0x831deeac
	if (cr6.eq) goto loc_831DEEAC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,23064
	ctx.r5.s64 = r11.s64 + 23064;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r7,476
	ctx.r7.s64 = 476;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEEAC:
	// cmplwi cr6,r30,4
	cr6.compare<uint32_t>(r30.u32, 4, xer);
	// blt cr6,0x831deeec
	if (cr6.lt) goto loc_831DEEEC;
	// rlwinm r11,r24,8,24,31
	r11.u64 = rotl64(r24.u32 | (r24.u64 << 32), 8) & 0xFF;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x831deeec
	if (cr6.eq) goto loc_831DEEEC;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x831deeec
	if (cr6.eq) goto loc_831DEEEC;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// beq cr6,0x831deeec
	if (cr6.eq) goto loc_831DEEEC;
	// li r7,480
	ctx.r7.s64 = 480;
loc_831DEED4:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r11,22808
	ctx.r5.s64 = r11.s64 + 22808;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEEEC:
	// stw r31,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r31.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_831DEA78) {
	__imp__sub_831DEA78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DEEF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,34
	ctx.r4.s64 = 34;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// li r4,35
	ctx.r4.s64 = 35;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,36
	ctx.r4.s64 = 36;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831090e8
	sub_831090E8(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// addi r28,r11,-18548
	r28.s64 = r11.s64 + -18548;
	// addi r27,r10,22656
	r27.s64 = ctx.r10.s64 + 22656;
	// beq cr6,0x831def64
	if (cr6.eq) goto loc_831DEF64;
	// cmplwi cr6,r31,17
	cr6.compare<uint32_t>(r31.u32, 17, xer);
	// blt cr6,0x831def80
	if (cr6.lt) goto loc_831DEF80;
loc_831DEF64:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r11,24772
	ctx.r5.s64 = r11.s64 + 24772;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,553
	ctx.r7.s64 = 553;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DEF80:
	// clrlwi r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	// rlwinm r10,r31,4,0,27
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 4) & 0xFFFFFFF0;
	// cmplwi cr6,r11,64
	cr6.compare<uint32_t>(r11.u32, 64, xer);
	// bne cr6,0x831defbc
	if (!cr6.eq) goto loc_831DEFBC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,21768
	r11.s64 = r11.s64 + 21768;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bne cr6,0x831df024
	if (!cr6.eq) goto loc_831DF024;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r7,564
	ctx.r7.s64 = 564;
	// addi r5,r11,24756
	ctx.r5.s64 = r11.s64 + 24756;
	// b 0x831df014
	goto loc_831DF014;
loc_831DEFBC:
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,21768
	r11.s64 = r11.s64 + 21768;
	// bne cr6,0x831deff0
	if (!cr6.eq) goto loc_831DEFF0;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bne cr6,0x831df024
	if (!cr6.eq) goto loc_831DF024;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r7,572
	ctx.r7.s64 = 572;
	// addi r5,r11,24756
	ctx.r5.s64 = r11.s64 + 24756;
	// b 0x831df014
	goto loc_831DF014;
loc_831DEFF0:
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bne cr6,0x831df024
	if (!cr6.eq) goto loc_831DF024;
	// cmplwi cr6,r31,1
	cr6.compare<uint32_t>(r31.u32, 1, xer);
	// beq cr6,0x831df024
	if (cr6.eq) goto loc_831DF024;
	// lis r11,-32245
	r11.s64 = -2113208320;
	// li r7,585
	ctx.r7.s64 = 585;
	// addi r5,r11,-10856
	ctx.r5.s64 = r11.s64 + -10856;
loc_831DF014:
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DF024:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DEEF8) {
	__imp__sub_831DEEF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF030) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831df078
	if (!cr6.eq) goto loc_831DF078;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,24860
	ctx.r5.s64 = ctx.r10.s64 + 24860;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,244
	ctx.r7.s64 = 244;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DF078:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fc6f8
	sub_831FC6F8(ctx, base);
	// stw r29,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r29.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831DF030) {
	__imp__sub_831DF030(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF090) {
	PPC_FUNC_PROLOGUE();
	// lbz r3,2144(r3)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + 2144);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF090) {
	__imp__sub_831DF090(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF098) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831eea08
	sub_831EEA08(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r11,1
	r11.s64 = 1;
	// stb r11,1394(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1394, r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF098) {
	__imp__sub_831DF098(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF0D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,2
	ctx.r9.s64 = 2;
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r3.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF0D8) {
	__imp__sub_831DF0D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF130) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r31,r3,184
	r31.s64 = ctx.r3.s64 + 184;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831fad00
	sub_831FAD00(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831fad80
	sub_831FAD80(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF130) {
	__imp__sub_831DF130(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF178) {
	PPC_FUNC_PROLOGUE();
	// lbz r3,2072(r3)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + 2072);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF178) {
	__imp__sub_831DF178(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF180) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,2076(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2076);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF180) {
	__imp__sub_831DF180(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF188) {
	PPC_FUNC_PROLOGUE();
	// lbz r3,2073(r3)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + 2073);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF188) {
	__imp__sub_831DF188(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF190) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// rlwinm. r11,r11,23,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 23) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831df1d4
	if (!cr0.eq) goto loc_831DF1D4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,25064
	ctx.r6.s64 = r11.s64 + 25064;
	// addi r5,r10,25036
	ctx.r5.s64 = ctx.r10.s64 + 25036;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1902
	ctx.r7.s64 = 1902;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DF1D4:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,58
	r11.s64 = r11.s64 + 58;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r31
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF190) {
	__imp__sub_831DF190(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF1F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// rlwinm. r11,r11,23,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 23) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831df23c
	if (!cr0.eq) goto loc_831DF23C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,25064
	ctx.r6.s64 = r11.s64 + 25064;
	// addi r5,r10,25036
	ctx.r5.s64 = ctx.r10.s64 + 25036;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1909
	ctx.r7.s64 = 1909;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DF23C:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,58
	r11.s64 = r11.s64 + 58;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r10,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r10.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,228(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// rlwinm r10,r10,0,23,21
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFDFF;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r10,228(r31)
	PPC_STORE_U32(r31.u32 + 228, ctx.r10.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF1F8) {
	__imp__sub_831DF1F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF280) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831df2c8
	if (!cr6.eq) goto loc_831DF2C8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,25064
	ctx.r6.s64 = r11.s64 + 25064;
	// addi r5,r10,25144
	ctx.r5.s64 = ctx.r10.s64 + 25144;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1919
	ctx.r7.s64 = 1919;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DF2C8:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,228(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm. r10,r10,23,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// beq 0x831df304
	if (cr0.eq) goto loc_831DF304;
	// addi r10,r11,57
	ctx.r10.s64 = r11.s64 + 57;
	// addi r11,r11,58
	r11.s64 = r11.s64 + 58;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r31.u32);
	// stwx r10,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r10.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,57
	r11.s64 = r11.s64 + 57;
	// b 0x831df308
	goto loc_831DF308;
loc_831DF304:
	// addi r11,r11,58
	r11.s64 = r11.s64 + 58;
loc_831DF308:
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r30,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF280) {
	__imp__sub_831DF280(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF328) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r29,r11,-18548
	r29.s64 = r11.s64 + -18548;
	// addi r28,r10,25064
	r28.s64 = ctx.r10.s64 + 25064;
	// cmpw cr6,r30,r9
	cr6.compare<int32_t>(r30.s32, ctx.r9.s32, xer);
	// ble cr6,0x831df378
	if (!cr6.gt) goto loc_831DF378;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,25232
	ctx.r5.s64 = r11.s64 + 25232;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,1945
	ctx.r7.s64 = 1945;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DF378:
	// lwz r11,952(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 952);
	// lbz r11,1393(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 1393);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831df3bc
	if (cr0.eq) goto loc_831DF3BC;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// bne cr6,0x831df3bc
	if (!cr6.eq) goto loc_831DF3BC;
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// rlwinm. r11,r11,23,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 23) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831df3bc
	if (cr0.eq) goto loc_831DF3BC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,25160
	ctx.r5.s64 = r11.s64 + 25160;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,1948
	ctx.r7.s64 = 1948;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DF3BC:
	// addi r11,r30,58
	r11.s64 = r30.s64 + 58;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r27,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, r27.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DF328) {
	__imp__sub_831DF328(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF3D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,2068(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2068);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lwz r4,4(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF3D0) {
	__imp__sub_831DF3D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF408) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// li r31,0
	r31.s64 = 0;
	// lwz r3,2068(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 2068);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x831df484
	if (!cr6.gt) goto loc_831DF484;
	// li r30,0
	r30.s64 = 0;
loc_831DF434:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bge cr6,0x831df44c
	if (!cr6.lt) goto loc_831DF44C;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// add r3,r11,r30
	ctx.r3.u64 = r11.u64 + r30.u64;
	// b 0x831df454
	goto loc_831DF454;
loc_831DF44C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
loc_831DF454:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x831df46c
	if (!cr6.eq) goto loc_831DF46C;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,2068(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 2068);
	// bl 0x831fc910
	sub_831FC910(ctx, base);
loc_831DF46C:
	// lwz r3,2068(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 2068);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x831df434
	if (cr6.lt) goto loc_831DF434;
loc_831DF484:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DF408) {
	__imp__sub_831DF408(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF490) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// lwz r24,136(r25)
	r24.u64 = PPC_LOAD_U32(r25.u32 + 136);
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831df630
	if (cr6.eq) goto loc_831DF630;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r28,r10,-18548
	r28.s64 = ctx.r10.s64 + -18548;
	// addi r27,r9,25252
	r27.s64 = ctx.r9.s64 + 25252;
	// addi r26,r11,24888
	r26.s64 = r11.s64 + 24888;
loc_831DF4C8:
	// lwz r31,28(r24)
	r31.u64 = PPC_LOAD_U32(r24.u32 + 28);
	// b 0x831df614
	goto loc_831DF614;
loc_831DF4D0:
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831df610
	if (cr0.eq) goto loc_831DF610;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r29,1
	r29.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// blt cr6,0x831df588
	if (cr6.lt) goto loc_831DF588;
	// addi r30,r31,84
	r30.s64 = r31.s64 + 84;
loc_831DF500:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,35
	cr6.compare<int32_t>(r11.s32, 35, xer);
	// beq cr6,0x831df54c
	if (cr6.eq) goto loc_831DF54C;
	// cmpwi cr6,r11,36
	cr6.compare<int32_t>(r11.s32, 36, xer);
	// beq cr6,0x831df54c
	if (cr6.eq) goto loc_831DF54C;
	// cmpwi cr6,r11,37
	cr6.compare<int32_t>(r11.s32, 37, xer);
	// beq cr6,0x831df54c
	if (cr6.eq) goto loc_831DF54C;
	// cmpwi cr6,r11,38
	cr6.compare<int32_t>(r11.s32, 38, xer);
	// beq cr6,0x831df54c
	if (cr6.eq) goto loc_831DF54C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpw cr6,r29,r3
	cr6.compare<int32_t>(r29.s32, ctx.r3.s32, xer);
	// ble cr6,0x831df500
	if (!cr6.gt) goto loc_831DF500;
	// b 0x831df588
	goto loc_831DF588;
loc_831DF54C:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,172(r25)
	ctx.r3.u64 = PPC_LOAD_U32(r25.u32 + 172);
	// li r4,31
	ctx.r4.s64 = 31;
	// bl 0x831ee258
	sub_831EE258(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x831df57c
	if (!cr0.eq) goto loc_831DF57C;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,306
	ctx.r7.s64 = 306;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DF57C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ffdc0
	sub_831FFDC0(ctx, base);
loc_831DF588:
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// rlwinm. r11,r11,31,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831df5c8
	if (cr0.eq) goto loc_831DF5C8;
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// lwz r4,12(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// bl 0x831ff888
	sub_831FF888(ctx, base);
	// cmpwi cr6,r3,8
	cr6.compare<int32_t>(ctx.r3.s32, 8, xer);
	// bne cr6,0x831df5c8
	if (!cr6.eq) goto loc_831DF5C8;
	// li r5,2
	ctx.r5.s64 = 2;
	// lwz r3,172(r25)
	ctx.r3.u64 = PPC_LOAD_U32(r25.u32 + 172);
	// li r4,31
	ctx.r4.s64 = 31;
	// bl 0x831ee258
	sub_831EE258(ctx, base);
	// mr. r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x831df5c8
	if (cr0.eq) goto loc_831DF5C8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ffdc0
	sub_831FFDC0(ctx, base);
loc_831DF5C8:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831df610
	if (cr6.eq) goto loc_831DF610;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831feda8
	sub_831FEDA8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831df610
	if (cr0.eq) goto loc_831DF610;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,42
	cr6.compare<int32_t>(r11.s32, 42, xer);
	// beq cr6,0x831df610
	if (cr6.eq) goto loc_831DF610;
	// lwz r30,28(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831ffdc0
	sub_831FFDC0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// bl 0x831fd370
	sub_831FD370(ctx, base);
loc_831DF610:
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
loc_831DF614:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831df4d0
	if (!cr6.eq) goto loc_831DF4D0;
	// lwz r24,8(r24)
	r24.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831df4c8
	if (!cr6.eq) goto loc_831DF4C8;
loc_831DF630:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_831DF490) {
	__imp__sub_831DF490(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF638) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r4,152(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 152);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831df668
	if (cr6.eq) goto loc_831DF668;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1452(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// bl 0x831c59e0
	sub_831C59E0(ctx, base);
loc_831DF668:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r10,r30,1
	ctx.r10.s64 = r30.s64 + 1;
	// rlwinm r4,r10,2,0,29
	ctx.r4.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,1452(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// stw r3,152(r31)
	PPC_STORE_U32(r31.u32 + 152, ctx.r3.u32);
	// li r11,0
	r11.s64 = 0;
	// addi r10,r30,1
	ctx.r10.s64 = r30.s64 + 1;
loc_831DF688:
	// lwzx r9,r11,r29
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r8,152(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 152);
	// stwx r9,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x831df688
	if (!cr0.eq) goto loc_831DF688;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831DF638) {
	__imp__sub_831DF638(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF6A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r29,0
	r29.s64 = 0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,1360(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1360);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x831df72c
	if (cr6.lt) goto loc_831DF72C;
	// addi r28,r1,80
	r28.s64 = ctx.r1.s64 + 80;
loc_831DF6D4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,20
	ctx.r4.s64 = 20;
	// lwz r27,1456(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// addic. r30,r3,4
	xer.ca = ctx.r3.u32 > 4294967291;
	r30.s64 = ctx.r3.s64 + 4;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// stw r27,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r27.u32);
	// beq 0x831df708
	if (cr0.eq) goto loc_831DF708;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,1456(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// bl 0x831df0d8
	sub_831DF0D8(ctx, base);
	// b 0x831df70c
	goto loc_831DF70C;
loc_831DF708:
	// li r30,0
	r30.s64 = 0;
loc_831DF70C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// stw r30,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r30.u32);
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// lwz r11,1360(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1360);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpw cr6,r29,r11
	cr6.compare<int32_t>(r29.s32, r11.s32, xer);
	// ble cr6,0x831df6d4
	if (!cr6.gt) goto loc_831DF6D4;
loc_831DF72C:
	// lwz r30,136(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// b 0x831df754
	goto loc_831DF754;
loc_831DF734:
	// lwz r11,52(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 52);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r4,4(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
	// lwz r30,8(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 8);
loc_831DF754:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831df734
	if (!cr6.eq) goto loc_831DF734;
	// addi r3,r31,128
	ctx.r3.s64 = r31.s64 + 128;
	// bl 0x831fc770
	sub_831FC770(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r10,r30,1
	ctx.r10.s64 = r30.s64 + 1;
	// rlwinm r4,r10,2,0,29
	ctx.r4.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,1452(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r30,-1
	r29.s64 = r30.s64 + -1;
	// stw r3,160(r31)
	PPC_STORE_U32(r31.u32 + 160, ctx.r3.u32);
	// li r25,0
	r25.s64 = 0;
	// lwz r11,1360(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1360);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x831df7fc
	if (cr6.lt) goto loc_831DF7FC;
	// addi r27,r1,80
	r27.s64 = ctx.r1.s64 + 80;
loc_831DF7A4:
	// lwz r26,0(r27)
	r26.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831df7e0
	if (cr6.eq) goto loc_831DF7E0;
	// rotlwi r28,r26,0
	r28.u64 = rotl32(r26.u32, 0);
	// rlwinm r30,r29,2,0,29
	r30.u64 = rotl64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
loc_831DF7BC:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x832027e0
	sub_832027E0(ctx, base);
	// lwz r11,160(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 160);
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// stwx r3,r30,r11
	PPC_STORE_U32(r30.u32 + r11.u32, ctx.r3.u32);
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831df7bc
	if (!cr6.eq) goto loc_831DF7BC;
loc_831DF7E0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// lwz r11,1360(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1360);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpw cr6,r25,r11
	cr6.compare<int32_t>(r25.s32, r11.s32, xer);
	// ble cr6,0x831df7a4
	if (!cr6.gt) goto loc_831DF7A4;
loc_831DF7FC:
	// lwz r3,160(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 160);
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831DF6A8) {
	__imp__sub_831DF6A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF808) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,18
	ctx.r4.s64 = 18;
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stb r11,2072(r31)
	PPC_STORE_U8(r31.u32 + 2072, r11.u8);
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// stw r11,2076(r31)
	PPC_STORE_U32(r31.u32 + 2076, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831DF808) {
	__imp__sub_831DF808(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF850) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831df808
	sub_831DF808(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// lwz r10,172(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 172);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// stb r11,2073(r30)
	PPC_STORE_U8(r30.u32 + 2073, r11.u8);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,4(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// bl 0x831fcfb8
	sub_831FCFB8(ctx, base);
	// b 0x831df960
	goto loc_831DF960;
loc_831DF884:
	// li r26,0
	r26.s64 = 0;
	// addi r25,r11,32
	r25.s64 = r11.s64 + 32;
loc_831DF88C:
	// cntlzw r11,r26
	r11.u64 = r26.u32 == 0 ? 32 : __builtin_clz(r26.u32);
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// addi r27,r11,21
	r27.s64 = r11.s64 + 21;
	// cmpw cr6,r10,r27
	cr6.compare<int32_t>(ctx.r10.s32, r27.s32, xer);
	// bne cr6,0x831df94c
	if (!cr6.eq) goto loc_831DF94C;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831df94c
	if (!cr6.eq) goto loc_831DF94C;
	// li r3,38
	ctx.r3.s64 = 38;
	// lwz r4,12(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r29,0
	r29.s64 = 0;
loc_831DF8E4:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// blt cr6,0x831df8e4
	if (cr6.lt) goto loc_831DF8E4;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r3,172(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,164(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 164);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
loc_831DF94C:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmpwi cr6,r26,2
	cr6.compare<int32_t>(r26.s32, 2, xer);
	// blt cr6,0x831df88c
	if (cr6.lt) goto loc_831DF88C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x831fcef0
	sub_831FCEF0(ctx, base);
loc_831DF960:
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r28,r11
	r28.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// bne cr6,0x831df884
	if (!cr6.eq) goto loc_831DF884;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_831DF850) {
	__imp__sub_831DF850(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DF980) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r23,r11,-18548
	r23.s64 = r11.s64 + -18548;
	// lwz r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// addi r22,r10,24888
	r22.s64 = ctx.r10.s64 + 24888;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x831dfa4c
	if (cr6.eq) goto loc_831DFA4C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831ee220
	sub_831EE220(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831df9f4
	if (!cr0.eq) goto loc_831DF9F4;
	// lwz r5,56(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 56);
	// lwz r4,80(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 80);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831ee278
	sub_831EE278(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,128(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 128);
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x831dfa0c
	goto loc_831DFA0C;
loc_831DF9F4:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,128(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 128);
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DFA0C:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831dfa30
	if (!cr6.eq) goto loc_831DFA30;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25280
	ctx.r5.s64 = r11.s64 + 25280;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,649
	ctx.r7.s64 = 649;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DFA30:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fd320
	sub_831FD320(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
loc_831DFA4C:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// li r26,1
	r26.s64 = 1;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// blt cr6,0x831dfd04
	if (cr6.lt) goto loc_831DFD04;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-31951
	ctx.r10.s64 = -2093940736;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r28,r29,84
	r28.s64 = r29.s64 + 84;
	// addi r27,r11,24848
	r27.s64 = r11.s64 + 24848;
	// addi r24,r10,10000
	r24.s64 = ctx.r10.s64 + 10000;
	// addi r25,r9,25264
	r25.s64 = ctx.r9.s64 + 25264;
loc_831DFA78:
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmpwi cr6,r10,26
	cr6.compare<int32_t>(ctx.r10.s32, 26, xer);
	// beq cr6,0x831dfa8c
	if (cr6.eq) goto loc_831DFA8C;
	// cmpwi cr6,r10,27
	cr6.compare<int32_t>(ctx.r10.s32, 27, xer);
	// bne cr6,0x831dfaa4
	if (!cr6.eq) goto loc_831DFAA4;
loc_831DFA8C:
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,1508(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1508);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,1508(r9)
	PPC_STORE_U32(ctx.r9.u32 + 1508, r11.u32);
	// stw r11,-24(r28)
	PPC_STORE_U32(r28.u32 + -24, r11.u32);
	// stw r10,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r10.u32);
loc_831DFAA4:
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x831ee220
	sub_831EE220(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831dfaec
	if (!cr0.eq) goto loc_831DFAEC;
	// lwz r5,-24(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + -24);
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831ee278
	sub_831EE278(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,-16(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + -16);
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x831dfb04
	goto loc_831DFB04;
loc_831DFAEC:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,-16(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + -16);
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_831DFB04:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831fd370
	sub_831FD370(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmpwi cr6,r11,26
	cr6.compare<int32_t>(r11.s32, 26, xer);
	// bne cr6,0x831dfba8
	if (!cr6.eq) goto loc_831DFBA8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df808
	sub_831DF808(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// li r3,62
	ctx.r3.s64 = 62;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// stb r11,2073(r31)
	PPC_STORE_U8(r31.u32 + 2073, r11.u8);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,132(r20)
	PPC_STORE_U32(r20.u32 + 132, r11.u32);
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// lwz r3,164(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 164);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831dfc68
	if (!cr0.eq) goto loc_831DFC68;
	// li r7,704
	ctx.r7.s64 = 704;
	// b 0x831dfc54
	goto loc_831DFC54;
loc_831DFBA8:
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// bne cr6,0x831dfc68
	if (!cr6.eq) goto loc_831DFC68;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df808
	sub_831DF808(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// li r6,3
	ctx.r6.s64 = 3;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// lwz r3,164(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 164);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831dfc68
	if (!cr0.eq) goto loc_831DFC68;
	// li r7,718
	ctx.r7.s64 = 718;
loc_831DFC54:
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DFC68:
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// mulli r11,r11,52
	r11.s64 = r11.s64 * 52;
	// lwzx r11,r11,r24
	r11.u64 = PPC_LOAD_U32(r11.u32 + r24.u32);
	// rlwinm. r10,r11,26,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831dfcf0
	if (!cr0.eq) goto loc_831DFCF0;
	// rlwinm. r11,r11,31,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831dfcf0
	if (cr0.eq) goto loc_831DFCF0;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// beq cr6,0x831dfcf0
	if (cr6.eq) goto loc_831DFCF0;
	// lbz r11,128(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 128);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// li r11,0
	r11.s64 = 0;
	// beq cr6,0x831dfca4
	if (cr6.eq) goto loc_831DFCA4;
	// lbz r11,48(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 48);
loc_831DFCA4:
	// stb r11,48(r28)
	PPC_STORE_U8(r28.u32 + 48, r11.u8);
	// lbz r11,129(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 129);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// li r11,1
	r11.s64 = 1;
	// beq cr6,0x831dfcbc
	if (cr6.eq) goto loc_831DFCBC;
	// lbz r11,49(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 49);
loc_831DFCBC:
	// stb r11,49(r28)
	PPC_STORE_U8(r28.u32 + 49, r11.u8);
	// lbz r11,130(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 130);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// li r11,2
	r11.s64 = 2;
	// beq cr6,0x831dfcd4
	if (cr6.eq) goto loc_831DFCD4;
	// lbz r11,50(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 50);
loc_831DFCD4:
	// stb r11,50(r28)
	PPC_STORE_U8(r28.u32 + 50, r11.u8);
	// lbz r11,131(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 131);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// li r11,3
	r11.s64 = 3;
	// beq cr6,0x831dfcec
	if (cr6.eq) goto loc_831DFCEC;
	// lbz r11,51(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 51);
loc_831DFCEC:
	// stb r11,51(r28)
	PPC_STORE_U8(r28.u32 + 51, r11.u8);
loc_831DFCF0:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmpw cr6,r26,r11
	cr6.compare<int32_t>(r26.s32, r11.s32, xer);
	// ble cr6,0x831dfa78
	if (!cr6.gt) goto loc_831DFA78;
loc_831DFD04:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	return;
}

PPC_WEAK_FUNC(sub_831DF980) {
	__imp__sub_831DF980(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DFD10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,136(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// b 0x831dfd3c
	goto loc_831DFD3C;
loc_831DFD28:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83201fd8
	sub_83201FD8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831dfd60
	if (cr0.eq) goto loc_831DFD60;
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
loc_831DFD3C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831dfd28
	if (!cr6.eq) goto loc_831DFD28;
	// li r3,1
	ctx.r3.s64 = 1;
loc_831DFD4C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_831DFD60:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831dfd4c
	goto loc_831DFD4C;
}

PPC_WEAK_FUNC(sub_831DFD10) {
	__imp__sub_831DFD10(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DFD68) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r11,r30,31
	r11.s64 = r30.s64 + 31;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// rlwinm r31,r11,27,5,31
	r31.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r11,r31,3
	r11.s64 = r31.s64 + 3;
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// stw r29,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r29.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r30.u32);
	// addi r11,r3,4
	r11.s64 = ctx.r3.s64 + 4;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r31.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831dfdd0
	if (cr6.eq) goto loc_831DFDD0;
	// addi r9,r11,8
	ctx.r9.s64 = r11.s64 + 8;
loc_831DFDB4:
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// blt cr6,0x831dfdb4
	if (cr6.lt) goto loc_831DFDB4;
loc_831DFDD0:
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831DFD68) {
	__imp__sub_831DFD68(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DFDE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,23
	ctx.r4.s64 = 23;
	// lwz r3,172(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r10,108(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// li r4,964
	ctx.r4.s64 = 964;
	// lwz r31,1452(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// lwz r27,28(r10)
	r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r28,32(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// beq 0x831dfe44
	if (cr0.eq) goto loc_831DFE44;
	// lwz r4,12(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// bl 0x832007a8
	sub_832007A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x831dfe48
	goto loc_831DFE48;
loc_831DFE44:
	// li r31,0
	r31.s64 = 0;
loc_831DFE48:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r29,0
	r29.s64 = 0;
loc_831DFE7C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// blt cr6,0x831dfe7c
	if (cr6.lt) goto loc_831DFE7C;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,108(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831fd6c8
	sub_831FD6C8(ctx, base);
	// lwz r3,108(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// bl 0x831ff7a0
	sub_831FF7A0(ctx, base);
	// lwz r3,108(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,96(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,168(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 168);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831dff14
	if (!cr0.eq) goto loc_831DFF14;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,25288
	ctx.r5.s64 = ctx.r10.s64 + 25288;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1198
	ctx.r7.s64 = 1198;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831DFF14:
	// stw r31,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r31.u32);
	// lwz r3,96(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 96);
	// lwz r4,4(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831DFDE0) {
	__imp__sub_831DFDE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831DFF30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x831dc7b8
	sub_831DC7B8(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc858
	sub_831DC858(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc8f8
	sub_831DC8F8(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc998
	sub_831DC998(ctx, base);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r3,18
	ctx.r3.s64 = 18;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r29,32(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bl 0x83200d28
	sub_83200D28(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// lfs f4,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lfs f3,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// li r11,1
	r11.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// stb r11,154(r30)
	PPC_STORE_U8(r30.u32 + 154, r11.u8);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r3,948(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 948);
	// bl 0x83201f30
	sub_83201F30(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// li r4,23
	ctx.r4.s64 = 23;
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r3,20
	ctx.r3.s64 = 20;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83200d98
	sub_83200D98(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r28,0
	r28.s64 = 0;
loc_831E0084:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmpwi cr6,r28,4
	cr6.compare<int32_t>(r28.s32, 4, xer);
	// blt cr6,0x831e0084
	if (cr6.lt) goto loc_831E0084;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r5,3
	ctx.r5.s64 = 3;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lfs f4,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lfs f3,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r3,948(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 948);
	// bl 0x83201f30
	sub_83201F30(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831DFF30) {
	__imp__sub_831DFF30(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E0120) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9b70
	sub_831D9B70(ctx, base);
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9c88
	sub_831D9C88(ctx, base);
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9d98
	sub_831D9D98(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// bl 0x832023c8
	sub_832023C8(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// addi r23,r11,-18548
	r23.s64 = r11.s64 + -18548;
	// addi r22,r10,24888
	r22.s64 = ctx.r10.s64 + 24888;
	// beq cr6,0x831e0240
	if (cr6.eq) goto loc_831E0240;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25356
	ctx.r5.s64 = r11.s64 + 25356;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,1338
	ctx.r7.s64 = 1338;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E0240:
	// lwz r9,168(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// li r26,0
	r26.s64 = 0;
	// lwz r29,84(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// mr r11,r26
	r11.u64 = r26.u64;
	// lwz r9,60(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// lwz r6,4(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
loc_831E0260:
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// ble cr6,0x831e0270
	if (!cr6.gt) goto loc_831E0270;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// b 0x831e027c
	goto loc_831E027C;
loc_831E0270:
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// li r7,1
	ctx.r7.s64 = 1;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_831E027C:
	// clrlwi. r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x831e0294
	if (cr0.eq) goto loc_831E0294;
	// mr r29,r10
	r29.u64 = ctx.r10.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// b 0x831e0260
	goto loc_831E0260;
loc_831E0294:
	// lwz r11,116(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// lwz r28,32(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bne cr6,0x831e04dc
	if (!cr6.eq) goto loc_831E04DC;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r25,r11,25480
	r25.s64 = r11.s64 + 25480;
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9eb0
	sub_831D9EB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x831e045c
	if (!cr0.eq) goto loc_831E045C;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dcc70
	sub_831DCC70(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dcd78
	sub_831DCD78(ctx, base);
	// li r3,18
	ctx.r3.s64 = 18;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83200d28
	sub_83200D28(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// addi r30,r11,24852
	r30.s64 = r11.s64 + 24852;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r11,-16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -16);
	// stw r11,128(r25)
	PPC_STORE_U32(r25.u32 + 128, r11.u32);
	// lfs f4,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// stb r11,153(r25)
	PPC_STORE_U8(r25.u32 + 153, r11.u8);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,136(r25)
	PPC_STORE_U32(r25.u32 + 136, r11.u32);
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e03cc
	if (!cr0.eq) goto loc_831E03CC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25340
	ctx.r5.s64 = r11.s64 + 25340;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,1372
	ctx.r7.s64 = 1372;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E03CC:
	// li r3,19
	ctx.r3.s64 = 19;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83200d28
	sub_83200D28(ctx, base);
	// lwz r11,-16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -16);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r10,23
	ctx.r10.s64 = 23;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r26,56(r28)
	PPC_STORE_U32(r28.u32 + 56, r26.u32);
	// stw r10,80(r28)
	PPC_STORE_U32(r28.u32 + 80, ctx.r10.u32);
	// stw r11,128(r28)
	PPC_STORE_U32(r28.u32 + 128, r11.u32);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,-4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -4);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,132(r28)
	PPC_STORE_U32(r28.u32 + 132, r11.u32);
	// lfs f4,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e06c4
	if (!cr0.eq) goto loc_831E06C4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r7,1383
	ctx.r7.s64 = 1383;
	// addi r5,r11,25324
	ctx.r5.s64 = r11.s64 + 25324;
	// b 0x831e06b4
	goto loc_831E06B4;
loc_831E045C:
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r27,r11,24852
	r27.s64 = r11.s64 + 24852;
	// li r10,23
	ctx.r10.s64 = 23;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r26,56(r30)
	PPC_STORE_U32(r30.u32 + 56, r26.u32);
	// lwz r11,-16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + -16);
	// stw r10,80(r30)
	PPC_STORE_U32(r30.u32 + 80, ctx.r10.u32);
	// stw r11,128(r30)
	PPC_STORE_U32(r30.u32 + 128, r11.u32);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,132(r30)
	PPC_STORE_U32(r30.u32 + 132, r11.u32);
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e06c4
	if (!cr0.eq) goto loc_831E06C4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r7,1394
	ctx.r7.s64 = 1394;
	// addi r5,r11,25264
	ctx.r5.s64 = r11.s64 + 25264;
	// b 0x831e06b4
	goto loc_831E06B4;
loc_831E04DC:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x831e06a0
	if (cr6.eq) goto loc_831E06A0;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dcf78
	sub_831DCF78(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dced8
	sub_831DCED8(ctx, base);
	// li r3,64
	ctx.r3.s64 = 64;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83200c70
	sub_83200C70(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r30,23
	r30.s64 = 23;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r26,56(r25)
	PPC_STORE_U32(r25.u32 + 56, r26.u32);
	// stw r30,80(r25)
	PPC_STORE_U32(r25.u32 + 80, r30.u32);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r27,r11,24852
	r27.s64 = r11.s64 + 24852;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// stw r11,132(r25)
	PPC_STORE_U32(r25.u32 + 132, r11.u32);
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// clrlwi. r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r25,r11,25324
	r25.s64 = r11.s64 + 25324;
	// bne 0x831e059c
	if (!cr0.eq) goto loc_831E059C;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,1412
	ctx.r7.s64 = 1412;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E059C:
	// li r3,19
	ctx.r3.s64 = 19;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83200d28
	sub_83200D28(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r26,56(r24)
	PPC_STORE_U32(r24.u32 + 56, r26.u32);
	// stw r30,80(r24)
	PPC_STORE_U32(r24.u32 + 80, r30.u32);
	// stw r26,60(r24)
	PPC_STORE_U32(r24.u32 + 60, r26.u32);
	// stw r30,84(r24)
	PPC_STORE_U32(r24.u32 + 84, r30.u32);
	// lfs f4,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e0618
	if (!cr0.eq) goto loc_831E0618;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,1420
	ctx.r7.s64 = 1420;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E0618:
	// li r3,20
	ctx.r3.s64 = 20;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83200d98
	sub_83200D98(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// stw r26,56(r24)
	PPC_STORE_U32(r24.u32 + 56, r26.u32);
	// stw r30,80(r24)
	PPC_STORE_U32(r24.u32 + 80, r30.u32);
	// stw r26,60(r24)
	PPC_STORE_U32(r24.u32 + 60, r26.u32);
	// stw r30,84(r24)
	PPC_STORE_U32(r24.u32 + 84, r30.u32);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,136(r24)
	PPC_STORE_U32(r24.u32 + 136, r11.u32);
	// lfs f4,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e06c4
	if (!cr0.eq) goto loc_831E06C4;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// li r7,1430
	ctx.r7.s64 = 1430;
	// b 0x831e06b4
	goto loc_831E06B4;
loc_831E06A0:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x831e06c4
	if (!cr6.eq) goto loc_831E06C4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r7,1432
	ctx.r7.s64 = 1432;
	// addi r5,r11,25308
	ctx.r5.s64 = r11.s64 + 25308;
loc_831E06B4:
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E06C4:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_831E0120) {
	__imp__sub_831E0120(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E06D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// li r10,23
	ctx.r10.s64 = 23;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// stw r11,56(r30)
	PPC_STORE_U32(r30.u32 + 56, r11.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r10,80(r30)
	PPC_STORE_U32(r30.u32 + 80, ctx.r10.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lfs f3,3084(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 3084);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,3080(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 3080);
	ctx.f4.f64 = double(temp.f32);
	// fmr f2,f3
	ctx.f2.f64 = ctx.f3.f64;
	// fmr f1,f3
	ctx.f1.f64 = ctx.f3.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e0778
	if (!cr0.eq) goto loc_831E0778;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,25264
	ctx.r5.s64 = ctx.r10.s64 + 25264;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1445
	ctx.r7.s64 = 1445;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E0778:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831E06D0) {
	__imp__sub_831E06D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E0790) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// lwz r22,136(r26)
	r22.u64 = PPC_LOAD_U32(r26.u32 + 136);
	// lwz r11,8(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831e096c
	if (cr6.eq) goto loc_831E096C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r25,r11,-18548
	r25.s64 = r11.s64 + -18548;
	// addi r24,r10,25392
	r24.s64 = ctx.r10.s64 + 25392;
	// addi r23,r9,24888
	r23.s64 = ctx.r9.s64 + 24888;
loc_831E07C8:
	// lwz r31,28(r22)
	r31.u64 = PPC_LOAD_U32(r22.u32 + 28);
	// b 0x831e0950
	goto loc_831E0950;
loc_831E07D0:
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e094c
	if (cr0.eq) goto loc_831E094C;
	// lwz r27,20(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// ble cr6,0x831e094c
	if (!cr6.gt) goto loc_831E094C;
	// addi r10,r31,84
	ctx.r10.s64 = r31.s64 + 84;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
loc_831E07F8:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831e0824
	if (cr6.eq) goto loc_831E0824;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x831e0824
	if (cr6.eq) goto loc_831E0824;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x831e0824
	if (cr6.eq) goto loc_831E0824;
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x831e0828
	if (!cr6.eq) goto loc_831E0828;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// b 0x831e0828
	goto loc_831E0828;
loc_831E0824:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
loc_831E0828:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x831e07f8
	if (!cr0.eq) goto loc_831E07F8;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x831e094c
	if (cr6.eq) goto loc_831E094C;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x831e094c
	if (cr6.eq) goto loc_831E094C;
	// cmpw cr6,r7,r8
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, xer);
	// li r28,0
	r28.s64 = 0;
	// bgt cr6,0x831e0854
	if (cr6.gt) goto loc_831E0854;
	// li r28,1
	r28.s64 = 1;
loc_831E0854:
	// cmpwi cr6,r8,1
	cr6.compare<int32_t>(ctx.r8.s32, 1, xer);
	// beq cr6,0x831e087c
	if (cr6.eq) goto loc_831E087C;
	// cmpwi cr6,r7,1
	cr6.compare<int32_t>(ctx.r7.s32, 1, xer);
	// beq cr6,0x831e087c
	if (cr6.eq) goto loc_831E087C;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// li r7,1915
	ctx.r7.s64 = 1915;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E087C:
	// li r29,0
	r29.s64 = 0;
	// addi r30,r31,32
	r30.s64 = r31.s64 + 32;
loc_831E0884:
	// lwz r11,52(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 52);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831e08a0
	if (cr6.eq) goto loc_831E08A0;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x831e08a0
	if (cr6.eq) goto loc_831E08A0;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x831e08a8
	if (!cr6.eq) goto loc_831E08A8;
loc_831E08A0:
	// clrlwi. r10,r28,24
	ctx.r10.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831e08b8
	if (!cr0.eq) goto loc_831E08B8;
loc_831E08A8:
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x831e093c
	if (!cr6.eq) goto loc_831E093C;
	// clrlwi. r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e093c
	if (!cr0.eq) goto loc_831E093C;
loc_831E08B8:
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// lwz r10,12(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// lwz r21,0(r30)
	r21.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x831fd6c8
	sub_831FD6C8(ctx, base);
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// addi r4,r29,1
	ctx.r4.s64 = r29.s64 + 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,948(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 948);
	// bl 0x83201f30
	sub_83201F30(ctx, base);
loc_831E093C:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmpw cr6,r29,r27
	cr6.compare<int32_t>(r29.s32, r27.s32, xer);
	// blt cr6,0x831e0884
	if (cr6.lt) goto loc_831E0884;
loc_831E094C:
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
loc_831E0950:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831e07d0
	if (!cr6.eq) goto loc_831E07D0;
	// lwz r22,8(r22)
	r22.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// lwz r11,8(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831e07c8
	if (!cr6.eq) goto loc_831E07C8;
loc_831E096C:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c14
	return;
}

PPC_WEAK_FUNC(sub_831E0790) {
	__imp__sub_831E0790(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E0978) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,32
	ctx.r4.s64 = 32;
	// addi r3,r31,184
	ctx.r3.s64 = r31.s64 + 184;
	// bl 0x831fb1b8
	sub_831FB1B8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e0e40
	if (cr0.eq) goto loc_831E0E40;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// li r4,32
	ctx.r4.s64 = 32;
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// clrlwi. r9,r3,24
	ctx.r9.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r23,r11,-18548
	r23.s64 = r11.s64 + -18548;
	// addi r22,r10,24888
	r22.s64 = ctx.r10.s64 + 24888;
	// bne 0x831e09fc
	if (!cr0.eq) goto loc_831E09FC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25488
	ctx.r5.s64 = r11.s64 + 25488;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,1977
	ctx.r7.s64 = 1977;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E09FC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,20
	ctx.r4.s64 = 20;
	// lwz r29,1452(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// addic. r30,r3,4
	xer.ca = ctx.r3.u32 > 4294967291;
	r30.s64 = ctx.r3.s64 + 4;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// stw r29,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r29.u32);
	// beq 0x831e0a34
	if (cr0.eq) goto loc_831E0A34;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,1452(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// bl 0x831df0d8
	sub_831DF0D8(ctx, base);
	// mr r21,r30
	r21.u64 = r30.u64;
	// b 0x831e0a38
	goto loc_831E0A38;
loc_831E0A34:
	// li r21,0
	r21.s64 = 0;
loc_831E0A38:
	// li r24,1
	r24.s64 = 1;
	// li r30,0
	r30.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// mr r25,r24
	r25.u64 = r24.u64;
loc_831E0A48:
	// lwz r11,36(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 36);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r25,r10
	cr6.compare<uint32_t>(r25.u32, ctx.r10.u32, xer);
	// ble cr6,0x831e0a60
	if (!cr6.gt) goto loc_831E0A60;
	// li r11,0
	r11.s64 = 0;
	// b 0x831e0a6c
	goto loc_831E0A6C;
loc_831E0A60:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r11,r24
	r11.u64 = r24.u64;
	// lwzx r30,r10,r26
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r26.u32);
loc_831E0A6C:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e0ad0
	if (cr0.eq) goto loc_831E0AD0;
	// lwz r11,228(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 228);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e0ac4
	if (cr0.eq) goto loc_831E0AC4;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r29,0
	r29.s64 = 0;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x831e0ac4
	if (!cr6.gt) goto loc_831E0AC4;
	// addi r28,r30,84
	r28.s64 = r30.s64 + 84;
loc_831E0A94:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// bne cr6,0x831e0ab0
	if (!cr6.eq) goto loc_831E0AB0;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r4,4(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_831E0AB0:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmpw cr6,r29,r11
	cr6.compare<int32_t>(r29.s32, r11.s32, xer);
	// blt cr6,0x831e0a94
	if (cr6.lt) goto loc_831E0A94;
loc_831E0AC4:
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// b 0x831e0a48
	goto loc_831E0A48;
loc_831E0AD0:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// stb r24,2073(r31)
	PPC_STORE_U8(r31.u32 + 2073, r24.u8);
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// lwz r11,52(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 52);
	// lwz r10,48(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x831e0b20
	if (cr6.eq) goto loc_831E0B20;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25448
	ctx.r5.s64 = r11.s64 + 25448;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,1996
	ctx.r7.s64 = 1996;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E0B20:
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r3,164(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 164);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e0bd0
	if (!cr0.eq) goto loc_831E0BD0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25264
	ctx.r5.s64 = r11.s64 + 25264;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2008
	ctx.r7.s64 = 2008;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E0BD0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df808
	sub_831DF808(ctx, base);
	// lwz r11,48(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831e0d38
	if (cr6.eq) goto loc_831E0D38;
	// li r3,18
	ctx.r3.s64 = 18;
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// stb r24,159(r29)
	PPC_STORE_U8(r29.u32 + 159, r24.u8);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc698
	sub_831DC698(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc6b0
	sub_831DC6B0(ctx, base);
	// lfs f4,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f3.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f1,f3
	ctx.f1.f64 = ctx.f3.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// stb r24,154(r29)
	PPC_STORE_U8(r29.u32 + 154, r24.u8);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r3,164(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 164);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// stb r24,153(r30)
	PPC_STORE_U8(r30.u32 + 153, r24.u8);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// b 0x831e0da8
	goto loc_831E0DA8;
loc_831E0D38:
	// li r3,49
	ctx.r3.s64 = 49;
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stb r24,159(r29)
	PPC_STORE_U8(r29.u32 + 159, r24.u8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
loc_831E0DA8:
	// lwz r3,164(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 164);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831e0e40
	if (cr6.eq) goto loc_831E0E40;
	// li r27,0
	r27.s64 = 0;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// bge cr6,0x831e0dd8
	if (!cr6.lt) goto loc_831E0DD8;
loc_831E0DCC:
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// add r3,r11,r27
	ctx.r3.u64 = r11.u64 + r27.u64;
	// b 0x831e0de4
	goto loc_831E0DE4;
loc_831E0DD8:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
loc_831E0DE4:
	// lwz r31,0(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r30,r24
	r30.u64 = r24.u64;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// blt cr6,0x831e0e2c
	if (cr6.lt) goto loc_831E0E2C;
	// addi r29,r31,84
	r29.s64 = r31.s64 + 84;
loc_831E0DFC:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// bne cr6,0x831e0e18
	if (!cr6.eq) goto loc_831E0E18;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
loc_831E0E18:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// ble cr6,0x831e0dfc
	if (!cr6.gt) goto loc_831E0DFC;
loc_831E0E2C:
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x831e0dcc
	if (cr6.lt) goto loc_831E0DCC;
loc_831E0E40:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c1c
	return;
}

PPC_WEAK_FUNC(sub_831E0978) {
	__imp__sub_831E0978(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E0E48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,32
	ctx.r4.s64 = 32;
	// addi r3,r31,184
	ctx.r3.s64 = r31.s64 + 184;
	// bl 0x831fb1b8
	sub_831FB1B8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e1154
	if (cr0.eq) goto loc_831E1154;
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// bl 0x832023c8
	sub_832023C8(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// addi r24,r11,-18548
	r24.s64 = r11.s64 + -18548;
	// addi r23,r10,24888
	r23.s64 = ctx.r10.s64 + 24888;
	// beq cr6,0x831e0eb0
	if (cr6.eq) goto loc_831E0EB0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// addi r5,r11,25356
	ctx.r5.s64 = r11.s64 + 25356;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,2104
	ctx.r7.s64 = 2104;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E0EB0:
	// lwz r9,168(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// li r27,0
	r27.s64 = 0;
	// lwz r26,88(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// mr r11,r27
	r11.u64 = r27.u64;
	// lwz r9,60(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// lwz r6,4(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
loc_831E0ED0:
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// ble cr6,0x831e0ee0
	if (!cr6.gt) goto loc_831E0EE0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// b 0x831e0eec
	goto loc_831E0EEC;
loc_831E0EE0:
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// li r7,1
	ctx.r7.s64 = 1;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_831E0EEC:
	// clrlwi. r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x831e0f04
	if (cr0.eq) goto loc_831E0F04;
	// mr r26,r10
	r26.u64 = ctx.r10.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// b 0x831e0ed0
	goto loc_831E0ED0;
loc_831E0F04:
	// lwz r11,116(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// lis r10,-31972
	ctx.r10.s64 = -2095316992;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r10,25480
	ctx.r6.s64 = ctx.r10.s64 + 25480;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r28,32(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bl 0x831dcf78
	sub_831DCF78(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dced8
	sub_831DCED8(ctx, base);
	// li r3,64
	ctx.r3.s64 = 64;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83200c70
	sub_83200C70(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r29,32
	r29.s64 = 32;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r27,56(r25)
	PPC_STORE_U32(r25.u32 + 56, r27.u32);
	// stw r29,80(r25)
	PPC_STORE_U32(r25.u32 + 80, r29.u32);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r30,r11,24840
	r30.s64 = r11.s64 + 24840;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,132(r25)
	PPC_STORE_U32(r25.u32 + 132, r11.u32);
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// clrlwi. r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r25,r11,25324
	r25.s64 = r11.s64 + 25324;
	// bne 0x831e0fc4
	if (!cr0.eq) goto loc_831E0FC4;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,2130
	ctx.r7.s64 = 2130;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E0FC4:
	// li r3,19
	ctx.r3.s64 = 19;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83200d28
	sub_83200D28(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r27,56(r22)
	PPC_STORE_U32(r22.u32 + 56, r27.u32);
	// stw r29,80(r22)
	PPC_STORE_U32(r22.u32 + 80, r29.u32);
	// stw r27,60(r22)
	PPC_STORE_U32(r22.u32 + 60, r27.u32);
	// stw r29,84(r22)
	PPC_STORE_U32(r22.u32 + 84, r29.u32);
	// lfs f4,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e1040
	if (!cr0.eq) goto loc_831E1040;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,2139
	ctx.r7.s64 = 2139;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1040:
	// li r3,20
	ctx.r3.s64 = 20;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83200d98
	sub_83200D98(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// lwz r11,-4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -4);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// stw r27,56(r22)
	PPC_STORE_U32(r22.u32 + 56, r27.u32);
	// stw r11,128(r22)
	PPC_STORE_U32(r22.u32 + 128, r11.u32);
	// stw r29,80(r22)
	PPC_STORE_U32(r22.u32 + 80, r29.u32);
	// stw r27,60(r22)
	PPC_STORE_U32(r22.u32 + 60, r27.u32);
	// stw r29,84(r22)
	PPC_STORE_U32(r22.u32 + 84, r29.u32);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,136(r22)
	PPC_STORE_U32(r22.u32 + 136, r11.u32);
	// lfs f4,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e10dc
	if (!cr0.eq) goto loc_831E10DC;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,2151
	ctx.r7.s64 = 2151;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E10DC:
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r27,56(r25)
	PPC_STORE_U32(r25.u32 + 56, r27.u32);
	// stw r29,80(r25)
	PPC_STORE_U32(r25.u32 + 80, r29.u32);
	// stw r11,128(r25)
	PPC_STORE_U32(r25.u32 + 128, r11.u32);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,132(r25)
	PPC_STORE_U32(r25.u32 + 132, r11.u32);
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e1154
	if (!cr0.eq) goto loc_831E1154;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// addi r5,r11,25264
	ctx.r5.s64 = r11.s64 + 25264;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,2161
	ctx.r7.s64 = 2161;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1154:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_831E0E48) {
	__imp__sub_831E0E48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E1160) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r31,12(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r3,1488(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// bl 0x831db5f0
	sub_831DB5F0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x831e1350
	if (!cr6.eq) goto loc_831E1350;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r6,12(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r5,r11,25480
	ctx.r5.s64 = r11.s64 + 25480;
	// bl 0x831dbbb8
	sub_831DBBB8(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// addi r28,r11,-18548
	r28.s64 = r11.s64 + -18548;
	// addi r27,r10,24888
	r27.s64 = ctx.r10.s64 + 24888;
	// beq cr6,0x831e11fc
	if (cr6.eq) goto loc_831E11FC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r11,25516
	ctx.r5.s64 = r11.s64 + 25516;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,2364
	ctx.r7.s64 = 2364;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E11FC:
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r7,164(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 164);
	// clrlwi r10,r4,16
	ctx.r10.u64 = ctx.r4.u32 & 0xFFFF;
	// li r8,1
	ctx.r8.s64 = 1;
	// oris r10,r10,5
	ctx.r10.u64 = ctx.r10.u64 | 327680;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r6,24828(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 24828);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83205558
	sub_83205558(ctx, base);
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,6
	r11.s64 = 6;
	// li r29,0
	r29.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
	// stw r29,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r29.u32);
	// lwz r11,84(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,25
	r11.s64 = 25;
	// stw r11,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r11.u32);
	// stw r10,60(r31)
	PPC_STORE_U32(r31.u32 + 60, ctx.r10.u32);
loc_831E12D8:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// blt cr6,0x831e12d8
	if (cr6.lt) goto loc_831E12D8;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,168(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 168);
	// bl 0x83201e88
	sub_83201E88(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e1348
	if (!cr0.eq) goto loc_831E1348;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r11,25264
	ctx.r5.s64 = r11.s64 + 25264;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,2382
	ctx.r7.s64 = 2382;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1348:
	// li r11,1
	r11.s64 = 1;
	// stb r11,124(r30)
	PPC_STORE_U8(r30.u32 + 124, r11.u8);
loc_831E1350:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831E1160) {
	__imp__sub_831E1160(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E1358) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// li r29,0
	r29.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// lfs f0,3084(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
loc_831E1384:
	// lwz r27,12(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r26,r11,25480
	r26.s64 = r11.s64 + 25480;
	// lwz r3,1488(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// bl 0x831dd970
	sub_831DD970(ctx, base);
	// addi r11,r3,-1
	r11.s64 = ctx.r3.s64 + -1;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// cmpwi cr6,r30,5
	cr6.compare<int32_t>(r30.s32, 5, xer);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or r29,r11,r29
	r29.u64 = r11.u64 | r29.u64;
	// blt cr6,0x831e1384
	if (cr6.lt) goto loc_831E1384;
	// lbz r11,126(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 126);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831e1574
	if (cr0.eq) goto loc_831E1574;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x831e1574
	if (cr6.eq) goto loc_831E1574;
	// clrlwi. r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e1574
	if (cr0.eq) goto loc_831E1574;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc558
	sub_831DC558(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc558
	sub_831DC558(ctx, base);
	// lwz r11,120(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// li r3,23
	ctx.r3.s64 = 23;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r30,32(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lfs f4,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// li r5,2
	ctx.r5.s64 = 2;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,120(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// bl 0x83201f30
	sub_83201F30(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// clrlwi. r9,r3,24
	ctx.r9.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r29,r11,-18548
	r29.s64 = r11.s64 + -18548;
	// addi r28,r10,24888
	r28.s64 = ctx.r10.s64 + 24888;
	// bne 0x831e14e0
	if (!cr0.eq) goto loc_831E14E0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,25556
	ctx.r5.s64 = r11.s64 + 25556;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,2421
	ctx.r7.s64 = 2421;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E14E0:
	// li r3,25
	ctx.r3.s64 = 25;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lfs f4,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f4.f64 = double(temp.f32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// li r5,2
	ctx.r5.s64 = 2;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r4,120(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// bl 0x83201f30
	sub_83201F30(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e1574
	if (!cr0.eq) goto loc_831E1574;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,25540
	ctx.r5.s64 = r11.s64 + 25540;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,2429
	ctx.r7.s64 = 2429;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1574:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831E1358) {
	__imp__sub_831E1358(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E1580) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -168, f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831df808
	sub_831DF808(ctx, base);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// stw r3,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r3.u32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r11,r11,5664
	r11.s64 = r11.s64 + 5664;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// lfs f30,3080(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 3080);
	f30.f64 = double(temp.f32);
	// lis r7,-32248
	ctx.r7.s64 = -2113404928;
	// lfs f31,3084(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 3084);
	f31.f64 = double(temp.f32);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// addi r29,r30,1096
	r29.s64 = r30.s64 + 1096;
	// li r28,16
	r28.s64 = 16;
	// lis r8,-32248
	ctx.r8.s64 = -2113404928;
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// lis r6,-32248
	ctx.r6.s64 = -2113404928;
	// stw r28,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r28.u32);
	// addi r10,r10,25264
	ctx.r10.s64 = ctx.r10.s64 + 25264;
	// addi r9,r9,25596
	ctx.r9.s64 = ctx.r9.s64 + 25596;
	// addi r11,r7,25572
	r11.s64 = ctx.r7.s64 + 25572;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// li r16,0
	r16.s64 = 0;
	// stw r9,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r9.u32);
	// li r17,1
	r17.s64 = 1;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// addi r23,r8,-18548
	r23.s64 = ctx.r8.s64 + -18548;
	// addi r22,r6,24888
	r22.s64 = ctx.r6.s64 + 24888;
loc_831E1608:
	// lwz r20,0(r29)
	r20.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x831e1bf8
	if (cr6.eq) goto loc_831E1BF8;
	// lwz r11,32(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 32);
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// bne cr6,0x831e1bf8
	if (!cr6.eq) goto loc_831E1BF8;
	// lwz r25,36(r20)
	r25.u64 = PPC_LOAD_U32(r20.u32 + 36);
	// li r27,0
	r27.s64 = 0;
	// li r21,0
	r21.s64 = 0;
	// mr r18,r17
	r18.u64 = r17.u64;
	// lwz r19,4(r25)
	r19.u64 = PPC_LOAD_U32(r25.u32 + 4);
loc_831E1634:
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// cmplw cr6,r18,r11
	cr6.compare<uint32_t>(r18.u32, r11.u32, xer);
	// ble cr6,0x831e1648
	if (!cr6.gt) goto loc_831E1648;
	// li r11,0
	r11.s64 = 0;
	// b 0x831e1654
	goto loc_831E1654;
loc_831E1648:
	// lwz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// mr r11,r17
	r11.u64 = r17.u64;
	// lwzx r27,r10,r21
	r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + r21.u32);
loc_831E1654:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e1ba8
	if (cr0.eq) goto loc_831E1BA8;
	// lwz r11,228(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 228);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e1b9c
	if (cr0.eq) goto loc_831E1B9C;
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r26,r17
	r26.u64 = r17.u64;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// blt cr6,0x831e1b9c
	if (cr6.lt) goto loc_831E1B9C;
	// addi r24,r27,32
	r24.s64 = r27.s64 + 32;
loc_831E167C:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// cmplw cr6,r20,r11
	cr6.compare<uint32_t>(r20.u32, r11.u32, xer);
	// bne cr6,0x831e1b80
	if (!cr6.eq) goto loc_831E1B80;
	// lwz r31,12(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r28,12(r20)
	r28.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r3,1488(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// bl 0x831ddc08
	sub_831DDC08(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x831e1898
	if (!cr6.eq) goto loc_831E1898;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x831e1864
	if (!cr6.eq) goto loc_831E1864;
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// mr r16,r3
	r16.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,3
	ctx.r6.s64 = 3;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stb r17,159(r31)
	PPC_STORE_U8(r31.u32 + 159, r17.u8);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,164(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 164);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e17a8
	if (!cr0.eq) goto loc_831E17A8;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2501
	ctx.r7.s64 = 2501;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E17A8:
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f30
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f30.f64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,164(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 164);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e1864
	if (!cr0.eq) goto loc_831E1864;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2511
	ctx.r7.s64 = 2511;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1864:
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e1b80
	if (!cr0.eq) goto loc_831E1B80;
	// li r7,2516
	ctx.r7.s64 = 2516;
	// b 0x831e1b6c
	goto loc_831E1B6C;
loc_831E1898:
	// lwz r31,12(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r3,1488(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// bl 0x831dda98
	sub_831DDA98(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x831e1b80
	if (!cr0.eq) goto loc_831E1B80;
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,3
	ctx.r6.s64 = 3;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stb r17,159(r31)
	PPC_STORE_U8(r31.u32 + 159, r17.u8);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,164(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 164);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e19ac
	if (!cr0.eq) goto loc_831E19AC;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// lwz r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2536
	ctx.r7.s64 = 2536;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E19AC:
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r15,r11,25480
	r15.s64 = r11.s64 + 25480;
	// lwz r14,12(r30)
	r14.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r3,1488(r14)
	ctx.r3.u64 = PPC_LOAD_U32(r14.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// bl 0x831ddd98
	sub_831DDD98(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x831e1a60
	if (!cr6.eq) goto loc_831E1A60;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x831e1aa4
	goto loc_831E1AA4;
loc_831E1A60:
	// lwz r15,12(r30)
	r15.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r14,r11,25480
	r14.s64 = r11.s64 + 25480;
	// lwz r3,1488(r15)
	ctx.r3.u64 = PPC_LOAD_U32(r15.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r6,r14
	ctx.r6.u64 = r14.u64;
	// mr r7,r15
	ctx.r7.u64 = r15.u64;
	// bl 0x831ddf28
	sub_831DDF28(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x831e1ae4
	if (!cr6.eq) goto loc_831E1AE4;
	// li r6,2
	ctx.r6.s64 = 2;
loc_831E1AA4:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r6,3
	ctx.r6.s64 = 3;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x831e1afc
	goto loc_831E1AFC;
loc_831E1AE4:
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// lwz r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2565
	ctx.r7.s64 = 2565;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1AFC:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,164(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 164);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e1b3c
	if (!cr0.eq) goto loc_831E1B3C;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// lwz r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2570
	ctx.r7.s64 = 2570;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1B3C:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e1b80
	if (!cr0.eq) goto loc_831E1B80;
	// li r7,2575
	ctx.r7.s64 = 2575;
loc_831E1B6C:
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// lwz r5,92(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1B80:
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// cmpw cr6,r26,r11
	cr6.compare<int32_t>(r26.s32, r11.s32, xer);
	// ble cr6,0x831e167c
	if (!cr6.gt) goto loc_831E167C;
	// lwz r28,96(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r29,100(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
loc_831E1B9C:
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// addi r21,r21,4
	r21.s64 = r21.s64 + 4;
	// b 0x831e1634
	goto loc_831E1634;
loc_831E1BA8:
	// cmpwi cr6,r19,0
	cr6.compare<int32_t>(r19.s32, 0, xer);
	// beq cr6,0x831e1bf8
	if (cr6.eq) goto loc_831E1BF8;
	// rlwinm r31,r19,2,0,29
	r31.u64 = rotl64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
loc_831E1BB4:
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// addi r19,r19,-1
	r19.s64 = r19.s64 + -1;
	// addi r31,r31,-4
	r31.s64 = r31.s64 + -4;
	// cmplw cr6,r19,r11
	cr6.compare<uint32_t>(r19.u32, r11.u32, xer);
	// bge cr6,0x831e1bd4
	if (!cr6.lt) goto loc_831E1BD4;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// b 0x831e1be4
	goto loc_831E1BE4;
loc_831E1BD4:
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831E1BE4:
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x831fd770
	sub_831FD770(ctx, base);
	// cmpwi cr6,r19,0
	cr6.compare<int32_t>(r19.s32, 0, xer);
	// bne cr6,0x831e1bb4
	if (!cr6.eq) goto loc_831E1BB4;
loc_831E1BF8:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// stw r28,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r28.u32);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// bne 0x831e1608
	if (!cr0.eq) goto loc_831E1608;
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82ca2c00
	return;
}

PPC_WEAK_FUNC(sub_831E1580) {
	__imp__sub_831E1580(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E1C20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,116(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831e1d4c
	if (!cr6.eq) goto loc_831E1D4C;
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// bl 0x832023c8
	sub_832023C8(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// addi r29,r11,-18548
	r29.s64 = r11.s64 + -18548;
	// addi r28,r10,24888
	r28.s64 = ctx.r10.s64 + 24888;
	// beq cr6,0x831e1c78
	if (cr6.eq) goto loc_831E1C78;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,25356
	ctx.r5.s64 = r11.s64 + 25356;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,2604
	ctx.r7.s64 = 2604;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1C78:
	// lwz r9,168(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r30,80(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,0
	r11.s64 = 0;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r9,60(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// lwz r6,4(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
loc_831E1C94:
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// ble cr6,0x831e1ca4
	if (!cr6.gt) goto loc_831E1CA4;
	// li r7,0
	ctx.r7.s64 = 0;
	// b 0x831e1cb0
	goto loc_831E1CB0;
loc_831E1CA4:
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// li r7,1
	ctx.r7.s64 = 1;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_831E1CB0:
	// clrlwi. r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x831e1cc8
	if (cr0.eq) goto loc_831E1CC8;
	// mr r30,r10
	r30.u64 = ctx.r10.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// b 0x831e1c94
	goto loc_831E1C94;
loc_831E1CC8:
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r11,5
	r11.s64 = 5;
	// li r10,0
	ctx.r10.s64 = 0;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r10,56(r27)
	PPC_STORE_U32(r27.u32 + 56, ctx.r10.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,80(r27)
	PPC_STORE_U32(r27.u32 + 80, r11.u32);
	// lfs f4,3084(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 3084);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e1d4c
	if (!cr0.eq) goto loc_831E1D4C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r5,r11,25264
	ctx.r5.s64 = r11.s64 + 25264;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r7,2616
	ctx.r7.s64 = 2616;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1D4C:
	// lwz r11,168(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831e1d7c
	goto loc_831E1D7C;
loc_831E1D5C:
	// lwz r9,228(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 228);
	// clrlwi. r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831e1d74
	if (cr0.eq) goto loc_831E1D74;
	// lwz r9,80(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmpwi cr6,r9,5
	cr6.compare<int32_t>(ctx.r9.s32, 5, xer);
	// beq cr6,0x831e1d88
	if (cr6.eq) goto loc_831E1D88;
loc_831E1D74:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_831E1D7C:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x831e1d5c
	if (!cr6.eq) goto loc_831E1D5C;
	// b 0x831e1d8c
	goto loc_831E1D8C;
loc_831E1D88:
	// stw r11,116(r31)
	PPC_STORE_U32(r31.u32 + 116, r11.u32);
loc_831E1D8C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831E1C20) {
	__imp__sub_831E1C20(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E1D98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31951
	r11.s64 = -2093940736;
	// lis r10,-32247
	ctx.r10.s64 = -2113339392;
	// addi r11,r11,10000
	r11.s64 = r11.s64 + 10000;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r10,r10,-20720
	ctx.r10.s64 = ctx.r10.s64 + -20720;
	// li r3,142
	ctx.r3.s64 = 142;
	// lwz r11,7432(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 7432);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// li r10,46
	ctx.r10.s64 = 46;
	// stw r11,56(r30)
	PPC_STORE_U32(r30.u32 + 56, r11.u32);
	// stw r10,80(r30)
	PPC_STORE_U32(r30.u32 + 80, ctx.r10.u32);
	// stw r11,168(r30)
	PPC_STORE_U32(r30.u32 + 168, r11.u32);
	// lbz r11,2144(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2144);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831e1e74
	if (cr0.eq) goto loc_831E1E74;
	// lwz r11,116(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831e1e74
	if (cr6.eq) goto loc_831E1E74;
	// lwz r29,948(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 948);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e88
	sub_83201E88(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r3,116(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// bl 0x831df280
	sub_831DF280(ctx, base);
	// lwz r11,120(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831e1e74
	if (cr6.eq) goto loc_831E1E74;
	// li r11,1
	r11.s64 = 1;
	// stw r11,168(r30)
	PPC_STORE_U32(r30.u32 + 168, r11.u32);
	// lwz r11,120(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// lwz r11,948(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 948);
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// beq cr6,0x831e1e68
	if (cr6.eq) goto loc_831E1E68;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,25612
	ctx.r5.s64 = ctx.r10.s64 + 25612;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2823
	ctx.r7.s64 = 2823;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1E68:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r3,120(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// bl 0x831df280
	sub_831DF280(ctx, base);
loc_831E1E74:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E1D98) {
	__imp__sub_831E1D98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E1E80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r11,948(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 948);
	// lwz r11,132(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 132);
	// rlwinm. r30,r11,29,31,31
	r30.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x831e1ed4
	if (cr0.eq) goto loc_831E1ED4;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x831e1ed4
	if (cr0.eq) goto loc_831E1ED4;
	// lwz r11,948(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 948);
	// lwz r10,948(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 948);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r30,r11,1
	r30.u64 = r11.u64 ^ 1;
loc_831E1ED4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E1E80) {
	__imp__sub_831E1E80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E1EE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc0
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r4,20
	ctx.r4.s64 = 20;
	// lwz r11,2148(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 2148);
	// lwz r10,12(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,2148(r25)
	PPC_STORE_U32(r25.u32 + 2148, r11.u32);
	// lwz r30,1456(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1456);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// addic. r31,r3,4
	xer.ca = ctx.r3.u32 > 4294967291;
	r31.s64 = ctx.r3.s64 + 4;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
	// beq 0x831e1f34
	if (cr0.eq) goto loc_831E1F34;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,1456(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// bl 0x831df0d8
	sub_831DF0D8(ctx, base);
	// mr r24,r31
	r24.u64 = r31.u64;
	// b 0x831e1f38
	goto loc_831E1F38;
loc_831E1F34:
	// li r24,0
	r24.s64 = 0;
loc_831E1F38:
	// lwz r11,96(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 96);
	// lwz r22,4(r11)
	r22.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// ble cr6,0x831e24b4
	if (!cr6.gt) goto loc_831E24B4;
	// rlwinm r11,r22,2,0,29
	r11.u64 = rotl64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r21,r11,-4
	r21.s64 = r11.s64 + -4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r23,r22,-1
	r23.s64 = r22.s64 + -1;
	// addi r20,r11,-18548
	r20.s64 = r11.s64 + -18548;
	// addi r19,r10,25664
	r19.s64 = ctx.r10.s64 + 25664;
	// addi r18,r9,24888
	r18.s64 = ctx.r9.s64 + 24888;
loc_831E1F6C:
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831e1f90
	if (cr6.eq) goto loc_831E1F90;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// li r7,2864
	ctx.r7.s64 = 2864;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E1F90:
	// lwz r3,96(r25)
	ctx.r3.u64 = PPC_LOAD_U32(r25.u32 + 96);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r23,r11
	cr6.compare<uint32_t>(r23.u32, r11.u32, xer);
	// bge cr6,0x831e1fac
	if (!cr6.lt) goto loc_831E1FAC;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// add r3,r11,r21
	ctx.r3.u64 = r11.u64 + r21.u64;
	// b 0x831e1fb4
	goto loc_831E1FB4;
loc_831E1FAC:
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
loc_831E1FB4:
	// lwz r28,0(r3)
	r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bgt cr6,0x831e2498
	if (cr6.gt) goto loc_831E2498;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831e2498
	if (cr0.eq) goto loc_831E2498;
	// lwz r11,228(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 228);
	// rlwinm. r11,r11,29,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e2498
	if (!cr0.eq) goto loc_831E2498;
	// lwz r3,236(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 236);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e2498
	if (!cr0.eq) goto loc_831E2498;
	// lwz r31,236(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 236);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ff818
	sub_831FF818(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e2224
	if (cr0.eq) goto loc_831E2224;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,100(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 100);
	// bl 0x831e1e80
	sub_831E1E80(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e2224
	if (cr0.eq) goto loc_831E2224;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x831e2194
	if (cr0.eq) goto loc_831E2194;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r26,1
	r26.s64 = 1;
	// li r27,1
	r27.s64 = 1;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// blt cr6,0x831e2104
	if (cr6.lt) goto loc_831E2104;
	// addi r29,r31,236
	r29.s64 = r31.s64 + 236;
loc_831E2078:
	// lwz r30,0(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831e20ec
	if (!cr0.eq) goto loc_831E20EC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,100(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 100);
	// bl 0x831e1e80
	sub_831E1E80(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e20ec
	if (cr0.eq) goto loc_831E20EC;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmpwi cr6,r11,50
	cr6.compare<int32_t>(r11.s32, 50, xer);
	// beq cr6,0x831e20ec
	if (cr6.eq) goto loc_831E20EC;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831e20ec
	if (cr6.eq) goto loc_831E20EC;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e20ec
	if (!cr0.eq) goto loc_831E20EC;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmpwi cr6,r11,128
	cr6.compare<int32_t>(r11.s32, 128, xer);
	// bne cr6,0x831e20f0
	if (!cr6.eq) goto loc_831E20F0;
loc_831E20EC:
	// li r26,0
	r26.s64 = 0;
loc_831E20F0:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmpw cr6,r27,r11
	cr6.compare<int32_t>(r27.s32, r11.s32, xer);
	// ble cr6,0x831e2078
	if (!cr6.gt) goto loc_831E2078;
loc_831E2104:
	// clrlwi. r11,r26,24
	r11.u64 = r26.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e2498
	if (cr0.eq) goto loc_831E2498;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r27,1
	r27.s64 = 1;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// blt cr6,0x831e215c
	if (cr6.lt) goto loc_831E215C;
	// addi r29,r31,236
	r29.s64 = r31.s64 + 236;
loc_831E2120:
	// lwz r30,0(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r11,2148(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 2148);
	// lwz r10,892(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 892);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// beq cr6,0x831e2148
	if (cr6.eq) goto loc_831E2148;
	// stw r11,892(r30)
	PPC_STORE_U32(r30.u32 + 892, r11.u32);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r4,4(r24)
	ctx.r4.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_831E2148:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmpw cr6,r27,r11
	cr6.compare<int32_t>(r27.s32, r11.s32, xer);
	// ble cr6,0x831e2120
	if (!cr6.gt) goto loc_831E2120;
loc_831E215C:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831df408
	sub_831DF408(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,96(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,96(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x831e2224
	goto loc_831E2224;
loc_831E2194:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpwi cr6,r11,50
	cr6.compare<int32_t>(r11.s32, 50, xer);
	// beq cr6,0x831e2498
	if (cr6.eq) goto loc_831E2498;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831e2498
	if (cr6.eq) goto loc_831E2498;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e2498
	if (!cr0.eq) goto loc_831E2498;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpwi cr6,r11,128
	cr6.compare<int32_t>(r11.s32, 128, xer);
	// beq cr6,0x831e2498
	if (cr6.eq) goto loc_831E2498;
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// rlwinm. r11,r11,23,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 23) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e2498
	if (!cr0.eq) goto loc_831E2498;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x831df408
	sub_831DF408(ctx, base);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,96(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,2148(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 2148);
	// lwz r10,892(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 892);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// beq cr6,0x831e2224
	if (cr6.eq) goto loc_831E2224;
	// stw r11,892(r31)
	PPC_STORE_U32(r31.u32 + 892, r11.u32);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r4,4(r24)
	ctx.r4.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
loc_831E2224:
	// lwz r27,80(r28)
	r27.u64 = PPC_LOAD_U32(r28.u32 + 80);
	// lwz r26,56(r28)
	r26.u64 = PPC_LOAD_U32(r28.u32 + 56);
	// b 0x831e2488
	goto loc_831E2488;
loc_831E2230:
	// lwz r3,8(r24)
	ctx.r3.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwz r31,0(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831e24a4
	if (cr6.eq) goto loc_831E24A4;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x831fc910
	sub_831FC910(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ff818
	sub_831FF818(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e23ac
	if (cr0.eq) goto loc_831E23AC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,100(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 100);
	// bl 0x831e1e80
	sub_831E1E80(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e23ac
	if (cr0.eq) goto loc_831E23AC;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpwi cr6,r11,50
	cr6.compare<int32_t>(r11.s32, 50, xer);
	// beq cr6,0x831e23ac
	if (cr6.eq) goto loc_831E23AC;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831e23ac
	if (cr6.eq) goto loc_831E23AC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e23ac
	if (!cr0.eq) goto loc_831E23AC;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpwi cr6,r11,128
	cr6.compare<int32_t>(r11.s32, 128, xer);
	// beq cr6,0x831e23ac
	if (cr6.eq) goto loc_831E23AC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x831e2338
	if (cr0.eq) goto loc_831E2338;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r28,1
	r28.s64 = 1;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// blt cr6,0x831e2320
	if (cr6.lt) goto loc_831E2320;
	// addi r29,r31,236
	r29.s64 = r31.s64 + 236;
loc_831E22E4:
	// lwz r30,0(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r11,2148(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 2148);
	// lwz r10,892(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 892);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// beq cr6,0x831e230c
	if (cr6.eq) goto loc_831E230C;
	// stw r11,892(r30)
	PPC_STORE_U32(r30.u32 + 892, r11.u32);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r4,4(r24)
	ctx.r4.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_831E230C:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmpw cr6,r28,r11
	cr6.compare<int32_t>(r28.s32, r11.s32, xer);
	// ble cr6,0x831e22e4
	if (!cr6.gt) goto loc_831E22E4;
loc_831E2320:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,96(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x831e2488
	goto loc_831E2488;
loc_831E2338:
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// rlwinm. r11,r11,23,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 23) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e237c
	if (cr0.eq) goto loc_831E237C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df190
	sub_831DF190(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,2148(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 2148);
	// lwz r10,892(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 892);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// beq cr6,0x831e2374
	if (cr6.eq) goto loc_831E2374;
	// stw r11,892(r30)
	PPC_STORE_U32(r30.u32 + 892, r11.u32);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r4,4(r24)
	ctx.r4.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_831E2374:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df1f8
	sub_831DF1F8(ctx, base);
loc_831E237C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,100(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 100);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,100(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 100);
	// bl 0x831df280
	sub_831DF280(ctx, base);
	// b 0x831e2488
	goto loc_831E2488;
loc_831E23AC:
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r4,12(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// bl 0x83201318
	sub_83201318(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831df328
	sub_831DF328(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r11,100(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 100);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,100(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 100);
	// bl 0x831df280
	sub_831DF280(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,100(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 100);
	// bl 0x831e1e80
	sub_831E1E80(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,100(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 100);
	// beq 0x831e2478
	if (cr0.eq) goto loc_831E2478;
	// lwz r3,948(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 948);
	// lwz r11,948(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 948);
	// cmpw cr6,r3,r11
	cr6.compare<int32_t>(ctx.r3.s32, r11.s32, xer);
	// bne cr6,0x831e2470
	if (!cr6.eq) goto loc_831E2470;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r28,r31
	r28.u64 = r31.u64;
	// mr r29,r31
	r29.u64 = r31.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x831e2448
	goto loc_831E2448;
loc_831E2430:
	// lwz r11,100(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 100);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// beq cr6,0x831e2460
	if (cr6.eq) goto loc_831E2460;
	// lwz r29,8(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
loc_831E2448:
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e2430
	if (cr0.eq) goto loc_831E2430;
	// b 0x831e2464
	goto loc_831E2464;
loc_831E2460:
	// mr r28,r29
	r28.u64 = r29.u64;
loc_831E2464:
	// lwz r3,948(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 948);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// b 0x831e2480
	goto loc_831E2480;
loc_831E2470:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// b 0x831e2480
	goto loc_831E2480;
loc_831E2478:
	// lwz r3,948(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 948);
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
loc_831E2480:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x83201ed0
	sub_83201ED0(ctx, base);
loc_831E2488:
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831e2230
	if (!cr6.eq) goto loc_831E2230;
	// b 0x831e24a4
	goto loc_831E24A4;
loc_831E2498:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r4,100(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 100);
	// bl 0x831df280
	sub_831DF280(ctx, base);
loc_831E24A4:
	// addic. r22,r22,-1
	xer.ca = r22.u32 > 0;
	r22.s64 = r22.s64 + -1;
	cr0.compare<int32_t>(r22.s32, 0, xer);
	// addi r21,r21,-4
	r21.s64 = r21.s64 + -4;
	// addi r23,r23,-1
	r23.s64 = r23.s64 + -1;
	// bgt 0x831e1f6c
	if (cr0.gt) goto loc_831E1F6C;
loc_831E24B4:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c10
	return;
}

PPC_WEAK_FUNC(sub_831E1EE0) {
	__imp__sub_831E1EE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E24C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lbz r11,2144(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 2144);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-31951
	r11.s64 = -2093940736;
	// addi r11,r11,10000
	r11.s64 = r11.s64 + 10000;
	// beq 0x831e24ec
	if (cr0.eq) goto loc_831E24EC;
	// lwz r11,7588(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 7588);
	// b 0x831e24f0
	goto loc_831E24F0;
loc_831E24EC:
	// lwz r11,7536(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 7536);
loc_831E24F0:
	// lis r10,-32247
	ctx.r10.s64 = -2113339392;
	// lwz r4,12(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r10,-20720
	ctx.r10.s64 = ctx.r10.s64 + -20720;
	// li r3,144
	ctx.r3.s64 = 144;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// li r11,45
	r11.s64 = 45;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r3,100(r27)
	PPC_STORE_U32(r27.u32 + 100, ctx.r3.u32);
	// stw r11,80(r3)
	PPC_STORE_U32(ctx.r3.u32 + 80, r11.u32);
	// stw r10,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, ctx.r10.u32);
	// lwz r11,96(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 96);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831e2538
	if (cr6.eq) goto loc_831E2538;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
loc_831E2538:
	// lwz r10,100(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 100);
	// stw r11,168(r10)
	PPC_STORE_U32(ctx.r10.u32 + 168, r11.u32);
	// lwz r25,168(r27)
	r25.u64 = PPC_LOAD_U32(r27.u32 + 168);
	// lwz r11,132(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 132);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stw r11,132(r25)
	PPC_STORE_U32(r25.u32 + 132, r11.u32);
	// lwz r29,84(r25)
	r29.u64 = PPC_LOAD_U32(r25.u32 + 84);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831e2794
	if (cr6.eq) goto loc_831E2794;
loc_831E255C:
	// lwz r11,132(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 132);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stw r11,132(r25)
	PPC_STORE_U32(r25.u32 + 132, r11.u32);
	// lwz r11,132(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 132);
	// rlwinm. r10,r11,31,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831e2594
	if (!cr0.eq) goto loc_831E2594;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831e2594
	if (!cr0.eq) goto loc_831E2594;
	// rlwinm. r11,r11,30,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e2594
	if (!cr0.eq) goto loc_831E2594;
	// mr r25,r29
	r25.u64 = r29.u64;
	// lwz r29,84(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 84);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x831e255c
	if (!cr6.eq) goto loc_831E255C;
loc_831E2594:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831e2794
	if (cr6.eq) goto loc_831E2794;
	// lwz r11,60(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 60);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x831e2794
	if (!cr6.eq) goto loc_831E2794;
	// lwz r11,132(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 132);
	// mr r25,r29
	r25.u64 = r29.u64;
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stw r11,132(r29)
	PPC_STORE_U32(r29.u32 + 132, r11.u32);
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// lwz r4,1456(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// lwz r3,1376(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1376);
	// bl 0x831dfd68
	sub_831DFD68(ctx, base);
	// lwz r31,36(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 36);
	// b 0x831e2644
	goto loc_831E2644;
loc_831E25D4:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e25fc
	if (!cr0.eq) goto loc_831E25FC;
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// rlwinm. r11,r11,19,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e2640
	if (cr0.eq) goto loc_831E2640;
loc_831E25FC:
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// ori r11,r11,8192
	r11.u64 = r11.u64 | 8192;
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// stw r11,228(r31)
	PPC_STORE_U32(r31.u32 + 228, r11.u32);
	// blt cr6,0x831e2640
	if (cr6.lt) goto loc_831E2640;
	// addi r11,r31,236
	r11.s64 = r31.s64 + 236;
loc_831E261C:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r8,228(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 228);
	// ori r8,r8,8192
	ctx.r8.u64 = ctx.r8.u64 | 8192;
	// stw r8,228(r9)
	PPC_STORE_U32(ctx.r9.u32 + 228, ctx.r8.u32);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// ble cr6,0x831e261c
	if (!cr6.gt) goto loc_831E261C;
loc_831E2640:
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
loc_831E2644:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831e25d4
	if (!cr6.eq) goto loc_831E25D4;
	// lwz r31,28(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// lwz r26,112(r29)
	r26.u64 = PPC_LOAD_U32(r29.u32 + 112);
	// b 0x831e26a8
	goto loc_831E26A8;
loc_831E265C:
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e26a4
	if (cr0.eq) goto loc_831E26A4;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831e26a0
	if (!cr0.eq) goto loc_831E26A0;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e26b4
	if (cr0.eq) goto loc_831E26B4;
loc_831E26A0:
	// mr r26,r31
	r26.u64 = r31.u64;
loc_831E26A4:
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
loc_831E26A8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831e265c
	if (!cr6.eq) goto loc_831E265C;
loc_831E26B4:
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// li r4,20
	ctx.r4.s64 = 20;
	// lwz r31,1456(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// addic. r30,r3,4
	xer.ca = ctx.r3.u32 > 4294967291;
	r30.s64 = ctx.r3.s64 + 4;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// beq 0x831e26e8
	if (cr0.eq) goto loc_831E26E8;
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,1456(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// bl 0x831df0d8
	sub_831DF0D8(ctx, base);
	// b 0x831e26ec
	goto loc_831E26EC;
loc_831E26E8:
	// li r30,0
	r30.s64 = 0;
loc_831E26EC:
	// lwz r31,36(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 36);
	// b 0x831e2708
	goto loc_831E2708;
loc_831E26F4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
loc_831E2708:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831e26f4
	if (!cr6.eq) goto loc_831E26F4;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831e2780
	if (cr6.eq) goto loc_831E2780;
loc_831E2724:
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r31,0(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fc910
	sub_831FC910(ctx, base);
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// rlwinm. r11,r11,19,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 19) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e2768
	if (cr0.eq) goto loc_831E2768;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x831e2750
	if (!cr6.eq) goto loc_831E2750;
	// mr r28,r31
	r28.u64 = r31.u64;
loc_831E2750:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831fc718
	sub_831FC718(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201ed0
	sub_83201ED0(ctx, base);
loc_831E2768:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831e2724
	if (!cr6.eq) goto loc_831E2724;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bne cr6,0x831e2784
	if (!cr6.eq) goto loc_831E2784;
loc_831E2780:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
loc_831E2784:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r5,100(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 100);
	// bl 0x83201ed0
	sub_83201ED0(ctx, base);
	// b 0x831e2804
	goto loc_831E2804;
loc_831E2794:
	// lwz r31,28(r25)
	r31.u64 = PPC_LOAD_U32(r25.u32 + 28);
	// b 0x831e27e4
	goto loc_831E27E4;
loc_831E279C:
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e27e0
	if (cr0.eq) goto loc_831E27E0;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831e27e0
	if (!cr0.eq) goto loc_831E27E0;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e27f4
	if (cr0.eq) goto loc_831E27F4;
loc_831E27E0:
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
loc_831E27E4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831e279c
	if (!cr6.eq) goto loc_831E279C;
	// b 0x831e2804
	goto loc_831E2804;
loc_831E27F4:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r5,100(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 100);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83201f30
	sub_83201F30(ctx, base);
loc_831E2804:
	// lwz r11,132(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 132);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stw r11,132(r25)
	PPC_STORE_U32(r25.u32 + 132, r11.u32);
	// lwz r4,104(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 104);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831e2824
	if (cr6.eq) goto loc_831E2824;
	// lwz r3,100(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 100);
	// bl 0x831df280
	sub_831DF280(ctx, base);
loc_831E2824:
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// li r4,20
	ctx.r4.s64 = 20;
	// lwz r30,1456(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// addic. r31,r3,4
	xer.ca = ctx.r3.u32 > 4294967291;
	r31.s64 = ctx.r3.s64 + 4;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
	// beq 0x831e285c
	if (cr0.eq) goto loc_831E285C;
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,1456(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// bl 0x831df0d8
	sub_831DF0D8(ctx, base);
	// mr r27,r31
	r27.u64 = r31.u64;
	// b 0x831e2860
	goto loc_831E2860;
loc_831E285C:
	// li r27,0
	r27.s64 = 0;
loc_831E2860:
	// li r29,0
	r29.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// li r30,1
	r30.s64 = 1;
loc_831E286C:
	// lwz r11,88(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 88);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r30,r10
	cr6.compare<uint32_t>(r30.u32, ctx.r10.u32, xer);
	// ble cr6,0x831e2884
	if (!cr6.gt) goto loc_831E2884;
	// li r11,0
	r11.s64 = 0;
	// b 0x831e2890
	goto loc_831E2890;
loc_831E2884:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r11,1
	r11.s64 = 1;
	// lwzx r29,r10,r31
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r31.u32);
loc_831E2890:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e2928
	if (cr0.eq) goto loc_831E2928;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,4(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// stw r29,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r29.u32);
	// b 0x831e286c
	goto loc_831E286C;
loc_831E28B4:
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r31,0(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831fc910
	sub_831FC910(ctx, base);
	// lwz r11,132(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// li r28,0
	r28.s64 = 0;
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// li r30,0
	r30.s64 = 0;
	// li r29,1
	r29.s64 = 1;
	// stw r11,132(r31)
	PPC_STORE_U32(r31.u32 + 132, r11.u32);
loc_831E28E0:
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r29,r10
	cr6.compare<uint32_t>(r29.u32, ctx.r10.u32, xer);
	// ble cr6,0x831e28f8
	if (!cr6.gt) goto loc_831E28F8;
	// li r11,0
	r11.s64 = 0;
	// b 0x831e2904
	goto loc_831E2904;
loc_831E28F8:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r11,1
	r11.s64 = 1;
	// lwzx r28,r10,r30
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
loc_831E2904:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e2928
	if (cr0.eq) goto loc_831E2928;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,4(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// stw r28,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r28.u32);
	// b 0x831e28e0
	goto loc_831E28E0;
loc_831E2928:
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831e28b4
	if (!cr6.eq) goto loc_831E28B4;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831E24C0) {
	__imp__sub_831E24C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E2940) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// addi r27,r31,128
	r27.s64 = r31.s64 + 128;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r5,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r5.u32);
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// stb r30,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r30.u8);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// stw r30,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r30.u32);
	// stw r30,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r30.u32);
	// stw r30,108(r31)
	PPC_STORE_U32(r31.u32 + 108, r30.u32);
	// stw r30,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r30.u32);
	// stw r30,116(r31)
	PPC_STORE_U32(r31.u32 + 116, r30.u32);
	// stw r30,120(r31)
	PPC_STORE_U32(r31.u32 + 120, r30.u32);
	// stb r30,124(r31)
	PPC_STORE_U8(r31.u32 + 124, r30.u8);
	// stb r30,125(r31)
	PPC_STORE_U8(r31.u32 + 125, r30.u8);
	// stb r30,126(r31)
	PPC_STORE_U8(r31.u32 + 126, r30.u8);
	// bl 0x831fc738
	sub_831FC738(ctx, base);
	// stw r30,152(r31)
	PPC_STORE_U32(r31.u32 + 152, r30.u32);
	// stw r30,156(r31)
	PPC_STORE_U32(r31.u32 + 156, r30.u32);
	// addi r3,r31,184
	ctx.r3.s64 = r31.s64 + 184;
	// stw r30,160(r31)
	PPC_STORE_U32(r31.u32 + 160, r30.u32);
	// li r5,1880
	ctx.r5.s64 = 1880;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// li r8,-1
	ctx.r8.s64 = -1;
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// stw r30,2064(r31)
	PPC_STORE_U32(r31.u32 + 2064, r30.u32);
	// stb r30,2072(r31)
	PPC_STORE_U8(r31.u32 + 2072, r30.u8);
	// li r10,16
	ctx.r10.s64 = 16;
	// stb r30,2073(r31)
	PPC_STORE_U8(r31.u32 + 2073, r30.u8);
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// stw r30,2076(r31)
	PPC_STORE_U32(r31.u32 + 2076, r30.u32);
	// stw r30,2084(r31)
	PPC_STORE_U32(r31.u32 + 2084, r30.u32);
	// stw r30,2088(r31)
	PPC_STORE_U32(r31.u32 + 2088, r30.u32);
	// stw r30,2092(r31)
	PPC_STORE_U32(r31.u32 + 2092, r30.u32);
	// stw r30,2096(r31)
	PPC_STORE_U32(r31.u32 + 2096, r30.u32);
	// stw r30,2148(r31)
	PPC_STORE_U32(r31.u32 + 2148, r30.u32);
	// stw r30,2152(r31)
	PPC_STORE_U32(r31.u32 + 2152, r30.u32);
	// stw r30,2156(r31)
	PPC_STORE_U32(r31.u32 + 2156, r30.u32);
	// stw r30,2160(r31)
	PPC_STORE_U32(r31.u32 + 2160, r30.u32);
	// stw r30,2164(r31)
	PPC_STORE_U32(r31.u32 + 2164, r30.u32);
	// stw r30,2168(r31)
	PPC_STORE_U32(r31.u32 + 2168, r30.u32);
	// stw r30,2172(r31)
	PPC_STORE_U32(r31.u32 + 2172, r30.u32);
	// stw r29,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r29.u32);
	// stw r8,2080(r31)
	PPC_STORE_U32(r31.u32 + 2080, ctx.r8.u32);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_831E2A0C:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x831e2a0c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_831E2A0C;
	// stw r31,2736(r29)
	PPC_STORE_U32(r29.u32 + 2736, r31.u32);
	// li r4,48
	ctx.r4.s64 = 48;
	// lwz r28,1452(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 1452);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r28,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r28.u32);
	// beq 0x831e2a4c
	if (cr0.eq) goto loc_831E2A4C;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x82c816e8
	sub_82C816E8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x831e2a50
	goto loc_831E2A50;
loc_831E2A4C:
	// mr r11,r30
	r11.u64 = r30.u64;
loc_831E2A50:
	// stw r11,172(r31)
	PPC_STORE_U32(r31.u32 + 172, r11.u32);
	// li r3,1024
	ctx.r3.s64 = 1024;
	// lwz r4,1452(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 1452);
	// bl 0x831dfd68
	sub_831DFD68(ctx, base);
	// stw r3,176(r31)
	PPC_STORE_U32(r31.u32 + 176, ctx.r3.u32);
	// lwz r28,1452(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 1452);
	// li r4,144
	ctx.r4.s64 = 144;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r28,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r28.u32);
	// beq 0x831e2a90
	if (cr0.eq) goto loc_831E2A90;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x83202b28
	sub_83202B28(ctx, base);
	// b 0x831e2a94
	goto loc_831E2A94;
loc_831E2A90:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_831E2A94:
	// stw r3,164(r31)
	PPC_STORE_U32(r31.u32 + 164, ctx.r3.u32);
	// li r4,140
	ctx.r4.s64 = 140;
	// lwz r28,1452(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 1452);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r28,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r28.u32);
	// beq 0x831e2ac4
	if (cr0.eq) goto loc_831E2AC4;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x83202b80
	sub_83202B80(ctx, base);
	// b 0x831e2ac8
	goto loc_831E2AC8;
loc_831E2AC4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_831E2AC8:
	// stw r3,168(r31)
	PPC_STORE_U32(r31.u32 + 168, ctx.r3.u32);
	// li r4,20
	ctx.r4.s64 = 20;
	// lwz r26,1452(r29)
	r26.u64 = PPC_LOAD_U32(r29.u32 + 1452);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// addic. r28,r3,4
	xer.ca = ctx.r3.u32 > 4294967291;
	r28.s64 = ctx.r3.s64 + 4;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// stw r26,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r26.u32);
	// beq 0x831e2af8
	if (cr0.eq) goto loc_831E2AF8;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r4,1452(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 1452);
	// bl 0x831df0d8
	sub_831DF0D8(ctx, base);
	// b 0x831e2afc
	goto loc_831E2AFC;
loc_831E2AF8:
	// mr r28,r30
	r28.u64 = r30.u64;
loc_831E2AFC:
	// stw r28,2068(r31)
	PPC_STORE_U32(r31.u32 + 2068, r28.u32);
	// li r4,20
	ctx.r4.s64 = 20;
	// lwz r26,1452(r29)
	r26.u64 = PPC_LOAD_U32(r29.u32 + 1452);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// addic. r28,r3,4
	xer.ca = ctx.r3.u32 > 4294967291;
	r28.s64 = ctx.r3.s64 + 4;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// stw r26,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r26.u32);
	// beq 0x831e2b2c
	if (cr0.eq) goto loc_831E2B2C;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r4,1452(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 1452);
	// bl 0x831df0d8
	sub_831DF0D8(ctx, base);
	// b 0x831e2b30
	goto loc_831E2B30;
loc_831E2B2C:
	// mr r28,r30
	r28.u64 = r30.u64;
loc_831E2B30:
	// stw r28,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r28.u32);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// lbz r4,1380(r29)
	ctx.r4.u64 = PPC_LOAD_U8(r29.u32 + 1380);
	// stb r4,2144(r31)
	PPC_STORE_U8(r31.u32 + 2144, ctx.r4.u8);
	// bl 0x831ee798
	sub_831EE798(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r28,164(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 164);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x831fc7c0
	sub_831FC7C0(ctx, base);
	// stw r31,16(r28)
	PPC_STORE_U32(r28.u32 + 16, r31.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r28,168(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x831fc798
	sub_831FC798(ctx, base);
	// stw r31,16(r28)
	PPC_STORE_U32(r28.u32 + 16, r31.u32);
	// lbz r11,2144(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2144);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831e2b84
	if (cr0.eq) goto loc_831E2B84;
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r11,r11,-22696
	r11.s64 = r11.s64 + -22696;
	// b 0x831e2b8c
	goto loc_831E2B8C;
loc_831E2B84:
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r11,r11,-22960
	r11.s64 = r11.s64 + -22960;
loc_831E2B8C:
	// stw r11,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r11.u32);
	// lwz r11,1360(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 1360);
	// lwz r28,4(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r4,1452(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 1452);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831dfd68
	sub_831DFD68(ctx, base);
	// stw r3,2136(r31)
	PPC_STORE_U32(r31.u32 + 2136, ctx.r3.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r4,1452(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 1452);
	// bl 0x831dfd68
	sub_831DFD68(ctx, base);
	// lwz r11,2136(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 2136);
	// stw r3,2140(r31)
	PPC_STORE_U32(r31.u32 + 2140, ctx.r3.u32);
	// li r8,-1
	ctx.r8.s64 = -1;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// ble cr6,0x831e2bec
	if (!cr6.gt) goto loc_831E2BEC;
	// addi r9,r11,8
	ctx.r9.s64 = r11.s64 + 8;
loc_831E2BD4:
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// blt cr6,0x831e2bd4
	if (cr6.lt) goto loc_831E2BD4;
loc_831E2BEC:
	// lwz r10,2140(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 2140);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x831e2c18
	if (!cr6.gt) goto loc_831E2C18;
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
loc_831E2C00:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r30,r9
	cr6.compare<uint32_t>(r30.u32, ctx.r9.u32, xer);
	// blt cr6,0x831e2c00
	if (cr6.lt) goto loc_831E2C00;
loc_831E2C18:
	// lwz r11,1360(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 1360);
	// lwz r3,1452(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 1452);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// rlwinm r4,r11,3,0,28
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// stw r3,88(r31)
	PPC_STORE_U32(r31.u32 + 88, ctx.r3.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831E2940) {
	__imp__sub_831E2940(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E2C40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,2140(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 2140);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831e2c70
	if (cr6.eq) goto loc_831E2C70;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r3,-4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// bl 0x831c59e0
	sub_831C59E0(ctx, base);
loc_831E2C70:
	// lwz r11,2136(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 2136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831e2c88
	if (cr6.eq) goto loc_831E2C88;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r3,-4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// bl 0x831c59e0
	sub_831C59E0(ctx, base);
loc_831E2C88:
	// lwz r3,2068(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 2068);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831e2c9c
	if (cr6.eq) goto loc_831E2C9C;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8320d3d0
	sub_8320D3D0(ctx, base);
loc_831E2C9C:
	// lwz r30,172(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831e2cbc
	if (cr6.eq) goto loc_831E2CBC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831f0708
	sub_831F0708(ctx, base);
	// addi r4,r30,-4
	ctx.r4.s64 = r30.s64 + -4;
	// lwz r3,-4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + -4);
	// bl 0x831c59e0
	sub_831C59E0(ctx, base);
loc_831E2CBC:
	// addi r3,r31,128
	ctx.r3.s64 = r31.s64 + 128;
	// bl 0x831fc7e0
	sub_831FC7E0(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r4,152(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 152);
	// lwz r3,1452(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// bl 0x831c59e0
	sub_831C59E0(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r4,156(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 156);
	// lwz r3,1452(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// bl 0x831c59e0
	sub_831C59E0(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r4,160(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 160);
	// lwz r3,1452(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// bl 0x831c59e0
	sub_831C59E0(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,25032
	r11.s64 = r11.s64 + 25032;
	// stw r11,140(r31)
	PPC_STORE_U32(r31.u32 + 140, r11.u32);
	// stw r11,128(r31)
	PPC_STORE_U32(r31.u32 + 128, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831E2C40) {
	__imp__sub_831E2C40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E2D20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,152(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 152);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831e2dac
	if (!cr6.eq) goto loc_831E2DAC;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r4,44
	ctx.r4.s64 = 44;
	// lwz r31,1456(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// beq 0x831e2d78
	if (cr0.eq) goto loc_831E2D78;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x832014c0
	sub_832014C0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x831e2d7c
	goto loc_831E2D7C;
loc_831E2D78:
	// li r31,0
	r31.s64 = 0;
loc_831E2D7C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,164(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 164);
	// bl 0x83201980
	sub_83201980(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,28(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x831df638
	sub_831DF638(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x832015b0
	sub_832015B0(ctx, base);
	// addi r4,r31,-4
	ctx.r4.s64 = r31.s64 + -4;
	// lwz r3,-4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + -4);
	// bl 0x831c59e0
	sub_831C59E0(ctx, base);
loc_831E2DAC:
	// lwz r3,152(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 152);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831E2D20) {
	__imp__sub_831E2D20(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E2DC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,156(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 156);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831e2e4c
	if (!cr6.eq) goto loc_831E2E4C;
	// addi r3,r31,128
	ctx.r3.s64 = r31.s64 + 128;
	// bl 0x831fc770
	sub_831FC770(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r29,r30,2,0,29
	r29.u64 = rotl64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r29,4
	ctx.r4.s64 = r29.s64 + 4;
	// lwz r3,1452(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// stw r3,156(r31)
	PPC_STORE_U32(r31.u32 + 156, ctx.r3.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e2d20
	sub_831E2D20(ctx, base);
	// lwz r11,156(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 156);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// blt cr6,0x831e2e4c
	if (cr6.lt) goto loc_831E2E4C;
	// li r9,4
	ctx.r9.s64 = 4;
	// add r10,r29,r3
	ctx.r10.u64 = r29.u64 + ctx.r3.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_831E2E30:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r7,156(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 156);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// stwx r8,r9,r7
	PPC_STORE_U32(ctx.r9.u32 + ctx.r7.u32, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x831e2e30
	if (!cr0.eq) goto loc_831E2E30;
loc_831E2E4C:
	// lwz r3,156(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 156);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E2DC8) {
	__imp__sub_831E2DC8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E2E58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831da310
	sub_831DA310(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x831e2ed8
	if (cr6.eq) goto loc_831E2ED8;
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// bne cr6,0x831e2ee0
	if (!cr6.eq) goto loc_831E2EE0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,5664
	ctx.r5.s64 = ctx.r10.s64 + 5664;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,553
	ctx.r7.s64 = 553;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
	// b 0x831e2ee0
	goto loc_831E2EE0;
loc_831E2ED8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df850
	sub_831DF850(ctx, base);
loc_831E2EE0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E2E58) {
	__imp__sub_831E2E58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E2EE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9440
	sub_831D9440(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x831e2f68
	if (cr6.eq) goto loc_831E2F68;
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// bne cr6,0x831e2fb8
	if (!cr6.eq) goto loc_831E2FB8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,5664
	ctx.r5.s64 = ctx.r10.s64 + 5664;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1013
	ctx.r7.s64 = 1013;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
	// b 0x831e2fb8
	goto loc_831E2FB8;
loc_831E2F68:
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9570
	sub_831D9570(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x831e2fb4
	if (!cr6.eq) goto loc_831E2FB4;
	// bl 0x831dfde0
	sub_831DFDE0(ctx, base);
	// b 0x831e2fb8
	goto loc_831E2FB8;
loc_831E2FB4:
	// bl 0x831dff30
	sub_831DFF30(ctx, base);
loc_831E2FB8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E2EE8) {
	__imp__sub_831E2EE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E2FC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831df808
	sub_831DF808(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// bl 0x832023c8
	sub_832023C8(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// addi r24,r11,-18548
	r24.s64 = r11.s64 + -18548;
	// addi r23,r10,24888
	r23.s64 = ctx.r10.s64 + 24888;
	// beq cr6,0x831e3050
	if (cr6.eq) goto loc_831E3050;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// addi r5,r11,25356
	ctx.r5.s64 = r11.s64 + 25356;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1083
	ctx.r7.s64 = 1083;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3050:
	// lwz r22,168(r31)
	r22.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r21,80(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,0
	r11.s64 = 0;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r10,60(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 60);
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
loc_831E306C:
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// ble cr6,0x831e307c
	if (!cr6.gt) goto loc_831E307C;
	// li r7,0
	ctx.r7.s64 = 0;
	// b 0x831e3088
	goto loc_831E3088;
loc_831E307C:
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// li r7,1
	ctx.r7.s64 = 1;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
loc_831E3088:
	// clrlwi. r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x831e30a0
	if (cr0.eq) goto loc_831E30A0;
	// mr r21,r9
	r21.u64 = ctx.r9.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// b 0x831e306c
	goto loc_831E306C;
loc_831E30A0:
	// li r3,135
	ctx.r3.s64 = 135;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r11,4
	r11.s64 = 4;
	// li r29,0
	r29.s64 = 0;
	// stw r11,168(r30)
	PPC_STORE_U32(r30.u32 + 168, r11.u32);
loc_831E30C8:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// blt cr6,0x831e30c8
	if (cr6.lt) goto loc_831E30C8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,164
	ctx.r4.s64 = 164;
	// lwz r29,1452(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// beq 0x831e3140
	if (cr0.eq) goto loc_831E3140;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83202f40
	sub_83202F40(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x831e3144
	goto loc_831E3144;
loc_831E3140:
	// li r29,0
	r29.s64 = 0;
loc_831E3144:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3170
	if (!cr0.eq) goto loc_831E3170;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// addi r5,r11,25700
	ctx.r5.s64 = r11.s64 + 25700;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1100
	ctx.r7.s64 = 1100;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3170:
	// li r3,105
	ctx.r3.s64 = 105;
	// lwz r27,144(r29)
	r27.u64 = PPC_LOAD_U32(r29.u32 + 144);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,3
	ctx.r6.s64 = 3;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831c5778
	sub_831C5778(ctx, base);
	// stw r3,172(r30)
	PPC_STORE_U32(r30.u32 + 172, ctx.r3.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// clrlwi. r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r26,r11,25680
	r26.s64 = r11.s64 + 25680;
	// bne 0x831e32b4
	if (!cr0.eq) goto loc_831E32B4;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1121
	ctx.r7.s64 = 1121;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E32B4:
	// li r3,78
	ctx.r3.s64 = 78;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r11,2
	r11.s64 = 2;
	// li r10,31
	ctx.r10.s64 = 31;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r11,56(r30)
	PPC_STORE_U32(r30.u32 + 56, r11.u32);
	// stw r10,80(r30)
	PPC_STORE_U32(r30.u32 + 80, ctx.r10.u32);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3320
	if (!cr0.eq) goto loc_831E3320;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1129
	ctx.r7.s64 = 1129;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3320:
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r3,19
	ctx.r3.s64 = 19;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r28,32(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r28,0
	r28.s64 = 0;
loc_831E33E8:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,3
	ctx.r6.s64 = 3;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,3
	ctx.r6.s64 = 3;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmpwi cr6,r28,4
	cr6.compare<int32_t>(r28.s32, 4, xer);
	// blt cr6,0x831e33e8
	if (cr6.lt) goto loc_831E33E8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3474
	if (!cr0.eq) goto loc_831E3474;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1151
	ctx.r7.s64 = 1151;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3474:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,140
	ctx.r4.s64 = 140;
	// lwz r30,1452(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// beq 0x831e34a8
	if (cr0.eq) goto loc_831E34A8;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83202060
	sub_83202060(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x831e34ac
	goto loc_831E34AC;
loc_831E34A8:
	// li r30,0
	r30.s64 = 0;
loc_831E34AC:
	// stw r30,148(r29)
	PPC_STORE_U32(r29.u32 + 148, r30.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83202840
	sub_83202840(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r28,152(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 152);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x83202840
	sub_83202840(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83202840
	sub_83202840(ctx, base);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83202d70
	sub_83202D70(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c1c
	return;
}

PPC_WEAK_FUNC(sub_831E2FC0) {
	__imp__sub_831E2FC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E3538) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r30,r11,25480
	r30.s64 = r11.s64 + 25480;
	// lwz r31,12(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lwz r3,1488(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// bl 0x831d9440
	sub_831D9440(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x831e35b8
	if (cr6.eq) goto loc_831E35B8;
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// bne cr6,0x831e3634
	if (!cr6.eq) goto loc_831E3634;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,5664
	ctx.r5.s64 = ctx.r10.s64 + 5664;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1282
	ctx.r7.s64 = 1282;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
	// b 0x831e3634
	goto loc_831E3634;
loc_831E35B8:
	// lwz r3,96(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 96);
	// li r28,0
	r28.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x831e3624
	if (!cr6.gt) goto loc_831E3624;
	// li r30,0
	r30.s64 = 0;
loc_831E35D4:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bge cr6,0x831e35ec
	if (!cr6.lt) goto loc_831E35EC;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// add r3,r11,r30
	ctx.r3.u64 = r11.u64 + r30.u64;
	// b 0x831e35f4
	goto loc_831E35F4;
loc_831E35EC:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
loc_831E35F4:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,80(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmpwi cr6,r11,23
	cr6.compare<int32_t>(r11.s32, 23, xer);
	// beq cr6,0x831e3620
	if (cr6.eq) goto loc_831E3620;
	// lwz r3,96(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 96);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpw cr6,r31,r11
	cr6.compare<int32_t>(r31.s32, r11.s32, xer);
	// blt cr6,0x831e35d4
	if (cr6.lt) goto loc_831E35D4;
	// b 0x831e3624
	goto loc_831E3624;
loc_831E3620:
	// li r28,1
	r28.s64 = 1;
loc_831E3624:
	// clrlwi. r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3634
	if (!cr0.eq) goto loc_831E3634;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831e06d0
	sub_831E06D0(ctx, base);
loc_831E3634:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831E3538) {
	__imp__sub_831E3538(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E3640) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9820
	sub_831D9820(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x831e36c0
	if (cr6.eq) goto loc_831E36C0;
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// bne cr6,0x831e36c8
	if (!cr6.eq) goto loc_831E36C8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,5664
	ctx.r5.s64 = ctx.r10.s64 + 5664;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1307
	ctx.r7.s64 = 1307;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
	// b 0x831e36c8
	goto loc_831E36C8;
loc_831E36C0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e0120
	sub_831E0120(ctx, base);
loc_831E36C8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E3640) {
	__imp__sub_831E3640(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E36D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stfd f31,-112(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -112, f31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,1488(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lis r10,-31972
	ctx.r10.s64 = -2095316992;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r29,r10,25480
	r29.s64 = ctx.r10.s64 + 25480;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// bl 0x831db8d8
	sub_831DB8D8(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r30,r11,25480
	r30.s64 = r11.s64 + 25480;
	// lwz r29,12(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// bl 0x831d9b70
	sub_831D9B70(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r30,r11,25480
	r30.s64 = r11.s64 + 25480;
	// lwz r29,12(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// bl 0x831d9c88
	sub_831D9C88(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r30,r11,25480
	r30.s64 = r11.s64 + 25480;
	// lwz r29,12(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// bl 0x831d9d98
	sub_831D9D98(ctx, base);
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// bl 0x832023c8
	sub_832023C8(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// addi r24,r11,-18548
	r24.s64 = r11.s64 + -18548;
	// addi r23,r10,24888
	r23.s64 = ctx.r10.s64 + 24888;
	// beq cr6,0x831e3824
	if (cr6.eq) goto loc_831E3824;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// addi r5,r11,25356
	ctx.r5.s64 = r11.s64 + 25356;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1505
	ctx.r7.s64 = 1505;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3824:
	// lwz r9,168(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// li r29,0
	r29.s64 = 0;
	// li r22,1
	r22.s64 = 1;
	// lwz r27,92(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// lwz r9,60(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// lwz r6,4(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
loc_831E3848:
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// ble cr6,0x831e3858
	if (!cr6.gt) goto loc_831E3858;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// b 0x831e3864
	goto loc_831E3864;
loc_831E3858:
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_831E3864:
	// clrlwi. r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x831e387c
	if (cr0.eq) goto loc_831E387C;
	// mr r27,r10
	r27.u64 = ctx.r10.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// b 0x831e3848
	goto loc_831E3848;
loc_831E387C:
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r28,r11,25480
	r28.s64 = r11.s64 + 25480;
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9eb0
	sub_831D9EB0(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// addi r25,r11,25680
	r25.s64 = r11.s64 + 25680;
	// bne 0x831e3940
	if (!cr0.eq) goto loc_831E3940;
	// li r3,105
	ctx.r3.s64 = 105;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r10,23
	ctx.r10.s64 = 23;
	// stw r29,60(r30)
	PPC_STORE_U32(r30.u32 + 60, r29.u32);
	// addi r9,r11,24848
	ctx.r9.s64 = r11.s64 + 24848;
	// stw r10,84(r30)
	PPC_STORE_U32(r30.u32 + 84, ctx.r10.u32);
	// lwz r10,24848(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24848);
	// lwz r11,-4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + -4);
	// stw r10,132(r30)
	PPC_STORE_U32(r30.u32 + 132, ctx.r10.u32);
	// stw r11,128(r30)
	PPC_STORE_U32(r30.u32 + 128, r11.u32);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831c57e0
	sub_831C57E0(ctx, base);
	// stw r3,172(r30)
	PPC_STORE_U32(r30.u32 + 172, ctx.r3.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3ea4
	if (!cr0.eq) goto loc_831E3EA4;
	// li r7,1527
	ctx.r7.s64 = 1527;
	// b 0x831e3ba8
	goto loc_831E3BA8;
loc_831E3940:
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r28,r11,25480
	r28.s64 = r11.s64 + 25480;
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// bl 0x831d9fc8
	sub_831D9FC8(ctx, base);
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r28,r11,25480
	r28.s64 = r11.s64 + 25480;
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// bl 0x831da0e0
	sub_831DA0E0(ctx, base);
	// lwz r28,12(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r20,r11,25480
	r20.s64 = r11.s64 + 25480;
	// lwz r3,1488(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// bl 0x831da1f8
	sub_831DA1F8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cmpwi cr6,r21,1
	cr6.compare<int32_t>(r21.s32, 1, xer);
	// bne cr6,0x831e3bc0
	if (!cr6.eq) goto loc_831E3BC0;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dd260
	sub_831DD260(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// addi r30,r11,25516
	r30.s64 = r11.s64 + 25516;
	// beq cr6,0x831e3a40
	if (cr6.eq) goto loc_831E3A40;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1554
	ctx.r7.s64 = 1554;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3A40:
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dd300
	sub_831DD300(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x831e3a7c
	if (cr6.eq) goto loc_831E3A7C;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1558
	ctx.r7.s64 = 1558;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3A7C:
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// li r3,18
	ctx.r3.s64 = 18;
	// fsubs f13,f0,f13
	ctx.f13.f64 = static_cast<float>(f0.f64 - ctx.f13.f64);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lfs f0,3080(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	f0.f64 = double(temp.f32);
	// fdivs f31,f0,f13
	f31.f64 = double(float(f0.f64 / ctx.f13.f64));
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lfs f4,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r10,23
	ctx.r10.s64 = 23;
	// stw r29,64(r30)
	PPC_STORE_U32(r30.u32 + 64, r29.u32);
	// stb r22,154(r30)
	PPC_STORE_U8(r30.u32 + 154, r22.u8);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r10,88(r30)
	PPC_STORE_U32(r30.u32 + 88, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,24848(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24848);
	// stw r11,136(r30)
	PPC_STORE_U32(r30.u32 + 136, r11.u32);
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3b2c
	if (!cr0.eq) goto loc_831E3B2C;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1570
	ctx.r7.s64 = 1570;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3B2C:
	// li r3,19
	ctx.r3.s64 = 19;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// stb r22,164(r30)
	PPC_STORE_U8(r30.u32 + 164, r22.u8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3ea4
	if (!cr0.eq) goto loc_831E3EA4;
	// li r7,1579
	ctx.r7.s64 = 1579;
loc_831E3BA8:
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
	// b 0x831e3ea4
	goto loc_831E3EA4;
loc_831E3BC0:
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// beq cr6,0x831e3bd0
	if (cr6.eq) goto loc_831E3BD0;
	// cmpwi cr6,r28,1
	cr6.compare<int32_t>(r28.s32, 1, xer);
	// bne cr6,0x831e3ea0
	if (!cr6.eq) goto loc_831E3EA0;
loc_831E3BD0:
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dd3a0
	sub_831DD3A0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x831e3c10
	if (cr6.eq) goto loc_831E3C10;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// addi r5,r11,25516
	ctx.r5.s64 = r11.s64 + 25516;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1588
	ctx.r7.s64 = 1588;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3C10:
	// li r3,19
	ctx.r3.s64 = 19;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r10,23
	ctx.r10.s64 = 23;
	// stw r29,60(r30)
	PPC_STORE_U32(r30.u32 + 60, r29.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r10,84(r30)
	PPC_STORE_U32(r30.u32 + 84, ctx.r10.u32);
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r11,24848(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24848);
	// stw r11,132(r30)
	PPC_STORE_U32(r30.u32 + 132, r11.u32);
	// lfs f4,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3ca4
	if (!cr0.eq) goto loc_831E3CA4;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1596
	ctx.r7.s64 = 1596;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3CA4:
	// cmpwi cr6,r28,1
	cr6.compare<int32_t>(r28.s32, 1, xer);
	// bne cr6,0x831e3d28
	if (!cr6.eq) goto loc_831E3D28;
	// li r3,19
	ctx.r3.s64 = 19;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3d28
	if (!cr0.eq) goto loc_831E3D28;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1605
	ctx.r7.s64 = 1605;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3D28:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lfd f1,25744(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 25744);
	// bl 0x821f3c80
	sub_821F3C80(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// lfd f1,3552(r11)
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 3552);
	// bl 0x821f3c80
	sub_821F3C80(ctx, base);
	// fdiv f0,f31,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = f31.f64 / ctx.f1.f64;
	// li r3,19
	ctx.r3.s64 = 19;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// frsp f31,f0
	f31.f64 = double(float(f0.f64));
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3dd8
	if (!cr0.eq) goto loc_831E3DD8;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1634
	ctx.r7.s64 = 1634;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3DD8:
	// li r3,55
	ctx.r3.s64 = 55;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3e44
	if (!cr0.eq) goto loc_831E3E44;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1642
	ctx.r7.s64 = 1642;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3E44:
	// li r3,64
	ctx.r3.s64 = 64;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3ea4
	if (!cr0.eq) goto loc_831E3EA4;
	// li r7,1649
	ctx.r7.s64 = 1649;
	// b 0x831e3ba8
	goto loc_831E3BA8;
loc_831E3EA0:
	// lwz r30,92(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
loc_831E3EA4:
	// lwz r28,12(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r27,r11,25480
	r27.s64 = r11.s64 + 25480;
	// lwz r3,1488(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// bl 0x831d9570
	sub_831D9570(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x831e3fd4
	if (!cr6.eq) goto loc_831E3FD4;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,964
	ctx.r4.s64 = 964;
	// lwz r10,108(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r22,1452(r11)
	r22.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// lwz r27,28(r10)
	r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// lwz r28,32(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
	// beq 0x831e3f20
	if (cr0.eq) goto loc_831E3F20;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x832007a8
	sub_832007A8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
loc_831E3F20:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r4,108(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// bl 0x831fd6c8
	sub_831FD6C8(ctx, base);
	// lwz r3,108(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// bl 0x831ff7a0
	sub_831FF7A0(ctx, base);
	// lwz r3,108(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,96(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e3fbc
	if (!cr0.eq) goto loc_831E3FBC;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1672
	ctx.r7.s64 = 1672;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E3FBC:
	// stw r29,108(r31)
	PPC_STORE_U32(r31.u32 + 108, r29.u32);
	// lwz r3,96(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// lwz r4,4(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// bl 0x831fc9d0
	sub_831FC9D0(ctx, base);
	// stw r29,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r29.u32);
	// b 0x831e41d0
	goto loc_831E41D0;
loc_831E3FD4:
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc7b8
	sub_831DC7B8(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc858
	sub_831DC858(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc8f8
	sub_831DC8F8(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc998
	sub_831DC998(ctx, base);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r3,18
	ctx.r3.s64 = 18;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r30,32(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bl 0x83200d28
	sub_83200D28(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// lfs f4,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lfs f3,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stb r22,154(r29)
	PPC_STORE_U8(r29.u32 + 154, r22.u8);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r3,948(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 948);
	// bl 0x83201f30
	sub_83201F30(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e4108
	if (!cr0.eq) goto loc_831E4108;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// addi r5,r11,25340
	ctx.r5.s64 = r11.s64 + 25340;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1706
	ctx.r7.s64 = 1706;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E4108:
	// li r3,20
	ctx.r3.s64 = 20;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83200d98
	sub_83200D98(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// lfs f4,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lfs f3,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r3,948(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 948);
	// bl 0x83201f30
	sub_83201F30(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e41d0
	if (!cr0.eq) goto loc_831E41D0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// addi r5,r11,25720
	ctx.r5.s64 = r11.s64 + 25720;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// li r7,1720
	ctx.r7.s64 = 1720;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E41D0:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lfd f31,-112(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// b 0x82ca2c18
	return;
}

PPC_WEAK_FUNC(sub_831E36D0) {
	__imp__sub_831E36D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E41E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc0
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831df808
	sub_831DF808(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// bl 0x832023c8
	sub_832023C8(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// addi r22,r11,-18548
	r22.s64 = r11.s64 + -18548;
	// addi r21,r10,24888
	r21.s64 = ctx.r10.s64 + 24888;
	// beq cr6,0x831e4274
	if (cr6.eq) goto loc_831E4274;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// addi r5,r11,25356
	ctx.r5.s64 = r11.s64 + 25356;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// li r7,1765
	ctx.r7.s64 = 1765;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E4274:
	// lwz r18,168(r31)
	r18.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// li r24,1
	r24.s64 = 1;
	// lwz r19,80(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// lwz r10,60(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 60);
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
loc_831E4294:
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// ble cr6,0x831e42a4
	if (!cr6.gt) goto loc_831E42A4;
	// li r7,0
	ctx.r7.s64 = 0;
	// b 0x831e42b0
	goto loc_831E42B0;
loc_831E42A4:
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
loc_831E42B0:
	// clrlwi. r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x831e42c8
	if (cr0.eq) goto loc_831E42C8;
	// mr r19,r9
	r19.u64 = ctx.r9.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// b 0x831e4294
	goto loc_831E4294;
loc_831E42C8:
	// li r3,64
	ctx.r3.s64 = 64;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stb r24,164(r30)
	PPC_STORE_U8(r30.u32 + 164, r24.u8);
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,24836(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24836);
	// stw r11,128(r30)
	PPC_STORE_U32(r30.u32 + 128, r11.u32);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r29,0
	r29.s64 = 0;
loc_831E4308:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// blt cr6,0x831e4308
	if (cr6.lt) goto loc_831E4308;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// clrlwi. r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r25,r11,25680
	r25.s64 = r11.s64 + 25680;
	// bne 0x831e437c
	if (!cr0.eq) goto loc_831E437C;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// li r7,1783
	ctx.r7.s64 = 1783;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E437C:
	// li r3,135
	ctx.r3.s64 = 135;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// li r4,164
	ctx.r4.s64 = 164;
	// stw r11,168(r30)
	PPC_STORE_U32(r30.u32 + 168, r11.u32);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r29,1452(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// beq 0x831e43e0
	if (cr0.eq) goto loc_831E43E0;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83202f40
	sub_83202F40(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x831e43e4
	goto loc_831E43E4;
loc_831E43E0:
	// li r27,0
	r27.s64 = 0;
loc_831E43E4:
	// li r29,0
	r29.s64 = 0;
loc_831E43E8:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// blt cr6,0x831e43e8
	if (cr6.lt) goto loc_831E43E8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e444c
	if (!cr0.eq) goto loc_831E444C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// addi r5,r11,25752
	ctx.r5.s64 = r11.s64 + 25752;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// li r7,1794
	ctx.r7.s64 = 1794;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E444C:
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r28,144(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + 144);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stb r24,159(r30)
	PPC_STORE_U8(r30.u32 + 159, r24.u8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,3
	ctx.r6.s64 = 3;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e4580
	if (!cr0.eq) goto loc_831E4580;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// li r7,1810
	ctx.r7.s64 = 1810;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E4580:
	// li r3,105
	ctx.r3.s64 = 105;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831c5848
	sub_831C5848(ctx, base);
	// stw r3,172(r30)
	PPC_STORE_U32(r30.u32 + 172, ctx.r3.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e4678
	if (!cr0.eq) goto loc_831E4678;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// li r7,1825
	ctx.r7.s64 = 1825;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E4678:
	// li r3,78
	ctx.r3.s64 = 78;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r11,2
	r11.s64 = 2;
	// li r10,31
	ctx.r10.s64 = 31;
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r11,56(r30)
	PPC_STORE_U32(r30.u32 + 56, r11.u32);
	// stw r10,80(r30)
	PPC_STORE_U32(r30.u32 + 80, ctx.r10.u32);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e46e4
	if (!cr0.eq) goto loc_831E46E4;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// li r7,1833
	ctx.r7.s64 = 1833;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E46E4:
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r3,19
	ctx.r3.s64 = 19;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r29,32(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r29,0
	r29.s64 = 0;
loc_831E47AC:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,3
	ctx.r6.s64 = 3;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,3
	ctx.r6.s64 = 3;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// blt cr6,0x831e47ac
	if (cr6.lt) goto loc_831E47AC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e4838
	if (!cr0.eq) goto loc_831E4838;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// li r7,1856
	ctx.r7.s64 = 1856;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E4838:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,140
	ctx.r4.s64 = 140;
	// lwz r30,1452(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// beq 0x831e486c
	if (cr0.eq) goto loc_831E486C;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83202060
	sub_83202060(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x831e4870
	goto loc_831E4870;
loc_831E486C:
	// li r30,0
	r30.s64 = 0;
loc_831E4870:
	// stw r30,148(r27)
	PPC_STORE_U32(r27.u32 + 148, r30.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83202840
	sub_83202840(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r29,152(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 152);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x83202840
	sub_83202840(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83202840
	sub_83202840(ctx, base);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83202d70
	sub_83202D70(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c10
	return;
}

PPC_WEAK_FUNC(sub_831E41E0) {
	__imp__sub_831E41E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E48F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831df808
	sub_831DF808(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r26,1
	r26.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// stb r26,2073(r31)
	PPC_STORE_U8(r31.u32 + 2073, r26.u8);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,1508(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1508);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// addi r5,r11,-1
	ctx.r5.s64 = r11.s64 + -1;
	// stw r5,1508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1508, ctx.r5.u32);
	// lwz r3,172(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r3,168(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// bl 0x832023c8
	sub_832023C8(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// addi r23,r11,-18548
	r23.s64 = r11.s64 + -18548;
	// addi r22,r10,24888
	r22.s64 = ctx.r10.s64 + 24888;
	// beq cr6,0x831e4994
	if (cr6.eq) goto loc_831E4994;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25356
	ctx.r5.s64 = r11.s64 + 25356;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2205
	ctx.r7.s64 = 2205;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E4994:
	// lwz r19,168(r31)
	r19.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r21,84(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r11,0
	r11.s64 = 0;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// lwz r10,60(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 60);
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
loc_831E49B0:
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// ble cr6,0x831e49c0
	if (!cr6.gt) goto loc_831E49C0;
	// li r7,0
	ctx.r7.s64 = 0;
	// b 0x831e49cc
	goto loc_831E49CC;
loc_831E49C0:
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
loc_831E49CC:
	// clrlwi. r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x831e49e4
	if (cr0.eq) goto loc_831E49E4;
	// mr r21,r9
	r21.u64 = ctx.r9.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// b 0x831e49b0
	goto loc_831E49B0;
loc_831E49E4:
	// li r3,64
	ctx.r3.s64 = 64;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r29,0
	r29.s64 = 0;
loc_831E4A94:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// blt cr6,0x831e4a94
	if (cr6.lt) goto loc_831E4A94;
	// stb r26,164(r30)
	PPC_STORE_U8(r30.u32 + 164, r26.u8);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e4b08
	if (!cr0.eq) goto loc_831E4B08;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25836
	ctx.r5.s64 = r11.s64 + 25836;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2226
	ctx.r7.s64 = 2226;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E4B08:
	// li r3,36
	ctx.r3.s64 = 36;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r29,0
	r29.s64 = 0;
loc_831E4BD8:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// blt cr6,0x831e4bd8
	if (cr6.lt) goto loc_831E4BD8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e4c88
	if (!cr0.eq) goto loc_831E4C88;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25816
	ctx.r5.s64 = r11.s64 + 25816;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2245
	ctx.r7.s64 = 2245;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E4C88:
	// li r3,135
	ctx.r3.s64 = 135;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// li r24,2
	r24.s64 = 2;
	// li r4,164
	ctx.r4.s64 = 164;
	// stw r24,168(r30)
	PPC_STORE_U32(r30.u32 + 168, r24.u32);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r29,1452(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// beq 0x831e4cec
	if (cr0.eq) goto loc_831E4CEC;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83202f40
	sub_83202F40(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x831e4cf0
	goto loc_831E4CF0;
loc_831E4CEC:
	// li r27,0
	r27.s64 = 0;
loc_831E4CF0:
	// li r29,0
	r29.s64 = 0;
loc_831E4CF4:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// blt cr6,0x831e4cf4
	if (cr6.lt) goto loc_831E4CF4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e4d58
	if (!cr0.eq) goto loc_831E4D58;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25700
	ctx.r5.s64 = r11.s64 + 25700;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2256
	ctx.r7.s64 = 2256;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E4D58:
	// li r3,49
	ctx.r3.s64 = 49;
	// lwz r29,144(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 144);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// stb r26,159(r30)
	PPC_STORE_U8(r30.u32 + 159, r26.u8);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e4dd0
	if (!cr0.eq) goto loc_831E4DD0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25264
	ctx.r5.s64 = r11.s64 + 25264;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2266
	ctx.r7.s64 = 2266;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E4DD0:
	// li r3,18
	ctx.r3.s64 = 18;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// stb r26,153(r30)
	PPC_STORE_U8(r30.u32 + 153, r26.u8);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc698
	sub_831DC698(ctx, base);
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r6,r11,25480
	ctx.r6.s64 = r11.s64 + 25480;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831dc6b0
	sub_831DC6B0(ctx, base);
	// lfs f4,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f3.f64 = double(temp.f32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f1,f3
	ctx.f1.f64 = ctx.f3.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e4f1c
	if (!cr0.eq) goto loc_831E4F1C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25340
	ctx.r5.s64 = r11.s64 + 25340;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2291
	ctx.r7.s64 = 2291;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E4F1C:
	// li r3,19
	ctx.r3.s64 = 19;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// stb r26,159(r30)
	PPC_STORE_U8(r30.u32 + 159, r26.u8);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lfs f4,3144(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3144);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831ffe70
	sub_831FFE70(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e5034
	if (!cr0.eq) goto loc_831E5034;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25324
	ctx.r5.s64 = r11.s64 + 25324;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2305
	ctx.r7.s64 = 2305;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E5034:
	// li r3,105
	ctx.r3.s64 = 105;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831c5978
	sub_831C5978(ctx, base);
	// stw r3,172(r30)
	PPC_STORE_U32(r30.u32 + 172, ctx.r3.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e5130
	if (!cr0.eq) goto loc_831E5130;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25796
	ctx.r5.s64 = r11.s64 + 25796;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2318
	ctx.r7.s64 = 2318;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E5130:
	// li r3,78
	ctx.r3.s64 = 78;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x831fede8
	sub_831FEDE8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r11,31
	r11.s64 = 31;
	// li r28,0
	r28.s64 = 0;
	// stw r24,56(r30)
	PPC_STORE_U32(r30.u32 + 56, r24.u32);
	// stw r11,80(r30)
	PPC_STORE_U32(r30.u32 + 80, r11.u32);
loc_831E5150:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmpwi cr6,r28,4
	cr6.compare<int32_t>(r28.s32, 4, xer);
	// blt cr6,0x831e5150
	if (cr6.lt) goto loc_831E5150;
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df980
	sub_831DF980(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83201e40
	sub_83201E40(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831fee78
	sub_831FEE78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e51d0
	if (!cr0.eq) goto loc_831E51D0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r5,r11,25776
	ctx.r5.s64 = r11.s64 + 25776;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r7,2329
	ctx.r7.s64 = 2329;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E51D0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,140
	ctx.r4.s64 = 140;
	// lwz r30,1452(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// beq 0x831e5204
	if (cr0.eq) goto loc_831E5204;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83202060
	sub_83202060(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x831e5208
	goto loc_831E5208;
loc_831E5204:
	// li r30,0
	r30.s64 = 0;
loc_831E5208:
	// stw r30,148(r27)
	PPC_STORE_U32(r27.u32 + 148, r30.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83202840
	sub_83202840(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r28,152(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + 152);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x83202840
	sub_83202840(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83202840
	sub_83202840(ctx, base);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83202d70
	sub_83202D70(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df030
	sub_831DF030(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	return;
}

PPC_WEAK_FUNC(sub_831E48F8) {
	__imp__sub_831E48F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5290) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9328
	sub_831D9328(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x831e5310
	if (cr6.eq) goto loc_831E5310;
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// bne cr6,0x831e5318
	if (!cr6.eq) goto loc_831E5318;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,5664
	ctx.r5.s64 = ctx.r10.s64 + 5664;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2453
	ctx.r7.s64 = 2453;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
	// b 0x831e5318
	goto loc_831E5318;
loc_831E5310:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e1580
	sub_831E1580(ctx, base);
loc_831E5318:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E5290) {
	__imp__sub_831E5290(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5320) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831e2dc8
	sub_831E2DC8(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r27,r31,128
	r27.s64 = r31.s64 + 128;
loc_831E533C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// li r30,0
	r30.s64 = 0;
	// li r29,1
	r29.s64 = 1;
	// bl 0x831fc770
	sub_831FC770(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// blt cr6,0x831e53fc
	if (cr6.lt) goto loc_831E53FC;
	// addi r28,r26,4
	r28.s64 = r26.s64 + 4;
loc_831E5358:
	// lwz r31,0(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e53e4
	if (!cr0.eq) goto loc_831E53E4;
	// lwz r7,56(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r6,132(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// li r11,0
	r11.s64 = 0;
	// li r9,1
	ctx.r9.s64 = 1;
loc_831E538C:
	// lwz r8,4(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// ble cr6,0x831e53a0
	if (!cr6.gt) goto loc_831E53A0;
	// li r8,0
	ctx.r8.s64 = 0;
	// b 0x831e53ac
	goto loc_831E53AC;
loc_831E53A0:
	// lwz r10,8(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// li r8,1
	ctx.r8.s64 = 1;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_831E53AC:
	// clrlwi. r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x831e53d0
	if (cr0.eq) goto loc_831E53D0;
	// lwz r8,132(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 132);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r5,132(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// or r8,r8,r5
	ctx.r8.u64 = ctx.r8.u64 | ctx.r5.u64;
	// stw r8,132(r31)
	PPC_STORE_U32(r31.u32 + 132, ctx.r8.u32);
	// b 0x831e538c
	goto loc_831E538C;
loc_831E53D0:
	// lwz r11,132(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// subf r11,r11,r6
	r11.s64 = ctx.r6.s64 - r11.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r30,r11,1
	r30.u64 = r11.u64 ^ 1;
loc_831E53E4:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// bl 0x831fc770
	sub_831FC770(ctx, base);
	// cmpw cr6,r29,r3
	cr6.compare<int32_t>(r29.s32, ctx.r3.s32, xer);
	// ble cr6,0x831e5358
	if (!cr6.gt) goto loc_831E5358;
loc_831E53FC:
	// clrlwi. r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831e533c
	if (!cr0.eq) goto loc_831E533C;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831E5320) {
	__imp__sub_831E5320(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5410) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// lwz r16,136(r21)
	r16.u64 = PPC_LOAD_U32(r21.u32 + 136);
	// lwz r11,8(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831e5904
	if (cr6.eq) goto loc_831E5904;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// lis r8,-32248
	ctx.r8.s64 = -2113404928;
	// lis r7,-32248
	ctx.r7.s64 = -2113404928;
	// addi r10,r10,25896
	ctx.r10.s64 = ctx.r10.s64 + 25896;
	// lis r17,-32248
	r17.s64 = -2113404928;
	// li r22,0
	r22.s64 = 0;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// li r20,1
	r20.s64 = 1;
	// addi r14,r11,25872
	r14.s64 = r11.s64 + 25872;
	// addi r19,r9,-18548
	r19.s64 = ctx.r9.s64 + -18548;
	// addi r15,r8,25856
	r15.s64 = ctx.r8.s64 + 25856;
	// addi r18,r7,24888
	r18.s64 = ctx.r7.s64 + 24888;
loc_831E5468:
	// lwz r31,28(r16)
	r31.u64 = PPC_LOAD_U32(r16.u32 + 28);
	// mr r25,r22
	r25.u64 = r22.u64;
	// mr r24,r22
	r24.u64 = r22.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831e58f4
	if (cr6.eq) goto loc_831E58F4;
loc_831E5480:
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e5648
	if (cr0.eq) goto loc_831E5648;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r28,84(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e5648
	if (cr0.eq) goto loc_831E5648;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e5648
	if (cr0.eq) goto loc_831E5648;
	// cmpwi cr6,r28,30
	cr6.compare<int32_t>(r28.s32, 30, xer);
	// beq cr6,0x831e54e8
	if (cr6.eq) goto loc_831E54E8;
	// cmpwi cr6,r28,12
	cr6.compare<int32_t>(r28.s32, 12, xer);
	// beq cr6,0x831e54e8
	if (cr6.eq) goto loc_831E54E8;
	// cmpwi cr6,r28,13
	cr6.compare<int32_t>(r28.s32, 13, xer);
	// beq cr6,0x831e54e8
	if (cr6.eq) goto loc_831E54E8;
	// cmpwi cr6,r28,14
	cr6.compare<int32_t>(r28.s32, 14, xer);
	// bne cr6,0x831e5648
	if (!cr6.eq) goto loc_831E5648;
loc_831E54E8:
	// lwz r11,12(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// li r4,24
	ctx.r4.s64 = 24;
	// lwz r29,1456(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// addi r30,r3,4
	r30.s64 = ctx.r3.s64 + 4;
	// stw r29,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r29.u32);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r24,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r24.u32);
	// mr r24,r30
	r24.u64 = r30.u64;
	// stw r31,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r31.u32);
	// stb r20,176(r31)
	PPC_STORE_U8(r31.u32 + 176, r20.u8);
	// lwz r29,132(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// bl 0x831ffad0
	sub_831FFAD0(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// ble cr6,0x831e5560
	if (!cr6.gt) goto loc_831E5560;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// li r7,3304
	ctx.r7.s64 = 3304;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E5560:
	// mr r11,r25
	r11.u64 = r25.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831e55a8
	if (cr6.eq) goto loc_831E55A8;
loc_831E556C:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x831e5594
	if (!cr6.eq) goto loc_831E5594;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpw cr6,r10,r28
	cr6.compare<int32_t>(ctx.r10.s32, r28.s32, xer);
	// bne cr6,0x831e5594
	if (!cr6.eq) goto loc_831E5594;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// beq cr6,0x831e55a0
	if (cr6.eq) goto loc_831E55A0;
loc_831E5594:
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831e556c
	if (!cr6.eq) goto loc_831E556C;
loc_831E55A0:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831e5600
	if (!cr6.eq) goto loc_831E5600;
loc_831E55A8:
	// lwz r11,12(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// li r4,52
	ctx.r4.s64 = 52;
	// lwz r27,1456(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// stw r27,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r27.u32);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r11,r3,4
	r11.s64 = ctx.r3.s64 + 4;
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r28,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r28.u32);
	// stw r29,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r29.u32);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r10,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r10.u32);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r25,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r25.u32);
	// mr r25,r11
	r25.u64 = r11.u64;
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r31.u32);
	// stw r20,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r20.u32);
	// stw r10,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r10.u32);
	// b 0x831e5644
	goto loc_831E5644;
loc_831E5600:
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r9,r10
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, xer);
	// bge cr6,0x831e561c
	if (!cr6.lt) goto loc_831E561C;
	// stw r31,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r31.u32);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
loc_831E561C:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmpw cr6,r10,r8
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r8.s32, xer);
	// ble cr6,0x831e5638
	if (!cr6.gt) goto loc_831E5638;
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
loc_831E5638:
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
loc_831E5644:
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_831E5648:
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831e5480
	if (!cr6.eq) goto loc_831E5480;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831e58f4
	if (cr6.eq) goto loc_831E58F4;
loc_831E5660:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x831e5680
	if (!cr6.eq) goto loc_831E5680;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// lwz r5,92(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// li r7,3348
	ctx.r7.s64 = 3348;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E5680:
	// li r5,3
	ctx.r5.s64 = 3;
	// lwz r3,172(r21)
	ctx.r3.u64 = PPC_LOAD_U32(r21.u32 + 172);
	// li r4,31
	ctx.r4.s64 = 31;
	// mr r23,r22
	r23.u64 = r22.u64;
	// bl 0x831eeac8
	sub_831EEAC8(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// b 0x831e57e0
	goto loc_831E57E0;
loc_831E569C:
	// mr r31,r25
	r31.u64 = r25.u64;
	// addi r27,r25,44
	r27.s64 = r25.s64 + 44;
	// lwz r25,44(r25)
	r25.u64 = PPC_LOAD_U32(r25.u32 + 44);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r22,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r22.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x831e56d0
	if (cr6.gt) goto loc_831E56D0;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// li r7,3359
	ctx.r7.s64 = 3359;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E56D0:
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r3,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r3.u32);
	// lwz r29,28(r3)
	r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// lwz r28,128(r3)
	r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// lwz r11,24828(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 24828);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// stw r11,128(r10)
	PPC_STORE_U32(ctx.r10.u32 + 128, r11.u32);
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// bl 0x831fd320
	sub_831FD320(ctx, base);
	// lwz r11,12(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// lwz r30,1452(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 1452);
	// li r4,964
	ctx.r4.s64 = 964;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831c58b0
	sub_831C58B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addic. r3,r11,4
	xer.ca = r11.u32 > 4294967291;
	ctx.r3.s64 = r11.s64 + 4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// beq 0x831e573c
	if (cr0.eq) goto loc_831E573C;
	// li r4,128
	ctx.r4.s64 = 128;
	// lwz r5,12(r21)
	ctx.r5.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// bl 0x83200408
	sub_83200408(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x831e5740
	goto loc_831E5740;
loc_831E573C:
	// mr r30,r22
	r30.u64 = r22.u64;
loc_831E5740:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// stw r28,128(r30)
	PPC_STORE_U32(r30.u32 + 128, r28.u32);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831ff250
	sub_831FF250(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831fd320
	sub_831FD320(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831fd370
	sub_831FD370(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// bl 0x83201ed0
	sub_83201ED0(ctx, base);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// stw r30,180(r11)
	PPC_STORE_U32(r11.u32 + 180, r30.u32);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// stw r22,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r22.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// stw r22,184(r10)
	PPC_STORE_U32(ctx.r10.u32 + 184, r22.u32);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// subf r10,r10,r11
	ctx.r10.s64 = r11.s64 - ctx.r10.s64;
	// cmpwi cr6,r10,8
	cr6.compare<int32_t>(ctx.r10.s32, 8, xer);
	// ble cr6,0x831e57e0
	if (!cr6.gt) goto loc_831E57E0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r23,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r23.u32);
	// stw r22,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r22.u32);
	// mr r23,r31
	r23.u64 = r31.u64;
	// stw r22,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r22.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r22,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r22.u32);
loc_831E57E0:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x831e569c
	if (!cr6.eq) goto loc_831E569C;
	// mr r29,r22
	r29.u64 = r22.u64;
	// b 0x831e58dc
	goto loc_831E58DC;
loc_831E57F0:
	// addi r6,r24,16
	ctx.r6.s64 = r24.s64 + 16;
	// lwz r31,0(r24)
	r31.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// mr r30,r24
	r30.u64 = r24.u64;
	// lwz r24,16(r24)
	r24.u64 = PPC_LOAD_U32(r24.u32 + 16);
	// stw r22,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r22.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r7,12(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r8,4(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r9,28(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// add r11,r11,r7
	r11.u64 = r11.u64 + ctx.r7.u64;
	// beq cr6,0x831e58c8
	if (cr6.eq) goto loc_831E58C8;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bgt cr6,0x831e587c
	if (cr6.gt) goto loc_831E587C;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// bge cr6,0x831e5844
	if (!cr6.lt) goto loc_831E5844;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// stw r11,184(r9)
	PPC_STORE_U32(ctx.r9.u32 + 184, r11.u32);
loc_831E5844:
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x831fc718
	sub_831FC718(ctx, base);
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x831fc6f8
	sub_831FC6F8(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x831ffdc0
	sub_831FFDC0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x831fd370
	sub_831FD370(ctx, base);
	// b 0x831e58dc
	goto loc_831E58DC;
loc_831E587C:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// bge cr6,0x831e5894
	if (!cr6.lt) goto loc_831E5894;
	// stw r8,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r8.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
loc_831E5894:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// ble cr6,0x831e58b0
	if (!cr6.gt) goto loc_831E58B0;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
loc_831E58B0:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// stw r29,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r29.u32);
	// mr r29,r30
	r29.u64 = r30.u64;
	// b 0x831e58dc
	goto loc_831E58DC;
loc_831E58C8:
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// bge cr6,0x831e58dc
	if (!cr6.lt) goto loc_831E58DC;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// stw r11,184(r9)
	PPC_STORE_U32(ctx.r9.u32 + 184, r11.u32);
loc_831E58DC:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x831e57f0
	if (!cr6.eq) goto loc_831E57F0;
	// mr r25,r23
	r25.u64 = r23.u64;
	// mr r24,r29
	r24.u64 = r29.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// bne cr6,0x831e5660
	if (!cr6.eq) goto loc_831E5660;
loc_831E58F4:
	// lwz r16,8(r16)
	r16.u64 = PPC_LOAD_U32(r16.u32 + 8);
	// lwz r11,8(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831e5468
	if (!cr6.eq) goto loc_831E5468;
loc_831E5904:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82ca2c00
	return;
}

PPC_WEAK_FUNC(sub_831E5410) {
	__imp__sub_831E5410(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5910) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9950
	sub_831D9950(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x831e5990
	if (cr6.eq) goto loc_831E5990;
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// bne cr6,0x831e5998
	if (!cr6.eq) goto loc_831E5998;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,5664
	ctx.r5.s64 = ctx.r10.s64 + 5664;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1054
	ctx.r7.s64 = 1054;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
	// b 0x831e5998
	goto loc_831E5998;
loc_831E5990:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e2fc0
	sub_831E2FC0(ctx, base);
loc_831E5998:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E5910) {
	__imp__sub_831E5910(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E59A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9820
	sub_831D9820(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x831e5a20
	if (cr6.eq) goto loc_831E5A20;
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// bne cr6,0x831e5a28
	if (!cr6.eq) goto loc_831E5A28;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,5664
	ctx.r5.s64 = ctx.r10.s64 + 5664;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1465
	ctx.r7.s64 = 1465;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
	// b 0x831e5a28
	goto loc_831E5A28;
loc_831E5A20:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e36d0
	sub_831E36D0(ctx, base);
loc_831E5A28:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E59A0) {
	__imp__sub_831E59A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5A30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831d9a60
	sub_831D9A60(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x831e5ab0
	if (cr6.eq) goto loc_831E5AB0;
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// bne cr6,0x831e5ab8
	if (!cr6.eq) goto loc_831E5AB8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,5664
	ctx.r5.s64 = ctx.r10.s64 + 5664;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,1741
	ctx.r7.s64 = 1741;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
	// b 0x831e5ab8
	goto loc_831E5AB8;
loc_831E5AB0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e41e0
	sub_831E41E0(ctx, base);
loc_831E5AB8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E5A30) {
	__imp__sub_831E5A30(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5AC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31972
	r11.s64 = -2095316992;
	// addi r29,r11,25480
	r29.s64 = r11.s64 + 25480;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,1488(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1488);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x831da7a0
	sub_831DA7A0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x831e5b40
	if (cr6.eq) goto loc_831E5B40;
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// bne cr6,0x831e5b48
	if (!cr6.eq) goto loc_831E5B48;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,5664
	ctx.r5.s64 = ctx.r10.s64 + 5664;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,2182
	ctx.r7.s64 = 2182;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
	// b 0x831e5b48
	goto loc_831E5B48;
loc_831E5B40:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e48f8
	sub_831E48F8(ctx, base);
loc_831E5B48:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E5AC0) {
	__imp__sub_831E5AC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5B50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831e5320
	sub_831E5320(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e24c0
	sub_831E24C0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e1d98
	sub_831E1D98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e1ee0
	sub_831E1EE0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831E5B50) {
	__imp__sub_831E5B50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5B98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831e5910
	sub_831E5910(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e5a30
	sub_831E5A30(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e5ac0
	sub_831E5AC0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e2ee8
	sub_831E2EE8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e59a0
	sub_831E59A0(ctx, base);
	// lwz r8,2068(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 2068);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
loc_831E5BE0:
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// ble cr6,0x831e5bf4
	if (!cr6.gt) goto loc_831E5BF4;
	// li r11,0
	r11.s64 = 0;
	// b 0x831e5c00
	goto loc_831E5C00;
loc_831E5BF4:
	// lwz r10,8(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// li r11,1
	r11.s64 = 1;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
loc_831E5C00:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e5c40
	if (cr0.eq) goto loc_831E5C40;
	// lwz r11,228(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 228);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e5c34
	if (cr0.eq) goto loc_831E5C34;
	// lwz r11,80(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x831e5c34
	if (!cr6.eq) goto loc_831E5C34;
	// lwz r11,56(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// lwz r6,2096(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 2096);
	// cmpw cr6,r11,r6
	cr6.compare<int32_t>(r11.s32, ctx.r6.s32, xer);
	// ble cr6,0x831e5c34
	if (!cr6.gt) goto loc_831E5C34;
	// stw r11,2096(r31)
	PPC_STORE_U32(r31.u32 + 2096, r11.u32);
loc_831E5C34:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// b 0x831e5be0
	goto loc_831E5BE0;
loc_831E5C40:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831E5B98) {
	__imp__sub_831E5B98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5C58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x83205f58
	sub_83205F58(ctx, base);
	// lbz r11,2144(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2144);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831e5cf0
	if (cr0.eq) goto loc_831E5CF0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lbz r11,2028(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 2028);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831e5c9c
	if (cr0.eq) goto loc_831E5C9C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e1c20
	sub_831E1C20(ctx, base);
loc_831E5C9C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e3538
	sub_831E3538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e3640
	sub_831E3640(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e0e48
	sub_831E0E48(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e1160
	sub_831E1160(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,2136(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 2136);
	// rlwinm. r11,r11,17,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 17) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831e5cd4
	if (cr0.eq) goto loc_831E5CD4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e5410
	sub_831E5410(ctx, base);
loc_831E5CD4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,1404(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1404);
	// stw r11,2088(r31)
	PPC_STORE_U32(r31.u32 + 2088, r11.u32);
	// bl 0x831e1358
	sub_831E1358(ctx, base);
	// b 0x831e5d4c
	goto loc_831E5D4C;
loc_831E5CF0:
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831e5d2c
	if (!cr6.eq) goto loc_831E5D2C;
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831e5d2c
	if (!cr6.eq) goto loc_831E5D2C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r6,r11,24888
	ctx.r6.s64 = r11.s64 + 24888;
	// addi r5,r10,24968
	ctx.r5.s64 = ctx.r10.s64 + 24968;
	// addi r4,r9,-18548
	ctx.r4.s64 = ctx.r9.s64 + -18548;
	// li r7,532
	ctx.r7.s64 = 532;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831034d8
	sub_831034D8(ctx, base);
loc_831E5D2C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e2e58
	sub_831E2E58(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e5b98
	sub_831E5B98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e0978
	sub_831E0978(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831e5290
	sub_831E5290(ctx, base);
loc_831E5D4C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83203980
	sub_83203980(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831df490
	sub_831DF490(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8320c568
	sub_8320C568(ctx, base);
	// lwz r5,2156(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 2156);
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x831e5d80
	if (cr6.eq) goto loc_831E5D80;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r4,r11,25912
	ctx.r4.s64 = r11.s64 + 25912;
	// bl 0x829ce870
	sub_829CE870(ctx, base);
loc_831E5D80:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831E5C58) {
	__imp__sub_831E5C58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5D98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831e5de0
	if (cr6.eq) goto loc_831E5DE0;
loc_831E5DBC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r30,0(r4)
	r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r3,1444(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1444);
	// lwz r11,1436(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1436);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831e5dbc
	if (!cr6.eq) goto loc_831E5DBC;
loc_831E5DE0:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831E5D98) {
	__imp__sub_831E5D98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5E10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831e5e50
	if (cr6.eq) goto loc_831E5E50;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// lwz r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// add r3,r10,r9
	ctx.r3.u64 = ctx.r10.u64 + ctx.r9.u64;
	// b 0x831e5e40
	goto loc_831E5E40;
loc_831E5E38:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
loc_831E5E40:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831e5e38
	if (!cr6.eq) goto loc_831E5E38;
	// blr 
	return;
loc_831E5E50:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831E5E10) {
	__imp__sub_831E5E10(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5E58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,12248
	cr6.compare<int32_t>(ctx.r4.s32, 12248, xer);
	// bge cr6,0x831e5e74
	if (!cr6.lt) goto loc_831E5E74;
	// li r4,12248
	ctx.r4.s64 = 12248;
loc_831E5E74:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r30,r4,8
	r30.s64 = ctx.r4.s64 + 8;
	// lwz r29,4(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r3,1444(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1444);
	// lwz r11,1440(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1440);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r3.u32);
	// stw r29,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r29.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// stw r30,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r30.u32);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// add r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 + r30.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r10,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831E5E58) {
	__imp__sub_831E5E58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831E5EC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r4,20(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r3,1448(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1448);
	// b 0x831c59e0
	sub_831C59E0(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_831E5EC8) {
	__imp__sub_831E5EC8(ctx, base);
}

