#include "ppc_recomp_shared.h"

PPC_FUNC_IMPL(__imp__sub_831945B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831945fc
	if (!cr0.eq) goto loc_831945FC;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831945fc
	if (cr0.eq) goto loc_831945FC;
loc_831945E0:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831945fc
	if (!cr0.eq) goto loc_831945FC;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831945e0
	if (!cr6.eq) goto loc_831945E0;
loc_831945FC:
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r4,r28,2,0,29
	ctx.r4.u64 = rotl64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83110880
	sub_83110880(ctx, base);
	// lwz r31,4(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// li r23,1
	r23.s64 = 1;
	// stw r3,96(r27)
	PPC_STORE_U32(r27.u32 + 96, ctx.r3.u32);
	// clrlwi. r11,r31,31
	r11.u64 = r31.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r30,r23
	r30.u64 = r23.u64;
	// bne 0x83194688
	if (!cr0.eq) goto loc_83194688;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x83194688
	if (cr0.eq) goto loc_83194688;
	// li r29,4
	r29.s64 = 4;
loc_83194630:
	// lis r11,31
	r11.s64 = 2031616;
	// ori r11,r11,65532
	r11.u64 = r11.u64 | 65532;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// bgt cr6,0x83194744
	if (cr6.gt) goto loc_83194744;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// addi r3,r31,84
	ctx.r3.s64 = r31.s64 + 84;
	// stw r23,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r23.u32);
	// addi r4,r28,1
	ctx.r4.s64 = r28.s64 + 1;
	// rlwimi r11,r30,0,13,31
	r11.u64 = (rotl32(r30.u32, 0) & 0x7FFFF) | (r11.u64 & 0xFFFFFFFFFFF80000);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// bl 0x8311d650
	sub_8311D650(ctx, base);
	// lwz r11,96(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 96);
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// stw r31,-4(r11)
	PPC_STORE_U32(r11.u32 + -4, r31.u32);
	// lwz r31,4(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// clrlwi. r11,r31,31
	r11.u64 = r31.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x83194688
	if (!cr0.eq) goto loc_83194688;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x83194630
	if (!cr6.eq) goto loc_83194630;
loc_83194688:
	// lwz r11,44(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 44);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// stw r30,92(r27)
	PPC_STORE_U32(r27.u32 + 92, r30.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// oris r11,r11,4
	r11.u64 = r11.u64 | 262144;
	// stw r11,44(r27)
	PPC_STORE_U32(r27.u32 + 44, r11.u32);
	// bl 0x83193230
	sub_83193230(ctx, base);
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// ble cr6,0x831946b8
	if (!cr6.gt) goto loc_831946B8;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83194340
	sub_83194340(ctx, base);
loc_831946B8:
	// lwz r11,40(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 40);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83194998
	if (cr0.eq) goto loc_83194998;
	// lis r11,-31980
	r11.s64 = -2095841280;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r11,6976
	ctx.r5.s64 = r11.s64 + 6976;
	// addi r4,r28,1
	ctx.r4.s64 = r28.s64 + 1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83140f90
	sub_83140F90(ctx, base);
	// li r5,6
	ctx.r5.s64 = 6;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r24,r26,4
	r24.s64 = r26.s64 + 4;
	// ori r11,r26,1
	r11.u64 = r26.u64 | 1;
	// ori r10,r24,1
	ctx.r10.u64 = r24.u64 | 1;
	// stw r11,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r11.u32);
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x83194998
	if (!cr0.eq) goto loc_83194998;
	// mr r25,r11
	r25.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x83194998
	if (cr0.eq) goto loc_83194998;
	// lwz r29,80(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_83194720:
	// lwz r11,48(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// rlwinm. r11,r11,13,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319497c
	if (cr0.eq) goto loc_8319497C;
	// not r11,r29
	r11.u64 = ~r29.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x83194750
	if (!cr0.eq) goto loc_83194750;
	// mr r29,r23
	r29.u64 = r23.u64;
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// b 0x83194764
	goto loc_83194764;
loc_83194744:
	// li r4,3529
	ctx.r4.s64 = 3529;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_83194750:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r29,4
	ctx.r3.s64 = r29.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
loc_83194764:
	// lwz r11,108(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 108);
	// addi r28,r11,1
	r28.s64 = r11.s64 + 1;
	// stw r28,108(r27)
	PPC_STORE_U32(r27.u32 + 108, r28.u32);
	// stw r28,44(r25)
	PPC_STORE_U32(r25.u32 + 44, r28.u32);
loc_83194774:
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831948d8
	if (!cr0.eq) goto loc_831948D8;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831948d8
	if (cr0.eq) goto loc_831948D8;
loc_8319478C:
	// lwz r11,48(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// lwz r10,40(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// clrlwi r9,r11,13
	ctx.r9.u64 = r11.u32 & 0x7FFFF;
	// rlwinm r11,r9,27,5,31
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// slw r9,r23,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r23.u32 << (ctx.r9.u8 & 0x3F));
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// and. r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831948bc
	if (cr0.eq) goto loc_831948BC;
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831948bc
	if (!cr0.eq) goto loc_831948BC;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r31,r11,-40
	xer.ca = r11.u32 > 39;
	r31.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x831948bc
	if (cr0.eq) goto loc_831948BC;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,86
	cr6.compare<uint32_t>(r11.u32, 86, xer);
	// beq cr6,0x831947f0
	if (cr6.eq) goto loc_831947F0;
	// cmplwi cr6,r11,87
	cr6.compare<uint32_t>(r11.u32, 87, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x831947f4
	if (!cr6.eq) goto loc_831947F4;
loc_831947F0:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_831947F4:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831948bc
	if (cr0.eq) goto loc_831948BC;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-16
	r11.s64 = r31.s64 + -16;
	// not r10,r29
	ctx.r10.u64 = ~r29.u64;
	// addi r9,r29,4
	ctx.r9.s64 = r29.s64 + 4;
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r31,r3,r11
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// clrlwi r11,r11,13
	r11.u64 = r11.u32 & 0x7FFFF;
	// bne 0x83194838
	if (!cr0.eq) goto loc_83194838;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
loc_83194838:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r10,r11,29,3,29
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// slw r11,r23,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r23.u32 << (r11.u8 & 0x3F));
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// or r11,r11,r8
	r11.u64 = r11.u64 | ctx.r8.u64;
	// stwx r11,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, r11.u32);
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x831948b8
	if (cr6.eq) goto loc_831948B8;
	// stw r28,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r28.u32);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x83194894
	if (!cr0.eq) goto loc_83194894;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x83194894
	if (cr0.eq) goto loc_83194894;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831948a0
	if (!cr6.gt) goto loc_831948A0;
loc_83194894:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831948A0:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831948B8:
	// lwz r29,80(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_831948BC:
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831948d8
	if (!cr0.eq) goto loc_831948D8;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319478c
	if (!cr6.eq) goto loc_8319478C;
loc_831948D8:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x83194944
	if (!cr0.eq) goto loc_83194944;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x83194944
	if (cr0.eq) goto loc_83194944;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x83194774
	if (!cr0.eq) goto loc_83194774;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
	// b 0x83194774
	goto loc_83194774;
loc_83194944:
	// not r11,r29
	r11.u64 = ~r29.u64;
	// lwz r10,48(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// clrlwi r11,r10,13
	r11.u64 = ctx.r10.u32 & 0x7FFFF;
	// addi r10,r29,4
	ctx.r10.s64 = r29.s64 + 4;
	// bne 0x83194960
	if (!cr0.eq) goto loc_83194960;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
loc_83194960:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r9,r11,29,3,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// srw r11,r10,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (r11.u8 & 0x3F));
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831949a0
	if (!cr0.eq) goto loc_831949A0;
loc_8319497C:
	// rlwinm r11,r25,0,0,30
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x83194998
	if (!cr0.eq) goto loc_83194998;
	// mr r25,r11
	r25.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x83194720
	if (!cr6.eq) goto loc_83194720;
loc_83194998:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	return;
loc_831949A0:
	// lwz r11,116(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 116);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831949e4
	if (cr6.eq) goto loc_831949E4;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831949e4
	if (cr6.eq) goto loc_831949E4;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831949e4
	if (cr6.eq) goto loc_831949E4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x831949e4
	if (!cr6.eq) goto loc_831949E4;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x831949e4
	if (!cr6.eq) goto loc_831949E4;
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// b 0x831949e8
	goto loc_831949E8;
loc_831949E4:
	// li r5,0
	ctx.r5.s64 = 0;
loc_831949E8:
	// li r4,3614
	ctx.r4.s64 = 3614;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831945B8) {
	__imp__sub_831945B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831949F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,33
	cr6.compare<uint32_t>(r11.u32, 33, xer);
	// beq cr6,0x83194a30
	if (cr6.eq) goto loc_83194A30;
	// cmplwi cr6,r11,34
	cr6.compare<uint32_t>(r11.u32, 34, xer);
	// ble cr6,0x83194a28
	if (!cr6.gt) goto loc_83194A28;
	// cmplwi cr6,r11,36
	cr6.compare<uint32_t>(r11.u32, 36, xer);
	// ble cr6,0x83194a30
	if (!cr6.gt) goto loc_83194A30;
	// cmplwi cr6,r11,58
	cr6.compare<uint32_t>(r11.u32, 58, xer);
	// beq cr6,0x83194a30
	if (cr6.eq) goto loc_83194A30;
	// cmplwi cr6,r11,82
	cr6.compare<uint32_t>(r11.u32, 82, xer);
	// beq cr6,0x83194a30
	if (cr6.eq) goto loc_83194A30;
loc_83194A28:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_83194A30:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831949F8) {
	__imp__sub_831949F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194A38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r30{};
	PPCRegister r31{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// li r11,1
	r11.s64 = 1;
	// lwz r31,84(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r30,92(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// slw r3,r11,r3
	ctx.r3.u64 = ctx.r3.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r3.u8 & 0x3F));
	// slw r4,r11,r4
	ctx.r4.u64 = ctx.r4.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r4.u8 & 0x3F));
	// slw r5,r11,r5
	ctx.r5.u64 = ctx.r5.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r5.u8 & 0x3F));
	// or r4,r3,r4
	ctx.r4.u64 = ctx.r3.u64 | ctx.r4.u64;
	// slw r6,r11,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r6.u8 & 0x3F));
	// or r5,r4,r5
	ctx.r5.u64 = ctx.r4.u64 | ctx.r5.u64;
	// slw r7,r11,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r7.u8 & 0x3F));
	// or r6,r5,r6
	ctx.r6.u64 = ctx.r5.u64 | ctx.r6.u64;
	// slw r8,r11,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r8.u8 & 0x3F));
	// or r7,r6,r7
	ctx.r7.u64 = ctx.r6.u64 | ctx.r7.u64;
	// slw r9,r11,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r9.u8 & 0x3F));
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// slw r10,r11,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r10.u8 & 0x3F));
	// or r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 | ctx.r9.u64;
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// slw r9,r11,r31
	ctx.r9.u64 = r31.u8 & 0x20 ? 0 : (r11.u32 << (r31.u8 & 0x3F));
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// slw r11,r11,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (r11.u32 << (r30.u8 & 0x3F));
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// rlwinm r3,r11,0,0,30
	ctx.r3.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83194A38) {
	__imp__sub_83194A38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194AA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister temp{};
	// stfs f1,-16(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -16, temp.u32);
	// lwz r11,-16(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// stfs f1,20(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// clrlwi. r10,r11,1
	ctx.r10.u64 = r11.u32 & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x83194ac8
	if (cr0.eq) goto loc_83194AC8;
	// rlwinm. r11,r11,0,1,8
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x7F800000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// beq 0x83194acc
	if (cr0.eq) goto loc_83194ACC;
loc_83194AC8:
	// li r11,1
	r11.s64 = 1;
loc_83194ACC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bnelr 
	if (!cr0.eq) return;
	// lwz r11,20(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// rlwinm r11,r11,0,0,0
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	// stw r11,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, r11.u32);
	// lfs f1,20(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83194AA8) {
	__imp__sub_83194AA8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194AE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,24(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83194b2c
	if (cr6.eq) goto loc_83194B2C;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83194b2c
	if (cr6.eq) goto loc_83194B2C;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83194b2c
	if (cr6.eq) goto loc_83194B2C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x83194b2c
	if (!cr6.eq) goto loc_83194B2C;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x83194b2c
	if (!cr6.eq) goto loc_83194B2C;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// blr 
	return;
loc_83194B2C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83194AE8) {
	__imp__sub_83194AE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194B38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// rlwinm r11,r4,4,0,27
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// or r11,r11,r4
	r11.u64 = r11.u64 | ctx.r4.u64;
	// rlwinm r11,r11,4,0,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// or r11,r11,r4
	r11.u64 = r11.u64 | ctx.r4.u64;
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// rlwinm r11,r11,4,0,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// or r11,r11,r4
	r11.u64 = r11.u64 | ctx.r4.u64;
	// and r8,r9,r11
	ctx.r8.u64 = ctx.r9.u64 & r11.u64;
	// clrlwi r8,r8,16
	ctx.r8.u64 = ctx.r8.u32 & 0xFFFF;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// bne cr6,0x83194b70
	if (!cr6.eq) goto loc_83194B70;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_83194B70:
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// sth r11,14(r10)
	PPC_STORE_U16(ctx.r10.u32 + 14, r11.u16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83194B38) {
	__imp__sub_83194B38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194B80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x83194b9c
	if (cr6.eq) goto loc_83194B9C;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpw cr6,r11,r5
	cr6.compare<int32_t>(r11.s32, ctx.r5.s32, xer);
	// bne cr6,0x83194b9c
	if (!cr6.eq) goto loc_83194B9C;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// blr 
	return;
loc_83194B9C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_83194B80) {
	__imp__sub_83194B80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194BA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x83194bc4
	if (cr6.eq) goto loc_83194BC4;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x83194bc4
	if (!cr6.eq) goto loc_83194BC4;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// blr 
	return;
loc_83194BC4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_83194BA8) {
	__imp__sub_83194BA8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194BD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x83194c00
	if (cr6.eq) goto loc_83194C00;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x83194c00
	if (!cr6.eq) goto loc_83194C00;
	// lwz r11,28(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// cmpw cr6,r11,r5
	cr6.compare<int32_t>(r11.s32, ctx.r5.s32, xer);
	// beq cr6,0x83194bf8
	if (cr6.eq) goto loc_83194BF8;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_83194BF8:
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// blr 
	return;
loc_83194C00:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_83194BD0) {
	__imp__sub_83194BD0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194C08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x83194c54
	if (cr6.eq) goto loc_83194C54;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x83194c54
	if (!cr6.eq) goto loc_83194C54;
	// lwz r11,28(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// cmpw cr6,r11,r5
	cr6.compare<int32_t>(r11.s32, ctx.r5.s32, xer);
	// beq cr6,0x83194c30
	if (cr6.eq) goto loc_83194C30;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_83194C30:
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// lwz r10,20(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// beq cr6,0x83194c4c
	if (cr6.eq) goto loc_83194C4C;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_83194C4C:
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// blr 
	return;
loc_83194C54:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_83194C08) {
	__imp__sub_83194C08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194C60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x83194c7c
	if (cr6.eq) goto loc_83194C7C;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x83194c7c
	if (!cr6.eq) goto loc_83194C7C;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// blr 
	return;
loc_83194C7C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_83194C60) {
	__imp__sub_83194C60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194C88) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x83194ca4
	if (cr6.eq) goto loc_83194CA4;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// bne cr6,0x83194ca4
	if (!cr6.eq) goto loc_83194CA4;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// blr 
	return;
loc_83194CA4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_83194C88) {
	__imp__sub_83194C88(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194CB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x83194ccc
	if (cr6.eq) goto loc_83194CCC;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x83194ccc
	if (!cr6.eq) goto loc_83194CCC;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// blr 
	return;
loc_83194CCC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_83194CB0) {
	__imp__sub_83194CB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194CD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x83194cf4
	if (cr6.eq) goto loc_83194CF4;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x83194cf4
	if (cr6.eq) goto loc_83194CF4;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_83194CF4:
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83194CD8) {
	__imp__sub_83194CD8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194D00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x83194d48
	if (cr6.eq) goto loc_83194D48;
	// lwz r3,24(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8301d1e0
	sub_8301D1E0(ctx, base);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x83194d48
	if (!cr0.lt) goto loc_83194D48;
	// li r11,-1
	r11.s64 = -1;
loc_83194D48:
	// rlwinm. r10,r11,0,0,15
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x83194d60
	if (cr0.eq) goto loc_83194D60;
	// lwz r9,48(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r9,r9,0,0,15
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x83194d74
	if (!cr6.eq) goto loc_83194D74;
loc_83194D60:
	// clrlwi. r10,r11,16
	ctx.r10.u64 = r11.u32 & 0xFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x83194d7c
	if (cr0.eq) goto loc_83194D7C;
	// lhz r9,50(r31)
	ctx.r9.u64 = PPC_LOAD_U16(r31.u32 + 50);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x83194d7c
	if (cr6.eq) goto loc_83194D7C;
loc_83194D74:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x83194d84
	goto loc_83194D84;
loc_83194D7C:
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// li r3,1
	ctx.r3.s64 = 1;
loc_83194D84:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83194D00) {
	__imp__sub_83194D00(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194DA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// b 0x83194df0
	goto loc_83194DF0;
loc_83194DA4:
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x83194e20
	if (!cr6.eq) goto loc_83194E20;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83194e38
	if (cr6.eq) goto loc_83194E38;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x83194e38
	if (!cr6.eq) goto loc_83194E38;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x83194e28
	if (!cr6.eq) goto loc_83194E28;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83194e30
	if (cr6.eq) goto loc_83194E30;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,11
	cr6.compare<int32_t>(ctx.r10.s32, 11, xer);
	// bne cr6,0x83194e30
	if (!cr6.eq) goto loc_83194E30;
	// lwz r4,48(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 48);
loc_83194DF0:
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x83194da4
	if (cr6.eq) goto loc_83194DA4;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x83194e40
	if (!cr6.eq) goto loc_83194E40;
	// lwz r11,28(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// lwz r11,32(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// blr 
	return;
loc_83194E20:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_83194E28:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_83194E30:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_83194E38:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_83194E40:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_83194DA0) {
	__imp__sub_83194DA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194E48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x83194eac
	if (cr6.eq) goto loc_83194EAC;
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// bne cr6,0x83194e70
	if (!cr6.eq) goto loc_83194E70;
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x83194ea4
	if (cr6.lt) goto loc_83194EA4;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// beq cr6,0x83194e78
	if (cr6.eq) goto loc_83194E78;
loc_83194E70:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_83194E78:
	// lwz r11,28(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x83194e8c
	if (!cr6.eq) goto loc_83194E8C;
loc_83194E84:
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// b 0x83194eb8
	goto loc_83194EB8;
loc_83194E8C:
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// b 0x83194da0
	sub_83194DA0(ctx, base);
	return;
loc_83194EA4:
	// li r11,1
	r11.s64 = 1;
	// b 0x83194e84
	goto loc_83194E84;
loc_83194EAC:
	// lwz r11,20(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
loc_83194EB8:
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83194E48) {
	__imp__sub_83194E48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194EC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// b 0x83194edc
	goto loc_83194EDC;
loc_83194ECC:
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x83194eec
	if (!cr6.eq) goto loc_83194EEC;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
loc_83194EDC:
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x83194ecc
	if (cr6.eq) goto loc_83194ECC;
	// b 0x83194e48
	sub_83194E48(ctx, base);
	return;
loc_83194EEC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83194EC8) {
	__imp__sub_83194EC8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194EF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x83194f40
	if (!cr6.eq) goto loc_83194F40;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83194f2c
	if (cr6.eq) goto loc_83194F2C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x83194f4c
	goto loc_83194F4C;
loc_83194F2C:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x83194f4c
	goto loc_83194F4C;
loc_83194F40:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_83194F4C:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x83194f5c
	if (!cr0.eq) goto loc_83194F5C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x83194f70
	goto loc_83194F70;
loc_83194F5C:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mullw r11,r10,r11
	r11.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_83194F70:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83194EF8) {
	__imp__sub_83194EF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194F88) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x83194f9c
	if (!cr6.eq) goto loc_83194F9C;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// blr 
	return;
loc_83194F9C:
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x83194fe0
	if (!cr6.eq) goto loc_83194FE0;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83194fb8
	if (cr6.eq) goto loc_83194FB8;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_83194FB8:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83194fd8
	if (cr6.eq) goto loc_83194FD8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x83194fd8
	if (!cr6.eq) goto loc_83194FD8;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_83194FD8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_83194FE0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_83194F88) {
	__imp__sub_83194F88(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83194FE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x83195070
	if (cr6.eq) goto loc_83195070;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x83195014
	if (cr6.eq) goto loc_83195014;
	// lwz r11,28(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x83195070
	if (!cr6.eq) goto loc_83195070;
loc_83195014:
	// lwz r11,20(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x83195070
	if (!cr6.eq) goto loc_83195070;
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x83195070
	if (!cr6.eq) goto loc_83195070;
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319514c
	if (cr6.eq) goto loc_8319514C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x8319514c
	if (!cr6.eq) goto loc_8319514C;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x83195084
	if (cr6.eq) goto loc_83195084;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x83195088
	if (cr6.eq) goto loc_83195088;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x83195084
	if (cr6.eq) goto loc_83195084;
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// beq cr6,0x8319508c
	if (cr6.eq) goto loc_8319508C;
loc_83195070:
	// li r3,0
	ctx.r3.s64 = 0;
loc_83195074:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_83195084:
	// li r8,1
	ctx.r8.s64 = 1;
loc_83195088:
	// li r9,1
	ctx.r9.s64 = 1;
loc_8319508C:
	// lwz r11,32(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x83195070
	if (!cr6.eq) goto loc_83195070;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x83195070
	if (!cr6.eq) goto loc_83195070;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// bne cr6,0x83195070
	if (!cr6.eq) goto loc_83195070;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x83195128
	if (cr6.eq) goto loc_83195128;
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// beq cr6,0x8319513c
	if (cr6.eq) goto loc_8319513C;
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x83195070
	if (!cr6.eq) goto loc_83195070;
	// clrlwi. r10,r8,24
	ctx.r10.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831950f0
	if (!cr0.eq) goto loc_831950F0;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfd f13,24(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// lfd f0,3376(r10)
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3376);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x83195070
	if (cr6.lt) goto loc_83195070;
loc_831950F0:
	// lfd f0,24(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// clrlwi. r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// fctidz f13,f0
	ctx.f13.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f13,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f13.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bne 0x83195140
	if (!cr0.eq) goto loc_83195140;
	// clrldi r10,r11,32
	ctx.r10.u64 = r11.u64 & 0xFFFFFFFF;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// beq cr6,0x83195140
	if (cr6.eq) goto loc_83195140;
	// b 0x83195070
	goto loc_83195070;
loc_83195128:
	// clrlwi. r10,r8,24
	ctx.r10.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8319513c
	if (!cr0.eq) goto loc_8319513C;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x83195070
	if (cr6.lt) goto loc_83195070;
loc_8319513C:
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
loc_83195140:
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x83195074
	goto loc_83195074;
loc_8319514C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_83194FE8) {
	__imp__sub_83194FE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195158) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x83195214
	if (cr6.eq) goto loc_83195214;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x83195178
	if (cr6.eq) goto loc_83195178;
	// lwz r11,28(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x83195214
	if (!cr6.eq) goto loc_83195214;
loc_83195178:
	// lwz r11,20(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x83195214
	if (!cr6.eq) goto loc_83195214;
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x83195214
	if (!cr6.eq) goto loc_83195214;
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319520c
	if (cr6.eq) goto loc_8319520C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x8319520c
	if (!cr6.eq) goto loc_8319520C;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x83195214
	if (!cr6.eq) goto loc_83195214;
	// lwz r11,32(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x83195214
	if (!cr6.eq) goto loc_83195214;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x83195214
	if (!cr6.eq) goto loc_83195214;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// bne cr6,0x83195214
	if (!cr6.eq) goto loc_83195214;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x83195214
	if (!cr6.eq) goto loc_83195214;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r11,r11,0
	r11.s64 = r11.s64 + 0;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// stb r11,0(r5)
	PPC_STORE_U8(ctx.r5.u32 + 0, r11.u8);
	// blr 
	return;
loc_8319520C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_83195214:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83195158) {
	__imp__sub_83195158(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195220) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x83195244
	if (!cr6.eq) goto loc_83195244;
	// li r4,3583
	ctx.r4.s64 = 3583;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_83195244:
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8319529c
	if (!cr6.eq) goto loc_8319529C;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83195264
	if (cr6.eq) goto loc_83195264;
	// li r4,3583
	ctx.r4.s64 = 3583;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_83195264:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// bl 0x83194fe8
	sub_83194FE8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x83195284
	if (!cr0.eq) goto loc_83195284;
	// li r4,3583
	ctx.r4.s64 = 3583;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_83195284:
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_8319529C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_83195220) {
	__imp__sub_83195220(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831952A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831952d0
	if (!cr6.eq) goto loc_831952D0;
	// li r4,3583
	ctx.r4.s64 = 3583;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831952D0:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x83195320
	if (!cr6.eq) goto loc_83195320;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831952f0
	if (!cr6.eq) goto loc_831952F0;
	// li r4,3583
	ctx.r4.s64 = 3583;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831952F0:
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x83194fe8
	sub_83194FE8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bne 0x8319530c
	if (!cr0.eq) goto loc_8319530C;
	// li r4,3583
	ctx.r4.s64 = 3583;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319530C:
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83195220
	sub_83195220(ctx, base);
	// stw r3,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r3.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_83195320:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831952A8) {
	__imp__sub_831952A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195328) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x8319534c
	if (!cr6.eq) goto loc_8319534C;
	// li r4,3609
	ctx.r4.s64 = 3609;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319534C:
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831953a4
	if (!cr6.eq) goto loc_831953A4;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319536c
	if (cr6.eq) goto loc_8319536C;
	// li r4,3609
	ctx.r4.s64 = 3609;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319536C:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// bl 0x83195158
	sub_83195158(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319538c
	if (!cr0.eq) goto loc_8319538C;
	// li r4,3609
	ctx.r4.s64 = 3609;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319538C:
	// lbz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_831953A4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_83195328) {
	__imp__sub_83195328(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831953B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,32(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831954e8
	if (cr6.eq) goto loc_831954E8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831954e8
	if (!cr6.eq) goto loc_831954E8;
	// mr r29,r11
	r29.u64 = r11.u64;
	// li r28,0
	r28.s64 = 0;
	// li r30,-1
	r30.s64 = -1;
loc_831953E4:
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831954dc
	if (cr6.eq) goto loc_831954DC;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// bne cr6,0x831954dc
	if (!cr6.eq) goto loc_831954DC;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x831954b8
	if (!cr6.eq) goto loc_831954B8;
	// lwz r11,568(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 568);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83195434
	if (cr6.eq) goto loc_83195434;
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
loc_83195418:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r9,40(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 40);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x831954b0
	if (cr6.eq) goto loc_831954B0;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x83195418
	if (!cr6.eq) goto loc_83195418;
loc_83195434:
	// li r31,0
	r31.s64 = 0;
loc_83195438:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x83195478
	if (cr6.eq) goto loc_83195478;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,36(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// bl 0x83194d00
	sub_83194D00(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83195478
	if (cr0.eq) goto loc_83195478;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// beq cr6,0x83195470
	if (cr6.eq) goto loc_83195470;
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// ble cr6,0x83195478
	if (!cr6.gt) goto loc_83195478;
loc_83195470:
	// mr r28,r31
	r28.u64 = r31.u64;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_83195478:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83195490
	if (cr6.eq) goto loc_83195490;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831954c4
	if (!cr6.eq) goto loc_831954C4;
loc_83195490:
	// mr r29,r11
	r29.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831953e4
	if (!cr6.eq) goto loc_831953E4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x831954d0
	if (!cr6.eq) goto loc_831954D0;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831954B0:
	// mr r31,r11
	r31.u64 = r11.u64;
	// b 0x83195438
	goto loc_83195438;
loc_831954B8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831954C4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831954D0:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
loc_831954DC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831954E8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831953B0) {
	__imp__sub_831953B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831954F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r4,63
	cr6.compare<uint32_t>(ctx.r4.u32, 63, xer);
	// bgt cr6,0x8319556c
	if (cr6.gt) goto loc_8319556C;
	// li r11,0
	r11.s64 = 0;
loc_83195514:
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// lis r10,-31946
	ctx.r10.s64 = -2093613056;
	// addi r31,r10,-15908
	r31.s64 = ctx.r10.s64 + -15908;
	// lhz r10,11932(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 11932);
loc_83195524:
	// sth r10,0(r31)
	PPC_STORE_U16(r31.u32 + 0, ctx.r10.u16);
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
loc_83195530:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x83195530
	if (!cr6.eq) goto loc_83195530;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// subf r6,r11,r4
	ctx.r6.s64 = ctx.r4.s64 - r11.s64;
	// rotlwi r10,r10,0
	ctx.r10.u64 = rotl32(ctx.r10.u32, 0);
	// addi r5,r9,30568
	ctx.r5.s64 = ctx.r9.s64 + 30568;
	// subfic r4,r10,15
	xer.ca = ctx.r10.u32 <= 15;
	ctx.r4.s64 = 15 - ctx.r10.s64;
	// add r3,r10,r31
	ctx.r3.u64 = ctx.r10.u64 + r31.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
loc_83195564:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x83195748
	goto loc_83195748;
loc_8319556C:
	// cmplwi cr6,r4,319
	cr6.compare<uint32_t>(ctx.r4.u32, 319, xer);
	// bgt cr6,0x8319558c
	if (cr6.gt) goto loc_8319558C;
	// lis r9,-32253
	ctx.r9.s64 = -2113732608;
	// lis r10,-31946
	ctx.r10.s64 = -2093613056;
	// li r11,64
	r11.s64 = 64;
	// addi r31,r10,-15908
	r31.s64 = ctx.r10.s64 + -15908;
	// lhz r10,936(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 936);
	// b 0x83195524
	goto loc_83195524;
loc_8319558C:
	// cmplwi cr6,r4,351
	cr6.compare<uint32_t>(ctx.r4.u32, 351, xer);
	// bgt cr6,0x831955ac
	if (cr6.gt) goto loc_831955AC;
	// lis r9,-32251
	ctx.r9.s64 = -2113601536;
	// lis r10,-31946
	ctx.r10.s64 = -2093613056;
	// li r11,320
	r11.s64 = 320;
	// addi r31,r10,-15908
	r31.s64 = ctx.r10.s64 + -15908;
	// lhz r10,3048(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 3048);
	// b 0x83195524
	goto loc_83195524;
loc_831955AC:
	// cmplwi cr6,r4,607
	cr6.compare<uint32_t>(ctx.r4.u32, 607, xer);
	// bgt cr6,0x831955cc
	if (cr6.gt) goto loc_831955CC;
	// lis r9,-32240
	ctx.r9.s64 = -2112880640;
	// lis r10,-31946
	ctx.r10.s64 = -2093613056;
	// li r11,352
	r11.s64 = 352;
	// addi r31,r10,-15908
	r31.s64 = ctx.r10.s64 + -15908;
	// lhz r10,-9652(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + -9652);
	// b 0x83195524
	goto loc_83195524;
loc_831955CC:
	// cmplwi cr6,r4,623
	cr6.compare<uint32_t>(ctx.r4.u32, 623, xer);
	// bgt cr6,0x831955dc
	if (cr6.gt) goto loc_831955DC;
	// li r11,608
	r11.s64 = 608;
	// b 0x83195514
	goto loc_83195514;
loc_831955DC:
	// cmplwi cr6,r4,687
	cr6.compare<uint32_t>(ctx.r4.u32, 687, xer);
	// bgt cr6,0x831955fc
	if (cr6.gt) goto loc_831955FC;
	// lis r9,-32240
	ctx.r9.s64 = -2112880640;
	// lis r10,-31946
	ctx.r10.s64 = -2093613056;
	// li r11,624
	r11.s64 = 624;
	// addi r31,r10,-15908
	r31.s64 = ctx.r10.s64 + -15908;
	// lhz r10,-960(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + -960);
	// b 0x83195524
	goto loc_83195524;
loc_831955FC:
	// cmplwi cr6,r4,719
	cr6.compare<uint32_t>(ctx.r4.u32, 719, xer);
	// bgt cr6,0x8319561c
	if (cr6.gt) goto loc_8319561C;
	// lis r9,-32251
	ctx.r9.s64 = -2113601536;
	// lis r10,-31946
	ctx.r10.s64 = -2093613056;
	// li r11,688
	r11.s64 = 688;
	// addi r31,r10,-15908
	r31.s64 = ctx.r10.s64 + -15908;
	// lhz r10,3044(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 3044);
	// b 0x83195524
	goto loc_83195524;
loc_8319561C:
	// cmplwi cr6,r4,720
	cr6.compare<uint32_t>(ctx.r4.u32, 720, xer);
	// bgt cr6,0x8319563c
	if (cr6.gt) goto loc_8319563C;
	// lis r10,-32241
	ctx.r10.s64 = -2112946176;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r31,r11,-15908
	r31.s64 = r11.s64 + -15908;
	// lhz r11,-20172(r10)
	r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + -20172);
loc_83195634:
	// sth r11,0(r31)
	PPC_STORE_U16(r31.u32 + 0, r11.u16);
	// b 0x83195564
	goto loc_83195564;
loc_8319563C:
	// cmplwi cr6,r4,721
	cr6.compare<uint32_t>(ctx.r4.u32, 721, xer);
	// bgt cr6,0x83195658
	if (cr6.gt) goto loc_83195658;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r31,r11,-15908
	r31.s64 = r11.s64 + -15908;
	// lhz r11,3020(r10)
	r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 3020);
	// b 0x83195634
	goto loc_83195634;
loc_83195658:
	// cmplwi cr6,r4,722
	cr6.compare<uint32_t>(ctx.r4.u32, 722, xer);
	// bgt cr6,0x83195678
	if (cr6.gt) goto loc_83195678;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r31,r11,-15908
	r31.s64 = r11.s64 + -15908;
	// lwz r11,2156(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2156);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x83195564
	goto loc_83195564;
loc_83195678:
	// cmplwi cr6,r4,723
	cr6.compare<uint32_t>(ctx.r4.u32, 723, xer);
	// bgt cr6,0x831956a8
	if (cr6.gt) goto loc_831956A8;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r9,r10,2840
	ctx.r9.s64 = ctx.r10.s64 + 2840;
	// addi r31,r11,-15908
	r31.s64 = r11.s64 + -15908;
	// lwz r11,2840(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2840);
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// lbz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// stb r9,4(r10)
	PPC_STORE_U8(ctx.r10.u32 + 4, ctx.r9.u8);
	// b 0x83195564
	goto loc_83195564;
loc_831956A8:
	// cmplwi cr6,r4,724
	cr6.compare<uint32_t>(ctx.r4.u32, 724, xer);
	// bgt cr6,0x831956e0
	if (cr6.gt) goto loc_831956E0;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r9,r10,2144
	ctx.r9.s64 = ctx.r10.s64 + 2144;
	// addi r31,r11,-15908
	r31.s64 = r11.s64 + -15908;
	// lwz r11,2144(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2144);
loc_831956C4:
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// lhz r9,8(r9)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r9.u32 + 8);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// sth r9,8(r10)
	PPC_STORE_U16(ctx.r10.u32 + 8, ctx.r9.u16);
	// b 0x83195564
	goto loc_83195564;
loc_831956E0:
	// cmplwi cr6,r4,725
	cr6.compare<uint32_t>(ctx.r4.u32, 725, xer);
	// bgt cr6,0x83195700
	if (cr6.gt) goto loc_83195700;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r9,r10,2132
	ctx.r9.s64 = ctx.r10.s64 + 2132;
	// addi r31,r11,-15908
	r31.s64 = r11.s64 + -15908;
	// lwz r11,2132(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2132);
	// b 0x831956c4
	goto loc_831956C4;
loc_83195700:
	// cmplwi cr6,r4,726
	cr6.compare<uint32_t>(ctx.r4.u32, 726, xer);
	// bgt cr6,0x83195740
	if (cr6.gt) goto loc_83195740;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r11,-31946
	r11.s64 = -2093613056;
	// addi r9,r10,2828
	ctx.r9.s64 = ctx.r10.s64 + 2828;
	// addi r31,r11,-15908
	r31.s64 = r11.s64 + -15908;
	// lwz r11,2828(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2828);
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lhz r7,8(r9)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r9.u32 + 8);
	// lbz r9,10(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 10);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// sth r7,8(r10)
	PPC_STORE_U16(ctx.r10.u32 + 8, ctx.r7.u16);
	// stb r9,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, ctx.r9.u8);
	// b 0x83195564
	goto loc_83195564;
loc_83195740:
	// lis r11,-32252
	r11.s64 = -2113667072;
	// addi r3,r11,18064
	ctx.r3.s64 = r11.s64 + 18064;
loc_83195748:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831954F8) {
	__imp__sub_831954F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195760) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,44(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 44);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831957d4
	if (cr6.eq) goto loc_831957D4;
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// bne cr6,0x83195794
	if (!cr6.eq) goto loc_83195794;
	// li r11,0
	r11.s64 = 0;
loc_83195794:
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// lwz r11,44(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831957c8
	if (cr6.eq) goto loc_831957C8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,11
	cr6.compare<int32_t>(ctx.r10.s32, 11, xer);
	// bne cr6,0x831957c8
	if (!cr6.eq) goto loc_831957C8;
	// lwz r3,16(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_831957B4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_831957C8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831957D4:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// beq 0x831958cc
	if (cr0.eq) goto loc_831958CC;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x8319587c
	if (!cr6.eq) goto loc_8319587C;
	// lwz r7,16(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x83195854
	if (cr6.eq) goto loc_83195854;
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_83195800:
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm. r11,r10,0,12,12
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83195844
	if (cr0.eq) goto loc_83195844;
	// lwz r9,4(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r11,r9,28,29,31
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 28) & 0x7;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x83195824
	if (cr6.eq) goto loc_83195824;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bne cr6,0x83195844
	if (!cr6.eq) goto loc_83195844;
loc_83195824:
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// rlwinm r10,r10,12,23,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0x1FF;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x83195844
	if (cr6.lt) goto loc_83195844;
	// rlwinm r9,r9,16,23,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0x1FF;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x831957b4
	if (cr6.lt) goto loc_831957B4;
loc_83195844:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r8,r8,40
	ctx.r8.s64 = ctx.r8.s64 + 40;
	// cmplw cr6,r3,r7
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r7.u32, xer);
	// blt cr6,0x83195800
	if (cr6.lt) goto loc_83195800;
loc_83195854:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r6,24(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// li r4,10
	ctx.r4.s64 = 10;
	// addi r5,r11,2848
	ctx.r5.s64 = r11.s64 + 2848;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,3521
	ctx.r4.s64 = 3521;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319587C:
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x83195890
	if (cr6.eq) goto loc_83195890;
	// li r4,3554
	ctx.r4.s64 = 3554;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_83195890:
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// blt cr6,0x831958c0
	if (cr6.lt) goto loc_831958C0;
	// cmplwi cr6,r11,37
	cr6.compare<uint32_t>(r11.u32, 37, xer);
	// bgt cr6,0x831958c0
	if (cr6.gt) goto loc_831958C0;
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// lwz r10,600(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r3,r11,-32
	ctx.r3.s64 = r11.s64 + -32;
	// b 0x831957b4
	goto loc_831957B4;
loc_831958C0:
	// li r4,3540
	ctx.r4.s64 = 3540;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831958CC:
	// cmplwi cr6,r11,19
	cr6.compare<uint32_t>(r11.u32, 19, xer);
	// bgt cr6,0x831959a0
	if (cr6.gt) goto loc_831959A0;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,2296
	r12.s64 = r12.s64 + 2296;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// lis r12,-31975
	r12.s64 = -2095513600;
	// addi r12,r12,22780
	r12.s64 = r12.s64 + 22780;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_831958FC;
	case 1:
		goto loc_831959A0;
	case 2:
		goto loc_83195904;
	case 3:
		goto loc_83195910;
	case 4:
		goto loc_8319591C;
	case 5:
		goto loc_831959A0;
	case 6:
		goto loc_8319591C;
	case 7:
		goto loc_831959A0;
	case 8:
		goto loc_8319591C;
	case 9:
		goto loc_8319591C;
	case 10:
		goto loc_83195928;
	case 11:
		goto loc_831959A0;
	case 12:
		goto loc_831959A0;
	case 13:
		goto loc_831959A0;
	case 14:
		goto loc_83195934;
	case 15:
		goto loc_83195940;
	case 16:
		goto loc_831959A0;
	case 17:
		goto loc_831959A0;
	case 18:
		goto loc_831959A0;
	case 19:
		goto loc_8319594C;
	default:
		__builtin_unreachable();
	}
loc_831958FC:
	// lwz r3,24(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// b 0x83195954
	goto loc_83195954;
loc_83195904:
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// addi r3,r11,64
	ctx.r3.s64 = r11.s64 + 64;
	// b 0x83195954
	goto loc_83195954;
loc_83195910:
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// addi r3,r11,720
	ctx.r3.s64 = r11.s64 + 720;
	// b 0x83195954
	goto loc_83195954;
loc_8319591C:
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// addi r3,r11,624
	ctx.r3.s64 = r11.s64 + 624;
	// b 0x83195954
	goto loc_83195954;
loc_83195928:
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// addi r3,r11,688
	ctx.r3.s64 = r11.s64 + 688;
	// b 0x83195954
	goto loc_83195954;
loc_83195934:
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// addi r3,r11,352
	ctx.r3.s64 = r11.s64 + 352;
	// b 0x83195954
	goto loc_83195954;
loc_83195940:
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// addi r3,r11,320
	ctx.r3.s64 = r11.s64 + 320;
	// b 0x83195954
	goto loc_83195954;
loc_8319594C:
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// addi r3,r11,721
	ctx.r3.s64 = r11.s64 + 721;
loc_83195954:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r11,r3,40
	r11.s64 = ctx.r3.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x8319597c
	goto loc_8319597C;
loc_83195968:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x83195994
	if (cr6.eq) goto loc_83195994;
	// addi r11,r11,-40
	r11.s64 = r11.s64 + -40;
	// addi r3,r3,-1
	ctx.r3.s64 = ctx.r3.s64 + -1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
loc_8319597C:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r9,r9,29
	ctx.r9.u64 = ctx.r9.u32 & 0x7;
	// cmplwi cr6,r9,5
	cr6.compare<uint32_t>(ctx.r9.u32, 5, xer);
	// beq cr6,0x83195968
	if (cr6.eq) goto loc_83195968;
	// stw r10,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r10.u32);
	// b 0x831957b4
	goto loc_831957B4;
loc_83195994:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831959A0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_83195760) {
	__imp__sub_83195760(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831959B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mulli r10,r4,40
	ctx.r10.s64 = ctx.r4.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83195a0c
	if (cr6.eq) goto loc_83195A0C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x83195a0c
	if (!cr6.eq) goto loc_83195A0C;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83195a04
	if (cr6.eq) goto loc_83195A04;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x83195a04
	if (!cr6.eq) goto loc_83195A04;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// b 0x83195aec
	goto loc_83195AEC;
loc_83195A04:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_83195A0C:
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// rlwinm. r10,r11,0,15,15
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x83195a28
	if (cr0.eq) goto loc_83195A28;
	// cmplwi cr6,r4,727
	cr6.compare<uint32_t>(ctx.r4.u32, 727, xer);
	// bge cr6,0x83195a28
	if (!cr6.lt) goto loc_83195A28;
	// bl 0x831954f8
	sub_831954F8(ctx, base);
	// b 0x83195aec
	goto loc_83195AEC;
loc_83195A28:
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83195a60
	if (cr0.eq) goto loc_83195A60;
	// lwz r11,600(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 600);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x83195a60
	if (cr6.lt) goto loc_83195A60;
	// addi r10,r11,12
	ctx.r10.s64 = r11.s64 + 12;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bge cr6,0x83195a60
	if (!cr6.lt) goto loc_83195A60;
	// subf r11,r11,r4
	r11.s64 = ctx.r4.s64 - r11.s64;
	// lis r10,-31952
	ctx.r10.s64 = -2094006272;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,14072
	ctx.r10.s64 = ctx.r10.s64 + 14072;
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x83195aec
	goto loc_83195AEC;
loc_83195A60:
	// lwz r11,604(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 604);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83195ac4
	if (cr6.eq) goto loc_83195AC4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x83195ac4
	if (cr6.lt) goto loc_83195AC4;
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rotlwi r8,r11,0
	ctx.r8.u64 = rotl32(r11.u32, 0);
	// lwz r9,600(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 600);
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// ble cr6,0x83195a90
	if (!cr6.gt) goto loc_83195A90;
	// subf r10,r11,r9
	ctx.r10.s64 = ctx.r9.s64 - r11.s64;
loc_83195A90:
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bge cr6,0x83195ac4
	if (!cr6.lt) goto loc_83195AC4;
	// lis r10,-31946
	ctx.r10.s64 = -2093613056;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// addi r31,r10,-15888
	r31.s64 = ctx.r10.s64 + -15888;
	// subf r6,r11,r4
	ctx.r6.s64 = ctx.r4.s64 - r11.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r5,r9,2868
	ctx.r5.s64 = ctx.r9.s64 + 2868;
	// li r4,100
	ctx.r4.s64 = 100;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x83195aec
	goto loc_83195AEC;
loc_83195AC4:
	// lwz r11,612(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 612);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83195ae4
	if (cr6.eq) goto loc_83195AE4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// bne cr6,0x83195ae4
	if (!cr6.eq) goto loc_83195AE4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r3,r11,2852
	ctx.r3.s64 = r11.s64 + 2852;
	// b 0x83195aec
	goto loc_83195AEC;
loc_83195AE4:
	// lis r11,-32252
	r11.s64 = -2113667072;
	// addi r3,r11,18064
	ctx.r3.s64 = r11.s64 + 18064;
loc_83195AEC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831959B0) {
	__imp__sub_831959B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195B00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83195b94
	if (cr6.eq) goto loc_83195B94;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x83195b94
	if (!cr6.eq) goto loc_83195B94;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// beq cr6,0x83195b2c
	if (cr6.eq) goto loc_83195B2C;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
loc_83195B2C:
	// lis r10,-31952
	ctx.r10.s64 = -2094006272;
	// lwz r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r8,r10,14328
	ctx.r8.s64 = ctx.r10.s64 + 14328;
loc_83195B3C:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
loc_83195B44:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r5,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r5.s64;
	// beq 0x83195b68
	if (cr0.eq) goto loc_83195B68;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x83195b44
	if (cr6.eq) goto loc_83195B44;
loc_83195B68:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x83195b80
	if (cr0.eq) goto loc_83195B80;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplwi cr6,r7,23
	cr6.compare<uint32_t>(ctx.r7.u32, 23, xer);
	// blt cr6,0x83195b3c
	if (cr6.lt) goto loc_83195B3C;
loc_83195B80:
	// cmplwi cr6,r7,23
	cr6.compare<uint32_t>(ctx.r7.u32, 23, xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// beqlr cr6
	if (cr6.eq) return;
	// addi r3,r7,1
	ctx.r3.s64 = ctx.r7.s64 + 1;
	// blr 
	return;
loc_83195B94:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_83195B00) {
	__imp__sub_83195B00(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195BA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// beq 0x83195bc0
	if (cr0.eq) goto loc_83195BC0;
	// oris r11,r11,8192
	r11.u64 = r11.u64 | 536870912;
	// b 0x83195bc4
	goto loc_83195BC4;
loc_83195BC0:
	// rlwinm r11,r11,0,3,1
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFDFFFFFFF;
loc_83195BC4:
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// beq 0x83195be0
	if (cr0.eq) goto loc_83195BE0;
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// b 0x83195be4
	goto loc_83195BE4;
loc_83195BE0:
	// rlwinm r11,r11,0,31,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
loc_83195BE4:
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83195BA0) {
	__imp__sub_83195BA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195BF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r11,28,18,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x3FFF;
	// rlwinm r8,r10,28,18,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0x3FFF;
	// subf. r3,r8,r9
	ctx.r3.s64 = ctx.r9.s64 - ctx.r8.s64;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bnelr 
	if (!cr0.eq) return;
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// subf r3,r10,r11
	ctx.r3.s64 = r11.s64 - ctx.r10.s64;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83195BF0) {
	__imp__sub_83195BF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195C20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mulli r11,r4,40
	r11.s64 = ctx.r4.s64 * 40;
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwimi r8,r6,3,15,28
	ctx.r8.u64 = (rotl32(ctx.r6.u32, 3) & 0x1FFF8) | (ctx.r8.u64 & 0xFFFFFFFFFFFE0007);
	// li r9,0
	ctx.r9.s64 = 0;
	// stwx r8,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r8.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// stw r9,20(r10)
	PPC_STORE_U32(ctx.r10.u32 + 20, ctx.r9.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// stw r9,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, ctx.r9.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// stw r9,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r9.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// stw r5,32(r10)
	PPC_STORE_U32(ctx.r10.u32 + 32, ctx.r5.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// oris r9,r9,7
	ctx.r9.u64 = ctx.r9.u64 | 458752;
	// ori r9,r9,65535
	ctx.r9.u64 = ctx.r9.u64 | 65535;
	// stw r9,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r9.u32);
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwimi r9,r7,19,10,12
	ctx.r9.u64 = (rotl32(ctx.r7.u32, 19) & 0x380000) | (ctx.r9.u64 & 0xFFFFFFFFFFC7FFFF);
	// stw r9,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r9.u32);
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// ori r9,r9,112
	ctx.r9.u64 = ctx.r9.u64 | 112;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// ori r9,r9,4
	ctx.r9.u64 = ctx.r9.u64 | 4;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r9,r10,1
	ctx.r9.u64 = ctx.r10.u64 | 1;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83195C20) {
	__imp__sub_83195C20(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195CE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// clrlwi r11,r10,30
	r11.u64 = ctx.r10.u32 & 0x3;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x83195d7c
	if (cr6.lt) goto loc_83195D7C;
	// beq cr6,0x83195d54
	if (cr6.eq) goto loc_83195D54;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x83195d24
	if (cr6.lt) goto loc_83195D24;
	// beq cr6,0x83195d7c
	if (cr6.eq) goto loc_83195D7C;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_83195D24:
	// lwz r3,0(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm. r11,r11,0,27,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x83195d7c
	if (!cr0.eq) goto loc_83195D7C;
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,16000
	cr6.compare<uint32_t>(r11.u32, 16000, xer);
	// bne cr6,0x83195d7c
	if (!cr6.eq) goto loc_83195D7C;
	// rlwinm r4,r10,30,18,31
	ctx.r4.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFF;
	// bl 0x83168018
	sub_83168018(ctx, base);
	// b 0x83195d70
	goto loc_83195D70;
loc_83195D54:
	// lwz r3,0(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,16000
	cr6.compare<uint32_t>(r11.u32, 16000, xer);
	// bne cr6,0x83195d7c
	if (!cr6.eq) goto loc_83195D7C;
	// rlwinm r4,r10,30,18,31
	ctx.r4.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFF;
	// bl 0x83167de0
	sub_83167DE0(ctx, base);
loc_83195D70:
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x83195d80
	goto loc_83195D80;
loc_83195D7C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_83195D80:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83195CE8) {
	__imp__sub_83195CE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195D98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwimi r11,r10,18,13,13
	r11.u64 = (rotl32(ctx.r10.u32, 18) & 0x40000) | (r11.u64 & 0xFFFFFFFFFFFBFFFF);
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-16
	r11.s64 = r31.s64 + -16;
	// clrlwi r10,r29,24
	ctx.r10.u64 = r29.u32 & 0xFF;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// rlwimi r9,r10,2,29,29
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 2) & 0x4) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFFB);
	// stw r9,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83195D98) {
	__imp__sub_83195D98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195E00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x83195e28
	if (!cr6.eq) goto loc_83195E28;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_83195E28:
	// li r5,17
	ctx.r5.s64 = 17;
	// li r4,48
	ctx.r4.s64 = 48;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83046d00
	sub_83046D00(ctx, base);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,3
	r11.s64 = 3;
	// stw r31,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r31.u32);
	// li r10,9
	ctx.r10.s64 = 9;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r10,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r10.u32);
	// stw r9,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r9.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83195E00) {
	__imp__sub_83195E00(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195E78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r5,9
	ctx.r5.s64 = 9;
	// li r4,52
	ctx.r4.s64 = 52;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83047348
	sub_83047348(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,6
	r11.s64 = 6;
	// stw r30,16(r27)
	PPC_STORE_U32(r27.u32 + 16, r30.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// stw r11,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r10.u32);
	// bl 0x83195e00
	sub_83195E00(ctx, base);
	// stw r3,20(r27)
	PPC_STORE_U32(r27.u32 + 20, ctx.r3.u32);
	// stw r28,24(r27)
	PPC_STORE_U32(r27.u32 + 24, r28.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_83195E78) {
	__imp__sub_83195E78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195EE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,20
	ctx.r4.s64 = 20;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x830468a8
	sub_830468A8(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,1
	r11.s64 = 1;
	// stw r31,8(r28)
	PPC_STORE_U32(r28.u32 + 8, r31.u32);
	// stw r30,12(r28)
	PPC_STORE_U32(r28.u32 + 12, r30.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r11,4(r28)
	PPC_STORE_U32(r28.u32 + 4, r11.u32);
	// stw r29,16(r28)
	PPC_STORE_U32(r28.u32 + 16, r29.u32);
	// stw r10,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r10.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83195EE0) {
	__imp__sub_83195EE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195F38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	r11.s64 = 0;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r29,r1,80
	r29.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x83195fd0
	if (cr6.eq) goto loc_83195FD0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// addi r27,r11,17964
	r27.s64 = r11.s64 + 17964;
loc_83195F6C:
	// li r5,19
	ctx.r5.s64 = 19;
	// li r4,64
	ctx.r4.s64 = 64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x83049700
	sub_83049700(ctx, base);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r11,15
	r11.s64 = 15;
	// li r10,3
	ctx.r10.s64 = 3;
	// stw r11,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r11.u32);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// stw r10,16(r26)
	PPC_STORE_U32(r26.u32 + 16, ctx.r10.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r9,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r9.u32);
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfd f0,24(r26)
	PPC_STORE_U64(r26.u32 + 24, f0.u64);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x83195ee0
	sub_83195EE0(ctx, base);
	// stw r3,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r3.u32);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// addi r29,r3,12
	r29.s64 = ctx.r3.s64 + 12;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x83195f6c
	if (!cr0.eq) goto loc_83195F6C;
loc_83195FD0:
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_83195F38) {
	__imp__sub_83195F38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83195FE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// li r5,19
	ctx.r5.s64 = 19;
	// li r4,64
	ctx.r4.s64 = 64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83049700
	sub_83049700(ctx, base);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,15
	r11.s64 = 15;
	// stw r31,24(r29)
	PPC_STORE_U32(r29.u32 + 24, r31.u32);
	// li r10,6
	ctx.r10.s64 = 6;
	// stw r30,28(r29)
	PPC_STORE_U32(r29.u32 + 28, r30.u32);
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r10,16(r29)
	PPC_STORE_U32(r29.u32 + 16, ctx.r10.u32);
	// stw r9,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r9.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83195FE0) {
	__imp__sub_83195FE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196038) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// li r5,10
	ctx.r5.s64 = 10;
	// li r4,80
	ctx.r4.s64 = 80;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83049360
	sub_83049360(ctx, base);
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,14
	r11.s64 = 14;
	// stw r30,24(r29)
	PPC_STORE_U32(r29.u32 + 24, r30.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r31,32(r29)
	PPC_STORE_U32(r29.u32 + 32, r31.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
	// stw r10,20(r29)
	PPC_STORE_U32(r29.u32 + 20, ctx.r10.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r9,28(r29)
	PPC_STORE_U32(r29.u32 + 28, ctx.r9.u32);
	// stw r8,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r8.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83196038) {
	__imp__sub_83196038(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196098) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r5,16
	ctx.r5.s64 = 16;
	// li r4,52
	ctx.r4.s64 = 52;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83048e80
	sub_83048E80(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,12
	r11.s64 = 12;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83196098) {
	__imp__sub_83196098(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831960E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83195fe0
	sub_83195FE0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,10
	ctx.r5.s64 = 10;
	// li r4,80
	ctx.r4.s64 = 80;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83049360
	sub_83049360(ctx, base);
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,14
	r11.s64 = 14;
	// stw r29,24(r27)
	PPC_STORE_U32(r27.u32 + 24, r29.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,27
	ctx.r9.s64 = 27;
	// stw r11,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r11.u32);
	// stw r10,20(r27)
	PPC_STORE_U32(r27.u32 + 20, ctx.r10.u32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r9,28(r27)
	PPC_STORE_U32(r27.u32 + 28, ctx.r9.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r8,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r8.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x83196038
	sub_83196038(ctx, base);
	// stw r3,32(r27)
	PPC_STORE_U32(r27.u32 + 32, ctx.r3.u32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196038
	sub_83196038(ctx, base);
	// stw r3,36(r27)
	PPC_STORE_U32(r27.u32 + 36, ctx.r3.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831960E8) {
	__imp__sub_831960E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196180) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83195fe0
	sub_83195FE0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831960e8
	sub_831960E8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196098
	sub_83196098(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r30,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r30.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83196180) {
	__imp__sub_83196180(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831961D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mulli r29,r4,40
	r29.s64 = ctx.r4.s64 * 40;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// rlwinm r5,r11,29,18,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// bl 0x83195fe0
	sub_83195FE0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,10
	ctx.r5.s64 = 10;
	// li r4,80
	ctx.r4.s64 = 80;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83049360
	sub_83049360(ctx, base);
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,14
	r11.s64 = 14;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r11.u32);
	// li r9,19
	ctx.r9.s64 = 19;
	// stw r10,20(r27)
	PPC_STORE_U32(r27.u32 + 20, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r8,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r8.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// rlwinm r11,r11,29,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// stw r11,24(r27)
	PPC_STORE_U32(r27.u32 + 24, r11.u32);
	// stw r9,28(r27)
	PPC_STORE_U32(r27.u32 + 28, ctx.r9.u32);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// rlwinm r5,r11,29,18,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// bl 0x83196038
	sub_83196038(ctx, base);
	// stw r3,32(r27)
	PPC_STORE_U32(r27.u32 + 32, ctx.r3.u32);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// rlwinm r5,r11,29,18,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// bl 0x83196038
	sub_83196038(ctx, base);
	// stw r3,36(r27)
	PPC_STORE_U32(r27.u32 + 36, ctx.r3.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831961D8) {
	__imp__sub_831961D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196298) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x831963ac
	if (cr6.eq) goto loc_831963AC;
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// beq cr6,0x8319637c
	if (cr6.eq) goto loc_8319637C;
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// bne cr6,0x83196390
	if (!cr6.eq) goto loc_83196390;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// bl 0x83195760
	sub_83195760(ctx, base);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mulli r11,r3,40
	r11.s64 = ctx.r3.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,8
	cr6.compare<int32_t>(ctx.r10.s32, 8, xer);
	// bne cr6,0x8319631c
	if (!cr6.eq) goto loc_8319631C;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x83196390
	if (cr6.eq) goto loc_83196390;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// beq cr6,0x83196330
	if (cr6.eq) goto loc_83196330;
	// li r11,0
	r11.s64 = 0;
	// b 0x83196330
	goto loc_83196330;
loc_8319631C:
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x83196370
	if (cr0.eq) goto loc_83196370;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x83196370
	if (!cr6.eq) goto loc_83196370;
loc_83196330:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83196390
	if (cr6.eq) goto loc_83196390;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x83196360
	if (!cr6.eq) goto loc_83196360;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// rlwinm. r10,r10,0,21,21
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x83196358
	if (cr0.eq) goto loc_83196358;
loc_83196350:
	// lwz r3,32(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// b 0x831963b8
	goto loc_831963B8;
loc_83196358:
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// b 0x831963b8
	goto loc_831963B8;
loc_83196360:
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x83196390
	if (!cr6.eq) goto loc_83196390;
	// b 0x83196350
	goto loc_83196350;
loc_83196370:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319637C:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x831963a4
	if (cr6.lt) goto loc_831963A4;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// beq cr6,0x8319639c
	if (cr6.eq) goto loc_8319639C;
loc_83196390:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319639C:
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// b 0x831963b8
	goto loc_831963B8;
loc_831963A4:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831963b8
	goto loc_831963B8;
loc_831963AC:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mullw r3,r11,r10
	ctx.r3.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
loc_831963B8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83196298) {
	__imp__sub_83196298(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831963D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x831963f0
	if (!cr6.eq) goto loc_831963F0;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831963F0:
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x83196454
	if (!cr6.eq) goto loc_83196454;
	// li r30,0
	r30.s64 = 0;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
loc_83196404:
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8319641c
	if (cr6.eq) goto loc_8319641C;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83196298
	sub_83196298(ctx, base);
	// add r30,r3,r30
	r30.u64 = ctx.r3.u64 + r30.u64;
loc_8319641C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83196434
	if (cr6.eq) goto loc_83196434;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x83196448
	if (!cr6.eq) goto loc_83196448;
loc_83196434:
	// mr r31,r11
	r31.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x83196404
	if (!cr6.eq) goto loc_83196404;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x8319645c
	goto loc_8319645C;
loc_83196448:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_83196454:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83196298
	sub_83196298(ctx, base);
loc_8319645C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831963D0) {
	__imp__sub_831963D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196468) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831965ac
	if (cr6.eq) goto loc_831965AC;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831965ac
	if (!cr6.eq) goto loc_831965AC;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831964a4
	if (cr6.eq) goto loc_831964A4;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831964A4:
	// lwz r28,8(r4)
	r28.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831965a0
	if (cr6.eq) goto loc_831965A0;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r27,r11,20620
	r27.s64 = r11.s64 + 20620;
loc_831964BC:
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83195ee0
	sub_83195EE0(ctx, base);
	// lwz r11,40(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 40);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// rlwinm. r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83196594
	if (cr0.eq) goto loc_83196594;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// bne cr6,0x83196594
	if (!cr6.eq) goto loc_83196594;
	// lwz r11,48(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// bne cr6,0x83196594
	if (!cr6.eq) goto loc_83196594;
	// lwz r11,52(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 52);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x8319651c
	if (cr6.eq) goto loc_8319651C;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x8319651c
	if (cr6.eq) goto loc_8319651C;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// beq cr6,0x8319651c
	if (cr6.eq) goto loc_8319651C;
	// cmplwi cr6,r11,14
	cr6.compare<uint32_t>(r11.u32, 14, xer);
	// bne cr6,0x83196590
	if (!cr6.eq) goto loc_83196590;
loc_8319651C:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83196098
	sub_83196098(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// beq cr6,0x83196554
	if (cr6.eq) goto loc_83196554;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r5,12(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x83195ee0
	sub_83195EE0(ctx, base);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// b 0x8319658c
	goto loc_8319658C;
loc_83196554:
	// lwz r10,12(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// addi r11,r26,12
	r11.s64 = r26.s64 + 12;
	// mr r31,r26
	r31.u64 = r26.u64;
	// b 0x83196570
	goto loc_83196570;
loc_83196564:
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r31,12
	r11.s64 = r31.s64 + 12;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_83196570:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x83196564
	if (!cr6.eq) goto loc_83196564;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83195ee0
	sub_83195EE0(ctx, base);
loc_8319658C:
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
loc_83196590:
	// mr r31,r26
	r31.u64 = r26.u64;
loc_83196594:
	// lwz r28,12(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x831964bc
	if (!cr6.eq) goto loc_831964BC;
loc_831965A0:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_831965AC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_83196468) {
	__imp__sub_83196468(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831965B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// li r5,18
	ctx.r5.s64 = 18;
	// li r4,40
	ctx.r4.s64 = 40;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x830480c0
	sub_830480C0(ctx, base);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,9
	r11.s64 = 9;
	// stw r31,20(r28)
	PPC_STORE_U32(r28.u32 + 20, r31.u32);
	// li r10,1024
	ctx.r10.s64 = 1024;
	// stw r30,28(r28)
	PPC_STORE_U32(r28.u32 + 28, r30.u32);
	// stw r11,4(r28)
	PPC_STORE_U32(r28.u32 + 4, r11.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r29,32(r28)
	PPC_STORE_U32(r28.u32 + 32, r29.u32);
	// stw r9,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r9.u32);
	// stw r10,36(r28)
	PPC_STORE_U32(r28.u32 + 36, ctx.r10.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831965B8) {
	__imp__sub_831965B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196618) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// addi r10,r30,-16
	ctx.r10.s64 = r30.s64 + -16;
	// rlwinm. r9,r11,0,28,28
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// add r31,r3,r10
	r31.u64 = ctx.r3.u64 + ctx.r10.u64;
	// beq 0x83196660
	if (cr0.eq) goto loc_83196660;
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x83196764
	goto loc_83196764;
loc_83196660:
	// rlwinm. r10,r11,0,22,22
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x83196678
	if (cr0.eq) goto loc_83196678;
	// li r10,5
	ctx.r10.s64 = 5;
loc_8319666C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwimi r11,r10,3,23,31
	r11.u64 = (rotl32(ctx.r10.u32, 3) & 0x1FF) | (r11.u64 & 0xFFFFFFFFFFFFFE00);
	// b 0x8319676c
	goto loc_8319676C;
loc_83196678:
	// rlwinm. r10,r11,0,21,21
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831966b0
	if (cr0.eq) goto loc_831966B0;
	// lwz r4,12(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831966a8
	if (cr6.eq) goto loc_831966A8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r3,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r3.u32);
	// rlwimi r11,r10,0,30,31
	r11.u64 = (rotl32(ctx.r10.u32, 0) & 0x3) | (r11.u64 & 0xFFFFFFFFFFFFFFFC);
	// b 0x8319676c
	goto loc_8319676C;
loc_831966A8:
	// li r10,7
	ctx.r10.s64 = 7;
	// b 0x83196764
	goto loc_83196764;
loc_831966B0:
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831966c0
	if (cr0.eq) goto loc_831966C0;
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x8319666c
	goto loc_8319666C;
loc_831966C0:
	// rlwinm. r10,r11,0,26,26
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831966d0
	if (cr0.eq) goto loc_831966D0;
	// li r10,3
	ctx.r10.s64 = 3;
	// b 0x83196764
	goto loc_83196764;
loc_831966D0:
	// rlwinm. r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831966e8
	if (cr0.eq) goto loc_831966E8;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwimi r11,r10,4,23,31
	r11.u64 = (rotl32(ctx.r10.u32, 4) & 0x1FF) | (r11.u64 & 0xFFFFFFFFFFFFFE00);
	// b 0x8319676c
	goto loc_8319676C;
loc_831966E8:
	// rlwinm. r10,r11,0,24,24
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x83196700
	if (cr0.eq) goto loc_83196700;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwimi r11,r10,5,23,31
	r11.u64 = (rotl32(ctx.r10.u32, 5) & 0x1FF) | (r11.u64 & 0xFFFFFFFFFFFFFE00);
	// b 0x8319676c
	goto loc_8319676C;
loc_83196700:
	// rlwinm. r11,r11,0,23,23
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83196710
	if (cr0.eq) goto loc_83196710;
	// li r10,9
	ctx.r10.s64 = 9;
	// b 0x83196764
	goto loc_83196764;
loc_83196710:
	// lwz r10,52(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 52);
	// rlwinm. r11,r10,0,21,21
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83196730
	if (cr0.eq) goto loc_83196730;
	// lwz r9,4(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// rlwinm. r9,r9,0,28,28
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x83196730
	if (cr0.eq) goto loc_83196730;
	// li r10,33
	ctx.r10.s64 = 33;
	// b 0x83196764
	goto loc_83196764;
loc_83196730:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319674c
	if (cr6.eq) goto loc_8319674C;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319674c
	if (cr0.eq) goto loc_8319674C;
	// li r10,21
	ctx.r10.s64 = 21;
	// b 0x8319666c
	goto loc_8319666C;
loc_8319674C:
	// rlwinm. r11,r10,0,22,22
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83196770
	if (cr0.eq) goto loc_83196770;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83196770
	if (cr0.eq) goto loc_83196770;
	// li r10,39
	ctx.r10.s64 = 39;
loc_83196764:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwimi r11,r10,2,23,31
	r11.u64 = (rotl32(ctx.r10.u32, 2) & 0x1FF) | (r11.u64 & 0xFFFFFFFFFFFFFE00);
loc_8319676C:
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
loc_83196770:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83196618) {
	__imp__sub_83196618(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196778) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// addi r29,r30,16
	r29.s64 = r30.s64 + 16;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// bl 0x83123688
	sub_83123688(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,117
	ctx.r4.s64 = 117;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-16
	r11.s64 = r31.s64 + -16;
	// li r10,1
	ctx.r10.s64 = 1;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r27,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r27.u32);
	// rlwimi r9,r10,0,29,31
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 0) & 0x7) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFF8);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_83196778) {
	__imp__sub_83196778(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196828) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// lwz r11,744(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 744);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831968ec
	if (cr6.eq) goto loc_831968EC;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,117
	ctx.r6.s64 = 117;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r11.u32);
	// bl 0x83123688
	sub_83123688(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123688
	sub_83123688(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,117
	ctx.r4.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-16
	r11.s64 = r30.s64 + -16;
	// li r10,1
	ctx.r10.s64 = 1;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r28,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r28.u32);
	// rlwimi r9,r10,1,29,31
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 1) & 0x7) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFF8);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
loc_831968EC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_83196828) {
	__imp__sub_83196828(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831968F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lis r10,512
	ctx.r10.s64 = 33554432;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// rlwinm r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x83196928
	if (!cr6.eq) goto loc_83196928;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// beq cr6,0x83196990
	if (cr6.eq) goto loc_83196990;
loc_83196928:
	// lwz r5,12(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// ori r11,r31,228
	r11.u64 = r31.u64 | 228;
	// lis r10,1
	ctx.r10.s64 = 65536;
	// rlwinm r9,r11,27,29,30
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x6;
	// rlwinm r8,r11,29,29,30
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x6;
	// lwz r7,0(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r6,r11,31,29,30
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x6;
	// rlwinm r11,r11,1,29,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0x6;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// rlwinm r7,r7,27,24,31
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0xFF;
	// rlwinm r5,r5,0,27,18
	ctx.r5.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// srw r9,r7,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r7.u32 >> (ctx.r9.u8 & 0x3F));
	// srw r8,r7,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r7.u32 >> (ctx.r8.u8 & 0x3F));
	// rlwimi r10,r9,2,28,29
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 2) & 0xC) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFF3);
	// clrlwi r9,r8,30
	ctx.r9.u64 = ctx.r8.u32 & 0x3;
	// srw r8,r7,r6
	ctx.r8.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r7.u32 >> (ctx.r6.u8 & 0x3F));
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// srw r11,r7,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 >> (r11.u8 & 0x3F));
	// rlwimi r8,r10,2,0,29
	ctx.r8.u64 = (rotl32(ctx.r10.u32, 2) & 0xFFFFFFFC) | (ctx.r8.u64 & 0xFFFFFFFF00000003);
	// rlwinm r5,r5,0,6,3
	ctx.r5.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFFF3FFFFFF;
	// rlwimi r11,r8,2,0,29
	r11.u64 = (rotl32(ctx.r8.u32, 2) & 0xFFFFFFFC) | (r11.u64 & 0xFFFFFFFF00000003);
	// rlwinm r11,r11,5,0,26
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// or r11,r11,r5
	r11.u64 = r11.u64 | ctx.r5.u64;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
loc_83196990:
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831968F8) {
	__imp__sub_831968F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831969A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r11,r11,972
	r11.s64 = r11.s64 + 972;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831969A8) {
	__imp__sub_831969A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831969C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,88
	ctx.r6.s64 = 88;
	// addi r5,r31,32
	ctx.r5.s64 = r31.s64 + 32;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// oris r11,r11,16
	r11.u64 = r11.u64 | 1048576;
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x83196a18
	if (!cr6.eq) goto loc_83196A18;
	// stw r31,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r31.u32);
	// b 0x83196a40
	goto loc_83196A40;
loc_83196A18:
	// li r5,56
	ctx.r5.s64 = 56;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r3,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r3.u32);
loc_83196A40:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r5,24(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83196828
	sub_83196828(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831969C8) {
	__imp__sub_831969C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196A60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// clrlwi r11,r10,30
	r11.u64 = ctx.r10.u32 & 0x3;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x83196ab8
	if (cr6.lt) goto loc_83196AB8;
	// beq cr6,0x83196ab0
	if (cr6.eq) goto loc_83196AB0;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x83196a94
	if (cr6.lt) goto loc_83196A94;
	// beq cr6,0x83196afc
	if (cr6.eq) goto loc_83196AFC;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_83196A94:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r10,r10,31,17,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFE;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,27,24,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0xFF;
	// srw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi r3,r11,30
	ctx.r3.u64 = r11.u32 & 0x3;
	// b 0x83196b24
	goto loc_83196B24;
loc_83196AB0:
	// rlwinm r3,r10,30,18,31
	ctx.r3.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFF;
	// b 0x83196b24
	goto loc_83196B24;
loc_83196AB8:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x83196ac8
	if (cr0.eq) goto loc_83196AC8;
	// li r11,0
	r11.s64 = 0;
loc_83196AC8:
	// lwz r9,564(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 564);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x83196b04
	if (cr6.eq) goto loc_83196B04;
	// rlwinm r11,r10,15,17,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0x7FFF;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x83196afc
	if (!cr0.eq) goto loc_83196AFC;
	// lwz r11,44(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83196b04
	if (cr0.eq) goto loc_83196B04;
loc_83196AFC:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x83196b24
	goto loc_83196B24;
loc_83196B04:
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rlwinm r6,r11,30,18,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFF;
	// rlwinm r5,r11,15,17,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x7FFF;
	// bl 0x831d46c0
	sub_831D46C0(ctx, base);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r3,r11,30,18,31
	ctx.r3.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFF;
loc_83196B24:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83196A60) {
	__imp__sub_83196A60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196B38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r24,r7
	r24.u64 = ctx.r7.u64;
	// mr r29,r8
	r29.u64 = ctx.r8.u64;
	// mr r28,r9
	r28.u64 = ctx.r9.u64;
	// mr r25,r10
	r25.u64 = ctx.r10.u64;
	// li r31,2
	r31.s64 = 2;
	// bl 0x831968f8
	sub_831968F8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831968f8
	sub_831968F8(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x83196b9c
	if (cr6.eq) goto loc_83196B9C;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831968f8
	sub_831968F8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r31,3
	r31.s64 = 3;
loc_83196B9C:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x83196bbc
	if (cr6.eq) goto loc_83196BBC;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r5,244(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831968f8
	sub_831968F8(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_83196BBC:
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// bl 0x831cde60
	sub_831CDE60(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// li r28,2
	r28.s64 = 2;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x83196c10
	if (cr6.eq) goto loc_83196C10;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r3.u32);
	// li r28,3
	r28.s64 = 3;
loc_83196C10:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x83196c30
	if (cr6.eq) goto loc_83196C30;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// addi r11,r28,11
	r11.s64 = r28.s64 + 11;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r3,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r3.u32);
loc_83196C30:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_83196B38) {
	__imp__sub_83196B38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196C48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// mr r30,r8
	r30.u64 = ctx.r8.u64;
	// mr r25,r9
	r25.u64 = ctx.r9.u64;
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x83196ca4
	if (cr6.eq) goto loc_83196CA4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
loc_83196CA4:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x83196cc0
	if (cr6.eq) goto loc_83196CC0;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
loc_83196CC0:
	// lwz r11,260(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196b38
	sub_83196B38(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_83196C48) {
	__imp__sub_83196C48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196CF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,104
	ctx.r6.s64 = 104;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// rlwinm r8,r11,7,29,31
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 7) & 0x7;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r31,-4
	r11.s64 = r31.s64 + -4;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// oris r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 2097152;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// stw r11,44(r30)
	PPC_STORE_U32(r30.u32 + 44, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83196CF0) {
	__imp__sub_83196CF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196D78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
loc_83196D80:
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x83196da0
	if (cr6.lt) goto loc_83196DA0;
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
loc_83196DA0:
	// add r11,r9,r8
	r11.u64 = ctx.r9.u64 + ctx.r8.u64;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x83196dd4
	if (!cr6.eq) goto loc_83196DD4;
	// rlwinm r11,r10,0,0,30
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x83196dc8
	if (cr0.eq) goto loc_83196DC8;
	// li r11,0
	r11.s64 = 0;
loc_83196DC8:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_83196DD4:
	// subf. r4,r8,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r8.s64;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// bne 0x83196d80
	if (!cr0.eq) goto loc_83196D80;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83196D78) {
	__imp__sub_83196D78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196DE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r31{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// addi r11,r4,4
	r11.s64 = ctx.r4.s64 + 4;
	// clrlwi. r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x83196e38
	if (!cr0.eq) goto loc_83196E38;
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r8,r10,0,0,30
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// ori r7,r3,1
	ctx.r7.u64 = ctx.r3.u64 | 1;
	// ori r6,r4,1
	ctx.r6.u64 = ctx.r4.u64 | 1;
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r5,r11,1
	ctx.r5.u64 = r11.u64 | 1;
	// stw r9,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r9.u32);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r31,r9,0,0,30
	r31.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r8.u32);
	// stw r7,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r7.u32);
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// stw r6,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r6.u32);
	// stw r5,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r5.u32);
loc_83196E38:
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83196DE0) {
	__imp__sub_83196DE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196E40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r10,r4,3
	ctx.r10.s64 = ctx.r4.s64 + 3;
	// addi r11,r3,812
	r11.s64 = ctx.r3.s64 + 812;
	// rlwinm r4,r10,0,0,29
	ctx.r4.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// cmplwi cr6,r4,132
	cr6.compare<uint32_t>(ctx.r4.u32, 132, xer);
	// ble cr6,0x83196e70
	if (!cr6.gt) goto loc_83196E70;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x83110758
	sub_83110758(ctx, base);
	// b 0x83196edc
	goto loc_83196EDC;
loc_83196E70:
	// lwz r9,140(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 140);
	// lwz r10,144(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 144);
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// addi r9,r9,4096
	ctx.r9.s64 = ctx.r9.s64 + 4096;
	// cmplw cr6,r9,r4
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r4.u32, xer);
	// blt cr6,0x83196e94
	if (cr6.lt) goto loc_83196E94;
	// add r9,r10,r4
	ctx.r9.u64 = ctx.r10.u64 + ctx.r4.u64;
	// stw r9,144(r11)
	PPC_STORE_U32(r11.u32 + 144, ctx.r9.u32);
	// b 0x83196ed8
	goto loc_83196ED8;
loc_83196E94:
	// rlwinm r10,r4,30,2,31
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x83196ecc
	if (cr6.eq) goto loc_83196ECC;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// bl 0x82ca3190
	sub_82CA3190(ctx, base);
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// b 0x83196ed8
	goto loc_83196ED8;
loc_83196ECC:
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x8310fe28
	sub_8310FE28(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
loc_83196ED8:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
loc_83196EDC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83196E40) {
	__imp__sub_83196E40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196EF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,116
	ctx.r4.s64 = 116;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// addi r11,r3,16
	r11.s64 = ctx.r3.s64 + 16;
	// addi r10,r3,24
	ctx.r10.s64 = ctx.r3.s64 + 24;
	// addi r8,r11,4
	ctx.r8.s64 = r11.s64 + 4;
	// addi r6,r11,-36
	ctx.r6.s64 = r11.s64 + -36;
	// addi r11,r10,4
	r11.s64 = ctx.r10.s64 + 4;
	// addi r9,r3,32
	ctx.r9.s64 = ctx.r3.s64 + 32;
	// addi r5,r10,-36
	ctx.r5.s64 = ctx.r10.s64 + -36;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r6,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r6.u32);
	// addi r10,r9,4
	ctx.r10.s64 = ctx.r9.s64 + 4;
	// stw r8,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r8.u32);
	// addi r9,r9,-36
	ctx.r9.s64 = ctx.r9.s64 + -36;
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// ori r6,r5,1
	ctx.r6.u64 = ctx.r5.u64 | 1;
	// ori r11,r10,1
	r11.u64 = ctx.r10.u64 | 1;
	// ori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 | 1;
	// stw r6,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r6.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// li r7,1
	ctx.r7.s64 = 1;
	// stw r9,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, ctx.r9.u32);
	// lwz r10,76(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 76);
	// lwz r11,68(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 68);
	// rlwimi r11,r7,0,4,31
	r11.u64 = (rotl32(ctx.r7.u32, 0) & 0xFFFFFFF) | (r11.u64 & 0xFFFFFFFFF0000000);
	// stw r11,68(r3)
	PPC_STORE_U32(ctx.r3.u32 + 68, r11.u32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// rlwimi r11,r10,0,0,12
	r11.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFF80000) | (r11.u64 & 0xFFFFFFFF0007FFFF);
	// stw r11,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, r11.u32);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r10,r10,0,2,2
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x83196f98
	if (cr0.eq) goto loc_83196F98;
	// oris r11,r11,8
	r11.u64 = r11.u64 | 524288;
	// stw r11,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, r11.u32);
loc_83196F98:
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r3,0,0,30
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r8,r31,1
	ctx.r8.u64 = r31.u64 | 1;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83196EF0) {
	__imp__sub_83196EF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83196FD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,124
	ctx.r4.s64 = 124;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r11,r31,16
	r11.s64 = r31.s64 + 16;
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// addi r6,r11,-36
	ctx.r6.s64 = r11.s64 + -36;
	// addi r9,r31,32
	ctx.r9.s64 = r31.s64 + 32;
	// addi r8,r11,4
	ctx.r8.s64 = r11.s64 + 4;
	// addi r11,r10,4
	r11.s64 = ctx.r10.s64 + 4;
	// addi r5,r10,-36
	ctx.r5.s64 = ctx.r10.s64 + -36;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// addi r10,r9,4
	ctx.r10.s64 = ctx.r9.s64 + 4;
	// addi r9,r9,-36
	ctx.r9.s64 = ctx.r9.s64 + -36;
	// stw r6,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r6.u32);
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// ori r6,r5,1
	ctx.r6.u64 = ctx.r5.u64 | 1;
	// stw r8,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r8.u32);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// ori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 | 1;
	// stw r6,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r6.u32);
	// stw r10,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r10.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r9.u32);
	// ori r9,r30,1
	ctx.r9.u64 = r30.u64 | 1;
	// lwz r6,68(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// oris r8,r8,8
	ctx.r8.u64 = ctx.r8.u64 | 524288;
	// rlwimi r6,r7,0,4,31
	ctx.r6.u64 = (rotl32(ctx.r7.u32, 0) & 0xFFFFFFF) | (ctx.r6.u64 & 0xFFFFFFFFF0000000);
	// stw r8,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r8.u32);
	// stw r6,68(r31)
	PPC_STORE_U32(r31.u32 + 68, ctx.r6.u32);
	// stw r29,116(r31)
	PPC_STORE_U32(r31.u32 + 116, r29.u32);
	// lwz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// lwz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r8,r8,0,0,30
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// lwz r11,744(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 744);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// beq cr6,0x831970b4
	if (cr6.eq) goto loc_831970B4;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83196778
	sub_83196778(ctx, base);
loc_831970B4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83196FD8) {
	__imp__sub_83196FD8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831970C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83197114
	if (cr6.eq) goto loc_83197114;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197114:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x83197140
	if (cr6.eq) goto loc_83197140;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197140:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831970C0) {
	__imp__sub_831970C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831971B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83197204
	if (cr6.eq) goto loc_83197204;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197204:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x83197230
	if (cr6.eq) goto loc_83197230;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197230:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831971B0) {
	__imp__sub_831971B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831972A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,3
	ctx.r6.s64 = 3;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831972f4
	if (cr6.eq) goto loc_831972F4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831972F4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x83197320
	if (cr6.eq) goto loc_83197320;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197320:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831972A0) {
	__imp__sub_831972A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197390) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831973e4
	if (cr6.eq) goto loc_831973E4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831973E4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x83197410
	if (cr6.eq) goto loc_83197410;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197410:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83197390) {
	__imp__sub_83197390(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197480) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,5
	ctx.r6.s64 = 5;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831974d4
	if (cr6.eq) goto loc_831974D4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831974D4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x83197500
	if (cr6.eq) goto loc_83197500;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197500:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83197480) {
	__imp__sub_83197480(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197570) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,6
	ctx.r6.s64 = 6;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831975c4
	if (cr6.eq) goto loc_831975C4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831975C4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x831975f0
	if (cr6.eq) goto loc_831975F0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831975F0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83197570) {
	__imp__sub_83197570(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197660) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,7
	ctx.r6.s64 = 7;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831976b4
	if (cr6.eq) goto loc_831976B4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831976B4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x831976e0
	if (cr6.eq) goto loc_831976E0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831976E0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83197660) {
	__imp__sub_83197660(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197750) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,8
	ctx.r6.s64 = 8;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831977a4
	if (cr6.eq) goto loc_831977A4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831977A4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x831977d0
	if (cr6.eq) goto loc_831977D0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831977D0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83197750) {
	__imp__sub_83197750(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197840) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,9
	ctx.r6.s64 = 9;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83197890
	if (cr6.eq) goto loc_83197890;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197890:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83197840) {
	__imp__sub_83197840(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197900) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,10
	ctx.r6.s64 = 10;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83197950
	if (cr6.eq) goto loc_83197950;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197950:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83197900) {
	__imp__sub_83197900(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831979C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,11
	ctx.r6.s64 = 11;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83197a10
	if (cr6.eq) goto loc_83197A10;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197A10:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831979C0) {
	__imp__sub_831979C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197A80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,13
	ctx.r6.s64 = 13;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83197ad8
	if (cr6.eq) goto loc_83197AD8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197AD8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x83197b04
	if (cr6.eq) goto loc_83197B04;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197B04:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// beq cr6,0x83197b30
	if (cr6.eq) goto loc_83197B30;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197B30:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_83197A80) {
	__imp__sub_83197A80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197BA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,16
	ctx.r6.s64 = 16;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83197bf4
	if (cr6.eq) goto loc_83197BF4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197BF4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x83197c20
	if (cr6.eq) goto loc_83197C20;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197C20:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// rlwimi r10,r9,14,15,17
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 14) & 0x1C000) | (ctx.r10.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r8,r10,-36
	ctx.r8.s64 = ctx.r10.s64 + -36;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r9,r11,-36
	ctx.r9.s64 = r11.s64 + -36;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83197BA0) {
	__imp__sub_83197BA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197C88) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,19
	ctx.r6.s64 = 19;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83197cdc
	if (cr6.eq) goto loc_83197CDC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197CDC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x83197d08
	if (cr6.eq) goto loc_83197D08;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197D08:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83197C88) {
	__imp__sub_83197C88(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197D60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,20
	ctx.r6.s64 = 20;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83197db0
	if (cr6.eq) goto loc_83197DB0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197DB0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// rlwimi r10,r9,14,15,17
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 14) & 0x1C000) | (ctx.r10.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r8,r10,-36
	ctx.r8.s64 = ctx.r10.s64 + -36;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r9,r11,-36
	ctx.r9.s64 = r11.s64 + -36;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83197D60) {
	__imp__sub_83197D60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197E18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,26
	ctx.r6.s64 = 26;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83197e6c
	if (cr6.eq) goto loc_83197E6C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197E6C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x83197e98
	if (cr6.eq) goto loc_83197E98;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197E98:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83197E18) {
	__imp__sub_83197E18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197F08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,29
	ctx.r6.s64 = 29;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83197f5c
	if (cr6.eq) goto loc_83197F5C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197F5C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x83197f88
	if (cr6.eq) goto loc_83197F88;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83197F88:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83197F08) {
	__imp__sub_83197F08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83197FE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,30
	ctx.r6.s64 = 30;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83198034
	if (cr6.eq) goto loc_83198034;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83198034:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x83198060
	if (cr6.eq) goto loc_83198060;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83198060:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83197FE0) {
	__imp__sub_83197FE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831980B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,46
	ctx.r6.s64 = 46;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83198108
	if (cr6.eq) goto loc_83198108;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83198108:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831980B8) {
	__imp__sub_831980B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198160) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,51
	ctx.r6.s64 = 51;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831981b0
	if (cr6.eq) goto loc_831981B0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831981B0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83198160) {
	__imp__sub_83198160(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198208) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,55
	ctx.r6.s64 = 55;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83198258
	if (cr6.eq) goto loc_83198258;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83198258:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83198208) {
	__imp__sub_83198208(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831982B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,72
	ctx.r6.s64 = 72;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83198300
	if (cr6.eq) goto loc_83198300;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83198300:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831982B0) {
	__imp__sub_831982B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198358) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,80
	ctx.r6.s64 = 80;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831983a8
	if (cr6.eq) goto loc_831983A8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831983A8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83198358) {
	__imp__sub_83198358(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198400) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,81
	ctx.r6.s64 = 81;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83198450
	if (cr6.eq) goto loc_83198450;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83198450:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83198400) {
	__imp__sub_83198400(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831984A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,98
	ctx.r6.s64 = 98;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831984f8
	if (cr6.eq) goto loc_831984F8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831984F8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831984A8) {
	__imp__sub_831984A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198550) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,100
	ctx.r6.s64 = 100;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831985a4
	if (cr6.eq) goto loc_831985A4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831985A4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// beq cr6,0x831985d0
	if (cr6.eq) goto loc_831985D0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831985D0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83198550) {
	__imp__sub_83198550(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198628) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,101
	ctx.r6.s64 = 101;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83198678
	if (cr6.eq) goto loc_83198678;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83198678:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83198628) {
	__imp__sub_83198628(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831986D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,102
	ctx.r6.s64 = 102;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83198720
	if (cr6.eq) goto loc_83198720;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83198720:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831986D0) {
	__imp__sub_831986D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198778) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831987e8
	if (cr6.eq) goto loc_831987E8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831987E8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83198778) {
	__imp__sub_83198778(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198858) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831988c8
	if (cr6.eq) goto loc_831988C8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831988C8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83198858) {
	__imp__sub_83198858(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198938) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831989a8
	if (cr6.eq) goto loc_831989A8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831989A8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83198938) {
	__imp__sub_83198938(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198A18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,5
	ctx.r6.s64 = 5;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83198a88
	if (cr6.eq) goto loc_83198A88;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83198A88:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83198A18) {
	__imp__sub_83198A18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198AF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,7
	ctx.r6.s64 = 7;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83198b68
	if (cr6.eq) goto loc_83198B68;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83198B68:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83198AF8) {
	__imp__sub_83198AF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198BD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,9
	ctx.r6.s64 = 9;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r9,r9,7,29,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0x7;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r11,r29,0,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// rlwimi r10,r9,14,15,17
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 14) & 0x1C000) | (ctx.r10.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r10,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r10.u32);
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83198BD8) {
	__imp__sub_83198BD8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198C80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,46
	ctx.r6.s64 = 46;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r29,0,0,30
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83198C80) {
	__imp__sub_83198C80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198D18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,48
	ctx.r6.s64 = 48;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r29,0,0,30
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83198D18) {
	__imp__sub_83198D18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198DB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,51
	ctx.r6.s64 = 51;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r29,0,0,30
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83198DB0) {
	__imp__sub_83198DB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198E48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,54
	ctx.r6.s64 = 54;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r29,0,0,30
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83198E48) {
	__imp__sub_83198E48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198EE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,72
	ctx.r6.s64 = 72;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r29,0,0,30
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83198EE0) {
	__imp__sub_83198EE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83198F78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83198fcc
	if (cr6.eq) goto loc_83198FCC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83198FCC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83198F78) {
	__imp__sub_83198F78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83199058) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831990ac
	if (cr6.eq) goto loc_831990AC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831990AC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83199058) {
	__imp__sub_83199058(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83199138) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,6
	ctx.r6.s64 = 6;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319918c
	if (cr6.eq) goto loc_8319918C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319918C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83199138) {
	__imp__sub_83199138(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83199218) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,7
	ctx.r6.s64 = 7;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319926c
	if (cr6.eq) goto loc_8319926C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319926C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83199218) {
	__imp__sub_83199218(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831992F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,17
	ctx.r6.s64 = 17;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319934c
	if (cr6.eq) goto loc_8319934C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319934C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// rlwimi r10,r9,14,15,17
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 14) & 0x1C000) | (ctx.r10.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r8,r10,-36
	ctx.r8.s64 = ctx.r10.s64 + -36;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r9,r11,-36
	ctx.r9.s64 = r11.s64 + -36;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831992F8) {
	__imp__sub_831992F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831993D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831993D0) {
	__imp__sub_831993D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831994A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831994A0) {
	__imp__sub_831994A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83199570) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,5
	ctx.r6.s64 = 5;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83199570) {
	__imp__sub_83199570(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83199640) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,14
	ctx.r6.s64 = 14;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x831996d0
	if (cr6.eq) goto loc_831996D0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831996D0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_83199640) {
	__imp__sub_83199640(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83199740) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// std r4,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r4.u64);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r3,48(r30)
	PPC_STORE_U32(r30.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r30)
	PPC_STORE_U32(r30.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_83199740) {
	__imp__sub_83199740(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83199828) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// std r6,152(r1)
	PPC_STORE_U64(ctx.r1.u32 + 152, ctx.r6.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,13
	ctx.r6.s64 = 13;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x83199880
	if (cr6.eq) goto loc_83199880;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83199880:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// addi r4,r1,152
	ctx.r4.s64 = ctx.r1.s64 + 152;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_83199828) {
	__imp__sub_83199828(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83199928) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x83199964
	if (!cr6.eq) goto loc_83199964;
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x83110880
	sub_83110880(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
loc_83199964:
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// rlwinm r30,r28,2,0,29
	r30.u64 = rotl64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319999c
	if (!cr6.eq) goto loc_8319999C;
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mulli r10,r28,40
	ctx.r10.s64 = r28.s64 * 40;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r4,r11,0,15,28
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1FFF8;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83110880
	sub_83110880(ctx, base);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// stwx r3,r30,r11
	PPC_STORE_U32(r30.u32 + r11.u32, ctx.r3.u32);
loc_8319999C:
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// lwzx r3,r30,r11
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_83199928) {
	__imp__sub_83199928(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831999B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,5
	ctx.r4.s64 = 5;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83196e40
	sub_83196E40(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r5,r11,-17752
	ctx.r5.s64 = r11.s64 + -17752;
	// extsb r6,r30
	ctx.r6.s64 = r30.s8;
	// li r4,5
	ctx.r4.s64 = 5;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,14
	ctx.r5.s64 = 14;
	// li r4,32
	ctx.r4.s64 = 32;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83049ea0
	sub_83049EA0(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,18
	r11.s64 = 18;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// bl 0x83195e00
	sub_83195E00(ctx, base);
	// stw r3,20(r30)
	PPC_STORE_U32(r30.u32 + 20, ctx.r3.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831999B0) {
	__imp__sub_831999B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83199A38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// cmplwi cr6,r4,15
	cr6.compare<uint32_t>(ctx.r4.u32, 15, xer);
	// bge cr6,0x83199ad8
	if (!cr6.lt) goto loc_83199AD8;
	// lis r11,-31952
	r11.s64 = -2094006272;
	// rlwinm r28,r4,2,0,29
	r28.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r29,r11,14420
	r29.s64 = r11.s64 + 14420;
	// lwzx r11,r28,r29
	r11.u64 = PPC_LOAD_U32(r28.u32 + r29.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83199ad8
	if (cr6.eq) goto loc_83199AD8;
	// cmplwi cr6,r27,9
	cr6.compare<uint32_t>(r27.u32, 9, xer);
	// bgt cr6,0x83199ad8
	if (cr6.gt) goto loc_83199AD8;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_83199A78:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x83199a78
	if (!cr6.eq) goto loc_83199A78;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// addi r31,r11,2
	r31.s64 = r11.s64 + 2;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x83196e40
	sub_83196E40(ctx, base);
	// lis r11,-32244
	r11.s64 = -2113142784;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// lwzx r6,r28,r29
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + r29.u32);
	// addi r5,r11,1876
	ctx.r5.s64 = r11.s64 + 1876;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83195e00
	sub_83195E00(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_83199AD8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_83199A38) {
	__imp__sub_83199A38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83199AE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bbc
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r17,-1
	r17.s64 = -65536;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r22,r5
	r22.u64 = ctx.r5.u64;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// mr r23,r8
	r23.u64 = ctx.r8.u64;
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// mr r18,r9
	r18.u64 = ctx.r9.u64;
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// beq cr6,0x83199b34
	if (cr6.eq) goto loc_83199B34;
	// lis r11,-31952
	r11.s64 = -2094006272;
	// li r28,19
	r28.s64 = 19;
	// addi r20,r11,13896
	r20.s64 = r11.s64 + 13896;
	// b 0x83199b40
	goto loc_83199B40;
loc_83199B34:
	// lis r11,-31952
	r11.s64 = -2094006272;
	// li r28,3
	r28.s64 = 3;
	// addi r20,r11,14048
	r20.s64 = r11.s64 + 14048;
loc_83199B40:
	// li r21,0
	r21.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x83199c38
	if (cr6.eq) goto loc_83199C38;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r30,r20,4
	r30.s64 = r20.s64 + 4;
	// li r19,1
	r19.s64 = 1;
	// addi r27,r11,3164
	r27.s64 = r11.s64 + 3164;
	// addi r29,r10,-15496
	r29.s64 = ctx.r10.s64 + -15496;
loc_83199B64:
	// cmpwi cr6,r25,-1
	cr6.compare<int32_t>(r25.s32, -1, xer);
	// bne cr6,0x83199b88
	if (!cr6.eq) goto loc_83199B88;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r4,-4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + -4);
	// rlwinm r5,r11,4,28,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 4) & 0xF;
	// bl 0x82cab438
	sub_82CAB438(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x83199b98
	if (cr0.eq) goto loc_83199B98;
loc_83199B88:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,20,28,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// bne cr6,0x83199c28
	if (!cr6.eq) goto loc_83199C28;
loc_83199B98:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x83199c10
	if (cr6.eq) goto loc_83199C10;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r5,10
	ctx.r5.s64 = 10;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r11,4,28,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 4) & 0xF;
	// add r3,r11,r24
	ctx.r3.u64 = r11.u64 + r24.u64;
	// bl 0x82ca6300
	sub_82CA6300(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r22,r3,r26
	r22.u64 = ctx.r3.u64 + r26.u64;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x83199c10
	if (cr6.eq) goto loc_83199C10;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r10,r10,0,10,12
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x380000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x83199c38
	if (!cr0.eq) goto loc_83199C38;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x83199c10
	if (cr0.eq) goto loc_83199C10;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x83199c38
	if (!cr0.eq) goto loc_83199C38;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83199c10
	if (cr6.eq) goto loc_83199C10;
	// stw r19,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r19.u32);
loc_83199C10:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r10,13,29,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 13) & 0x7;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r6,r10,10,26,31
	ctx.r6.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x3F;
	// beq 0x83199cc0
	if (cr0.eq) goto loc_83199CC0;
	// cmplw cr6,r22,r11
	cr6.compare<uint32_t>(r22.u32, r11.u32, xer);
	// blt cr6,0x83199c44
	if (cr6.lt) goto loc_83199C44;
loc_83199C28:
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// cmplw cr6,r21,r28
	cr6.compare<uint32_t>(r21.u32, r28.u32, xer);
	// blt cr6,0x83199b64
	if (cr6.lt) goto loc_83199B64;
loc_83199C38:
	// li r3,0
	ctx.r3.s64 = 0;
loc_83199C3C:
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// b 0x82ca2c0c
	return;
loc_83199C44:
	// rlwinm r11,r21,3,0,28
	r11.u64 = rotl64(r21.u32 | (r21.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r20
	r11.u64 = r11.u64 + r20.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r10,24,28,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83199c6c
	if (cr0.eq) goto loc_83199C6C;
	// rlwinm r9,r10,16,29,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0x7;
	// cmplw cr6,r23,r9
	cr6.compare<uint32_t>(r23.u32, ctx.r9.u32, xer);
	// beq cr6,0x83199c74
	if (cr6.eq) goto loc_83199C74;
	// rlwinm r3,r10,20,25,27
	ctx.r3.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0x70;
	// b 0x83199c3c
	goto loc_83199C3C;
loc_83199C6C:
	// slw r11,r19,r23
	r11.u64 = r23.u8 & 0x20 ? 0 : (r19.u32 << (r23.u8 & 0x3F));
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
loc_83199C74:
	// add r9,r6,r22
	ctx.r9.u64 = ctx.r6.u64 + r22.u64;
	// lwz r7,336(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwimi r11,r9,4,0,27
	r11.u64 = (rotl32(ctx.r9.u32, 4) & 0xFFFFFFF0) | (r11.u64 & 0xFFFFFFFF0000000F);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// mr r30,r11
	r30.u64 = r11.u64;
	// beq cr6,0x83199d30
	if (cr6.eq) goto loc_83199D30;
	// addi r11,r31,128
	r11.s64 = r31.s64 + 128;
loc_83199C94:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r9,r30
	cr6.compare<uint32_t>(ctx.r9.u32, r30.u32, xer);
	// beq cr6,0x83199cb8
	if (cr6.eq) goto loc_83199CB8;
	// lwz r9,336(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x83199c94
	if (cr6.lt) goto loc_83199C94;
	// b 0x83199d30
	goto loc_83199D30;
loc_83199CB8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x83199c3c
	goto loc_83199C3C;
loc_83199CC0:
	// lwz r7,336(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x83199d14
	if (cr6.eq) goto loc_83199D14;
	// addi r8,r31,124
	ctx.r8.s64 = r31.s64 + 124;
loc_83199CD4:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r10,r11,27,28,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0xF;
	// cmplw cr6,r10,r22
	cr6.compare<uint32_t>(ctx.r10.u32, r22.u32, xer);
	// bne cr6,0x83199d00
	if (!cr6.eq) goto loc_83199D00;
	// rlwinm r10,r21,3,0,28
	ctx.r10.u64 = rotl64(r21.u32 | (r21.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r20
	ctx.r10.u64 = ctx.r10.u64 + r20.u64;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,20,28,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xF;
	// xor r11,r10,r11
	r11.u64 = ctx.r10.u64 ^ r11.u64;
	// clrlwi. r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83199ec0
	if (cr0.eq) goto loc_83199EC0;
loc_83199D00:
	// lwz r11,336(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r8,r8,12
	ctx.r8.s64 = ctx.r8.s64 + 12;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x83199cd4
	if (cr6.lt) goto loc_83199CD4;
loc_83199D14:
	// lwz r11,340(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 340);
	// slw r10,r19,r23
	ctx.r10.u64 = r23.u8 & 0x20 ? 0 : (r19.u32 << (r23.u8 & 0x3F));
	// add r9,r11,r6
	ctx.r9.u64 = r11.u64 + ctx.r6.u64;
	// addi r30,r10,-1
	r30.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwimi r30,r9,4,0,27
	r30.u64 = (rotl32(ctx.r9.u32, 4) & 0xFFFFFFF0) | (r30.u64 & 0xFFFFFFFF0000000F);
	// stw r11,340(r31)
	PPC_STORE_U32(r31.u32 + 340, r11.u32);
loc_83199D30:
	// cmplwi cr6,r7,18
	cr6.compare<uint32_t>(ctx.r7.u32, 18, xer);
	// beq cr6,0x83199c38
	if (cr6.eq) goto loc_83199C38;
	// rlwinm r11,r21,3,0,28
	r11.u64 = rotl64(r21.u32 | (r21.u64 << 32), 3) & 0xFFFFFFF8;
	// add r29,r11,r20
	r29.u64 = r11.u64 + r20.u64;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwinm. r11,r11,0,24,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83199d5c
	if (cr0.eq) goto loc_83199D5C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x83199d5c
	if (cr6.eq) goto loc_83199D5C;
	// stw r19,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r19.u32);
loc_83199D5C:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x83199de8
	if (!cr6.eq) goto loc_83199DE8;
	// lwz r24,0(r29)
	r24.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x83199de8
	if (cr6.eq) goto loc_83199DE8;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// addi r5,r11,1876
	ctx.r5.s64 = r11.s64 + 1876;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// li r4,100
	ctx.r4.s64 = 100;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_83199D94:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x83199d94
	if (!cr6.eq) goto loc_83199D94;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r4,r11,0,0,29
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFC;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// subf r10,r10,r24
	ctx.r10.s64 = r24.s64 - ctx.r10.s64;
loc_83199DD4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// stbx r9,r10,r11
	PPC_STORE_U8(ctx.r10.u32 + r11.u32, ctx.r9.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne 0x83199dd4
	if (!cr0.eq) goto loc_83199DD4;
loc_83199DE8:
	// lwz r11,336(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// clrlwi r10,r18,24
	ctx.r10.u64 = r18.u32 & 0xFF;
	// addi r11,r11,10
	r11.s64 = r11.s64 + 10;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// stwx r24,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, r24.u32);
	// lwz r11,336(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// stw r30,128(r11)
	PPC_STORE_U32(r11.u32 + 128, r30.u32);
	// lwz r9,4(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// lwz r11,336(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// rlwinm r9,r9,20,28,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 20) & 0xF;
	// lwz r8,124(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 124);
	// rlwinm r8,r8,0,0,26
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFE0;
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// stw r9,124(r11)
	PPC_STORE_U32(r11.u32 + 124, ctx.r9.u32);
	// lwz r11,336(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lwz r9,124(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 124);
	// rlwimi r9,r22,5,23,26
	ctx.r9.u64 = (rotl32(r22.u32, 5) & 0x1E0) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFE1F);
	// stw r9,124(r11)
	PPC_STORE_U32(r11.u32 + 124, ctx.r9.u32);
	// lwz r11,336(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lwz r9,124(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 124);
	// rlwimi r9,r10,18,13,13
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 18) & 0x40000) | (ctx.r9.u64 & 0xFFFFFFFFFFFBFFFF);
	// stw r9,124(r11)
	PPC_STORE_U32(r11.u32 + 124, ctx.r9.u32);
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x83199eac
	if (cr0.eq) goto loc_83199EAC;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// beq cr6,0x83199eac
	if (cr6.eq) goto loc_83199EAC;
	// rlwinm r11,r30,0,0,27
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplwi cr6,r11,992
	cr6.compare<uint32_t>(r11.u32, 992, xer);
	// bne cr6,0x83199eac
	if (!cr6.eq) goto loc_83199EAC;
	// lwz r11,336(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lwz r10,124(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 124);
	// oris r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 262144;
	// stw r10,124(r11)
	PPC_STORE_U32(r11.u32 + 124, ctx.r10.u32);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// ori r11,r11,32768
	r11.u64 = r11.u64 | 32768;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
loc_83199EAC:
	// lwz r11,336(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,336(r31)
	PPC_STORE_U32(r31.u32 + 336, r11.u32);
	// b 0x83199c3c
	goto loc_83199C3C;
loc_83199EC0:
	// mulli r11,r9,12
	r11.s64 = ctx.r9.s64 * 12;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lwz r3,128(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 128);
	// b 0x83199c3c
	goto loc_83199C3C;
}

PPC_WEAK_FUNC(sub_83199AE8) {
	__imp__sub_83199AE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_83199ED0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r22,r6
	r22.u64 = ctx.r6.u64;
	// mr r23,r7
	r23.u64 = ctx.r7.u64;
	// mr r26,r8
	r26.u64 = ctx.r8.u64;
	// mr r25,r9
	r25.u64 = ctx.r9.u64;
	// mr r24,r10
	r24.u64 = ctx.r10.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x83199f20
	if (cr6.eq) goto loc_83199F20;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_83199F08:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x83199f08
	if (!cr6.eq) goto loc_83199F08;
	// subf r11,r28,r11
	r11.s64 = r11.s64 - r28.s64;
	// b 0x83199f44
	goto loc_83199F44;
loc_83199F20:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831954f8
	sub_831954F8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_83199F30:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x83199f30
	if (!cr6.eq) goto loc_83199F30;
	// subf r11,r11,r3
	r11.s64 = ctx.r3.s64 - r11.s64;
loc_83199F44:
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// li r5,0
	ctx.r5.s64 = 0;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r29,r11,1
	r29.s64 = r11.s64 + 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x83196e40
	sub_83196E40(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x83199f74
	if (cr6.eq) goto loc_83199F74;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// b 0x83199f84
	goto loc_83199F84;
loc_83199F74:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831954f8
	sub_831954F8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_83199F84:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831965b8
	sub_831965B8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r5,20
	ctx.r5.s64 = 20;
	// li r4,88
	ctx.r4.s64 = 88;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x830488a8
	sub_830488A8(ctx, base);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,11
	r11.s64 = 11;
	// stw r27,16(r28)
	PPC_STORE_U32(r28.u32 + 16, r27.u32);
	// mullw r10,r26,r25
	ctx.r10.s64 = int64_t(r26.s32) * int64_t(r25.s32);
	// stw r29,48(r28)
	PPC_STORE_U32(r28.u32 + 48, r29.u32);
	// stw r11,4(r28)
	PPC_STORE_U32(r28.u32 + 4, r11.u32);
	// stw r10,20(r28)
	PPC_STORE_U32(r28.u32 + 20, ctx.r10.u32);
	// stw r9,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r9.u32);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// bl 0x83195e78
	sub_83195E78(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8319a020
	if (cr6.eq) goto loc_8319A020;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lwz r5,0(r24)
	ctx.r5.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r6,r11,20620
	ctx.r6.s64 = r11.s64 + 20620;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83195ee0
	sub_83195EE0(ctx, base);
	// stw r3,0(r24)
	PPC_STORE_U32(r24.u32 + 0, ctx.r3.u32);
loc_8319A020:
	// addi r11,r27,1
	r11.s64 = r27.s64 + 1;
	// add r8,r27,r22
	ctx.r8.u64 = r27.u64 + r22.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bge cr6,0x8319a06c
	if (!cr6.lt) goto loc_8319A06C;
	// mulli r10,r11,40
	ctx.r10.s64 = r11.s64 * 40;
loc_8319A034:
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// clrlwi. r9,r9,29
	ctx.r9.u64 = ctx.r9.u32 & 0x7;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8319a078
	if (!cr0.eq) goto loc_8319A078;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r7,5
	ctx.r7.s64 = 5;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// addi r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 + 40;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// lwz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwimi r6,r7,0,29,31
	ctx.r6.u64 = (rotl32(ctx.r7.u32, 0) & 0x7) | (ctx.r6.u64 & 0xFFFFFFFFFFFFFFF8);
	// stw r6,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r6.u32);
	// blt cr6,0x8319a034
	if (cr6.lt) goto loc_8319A034;
loc_8319A06C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82ca2c20
	return;
loc_8319A078:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_83199ED0) {
	__imp__sub_83199ED0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319A088) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// mr r26,r9
	r26.u64 = ctx.r9.u64;
	// rlwinm r25,r7,28,4,31
	r25.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 28) & 0xFFFFFFF;
	// clrlwi r24,r7,28
	r24.u64 = ctx.r7.u32 & 0xF;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x8319a178
	if (cr6.eq) goto loc_8319A178;
	// addic. r11,r6,1
	xer.ca = ctx.r6.u32 > 4294967294;
	r11.s64 = ctx.r6.s64 + 1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319a0d0
	if (cr0.eq) goto loc_8319A0D0;
	// addi r9,r11,-1
	ctx.r9.s64 = r11.s64 + -1;
	// andc r9,r11,r9
	ctx.r9.u64 = r11.u64 & ~ctx.r9.u64;
	// subf. r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x8319a0d4
	if (cr0.eq) goto loc_8319A0D4;
loc_8319A0D0:
	// li r11,0
	r11.s64 = 0;
loc_8319A0D4:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319a178
	if (cr0.eq) goto loc_8319A178;
	// cntlzw r11,r6
	r11.u64 = ctx.r6.u32 == 0 ? 32 : __builtin_clz(ctx.r6.u32);
	// addi r29,r27,608
	r29.s64 = r27.s64 + 608;
	// subfic r28,r11,32
	xer.ca = r11.u32 <= 32;
	r28.s64 = 32 - r11.s64;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// li r7,12
	ctx.r7.s64 = 12;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199ed0
	sub_83199ED0(ctx, base);
	// lwz r30,24(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8319a16c
	if (cr6.eq) goto loc_8319A16C;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x8319a16c
	if (!cr6.eq) goto loc_8319A16C;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199a38
	sub_83199A38(ctx, base);
	// stw r3,60(r30)
	PPC_STORE_U32(r30.u32 + 60, ctx.r3.u32);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196180
	sub_83196180(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r5,0(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// addi r6,r11,20620
	ctx.r6.s64 = r11.s64 + 20620;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83195ee0
	sub_83195EE0(ctx, base);
	// stw r3,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r3.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
loc_8319A16C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319A178:
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_8319A088) {
	__imp__sub_8319A088(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319A188) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x8319a244
	if (cr6.eq) goto loc_8319A244;
	// addic. r11,r6,1
	xer.ca = ctx.r6.u32 > 4294967294;
	r11.s64 = ctx.r6.s64 + 1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319a1c8
	if (cr0.eq) goto loc_8319A1C8;
	// addi r9,r11,-1
	ctx.r9.s64 = r11.s64 + -1;
	// andc r9,r11,r9
	ctx.r9.u64 = r11.u64 & ~ctx.r9.u64;
	// subf. r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x8319a1cc
	if (cr0.eq) goto loc_8319A1CC;
loc_8319A1C8:
	// li r11,0
	r11.s64 = 0;
loc_8319A1CC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319a244
	if (cr0.eq) goto loc_8319A244;
	// cntlzw r11,r6
	r11.u64 = ctx.r6.u32 == 0 ? 32 : __builtin_clz(ctx.r6.u32);
	// li r8,1
	ctx.r8.s64 = 1;
	// subfic r9,r11,32
	xer.ca = r11.u32 <= 32;
	ctx.r9.s64 = 32 - r11.s64;
	// li r7,12
	ctx.r7.s64 = 12;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r5,624
	ctx.r5.s64 = ctx.r5.s64 + 624;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83199ed0
	sub_83199ED0(ctx, base);
	// lwz r31,24(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8319a238
	if (cr6.eq) goto loc_8319A238;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x8319a238
	if (!cr6.eq) goto loc_8319A238;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// ori r11,r11,32
	r11.u64 = r11.u64 | 32;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// bl 0x83199a38
	sub_83199A38(ctx, base);
	// stw r3,60(r31)
	PPC_STORE_U32(r31.u32 + 60, ctx.r3.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_8319A238:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319A244:
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_8319A188) {
	__imp__sub_8319A188(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319A258) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,756(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 756);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319a290
	if (!cr6.eq) goto loc_8319A290;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,40
	ctx.r4.s64 = 40;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// li r11,10
	r11.s64 = 10;
	// stw r3,756(r31)
	PPC_STORE_U32(r31.u32 + 756, ctx.r3.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// b 0x8319a2e8
	goto loc_8319A2E8;
loc_8319A290:
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r30,0(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r10,1
	r11.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// blt cr6,0x8319a2e8
	if (cr6.lt) goto loc_8319A2E8;
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r4,r30,3,0,28
	ctx.r4.u64 = rotl64(r30.u32 | (r30.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r29,r30,1,0,30
	r29.u64 = rotl64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// rlwinm r30,r30,2,0,29
	r30.u64 = rotl64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,756(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 756);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// stw r29,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r29.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,756(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 756);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831104e0
	sub_831104E0(ctx, base);
	// stw r28,756(r31)
	PPC_STORE_U32(r31.u32 + 756, r28.u32);
loc_8319A2E8:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r10,756(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 756);
	// lwz r9,752(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 752);
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319A258) {
	__imp__sub_8319A258(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319A308) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// li r22,0
	r22.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r25,r22
	r25.u64 = r22.u64;
	// stw r22,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r22.u32);
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r20,r22
	r20.u64 = r22.u64;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// rlwinm. r11,r11,0,4,17
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFC000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r23,r22
	r23.u64 = r22.u64;
	// beq 0x8319a524
	if (cr0.eq) goto loc_8319A524;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r21,r27,12
	r21.s64 = r27.s64 + 12;
	// lfs f31,3084(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f31.f64 = double(temp.f32);
loc_8319A358:
	// ld r31,0(r21)
	r31.u64 = PPC_LOAD_U64(r21.u32 + 0);
	// std r31,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r31.u64);
	// lwz r28,92(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// clrlwi r11,r28,30
	r11.u64 = r28.u32 & 0x3;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8319a3e8
	if (!cr6.eq) goto loc_8319A3E8;
	// rlwinm. r11,r28,16,31,31
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 16) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319a3e8
	if (cr0.eq) goto loc_8319A3E8;
	// lwz r31,88(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x8319a390
	if (cr6.eq) goto loc_8319A390;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplw cr6,r20,r11
	cr6.compare<uint32_t>(r20.u32, r11.u32, xer);
	// beq cr6,0x8319a3c0
	if (cr6.eq) goto loc_8319A3C0;
loc_8319A390:
	// ld r11,0(r31)
	r11.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// bl 0x83199740
	sub_83199740(ctx, base);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lwz r20,104(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// rlwinm r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// stw r3,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r3.u32);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
loc_8319A3C0:
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// ld r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319a308
	sub_8319A308(ctx, base);
	// rlwinm r11,r28,0,15,15
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0x10000;
	// stw r3,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r3.u32);
	// ori r28,r11,1
	r28.u64 = r11.u64 | 1;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// ld r31,88(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
loc_8319A3E8:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8319a4fc
	if (cr6.eq) goto loc_8319A4FC;
	// clrldi r11,r26,32
	r11.u64 = r26.u64 & 0xFFFFFFFF;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fneg f1,f0
	ctx.f1.u64 = f0.u64 ^ 0x8000000000000000;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// ld r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x83199740
	sub_83199740(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// clrlwi r29,r28,30
	r29.u64 = r28.u32 & 0x3;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// bne cr6,0x8319a474
	if (!cr6.eq) goto loc_8319A474;
	// rlwinm. r11,r28,0,0,14
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFE0000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319a474
	if (cr0.eq) goto loc_8319A474;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwimi r10,r11,11,4,6
	ctx.r10.u64 = (rotl32(r11.u32, 11) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// rlwinm r11,r10,0,27,18
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
loc_8319A474:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// ld r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83199828
	sub_83199828(ctx, base);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r5,22
	ctx.r5.s64 = 22;
	// li r4,12
	ctx.r4.s64 = 12;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// clrlwi r25,r11,18
	r25.u64 = r11.u32 & 0x3FFF;
	// rlwinm r19,r11,18,18,31
	r19.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x3FFF;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwimi r19,r25,14,4,17
	r19.u64 = (rotl32(r25.u32, 14) & 0xFFFC000) | (r19.u64 & 0xFFFFFFFFF0003FFF);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r25,r31
	r25.u64 = r31.u64;
	// rlwimi r19,r10,0,0,3
	r19.u64 = (rotl32(ctx.r10.u32, 0) & 0xF0000000) | (r19.u64 & 0xFFFFFFFF0FFFFFFF);
	// stw r22,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r22.u32);
	// rlwinm r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// stw r19,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r19.u32);
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// bne cr6,0x8319a504
	if (!cr6.eq) goto loc_8319A504;
	// rlwinm. r10,r28,0,0,14
	ctx.r10.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFE0000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319a504
	if (cr0.eq) goto loc_8319A504;
	// clrlwi r11,r11,15
	r11.u64 = r11.u32 & 0x1FFFF;
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// b 0x8319a504
	goto loc_8319A504;
loc_8319A4FC:
	// std r31,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r31.u64);
	// lwz r25,80(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8319A504:
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r21,r21,8
	r21.s64 = r21.s64 + 8;
	// clrlwi r11,r10,18
	r11.u64 = ctx.r10.u32 & 0x3FFF;
	// rlwinm r10,r10,18,18,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x3FFF;
	// add r26,r11,r26
	r26.u64 = r11.u64 + r26.u64;
	// cmplw cr6,r23,r10
	cr6.compare<uint32_t>(r23.u32, ctx.r10.u32, xer);
	// blt cr6,0x8319a358
	if (cr6.lt) goto loc_8319A358;
loc_8319A524:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// b 0x82ca2c14
	return;
}

PPC_WEAK_FUNC(sub_8319A308) {
	__imp__sub_8319A308(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319A538) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bbc
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r21,r5
	r21.u64 = ctx.r5.u64;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r19,r4
	r19.u64 = ctx.r4.u64;
	// mr r20,r6
	r20.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// lwz r24,80(r21)
	r24.u64 = PPC_LOAD_U32(r21.u32 + 80);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8319a718
	if (cr6.eq) goto loc_8319A718;
	// lwz r23,20(r27)
	r23.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// rlwinm r4,r23,2,0,29
	ctx.r4.u64 = rotl64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x83110880
	sub_83110880(ctx, base);
	// li r26,0
	r26.s64 = 0;
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r28,r26
	r28.u64 = r26.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x8319a710
	if (cr6.eq) goto loc_8319A710;
	// mr r30,r26
	r30.u64 = r26.u64;
	// mr r31,r24
	r31.u64 = r24.u64;
	// subf r29,r24,r22
	r29.s64 = r22.s64 - r24.s64;
loc_8319A598:
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8319a6fc
	if (cr6.eq) goto loc_8319A6FC;
	// lwz r11,16(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// beq cr6,0x8319a64c
	if (cr6.eq) goto loc_8319A64C;
	// lwz r11,44(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319a5c8
	if (cr6.eq) goto loc_8319A5C8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x8319a720
	if (!cr6.eq) goto loc_8319A720;
loc_8319A5C8:
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319a658
	if (cr6.eq) goto loc_8319A658;
loc_8319A5D4:
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r8,6
	cr6.compare<int32_t>(ctx.r8.s32, 6, xer);
	// bne cr6,0x8319a620
	if (!cr6.eq) goto loc_8319A620;
	// lwz r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r8,1
	cr6.compare<int32_t>(ctx.r8.s32, 1, xer);
	// bne cr6,0x8319a72c
	if (!cr6.eq) goto loc_8319A72C;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319a738
	if (cr6.eq) goto loc_8319A738;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r8,11
	cr6.compare<int32_t>(ctx.r8.s32, 11, xer);
	// bne cr6,0x8319a738
	if (!cr6.eq) goto loc_8319A738;
	// lwz r8,44(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// rlwinm. r8,r8,0,26,26
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8319a620
	if (cr0.eq) goto loc_8319A620;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// beq cr6,0x8319a644
	if (cr6.eq) goto loc_8319A644;
loc_8319A620:
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319a638
	if (cr6.eq) goto loc_8319A638;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x8319a744
	if (!cr6.eq) goto loc_8319A744;
loc_8319A638:
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319a5d4
	if (!cr6.eq) goto loc_8319A5D4;
loc_8319A644:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8319a658
	if (cr6.eq) goto loc_8319A658;
loc_8319A64C:
	// stwx r9,r29,r31
	PPC_STORE_U32(r29.u32 + r31.u32, ctx.r9.u32);
	// stw r26,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r26.u32);
	// b 0x8319a6fc
	goto loc_8319A6FC;
loc_8319A658:
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// rlwinm r18,r11,0,15,28
	r18.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1FFF8;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// bl 0x83110880
	sub_83110880(ctx, base);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r17,r3
	r17.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// stwx r17,r29,r31
	PPC_STORE_U32(r29.u32 + r31.u32, r17.u32);
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,30,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319a6fc
	if (cr0.eq) goto loc_8319A6FC;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// rlwinm. r11,r11,0,15,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1FFF8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319a6fc
	if (cr0.eq) goto loc_8319A6FC;
	// rlwinm r8,r28,17,0,14
	ctx.r8.u64 = rotl64(r28.u32 | (r28.u64 << 32), 17) & 0xFFFE0000;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
loc_8319A6B8:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// addi r9,r9,8
	ctx.r9.s64 = ctx.r9.s64 + 8;
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,0,15,15
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x10000;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// or r7,r7,r8
	ctx.r7.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r6,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r6.u32);
	// rlwimi r7,r10,2,16,29
	ctx.r7.u64 = (rotl32(ctx.r10.u32, 2) & 0xFFFC) | (ctx.r7.u64 & 0xFFFFFFFFFFFF0003);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// rlwinm r11,r11,29,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x8319a6b8
	if (cr6.lt) goto loc_8319A6B8;
loc_8319A6FC:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,40
	r30.s64 = r30.s64 + 40;
	// cmplw cr6,r28,r23
	cr6.compare<uint32_t>(r28.u32, r23.u32, xer);
	// blt cr6,0x8319a598
	if (cr6.lt) goto loc_8319A598;
loc_8319A710:
	// stw r24,80(r19)
	PPC_STORE_U32(r19.u32 + 80, r24.u32);
	// stw r22,80(r21)
	PPC_STORE_U32(r21.u32 + 80, r22.u32);
loc_8319A718:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c0c
	return;
loc_8319A720:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319A72C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319A738:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319A744:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_8319A538) {
	__imp__sub_8319A538(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319A750) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r11,r4,31
	r11.u64 = ctx.r4.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319a7d0
	if (!cr0.eq) goto loc_8319A7D0;
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x8319a7d0
	if (cr0.eq) goto loc_8319A7D0;
loc_8319A77C:
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r31,31
	ctx.r10.u64 = r31.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319a790
	if (cr0.eq) goto loc_8319A790;
	// li r31,0
	r31.s64 = 0;
loc_8319A790:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r5,r11,3,0,28
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8319a77c
	if (!cr6.eq) goto loc_8319A77C;
loc_8319A7D0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319A750) {
	__imp__sub_8319A750(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319A7E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8319a84c
	if (!cr0.eq) goto loc_8319A84C;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8319a84c
	if (cr0.eq) goto loc_8319A84C;
loc_8319A800:
	// lwz r8,8(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x8319a830
	if (cr6.eq) goto loc_8319A830;
	// addi r11,r9,16
	r11.s64 = ctx.r9.s64 + 16;
loc_8319A814:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r7,r4
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r4.u32, xer);
	// beq cr6,0x8319a854
	if (cr6.eq) goto loc_8319A854;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// blt cr6,0x8319a814
	if (cr6.lt) goto loc_8319A814;
loc_8319A830:
	// rlwinm r11,r9,0,0,30
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8319a84c
	if (!cr0.eq) goto loc_8319A84C;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319a800
	if (!cr6.eq) goto loc_8319A800;
loc_8319A84C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_8319A854:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319A7E8) {
	__imp__sub_8319A7E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319A860) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
loc_8319A878:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319a88c
	if (cr0.eq) goto loc_8319A88C;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x8319a898
	goto loc_8319A898;
loc_8319A88C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_8319A898:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// ble cr6,0x8319a8e4
	if (!cr6.gt) goto loc_8319A8E4;
	// rlwinm r10,r4,0,0,30
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// subf r31,r11,r31
	r31.s64 = r31.s64 - r11.s64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r5,r11,3,0,28
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
	// b 0x8319a878
	goto loc_8319A878;
loc_8319A8E4:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// subf. r11,r31,r11
	r11.s64 = r11.s64 - r31.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r11,2
	ctx.r10.s64 = r11.s64 + 2;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r9,r10,r4
	ctx.r9.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lwzx r10,r10,r4
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
	// stw r9,4(r29)
	PPC_STORE_U32(r29.u32 + 4, ctx.r9.u32);
	// bne 0x8319a948
	if (!cr0.eq) goto loc_8319A948;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r5,r11,3,0,28
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_8319A948:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319A860) {
	__imp__sub_8319A860(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319A958) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
loc_8319A960:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319a99c
	if (!cr6.eq) goto loc_8319A99C;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319a988
	if (cr0.eq) goto loc_8319A988;
	// li r11,0
	r11.s64 = 0;
	// b 0x8319a990
	goto loc_8319A990;
loc_8319A988:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319A990:
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
loc_8319A99C:
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// blt cr6,0x8319a9b0
	if (cr6.lt) goto loc_8319A9B0;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8319A9B0:
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// subf. r4,r11,r4
	ctx.r4.s64 = ctx.r4.s64 - r11.s64;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// bne 0x8319a960
	if (!cr0.eq) goto loc_8319A960;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319A958) {
	__imp__sub_8319A958(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319A9C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319aa0c
	if (!cr6.eq) goto loc_8319AA0C;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319a9f0
	if (cr0.eq) goto loc_8319A9F0;
	// li r11,0
	r11.s64 = 0;
	// b 0x8319a9f8
	goto loc_8319A9F8;
loc_8319A9F0:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319A9F8:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + r11.u64;
	// blr 
	return;
loc_8319AA0C:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319A9C8) {
	__imp__sub_8319A9C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AA20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319aa5c
	if (!cr6.eq) goto loc_8319AA5C;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319aa48
	if (cr0.eq) goto loc_8319AA48;
	// li r11,0
	r11.s64 = 0;
	// b 0x8319aa50
	goto loc_8319AA50;
loc_8319AA48:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319AA50:
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
loc_8319AA5C:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// rlwinm r11,r9,3,0,28
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319AA20) {
	__imp__sub_8319AA20(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AA80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r11,r4,31
	r11.u64 = ctx.r4.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319ab00
	if (!cr0.eq) goto loc_8319AB00;
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x8319ab00
	if (cr0.eq) goto loc_8319AB00;
loc_8319AAAC:
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r31,31
	ctx.r10.u64 = r31.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319aac0
	if (cr0.eq) goto loc_8319AAC0;
	// li r31,0
	r31.s64 = 0;
loc_8319AAC0:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8319aaac
	if (!cr6.eq) goto loc_8319AAAC;
loc_8319AB00:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319AA80) {
	__imp__sub_8319AA80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AB18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319ab54
	if (!cr6.eq) goto loc_8319AB54;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319ab40
	if (cr0.eq) goto loc_8319AB40;
	// li r11,0
	r11.s64 = 0;
	// b 0x8319ab48
	goto loc_8319AB48;
loc_8319AB40:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319AB48:
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
loc_8319AB54:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rlwinm r10,r11,5,0,26
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// add r11,r10,r9
	r11.u64 = ctx.r10.u64 + ctx.r9.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319AB18) {
	__imp__sub_8319AB18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AB78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,10
	cr6.compare<uint32_t>(ctx.r4.u32, 10, xer);
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bgt cr6,0x8319aba0
	if (cr6.gt) goto loc_8319ABA0;
	// li r30,10
	r30.s64 = 10;
loc_8319ABA0:
	// addi r11,r30,2
	r11.s64 = r30.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r4,r11,3,0,28
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x831107d0
	sub_831107D0(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r30.u32);
	// rlwinm r11,r3,0,0,30
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// ori r8,r31,1
	ctx.r8.u64 = r31.u64 | 1;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319AB78) {
	__imp__sub_8319AB78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AC00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,10
	cr6.compare<uint32_t>(ctx.r4.u32, 10, xer);
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bgt cr6,0x8319ac28
	if (cr6.gt) goto loc_8319AC28;
	// li r30,10
	r30.s64 = 10;
loc_8319AC28:
	// mulli r11,r30,24
	r11.s64 = r30.s64 * 24;
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831107d0
	sub_831107D0(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r30.u32);
	// rlwinm r11,r3,0,0,30
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// ori r8,r31,1
	ctx.r8.u64 = r31.u64 | 1;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319AC00) {
	__imp__sub_8319AC00(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AC88) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,10
	cr6.compare<uint32_t>(ctx.r4.u32, 10, xer);
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bgt cr6,0x8319acb0
	if (cr6.gt) goto loc_8319ACB0;
	// li r30,10
	r30.s64 = 10;
loc_8319ACB0:
	// rlwinm r11,r30,5,0,26
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 5) & 0xFFFFFFE0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// bl 0x831107d0
	sub_831107D0(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r30.u32);
	// rlwinm r11,r3,0,0,30
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// ori r8,r31,1
	ctx.r8.u64 = r31.u64 | 1;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319AC88) {
	__imp__sub_8319AC88(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AD10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,10
	cr6.compare<uint32_t>(ctx.r4.u32, 10, xer);
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bgt cr6,0x8319ad38
	if (cr6.gt) goto loc_8319AD38;
	// li r30,10
	r30.s64 = 10;
loc_8319AD38:
	// mulli r11,r30,12
	r11.s64 = r30.s64 * 12;
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831107d0
	sub_831107D0(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r30.u32);
	// rlwinm r11,r3,0,0,30
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// ori r8,r31,1
	ctx.r8.u64 = r31.u64 | 1;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319AD10) {
	__imp__sub_8319AD10(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AD98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319adac
	if (!cr6.eq) goto loc_8319ADAC;
	// li r11,1
	r11.s64 = 1;
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
loc_8319ADAC:
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// addi r11,r10,1
	r11.s64 = ctx.r10.s64 + 1;
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r10,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r10.u32);
	// rotlwi r10,r10,0
	ctx.r10.u64 = rotl32(ctx.r10.u32, 0);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x8319ade8
	if (cr6.lt) goto loc_8319ADE8;
	// lis r11,7
	r11.s64 = 458752;
	// ori r11,r11,65534
	r11.u64 = r11.u64 | 65534;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bgt cr6,0x8319ade8
	if (cr6.gt) goto loc_8319ADE8;
	// lwz r11,744(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 744);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// b 0x8319a258
	sub_8319A258(ctx, base);
	return;
loc_8319ADE8:
	// li r4,3529
	ctx.r4.s64 = 3529;
	// b 0x830fd318
	sub_830FD318(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_8319AD98) {
	__imp__sub_8319AD98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319ADF0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319ADF0) {
	__imp__sub_8319ADF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319ADF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// rlwinm. r11,r11,30,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319ae30
	if (cr0.eq) goto loc_8319AE30;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// bl 0x831972a0
	sub_831972A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// b 0x8319ae38
	goto loc_8319AE38;
loc_8319AE30:
	// lwz r5,12(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
loc_8319AE38:
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319ADF8) {
	__imp__sub_8319ADF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AE60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r30,4(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r29,8(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// stw r29,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r29.u32);
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319AE60) {
	__imp__sub_8319AE60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AEA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r11,1
	r11.s64 = 1;
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// rlwimi r10,r30,2,16,29
	ctx.r10.u64 = (rotl32(r30.u32, 2) & 0xFFFC) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0003);
	// rlwimi r10,r11,0,30,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFE0003) | (ctx.r10.u64 & 0x1FFFC);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319AEA0) {
	__imp__sub_8319AEA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AEF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r11,1
	r11.s64 = 1;
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// rlwimi r10,r30,2,16,29
	ctx.r10.u64 = (rotl32(r30.u32, 2) & 0xFFFC) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0003);
	// rlwimi r10,r11,1,30,14
	ctx.r10.u64 = (rotl32(r11.u32, 1) & 0xFFFFFFFFFFFE0003) | (ctx.r10.u64 & 0x1FFFC);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319AEF0) {
	__imp__sub_8319AEF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AF40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8319af90
	if (cr6.eq) goto loc_8319AF90;
loc_8319AF64:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r11,1
	r11.s64 = 1;
	// stw r28,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r28.u32);
	// rlwimi r10,r31,2,16,29
	ctx.r10.u64 = (rotl32(r31.u32, 2) & 0xFFFC) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0003);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// rlwimi r10,r11,0,30,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFE0003) | (ctx.r10.u64 & 0x1FFFC);
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// blt cr6,0x8319af64
	if (cr6.lt) goto loc_8319AF64;
loc_8319AF90:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319AF40) {
	__imp__sub_8319AF40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AF98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8319afe8
	if (cr6.eq) goto loc_8319AFE8;
loc_8319AFBC:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r11,1
	r11.s64 = 1;
	// stw r28,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r28.u32);
	// rlwimi r10,r31,2,16,29
	ctx.r10.u64 = (rotl32(r31.u32, 2) & 0xFFFC) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0003);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// rlwimi r10,r11,1,30,14
	ctx.r10.u64 = (rotl32(r11.u32, 1) & 0xFFFFFFFFFFFE0003) | (ctx.r10.u64 & 0x1FFFC);
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// blt cr6,0x8319afbc
	if (cr6.lt) goto loc_8319AFBC;
loc_8319AFE8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319AF98) {
	__imp__sub_8319AF98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319AFF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// bl 0x83194f88
	sub_83194F88(ctx, base);
	// lwz r6,24(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199ae8
	sub_83199AE8(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// bne 0x8319b064
	if (!cr0.eq) goto loc_8319B064;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,100
	ctx.r5.s64 = 100;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ca410
	sub_831CA410(ctx, base);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,3523
	ctx.r4.s64 = 3523;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319B064:
	// clrlwi. r11,r28,28
	r11.u64 = r28.u32 & 0xF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319b098
	if (!cr0.eq) goto loc_8319B098;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,100
	ctx.r5.s64 = 100;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ca410
	sub_831CA410(ctx, base);
	// rlwinm r6,r28,28,4,31
	ctx.r6.u64 = rotl64(r28.u32 | (r28.u64 << 32), 28) & 0xFFFFFFF;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,3634
	ctx.r4.s64 = 3634;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319B098:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8319AFF0) {
	__imp__sub_8319AFF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319B0A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8319b0d4
	if (cr6.eq) goto loc_8319B0D4;
loc_8319B0C8:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
loc_8319B0D4:
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// blt cr6,0x8319b210
	if (cr6.lt) goto loc_8319B210;
	// beq cr6,0x8319b1b8
	if (cr6.eq) goto loc_8319B1B8;
	// cmplwi cr6,r5,3
	cr6.compare<uint32_t>(ctx.r5.u32, 3, xer);
	// blt cr6,0x8319b0f4
	if (cr6.lt) goto loc_8319B0F4;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319B0F4:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 + 40;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,320
	ctx.r5.s64 = r11.s64 + 320;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199ed0
	sub_83199ED0(ctx, base);
	// lwz r30,24(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8319b1ac
	if (cr6.eq) goto loc_8319B1AC;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x8319b1ac
	if (!cr6.eq) goto loc_8319B1AC;
	// lwa r11,12(r29)
	r11.s64 = int32_t(PPC_LOAD_U32(r29.u32 + 12));
	// li r5,4
	ctx.r5.s64 = 4;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwa r9,4(r29)
	ctx.r9.s64 = int32_t(PPC_LOAD_U32(r29.u32 + 4));
	// lwa r10,0(r29)
	ctx.r10.s64 = int32_t(PPC_LOAD_U32(r29.u32 + 0));
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfd f12,80(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r10,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r10.u64);
	// lwa r8,8(r29)
	ctx.r8.s64 = int32_t(PPC_LOAD_U32(r29.u32 + 8));
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// lwz r10,44(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lfd f11,96(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// ori r11,r10,2
	r11.u64 = ctx.r10.u64 | 2;
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// stfs f11,104(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// stfs f12,100(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// b 0x8319b284
	goto loc_8319B284;
loc_8319B1AC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319B1B8:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 + 40;
	// li r7,12
	ctx.r7.s64 = 12;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,64
	ctx.r5.s64 = r11.s64 + 64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199ed0
	sub_83199ED0(ctx, base);
	// lwz r30,24(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8319b204
	if (cr6.eq) goto loc_8319B204;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x8319b204
	if (!cr6.eq) goto loc_8319B204;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// b 0x8319b27c
	goto loc_8319B27C;
loc_8319B204:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319B210:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r9,1
	ctx.r9.s64 = 1;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 + 40;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,352
	ctx.r5.s64 = r11.s64 + 352;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199ed0
	sub_83199ED0(ctx, base);
	// lwz r30,24(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8319b298
	if (cr6.eq) goto loc_8319B298;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x8319b298
	if (!cr6.eq) goto loc_8319B298;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8319b268
	if (cr6.eq) goto loc_8319B268;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,3080(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	f0.f64 = double(temp.f32);
	// b 0x8319b270
	goto loc_8319B270;
loc_8319B268:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,3084(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f0.f64 = double(temp.f32);
loc_8319B270:
	// stfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
loc_8319B27C:
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
loc_8319B284:
	// stw r11,44(r30)
	PPC_STORE_U32(r30.u32 + 44, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83195f38
	sub_83195F38(ctx, base);
	// stw r3,52(r30)
	PPC_STORE_U32(r30.u32 + 52, ctx.r3.u32);
	// b 0x8319b0c8
	goto loc_8319B0C8;
loc_8319B298:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_8319B0A8) {
	__imp__sub_8319B0A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319B2A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// clrlwi r11,r10,30
	r11.u64 = ctx.r10.u32 & 0x3;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8319b314
	if (cr6.lt) goto loc_8319B314;
	// beq cr6,0x8319b30c
	if (cr6.eq) goto loc_8319B30C;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8319b300
	if (cr6.lt) goto loc_8319B300;
	// beq cr6,0x8319b2dc
	if (cr6.eq) goto loc_8319B2DC;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319B2DC:
	// lwz r4,0(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm. r11,r10,16,31,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319b2f8
	if (cr0.eq) goto loc_8319B2F8;
	// li r6,0
	ctx.r6.s64 = 0;
	// ld r5,0(r4)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r4.u32 + 0);
	// bl 0x8319a308
	sub_8319A308(ctx, base);
	// b 0x8319b390
	goto loc_8319B390;
loc_8319B2F8:
	// bl 0x8319b2a8
	sub_8319B2A8(ctx, base);
	// b 0x8319b390
	goto loc_8319B390;
loc_8319B300:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r3,12(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// b 0x8319b390
	goto loc_8319B390;
loc_8319B30C:
	// lwz r3,0(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// b 0x8319b390
	goto loc_8319B390;
loc_8319B314:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8319b324
	if (cr0.eq) goto loc_8319B324;
	// li r11,0
	r11.s64 = 0;
loc_8319B324:
	// lwz r5,564(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 564);
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// beq cr6,0x8319b374
	if (cr6.eq) goto loc_8319B374;
	// rlwinm r10,r10,15,17,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0x7FFF;
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319b358
	if (!cr0.eq) goto loc_8319B358;
	// lwz r11,44(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319b374
	if (cr0.eq) goto loc_8319B374;
loc_8319B358:
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rlwinm r7,r11,30,18,31
	ctx.r7.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFF;
	// rlwinm r6,r11,15,17,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x7FFF;
	// bl 0x831ced48
	sub_831CED48(ctx, base);
	// b 0x8319b38c
	goto loc_8319B38C;
loc_8319B374:
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// rlwinm r6,r11,30,18,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFF;
	// rlwinm r5,r11,15,17,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x7FFF;
	// bl 0x831d46c0
	sub_831D46C0(ctx, base);
loc_8319B38C:
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
loc_8319B390:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319B2A8) {
	__imp__sub_8319B2A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319B3A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi r11,r10,30
	r11.u64 = ctx.r10.u32 & 0x3;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8319b498
	if (cr6.lt) goto loc_8319B498;
	// beq cr6,0x8319b460
	if (cr6.eq) goto loc_8319B460;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8319b418
	if (cr6.lt) goto loc_8319B418;
	// beq cr6,0x8319b3e4
	if (cr6.eq) goto loc_8319B3E4;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319B3E4:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r10,16,31,31
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319b520
	if (cr0.eq) goto loc_8319B520;
	// li r6,0
	ctx.r6.s64 = 0;
	// ld r5,0(r4)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r4.u32 + 0);
	// bl 0x8319a308
	sub_8319A308(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r11,1
	r11.s64 = 1;
	// rlwimi r10,r11,25,4,6
	ctx.r10.u64 = (rotl32(r11.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// b 0x8319b490
	goto loc_8319B490;
loc_8319B418:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r5,12(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r10,r11,0,0,14
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFE0000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r10,r11,27,24,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0xFF;
	// bne 0x8319b524
	if (!cr0.eq) goto loc_8319B524;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwimi r11,r9,25,4,6
	r11.u64 = (rotl32(ctx.r9.u32, 25) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// lwz r9,4(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r9,r9,31,17,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x7FFE;
	// srw r10,r10,r9
	ctx.r10.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r9.u8 & 0x3F));
	// rlwimi r11,r10,5,25,26
	r11.u64 = (rotl32(ctx.r10.u32, 5) & 0x60) | (r11.u64 & 0xFFFFFFFFFFFFFF9F);
	// rlwinm r11,r11,0,25,18
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFE07F;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// b 0x8319b524
	goto loc_8319B524;
loc_8319B460:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,0,14
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFE0000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319b524
	if (!cr0.eq) goto loc_8319B524;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwimi r11,r10,25,4,6
	r11.u64 = (rotl32(ctx.r10.u32, 25) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,3,19,26
	ctx.r10.u64 = (rotl32(r11.u32, 3) & 0x1FE0) | (ctx.r10.u64 & 0xFFFFFFFFFFFFE01F);
loc_8319B490:
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// b 0x8319b524
	goto loc_8319B524;
loc_8319B498:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8319b4a8
	if (cr0.eq) goto loc_8319B4A8;
	// li r11,0
	r11.s64 = 0;
loc_8319B4A8:
	// lwz r5,564(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// beq cr6,0x8319b4f8
	if (cr6.eq) goto loc_8319B4F8;
	// rlwinm r10,r10,15,17,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0x7FFF;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319b4dc
	if (!cr0.eq) goto loc_8319B4DC;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319b4f8
	if (cr0.eq) goto loc_8319B4F8;
loc_8319B4DC:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// rlwinm r7,r11,30,18,31
	ctx.r7.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFF;
	// rlwinm r6,r11,15,17,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x7FFF;
	// bl 0x831ced48
	sub_831CED48(ctx, base);
	// b 0x8319b510
	goto loc_8319B510;
loc_8319B4F8:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// rlwinm r6,r11,30,18,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFF;
	// rlwinm r5,r11,15,17,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x7FFF;
	// bl 0x831d46c0
	sub_831D46C0(ctx, base);
loc_8319B510:
	// ld r11,0(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
loc_8319B520:
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
loc_8319B524:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319B3A0) {
	__imp__sub_8319B3A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319B540) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r20,r6
	r20.u64 = ctx.r6.u64;
	// mr r23,r7
	r23.u64 = ctx.r7.u64;
	// lwz r22,4(r26)
	r22.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// li r30,0
	r30.s64 = 0;
	// lwz r21,8(r26)
	r21.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// li r24,0
	r24.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8319b634
	if (cr6.eq) goto loc_8319B634;
	// li r25,0
	r25.s64 = 0;
loc_8319B580:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8319b600
	if (cr6.eq) goto loc_8319B600;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b2a8
	sub_8319B2A8(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b2a8
	sub_8319B2A8(ctx, base);
	// cmplw cr6,r19,r3
	cr6.compare<uint32_t>(r19.u32, ctx.r3.u32, xer);
	// bne cr6,0x8319b634
	if (!cr6.eq) goto loc_8319B634;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// blt cr6,0x8319b5d4
	if (cr6.lt) goto loc_8319B5D4;
	// beq cr6,0x8319b6ec
	if (cr6.eq) goto loc_8319B6EC;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bge cr6,0x8319b70c
	if (!cr6.lt) goto loc_8319B70C;
loc_8319B5D4:
	// li r10,0
	ctx.r10.s64 = 0;
loc_8319B5D8:
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// blt cr6,0x8319b5f4
	if (cr6.lt) goto loc_8319B5F4;
	// beq cr6,0x8319b6fc
	if (cr6.eq) goto loc_8319B6FC;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bge cr6,0x8319b718
	if (!cr6.lt) goto loc_8319B718;
loc_8319B5F4:
	// li r11,0
	r11.s64 = 0;
loc_8319B5F8:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8319b634
	if (!cr6.eq) goto loc_8319B634;
loc_8319B600:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196a60
	sub_83196A60(ctx, base);
	// li r11,3
	r11.s64 = 3;
	// slw r10,r3,r25
	ctx.r10.u64 = r25.u8 & 0x20 ? 0 : (ctx.r3.u32 << (r25.u8 & 0x3F));
	// slw r11,r11,r25
	r11.u64 = r25.u8 & 0x20 ? 0 : (r11.u32 << (r25.u8 & 0x3F));
	// andc r11,r24,r11
	r11.u64 = r24.u64 & ~r11.u64;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// or r24,r10,r11
	r24.u64 = ctx.r10.u64 | r11.u64;
	// mr r30,r27
	r30.u64 = r27.u64;
	// addi r25,r25,2
	r25.s64 = r25.s64 + 2;
	// cmplw cr6,r28,r29
	cr6.compare<uint32_t>(r28.u32, r29.u32, xer);
	// blt cr6,0x8319b580
	if (cr6.lt) goto loc_8319B580;
loc_8319B634:
	// clrlwi. r11,r23,24
	r11.u64 = r23.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319b724
	if (cr0.eq) goto loc_8319B724;
	// cmplw cr6,r28,r29
	cr6.compare<uint32_t>(r28.u32, r29.u32, xer);
	// bge cr6,0x8319b724
	if (!cr6.lt) goto loc_8319B724;
	// stw r22,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r22.u32);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// stw r21,8(r26)
	PPC_STORE_U32(r26.u32 + 8, r21.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cde60
	sub_831CDE60(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8319b6a0
	if (cr6.eq) goto loc_8319B6A0;
	// addi r28,r30,44
	r28.s64 = r30.s64 + 44;
loc_8319B670:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r3.u32);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// bne 0x8319b670
	if (!cr0.eq) goto loc_8319B670;
loc_8319B6A0:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r10,r30,0,0,30
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// addi r9,r11,-36
	ctx.r9.s64 = r11.s64 + -36;
	// addi r8,r10,-36
	ctx.r8.s64 = ctx.r10.s64 + -36;
	// ori r7,r9,1
	ctx.r7.u64 = ctx.r9.u64 | 1;
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r6,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r6.u32);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stw r7,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r7.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// b 0x8319b754
	goto loc_8319B754;
loc_8319B6EC:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r10,r11,27
	ctx.r10.u64 = r11.u32 & 0x1F;
	// b 0x8319b5d8
	goto loc_8319B5D8;
loc_8319B6FC:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// b 0x8319b5f8
	goto loc_8319B5F8;
loc_8319B70C:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319B718:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319B724:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// clrlwi r10,r24,24
	ctx.r10.u64 = r24.u32 & 0xFF;
	// rlwinm r11,r28,20,9,11
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 20) & 0x700000;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r10,r10,0,27,18
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// rlwinm r11,r11,5,0,26
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r10,r10,0,7,3
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_8319B754:
	// clrlwi. r11,r20,24
	r11.u64 = r20.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319b764
	if (cr0.eq) goto loc_8319B764;
	// stw r22,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r22.u32);
	// stw r21,8(r26)
	PPC_STORE_U32(r26.u32 + 8, r21.u32);
loc_8319B764:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c14
	return;
}

PPC_WEAK_FUNC(sub_8319B540) {
	__imp__sub_8319B540(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319B770) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// cmplwi cr6,r31,228
	cr6.compare<uint32_t>(r31.u32, 228, xer);
	// beq cr6,0x8319b7e0
	if (cr6.eq) goto loc_8319B7E0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r10,r31,27,29,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 27) & 0x6;
	// rlwinm r9,r31,29,29,30
	ctx.r9.u64 = rotl64(r31.u32 | (r31.u64 << 32), 29) & 0x6;
	// rlwinm r8,r11,27,24,31
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0xFF;
	// rlwinm r7,r31,31,29,30
	ctx.r7.u64 = rotl64(r31.u32 | (r31.u64 << 32), 31) & 0x6;
	// srw r10,r8,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r10.u8 & 0x3F));
	// srw r9,r8,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r9.u8 & 0x3F));
	// rlwimi r9,r10,2,28,29
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 2) & 0xC) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFF3);
	// srw r10,r8,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r7.u8 & 0x3F));
	// clrlwi r9,r9,28
	ctx.r9.u64 = ctx.r9.u32 & 0xF;
	// rlwinm r7,r31,1,29,30
	ctx.r7.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0x6;
	// rlwimi r10,r9,2,0,29
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 2) & 0xFFFFFFFC) | (ctx.r10.u64 & 0xFFFFFFFF00000003);
	// srw r9,r8,r7
	ctx.r9.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (ctx.r7.u8 & 0x3F));
	// rlwimi r9,r10,2,0,29
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 2) & 0xFFFFFFFC) | (ctx.r9.u64 & 0xFFFFFFFF00000003);
	// rlwinm r11,r11,0,27,18
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// rlwinm r10,r9,5,0,26
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_8319B7E0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319B770) {
	__imp__sub_8319B770(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319B7F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r9,4(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// clrlwi. r11,r9,30
	r11.u64 = ctx.r9.u32 & 0x3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319b91c
	if (cr0.eq) goto loc_8319B91C;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8319ba04
	if (!cr6.eq) goto loc_8319BA04;
	// rlwinm. r11,r9,16,31,31
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319b904
	if (cr0.eq) goto loc_8319B904;
	// lwz r29,0(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm. r11,r11,18,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x3FFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319b868
	if (cr0.eq) goto loc_8319B868;
	// addi r9,r29,16
	ctx.r9.s64 = r29.s64 + 16;
loc_8319B840:
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// clrlwi r8,r8,30
	ctx.r8.u64 = ctx.r8.u32 & 0x3;
	// cmpwi cr6,r8,3
	cr6.compare<int32_t>(ctx.r8.s32, 3, xer);
	// beq cr6,0x8319b868
	if (cr6.eq) goto loc_8319B868;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8319b868
	if (cr6.eq) goto loc_8319B868;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,8
	ctx.r9.s64 = ctx.r9.s64 + 8;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x8319b840
	if (cr6.lt) goto loc_8319B840;
loc_8319B868:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bge cr6,0x8319b8e4
	if (!cr6.lt) goto loc_8319B8E4;
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// li r5,32
	ctx.r5.s64 = 32;
	// addi r30,r11,12
	r30.s64 = r11.s64 + 12;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83110880
	sub_83110880(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r30,0
	r30.s64 = 0;
	// rlwinm. r11,r11,0,4,17
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFC000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319b8d0
	if (cr0.eq) goto loc_8319B8D0;
	// addi r29,r31,12
	r29.s64 = r31.s64 + 12;
loc_8319B8AC:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8319b7f8
	sub_8319B7F8(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// rlwinm r11,r11,18,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x3FFF;
	// addi r29,r29,8
	r29.s64 = r29.s64 + 8;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x8319b8ac
	if (cr6.lt) goto loc_8319B8AC;
loc_8319B8D0:
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// stw r31,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r31.u32);
	// oris r11,r11,1
	r11.u64 = r11.u64 | 65536;
	// ori r11,r11,3
	r11.u64 = r11.u64 | 3;
	// stw r11,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r11.u32);
loc_8319B8E4:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8319b2a8
	sub_8319B2A8(ctx, base);
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r3,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r3.u32);
	// rlwimi r11,r10,0,16,14
	r11.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// b 0x8319b914
	goto loc_8319B914;
loc_8319B904:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r10,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
loc_8319B914:
	// stw r11,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r11.u32);
	// b 0x8319ba04
	goto loc_8319BA04;
loc_8319B91C:
	// lwz r5,564(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 564);
	// lwz r11,80(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 80);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319b938
	if (cr6.eq) goto loc_8319B938;
	// rlwinm r10,r9,17,15,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 17) & 0x1FFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x8319b93c
	goto loc_8319B93C;
loc_8319B938:
	// li r11,0
	r11.s64 = 0;
loc_8319B93C:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// beq cr6,0x8319b984
	if (cr6.eq) goto loc_8319B984;
	// rlwinm r10,r9,1,15,28
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x1FFF8;
	// ldx r11,r10,r11
	r11.u64 = PPC_LOAD_U64(ctx.r10.u32 + r11.u32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8319b988
	if (cr6.eq) goto loc_8319B988;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x8319b97c
	if (cr6.eq) goto loc_8319B97C;
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// bne cr6,0x8319b988
	if (!cr6.eq) goto loc_8319B988;
loc_8319B97C:
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x8319b98c
	goto loc_8319B98C;
loc_8319B984:
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
loc_8319B988:
	// li r10,0
	ctx.r10.s64 = 0;
loc_8319B98C:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8319ba00
	if (!cr0.eq) goto loc_8319BA00;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319b9a4
	if (cr0.eq) goto loc_8319B9A4;
	// li r11,0
	r11.s64 = 0;
loc_8319B9A4:
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// beq cr6,0x8319b9e8
	if (cr6.eq) goto loc_8319B9E8;
	// rlwinm r6,r9,15,17,31
	ctx.r6.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 15) & 0x7FFF;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mulli r10,r6,40
	ctx.r10.s64 = ctx.r6.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319b9d4
	if (!cr0.eq) goto loc_8319B9D4;
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319b9e8
	if (cr0.eq) goto loc_8319B9E8;
loc_8319B9D4:
	// rlwinm r7,r9,30,18,31
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFF;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x831ced48
	sub_831CED48(ctx, base);
	// b 0x8319b9fc
	goto loc_8319B9FC;
loc_8319B9E8:
	// rlwinm r6,r9,30,18,31
	ctx.r6.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFF;
	// rlwinm r5,r9,15,17,31
	ctx.r5.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 15) & 0x7FFF;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x831d46c0
	sub_831D46C0(ctx, base);
loc_8319B9FC:
	// ld r11,0(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
loc_8319BA00:
	// std r11,0(r27)
	PPC_STORE_U64(r27.u32 + 0, r11.u64);
loc_8319BA04:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8319B7F8) {
	__imp__sub_8319B7F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319BA10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r31,0(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mullw r11,r11,r4
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r4.s32);
	// lwz r30,4(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r29,8(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r4,r11,r5
	ctx.r4.u64 = r11.u64 + ctx.r5.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// stw r29,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r29.u32);
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319BA10) {
	__imp__sub_8319BA10(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319BA60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8319bb7c
	if (!cr6.eq) goto loc_8319BB7C;
	// addi r11,r1,84
	r11.s64 = ctx.r1.s64 + 84;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r27.u32);
	// stw r27,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r27.u32);
	// bne cr6,0x8319bacc
	if (!cr6.eq) goto loc_8319BACC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8319bac0
	if (cr0.eq) goto loc_8319BAC0;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_8319BAC0:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// li r11,1
	r11.s64 = 1;
	// beq cr6,0x8319bad0
	if (cr6.eq) goto loc_8319BAD0;
loc_8319BACC:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_8319BAD0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm. r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r28,r11
	r28.u64 = r11.u64;
	// beq 0x8319bb00
	if (cr0.eq) goto loc_8319BB00;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319aa20
	sub_8319AA20(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r29,4(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// b 0x8319bb08
	goto loc_8319BB08;
loc_8319BB00:
	// lwz r30,84(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r29,80(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8319BB08:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r5,r11,3,0,28
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8319bb5c
	if (cr6.eq) goto loc_8319BB5C;
	// stw r29,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r29.u32);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// b 0x8319bba4
	goto loc_8319BBA4;
loc_8319BB5C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319bb70
	if (cr0.eq) goto loc_8319BB70;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_8319BB70:
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r27,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r27.u32);
	// b 0x8319bba4
	goto loc_8319BBA4;
loc_8319BB7C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r8,r11,2
	ctx.r8.s64 = r11.s64 + 2;
	// addi r7,r11,3
	ctx.r7.s64 = r11.s64 + 3;
	// subf r6,r11,r9
	ctx.r6.s64 = ctx.r9.s64 - r11.s64;
	// rlwinm r11,r7,3,0,28
	r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r5,r6,3,0,28
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// add r3,r9,r10
	ctx.r3.u64 = ctx.r9.u64 + ctx.r10.u64;
	// bl 0x82caa2e0
	sub_82CAA2E0(ctx, base);
loc_8319BBA4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8319BA60) {
	__imp__sub_8319BA60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319BBB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319bbc8
	if (cr0.eq) goto loc_8319BBC8;
	// li r11,0
	r11.s64 = 0;
	// b 0x8319bbd4
	goto loc_8319BBD4;
loc_8319BBC8:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319BBD4:
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319bbe8
	if (cr6.eq) goto loc_8319BBE8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x8319bbec
	goto loc_8319BBEC;
loc_8319BBE8:
	// li r11,0
	r11.s64 = 0;
loc_8319BBEC:
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319BBB0) {
	__imp__sub_8319BBB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319BBF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// std r4,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r4.u64);
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319BBF8) {
	__imp__sub_8319BBF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319BC38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// std r4,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r4.u64);
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319BC38) {
	__imp__sub_8319BC38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319BC78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// std r4,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r4.u64);
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319bce8
	if (cr6.eq) goto loc_8319BCE8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319BCE8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319BC78) {
	__imp__sub_8319BC78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319BD58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// std r4,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r4.u64);
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319bdc8
	if (cr6.eq) goto loc_8319BDC8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319BDC8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319BD58) {
	__imp__sub_8319BD58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319BE38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// std r4,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r4.u64);
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,6
	ctx.r6.s64 = 6;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319bea8
	if (cr6.eq) goto loc_8319BEA8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319BEA8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319BE38) {
	__imp__sub_8319BE38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319BF18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r4,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r4.u64);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,48
	ctx.r6.s64 = 48;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r30,0,0,30
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319BF18) {
	__imp__sub_8319BF18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319BFC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r4,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r4.u64);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,60
	ctx.r6.s64 = 60;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r30,0,0,30
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319BFC8) {
	__imp__sub_8319BFC8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C078) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319c0e8
	if (cr6.eq) goto loc_8319C0E8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319C0E8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319C078) {
	__imp__sub_8319C078(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C158) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,9
	ctx.r6.s64 = 9;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r9,r9,7,29,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0x7;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r11,r29,0,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// rlwimi r10,r9,14,15,17
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 14) & 0x1C000) | (ctx.r10.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r10,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r10.u32);
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319C158) {
	__imp__sub_8319C158(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C200) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,46
	ctx.r6.s64 = 46;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r29,0,0,30
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319C200) {
	__imp__sub_8319C200(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C298) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,48
	ctx.r6.s64 = 48;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r29,0,0,30
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319C298) {
	__imp__sub_8319C298(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C330) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,51
	ctx.r6.s64 = 51;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r29,0,0,30
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319C330) {
	__imp__sub_8319C330(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C3C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,60
	ctx.r6.s64 = 60;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,28(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r27)
	PPC_STORE_U32(r27.u32 + 44, ctx.r3.u32);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831184d0
	sub_831184D0(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8319C3C8) {
	__imp__sub_8319C3C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C440) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,97
	ctx.r6.s64 = 97;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319c4b0
	if (cr6.eq) goto loc_8319C4B0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319C4B0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// rlwinm r10,r31,0,0,30
	ctx.r10.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,0,30
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319C440) {
	__imp__sub_8319C440(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C508) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r4,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r4.u64);
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// stw r3,48(r29)
	PPC_STORE_U32(r29.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r29,0,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319C508) {
	__imp__sub_8319C508(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C5D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319C5D8) {
	__imp__sub_8319C5D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C6A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319c6fc
	if (cr6.eq) goto loc_8319C6FC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319C6FC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319C6A8) {
	__imp__sub_8319C6A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C788) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319c7dc
	if (cr6.eq) goto loc_8319C7DC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319C7DC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319C788) {
	__imp__sub_8319C788(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C868) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,5
	ctx.r6.s64 = 5;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319c8bc
	if (cr6.eq) goto loc_8319C8BC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319C8BC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319C868) {
	__imp__sub_8319C868(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319C948) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,6
	ctx.r6.s64 = 6;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319c99c
	if (cr6.eq) goto loc_8319C99C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319C99C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319C948) {
	__imp__sub_8319C948(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319CA28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// stw r3,48(r29)
	PPC_STORE_U32(r29.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r29,0,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319CA28) {
	__imp__sub_8319CA28(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319CAF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// stw r3,48(r29)
	PPC_STORE_U32(r29.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r29,0,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319CAF8) {
	__imp__sub_8319CAF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319CBC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,7
	ctx.r6.s64 = 7;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// stw r3,48(r29)
	PPC_STORE_U32(r29.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r29,0,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319CBC8) {
	__imp__sub_8319CBC8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319CC98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r4,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r4.u64);
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r3,48(r30)
	PPC_STORE_U32(r30.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r30)
	PPC_STORE_U32(r30.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319CC98) {
	__imp__sub_8319CC98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319CD80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,3
	ctx.r6.s64 = 3;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319cdd4
	if (cr6.eq) goto loc_8319CDD4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319CDD4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319CD80) {
	__imp__sub_8319CD80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319CE60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,6
	ctx.r6.s64 = 6;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319ceb4
	if (cr6.eq) goto loc_8319CEB4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319CEB4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319CE60) {
	__imp__sub_8319CE60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319CF40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319CF40) {
	__imp__sub_8319CF40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D010) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319D010) {
	__imp__sub_8319D010(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D0E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319D0E0) {
	__imp__sub_8319D0E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D1B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,3
	ctx.r6.s64 = 3;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319D1B0) {
	__imp__sub_8319D1B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D280) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319D280) {
	__imp__sub_8319D280(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D350) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// std r6,152(r1)
	PPC_STORE_U64(ctx.r1.u32 + 152, ctx.r6.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,14
	ctx.r6.s64 = 14;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,564(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// beq cr6,0x8319d3a8
	if (cr6.eq) goto loc_8319D3A8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_8319D3A8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// addi r4,r1,152
	ctx.r4.s64 = ctx.r1.s64 + 152;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r3,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r3.u32);
	// rlwinm r11,r31,0,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319D350) {
	__imp__sub_8319D350(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D450) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// std r6,152(r1)
	PPC_STORE_U64(ctx.r1.u32 + 152, ctx.r6.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,13
	ctx.r6.s64 = 13;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r29)
	PPC_STORE_U32(r29.u32 + 48, ctx.r3.u32);
	// addi r4,r1,152
	ctx.r4.s64 = ctx.r1.s64 + 152;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// stw r3,52(r29)
	PPC_STORE_U32(r29.u32 + 52, ctx.r3.u32);
	// rlwinm r11,r29,0,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319D450) {
	__imp__sub_8319D450(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D540) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r5,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r5.u64);
	// std r6,152(r1)
	PPC_STORE_U64(ctx.r1.u32 + 152, ctx.r6.u64);
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,14
	ctx.r6.s64 = 14;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r29)
	PPC_STORE_U32(r29.u32 + 44, ctx.r3.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r29)
	PPC_STORE_U32(r29.u32 + 48, ctx.r3.u32);
	// addi r4,r1,152
	ctx.r4.s64 = ctx.r1.s64 + 152;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r10,44(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// stw r3,52(r29)
	PPC_STORE_U32(r29.u32 + 52, ctx.r3.u32);
	// rlwinm r11,r29,0,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,7,29,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// rlwimi r9,r10,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// stw r9,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r9.u32);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// ori r6,r6,1
	ctx.r6.u64 = ctx.r6.u64 | 1;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319D540) {
	__imp__sub_8319D540(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D630) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319d65c
	if (cr0.eq) goto loc_8319D65C;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x8319d668
	goto loc_8319D668;
loc_8319D65C:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_8319D668:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r9,r10,r4
	ctx.r9.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lwzx r10,r10,r4
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
	// bne 0x8319d6c8
	if (!cr0.eq) goto loc_8319D6C8;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r5,r11,3,0,28
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_8319D6C8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319D630) {
	__imp__sub_8319D630(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D6E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319d6f8
	if (cr0.eq) goto loc_8319D6F8;
	// li r11,0
	r11.s64 = 0;
	// b 0x8319d704
	goto loc_8319D704;
loc_8319D6F8:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319D704:
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319d718
	if (cr6.eq) goto loc_8319D718;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x8319d71c
	goto loc_8319D71C;
loc_8319D718:
	// li r11,0
	r11.s64 = 0;
loc_8319D71C:
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// b 0x8319a958
	sub_8319A958(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_8319D6E0) {
	__imp__sub_8319D6E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D728) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// addi r3,r10,24
	ctx.r3.s64 = ctx.r10.s64 + 24;
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319d754
	if (cr0.eq) goto loc_8319D754;
	// li r11,0
	r11.s64 = 0;
	// b 0x8319d760
	goto loc_8319D760;
loc_8319D754:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319D760:
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mulli r9,r9,24
	ctx.r9.s64 = ctx.r9.s64 * 24;
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// addi r11,r11,-8
	r11.s64 = r11.s64 + -8;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r9,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r9.u32);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// stw r9,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r9.u32);
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// stw r9,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, ctx.r9.u32);
	// lbz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// stb r9,32(r10)
	PPC_STORE_U8(ctx.r10.u32 + 32, ctx.r9.u8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// beq cr6,0x8319d7ac
	if (cr6.eq) goto loc_8319D7AC;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// b 0x8319d810
	goto loc_8319D810;
loc_8319D7AC:
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r10,31
	r11.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319d7c0
	if (cr0.eq) goto loc_8319D7C0;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x8319d7cc
	goto loc_8319D7CC;
loc_8319D7C0:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_8319D7CC:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x8319d810
	if (!cr0.eq) goto loc_8319D810;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mulli r11,r11,24
	r11.s64 = r11.s64 * 24;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_8319D810:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319D728) {
	__imp__sub_8319D728(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D828) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319d84c
	if (cr0.eq) goto loc_8319D84C;
	// li r11,0
	r11.s64 = 0;
	// b 0x8319d858
	goto loc_8319D858;
loc_8319D84C:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319D858:
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// rlwinm r10,r9,3,0,28
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r31,12(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// beq cr6,0x8319d878
	if (cr6.eq) goto loc_8319D878;
	// li r11,0
	r11.s64 = 0;
	// b 0x8319d884
	goto loc_8319D884;
loc_8319D878:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319D884:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319d8ac
	if (cr0.eq) goto loc_8319D8AC;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x8319d8b8
	goto loc_8319D8B8;
loc_8319D8AC:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_8319D8B8:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x8319d8fc
	if (!cr0.eq) goto loc_8319D8FC;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r5,r11,3,0,28
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_8319D8FC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319D828) {
	__imp__sub_8319D828(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319D918) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,584(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 584);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319d940
	if (cr0.eq) goto loc_8319D940;
	// li r11,0
	r11.s64 = 0;
	// b 0x8319d94c
	goto loc_8319D94C;
loc_8319D940:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319D94C:
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r9,r9,5,0,26
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x8319d970
	if (cr0.eq) goto loc_8319D970;
	// lwz r9,44(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// stw r9,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, ctx.r9.u32);
loc_8319D970:
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r31,-4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// stw r9,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r9.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319d990
	if (cr0.eq) goto loc_8319D990;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x8319d99c
	goto loc_8319D99C;
loc_8319D990:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_8319D99C:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x8319d9e4
	if (!cr0.eq) goto loc_8319D9E4;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// rlwinm r11,r11,5,0,26
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_8319D9E4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319D918) {
	__imp__sub_8319D918(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319DA00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319da60
	if (cr0.eq) goto loc_8319DA60;
	// lwz r11,584(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319da40
	if (cr0.eq) goto loc_8319DA40;
	// li r11,0
	r11.s64 = 0;
	// b 0x8319da4c
	goto loc_8319DA4C;
loc_8319DA40:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319DA4C:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r26,-4(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// b 0x8319da6c
	goto loc_8319DA6C;
loc_8319DA60:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
loc_8319DA6C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// lwz r10,556(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 556);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r10,556(r31)
	PPC_STORE_U32(r31.u32 + 556, ctx.r10.u32);
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// oris r10,r10,128
	ctx.r10.u64 = ctx.r10.u64 | 8388608;
	// stw r10,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r10.u32);
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// oris r10,r10,32768
	ctx.r10.u64 = ctx.r10.u64 | 2147483648;
	// stw r10,68(r11)
	PPC_STORE_U32(r11.u32 + 68, ctx.r10.u32);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,117
	ctx.r4.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r28)
	PPC_STORE_U32(r28.u32 + 8, r11.u32);
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r28,-16
	r11.s64 = r28.s64 + -16;
	// li r10,2
	ctx.r10.s64 = 2;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// ori r10,r9,7
	ctx.r10.u64 = ctx.r9.u64 | 7;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r10,556(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 556);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// stw r30,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r30.u32);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// bl 0x831236f0
	sub_831236F0(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r24,1
	r24.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319dd8c
	if (cr6.eq) goto loc_8319DD8C;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// andi. r10,r11,1280
	ctx.r10.u64 = r11.u64 & 1280;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8319dd8c
	if (cr0.eq) goto loc_8319DD8C;
	// lwz r25,32(r31)
	r25.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319db74
	if (!cr0.eq) goto loc_8319DB74;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319ad98
	sub_8319AD98(ctx, base);
loc_8319DB74:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r11,68(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 68);
	// lwz r10,48(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// oris r11,r11,16384
	r11.u64 = r11.u64 | 1073741824;
	// oris r10,r10,4096
	ctx.r10.u64 = ctx.r10.u64 | 268435456;
	// stw r11,68(r30)
	PPC_STORE_U32(r30.u32 + 68, r11.u32);
	// stw r10,48(r30)
	PPC_STORE_U32(r30.u32 + 48, ctx.r10.u32);
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,48(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// oris r11,r11,4096
	r11.u64 = r11.u64 | 268435456;
	// stw r11,48(r29)
	PPC_STORE_U32(r29.u32 + 48, r11.u32);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// addi r27,r30,32
	r27.s64 = r30.s64 + 32;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r11,8(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r22)
	PPC_STORE_U32(r22.u32 + 8, r11.u32);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// bl 0x831236f0
	sub_831236F0(ctx, base);
	// addi r30,r29,32
	r30.s64 = r29.s64 + 32;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r11.u32);
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// bl 0x831236f0
	sub_831236F0(ctx, base);
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c3c8
	sub_8319C3C8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r5,7
	ctx.r5.s64 = 7;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// rlwimi r11,r24,17,13,14
	r11.u64 = (rotl32(r24.u32, 17) & 0x60000) | (r11.u64 & 0xFFFFFFFFFFF9FFFF);
	// li r5,7
	ctx.r5.s64 = 7;
	// stw r11,8(r28)
	PPC_STORE_U32(r28.u32 + 8, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r30,r11,32
	r30.s64 = r11.s64 + 32;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8316c778
	sub_8316C778(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r29,r30,-16
	r29.s64 = r30.s64 + -16;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,6
	r11.u64 = r11.u64 | 393216;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// add r11,r3,r29
	r11.u64 = ctx.r3.u64 + r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r26,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r26.u32);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// add r11,r3,r29
	r11.u64 = ctx.r3.u64 + r29.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwimi r10,r24,5,23,31
	ctx.r10.u64 = (rotl32(r24.u32, 5) & 0x1FF) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFE00);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// stw r25,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r25.u32);
	// b 0x8319de04
	goto loc_8319DE04;
loc_8319DD8C:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,103
	ctx.r6.s64 = 103;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,103
	ctx.r4.s64 = 103;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-4
	r11.s64 = r30.s64 + -4;
	// li r10,15
	ctx.r10.s64 = 15;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// stwx r10,r3,r11
	PPC_STORE_U32(ctx.r3.u32 + r11.u32, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
loc_8319DE04:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r10,0,22,22
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8319de18
	if (!cr0.eq) goto loc_8319DE18;
	// stw r26,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r26.u32);
loc_8319DE18:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319de24
	if (cr6.eq) goto loc_8319DE24;
	// stw r24,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r24.u32);
loc_8319DE24:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_8319DA00) {
	__imp__sub_8319DA00(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319DE30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r3,564(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 564);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x83199928
	sub_83199928(ctx, base);
	// lwz r10,12(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mulli r27,r31,40
	r27.s64 = r31.s64 * 40;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// lwzx r9,r27,r10
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + ctx.r10.u32);
	// clrlwi. r8,r11,31
	ctx.r8.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r31,r9,29,18,31
	r31.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x3FFF;
	// bne 0x8319deb0
	if (!cr0.eq) goto loc_8319DEB0;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8319deb0
	if (cr0.eq) goto loc_8319DEB0;
loc_8319DE90:
	// rlwinm r9,r11,0,0,30
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8319deb0
	if (!cr0.eq) goto loc_8319DEB0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319de90
	if (!cr6.eq) goto loc_8319DE90;
loc_8319DEB0:
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// beq cr6,0x8319df4c
	if (cr6.eq) goto loc_8319DF4C;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x8319decc
	if (cr6.eq) goto loc_8319DECC;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319DECC:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// clrlwi r10,r11,30
	ctx.r10.u64 = r11.u32 & 0x3;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x8319df40
	if (!cr6.eq) goto loc_8319DF40;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm r10,r10,0,18,24
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r10,16000
	cr6.compare<uint32_t>(ctx.r10.u32, 16000, xer);
	// bne cr6,0x8319df40
	if (!cr6.eq) goto loc_8319DF40;
	// rlwinm r4,r11,30,18,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFF;
	// bl 0x83167de0
	sub_83167DE0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,3376(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3376);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bne cr6,0x8319df40
	if (!cr6.eq) goto loc_8319DF40;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8319df84
	if (cr6.eq) goto loc_8319DF84;
	// ld r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r3,r30,8
	ctx.r3.s64 = r30.s64 + 8;
	// rlwinm r5,r11,0,0,28
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF8;
	// std r10,0(r30)
	PPC_STORE_U64(r30.u32 + 0, ctx.r10.u64);
	// bl 0x82ca30e8
	sub_82CA30E8(ctx, base);
	// b 0x8319df84
	goto loc_8319DF84;
loc_8319DF40:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319DF4C:
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x8319df84
	if (cr0.lt) goto loc_8319DF84;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
loc_8319DF5C:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// addi r30,r30,-8
	r30.s64 = r30.s64 + -8;
	// bge 0x8319df5c
	if (!cr0.lt) goto loc_8319DF5C;
loc_8319DF84:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// add r11,r27,r11
	r11.u64 = r27.u64 + r11.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_8319DE30) {
	__imp__sub_8319DE30(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319DFA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// lwz r22,4(r30)
	r22.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplw cr6,r29,r31
	cr6.compare<uint32_t>(r29.u32, r31.u32, xer);
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r23,8(r30)
	r23.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r22,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r22.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r23.u32);
	// bne cr6,0x8319e030
	if (!cr6.eq) goto loc_8319E030;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8319e140
	if (cr6.eq) goto loc_8319E140;
loc_8319DFF8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// ld r11,0(r31)
	r11.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// std r11,0(r3)
	PPC_STORE_U64(ctx.r3.u32 + 0, r11.u64);
	// bne 0x8319dff8
	if (!cr0.eq) goto loc_8319DFF8;
	// b 0x8319e140
	goto loc_8319E140;
loc_8319E030:
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// ble cr6,0x8319e068
	if (!cr6.gt) goto loc_8319E068;
	// ld r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// mr r11,r30
	r11.u64 = r30.u64;
	// ld r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// mr r30,r28
	r30.u64 = r28.u64;
	// mr r29,r31
	r29.u64 = r31.u64;
	// mr r28,r11
	r28.u64 = r11.u64;
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// mr r31,r10
	r31.u64 = ctx.r10.u64;
	// lwz r23,84(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r22,80(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// std r8,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r8.u64);
loc_8319E068:
	// rlwinm r24,r31,3,0,28
	r24.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83110880
	sub_83110880(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8319e0b4
	if (cr6.eq) goto loc_8319E0B4;
	// mr r27,r25
	r27.u64 = r25.u64;
	// mr r26,r31
	r26.u64 = r31.u64;
loc_8319E090:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addic. r26,r26,-1
	xer.ca = r26.u32 > 0;
	r26.s64 = r26.s64 + -1;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r11.u32);
	// addi r27,r27,8
	r27.s64 = r27.s64 + 8;
	// bne 0x8319e090
	if (!cr0.eq) goto loc_8319E090;
loc_8319E0B4:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8319e0f4
	if (cr6.eq) goto loc_8319E0F4;
loc_8319E0C8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319aa20
	sub_8319AA20(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8319aa20
	sub_8319AA20(ctx, base);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// bne 0x8319e0c8
	if (!cr0.eq) goto loc_8319E0C8;
loc_8319E0F4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// stw r22,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r22.u32);
	// stw r23,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r23.u32);
	// beq cr6,0x8319e12c
	if (cr6.eq) goto loc_8319E12C;
	// mr r29,r25
	r29.u64 = r25.u64;
loc_8319E108:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// addi r29,r29,8
	r29.s64 = r29.s64 + 8;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// bne 0x8319e108
	if (!cr0.eq) goto loc_8319E108;
loc_8319E12C:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x83118478
	sub_83118478(ctx, base);
loc_8319E140:
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stw r22,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r22.u32);
	// stw r23,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r23.u32);
	// stw r11,4(r28)
	PPC_STORE_U32(r28.u32 + 4, r11.u32);
	// stw r10,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r10.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c1c
	return;
}

PPC_WEAK_FUNC(sub_8319DFA8) {
	__imp__sub_8319DFA8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319E160) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// li r24,0
	r24.s64 = 0;
loc_8319E180:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8319e304
	if (cr6.eq) goto loc_8319E304;
	// cmplwi cr6,r25,4
	cr6.compare<uint32_t>(r25.u32, 4, xer);
	// mr r27,r25
	r27.u64 = r25.u64;
	// blt cr6,0x8319e198
	if (cr6.lt) goto loc_8319E198;
	// li r27,4
	r27.s64 = 4;
loc_8319E198:
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lis r10,512
	ctx.r10.s64 = 33554432;
	// rlwinm r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8319e1fc
	if (!cr6.eq) goto loc_8319E1FC;
	// mr r30,r29
	r30.u64 = r29.u64;
	// b 0x8319e2cc
	goto loc_8319E2CC;
loc_8319E1FC:
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lis r10,1024
	ctx.r10.s64 = 67108864;
	// rlwinm r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8319e280
	if (!cr6.gt) goto loc_8319E280;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_8319E280:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lis r10,1536
	ctx.r10.s64 = 100663296;
	// rlwinm r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8319e2cc
	if (!cr6.gt) goto loc_8319E2CC;
	// li r5,3
	ctx.r5.s64 = 3;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_8319E2CC:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x8319e2dc
	if (!cr6.eq) goto loc_8319E2DC;
	// mr r24,r30
	r24.u64 = r30.u64;
	// b 0x8319e2f0
	goto loc_8319E2F0;
loc_8319E2DC:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
loc_8319E2F0:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// subf r25,r27,r25
	r25.s64 = r25.s64 - r27.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x8319e180
	goto loc_8319E180;
loc_8319E304:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_8319E160) {
	__imp__sub_8319E160(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319E310) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r22,r8
	r22.u64 = ctx.r8.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// mr r23,r9
	r23.u64 = ctx.r9.u64;
	// mr r21,r10
	r21.u64 = ctx.r10.u64;
	// cmplwi cr6,r22,1
	cr6.compare<uint32_t>(r22.u32, 1, xer);
	// blt cr6,0x8319e4e4
	if (cr6.lt) goto loc_8319E4E4;
	// beq cr6,0x8319e490
	if (cr6.eq) goto loc_8319E490;
	// cmplwi cr6,r22,3
	cr6.compare<uint32_t>(r22.u32, 3, xer);
	// blt cr6,0x8319e3b8
	if (cr6.lt) goto loc_8319E3B8;
	// cmplwi cr6,r22,5
	cr6.compare<uint32_t>(r22.u32, 5, xer);
	// blt cr6,0x8319e360
	if (cr6.lt) goto loc_8319E360;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319E360:
	// lwz r4,284(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x8319e3a8
	if (!cr6.eq) goto loc_8319E3A8;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lis r11,512
	r11.s64 = 33554432;
	// lis r12,-3073
	r12.s64 = -201392128;
	// ori r11,r11,7296
	r11.u64 = r11.u64 | 7296;
	// ori r12,r12,64671
	r12.u64 = r12.u64 | 64671;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// rlwimi r11,r10,26,25,26
	r11.u64 = (rotl32(ctx.r10.u32, 26) & 0x60) | (r11.u64 & 0xFFFFFFFFFFFFFF9F);
	// and r10,r9,r12
	ctx.r10.u64 = ctx.r9.u64 & r12.u64;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
loc_8319E3A8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831984a8
	sub_831984A8(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// b 0x8319e4e4
	goto loc_8319E4E4;
loc_8319E3B8:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lis r10,2048
	ctx.r10.s64 = 134217728;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,0,4,6
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8319e3d8
	if (cr6.eq) goto loc_8319E3D8;
	// li r4,3536
	ctx.r4.s64 = 3536;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319E3D8:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,512
	ctx.r10.s64 = 33554432;
	// lis r12,-3073
	r12.s64 = -201392128;
	// ori r10,r10,7296
	ctx.r10.u64 = ctx.r10.u64 | 7296;
	// ori r12,r12,64671
	r12.u64 = r12.u64 | 64671;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// rlwimi r10,r9,26,25,26
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 26) & 0x60) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFF9F);
	// and r9,r8,r12
	ctx.r9.u64 = ctx.r8.u64 & r12.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x83198160
	sub_83198160(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// rlwinm r27,r24,25,4,6
	r27.u64 = rotl64(r24.u32 | (r24.u64 << 32), 25) & 0xE000000;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r11,0,27,20
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFF81F;
	// rlwinm r11,r11,0,7,3
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// or r11,r11,r27
	r11.u64 = r11.u64 | r27.u64;
	// ori r11,r11,6144
	r11.u64 = r11.u64 | 6144;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r10,r10,0,7,3
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// or r10,r10,r27
	ctx.r10.u64 = ctx.r10.u64 | r27.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x8319e4e4
	goto loc_8319E4E4;
loc_8319E490:
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198628
	sub_83198628(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,276(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// bl 0x831986d0
	sub_831986D0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// stw r3,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, ctx.r3.u32);
	// oris r11,r11,64
	r11.u64 = r11.u64 | 4194304;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
loc_8319E4E4:
	// clrlwi. r25,r30,24
	r25.u64 = r30.u32 & 0xFF;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// li r27,1
	r27.s64 = 1;
	// beq 0x8319e778
	if (cr0.eq) goto loc_8319E778;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwimi r11,r27,27,4,6
	r11.u64 = (rotl32(r27.u32, 27) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// rlwinm r10,r11,23,30,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 23) & 0x3;
	// rlwinm r9,r11,25,28,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0xC;
	// rlwinm r8,r11,31,24,27
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0xF0;
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// rlwinm r11,r11,0,27,18
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r5,12(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwimi r10,r27,27,4,6
	ctx.r10.u64 = (rotl32(r27.u32, 27) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// rlwinm r9,r10,27,24,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0xFF;
	// rlwinm r8,r10,23,30,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0x3;
	// rlwinm r7,r10,25,28,29
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0xC;
	// mr r6,r9
	ctx.r6.u64 = ctx.r9.u64;
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// rlwinm r10,r10,0,27,18
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// rlwimi r6,r8,2,26,29
	ctx.r6.u64 = (rotl32(ctx.r8.u32, 2) & 0x3C) | (ctx.r6.u64 & 0xFFFFFFFFFFFFFFC3);
	// clrlwi r8,r6,26
	ctx.r8.u64 = ctx.r6.u32 & 0x3F;
	// rlwimi r9,r8,4,0,27
	ctx.r9.u64 = (rotl32(ctx.r8.u32, 4) & 0xFFFFFFF0) | (ctx.r9.u64 & 0xFFFFFFFF0000000F);
	// rlwinm r9,r9,3,0,26
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFE0;
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x83197c88
	sub_83197C88(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,14
	ctx.r10.s64 = 917504;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r10,r10,24833
	ctx.r10.u64 = ctx.r10.u64 | 24833;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r9,r10,25,19,31
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 25) & 0x1FFF) | (ctx.r9.u64 & 0xFFFFFFFFFFFFE000);
	// rlwimi r9,r10,25,4,6
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 25) & 0xE000000) | (ctx.r9.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// bl 0x83198160
	sub_83198160(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwimi r11,r27,26,4,6
	r11.u64 = (rotl32(r27.u32, 26) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,1
	ctx.r10.s64 = 65536;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// ori r10,r10,7
	ctx.r10.u64 = ctx.r10.u64 | 7;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// rlwimi r9,r10,10,19,26
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 10) & 0x1FE0) | (ctx.r9.u64 & 0xFFFFFFFFFFFFE01F);
	// rlwimi r9,r10,10,4,6
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 10) & 0xE000000) | (ctx.r9.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// lfs f4,3084(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	ctx.f4.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lfs f1,2708(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2708);
	ctx.f1.f64 = double(temp.f32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwimi r11,r27,26,4,6
	r11.u64 = (rotl32(r27.u32, 26) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r27,26,4,6
	ctx.r10.u64 = (rotl32(r27.u32, 26) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// rlwinm r9,r10,27,24,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0xFF;
	// rlwinm r8,r10,27,30,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x3;
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
	// rlwimi r7,r9,2,28,29
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 2) & 0xC) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFFF3);
	// rlwinm r9,r7,0,0,29
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFC;
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// rlwimi r10,r9,5,19,26
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 5) & 0x1FE0) | (ctx.r10.u64 & 0xFFFFFFFFFFFFE01F);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,3
	ctx.r6.s64 = 3;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cde60
	sub_831CDE60(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// lis r11,14
	r11.s64 = 917504;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// ori r11,r11,20481
	r11.u64 = r11.u64 | 20481;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,0(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// rlwimi r10,r11,25,19,26
	ctx.r10.u64 = (rotl32(r11.u32, 25) & 0x1FE0) | (ctx.r10.u64 & 0xFFFFFFFFFFFFE01F);
	// rlwimi r10,r11,25,4,6
	ctx.r10.u64 = (rotl32(r11.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r20)
	PPC_STORE_U32(r20.u32 + 0, ctx.r10.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwimi r11,r27,25,4,6
	r11.u64 = (rotl32(r27.u32, 25) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lis r11,14
	r11.s64 = 917504;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// ori r11,r11,28673
	r11.u64 = r11.u64 | 28673;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwimi r10,r11,25,19,26
	ctx.r10.u64 = (rotl32(r11.u32, 25) & 0x1FE0) | (ctx.r10.u64 & 0xFFFFFFFFFFFFE01F);
	// rlwimi r10,r11,25,4,6
	ctx.r10.u64 = (rotl32(r11.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r28)
	PPC_STORE_U32(r28.u32 + 44, ctx.r3.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,52(r28)
	PPC_STORE_U32(r28.u32 + 52, ctx.r3.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
loc_8319E778:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwimi r11,r24,25,4,6
	r11.u64 = (rotl32(r24.u32, 25) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r30,0(r26)
	r30.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8319e7a0
	if (cr6.eq) goto loc_8319E7A0;
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// clrlwi. r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r27
	r11.u64 = r27.u64;
	// beq 0x8319e7a4
	if (cr0.eq) goto loc_8319E7A4;
loc_8319E7A0:
	// li r11,0
	r11.s64 = 0;
loc_8319E7A4:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319e7ec
	if (cr0.eq) goto loc_8319E7EC;
	// lwz r10,4(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r10,r10,15,17,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0x7FFF;
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,0,25,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x70;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x8319e7dc
	if (cr6.eq) goto loc_8319E7DC;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319E7DC:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r10,r11,0,28,28
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319e93c
	if (cr0.eq) goto loc_8319E93C;
	// b 0x8319e8dc
	goto loc_8319E8DC;
loc_8319E7EC:
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8319e808
	if (!cr6.eq) goto loc_8319E808;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319E808:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x8319e830
	if (cr6.eq) goto loc_8319E830;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x8319ea30
	if (!cr6.eq) goto loc_8319EA30;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r10,r11,0,25,26
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x60;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8319ea24
	if (!cr0.eq) goto loc_8319EA24;
	// clrlwi. r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319ea24
	if (!cr0.eq) goto loc_8319EA24;
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
loc_8319E830:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,384
	cr6.compare<uint32_t>(r11.u32, 384, xer);
	// bne cr6,0x8319e884
	if (!cr6.eq) goto loc_8319E884;
	// lwz r28,44(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// lwz r4,48(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8310fb10
	sub_8310FB10(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319e8e8
	if (cr0.eq) goto loc_8319E8E8;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lis r10,512
	ctx.r10.s64 = 33554432;
	// rlwinm r9,r11,0,4,6
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x8319e8e8
	if (!cr6.eq) goto loc_8319E8E8;
	// rlwinm. r10,r11,0,25,26
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x60;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8319e8e8
	if (!cr0.eq) goto loc_8319E8E8;
	// andi. r11,r11,23
	r11.u64 = r11.u64 & 23;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x8319e8e8
	if (!cr0.eq) goto loc_8319E8E8;
	// lwz r30,12(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 12);
loc_8319E884:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r28,r11,25,25,31
	r28.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r28,118
	cr6.compare<uint32_t>(r28.u32, 118, xer);
	// beq cr6,0x8319e93c
	if (cr6.eq) goto loc_8319E93C;
	// cmplwi cr6,r28,112
	cr6.compare<uint32_t>(r28.u32, 112, xer);
	// bne cr6,0x8319e8f4
	if (!cr6.eq) goto loc_8319E8F4;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,112
	ctx.r4.s64 = 112;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r10,r30,-8
	ctx.r10.s64 = r30.s64 + -8;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwzx r10,r3,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r10.u32);
	// clrlwi r10,r10,17
	ctx.r10.u64 = ctx.r10.u32 & 0x7FFF;
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,0,25,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x70;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bne cr6,0x8319e8f4
	if (!cr6.eq) goto loc_8319E8F4;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
loc_8319E8DC:
	// ori r11,r11,128
	r11.u64 = r11.u64 | 128;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// b 0x8319e93c
	goto loc_8319E93C;
loc_8319E8E8:
	// li r4,3538
	ctx.r4.s64 = 3538;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319E8F4:
	// cmplwi cr6,r28,124
	cr6.compare<uint32_t>(r28.u32, 124, xer);
	// bne cr6,0x8319ea18
	if (!cr6.eq) goto loc_8319EA18;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r10,r30,-8
	ctx.r10.s64 = r30.s64 + -8;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwzx r10,r3,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r10.u32);
	// clrlwi r10,r10,17
	ctx.r10.u64 = ctx.r10.u32 & 0x7FFF;
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,0,25,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x70;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bne cr6,0x8319ea18
	if (!cr6.eq) goto loc_8319EA18;
loc_8319E93C:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c440
	sub_8319C440(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r29,-24
	r11.s64 = r29.s64 + -24;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// add r30,r3,r11
	r30.u64 = ctx.r3.u64 + r11.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwimi r11,r27,0,27,31
	r11.u64 = (rotl32(r27.u32, 0) & 0x1F) | (r11.u64 & 0xFFFFFFFFFFFFFFE0);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// beq cr6,0x8319e990
	if (cr6.eq) goto loc_8319E990;
	// ori r11,r11,49152
	r11.u64 = r11.u64 | 49152;
	// b 0x8319e998
	goto loc_8319E998;
loc_8319E990:
	// addi r10,r24,-1
	ctx.r10.s64 = r24.s64 + -1;
	// rlwimi r11,r10,14,16,17
	r11.u64 = (rotl32(ctx.r10.u32, 14) & 0xC000) | (r11.u64 & 0xFFFFFFFFFFFF3FFF);
loc_8319E998:
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// cmpwi cr6,r22,4
	cr6.compare<int32_t>(r22.s32, 4, xer);
	// beq cr6,0x8319e9b0
	if (cr6.eq) goto loc_8319E9B0;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// oris r11,r11,4096
	r11.u64 = r11.u64 | 268435456;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_8319E9B0:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x8319e9e0
	if (cr6.eq) goto loc_8319E9E0;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// oris r11,r11,8192
	r11.u64 = r11.u64 | 536870912;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_8319E9E0:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x8319ea0c
	if (cr6.eq) goto loc_8319EA0C;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,276(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
loc_8319EA0C:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	return;
loc_8319EA18:
	// li r4,3538
	ctx.r4.s64 = 3538;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319EA24:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319EA30:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_8319E310) {
	__imp__sub_8319E310(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319EA40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stfd f31,-112(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -112, f31.u64);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// li r23,0
	r23.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// stw r23,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r23.u32);
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r22,r23
	r22.u64 = r23.u64;
	// rlwinm. r11,r11,0,4,17
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFC000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r24,r23
	r24.u64 = r23.u64;
	// beq 0x8319ec08
	if (cr0.eq) goto loc_8319EC08;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r27,r28,12
	r27.s64 = r28.s64 + 12;
	// lfs f31,3084(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f31.f64 = double(temp.f32);
loc_8319EA8C:
	// ld r11,0(r27)
	r11.u64 = PPC_LOAD_U64(r27.u32 + 0);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// clrlwi r11,r10,30
	r11.u64 = ctx.r10.u32 & 0x3;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8319eb10
	if (!cr6.eq) goto loc_8319EB10;
	// rlwinm. r10,r10,16,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319eb10
	if (cr0.eq) goto loc_8319EB10;
	// lwz r30,88(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x8319eac4
	if (cr6.eq) goto loc_8319EAC4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r22,r11
	cr6.compare<uint32_t>(r22.u32, r11.u32, xer);
	// beq cr6,0x8319eaf4
	if (cr6.eq) goto loc_8319EAF4;
loc_8319EAC4:
	// ld r11,0(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// bl 0x83199740
	sub_83199740(ctx, base);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r22,88(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// rlwinm r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// stw r3,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r3.u32);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
loc_8319EAF4:
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// ld r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319ea40
	sub_8319EA40(ctx, base);
	// b 0x8319ebe8
	goto loc_8319EBE8;
loc_8319EB10:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8319eb24
	if (!cr6.eq) goto loc_8319EB24;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b7f8
	sub_8319B7F8(ctx, base);
loc_8319EB24:
	// clrldi r11,r29,32
	r11.u64 = r29.u64 & 0xFFFFFFFF;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fneg f1,f0
	ctx.f1.u64 = f0.u64 ^ 0x8000000000000000;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x83199740
	sub_83199740(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// ld r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d450
	sub_8319D450(ctx, base);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r5,22
	ctx.r5.s64 = 22;
	// li r4,12
	ctx.r4.s64 = 12;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// clrlwi r21,r11,18
	r21.u64 = r11.u32 & 0x3FFF;
	// rlwinm r20,r11,18,18,31
	r20.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x3FFF;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// rlwimi r20,r21,14,4,17
	r20.u64 = (rotl32(r21.u32, 14) & 0xFFFC000) | (r20.u64 & 0xFFFFFFFFF0003FFF);
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r30.u32);
	// rlwinm r10,r10,0,15,15
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10000;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r23,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r23.u32);
	// rlwimi r20,r9,0,0,3
	r20.u64 = (rotl32(ctx.r9.u32, 0) & 0xF0000000) | (r20.u64 & 0xFFFFFFFF0FFFFFFF);
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// ld r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// stw r20,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r20.u32);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// bl 0x8319fa18
	sub_8319FA18(ctx, base);
loc_8319EBE8:
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r27,r27,8
	r27.s64 = r27.s64 + 8;
	// clrlwi r11,r10,18
	r11.u64 = ctx.r10.u32 & 0x3FFF;
	// rlwinm r10,r10,18,18,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x3FFF;
	// add r29,r11,r29
	r29.u64 = r11.u64 + r29.u64;
	// cmplw cr6,r24,r10
	cr6.compare<uint32_t>(r24.u32, ctx.r10.u32, xer);
	// blt cr6,0x8319ea8c
	if (cr6.lt) goto loc_8319EA8C;
loc_8319EC08:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// lfd f31,-112(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// b 0x82ca2c18
	return;
}

PPC_WEAK_FUNC(sub_8319EA40) {
	__imp__sub_8319EA40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319EC18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb8
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,-1
	r11.s64 = -1;
	// std r5,256(r1)
	PPC_STORE_U64(ctx.r1.u32 + 256, ctx.r5.u64);
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// mr r16,r8
	r16.u64 = ctx.r8.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r18,r7
	r18.u64 = ctx.r7.u64;
	// mr r23,r16
	r23.u64 = r16.u64;
	// mr r20,r11
	r20.u64 = r11.u64;
	// mr r17,r11
	r17.u64 = r11.u64;
	// li r28,0
	r28.s64 = 0;
	// li r21,4
	r21.s64 = 4;
	// mr r24,r11
	r24.u64 = r11.u64;
	// li r22,0
	r22.s64 = 0;
	// li r19,0
	r19.s64 = 0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8319ede0
	if (cr6.eq) goto loc_8319EDE0;
loc_8319EC68:
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// lwz r30,4(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r27,8(r29)
	r27.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// add r23,r23,r18
	r23.u64 = r23.u64 + r18.u64;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r30,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r30.u32);
	// stw r27,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r27.u32);
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi r9,r10,30
	ctx.r9.u64 = ctx.r10.u32 & 0x3;
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x8319ecbc
	if (!cr6.eq) goto loc_8319ECBC;
	// lwz r30,0(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// li r27,0
	r27.s64 = 0;
	// rlwinm r26,r10,30,18,31
	r26.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFF;
	// b 0x8319ece4
	goto loc_8319ECE4;
loc_8319ECBC:
	// cmplwi cr6,r9,2
	cr6.compare<uint32_t>(ctx.r9.u32, 2, xer);
	// bne cr6,0x8319edb4
	if (!cr6.eq) goto loc_8319EDB4;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,31,17,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFE;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r30,12(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwinm r11,r9,27,24,31
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0xFF;
	// clrlwi r27,r9,27
	r27.u64 = ctx.r9.u32 & 0x1F;
	// srw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi r26,r11,30
	r26.u64 = r11.u32 & 0x3;
loc_8319ECE4:
	// rlwinm. r11,r27,0,27,28
	r11.u64 = rotl64(r27.u32 | (r27.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319edb4
	if (!cr0.eq) goto loc_8319EDB4;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,124
	cr6.compare<uint32_t>(r11.u32, 124, xer);
	// bne cr6,0x8319ed30
	if (!cr6.eq) goto loc_8319ED30;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-8
	r11.s64 = r30.s64 + -8;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r10,r10,0,11,11
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319edb4
	if (cr0.eq) goto loc_8319EDB4;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x8319ed68
	goto loc_8319ED68;
loc_8319ED30:
	// cmplwi cr6,r11,97
	cr6.compare<uint32_t>(r11.u32, 97, xer);
	// bne cr6,0x8319edb4
	if (!cr6.eq) goto loc_8319EDB4;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-24
	r11.s64 = r30.s64 + -24;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwinm. r10,r10,0,14,14
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319edb4
	if (cr0.eq) goto loc_8319EDB4;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_8319ED68:
	// clrlwi r10,r11,17
	ctx.r10.u64 = r11.u32 & 0x7FFF;
	// rlwinm r11,r11,17,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 17) & 0x3FFF;
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x8319edc0
	if (cr6.eq) goto loc_8319EDC0;
	// cmplwi cr6,r19,1
	cr6.compare<uint32_t>(r19.u32, 1, xer);
	// bne cr6,0x8319ed8c
	if (!cr6.eq) goto loc_8319ED8C;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// bge cr6,0x8319edb4
	if (!cr6.lt) goto loc_8319EDB4;
	// subf r22,r24,r11
	r22.s64 = r11.s64 - r24.s64;
loc_8319ED8C:
	// cmplw cr6,r20,r10
	cr6.compare<uint32_t>(r20.u32, ctx.r10.u32, xer);
	// bne cr6,0x8319edb4
	if (!cr6.eq) goto loc_8319EDB4;
	// cmplw cr6,r17,r27
	cr6.compare<uint32_t>(r17.u32, r27.u32, xer);
	// bne cr6,0x8319edb4
	if (!cr6.eq) goto loc_8319EDB4;
	// cmpw cr6,r21,r26
	cr6.compare<int32_t>(r21.s32, r26.s32, xer);
	// bne cr6,0x8319edb4
	if (!cr6.eq) goto loc_8319EDB4;
	// mullw r10,r19,r22
	ctx.r10.s64 = int64_t(r19.s32) * int64_t(r22.s32);
	// add r10,r10,r24
	ctx.r10.u64 = ctx.r10.u64 + r24.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x8319edd4
	if (cr6.eq) goto loc_8319EDD4;
loc_8319EDB4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8319EDB8:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c08
	return;
loc_8319EDC0:
	// mr r28,r30
	r28.u64 = r30.u64;
	// mr r20,r10
	r20.u64 = ctx.r10.u64;
	// mr r17,r27
	r17.u64 = r27.u64;
	// mr r21,r26
	r21.u64 = r26.u64;
	// mr r24,r11
	r24.u64 = r11.u64;
loc_8319EDD4:
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// cmplw cr6,r19,r25
	cr6.compare<uint32_t>(r19.u32, r25.u32, xer);
	// blt cr6,0x8319ec68
	if (cr6.lt) goto loc_8319EC68;
loc_8319EDE0:
	// addi r4,r1,256
	ctx.r4.s64 = ctx.r1.s64 + 256;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831979c0
	sub_831979C0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r22,1
	cr6.compare<uint32_t>(r22.u32, 1, xer);
	// beq cr6,0x8319ee68
	if (cr6.eq) goto loc_8319EE68;
	// clrldi r10,r22,32
	ctx.r10.u64 = r22.u64 & 0xFFFFFFFF;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// li r5,1
	ctx.r5.s64 = 1;
	// lfs f4,3084(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	ctx.f4.f64 = double(temp.f32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x8319c788
	sub_8319C788(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_8319EE68:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r27,1
	r27.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,124
	cr6.compare<uint32_t>(r11.u32, 124, xer);
	// bne cr6,0x8319ef94
	if (!cr6.eq) goto loc_8319EF94;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// rlwimi r11,r10,26,19,26
	r11.u64 = (rotl32(ctx.r10.u32, 26) & 0x1FE0) | (r11.u64 & 0xFFFFFFFFFFFFE01F);
	// rlwimi r11,r10,26,4,6
	r11.u64 = (rotl32(ctx.r10.u32, 26) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bl 0x83198208
	sub_83198208(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// rlwinm r11,r21,5,22,26
	r11.u64 = rotl64(r21.u32 | (r21.u64 << 32), 5) & 0x3E0;
	// lis r12,-3073
	r12.s64 = -201392128;
	// rlwinm r11,r11,0,25,23
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
	// ori r12,r12,64671
	r12.u64 = r12.u64 | 64671;
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// li r8,1
	ctx.r8.s64 = 1;
	// ori r11,r11,7296
	r11.u64 = r11.u64 | 7296;
	// and r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 & r12.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// li r6,118
	ctx.r6.s64 = 118;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r26)
	PPC_STORE_U32(r26.u32 + 44, ctx.r3.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,48(r26)
	PPC_STORE_U32(r26.u32 + 48, ctx.r3.u32);
	// li r5,22
	ctx.r5.s64 = 22;
	// li r4,12
	ctx.r4.s64 = 12;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// rlwimi r25,r22,14,4,17
	r25.u64 = (rotl32(r22.u32, 14) & 0xFFFC000) | (r25.u64 & 0xFFFFFFFFF0003FFF);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// rlwimi r25,r9,0,0,3
	r25.u64 = (rotl32(ctx.r9.u32, 0) & 0xF0000000) | (r25.u64 & 0xFFFFFFFF0FFFFFFF);
	// stw r25,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r25.u32);
	// lwz r10,16(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// stw r11,16(r26)
	PPC_STORE_U32(r26.u32 + 16, r11.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwimi r11,r27,3,27,31
	r11.u64 = (rotl32(r27.u32, 3) & 0x1F) | (r11.u64 & 0xFFFFFFFFFFFFFFE0);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r11,r4,24
	r11.s64 = ctx.r4.s64 + 24;
	// ori r5,r11,3
	ctx.r5.u64 = r11.u64 | 3;
	// bl 0x831d3380
	sub_831D3380(ctx, base);
	// b 0x8319f0dc
	goto loc_8319F0DC;
loc_8319EF94:
	// cmplwi cr6,r11,97
	cr6.compare<uint32_t>(r11.u32, 97, xer);
	// bne cr6,0x8319f130
	if (!cr6.eq) goto loc_8319F130;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r5,48(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdf00
	sub_831CDF00(ctx, base);
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r10,28(r30)
	PPC_STORE_U32(r30.u32 + 28, ctx.r10.u32);
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r8,r10,-36
	ctx.r8.s64 = ctx.r10.s64 + -36;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r9,r11,-36
	ctx.r9.s64 = r11.s64 + -36;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r4,44(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r3,48(r30)
	PPC_STORE_U32(r30.u32 + 48, ctx.r3.u32);
	// lwz r4,12(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,15360
	cr6.compare<uint32_t>(r11.u32, 15360, xer);
	// bne cr6,0x8319f0cc
	if (!cr6.eq) goto loc_8319F0CC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdf00
	sub_831CDF00(ctx, base);
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r11,r3,0,0,30
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// stw r10,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r10.u32);
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r8,r10,-36
	ctx.r8.s64 = ctx.r10.s64 + -36;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r9,r11,-36
	ctx.r9.s64 = r11.s64 + -36;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// b 0x8319f0ac
	goto loc_8319F0AC;
loc_8319F0A4:
	// addi r10,r9,8
	ctx.r10.s64 = ctx.r9.s64 + 8;
	// lwz r9,8(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
loc_8319F0AC:
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x8319f0a4
	if (!cr6.eq) goto loc_8319F0A4;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// stw r3,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r3.u32);
loc_8319F0CC:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_8319F0DC:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// rlwimi r11,r17,0,27,31
	r11.u64 = (rotl32(r17.u32, 0) & 0x1F) | (r11.u64 & 0xFFFFFFFFFFFFFFE0);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r28,8(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r31,4(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r28,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r28.u32);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// stw r31,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r31.u32);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwimi r10,r27,1,16,14
	ctx.r10.u64 = (rotl32(r27.u32, 1) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// b 0x8319edb8
	goto loc_8319EDB8;
loc_8319F130:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_8319EC18) {
	__imp__sub_8319EC18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319F138) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x83195ce8
	sub_83195CE8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319f188
	if (cr0.eq) goto loc_8319F188;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lfd f13,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// lfd f0,19504(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 19504);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x8319f188
	if (cr6.lt) goto loc_8319F188;
	// lis r11,-32240
	r11.s64 = -2112880640;
	// lfd f0,3344(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 3344);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x8319f284
	if (!cr6.gt) goto loc_8319F284;
loc_8319F188:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f31,3084(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3084);
	f31.f64 = double(temp.f32);
	// lfs f1,420(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 420);
	ctx.f1.f64 = double(temp.f32);
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lfs f1,3056(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3056);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lis r11,-32255
	r11.s64 = -2113863680;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f1,26868(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 26868);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lis r11,-32240
	r11.s64 = -2112880640;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// lfs f1,2376(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2376);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d0e0
	sub_8319D0E0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319cf40
	sub_8319CF40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198bd8
	sub_83198BD8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d010
	sub_8319D010(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319cf40
	sub_8319CF40(ctx, base);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r3,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r3.u32);
	// addi r30,r1,80
	r30.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
loc_8319F284:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r28,11
	cr6.compare<int32_t>(r28.s32, 11, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x8319f2ac
	if (!cr6.eq) goto loc_8319F2AC;
	// bl 0x83198400
	sub_83198400(ctx, base);
	// b 0x8319f2e4
	goto loc_8319F2E4;
loc_8319F2AC:
	// bl 0x83198358
	sub_83198358(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r28,74
	cr6.compare<int32_t>(r28.s32, 74, xer);
	// bne cr6,0x8319f2e8
	if (!cr6.eq) goto loc_8319F2E8;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198400
	sub_83198400(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198db0
	sub_83198DB0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
loc_8319F2E4:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_8319F2E8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319F138) {
	__imp__sub_8319F138(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319F2F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8319f310
	if (cr0.eq) goto loc_8319F310;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8319F310:
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319f32c
	if (cr0.eq) goto loc_8319F32C;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// b 0x8319f338
	goto loc_8319F338;
loc_8319F32C:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319F338:
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319f350
	if (cr6.eq) goto loc_8319F350;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// blr 
	return;
loc_8319F350:
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319F2F8) {
	__imp__sub_8319F2F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319F358) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319F358) {
	__imp__sub_8319F358(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319F3A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319f3f4
	if (cr0.eq) goto loc_8319F3F4;
	// li r11,0
	r11.s64 = 0;
loc_8319F3D4:
	// li r10,0
	ctx.r10.s64 = 0;
loc_8319F3D8:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_8319F3F4:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319f3d4
	if (cr0.eq) goto loc_8319F3D4;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x8319f3d8
	goto loc_8319F3D8;
}

PPC_WEAK_FUNC(sub_8319F3A0) {
	__imp__sub_8319F3A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319F410) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x83195b00
	sub_83195B00(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x8319f484
	if (!cr0.eq) goto loc_8319F484;
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319f478
	if (cr6.eq) goto loc_8319F478;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x8319f478
	if (!cr6.eq) goto loc_8319F478;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// beq cr6,0x8319f468
	if (cr6.eq) goto loc_8319F468;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319F468:
	// li r4,3606
	ctx.r4.s64 = 3606;
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x830fd220
	sub_830FD220(ctx, base);
	// b 0x8319f680
	goto loc_8319F680;
loc_8319F478:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319F484:
	// lis r11,-31952
	r11.s64 = -2094006272;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,14480
	r11.s64 = r11.s64 + 14480;
	// li r29,1
	r29.s64 = 1;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// slw r9,r29,r30
	ctx.r9.u64 = r30.u8 & 0x20 ? 0 : (r29.u32 << (r30.u8 & 0x3F));
	// lwz r10,-4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// clrlwi. r8,r11,31
	ctx.r8.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// or r27,r10,r9
	r27.u64 = ctx.r10.u64 | ctx.r9.u64;
	// beq 0x8319f4bc
	if (cr0.eq) goto loc_8319F4BC;
	// li r11,0
	r11.s64 = 0;
loc_8319F4BC:
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// li r11,0
	r11.s64 = 0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
loc_8319F4CC:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8319f4e8
	if (cr6.eq) goto loc_8319F4E8;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x8319f4ec
	if (!cr6.eq) goto loc_8319F4EC;
loc_8319F4E8:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_8319F4EC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319f624
	if (!cr0.eq) goto loc_8319F624;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r31,r11,r10
	r31.u64 = r11.u64 + ctx.r10.u64;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// slw r10,r29,r11
	ctx.r10.u64 = r11.u8 & 0x20 ? 0 : (r29.u32 << (r11.u8 & 0x3F));
	// and r10,r10,r27
	ctx.r10.u64 = ctx.r10.u64 & r27.u64;
	// rlwinm. r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319f5ec
	if (cr0.eq) goto loc_8319F5EC;
	// cmpw cr6,r11,r30
	cr6.compare<int32_t>(r11.s32, r30.s32, xer);
	// bne cr6,0x8319f530
	if (!cr6.eq) goto loc_8319F530;
	// li r4,3577
	ctx.r4.s64 = 3577;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
	// b 0x8319f5dc
	goto loc_8319F5DC;
loc_8319F530:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// beq cr6,0x8319f55c
	if (cr6.eq) goto loc_8319F55C;
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// bne cr6,0x8319f574
	if (!cr6.eq) goto loc_8319F574;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8319f574
	if (!cr6.eq) goto loc_8319F574;
	// li r4,3578
	ctx.r4.s64 = 3578;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
	// b 0x8319f680
	goto loc_8319F680;
loc_8319F55C:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8319f574
	if (!cr6.eq) goto loc_8319F574;
	// li r4,3578
	ctx.r4.s64 = 3578;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_8319F574:
	// clrlwi. r11,r10,24
	r11.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319f5dc
	if (!cr0.eq) goto loc_8319F5DC;
	// lwz r10,16(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8319f618
	if (cr6.eq) goto loc_8319F618;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8319f618
	if (!cr6.eq) goto loc_8319F618;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8319f5f8
	if (!cr6.eq) goto loc_8319F5F8;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319f60c
	if (cr6.eq) goto loc_8319F60C;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// bne cr6,0x8319f60c
	if (!cr6.eq) goto loc_8319F60C;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// cmpwi cr6,r9,9
	cr6.compare<int32_t>(ctx.r9.s32, 9, xer);
	// bne cr6,0x8319f604
	if (!cr6.eq) goto loc_8319F604;
	// li r4,3579
	ctx.r4.s64 = 3579;
	// lwz r6,24(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x830fd220
	sub_830FD220(ctx, base);
loc_8319F5DC:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319ba60
	sub_8319BA60(ctx, base);
loc_8319F5E4:
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// b 0x8319f4cc
	goto loc_8319F4CC;
loc_8319F5EC:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// b 0x8319f5e4
	goto loc_8319F5E4;
loc_8319F5F8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319F604:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319F60C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319F618:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319F624:
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319f654
	if (!cr0.eq) goto loc_8319F654;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8319f654
	if (cr0.eq) goto loc_8319F654;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8319f660
	if (!cr6.gt) goto loc_8319F660;
loc_8319F654:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8319ab78
	sub_8319AB78(ctx, base);
loc_8319F660:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,2
	ctx.r10.s64 = r11.s64 + 2;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,3,0,28
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// stw r25,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r25.u32);
loc_8319F680:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_8319F410) {
	__imp__sub_8319F410(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319F688) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x8319a750
	sub_8319A750(ctx, base);
	// lwz r3,576(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 576);
	// bl 0x8319a750
	sub_8319A750(ctx, base);
	// lwz r11,580(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 580);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8319f7b4
	if (!cr0.eq) goto loc_8319F7B4;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8319f7b4
	if (cr0.eq) goto loc_8319F7B4;
	// rotlwi r10,r10,0
	ctx.r10.u64 = rotl32(ctx.r10.u32, 0);
	// li r28,0
	r28.s64 = 0;
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319f6d8
	if (cr0.eq) goto loc_8319F6D8;
	// mr r11,r28
	r11.u64 = r28.u64;
	// b 0x8319f6e4
	goto loc_8319F6E4;
loc_8319F6D8:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319F6E4:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mulli r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 * 12;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r30,r11,4
	r30.s64 = r11.s64 + 4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319f70c
	if (cr0.eq) goto loc_8319F70C;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8319F70C:
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r28.u32);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8319F718:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8319f734
	if (cr6.eq) goto loc_8319F734;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// mr r11,r28
	r11.u64 = r28.u64;
	// bne cr6,0x8319f738
	if (!cr6.eq) goto loc_8319F738;
loc_8319F734:
	// li r11,1
	r11.s64 = 1;
loc_8319F738:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319f7ac
	if (!cr0.eq) goto loc_8319F7AC;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r11,576(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 576);
	// ld r31,0(r3)
	r31.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8319f780
	if (!cr0.eq) goto loc_8319F780;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r10,-4
	xer.ca = ctx.r10.u32 > 3;
	ctx.r3.s64 = ctx.r10.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8319f780
	if (cr0.eq) goto loc_8319F780;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r9,12(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x8319f78c
	if (!cr6.gt) goto loc_8319F78C;
loc_8319F780:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x8319ab78
	sub_8319AB78(ctx, base);
loc_8319F78C:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
	// addi r8,r11,1
	ctx.r8.s64 = r11.s64 + 1;
	// rlwinm r11,r9,3,0,28
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r8,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r8.u32);
	// stdx r31,r11,r3
	PPC_STORE_U64(r11.u32 + ctx.r3.u32, r31.u64);
	// b 0x8319f718
	goto loc_8319F718;
loc_8319F7AC:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// b 0x8319f7c8
	goto loc_8319F7C8;
loc_8319F7B4:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// li r28,0
	r28.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// std r28,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r28.u64);
	// stw r28,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r28.u32);
loc_8319F7C8:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83195ba0
	sub_83195BA0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_8319F688) {
	__imp__sub_8319F688(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319F7D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r28,4(r4)
	r28.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r31,8(r5)
	r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319f8b0
	if (cr6.eq) goto loc_8319F8B0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x8319f8b0
	if (cr6.eq) goto loc_8319F8B0;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319F814:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x8319f898
	if (!cr6.eq) goto loc_8319F898;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x8319f8c4
	if (!cr6.eq) goto loc_8319F8C4;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319f8d0
	if (cr6.eq) goto loc_8319F8D0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,11
	cr6.compare<int32_t>(ctx.r10.s32, 11, xer);
	// bne cr6,0x8319f8d0
	if (!cr6.eq) goto loc_8319F8D0;
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// beq cr6,0x8319f898
	if (cr6.eq) goto loc_8319F898;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// beq cr6,0x8319f898
	if (cr6.eq) goto loc_8319F898;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8319f898
	if (cr6.eq) goto loc_8319F898;
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319f898
	if (cr0.eq) goto loc_8319F898;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8319f898
	if (cr6.eq) goto loc_8319F898;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319de30
	sub_8319DE30(ctx, base);
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_8319F898:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319f8b0
	if (cr6.eq) goto loc_8319F8B0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x8319f8dc
	if (!cr6.eq) goto loc_8319F8DC;
loc_8319F8B0:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r29,r11
	r29.u64 = r11.u64;
	// bne cr6,0x8319f814
	if (!cr6.eq) goto loc_8319F814;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_8319F8C4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319F8D0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319F8DC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_8319F7D8) {
	__imp__sub_8319F7D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319F8E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8319f93c
	if (cr6.eq) goto loc_8319F93C;
loc_8319F920:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b7f8
	sub_8319B7F8(ctx, base);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x8319f920
	if (!cr0.eq) goto loc_8319F920;
loc_8319F93C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319F8E8) {
	__imp__sub_8319F8E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319F958) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319e160
	sub_8319E160(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319F958) {
	__imp__sub_8319F958(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319F9B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// rlwinm r4,r29,1,0,30
	ctx.r4.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319e160
	sub_8319E160(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319F9B8) {
	__imp__sub_8319F9B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319FA18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// lwz r10,4(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r28,r10,15,17,31
	r28.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0x7FFF;
	// rlwinm r26,r10,30,18,31
	r26.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFF;
	// mulli r25,r28,40
	r25.s64 = r28.s64 * 40;
	// add r11,r11,r25
	r11.u64 = r11.u64 + r25.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319fa5c
	if (!cr0.eq) goto loc_8319FA5C;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319FA5C:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319fbdc
	if (cr0.eq) goto loc_8319FBDC;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,584(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r27,0
	r27.s64 = 0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319fa90
	if (cr0.eq) goto loc_8319FA90;
	// mr r11,r27
	r11.u64 = r27.u64;
	// b 0x8319fa9c
	goto loc_8319FA9C;
loc_8319FA90:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_8319FA9C:
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8319fab4
	if (cr6.eq) goto loc_8319FAB4;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// b 0x8319fab8
	goto loc_8319FAB8;
loc_8319FAB4:
	// stw r27,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r27.u32);
loc_8319FAB8:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319ab18
	sub_8319AB18(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8319fab8
	if (!cr6.eq) goto loc_8319FAB8;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwzx r11,r11,r25
	r11.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// clrlwi r11,r11,29
	r11.u64 = r11.u32 & 0x7;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x8319fb98
	if (cr6.eq) goto loc_8319FB98;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,588(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 588);
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
loc_8319FB00:
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319fb30
	if (!cr6.eq) goto loc_8319FB30;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8319fb20
	if (cr0.eq) goto loc_8319FB20;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_8319FB20:
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// li r11,1
	r11.s64 = 1;
	// beq cr6,0x8319fb34
	if (cr6.eq) goto loc_8319FB34;
loc_8319FB30:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_8319FB34:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319fb9c
	if (!cr0.eq) goto loc_8319FB9C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319a9c8
	sub_8319A9C8(ctx, base);
	// lwz r30,4(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319aa20
	sub_8319AA20(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8319fb00
	if (!cr6.eq) goto loc_8319FB00;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8319fb00
	if (cr6.eq) goto loc_8319FB00;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x8319fb00
	if (!cr6.eq) goto loc_8319FB00;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8319fc1c
	if (!cr6.eq) goto loc_8319FC1C;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8319fb00
	if (cr6.eq) goto loc_8319FB00;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x8319fb00
	if (!cr6.eq) goto loc_8319FB00;
loc_8319FB98:
	// li r27,1
	r27.s64 = 1;
loc_8319FB9C:
	// clrlwi. r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319fbdc
	if (cr0.eq) goto loc_8319FBDC;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,12(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x83199928
	sub_83199928(ctx, base);
	// rlwinm r11,r26,3,0,28
	r11.u64 = rotl64(r26.u32 | (r26.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r11,r11,r3
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8319fbdc
	if (!cr6.eq) goto loc_8319FBDC;
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r4,12(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83191808
	sub_83191808(ctx, base);
loc_8319FBDC:
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// clrlwi. r10,r11,30
	ctx.r10.u64 = r11.u32 & 0x3;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8319fc28
	if (!cr0.eq) goto loc_8319FC28;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x83199928
	sub_83199928(ctx, base);
	// rlwinm r11,r26,3,0,28
	r11.u64 = rotl64(r26.u32 | (r26.u64 << 32), 3) & 0xFFFFFFF8;
	// stdx r23,r3,r11
	PPC_STORE_U64(ctx.r3.u32 + r11.u32, r23.u64);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r11,r11,r25
	r11.u64 = r11.u64 + r25.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r9,r10,2
	ctx.r9.u64 = ctx.r10.u64 | 2;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// b 0x8319fc54
	goto loc_8319FC54;
loc_8319FC1C:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_8319FC28:
	// rlwinm. r11,r11,16,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 16) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319fc3c
	if (!cr0.eq) goto loc_8319FC3C;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// std r23,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r23.u64);
	// b 0x8319fc54
	goto loc_8319FC54;
loc_8319FC3C:
	// lwz r4,0(r24)
	ctx.r4.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,0(r4)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r4.u32 + 0);
	// bl 0x8319ea40
	sub_8319EA40(ctx, base);
loc_8319FC54:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_8319FA18) {
	__imp__sub_8319FA18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319FC60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319fc9c
	if (!cr0.eq) goto loc_8319FC9C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319fc9c
	if (cr0.eq) goto loc_8319FC9C;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x8319fca8
	if (!cr6.gt) goto loc_8319FCA8;
loc_8319FC9C:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8319ac88
	sub_8319AC88(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8319FCA8:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r9,r10,5,0,26
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// add r10,r9,r11
	ctx.r10.u64 = ctx.r9.u64 + r11.u64;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// addi r3,r10,16
	ctx.r3.s64 = ctx.r10.s64 + 16;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319FC60) {
	__imp__sub_8319FC60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319FCD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319fd0c
	if (!cr0.eq) goto loc_8319FD0C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319fd0c
	if (cr0.eq) goto loc_8319FD0C;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x8319fd18
	if (!cr6.gt) goto loc_8319FD18;
loc_8319FD0C:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8319ad10
	sub_8319AD10(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8319FD18:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mulli r9,r10,12
	ctx.r9.s64 = ctx.r10.s64 * 12;
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r3,r9,16
	ctx.r3.s64 = ctx.r9.s64 + 16;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319FCD0) {
	__imp__sub_8319FCD0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319FD40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319fd84
	if (!cr0.eq) goto loc_8319FD84;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319fd84
	if (cr0.eq) goto loc_8319FD84;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x8319fd90
	if (!cr6.gt) goto loc_8319FD90;
loc_8319FD84:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8319ab78
	sub_8319AB78(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8319FD90:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r9,r10,2
	ctx.r9.s64 = ctx.r10.s64 + 2;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,3,0,28
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stdx r31,r10,r11
	PPC_STORE_U64(ctx.r10.u32 + r11.u32, r31.u64);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319FD40) {
	__imp__sub_8319FD40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319FDC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r5,15
	ctx.r5.s64 = 15;
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// addi r11,r3,4
	r11.s64 = ctx.r3.s64 + 4;
	// ori r10,r3,1
	ctx.r10.u64 = ctx.r3.u64 | 1;
	// stw r3,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r3.u32);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319fe40
	if (!cr0.eq) goto loc_8319FE40;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319fe40
	if (cr0.eq) goto loc_8319FE40;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x8319fe4c
	if (!cr6.gt) goto loc_8319FE4C;
loc_8319FE40:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8319FE4C:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r30,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319FDC0) {
	__imp__sub_8319FDC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319FE80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
loc_8319FE90:
	// lwz r3,4(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8319ffb0
	if (!cr0.eq) goto loc_8319FFB0;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8319ffb0
	if (cr0.eq) goto loc_8319FFB0;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319febc
	if (cr0.eq) goto loc_8319FEBC;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x8319fec8
	goto loc_8319FEC8;
loc_8319FEBC:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_8319FEC8:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r4
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x8319ff18
	if (!cr0.eq) goto loc_8319FF18;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_8319FF18:
	// mr r30,r31
	r30.u64 = r31.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8319fe90
	if (cr6.eq) goto loc_8319FE90;
loc_8319FF24:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8319ffa0
	if (!cr6.eq) goto loc_8319FFA0;
	// lwz r31,12(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8319ff94
	if (cr6.eq) goto loc_8319FF94;
	// lwz r3,4(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8319ff70
	if (!cr0.eq) goto loc_8319FF70;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8319ff70
	if (cr0.eq) goto loc_8319FF70;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x8319ff7c
	if (!cr6.gt) goto loc_8319FF7C;
loc_8319FF70:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8319FF7C:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r31,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r31.u32);
loc_8319FF94:
	// lwz r30,8(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8319ff24
	if (!cr6.eq) goto loc_8319FF24;
loc_8319FFA0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8319fe90
	if (cr6.eq) goto loc_8319FE90;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x8319ffb4
	goto loc_8319FFB4;
loc_8319FFB0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8319FFB4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_8319FE80) {
	__imp__sub_8319FE80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_8319FFC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x83171fa0
	sub_83171FA0(ctx, base);
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a0018
	if (!cr0.eq) goto loc_831A0018;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a0018
	if (cr0.eq) goto loc_831A0018;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831a0024
	if (!cr6.gt) goto loc_831A0024;
loc_831A0018:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831A0024:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r31,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r31.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_8319FFC0) {
	__imp__sub_8319FFC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A0058) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r4,24(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x831a0080
	if (!cr6.eq) goto loc_831A0080;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831a00fc
	goto loc_831A00FC;
loc_831A0080:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// li r31,0
	r31.s64 = 0;
	// bl 0x8319fdc0
	sub_8319FDC0(ctx, base);
	// b 0x831a00b0
	goto loc_831A00B0;
loc_831A0094:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// bne cr6,0x831a00c4
	if (!cr6.eq) goto loc_831A00C4;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// li r31,1
	r31.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a00d0
	if (cr6.eq) goto loc_831A00D0;
loc_831A00B0:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831a0094
	if (!cr0.eq) goto loc_831A0094;
	// b 0x831a00d4
	goto loc_831A00D4;
loc_831A00C4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A00D0:
	// li r29,1
	r29.s64 = 1;
loc_831A00D4:
	// clrlwi r10,r31,24
	ctx.r10.u64 = r31.u32 & 0xFF;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cntlzw r8,r10
	ctx.r8.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// addi r10,r11,972
	ctx.r10.s64 = r11.s64 + 972;
	// rlwinm r10,r8,27,31,31
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// lwz r8,976(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 976);
	// or r3,r10,r29
	ctx.r3.u64 = ctx.r10.u64 | r29.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// stw r9,976(r11)
	PPC_STORE_U32(r11.u32 + 976, ctx.r9.u32);
loc_831A00FC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831A0058) {
	__imp__sub_831A0058(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A0108) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r29,1
	r29.s64 = 1;
	// li r28,0
	r28.s64 = 0;
loc_831A0124:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831a014c
	if (!cr6.eq) goto loc_831A014C;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a0318
	if (!cr0.eq) goto loc_831A0318;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831a0318
	if (cr0.eq) goto loc_831A0318;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d728
	sub_8319D728(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_831A014C:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831a0278
	if (cr6.eq) goto loc_831A0278;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x831a0220
	if (cr6.eq) goto loc_831A0220;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x831a0324
	if (!cr6.eq) goto loc_831A0324;
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r11,r30,20
	r11.s64 = r30.s64 + 20;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a0384
	if (cr6.eq) goto loc_831A0384;
	// lwz r30,16(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a0398
	if (cr6.eq) goto loc_831A0398;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x831a0310
	if (!cr6.gt) goto loc_831A0310;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r7,28(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// clrlwi. r7,r7,31
	ctx.r7.u64 = ctx.r7.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// stw r8,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r8.u32);
	// stb r29,84(r1)
	PPC_STORE_U8(ctx.r1.u32 + 84, r29.u8);
	// bne 0x831a01ec
	if (!cr0.eq) goto loc_831A01EC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a01ec
	if (cr0.eq) goto loc_831A01EC;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831a01f8
	if (!cr6.gt) goto loc_831A01F8;
loc_831A01EC:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8319ac00
	sub_8319AC00(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831A01F8:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r5,24
	ctx.r5.s64 = 24;
	// mulli r9,r10,24
	ctx.r9.s64 = ctx.r10.s64 * 24;
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r3,r9,16
	ctx.r3.s64 = ctx.r9.s64 + 16;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// b 0x831a0310
	goto loc_831A0310;
loc_831A0220:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a03ac
	if (!cr6.eq) goto loc_831A03AC;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,11
	cr6.compare<int32_t>(ctx.r10.s32, 11, xer);
	// bne cr6,0x831a03c0
	if (!cr6.eq) goto loc_831A03C0;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831a0254
	if (!cr6.eq) goto loc_831A0254;
	// lwz r10,60(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// stw r28,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r28.u32);
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
loc_831A0254:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831a0268
	if (!cr6.eq) goto loc_831A0268;
	// lwz r10,64(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// stw r10,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r10.u32);
loc_831A0268:
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// stw r10,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r10.u32);
	// lwz r30,48(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x831a0124
	goto loc_831A0124;
loc_831A0278:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a030c
	if (cr6.eq) goto loc_831A030C;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r7,28(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// clrlwi. r11,r7,31
	r11.u64 = ctx.r7.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r28.u32);
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// stw r8,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r8.u32);
	// stb r28,84(r1)
	PPC_STORE_U8(ctx.r1.u32 + 84, r28.u8);
	// bne 0x831a02dc
	if (!cr0.eq) goto loc_831A02DC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a02dc
	if (cr0.eq) goto loc_831A02DC;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831a02e8
	if (!cr6.gt) goto loc_831A02E8;
loc_831A02DC:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8319ac00
	sub_8319AC00(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831A02E8:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r5,24
	ctx.r5.s64 = 24;
	// mulli r9,r10,24
	ctx.r9.s64 = ctx.r10.s64 * 24;
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r3,r9,16
	ctx.r3.s64 = ctx.r9.s64 + 16;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
loc_831A030C:
	// lwz r30,8(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 8);
loc_831A0310:
	// stb r29,32(r31)
	PPC_STORE_U8(r31.u32 + 32, r29.u8);
	// b 0x831a0124
	goto loc_831A0124;
loc_831A0318:
	// li r3,0
	ctx.r3.s64 = 0;
loc_831A031C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
loc_831A0324:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x831a0344
	if (cr6.eq) goto loc_831A0344;
	// rlwinm r11,r31,0,0,19
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFF000;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A0344:
	// stw r30,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r30.u32);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a0370
	if (cr6.eq) goto loc_831A0370;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a0370
	if (cr6.eq) goto loc_831A0370;
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831a031c
	goto loc_831A031C;
loc_831A0370:
	// rlwinm r11,r31,0,0,19
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFF000;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A0384:
	// rlwinm r11,r31,0,0,19
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFF000;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A0398:
	// rlwinm r11,r31,0,0,19
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFF000;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A03AC:
	// rlwinm r11,r31,0,0,19
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFF000;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A03C0:
	// rlwinm r11,r31,0,0,19
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFF000;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831A0108) {
	__imp__sub_831A0108(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A03D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a0400
	if (!cr0.eq) goto loc_831A0400;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x831a0408
	if (!cr0.eq) goto loc_831A0408;
loc_831A0400:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831a041c
	goto loc_831A041C;
loc_831A0408:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d728
	sub_8319D728(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a0108
	sub_831A0108(ctx, base);
loc_831A041C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831A03D8) {
	__imp__sub_831A03D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A0430) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// stb r10,32(r31)
	PPC_STORE_U8(r31.u32 + 32, ctx.r10.u8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a0478
	if (!cr6.eq) goto loc_831A0478;
	// bl 0x831a03d8
	sub_831A03D8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a0478
	if (!cr0.eq) goto loc_831A0478;
	// rlwinm r11,r31,0,0,19
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFF000;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r3,148(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 148);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A0478:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// lwz r3,20(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831A0430) {
	__imp__sub_831A0430(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A04A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bne 0x831a04e8
	if (!cr0.eq) goto loc_831A04E8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a04e8
	if (cr0.eq) goto loc_831A04E8;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831a04f4
	if (!cr6.gt) goto loc_831A04F4;
loc_831A04E8:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8319ab78
	sub_8319AB78(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831A04F4:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// ld r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stdx r9,r10,r11
	PPC_STORE_U64(ctx.r10.u32 + r11.u32, ctx.r9.u64);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831A04A0) {
	__imp__sub_831A04A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A0520) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r10,2
	ctx.r10.s64 = 2;
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bne 0x831a0568
	if (!cr0.eq) goto loc_831A0568;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a0568
	if (cr0.eq) goto loc_831A0568;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831a0574
	if (!cr6.gt) goto loc_831A0574;
loc_831A0568:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8319ab78
	sub_8319AB78(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831A0574:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// ld r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stdx r9,r10,r11
	PPC_STORE_U64(ctx.r10.u32 + r11.u32, ctx.r9.u64);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831A0520) {
	__imp__sub_831A0520(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A05A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r10,1
	ctx.r10.s64 = 1;
	// clrlwi. r11,r5,24
	r11.u64 = ctx.r5.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// beq 0x831a05c4
	if (cr0.eq) goto loc_831A05C4;
	// li r11,3
	r11.s64 = 3;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
loc_831A05C4:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a05f8
	if (!cr0.eq) goto loc_831A05F8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a05f8
	if (cr0.eq) goto loc_831A05F8;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831a0604
	if (!cr6.gt) goto loc_831A0604;
loc_831A05F8:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8319ab78
	sub_8319AB78(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831A0604:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// ld r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stdx r9,r10,r11
	PPC_STORE_U64(ctx.r10.u32 + r11.u32, ctx.r9.u64);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831A05A0) {
	__imp__sub_831A05A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A0630) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r5,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r5.u32);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// bne 0x831a0674
	if (!cr0.eq) goto loc_831A0674;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a0674
	if (cr0.eq) goto loc_831A0674;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831a0680
	if (!cr6.gt) goto loc_831A0680;
loc_831A0674:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8319ab78
	sub_8319AB78(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831A0680:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// ld r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stdx r9,r10,r11
	PPC_STORE_U64(ctx.r10.u32 + r11.u32, ctx.r9.u64);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831A0630) {
	__imp__sub_831A0630(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A06B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r27,32(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// bl 0x8319ad98
	sub_8319AD98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,76(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 76);
	// oris r11,r11,16
	r11.u64 = r11.u64 | 1048576;
	// stw r11,76(r29)
	PPC_STORE_U32(r29.u32 + 76, r11.u32);
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319ad98
	sub_8319AD98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// rlwinm. r11,r11,0,2,2
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a0734
	if (cr0.eq) goto loc_831A0734;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// oris r11,r11,8192
	r11.u64 = r11.u64 | 536870912;
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
loc_831A0734:
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319ad98
	sub_8319AD98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831a0764
	if (cr6.eq) goto loc_831A0764;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// stw r29,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r29.u32);
loc_831A0764:
	// lwz r3,584(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// bl 0x8319fc60
	sub_8319FC60(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// addi r4,r30,4
	ctx.r4.s64 = r30.s64 + 4;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r3,588(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 588);
	// bl 0x8319f3a0
	sub_8319F3A0(ctx, base);
	// stw r29,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r29.u32);
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm r11,r11,31,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// stw r27,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r27.u32);
	// stb r11,16(r30)
	PPC_STORE_U8(r30.u32 + 16, r11.u8);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stw r10,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r10.u32);
	// lwz r11,76(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 76);
	// clrlwi r11,r11,13
	r11.u64 = r11.u32 & 0x7FFFF;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831A06B0) {
	__imp__sub_831A06B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A07C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r28,r31,4
	r28.s64 = r31.s64 + 4;
	// ori r11,r31,1
	r11.u64 = r31.u64 | 1;
	// ori r10,r28,1
	ctx.r10.u64 = r28.u64 | 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lwz r11,576(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 576);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a080c
	if (cr0.eq) goto loc_831A080C;
	// li r11,0
	r11.s64 = 0;
loc_831A080C:
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// li r11,0
	r11.s64 = 0;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
loc_831A081C:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a0838
	if (cr6.eq) goto loc_831A0838;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x831a083c
	if (!cr6.eq) goto loc_831A083C;
loc_831A0838:
	// li r11,1
	r11.s64 = 1;
loc_831A083C:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a08ac
	if (!cr0.eq) goto loc_831A08AC;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// ld r30,0(r3)
	r30.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a0880
	if (!cr0.eq) goto loc_831A0880;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831a0880
	if (cr0.eq) goto loc_831A0880;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831a088c
	if (!cr6.gt) goto loc_831A088C;
loc_831A0880:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319ab78
	sub_8319AB78(ctx, base);
loc_831A088C:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
	// addi r8,r11,1
	ctx.r8.s64 = r11.s64 + 1;
	// rlwinm r11,r9,3,0,28
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r8,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r8.u32);
	// stdx r30,r11,r3
	PPC_STORE_U64(r11.u32 + ctx.r3.u32, r30.u64);
	// b 0x831a081c
	goto loc_831A081C;
loc_831A08AC:
	// lwz r3,580(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 580);
	// bl 0x8319fcd0
	sub_8319FCD0(ctx, base);
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// lwz r11,32(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,40(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 40);
	// rlwimi r10,r11,3,31,31
	ctx.r10.u64 = (rotl32(r11.u32, 3) & 0x1) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFFE);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lwz r10,40(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 40);
	// rlwimi r11,r10,0,30,30
	r11.u64 = (rotl32(ctx.r10.u32, 0) & 0x2) | (r11.u64 & 0xFFFFFFFFFFFFFFFD);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831A07C0) {
	__imp__sub_831A07C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A08E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// mr r20,r5
	r20.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// lwz r11,584(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a091c
	if (cr0.eq) goto loc_831A091C;
	// li r11,0
	r11.s64 = 0;
	// b 0x831a0928
	goto loc_831A0928;
loc_831A091C:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_831A0928:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// li r6,117
	ctx.r6.s64 = 117;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r9,76(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 76);
	// lwz r19,-4(r10)
	r19.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	// oris r10,r9,4096
	ctx.r10.u64 = ctx.r9.u64 | 268435456;
	// stw r10,76(r11)
	PPC_STORE_U32(r11.u32 + 76, ctx.r10.u32);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// oris r10,r10,4096
	ctx.r10.u64 = ctx.r10.u64 | 268435456;
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r25)
	PPC_STORE_U32(r25.u32 + 8, r11.u32);
	// bl 0x831236f0
	sub_831236F0(ctx, base);
	// lwz r11,560(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// clrlwi. r30,r30,24
	r30.u64 = r30.u32 & 0xFF;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,560(r31)
	PPC_STORE_U32(r31.u32 + 560, r11.u32);
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// oris r11,r11,256
	r11.u64 = r11.u64 | 16777216;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// beq 0x831a09e4
	if (cr0.eq) goto loc_831A09E4;
	// mr r29,r20
	r29.u64 = r20.u64;
	// b 0x831a0a18
	goto loc_831A0A18;
loc_831A09E4:
	// lwz r11,36(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a1198
	if (cr6.eq) goto loc_831A1198;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a1198
	if (!cr6.eq) goto loc_831A1198;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a118c
	if (cr6.eq) goto loc_831A118C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a118c
	if (!cr6.eq) goto loc_831A118C;
	// mr r29,r11
	r29.u64 = r11.u64;
loc_831A0A18:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// li r28,0
	r28.s64 = 0;
	// bl 0x8319fdc0
	sub_8319FDC0(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831a0aa4
	if (!cr6.eq) goto loc_831A0AA4;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// b 0x831a0aa4
	goto loc_831A0AA4;
loc_831A0A40:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a0a78
	if (!cr6.eq) goto loc_831A0A78;
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a0a60
	if (cr6.eq) goto loc_831A0A60;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831a0a8c
	goto loc_831A0A8C;
loc_831A0A60:
	// lwz r4,8(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831a0a8c
	goto loc_831A0A8C;
loc_831A0A78:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831A0A8C:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a0af4
	if (cr0.eq) goto loc_831A0AF4;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mullw r11,r10,r11
	r11.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// add r28,r11,r28
	r28.u64 = r11.u64 + r28.u64;
loc_831A0AA4:
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831a0a40
	if (!cr0.eq) goto loc_831A0A40;
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r21,1
	r21.s64 = 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a0ad0
	if (cr6.eq) goto loc_831A0AD0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a0aec
	if (!cr0.eq) goto loc_831A0AEC;
loc_831A0AD0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a0b00
	if (cr6.eq) goto loc_831A0B00;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a0aec
	if (cr6.eq) goto loc_831A0AEC;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r11,r11,0,19,19
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a0b00
	if (!cr0.eq) goto loc_831A0B00;
loc_831A0AEC:
	// mr r11,r21
	r11.u64 = r21.u64;
	// b 0x831a0b04
	goto loc_831A0B04;
loc_831A0AF4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A0B00:
	// li r11,0
	r11.s64 = 0;
loc_831A0B04:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a0f38
	if (cr0.eq) goto loc_831A0F38;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// li r27,0
	r27.s64 = 0;
	// li r24,0
	r24.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// li r29,0
	r29.s64 = 0;
	// li r25,0
	r25.s64 = 0;
	// bl 0x8319fdc0
	sub_8319FDC0(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831a0b5c
	if (!cr6.eq) goto loc_831A0B5C;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
loc_831A0B5C:
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
loc_831A0B74:
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// mr. r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x831a0be4
	if (cr0.eq) goto loc_831A0BE4;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a0bbc
	if (!cr6.eq) goto loc_831A0BBC;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a0ba4
	if (cr6.eq) goto loc_831A0BA4;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831a0bcc
	goto loc_831A0BCC;
loc_831A0BA4:
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831a0bcc
	goto loc_831A0BCC;
loc_831A0BBC:
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831A0BCC:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a0ea8
	if (cr0.eq) goto loc_831A0EA8;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mullw r23,r10,r11
	r23.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// b 0x831a0e94
	goto loc_831A0E94;
loc_831A0BE4:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831a0c64
	if (cr6.eq) goto loc_831A0C64;
	// slw r11,r21,r25
	r11.u64 = r25.u8 & 0x20 ? 0 : (r21.u32 << (r25.u8 & 0x3F));
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// li r7,1
	ctx.r7.s64 = 1;
	// rlwimi r11,r29,4,0,27
	r11.u64 = (rotl32(r29.u32, 4) & 0xFFFFFFF0) | (r11.u64 & 0xFFFFFFFF0000000F);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r30,r11
	r30.u64 = r11.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// bl 0x831cfba8
	sub_831CFBA8(ctx, base);
	// lwz r29,564(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r30,12(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r5,100(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 100);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831a0c50
	if (cr6.eq) goto loc_831A0C50;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123db0
	sub_83123DB0(ctx, base);
loc_831A0C50:
	// stw r30,100(r29)
	PPC_STORE_U32(r29.u32 + 100, r30.u32);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
loc_831A0C64:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x831a0eb4
	if (!cr6.eq) goto loc_831A0EB4;
	// li r23,0
	r23.s64 = 0;
loc_831A0C70:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,94
	ctx.r6.s64 = 94;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,94
	ctx.r4.s64 = 94;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-12
	r11.s64 = r30.s64 + -12;
	// li r10,5
	ctx.r10.s64 = 5;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// stw r20,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r20.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r9,r10,1,28,31
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 1) & 0xF) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFF0);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r29,564(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r5,100(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 100);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831a0ce8
	if (cr6.eq) goto loc_831A0CE8;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123db0
	sub_83123DB0(ctx, base);
loc_831A0CE8:
	// stw r30,100(r29)
	PPC_STORE_U32(r29.u32 + 100, r30.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// li r27,20
	r27.s64 = 20;
	// li r29,33
	r29.s64 = 33;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// bne cr6,0x831a0de8
	if (!cr6.eq) goto loc_831A0DE8;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,560(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x831d3eb8
	sub_831D3EB8(ctx, base);
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,543
	ctx.r5.s64 = 543;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// rlwimi r10,r21,27,4,6
	ctx.r10.u64 = (rotl32(r21.u32, 27) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// rlwinm r9,r10,27,30,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x3;
	// rlwinm r8,r10,29,28,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0xC;
	// or r8,r8,r9
	ctx.r8.u64 = ctx.r8.u64 | ctx.r9.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// or r8,r8,r9
	ctx.r8.u64 = ctx.r8.u64 | ctx.r9.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// or r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 | ctx.r9.u64;
	// rlwimi r10,r9,5,19,26
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 5) & 0x1FE0) | (ctx.r10.u64 & 0xFFFFFFFFFFFFE01F);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x831cfba8
	sub_831CFBA8(ctx, base);
	// lwz r28,564(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r29,12(r3)
	r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r5,100(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 100);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831a0dc0
	if (cr6.eq) goto loc_831A0DC0;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123db0
	sub_83123DB0(ctx, base);
loc_831A0DC0:
	// stw r29,100(r28)
	PPC_STORE_U32(r28.u32 + 100, r29.u32);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// li r27,16
	r27.s64 = 16;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// li r29,34
	r29.s64 = 34;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// oris r11,r11,32
	r11.u64 = r11.u64 | 2097152;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
loc_831A0DE8:
	// mr r26,r30
	r26.u64 = r30.u64;
loc_831A0DEC:
	// cmplw cr6,r23,r27
	cr6.compare<uint32_t>(r23.u32, r27.u32, xer);
	// mr r11,r23
	r11.u64 = r23.u64;
	// blt cr6,0x831a0dfc
	if (cr6.lt) goto loc_831A0DFC;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_831A0DFC:
	// add r10,r11,r25
	ctx.r10.u64 = r11.u64 + r25.u64;
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// blt cr6,0x831a0e8c
	if (cr6.lt) goto loc_831A0E8C;
	// rlwinm r11,r29,4,0,27
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 4) & 0xFFFFFFF0;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r30,r11,15
	r30.u64 = r11.u64 | 15;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// bl 0x831cfba8
	sub_831CFBA8(ctx, base);
	// lwz r28,564(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r30,12(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r5,100(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 100);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831a0e64
	if (cr6.eq) goto loc_831A0E64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123db0
	sub_83123DB0(ctx, base);
loc_831A0E64:
	// stw r30,100(r28)
	PPC_STORE_U32(r28.u32 + 100, r30.u32);
	// subfic r11,r25,4
	xer.ca = r25.u32 <= 4;
	r11.s64 = 4 - r25.s64;
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// li r25,0
	r25.s64 = 0;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r27,r27,-4
	r27.s64 = r27.s64 + -4;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r10,r10,512
	ctx.r10.u64 = ctx.r10.u64 | 33554432;
	// stw r10,8(r30)
	PPC_STORE_U32(r30.u32 + 8, ctx.r10.u32);
	// b 0x831a0e90
	goto loc_831A0E90;
loc_831A0E8C:
	// mr r25,r10
	r25.u64 = ctx.r10.u64;
loc_831A0E90:
	// subf r23,r11,r23
	r23.s64 = r23.s64 - r11.s64;
loc_831A0E94:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x831a0b74
	if (cr6.eq) goto loc_831A0B74;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x831a0dec
	if (!cr6.eq) goto loc_831A0DEC;
	// b 0x831a0c70
	goto loc_831A0C70;
loc_831A0EA8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A0EB4:
	// stw r22,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r22.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x831d3eb8
	sub_831D3EB8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,612(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 612);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x831d46c0
	sub_831D46C0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// ld r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x83199740
	sub_83199740(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,612(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 612);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x83199928
	sub_83199928(ctx, base);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r9,116(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// addi r10,r11,972
	ctx.r10.s64 = r11.s64 + 972;
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
	// rlwimi r10,r21,0,16,14
	ctx.r10.u64 = (rotl32(r21.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// lwz r10,976(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 976);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// stw r9,976(r11)
	PPC_STORE_U32(r11.u32 + 976, ctx.r9.u32);
	// b 0x831a1140
	goto loc_831A1140;
loc_831A0F38:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a1140
	if (cr6.eq) goto loc_831A1140;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r11,r11,0,19,19
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a1140
	if (cr0.eq) goto loc_831A1140;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x8319ffc0
	sub_8319FFC0(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831a0f68
	if (!cr6.eq) goto loc_831A0F68;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
loc_831A0F68:
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// mr r26,r25
	r26.u64 = r25.u64;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// li r24,3
	r24.s64 = 3;
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x831a10cc
	if (cr0.eq) goto loc_831A10CC;
loc_831A0F98:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a0fd0
	if (!cr6.eq) goto loc_831A0FD0;
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a0fb8
	if (cr6.eq) goto loc_831A0FB8;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831a0fe4
	goto loc_831A0FE4;
loc_831A0FB8:
	// lwz r4,8(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// addi r5,r1,100
	ctx.r5.s64 = ctx.r1.s64 + 100;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831a0fe4
	goto loc_831A0FE4;
loc_831A0FD0:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// addi r5,r1,100
	ctx.r5.s64 = ctx.r1.s64 + 100;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831A0FE4:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a1180
	if (cr0.eq) goto loc_831A1180;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mullw. r29,r10,r11
	r29.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x831a10b4
	if (cr0.eq) goto loc_831A10B4;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,117
	ctx.r4.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r28,r3,-16
	r28.s64 = ctx.r3.s64 + -16;
loc_831A1014:
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// li r27,4
	r27.s64 = 4;
	// bgt cr6,0x831a1024
	if (cr6.gt) goto loc_831A1024;
	// mr r27,r29
	r27.u64 = r29.u64;
loc_831A1024:
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// add r11,r28,r30
	r11.u64 = r28.u64 + r30.u64;
	// lwzx r10,r28,r30
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + r30.u32);
	// stw r24,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r24.u32);
	// ori r10,r10,7
	ctx.r10.u64 = ctx.r10.u64 | 7;
	// stwx r10,r28,r30
	PPC_STORE_U32(r28.u32 + r30.u32, ctx.r10.u32);
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// stw r20,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r20.u32);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// bl 0x83123628
	sub_83123628(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// subf r29,r27,r29
	r29.s64 = r29.s64 - r27.s64;
	// bl 0x831236f0
	sub_831236F0(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r26,r30
	r26.u64 = r30.u64;
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// bne cr6,0x831a1014
	if (!cr6.eq) goto loc_831A1014;
loc_831A10B4:
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831a0f98
	if (!cr0.eq) goto loc_831A0F98;
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// bne cr6,0x831a1140
	if (!cr6.eq) goto loc_831A1140;
loc_831A10CC:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,117
	ctx.r4.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-16
	r11.s64 = r30.s64 + -16;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r24,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r24.u32);
	// ori r10,r10,7
	ctx.r10.u64 = ctx.r10.u64 | 7;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r10,560(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 560);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// stw r20,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r20.u32);
	// bl 0x831236f0
	sub_831236F0(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
loc_831A1140:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a1160
	if (cr6.eq) goto loc_831A1160;
	// stw r21,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r21.u32);
loc_831A1160:
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r9,108(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// addi r10,r11,972
	ctx.r10.s64 = r11.s64 + 972;
	// lwz r10,976(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 976);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// stw r9,976(r11)
	PPC_STORE_U32(r11.u32 + 976, ctx.r9.u32);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82ca2c14
	return;
loc_831A1180:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A118C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A1198:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831A08E8) {
	__imp__sub_831A08E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A11A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// li r5,15
	ctx.r5.s64 = 15;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r27,r28,4
	r27.s64 = r28.s64 + 4;
	// ori r11,r28,1
	r11.u64 = r28.u64 | 1;
	// ori r10,r27,1
	ctx.r10.u64 = r27.u64 | 1;
	// stw r11,4(r28)
	PPC_STORE_U32(r28.u32 + 4, r11.u32);
	// stw r10,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r10.u32);
	// b 0x831a14c4
	goto loc_831A14C4;
loc_831A11E8:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831a1390
	if (cr6.eq) goto loc_831A1390;
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x831a12c0
	if (cr6.eq) goto loc_831A12C0;
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// beq cr6,0x831a1258
	if (cr6.eq) goto loc_831A1258;
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// bne cr6,0x831a1450
	if (!cr6.eq) goto loc_831A1450;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83195760
	sub_83195760(ctx, base);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a1248
	if (cr6.eq) goto loc_831A1248;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x831a1248
	if (cr6.eq) goto loc_831A1248;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// beq cr6,0x831a1248
	if (cr6.eq) goto loc_831A1248;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// ble cr6,0x831a14d8
	if (!cr6.gt) goto loc_831A14D8;
	// cmplwi cr6,r11,9
	cr6.compare<uint32_t>(r11.u32, 9, xer);
	// bgt cr6,0x831a14d8
	if (cr6.gt) goto loc_831A14D8;
loc_831A1248:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mulli r10,r3,40
	ctx.r10.s64 = ctx.r3.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// b 0x831a12ac
	goto loc_831A12AC;
loc_831A1258:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x831a1450
	if (cr6.lt) goto loc_831A1450;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x831a14e4
	if (!cr6.eq) goto loc_831A14E4;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a1450
	if (cr6.eq) goto loc_831A1450;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x831a14f0
	if (cr6.eq) goto loc_831A14F0;
	// lwz r10,12(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,0,25,27
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x70;
	// cmplwi cr6,r10,48
	cr6.compare<uint32_t>(ctx.r10.u32, 48, xer);
	// beq cr6,0x831a14fc
	if (cr6.eq) goto loc_831A14FC;
	// lwz r10,12(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
loc_831A12AC:
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// b 0x831a1450
	goto loc_831A1450;
loc_831A12C0:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831a12f4
	if (cr6.eq) goto loc_831A12F4;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// ble cr6,0x831a1508
	if (!cr6.gt) goto loc_831A1508;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// ble cr6,0x831a12f4
	if (!cr6.gt) goto loc_831A12F4;
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// ble cr6,0x831a1508
	if (!cr6.gt) goto loc_831A1508;
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// ble cr6,0x831a12fc
	if (!cr6.gt) goto loc_831A12FC;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x831a1508
	if (!cr6.eq) goto loc_831A1508;
loc_831A12F4:
	// lwz r31,32(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// b 0x831a13fc
	goto loc_831A13FC;
loc_831A12FC:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r30,32(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a1330
	if (!cr0.eq) goto loc_831A1330;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831a1330
	if (cr0.eq) goto loc_831A1330;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831a133c
	if (!cr6.gt) goto loc_831A133C;
loc_831A1330:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831A133C:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r31,36(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// bne 0x831a1388
	if (!cr0.eq) goto loc_831A1388;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831a1388
	if (cr0.eq) goto loc_831A1388;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831a1438
	if (!cr6.gt) goto loc_831A1438;
loc_831A1388:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// b 0x831a1430
	goto loc_831A1430;
loc_831A1390:
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a13f0
	if (cr6.eq) goto loc_831A13F0;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a13cc
	if (!cr0.eq) goto loc_831A13CC;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831a13cc
	if (cr0.eq) goto loc_831A13CC;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831a13d8
	if (!cr6.gt) goto loc_831A13D8;
loc_831A13CC:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831A13D8:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
loc_831A13F0:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831a1450
	if (cr6.eq) goto loc_831A1450;
loc_831A13FC:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a142c
	if (!cr0.eq) goto loc_831A142C;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831a142c
	if (cr0.eq) goto loc_831A142C;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831a1438
	if (!cr6.gt) goto loc_831A1438;
loc_831A142C:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_831A1430:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831A1438:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r31,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r31.u32);
loc_831A1450:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a1514
	if (!cr0.eq) goto loc_831A1514;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831a1514
	if (cr0.eq) goto loc_831A1514;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r4
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831a14c4
	if (!cr0.eq) goto loc_831A14C4;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831A14C4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831a11e8
	if (!cr6.eq) goto loc_831A11E8;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A14D8:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A14E4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A14F0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A14FC:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A1508:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A1514:
	// lwz r10,976(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 976);
	// addi r11,r29,972
	r11.s64 = r29.s64 + 972;
	// stw r10,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r10.u32);
	// stw r28,976(r29)
	PPC_STORE_U32(r29.u32 + 976, r28.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831A11A8) {
	__imp__sub_831A11A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A1530) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// mr r22,r6
	r22.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// mr r27,r8
	r27.u64 = ctx.r8.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x831a1564
	if (!cr6.eq) goto loc_831A1564;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831a1754
	goto loc_831A1754;
loc_831A1564:
	// li r5,15
	ctx.r5.s64 = 15;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// li r24,0
	r24.s64 = 0;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r25,r31,4
	r25.s64 = r31.s64 + 4;
	// ori r11,r31,1
	r11.u64 = r31.u64 | 1;
	// ori r10,r25,1
	ctx.r10.u64 = r25.u64 | 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
loc_831A1590:
	// lwz r30,8(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a1630
	if (cr6.eq) goto loc_831A1630;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831a15ac
	if (cr6.eq) goto loc_831A15AC;
	// addi r28,r28,-1
	r28.s64 = r28.s64 + -1;
	// b 0x831a1630
	goto loc_831A1630;
loc_831A15AC:
	// clrlwi. r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a15c4
	if (cr0.eq) goto loc_831A15C4;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// beq cr6,0x831a15c4
	if (cr6.eq) goto loc_831A15C4;
	// li r30,0
	r30.s64 = 0;
loc_831A15C4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a1630
	if (cr6.eq) goto loc_831A1630;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831a162c
	if (cr6.eq) goto loc_831A162C;
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a1604
	if (!cr0.eq) goto loc_831A1604;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831a1604
	if (cr0.eq) goto loc_831A1604;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831a1610
	if (!cr6.gt) goto loc_831A1610;
loc_831A1604:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831A1610:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
	// b 0x831a1630
	goto loc_831A1630;
loc_831A162C:
	// mr r24,r30
	r24.u64 = r30.u64;
loc_831A1630:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a1648
	if (cr6.eq) goto loc_831A1648;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a16e0
	if (!cr6.eq) goto loc_831A16E0;
loc_831A1648:
	// mr r29,r11
	r29.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a1590
	if (!cr6.eq) goto loc_831A1590;
loc_831A1654:
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a1740
	if (!cr0.eq) goto loc_831A1740;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831a1740
	if (cr0.eq) goto loc_831A1740;
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r10,r4
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// beq 0x831a16ec
	if (cr0.eq) goto loc_831A16EC;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831a16d0
	if (!cr0.eq) goto loc_831A16D0;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831A16D0:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x831a0520
	sub_831A0520(ctx, base);
	// b 0x831a1654
	goto loc_831A1654;
loc_831A16E0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A16EC:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831a1730
	if (!cr0.eq) goto loc_831A1730;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831A1730:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// b 0x831a1654
	goto loc_831A1654;
loc_831A1740:
	// lwz r10,976(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 976);
	// addi r11,r26,972
	r11.s64 = r26.s64 + 972;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r31,976(r26)
	PPC_STORE_U32(r26.u32 + 976, r31.u32);
loc_831A1754:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_831A1530) {
	__imp__sub_831A1530(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A1760) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mulli r27,r29,40
	r27.s64 = r29.s64 * 40;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a179c
	if (!cr0.eq) goto loc_831A179C;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A179C:
	// clrlwi. r23,r9,24
	r23.u64 = ctx.r9.u32 & 0xFF;
	cr0.compare<int32_t>(r23.s32, 0, xer);
	// beq 0x831a17b8
	if (cr0.eq) goto loc_831A17B8;
	// rlwinm. r11,r11,0,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a17b8
	if (!cr0.eq) goto loc_831A17B8;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A17B8:
	// add r26,r7,r8
	r26.u64 = ctx.r7.u64 + ctx.r8.u64;
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
	// cmplw cr6,r7,r26
	cr6.compare<uint32_t>(ctx.r7.u32, r26.u32, xer);
	// bge cr6,0x831a1870
	if (!cr6.lt) goto loc_831A1870;
	// rlwinm r11,r7,3,0,28
	r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// add r30,r11,r24
	r30.u64 = r11.u64 + r24.u64;
loc_831A17D0:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831a1830
	if (cr6.eq) goto loc_831A1830;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a1830
	if (cr6.eq) goto loc_831A1830;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x831a1824
	if (cr6.eq) goto loc_831A1824;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// clrlwi r10,r31,18
	ctx.r10.u64 = r31.u32 & 0x3FFF;
	// rlwinm r9,r29,15,0,16
	ctx.r9.u64 = rotl64(r29.u32 | (r29.u64 << 32), 15) & 0xFFFF8000;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// or r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 | ctx.r9.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,3
	ctx.r10.u64 = ctx.r10.u64 | 3;
	// ori r9,r9,2
	ctx.r9.u64 = ctx.r9.u64 | 2;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// b 0x831a1854
	goto loc_831A1854;
loc_831A1824:
	// ld r11,0(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// b 0x831a1854
	goto loc_831A1854;
loc_831A1830:
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,0,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFC;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// rlwimi r11,r29,17,0,14
	r11.u64 = (rotl32(r29.u32, 17) & 0xFFFE0000) | (r11.u64 & 0xFFFFFFFF0001FFFF);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// rlwinm r11,r11,0,30,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFF0003;
	// rlwimi r11,r31,2,16,29
	r11.u64 = (rotl32(r31.u32, 2) & 0xFFFC) | (r11.u64 & 0xFFFFFFFFFFFF0003);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
loc_831A1854:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// ld r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// bl 0x8319fd40
	sub_8319FD40(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// cmplw cr6,r31,r26
	cr6.compare<uint32_t>(r31.u32, r26.u32, xer);
	// blt cr6,0x831a17d0
	if (cr6.lt) goto loc_831A17D0;
loc_831A1870:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_831A1760) {
	__imp__sub_831A1760(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A1878) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r21,r6
	r21.u64 = ctx.r6.u64;
	// mr r22,r7
	r22.u64 = ctx.r7.u64;
	// lwz r11,564(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// mr r23,r8
	r23.u64 = ctx.r8.u64;
	// lwz r11,80(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a18b8
	if (cr6.eq) goto loc_831A18B8;
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r25,r10,r11
	r25.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x831a18bc
	goto loc_831A18BC;
loc_831A18B8:
	// li r25,0
	r25.s64 = 0;
loc_831A18BC:
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// rlwinm. r10,r11,0,15,15
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a18d0
	if (cr0.eq) goto loc_831A18D0;
	// cmplwi cr6,r29,727
	cr6.compare<uint32_t>(r29.u32, 727, xer);
	// blt cr6,0x831a18f0
	if (cr6.lt) goto loc_831A18F0;
loc_831A18D0:
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a1918
	if (cr0.eq) goto loc_831A1918;
	// lwz r11,600(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 600);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x831a1918
	if (cr6.lt) goto loc_831A1918;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// bge cr6,0x831a1918
	if (!cr6.lt) goto loc_831A1918;
loc_831A18F0:
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831a1760
	sub_831A1760(ctx, base);
	// li r3,4
	ctx.r3.s64 = 4;
	// b 0x831a19b0
	goto loc_831A19B0;
loc_831A1918:
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mulli r11,r29,40
	r11.s64 = r29.s64 * 40;
	// add r27,r11,r10
	r27.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,28(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a193c
	if (!cr6.eq) goto loc_831A193C;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831387b8
	sub_831387B8(ctx, base);
loc_831A193C:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// li r31,0
	r31.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// rlwinm. r11,r11,0,15,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1FFF8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a19ac
	if (cr0.eq) goto loc_831A19AC;
	// li r26,0
	r26.s64 = 0;
loc_831A1954:
	// lwz r11,28(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// rlwinm r11,r11,28,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x3FFF;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bne cr6,0x831a1994
	if (!cr6.eq) goto loc_831A1994;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831a1760
	sub_831A1760(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r22
	cr6.compare<uint32_t>(r31.u32, r22.u32, xer);
	// bge cr6,0x831a19ac
	if (!cr6.lt) goto loc_831A19AC;
loc_831A1994:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r26,r26,8
	r26.s64 = r26.s64 + 8;
	// rlwinm r11,r11,29,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x831a1954
	if (cr6.lt) goto loc_831A1954;
loc_831A19AC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_831A19B0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c1c
	return;
}

PPC_WEAK_FUNC(sub_831A1878) {
	__imp__sub_831A1878(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A19B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// stw r5,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r5.u32);
	// rlwimi r11,r6,2,16,29
	r11.u64 = (rotl32(ctx.r6.u32, 2) & 0xFFFC) | (r11.u64 & 0xFFFFFFFFFFFF0003);
	// rlwinm r11,r11,0,15,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1FFFC;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// ld r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// bl 0x8319fd40
	sub_8319FD40(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831A19B8) {
	__imp__sub_831A19B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A19F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// lwz r28,4(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r27,8(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// b 0x831a1a38
	goto loc_831A1A38;
loc_831A1A1C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// ld r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x8319fd40
	sub_8319FD40(ctx, base);
loc_831A1A38:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831a1a1c
	if (!cr6.eq) goto loc_831A1A1C;
	// stw r28,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r28.u32);
	// stw r27,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r27.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831A19F8) {
	__imp__sub_831A19F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A1A50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb8
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r19,r9
	r19.u64 = ctx.r9.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r17,r4
	r17.u64 = ctx.r4.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// mr r18,r7
	r18.u64 = ctx.r7.u64;
	// lwz r9,20(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// mr r27,r8
	r27.u64 = ctx.r8.u64;
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// mullw r16,r11,r9
	r16.s64 = int64_t(r11.s32) * int64_t(ctx.r9.s32);
	// cmpwi cr6,r10,33
	cr6.compare<int32_t>(ctx.r10.s32, 33, xer);
	// beq cr6,0x831a1aa0
	if (cr6.eq) goto loc_831A1AA0;
	// cmplwi cr6,r16,4
	cr6.compare<uint32_t>(r16.u32, 4, xer);
	// beq cr6,0x831a1adc
	if (cr6.eq) goto loc_831A1ADC;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A1AA0:
	// cmplwi cr6,r16,4
	cr6.compare<uint32_t>(r16.u32, 4, xer);
	// ble cr6,0x831a1adc
	if (!cr6.gt) goto loc_831A1ADC;
	// lwz r11,48(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 48);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x831a1ac8
	if (cr6.eq) goto loc_831A1AC8;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r5,r11,-29688
	ctx.r5.s64 = r11.s64 + -29688;
	// b 0x831a1ad0
	goto loc_831A1AD0;
loc_831A1AC8:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r5,r11,-29696
	ctx.r5.s64 = r11.s64 + -29696;
loc_831A1AD0:
	// li r4,4532
	ctx.r4.s64 = 4532;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A1ADC:
	// lwz r11,36(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 36);
	// cmpwi cr6,r10,33
	cr6.compare<int32_t>(ctx.r10.s32, 33, xer);
	// bne cr6,0x831a1b0c
	if (!cr6.eq) goto loc_831A1B0C;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a1b00
	if (cr6.eq) goto loc_831A1B00;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// beq cr6,0x831a1b20
	if (cr6.eq) goto loc_831A1B20;
loc_831A1B00:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A1B0C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a1e14
	if (cr6.eq) goto loc_831A1E14;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// bne cr6,0x831a1e14
	if (!cr6.eq) goto loc_831A1E14;
loc_831A1B20:
	// lwz r28,8(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831a1e08
	if (cr6.eq) goto loc_831A1E08;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a1e08
	if (!cr6.eq) goto loc_831A1E08;
	// mr r31,r30
	r31.u64 = r30.u64;
	// cmpwi cr6,r10,33
	cr6.compare<int32_t>(ctx.r10.s32, 33, xer);
	// bne cr6,0x831a1b5c
	if (!cr6.eq) goto loc_831A1B5C;
	// lwz r4,12(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a1b84
	if (!cr6.eq) goto loc_831A1B84;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// b 0x831a1b84
	goto loc_831A1B84;
loc_831A1B5C:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a1dfc
	if (cr6.eq) goto loc_831A1DFC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a1dfc
	if (!cr6.eq) goto loc_831A1DFC;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r19,1
	cr6.compare<int32_t>(r19.s32, 1, xer);
	// ble cr6,0x831a1b84
	if (!cr6.gt) goto loc_831A1B84;
	// li r31,4
	r31.s64 = 4;
loc_831A1B84:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// cmplw cr6,r31,r3
	cr6.compare<uint32_t>(r31.u32, ctx.r3.u32, xer);
	// beq cr6,0x831a1ba0
	if (cr6.eq) goto loc_831A1BA0;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A1BA0:
	// addi r21,r31,1
	r21.s64 = r31.s64 + 1;
	// cmpwi cr6,r19,1
	cr6.compare<int32_t>(r19.s32, 1, xer);
	// bne cr6,0x831a1bb8
	if (!cr6.eq) goto loc_831A1BB8;
	// rlwinm r11,r31,1,0,30
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// add r21,r11,r21
	r21.u64 = r11.u64 + r21.u64;
	// b 0x831a1bd0
	goto loc_831A1BD0;
loc_831A1BB8:
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// bne cr6,0x831a1bd0
	if (!cr6.eq) goto loc_831A1BD0;
	// cmpwi cr6,r19,1
	cr6.compare<int32_t>(r19.s32, 1, xer);
	// ble cr6,0x831a1bd0
	if (!cr6.gt) goto loc_831A1BD0;
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
loc_831A1BD0:
	// clrlwi. r20,r27,24
	r20.u64 = r27.u32 & 0xFF;
	cr0.compare<int32_t>(r20.s32, 0, xer);
	// beq 0x831a1bdc
	if (cr0.eq) goto loc_831A1BDC;
	// add r21,r21,r30
	r21.u64 = r21.u64 + r30.u64;
loc_831A1BDC:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// cmplw cr6,r21,r3
	cr6.compare<uint32_t>(r21.u32, ctx.r3.u32, xer);
	// beq cr6,0x831a1bfc
	if (cr6.eq) goto loc_831A1BFC;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A1BFC:
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// li r27,0
	r27.s64 = 0;
	// li r25,0
	r25.s64 = 0;
	// cmpwi cr6,r19,1
	cr6.compare<int32_t>(r19.s32, 1, xer);
	// bne cr6,0x831a1c8c
	if (!cr6.eq) goto loc_831A1C8C;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x831a1cb8
	goto loc_831A1CB8;
loc_831A1C8C:
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// bne cr6,0x831a1cb8
	if (!cr6.eq) goto loc_831A1CB8;
	// cmpwi cr6,r19,1
	cr6.compare<int32_t>(r19.s32, 1, xer);
	// ble cr6,0x831a1cb8
	if (!cr6.gt) goto loc_831A1CB8;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
loc_831A1CB8:
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x831a1d14
	if (cr6.eq) goto loc_831A1D14;
	// addi r11,r30,2
	r11.s64 = r30.s64 + 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r30,4(r24)
	PPC_STORE_U32(r24.u32 + 4, r30.u32);
	// beq cr6,0x831a1d14
	if (cr6.eq) goto loc_831A1D14;
	// addi r29,r24,8
	r29.s64 = r24.s64 + 8;
	// mr r31,r30
	r31.u64 = r30.u64;
loc_831A1CF0:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// stw r3,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r3.u32);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// bne 0x831a1cf0
	if (!cr0.eq) goto loc_831A1CF0;
loc_831A1D14:
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// stw r25,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r25.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r27.u32);
	// mr r8,r19
	ctx.r8.u64 = r19.u64;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8319e310
	sub_8319E310(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x831a1da0
	if (cr6.eq) goto loc_831A1DA0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a1d74
	if (cr6.eq) goto loc_831A1D74;
	// addi r31,r24,8
	r31.s64 = r24.s64 + 8;
loc_831A1D58:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// bne 0x831a1d58
	if (!cr0.eq) goto loc_831A1D58;
loc_831A1D74:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r29,-4
	r11.s64 = r29.s64 + -4;
	// stwx r24,r3,r11
	PPC_STORE_U32(ctx.r3.u32 + r11.u32, r24.u32);
	// lwz r11,40(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 40);
	// oris r11,r11,16
	r11.u64 = r11.u64 | 1048576;
	// stw r11,40(r26)
	PPC_STORE_U32(r26.u32 + 40, r11.u32);
loc_831A1DA0:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x831a1db8
	if (cr6.eq) goto loc_831A1DB8;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831A1DB8:
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x831a1df4
	if (cr6.eq) goto loc_831A1DF4;
loc_831A1DC4:
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// rlwimi r11,r31,2,16,29
	r11.u64 = (rotl32(r31.u32, 2) & 0xFFFC) | (r11.u64 & 0xFFFFFFFFFFFF0003);
	// rlwinm r11,r11,0,15,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1FFFC;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// ld r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// bl 0x8319fd40
	sub_8319FD40(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r16
	cr6.compare<uint32_t>(r31.u32, r16.u32, xer);
	// blt cr6,0x831a1dc4
	if (cr6.lt) goto loc_831A1DC4;
loc_831A1DF4:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82ca2c08
	return;
loc_831A1DFC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A1E08:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A1E14:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831A1A50) {
	__imp__sub_831A1A50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A1E20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x831385c0
	sub_831385C0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_831A1E48:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a1e68
	if (!cr6.eq) goto loc_831A1E68;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a03d8
	sub_831A03D8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x831a1e6c
	if (cr0.eq) goto loc_831A1E6C;
loc_831A1E68:
	// li r11,0
	r11.s64 = 0;
loc_831A1E6C:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a1ef0
	if (!cr0.eq) goto loc_831A1EF0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a0430
	sub_831A0430(ctx, base);
	// cmpwi cr6,r3,38
	cr6.compare<int32_t>(ctx.r3.s32, 38, xer);
	// bgt cr6,0x831a1ebc
	if (cr6.gt) goto loc_831A1EBC;
	// cmpwi cr6,r3,33
	cr6.compare<int32_t>(ctx.r3.s32, 33, xer);
	// bge cr6,0x831a1ee4
	if (!cr6.lt) goto loc_831A1EE4;
	// cmpwi cr6,r3,22
	cr6.compare<int32_t>(ctx.r3.s32, 22, xer);
	// blt cr6,0x831a1eb4
	if (cr6.lt) goto loc_831A1EB4;
	// cmpwi cr6,r3,25
	cr6.compare<int32_t>(ctx.r3.s32, 25, xer);
	// ble cr6,0x831a1ee4
	if (!cr6.gt) goto loc_831A1EE4;
	// cmpwi cr6,r3,27
	cr6.compare<int32_t>(ctx.r3.s32, 27, xer);
	// beq cr6,0x831a1ee4
	if (cr6.eq) goto loc_831A1EE4;
	// cmpwi cr6,r3,28
	cr6.compare<int32_t>(ctx.r3.s32, 28, xer);
	// ble cr6,0x831a1eb4
	if (!cr6.gt) goto loc_831A1EB4;
	// cmpwi cr6,r3,30
	cr6.compare<int32_t>(ctx.r3.s32, 30, xer);
	// ble cr6,0x831a1ee4
	if (!cr6.gt) goto loc_831A1EE4;
loc_831A1EB4:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x831a1f04
	goto loc_831A1F04;
loc_831A1EBC:
	// cmpwi cr6,r3,42
	cr6.compare<int32_t>(ctx.r3.s32, 42, xer);
	// blt cr6,0x831a1eb4
	if (cr6.lt) goto loc_831A1EB4;
	// cmpwi cr6,r3,43
	cr6.compare<int32_t>(ctx.r3.s32, 43, xer);
	// ble cr6,0x831a1ee4
	if (!cr6.gt) goto loc_831A1EE4;
	// cmpwi cr6,r3,44
	cr6.compare<int32_t>(ctx.r3.s32, 44, xer);
	// ble cr6,0x831a1eb4
	if (!cr6.gt) goto loc_831A1EB4;
	// cmpwi cr6,r3,47
	cr6.compare<int32_t>(ctx.r3.s32, 47, xer);
	// ble cr6,0x831a1ee4
	if (!cr6.gt) goto loc_831A1EE4;
	// cmpwi cr6,r3,55
	cr6.compare<int32_t>(ctx.r3.s32, 55, xer);
	// bne cr6,0x831a1eb4
	if (!cr6.eq) goto loc_831A1EB4;
loc_831A1EE4:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// b 0x831a1e48
	goto loc_831A1E48;
loc_831A1EF0:
	// lwz r10,1004(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 1004);
	// addi r11,r30,972
	r11.s64 = r30.s64 + 972;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r31,1004(r30)
	PPC_STORE_U32(r30.u32 + 1004, r31.u32);
loc_831A1F04:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831A1E20) {
	__imp__sub_831A1E20(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A1F20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// mr r24,r7
	r24.u64 = ctx.r7.u64;
	// lwz r11,112(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 112);
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a2154
	if (cr6.eq) goto loc_831A2154;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a2154
	if (!cr6.eq) goto loc_831A2154;
	// mr r31,r11
	r31.u64 = r11.u64;
loc_831A1F60:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a2118
	if (cr6.eq) goto loc_831A2118;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a2118
	if (!cr6.eq) goto loc_831A2118;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a1fe0
	if (cr6.eq) goto loc_831A1FE0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// beq cr6,0x831a1fe0
	if (cr6.eq) goto loc_831A1FE0;
	// rotlwi r10,r10,0
	ctx.r10.u64 = rotl32(ctx.r10.u32, 0);
	// cmpwi cr6,r10,11
	cr6.compare<int32_t>(ctx.r10.s32, 11, xer);
	// bne cr6,0x831a210c
	if (!cr6.eq) goto loc_831A210C;
	// lwz r10,564(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 564);
	// lwz r10,80(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a1fbc
	if (cr6.eq) goto loc_831A1FBC;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r9,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// b 0x831a1fc0
	goto loc_831A1FC0;
loc_831A1FBC:
	// li r6,0
	ctx.r6.s64 = 0;
loc_831A1FC0:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831a1760
	sub_831A1760(ctx, base);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
loc_831A1FE0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a1ff8
	if (cr6.eq) goto loc_831A1FF8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a2100
	if (!cr6.eq) goto loc_831A2100;
loc_831A1FF8:
	// mr r31,r11
	r31.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a1f60
	if (!cr6.eq) goto loc_831A1F60;
	// addi r11,r27,2
	r11.s64 = r27.s64 + 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r29,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r29.u32);
	// stw r27,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r27.u32);
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// lwz r11,112(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 112);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a2148
	if (cr6.eq) goto loc_831A2148;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a2148
	if (!cr6.eq) goto loc_831A2148;
	// mr r26,r11
	r26.u64 = r11.u64;
	// addi r29,r31,8
	r29.s64 = r31.s64 + 8;
loc_831A2060:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a213c
	if (cr6.eq) goto loc_831A213C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a213c
	if (!cr6.eq) goto loc_831A213C;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a20c4
	if (cr6.eq) goto loc_831A20C4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x831a20c4
	if (cr6.eq) goto loc_831A20C4;
	// cmplw cr6,r28,r27
	cr6.compare<uint32_t>(r28.u32, r27.u32, xer);
	// bge cr6,0x831a2124
	if (!cr6.lt) goto loc_831A2124;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r3.u32);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
loc_831A20C4:
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a20dc
	if (cr6.eq) goto loc_831A20DC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a2130
	if (!cr6.eq) goto loc_831A2130;
loc_831A20DC:
	// mr r26,r11
	r26.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a2060
	if (!cr6.eq) goto loc_831A2060;
	// stw r31,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r31.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// oris r11,r11,16
	r11.u64 = r11.u64 | 1048576;
	// stw r11,40(r30)
	PPC_STORE_U32(r30.u32 + 40, r11.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c28
	return;
loc_831A2100:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A210C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2118:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2124:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2130:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A213C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2148:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2154:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831A1F20) {
	__imp__sub_831A1F20(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A2160) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc0
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r10
	r24.u64 = ctx.r10.u64;
	// li r26,0
	r26.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r19,r4
	r19.u64 = ctx.r4.u64;
	// mr r20,r5
	r20.u64 = ctx.r5.u64;
	// stw r26,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r26.u32);
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// stw r26,4(r24)
	PPC_STORE_U32(r24.u32 + 4, r26.u32);
	// mr r18,r7
	r18.u64 = ctx.r7.u64;
	// stw r26,8(r24)
	PPC_STORE_U32(r24.u32 + 8, r26.u32);
	// mr r22,r8
	r22.u64 = ctx.r8.u64;
	// stw r26,12(r24)
	PPC_STORE_U32(r24.u32 + 12, r26.u32);
	// mr r23,r9
	r23.u64 = ctx.r9.u64;
	// lwz r11,576(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 576);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a21b8
	if (cr0.eq) goto loc_831A21B8;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_831A21B8:
	// stw r26,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r26.u32);
	// mr r21,r26
	r21.u64 = r26.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r28,1
	r28.s64 = 1;
loc_831A21C8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a21e4
	if (cr6.eq) goto loc_831A21E4;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// bne cr6,0x831a21e8
	if (!cr6.eq) goto loc_831A21E8;
loc_831A21E4:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_831A21E8:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a2210
	if (!cr0.eq) goto loc_831A2210;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// slw r10,r28,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r10.u8 & 0x3F));
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// or r21,r10,r21
	r21.u64 = ctx.r10.u64 | r21.u64;
	// b 0x831a21c8
	goto loc_831A21C8;
loc_831A2210:
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// stw r19,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r19.u32);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a2224
	if (cr0.eq) goto loc_831A2224;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_831A2224:
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r27,r26
	r27.u64 = r26.u64;
	// stw r26,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r26.u32);
	// lis r29,-1
	r29.s64 = -65536;
loc_831A2234:
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a2254
	if (cr6.eq) goto loc_831A2254;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// bne cr6,0x831a2258
	if (!cr6.eq) goto loc_831A2258;
loc_831A2254:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_831A2258:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a2574
	if (!cr0.eq) goto loc_831A2574;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r30,r11,r10
	r30.u64 = r11.u64 + ctx.r10.u64;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// slw r11,r28,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r10.u8 & 0x3F));
	// and r9,r11,r20
	ctx.r9.u64 = r11.u64 & r20.u64;
	// rlwinm. r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831a22d4
	if (!cr0.eq) goto loc_831A22D4;
	// and r11,r11,r25
	r11.u64 = r11.u64 & r25.u64;
	// rlwinm. r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a22c8
	if (!cr0.eq) goto loc_831A22C8;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a2540
	if (cr6.eq) goto loc_831A2540;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x831a2540
	if (!cr6.eq) goto loc_831A2540;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x831a2538
	if (!cr6.eq) goto loc_831A2538;
	// li r4,3580
	ctx.r4.s64 = 3580;
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x830fd220
	sub_830FD220(ctx, base);
loc_831A22C8:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319ba60
	sub_8319BA60(ctx, base);
	// b 0x831a2234
	goto loc_831A2234;
loc_831A22D4:
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831a2300
	if (cr6.eq) goto loc_831A2300;
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// beq cr6,0x831a230c
	if (cr6.eq) goto loc_831A230C;
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
loc_831A22E8:
	// rlwinm. r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a230c
	if (cr0.eq) goto loc_831A230C;
	// li r4,3577
	ctx.r4.s64 = 3577;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
	// b 0x831a22c8
	goto loc_831A22C8;
loc_831A2300:
	// or r9,r27,r21
	ctx.r9.u64 = r27.u64 | r21.u64;
	// and r11,r9,r11
	r11.u64 = ctx.r9.u64 & r11.u64;
	// b 0x831a22e8
	goto loc_831A22E8;
loc_831A230C:
	// addi r11,r10,-10
	r11.s64 = ctx.r10.s64 + -10;
	// cmplwi cr6,r11,13
	cr6.compare<uint32_t>(r11.u32, 13, xer);
	// bgt cr6,0x831a251c
	if (cr6.gt) goto loc_831A251C;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,2320
	r12.s64 = r12.s64 + 2320;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// rlwinm r0,r0,2,0,29
	r0.u64 = rotl64(r0.u32 | (r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-31974
	r12.s64 = -2095448064;
	// addi r12,r12,9024
	r12.s64 = r12.s64 + 9024;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_831A2340;
	case 1:
		goto loc_831A251C;
	case 2:
		goto loc_831A251C;
	case 3:
		goto loc_831A234C;
	case 4:
		goto loc_831A2364;
	case 5:
		goto loc_831A251C;
	case 6:
		goto loc_831A23B8;
	case 7:
		goto loc_831A2460;
	case 8:
		goto loc_831A251C;
	case 9:
		goto loc_831A24C8;
	case 10:
		goto loc_831A23E8;
	case 11:
		goto loc_831A251C;
	case 12:
		goto loc_831A24E4;
	case 13:
		goto loc_831A24F0;
	default:
		__builtin_unreachable();
	}
loc_831A2340:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r11,8(r24)
	PPC_STORE_U32(r24.u32 + 8, r11.u32);
	// b 0x831a251c
	goto loc_831A251C;
loc_831A234C:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x83195220
	sub_83195220(ctx, base);
	// stw r3,788(r31)
	PPC_STORE_U32(r31.u32 + 788, ctx.r3.u32);
	// b 0x831a251c
	goto loc_831A251C;
loc_831A2364:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x83195220
	sub_83195220(ctx, base);
	// stw r3,792(r31)
	PPC_STORE_U32(r31.u32 + 792, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x831a254c
	if (cr0.eq) goto loc_831A254C;
	// cmplwi cr6,r3,64
	cr6.compare<uint32_t>(ctx.r3.u32, 64, xer);
	// bgt cr6,0x831a254c
	if (cr6.gt) goto loc_831A254C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a251c
	if (cr6.eq) goto loc_831A251C;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a251c
	if (cr6.eq) goto loc_831A251C;
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// beq cr6,0x831a251c
	if (cr6.eq) goto loc_831A251C;
	// li r4,3581
	ctx.r4.s64 = 3581;
loc_831A23AC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
	// b 0x831a251c
	goto loc_831A251C;
loc_831A23B8:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x83195220
	sub_83195220(ctx, base);
	// stw r3,796(r31)
	PPC_STORE_U32(r31.u32 + 796, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831a251c
	if (!cr0.eq) goto loc_831A251C;
	// rotlwi r6,r3,0
	ctx.r6.u64 = rotl32(ctx.r3.u32, 0);
	// li r5,64
	ctx.r5.s64 = 64;
	// li r4,3603
	ctx.r4.s64 = 3603;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A23E8:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x83195220
	sub_83195220(ctx, base);
	// stw r3,808(r31)
	PPC_STORE_U32(r31.u32 + 808, ctx.r3.u32);
	// cmplwi cr6,r3,256
	cr6.compare<uint32_t>(ctx.r3.u32, 256, xer);
	// blt cr6,0x831a2560
	if (cr6.lt) goto loc_831A2560;
	// cmplwi cr6,r3,3839
	cr6.compare<uint32_t>(ctx.r3.u32, 3839, xer);
	// bgt cr6,0x831a2560
	if (cr6.gt) goto loc_831A2560;
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831a251c
	if (cr6.eq) goto loc_831A251C;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r10,r11,0,0,15
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// bne cr6,0x831a2444
	if (!cr6.eq) goto loc_831A2444;
	// lwz r11,48(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a243c
	if (cr6.eq) goto loc_831A243C;
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// bne cr6,0x831a2458
	if (!cr6.eq) goto loc_831A2458;
loc_831A243C:
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// beq cr6,0x831a251c
	if (cr6.eq) goto loc_831A251C;
loc_831A2444:
	// lwz r11,52(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 52);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a251c
	if (cr6.eq) goto loc_831A251C;
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// beq cr6,0x831a251c
	if (cr6.eq) goto loc_831A251C;
loc_831A2458:
	// li r4,3616
	ctx.r4.s64 = 3616;
	// b 0x831a23ac
	goto loc_831A23AC;
loc_831A2460:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x83195328
	sub_83195328(ctx, base);
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// beq cr6,0x831a251c
	if (cr6.eq) goto loc_831A251C;
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a24b8
	if (cr0.eq) goto loc_831A24B8;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a24ac
	if (cr6.eq) goto loc_831A24AC;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a24ac
	if (!cr0.eq) goto loc_831A24AC;
	// li r4,3608
	ctx.r4.s64 = 3608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
loc_831A24AC:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// ori r11,r11,16
	r11.u64 = r11.u64 | 16;
	// b 0x831a24c0
	goto loc_831A24C0;
loc_831A24B8:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// rlwinm r11,r11,0,28,26
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFEF;
loc_831A24C0:
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// b 0x831a251c
	goto loc_831A251C;
loc_831A24C8:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bne cr6,0x831a251c
	if (!cr6.eq) goto loc_831A251C;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// b 0x831a24c0
	goto loc_831A24C0;
loc_831A24E4:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// ori r11,r11,4096
	r11.u64 = r11.u64 | 4096;
	// b 0x831a24c0
	goto loc_831A24C0;
loc_831A24F0:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x83195328
	sub_83195328(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// beq 0x831a2514
	if (cr0.eq) goto loc_831A2514;
	// rlwinm r11,r11,0,31,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
	// b 0x831a2518
	goto loc_831A2518;
loc_831A2514:
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
loc_831A2518:
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
loc_831A251C:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// slw r11,r28,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r28.u32 << (r11.u8 & 0x3F));
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// or r27,r11,r27
	r27.u64 = r11.u64 | r27.u64;
	// b 0x831a2234
	goto loc_831A2234;
loc_831A2538:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2540:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A254C:
	// li r5,64
	ctx.r5.s64 = 64;
	// lwz r6,792(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 792);
	// li r4,3589
	ctx.r4.s64 = 3589;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2560:
	// li r5,3839
	ctx.r5.s64 = 3839;
	// lwz r6,808(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 808);
	// li r4,3615
	ctx.r4.s64 = 3615;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2574:
	// rlwinm. r11,r27,0,29,29
	r11.u64 = rotl64(r27.u32 | (r27.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a25f4
	if (!cr0.eq) goto loc_831A25F4;
	// rlwinm. r11,r27,0,30,30
	r11.u64 = rotl64(r27.u32 | (r27.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a25f4
	if (cr0.eq) goto loc_831A25F4;
	// lwz r3,576(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 576);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// li r10,2
	ctx.r10.s64 = 2;
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// std r26,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r26.u64);
	// clrlwi. r11,r9,31
	r11.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bne 0x831a25c8
	if (!cr0.eq) goto loc_831A25C8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a25c8
	if (cr0.eq) goto loc_831A25C8;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831a25d4
	if (!cr6.gt) goto loc_831A25D4;
loc_831A25C8:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8319ab78
	sub_8319AB78(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831A25D4:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// ori r27,r27,4
	r27.u64 = r27.u64 | 4;
	// ld r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stdx r9,r10,r11
	PPC_STORE_U64(ctx.r10.u32 + r11.u32, ctx.r9.u64);
loc_831A25F4:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831a2768
	if (cr6.eq) goto loc_831A2768;
	// cmpwi cr6,r18,3
	cr6.compare<int32_t>(r18.s32, 3, xer);
	// bne cr6,0x831a2700
	if (!cr6.eq) goto loc_831A2700;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x831a2700
	if (cr6.eq) goto loc_831A2700;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a07c0
	sub_831A07C0(ctx, base);
	// rlwinm. r11,r27,0,29,30
	r11.u64 = rotl64(r27.u32 | (r27.u64 << 32), 0) & 0x6;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a26f0
	if (cr0.eq) goto loc_831A26F0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r3,592(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 592);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a265c
	if (!cr0.eq) goto loc_831A265C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a265c
	if (cr0.eq) goto loc_831A265C;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831a2668
	if (!cr6.gt) goto loc_831A2668;
loc_831A265C:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831A2668:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r29,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r29.u32);
	// lwz r3,592(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 592);
	// lwz r30,0(r23)
	r30.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a26b8
	if (!cr0.eq) goto loc_831A26B8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a26b8
	if (cr0.eq) goto loc_831A26B8;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831a26c4
	if (!cr6.gt) goto loc_831A26C4;
loc_831A26B8:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831A26C4:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r30,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r30.u32);
	// lwz r4,0(r22)
	ctx.r4.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// lwz r3,588(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 588);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// stw r29,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r29.u32);
	// stw r26,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r26.u32);
loc_831A26F0:
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,588(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 588);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x831a0630
	sub_831A0630(ctx, base);
loc_831A2700:
	// rlwinm. r11,r27,0,30,30
	r11.u64 = rotl64(r27.u32 | (r27.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a2714
	if (cr0.eq) goto loc_831A2714;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// oris r11,r11,8192
	r11.u64 = r11.u64 | 536870912;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
loc_831A2714:
	// rlwinm. r11,r27,0,20,20
	r11.u64 = rotl64(r27.u32 | (r27.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a2728
	if (cr0.eq) goto loc_831A2728;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
loc_831A2728:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r10,r27,0,29,29
	ctx.r10.u64 = rotl64(r27.u32 | (r27.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// beq 0x831a2768
	if (cr0.eq) goto loc_831A2768;
	// cmpwi cr6,r18,3
	cr6.compare<int32_t>(r18.s32, 3, xer);
	// bne cr6,0x831a2768
	if (!cr6.eq) goto loc_831A2768;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x831a2768
	if (cr6.eq) goto loc_831A2768;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a06b0
	sub_831A06B0(ctx, base);
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,588(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 588);
	// bl 0x831a0630
	sub_831A0630(ctx, base);
loc_831A2768:
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// lwz r3,576(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 576);
	// bl 0x83196de0
	sub_83196DE0(ctx, base);
	// or r11,r27,r21
	r11.u64 = r27.u64 | r21.u64;
	// stw r20,4(r24)
	PPC_STORE_U32(r24.u32 + 4, r20.u32);
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c10
	return;
}

PPC_WEAK_FUNC(sub_831A2160) {
	__imp__sub_831A2160(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A2788) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// mr r26,r8
	r26.u64 = ctx.r8.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r11,r31,4
	r11.s64 = r31.s64 + 4;
	// ori r10,r31,1
	ctx.r10.u64 = r31.u64 | 1;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319fdc0
	sub_8319FDC0(ctx, base);
	// b 0x831a2808
	goto loc_831A2808;
loc_831A27E4:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831a28b4
	if (cr6.eq) goto loc_831A28B4;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831a28b4
	if (!cr6.eq) goto loc_831A28B4;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319f410
	sub_8319F410(ctx, base);
loc_831A2808:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831a27e4
	if (!cr0.eq) goto loc_831A27E4;
	// li r5,0
	ctx.r5.s64 = 0;
	// cmpwi cr6,r28,2
	cr6.compare<int32_t>(r28.s32, 2, xer);
	// bne cr6,0x831a2850
	if (!cr6.eq) goto loc_831A2850;
	// rlwinm. r11,r29,0,26,26
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a2834
	if (cr0.eq) goto loc_831A2834;
	// rlwinm. r10,r29,0,27,27
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a2838
	if (cr0.eq) goto loc_831A2838;
loc_831A2834:
	// li r5,4096
	ctx.r5.s64 = 4096;
loc_831A2838:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a2850
	if (cr6.eq) goto loc_831A2850;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// rlwinm. r11,r11,0,3,3
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a2850
	if (!cr0.eq) goto loc_831A2850;
	// li r5,4
	ctx.r5.s64 = 4;
loc_831A2850:
	// cmpwi cr6,r26,1
	cr6.compare<int32_t>(r26.s32, 1, xer);
	// bne cr6,0x831a285c
	if (!cr6.eq) goto loc_831A285C;
	// rlwinm r5,r5,0,29,29
	ctx.r5.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x4;
loc_831A285C:
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm. r10,r11,0,19,19
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a2894
	if (cr0.eq) goto loc_831A2894;
	// lwz r10,4(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// oris r10,r10,8192
	ctx.r10.u64 = ctx.r10.u64 | 536870912;
	// stw r10,4(r27)
	PPC_STORE_U32(r27.u32 + 4, ctx.r10.u32);
loc_831A2894:
	// rlwinm. r11,r11,0,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a28e0
	if (cr0.eq) goto loc_831A28E0;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpw cr6,r28,r26
	cr6.compare<int32_t>(r28.s32, r26.s32, xer);
	// bne cr6,0x831a28c0
	if (!cr6.eq) goto loc_831A28C0;
	// oris r11,r11,16384
	r11.u64 = r11.u64 | 1073741824;
	// stw r11,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r11.u32);
	// b 0x831a28d4
	goto loc_831A28D4;
loc_831A28B4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A28C0:
	// rlwinm. r11,r11,0,1,1
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a28d4
	if (cr0.eq) goto loc_831A28D4;
	// li r4,3577
	ctx.r4.s64 = 3577;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
loc_831A28D4:
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// ori r11,r11,32768
	r11.u64 = r11.u64 | 32768;
	// stw r11,40(r30)
	PPC_STORE_U32(r30.u32 + 40, r11.u32);
loc_831A28E0:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319f688
	sub_8319F688(ctx, base);
	// addi r10,r30,972
	ctx.r10.s64 = r30.s64 + 972;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r9,r11,972
	ctx.r9.s64 = r11.s64 + 972;
	// lwz r10,976(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 976);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r31,976(r30)
	PPC_STORE_U32(r30.u32 + 976, r31.u32);
	// lwz r10,976(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 976);
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// stw r8,976(r11)
	PPC_STORE_U32(r11.u32 + 976, ctx.r8.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_831A2788) {
	__imp__sub_831A2788(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A2920) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r7,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, ctx.r7.u32);
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r15,r5
	r15.u64 = ctx.r5.u64;
	// stw r28,332(r1)
	PPC_STORE_U32(ctx.r1.u32 + 332, r28.u32);
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplw cr6,r15,r11
	cr6.compare<uint32_t>(r15.u32, r11.u32, xer);
	// beq cr6,0x831a2c84
	if (cr6.eq) goto loc_831A2C84;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r9,r15,40
	ctx.r9.s64 = r15.s64 * 40;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r8,r9,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r11,80(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// li r18,0
	r18.s64 = 0;
	// add r20,r9,r10
	r20.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// rlwinm r30,r8,29,18,31
	r30.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x3FFF;
	// beq cr6,0x831a2984
	if (cr6.eq) goto loc_831A2984;
	// rlwinm r10,r15,2,0,29
	ctx.r10.u64 = rotl64(r15.u32 | (r15.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r10,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x831a2988
	goto loc_831A2988;
loc_831A2984:
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
loc_831A2988:
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a1760
	sub_831A1760(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,20(r20)
	ctx.r4.u64 = PPC_LOAD_U32(r20.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831385c0
	sub_831385C0(ctx, base);
	// mr r16,r3
	r16.u64 = ctx.r3.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r30.u32);
	// mr r21,r18
	r21.u64 = r18.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a2c6c
	if (cr6.eq) goto loc_831A2C6C;
loc_831A29E4:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x831a0430
	sub_831A0430(ctx, base);
	// lwz r29,8(r16)
	r29.u64 = PPC_LOAD_U32(r16.u32 + 8);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// beq cr6,0x831a2ccc
	if (cr6.eq) goto loc_831A2CCC;
	// lwz r11,28(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a2a14
	if (!cr6.eq) goto loc_831A2A14;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831387b8
	sub_831387B8(ctx, base);
loc_831A2A14:
	// lwz r11,4(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 4);
	// mr r22,r18
	r22.u64 = r18.u64;
	// addic. r19,r11,1
	xer.ca = r11.u32 > 4294967294;
	r19.s64 = r11.s64 + 1;
	cr0.compare<int32_t>(r19.s32, 0, xer);
	// beq 0x831a2c54
	if (cr0.eq) goto loc_831A2C54;
	// rlwinm r14,r21,3,0,28
	r14.u64 = rotl64(r21.u32 | (r21.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r17,r14
	r17.u64 = r14.u64;
loc_831A2A2C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r15,40
	ctx.r10.s64 = r15.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwzx r11,r17,r10
	r11.u64 = PPC_LOAD_U32(r17.u32 + ctx.r10.u32);
	// rlwinm. r9,r11,0,5,5
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831a2c8c
	if (cr0.eq) goto loc_831A2C8C;
	// rlwinm r23,r11,5,28,31
	r23.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0xF;
	// mr r11,r18
	r11.u64 = r18.u64;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x831a2a84
	if (cr6.eq) goto loc_831A2A84;
	// add r10,r14,r10
	ctx.r10.u64 = r14.u64 + ctx.r10.u64;
loc_831A2A5C:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,5,28,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xF;
	// cmplw cr6,r9,r23
	cr6.compare<uint32_t>(ctx.r9.u32, r23.u32, xer);
	// beq cr6,0x831a2a7c
	if (cr6.eq) goto loc_831A2A7C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// blt cr6,0x831a2a5c
	if (cr6.lt) goto loc_831A2A5C;
loc_831A2A7C:
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// blt cr6,0x831a2c44
	if (cr6.lt) goto loc_831A2C44;
loc_831A2A84:
	// addi r11,r1,132
	r11.s64 = ctx.r1.s64 + 132;
	// stw r18,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r18.u32);
	// mr r26,r18
	r26.u64 = r18.u64;
	// mr r27,r18
	r27.u64 = r18.u64;
	// mr r24,r22
	r24.u64 = r22.u64;
	// cmplw cr6,r22,r19
	cr6.compare<uint32_t>(r22.u32, r19.u32, xer);
	// stw r18,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r18.u32);
	// stw r18,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r18.u32);
	// stw r18,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r18.u32);
	// bge cr6,0x831a2cc0
	if (!cr6.lt) goto loc_831A2CC0;
	// addi r30,r1,128
	r30.s64 = ctx.r1.s64 + 128;
	// mr r25,r17
	r25.u64 = r17.u64;
loc_831A2AB4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r15,40
	ctx.r10.s64 = r15.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwzx r11,r11,r25
	r11.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// rlwinm r11,r11,5,28,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0xF;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// bne cr6,0x831a2b38
	if (!cr6.eq) goto loc_831A2B38;
	// cmplwi cr6,r26,4
	cr6.compare<uint32_t>(r26.u32, 4, xer);
	// beq cr6,0x831a2ca8
	if (cr6.eq) goto loc_831A2CA8;
	// lwz r11,28(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 28);
	// add r4,r24,r21
	ctx.r4.u64 = r24.u64 + r21.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// lwz r29,116(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r28,120(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
	// or r27,r11,r27
	r27.u64 = r11.u64 | r27.u64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// stw r28,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r28.u32);
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// lwz r29,100(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// lwz r28,332(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
loc_831A2B38:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r25,r25,8
	r25.s64 = r25.s64 + 8;
	// cmplw cr6,r24,r19
	cr6.compare<uint32_t>(r24.u32, r19.u32, xer);
	// blt cr6,0x831a2ab4
	if (cr6.lt) goto loc_831A2AB4;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831a2cc0
	if (cr6.eq) goto loc_831A2CC0;
	// li r11,1
	r11.s64 = 1;
	// slw r11,r11,r26
	r11.u64 = r26.u8 & 0x20 ? 0 : (r11.u32 << (r26.u8 & 0x3F));
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// bne cr6,0x831a2cc0
	if (!cr6.eq) goto loc_831A2CC0;
	// lwz r11,4(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 4);
	// rlwinm. r30,r11,2,31,31
	r30.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x831a2be0
	if (!cr0.eq) goto loc_831A2BE0;
	// lwz r4,16(r16)
	ctx.r4.u64 = PPC_LOAD_U32(r16.u32 + 16);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831a2be0
	if (cr6.eq) goto loc_831A2BE0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x8319fdc0
	sub_8319FDC0(ctx, base);
	// b 0x831a2bb8
	goto loc_831A2BB8;
loc_831A2B8C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831a2cb4
	if (cr6.eq) goto loc_831A2CB4;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831a2cb4
	if (!cr6.eq) goto loc_831A2CB4;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83195b00
	sub_83195B00(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bne cr6,0x831a2bb8
	if (!cr6.eq) goto loc_831A2BB8;
	// li r30,1
	r30.s64 = 1;
loc_831A2BB8:
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831a2b8c
	if (!cr0.eq) goto loc_831A2B8C;
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r9,108(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// addi r10,r11,972
	ctx.r10.s64 = r11.s64 + 972;
	// lwz r10,976(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 976);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// stw r9,976(r11)
	PPC_STORE_U32(r11.u32 + 976, ctx.r9.u32);
loc_831A2BE0:
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319aff0
	sub_8319AFF0(ctx, base);
	// lwz r4,128(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r26,1
	cr6.compare<uint32_t>(r26.u32, 1, xer);
	// ble cr6,0x831a2c30
	if (!cr6.gt) goto loc_831A2C30;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r10,140(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r8,136(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,132(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r18,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r18.u32);
	// bl 0x83196b38
	sub_83196B38(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831A2C30:
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r6,356(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cfba8
	sub_831CFBA8(ctx, base);
loc_831A2C44:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// addi r17,r17,8
	r17.s64 = r17.s64 + 8;
	// cmplw cr6,r22,r19
	cr6.compare<uint32_t>(r22.u32, r19.u32, xer);
	// blt cr6,0x831a2a2c
	if (cr6.lt) goto loc_831A2A2C;
loc_831A2C54:
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// add r21,r19,r21
	r21.u64 = r19.u64 + r21.u64;
	// stw r18,4(r16)
	PPC_STORE_U32(r16.u32 + 4, r18.u32);
	// subf. r11,r19,r11
	r11.s64 = r11.s64 - r19.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// bne 0x831a29e4
	if (!cr0.eq) goto loc_831A29E4;
loc_831A2C6C:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8319a750
	sub_8319A750(ctx, base);
	// addi r11,r31,972
	r11.s64 = r31.s64 + 972;
	// lwz r11,1004(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1004);
	// stw r11,0(r16)
	PPC_STORE_U32(r16.u32 + 0, r11.u32);
	// stw r16,1004(r31)
	PPC_STORE_U32(r31.u32 + 1004, r16.u32);
loc_831A2C84:
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82ca2c00
	return;
loc_831A2C8C:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194f88
	sub_83194F88(ctx, base);
	// lwz r5,24(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// li r4,4503
	ctx.r4.s64 = 4503;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2CA8:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2CB4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2CC0:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2CCC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r15,40
	ctx.r10.s64 = r15.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x831a2cf4
	if (!cr6.eq) goto loc_831A2CF4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r28,r11,3196
	r28.s64 = r11.s64 + 3196;
	// b 0x831a2d60
	goto loc_831A2D60;
loc_831A2CF4:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// addi r4,r11,3172
	ctx.r4.s64 = r11.s64 + 3172;
	// li r5,22
	ctx.r5.s64 = 22;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831959b0
	sub_831959B0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_831A2D1C:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831a2d1c
	if (!cr6.eq) goto loc_831A2D1C;
	// subf r11,r29,r11
	r11.s64 = r11.s64 - r29.s64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// addi r30,r11,22
	r30.s64 = r11.s64 + 22;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83110928
	sub_83110928(ctx, base);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
loc_831A2D60:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ae8
	sub_83194AE8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,3503
	ctx.r4.s64 = 3503;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831A2920) {
	__imp__sub_831A2920(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A2D80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,44(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 44);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a2e28
	if (cr6.eq) goto loc_831A2E28;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831a2e28
	if (cr6.eq) goto loc_831A2E28;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2DB8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x831a2e10
	if (!cr6.eq) goto loc_831A2E10;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a2e3c
	if (cr6.eq) goto loc_831A2E3C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,11
	cr6.compare<int32_t>(ctx.r10.s32, 11, xer);
	// bne cr6,0x831a2e3c
	if (!cr6.eq) goto loc_831A2E3C;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a2e10
	if (cr6.eq) goto loc_831A2E10;
	// lwz r10,44(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a2e10
	if (cr0.eq) goto loc_831A2E10;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// lwz r6,60(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831a2920
	sub_831A2920(ctx, base);
loc_831A2E10:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a2e28
	if (cr6.eq) goto loc_831A2E28;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a2e48
	if (!cr6.eq) goto loc_831A2E48;
loc_831A2E28:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r31,r11
	r31.u64 = r11.u64;
	// bne cr6,0x831a2db8
	if (!cr6.eq) goto loc_831A2DB8;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_831A2E3C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A2E48:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831A2D80) {
	__imp__sub_831A2D80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A2E58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a2ea0
	if (!cr0.eq) goto loc_831A2EA0;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r30,r11,-40
	xer.ca = r11.u32 > 39;
	r30.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x831a2ea0
	if (cr0.eq) goto loc_831A2EA0;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,10624
	cr6.compare<uint32_t>(r11.u32, 10624, xer);
	// beq cr6,0x831a2f2c
	if (cr6.eq) goto loc_831A2F2C;
loc_831A2EA0:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a2ecc
	if (cr0.eq) goto loc_831A2ECC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
loc_831A2ECC:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// li r6,83
	ctx.r6.s64 = 83;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a2f18
	if (cr6.eq) goto loc_831A2F18;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,56(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x831a2920
	sub_831A2920(ctx, base);
loc_831A2F18:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// lwz r4,4(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2d80
	sub_831A2D80(ctx, base);
loc_831A2F2C:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196828
	sub_83196828(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_831A2E58) {
	__imp__sub_831A2E58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A2F48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc8
	// stfd f29,-128(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -128, f29.u64);
	// stfd f30,-120(r1)
	PPC_STORE_U64(ctx.r1.u32 + -120, f30.u64);
	// stfd f31,-112(r1)
	PPC_STORE_U64(ctx.r1.u32 + -112, f31.u64);
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x831385c0
	sub_831385C0(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// li r23,1
	r23.s64 = 1;
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831a3670
	if (cr6.eq) goto loc_831A3670;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// li r22,2
	r22.s64 = 2;
	// lfs f29,3080(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	f29.f64 = double(temp.f32);
	// lfd f30,3376(r10)
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3376);
	// lfs f31,3084(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 3084);
	f31.f64 = double(temp.f32);
loc_831A2FA8:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x831a0430
	sub_831A0430(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// blt cr6,0x831a3560
	if (cr6.lt) goto loc_831A3560;
	// cmplwi cr6,r28,14
	cr6.compare<uint32_t>(r28.u32, 14, xer);
	// bge cr6,0x831a36a8
	if (!cr6.lt) goto loc_831A36A8;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,168
	ctx.r3.s64 = ctx.r1.s64 + 168;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,168
	ctx.r3.s64 = ctx.r1.s64 + 168;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,168
	ctx.r3.s64 = ctx.r1.s64 + 168;
	// lwz r27,172(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lwz r20,176(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r30,0
	r30.s64 = 0;
	// lwz r11,172(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// li r29,0
	r29.s64 = 0;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// stw r27,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, r27.u32);
	// stw r20,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r20.u32);
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r27,r10,r11
	r27.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// clrlwi. r10,r11,30
	ctx.r10.u64 = r11.u32 & 0x3;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a302c
	if (!cr0.eq) goto loc_831A302C;
	// rlwinm r4,r11,15,17,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x7FFF;
	// rlwinm r29,r11,30,18,31
	r29.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFF;
	// b 0x831a30b4
	goto loc_831A30B4;
loc_831A302C:
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a3200
	if (!cr6.eq) goto loc_831A3200;
	// lwz r30,0(r27)
	r30.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r10,r10,25,25,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r10,124
	cr6.compare<uint32_t>(ctx.r10.u32, 124, xer);
	// bne cr6,0x831a3088
	if (!cr6.eq) goto loc_831A3088;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-8
	r11.s64 = r30.s64 + -8;
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// rlwinm r11,r11,3,30,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0x3;
	// addi r10,r11,-2
	ctx.r10.s64 = r11.s64 + -2;
	// subfc r11,r22,r11
	xer.ca = r11.u32 >= r22.u32;
	r11.s64 = r11.s64 - r22.s64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// rlwinm r29,r10,27,31,31
	r29.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
	// b 0x831a3200
	goto loc_831A3200;
loc_831A3088:
	// cmplwi cr6,r10,112
	cr6.compare<uint32_t>(ctx.r10.u32, 112, xer);
	// bne cr6,0x831a318c
	if (!cr6.eq) goto loc_831A318C;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,112
	ctx.r4.s64 = 112;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-8
	r11.s64 = r30.s64 + -8;
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// clrlwi r4,r11,17
	ctx.r4.u64 = r11.u32 & 0x7FFF;
	// rlwinm r29,r11,17,18,31
	r29.u64 = rotl64(r11.u32 | (r11.u64 << 32), 17) & 0x3FFF;
loc_831A30B4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r30,r4,40
	r30.s64 = ctx.r4.s64 * 40;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r10,r10,29
	ctx.r10.u64 = ctx.r10.u32 & 0x7;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x831a3118
	if (!cr6.eq) goto loc_831A3118;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a30e4
	if (!cr6.eq) goto loc_831A30E4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831387b8
	sub_831387B8(ctx, base);
loc_831A30E4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r10,r29,3,0,28
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,14,30,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 14) & 0x3;
	// subfc r10,r22,r11
	xer.ca = r11.u32 >= r22.u32;
	ctx.r10.s64 = r11.s64 - r22.s64;
	// subf r9,r22,r11
	ctx.r9.s64 = r11.s64 - r22.s64;
	// subfe r11,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + xer.ca < xer.ca);
	r11.u64 = ~ctx.r10.u64 + ctx.r10.u64 + xer.ca;
	xer.ca = temp.u8;
	// cntlzw r10,r9
	ctx.r10.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
	// rlwinm r29,r10,27,31,31
	r29.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// b 0x831a3200
	goto loc_831A3200;
loc_831A3118:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831385c0
	sub_831385C0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_831A3130:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831a0430
	sub_831A0430(ctx, base);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// bne cr6,0x831a3130
	if (!cr6.eq) goto loc_831A3130;
	// lwz r10,1004(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1004);
	// addi r11,r31,972
	r11.s64 = r31.s64 + 972;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// stw r30,1004(r31)
	PPC_STORE_U32(r31.u32 + 1004, r30.u32);
	// ble cr6,0x831a3168
	if (!cr6.gt) goto loc_831A3168;
	// cmpwi cr6,r3,9
	cr6.compare<int32_t>(ctx.r3.s32, 9, xer);
	// mr r30,r23
	r30.u64 = r23.u64;
	// ble cr6,0x831a316c
	if (!cr6.gt) goto loc_831A316C;
loc_831A3168:
	// li r30,0
	r30.s64 = 0;
loc_831A316C:
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// blt cr6,0x831a3184
	if (cr6.lt) goto loc_831A3184;
	// cmpwi cr6,r3,5
	cr6.compare<int32_t>(ctx.r3.s32, 5, xer);
	// bgt cr6,0x831a3184
	if (cr6.gt) goto loc_831A3184;
	// mr r29,r23
	r29.u64 = r23.u64;
	// b 0x831a3200
	goto loc_831A3200;
loc_831A3184:
	// li r29,0
	r29.s64 = 0;
	// b 0x831a3200
	goto loc_831A3200;
loc_831A318C:
	// cmplwi cr6,r10,125
	cr6.compare<uint32_t>(ctx.r10.u32, 125, xer);
	// bne cr6,0x831a31e8
	if (!cr6.eq) goto loc_831A31E8;
	// rlwinm r10,r30,0,0,19
	ctx.r10.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFF000;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r10,148(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 148);
	// lwz r10,40(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// not r10,r10
	ctx.r10.u64 = ~ctx.r10.u64;
	// rlwinm. r10,r10,18,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a31b8
	if (!cr0.eq) goto loc_831A31B8;
	// li r11,0
	r11.s64 = 0;
	// b 0x831a31cc
	goto loc_831A31CC;
loc_831A31B8:
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r11,r11,31,17,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFE;
	// rlwinm r10,r10,30,24,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0xFF;
	// srw r11,r10,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (r11.u8 & 0x3F));
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
loc_831A31CC:
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subf r11,r23,r11
	r11.s64 = r11.s64 - r23.s64;
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// xori r30,r10,1
	r30.u64 = ctx.r10.u64 ^ 1;
	// rlwinm r29,r11,27,31,31
	r29.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x831a3200
	goto loc_831A3200;
loc_831A31E8:
	// lhz r10,14(r30)
	ctx.r10.u64 = PPC_LOAD_U16(r30.u32 + 14);
	// rlwinm r11,r11,0,16,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFC;
	// srw r11,r10,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (r11.u8 & 0x3F));
	// not r10,r11
	ctx.r10.u64 = ~r11.u64;
	// rlwinm r30,r11,30,31,31
	r30.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	// rlwinm r29,r10,31,31,31
	r29.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
loc_831A3200:
	// cmpwi cr6,r28,10
	cr6.compare<int32_t>(r28.s32, 10, xer);
	// mr r11,r23
	r11.u64 = r23.u64;
	// blt cr6,0x831a3210
	if (cr6.lt) goto loc_831A3210;
	// li r11,0
	r11.s64 = 0;
loc_831A3210:
	// clrlwi r10,r11,24
	ctx.r10.u64 = r11.u32 & 0xFF;
	// cmpwi cr6,r28,6
	cr6.compare<int32_t>(r28.s32, 6, xer);
	// mr r11,r23
	r11.u64 = r23.u64;
	// blt cr6,0x831a3224
	if (cr6.lt) goto loc_831A3224;
	// li r11,0
	r11.s64 = 0;
loc_831A3224:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// clrlwi r28,r11,24
	r28.u64 = r11.u32 & 0xFF;
	// beq 0x831a3444
	if (cr0.eq) goto loc_831A3444;
	// clrlwi. r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a33d4
	if (!cr0.eq) goto loc_831A33D4;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83195ce8
	sub_83195CE8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// beq 0x831a3294
	if (cr0.eq) goto loc_831A3294;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// clrlwi. r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a3278
	if (cr0.eq) goto loc_831A3278;
	// fctiwz f0,f0
	f0.u64 = uint64_t(int32_t(std::trunc(f0.f64)));
	// stfd f0,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, f0.u64);
	// lwz r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// b 0x831a328c
	goto loc_831A328C;
loc_831A3278:
	// fctidz f0,f0
	ctx.fpscr.disableFlushMode();
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f0,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, f0.u64);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// lwz r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
loc_831A328C:
	// bl 0x831d3eb8
	sub_831D3EB8(ctx, base);
	// b 0x831a3488
	goto loc_831A3488;
loc_831A3294:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x831d3eb8
	sub_831D3EB8(ctx, base);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x831d3eb8
	sub_831D3EB8(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// ld r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// bl 0x8319d540
	sub_8319D540(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c158
	sub_8319C158(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c078
	sub_8319C078(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r6,88(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// ld r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// bl 0x8319d350
	sub_8319D350(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,103
	ctx.r6.s64 = 103;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// clrlwi r28,r28,24
	r28.u64 = r28.u32 & 0xFF;
	// li r6,0
	ctx.r6.s64 = 0;
	// cntlzw r11,r28
	r11.u64 = r28.u32 == 0 ? 32 : __builtin_clz(r28.u32);
	// li r4,103
	ctx.r4.s64 = 103;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r5,r10,13,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 13) & 0x7;
	// addi r20,r11,4
	r20.s64 = r11.s64 + 4;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-4
	r11.s64 = r30.s64 + -4;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// stwx r20,r3,r11
	PPC_STORE_U32(ctx.r3.u32 + r11.u32, r20.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
loc_831A33C0:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// b 0x831a350c
	goto loc_831A350C;
loc_831A33D4:
	// clrlwi r28,r28,24
	r28.u64 = r28.u32 & 0xFF;
	// clrlwi r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// beq cr6,0x831a3664
	if (cr6.eq) goto loc_831A3664;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,103
	ctx.r6.s64 = 103;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cntlzw r11,r28
	r11.u64 = r28.u32 == 0 ? 32 : __builtin_clz(r28.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r4,103
	ctx.r4.s64 = 103;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r5,r10,13,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 13) & 0x7;
	// addi r29,r11,2
	r29.s64 = r11.s64 + 2;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-4
	r11.s64 = r30.s64 + -4;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// stwx r29,r3,r11
	PPC_STORE_U32(ctx.r3.u32 + r11.u32, r29.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// b 0x831a33c0
	goto loc_831A33C0;
loc_831A3444:
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83195ce8
	sub_83195CE8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a349c
	if (cr0.eq) goto loc_831A349C;
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bne cr6,0x831a349c
	if (!cr6.eq) goto loc_831A349C;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
loc_831A3488:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r11.u32);
	// b 0x831a3664
	goto loc_831A3664;
loc_831A349C:
	// clrlwi. r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a3664
	if (cr0.eq) goto loc_831A3664;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,103
	ctx.r6.s64 = 103;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// clrlwi r29,r29,24
	r29.u64 = r29.u32 & 0xFF;
	// li r6,0
	ctx.r6.s64 = 0;
	// cntlzw r11,r29
	r11.u64 = r29.u32 == 0 ? 32 : __builtin_clz(r29.u32);
	// li r4,103
	ctx.r4.s64 = 103;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r28,r11,27,31,31
	r28.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// rlwinm r5,r10,13,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 13) & 0x7;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-4
	r11.s64 = r30.s64 + -4;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// stwx r28,r3,r11
	PPC_STORE_U32(ctx.r3.u32 + r11.u32, r28.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
loc_831A350C:
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// beq cr6,0x831a352c
	if (cr6.eq) goto loc_831A352C;
	// andi. r10,r11,17476
	ctx.r10.u64 = r11.u64 & 17476;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,17476
	cr6.compare<uint32_t>(ctx.r10.u32, 17476, xer);
	// beq cr6,0x831a3540
	if (cr6.eq) goto loc_831A3540;
	// ori r11,r11,17476
	r11.u64 = r11.u64 | 17476;
	// b 0x831a353c
	goto loc_831A353C;
loc_831A352C:
	// andi. r10,r11,26214
	ctx.r10.u64 = r11.u64 & 26214;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi cr6,r10,26214
	cr6.compare<uint32_t>(ctx.r10.u32, 26214, xer);
	// beq cr6,0x831a3540
	if (cr6.eq) goto loc_831A3540;
	// ori r11,r11,26214
	r11.u64 = r11.u64 | 26214;
loc_831A353C:
	// sth r11,14(r30)
	PPC_STORE_U16(r30.u32 + 14, r11.u16);
loc_831A3540:
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// stw r30,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r30.u32);
	// rlwimi r11,r23,0,16,14
	r11.u64 = (rotl32(r23.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// stw r11,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r11.u32);
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// b 0x831a3664
	goto loc_831A3664;
loc_831A3560:
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,184
	ctx.r3.s64 = ctx.r1.s64 + 184;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,184
	ctx.r3.s64 = ctx.r1.s64 + 184;
	// bl 0x8319a958
	sub_8319A958(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,184
	ctx.r3.s64 = ctx.r1.s64 + 184;
	// lwz r30,188(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r29,192(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// lwz r10,192(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// lwz r11,188(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// stw r30,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, r30.u32);
	// stw r29,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r29.u32);
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r30,r10,r11
	r30.u64 = ctx.r10.u64 + r11.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83195ce8
	sub_83195CE8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a360c
	if (cr0.eq) goto loc_831A360C;
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// beq cr6,0x831a35d4
	if (cr6.eq) goto loc_831A35D4;
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// b 0x831a35d8
	goto loc_831A35D8;
loc_831A35D4:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
loc_831A35D8:
	// fcmpu cr6,f0,f1
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f1.f64);
	// beq cr6,0x831a3664
	if (cr6.eq) goto loc_831A3664;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// b 0x831a3660
	goto loc_831A3660;
loc_831A360C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// ld r5,128(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c948
	sub_8319C948(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// rlwimi r11,r23,0,16,14
	r11.u64 = (rotl32(r23.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
loc_831A3660:
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_831A3664:
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// cmplw cr6,r25,r26
	cr6.compare<uint32_t>(r25.u32, r26.u32, xer);
	// blt cr6,0x831a2fa8
	if (cr6.lt) goto loc_831A2FA8;
loc_831A3670:
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a3690
	if (!cr6.eq) goto loc_831A3690;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x831a03d8
	sub_831A03D8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r23
	r11.u64 = r23.u64;
	// beq 0x831a3694
	if (cr0.eq) goto loc_831A3694;
loc_831A3690:
	// li r11,0
	r11.s64 = 0;
loc_831A3694:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a36b4
	if (!cr0.eq) goto loc_831A36B4;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A36A8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A36B4:
	// lwz r10,1004(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1004);
	// addi r11,r31,972
	r11.s64 = r31.s64 + 972;
	// stw r10,0(r21)
	PPC_STORE_U32(r21.u32 + 0, ctx.r10.u32);
	// stw r21,1004(r31)
	PPC_STORE_U32(r31.u32 + 1004, r21.u32);
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// lfd f29,-128(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -128);
	// lfd f30,-120(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// lfd f31,-112(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// b 0x82ca2c18
	return;
}

PPC_WEAK_FUNC(sub_831A2F48) {
	__imp__sub_831A2F48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A36D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// bl 0x831385c0
	sub_831385C0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_831A3708:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a3728
	if (!cr6.eq) goto loc_831A3728;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831a03d8
	sub_831A03D8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x831a372c
	if (cr0.eq) goto loc_831A372C;
loc_831A3728:
	// li r11,0
	r11.s64 = 0;
loc_831A372C:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a37a0
	if (!cr0.eq) goto loc_831A37A0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831a0430
	sub_831A0430(ctx, base);
	// cmpwi cr6,r3,33
	cr6.compare<int32_t>(ctx.r3.s32, 33, xer);
	// beq cr6,0x831a3778
	if (cr6.eq) goto loc_831A3778;
	// ble cr6,0x831a3750
	if (!cr6.gt) goto loc_831A3750;
	// cmpwi cr6,r3,37
	cr6.compare<int32_t>(ctx.r3.s32, 37, xer);
	// ble cr6,0x831a3784
	if (!cr6.gt) goto loc_831A3784;
loc_831A3750:
	// lwz r6,16(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x831a3794
	if (cr6.eq) goto loc_831A3794;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2788
	sub_831A2788(ctx, base);
	// b 0x831a3794
	goto loc_831A3794;
loc_831A3778:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
loc_831A3784:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// li r10,3
	ctx.r10.s64 = 3;
	// rlwimi r11,r10,4,25,27
	r11.u64 = (rotl32(ctx.r10.u32, 4) & 0x70) | (r11.u64 & 0xFFFFFFFFFFFFFF8F);
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
loc_831A3794:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// b 0x831a3708
	goto loc_831A3708;
loc_831A37A0:
	// lwz r10,1004(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1004);
	// addi r11,r31,972
	r11.s64 = r31.s64 + 972;
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// stw r30,1004(r31)
	PPC_STORE_U32(r31.u32 + 1004, r30.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_831A36D8) {
	__imp__sub_831A36D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A37B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,40(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 40);
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a3960
	if (cr6.eq) goto loc_831A3960;
	// lwz r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x831a37f4
	if (cr6.lt) goto loc_831A37F4;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A37F4:
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a3814
	if (cr0.eq) goto loc_831A3814;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A3814:
	// lwz r9,20(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// cmplwi cr6,r9,16383
	cr6.compare<uint32_t>(ctx.r9.u32, 16383, xer);
	// ble cr6,0x831a3828
	if (!cr6.gt) goto loc_831A3828;
	// li r4,3519
	ctx.r4.s64 = 3519;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A3828:
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// li r31,0
	r31.s64 = 0;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// li r5,32
	ctx.r5.s64 = 32;
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// lwzx r7,r11,r10
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwimi r7,r9,3,15,28
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 3) & 0x1FFF8) | (ctx.r7.u64 & 0xFFFFFFFFFFFE0007);
	// li r9,1
	ctx.r9.s64 = 1;
	// stwx r7,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r7.u32);
	// li r7,2
	ctx.r7.s64 = 2;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwimi r30,r8,0,29,31
	r30.u64 = (rotl32(ctx.r8.u32, 0) & 0x7) | (r30.u64 & 0xFFFFFFFFFFFFFFF8);
	// stwx r30,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r30.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r8,40(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 40);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r8,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r8.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r31,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r31.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r6,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r6.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// oris r10,r10,2048
	ctx.r10.u64 = ctx.r10.u64 | 134217728;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,112
	ctx.r10.u64 = ctx.r10.u64 | 112;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwimi r10,r9,20,10,12
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 20) & 0x380000) | (ctx.r10.u64 & 0xFFFFFFFFFFC7FFFF);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r6,40(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 40);
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x831a36d8
	sub_831A36D8(ctx, base);
loc_831A3960:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831A37B8) {
	__imp__sub_831A37B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A3978) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mulli r31,r4,40
	r31.s64 = ctx.r4.s64 * 40;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r4,r31,r11
	ctx.r4.u64 = r31.u64 + r11.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// mr r26,r8
	r26.u64 = ctx.r8.u64;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a39b8
	if (cr0.eq) goto loc_831A39B8;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A39B8:
	// lwz r5,44(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// rlwinm. r11,r5,0,29,29
	r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a39d8
	if (cr0.eq) goto loc_831A39D8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3220
	ctx.r5.s64 = r11.s64 + 3220;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A39D8:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// cmplwi cr6,r11,16383
	cr6.compare<uint32_t>(r11.u32, 16383, xer);
	// ble cr6,0x831a39f0
	if (!cr6.gt) goto loc_831A39F0;
	// li r4,3519
	ctx.r4.s64 = 3519;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A39F0:
	// lwz r6,72(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 72);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x831a3a0c
	if (cr6.eq) goto loc_831A3A0C;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831a2788
	sub_831A2788(ctx, base);
loc_831A3A0C:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwzx r9,r31,r11
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// rlwimi r9,r10,3,15,28
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 3) & 0x1FFF8) | (ctx.r9.u64 & 0xFFFFFFFFFFFE0007);
	// stwx r9,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r9.u32);
	// lwz r10,48(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// stw r29,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r29.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// stw r27,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r27.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// stw r26,32(r11)
	PPC_STORE_U32(r11.u32 + 32, r26.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// oris r10,r10,7
	ctx.r10.u64 = ctx.r10.u64 | 458752;
	// ori r10,r10,65535
	ctx.r10.u64 = ctx.r10.u64 | 65535;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwimi r10,r28,19,10,12
	ctx.r10.u64 = (rotl32(r28.u32, 19) & 0x380000) | (ctx.r10.u64 & 0xFFFFFFFFFFC7FFFF);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,112
	ctx.r10.u64 = ctx.r10.u64 | 112;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r6,48(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x831a3adc
	if (cr6.eq) goto loc_831A3ADC;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,44(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// add r4,r31,r11
	ctx.r4.u64 = r31.u64 + r11.u64;
	// bl 0x831a36d8
	sub_831A36D8(ctx, base);
loc_831A3ADC:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_831A3978) {
	__imp__sub_831A3978(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A3AE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r31,24(r5)
	r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + 24);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831a3c38
	if (cr6.eq) goto loc_831A3C38;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x831a3c38
	if (!cr6.eq) goto loc_831A3C38;
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x831a3c30
	if (cr6.eq) goto loc_831A3C30;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a3c30
	if (cr6.eq) goto loc_831A3C30;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// bl 0x831a3978
	sub_831A3978(ctx, base);
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// lwz r9,12(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// rlwinm. r10,r11,0,30,30
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// add r30,r10,r9
	r30.u64 = ctx.r10.u64 + ctx.r9.u64;
	// beq 0x831a3b80
	if (cr0.eq) goto loc_831A3B80;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r28,1
	r28.s64 = 1;
	// rlwimi r11,r28,1,29,31
	r11.u64 = (rotl32(r28.u32, 1) & 0x7) | (r11.u64 & 0xFFFFFFFFFFFFFFF8);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a3bdc
	if (cr6.eq) goto loc_831A3BDC;
	// b 0x831a3bb0
	goto loc_831A3BB0;
loc_831A3B80:
	// rlwinm. r11,r11,0,24,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a3bc0
	if (cr0.eq) goto loc_831A3BC0;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a3ba0
	if (!cr6.eq) goto loc_831A3BA0;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A3BA0:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r28,1
	r28.s64 = 1;
	// rlwimi r11,r28,1,29,31
	r11.u64 = (rotl32(r28.u32, 1) & 0x7) | (r11.u64 & 0xFFFFFFFFFFFFFFF8);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_831A3BB0:
	// lwz r11,40(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 40);
	// ori r11,r11,32
	r11.u64 = r11.u64 | 32;
	// stw r11,40(r29)
	PPC_STORE_U32(r29.u32 + 40, r11.u32);
	// b 0x831a3bdc
	goto loc_831A3BDC;
loc_831A3BC0:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r28,1
	r28.s64 = 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// rlwimi r11,r28,0,29,31
	r11.u64 = (rotl32(r28.u32, 0) & 0x7) | (r11.u64 & 0xFFFFFFFFFFFFFFF8);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x831387b8
	sub_831387B8(ctx, base);
loc_831A3BDC:
	// lwz r9,596(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 596);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831a3c0c
	if (cr6.eq) goto loc_831A3C0C;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r10,r11,28,29,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x7;
	// cmplwi cr6,r10,7
	cr6.compare<uint32_t>(ctx.r10.u32, 7, xer);
	// beq cr6,0x831a3c00
	if (cr6.eq) goto loc_831A3C00;
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// bne cr6,0x831a3c0c
	if (!cr6.eq) goto loc_831A3C0C;
loc_831A3C00:
	// rlwimi r11,r28,5,25,27
	r11.u64 = (rotl32(r28.u32, 5) & 0x70) | (r11.u64 & 0xFFFFFFFFFFFFFF8F);
	// stw r9,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r9.u32);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_831A3C0C:
	// lwz r11,44(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a3c24
	if (cr0.eq) goto loc_831A3C24;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// oris r11,r11,32768
	r11.u64 = r11.u64 | 2147483648;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_831A3C24:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_831A3C28:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_831A3C30:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831a3c28
	goto loc_831A3C28;
loc_831A3C38:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831A3AE8) {
	__imp__sub_831A3AE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A3C48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r21,r5
	r21.u64 = ctx.r5.u64;
	// mr r19,r6
	r19.u64 = ctx.r6.u64;
	// lwz r20,4(r23)
	r20.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// lwz r11,44(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a401c
	if (cr6.eq) goto loc_831A401C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831a401c
	if (cr6.eq) goto loc_831A401C;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A3C88:
	// lwz r5,8(r22)
	ctx.r5.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x831a4004
	if (!cr6.eq) goto loc_831A4004;
	// lwz r11,16(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a4108
	if (!cr6.eq) goto loc_831A4108;
	// lwz r24,24(r5)
	r24.u64 = PPC_LOAD_U32(ctx.r5.u32 + 24);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831a4138
	if (cr6.eq) goto loc_831A4138;
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x831a4138
	if (!cr6.eq) goto loc_831A4138;
	// lwz r27,16(r24)
	r27.u64 = PPC_LOAD_U32(r24.u32 + 16);
	// lwz r11,16(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// beq cr6,0x831a4004
	if (cr6.eq) goto loc_831A4004;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// beq cr6,0x831a4004
	if (cr6.eq) goto loc_831A4004;
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a4004
	if (cr6.eq) goto loc_831A4004;
	// clrlwi. r30,r19,24
	r30.u64 = r19.u32 & 0xFF;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x831a3d08
	if (!cr0.eq) goto loc_831A3D08;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r27,40
	ctx.r10.s64 = r27.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// oris r10,r10,4096
	ctx.r10.u64 = ctx.r10.u64 | 268435456;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_831A3D08:
	// lwz r11,44(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 44);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm. r10,r11,0,25,25
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a3d40
	if (cr0.eq) goto loc_831A3D40;
	// rlwinm. r11,r11,0,26,26
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a4114
	if (!cr0.eq) goto loc_831A4114;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// bl 0x831a3ae8
	sub_831A3AE8(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r27,40
	ctx.r10.s64 = r27.s64 * 40;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// oris r9,r9,32768
	ctx.r9.u64 = ctx.r9.u64 | 2147483648;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// b 0x831a4004
	goto loc_831A4004;
loc_831A3D40:
	// rlwinm. r11,r11,0,30,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a411c
	if (!cr0.eq) goto loc_831A411C;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x831a3978
	sub_831A3978(ctx, base);
	// lwz r11,44(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 44);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// beq 0x831a3e24
	if (cr0.eq) goto loc_831A3E24;
	// mulli r28,r27,40
	r28.s64 = r27.s64 * 40;
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,0,25,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x70;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x831a412c
	if (cr6.eq) goto loc_831A412C;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r10,1
	ctx.r10.s64 = 1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lwzx r9,r28,r11
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// rlwimi r9,r10,1,29,31
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 1) & 0x7) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFF8);
	// stwx r9,r28,r11
	PPC_STORE_U32(r28.u32 + r11.u32, ctx.r9.u32);
	// beq cr6,0x831a4004
	if (cr6.eq) goto loc_831A4004;
	// lwz r11,44(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 44);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a4004
	if (cr0.eq) goto loc_831A4004;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x83199928
	sub_83199928(ctx, base);
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x831a3e08
	if (!cr6.gt) goto loc_831A3E08;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
loc_831A3DD0:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x831d3808
	sub_831D3808(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
	// addi r29,r29,8
	r29.s64 = r29.s64 + 8;
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x831a3dd0
	if (cr6.lt) goto loc_831A3DD0;
loc_831A3E08:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// b 0x831a4004
	goto loc_831A4004;
loc_831A3E24:
	// mulli r25,r27,40
	r25.s64 = r27.s64 * 40;
	// lwzx r10,r25,r11
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// rlwimi r9,r10,0,0,28
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFF8) | (ctx.r9.u64 & 0xFFFFFFFF00000007);
	// stwx r9,r25,r11
	PPC_STORE_U32(r25.u32 + r11.u32, ctx.r9.u32);
	// beq cr6,0x831a4004
	if (cr6.eq) goto loc_831A4004;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a4004
	if (!cr0.eq) goto loc_831A4004;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x83199928
	sub_83199928(ctx, base);
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// li r29,0
	r29.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x831a4004
	if (!cr6.gt) goto loc_831A4004;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
loc_831A3E74:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x831d3808
	sub_831D3808(ctx, base);
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// std r11,0(r26)
	PPC_STORE_U64(r26.u32 + 0, r11.u64);
	// bl 0x8319b2a8
	sub_8319B2A8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,384
	cr6.compare<uint32_t>(r11.u32, 384, xer);
	// bne cr6,0x831a3eb8
	if (!cr6.eq) goto loc_831A3EB8;
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// lwz r30,12(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_831A3EB8:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,14464
	cr6.compare<uint32_t>(r11.u32, 14464, xer);
	// bne cr6,0x831a3f94
	if (!cr6.eq) goto loc_831A3F94;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x831a3f48
	if (!cr6.eq) goto loc_831A3F48;
	// lwz r8,536(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 536);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x831a3f28
	if (cr6.eq) goto loc_831A3F28;
	// addi r10,r31,348
	ctx.r10.s64 = r31.s64 + 348;
loc_831A3EF0:
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r30,r9
	cr6.compare<uint32_t>(r30.u32, ctx.r9.u32, xer);
	// bne cr6,0x831a3f18
	if (!cr6.eq) goto loc_831A3F18;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r7,r9,0,23,26
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1E0;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x831a3f18
	if (!cr0.eq) goto loc_831A3F18;
	// clrlwi. r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831a3f28
	if (cr0.eq) goto loc_831A3F28;
	// cmplwi cr6,r9,4
	cr6.compare<uint32_t>(ctx.r9.u32, 4, xer);
	// beq cr6,0x831a3f28
	if (cr6.eq) goto loc_831A3F28;
loc_831A3F18:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x831a3ef0
	if (cr6.lt) goto loc_831A3EF0;
loc_831A3F28:
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bge cr6,0x831a3f48
	if (!cr6.lt) goto loc_831A3F48;
	// addi r11,r11,29
	r11.s64 = r11.s64 + 29;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// lwzx r10,r11,r31
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// ori r10,r10,8192
	ctx.r10.u64 = ctx.r10.u64 | 8192;
	// stwx r10,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r10.u32);
	// b 0x831a3f94
	goto loc_831A3F94;
loc_831A3F48:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x831a3f7c
	if (!cr6.eq) goto loc_831A3F7C;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
loc_831A3F7C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
loc_831A3F94:
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r26,r26,8
	r26.s64 = r26.s64 + 8;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x831a3e74
	if (cr6.lt) goto loc_831A3E74;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a4004
	if (cr6.eq) goto loc_831A4004;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r10,r29,0,0,30
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// addi r9,r11,-36
	ctx.r9.s64 = r11.s64 + -36;
	// addi r8,r10,-36
	ctx.r8.s64 = ctx.r10.s64 + -36;
	// ori r7,r9,1
	ctx.r7.u64 = ctx.r9.u64 | 1;
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stw r6,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r6.u32);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stw r7,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r7.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r11,r25,r11
	r11.u64 = r25.u64 + r11.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r9,r10,2
	ctx.r9.u64 = ctx.r10.u64 | 2;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
loc_831A4004:
	// lwz r11,12(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a401c
	if (cr6.eq) goto loc_831A401C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831a4144
	if (!cr6.eq) goto loc_831A4144;
loc_831A401C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r22,r11
	r22.u64 = r11.u64;
	// bne cr6,0x831a3c88
	if (!cr6.eq) goto loc_831A3C88;
	// clrlwi. r11,r19,24
	r11.u64 = r19.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a4100
	if (cr0.eq) goto loc_831A4100;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r29,0
	r29.s64 = 0;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a4100
	if (!cr0.eq) goto loc_831A4100;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831a4100
	if (cr0.eq) goto loc_831A4100;
loc_831A4050:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,12288
	cr6.compare<uint32_t>(r11.u32, 12288, xer);
	// bne cr6,0x831a4080
	if (!cr6.eq) goto loc_831A4080;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a407c
	if (cr6.eq) goto loc_831A407C;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123db0
	sub_83123DB0(ctx, base);
loc_831A407C:
	// mr r29,r30
	r29.u64 = r30.u64;
loc_831A4080:
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r30,40(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a4098
	if (!cr0.eq) goto loc_831A4098;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831a4050
	if (!cr6.eq) goto loc_831A4050;
loc_831A4098:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a4100
	if (cr6.eq) goto loc_831A4100;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x83123db0
	sub_83123DB0(ctx, base);
	// lwz r29,564(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r5,104(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 104);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831a40f0
	if (cr6.eq) goto loc_831A40F0;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83123db0
	sub_83123DB0(ctx, base);
loc_831A40F0:
	// stw r30,104(r29)
	PPC_STORE_U32(r29.u32 + 104, r30.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
loc_831A4100:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	return;
loc_831A4108:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A4114:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A411C:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3240
	ctx.r5.s64 = r11.s64 + 3240;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A412C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A4138:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A4144:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831A3C48) {
	__imp__sub_831A3C48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A4150) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831a417c
	if (cr6.eq) goto loc_831A417C;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A417C:
	// lwz r30,24(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// beq cr6,0x831a426c
	if (cr6.eq) goto loc_831A426C;
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x831a426c
	if (cr6.eq) goto loc_831A426C;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r4,40
	ctx.r10.s64 = ctx.r4.s64 * 40;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a41cc
	if (cr6.eq) goto loc_831A41CC;
	// bl 0x831959b0
	sub_831959B0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,3520
	ctx.r4.s64 = 3520;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A41CC:
	// cmplwi cr6,r8,16383
	cr6.compare<uint32_t>(ctx.r8.u32, 16383, xer);
	// ble cr6,0x831a41dc
	if (!cr6.gt) goto loc_831A41DC;
	// li r4,3519
	ctx.r4.s64 = 3519;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A41DC:
	// li r7,3
	ctx.r7.s64 = 3;
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// bl 0x831a3978
	sub_831A3978(ctx, base);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r9,1
	ctx.r9.s64 = 1;
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwimi r8,r9,1,29,31
	ctx.r8.u64 = (rotl32(ctx.r9.u32, 1) & 0x7) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFF8);
	// stwx r8,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r8.u32);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// oris r10,r10,1024
	ctx.r10.u64 = ctx.r10.u64 | 67108864;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r9,752(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 752);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mulli r11,r11,40
	r11.s64 = r11.s64 * 40;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwimi r9,r10,0,0,12
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFF80000) | (ctx.r9.u64 & 0xFFFFFFFF0007FFFF);
	// stw r9,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r9.u32);
	// lwz r6,52(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 52);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x831a426c
	if (cr6.eq) goto loc_831A426C;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r5,16(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319de30
	sub_8319DE30(ctx, base);
loc_831A426C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_831A4150) {
	__imp__sub_831A4150(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831A4278) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f14{};
	PPCRegister f15{};
	PPCRegister f16{};
	PPCRegister f17{};
	PPCRegister f18{};
	PPCRegister f19{};
	PPCRegister f20{};
	PPCRegister f21{};
	PPCRegister f22{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82ca74d0
	// stwu r1,-3472(r1)
	ea = -3472 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r20,r4
	r20.u64 = ctx.r4.u64;
	// stw r6,3516(r1)
	PPC_STORE_U32(ctx.r1.u32 + 3516, ctx.r6.u32);
	// mr r14,r5
	r14.u64 = ctx.r5.u64;
	// li r19,0
	r19.s64 = 0;
	// stw r20,3500(r1)
	PPC_STORE_U32(ctx.r1.u32 + 3500, r20.u32);
	// li r5,43
	ctx.r5.s64 = 43;
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r19,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r19.u32);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r22,r19
	r22.u64 = r19.u64;
	// addi r11,r26,4
	r11.s64 = r26.s64 + 4;
	// stw r26,440(r1)
	PPC_STORE_U32(ctx.r1.u32 + 440, r26.u32);
	// ori r10,r26,1
	ctx.r10.u64 = r26.u64 | 1;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r10,4(r26)
	PPC_STORE_U32(r26.u32 + 4, ctx.r10.u32);
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// bne cr6,0x831a42e8
	if (!cr6.eq) goto loc_831A42E8;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A42E8:
	// lis r11,-32252
	r11.s64 = -2113667072;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r9,-32248
	ctx.r9.s64 = -2113404928;
	// lis r8,-32240
	ctx.r8.s64 = -2112880640;
	// lis r7,-32240
	ctx.r7.s64 = -2112880640;
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lfs f0,-16948(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -16948);
	f0.f64 = double(temp.f32);
	// lfd f13,3384(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3384);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,3784(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 3784);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,476(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 476);
	ctx.f11.f64 = double(temp.f32);
	// lis r9,-32240
	ctx.r9.s64 = -2112880640;
	// lfs f14,512(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 512);
	f14.f64 = double(temp.f32);
	// lis r8,-32248
	ctx.r8.s64 = -2113404928;
	// lfd f10,3376(r6)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r6.u32 + 3376);
	// lis r7,-32248
	ctx.r7.s64 = -2113404928;
	// lis r6,-32248
	ctx.r6.s64 = -2113404928;
	// lfs f15,3056(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3056);
	f15.f64 = double(temp.f32);
	// lfd f27,3552(r10)
	f27.u64 = PPC_LOAD_U64(ctx.r10.u32 + 3552);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lfs f21,2376(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2376);
	f21.f64 = double(temp.f32);
	// lfs f22,3780(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 3780);
	f22.f64 = double(temp.f32);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lfs f23,3776(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 3776);
	f23.f64 = double(temp.f32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f24,3772(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 3772);
	f24.f64 = double(temp.f32);
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// lis r6,-32248
	ctx.r6.s64 = -2113404928;
	// lfs f25,3768(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3768);
	f25.f64 = double(temp.f32);
	// lis r5,-32248
	ctx.r5.s64 = -2113404928;
	// lfs f26,3764(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3764);
	f26.f64 = double(temp.f32);
	// lis r11,-31952
	r11.s64 = -2094006272;
	// lfs f28,26876(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 26876);
	f28.f64 = double(temp.f32);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// lfs f16,2876(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2876);
	f16.f64 = double(temp.f32);
	// lfs f29,3168(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 3168);
	f29.f64 = double(temp.f32);
	// addi r11,r11,14120
	r11.s64 = r11.s64 + 14120;
	// lfs f17,3760(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 3760);
	f17.f64 = double(temp.f32);
	// addi r10,r10,-328
	ctx.r10.s64 = ctx.r10.s64 + -328;
	// lfs f18,3756(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 3756);
	f18.f64 = double(temp.f32);
	// lis r4,-32248
	ctx.r4.s64 = -2113404928;
	// lis r3,-32248
	ctx.r3.s64 = -2113404928;
	// stw r11,532(r1)
	PPC_STORE_U32(ctx.r1.u32 + 532, r11.u32);
	// lis r30,-32256
	r30.s64 = -2113929216;
	// stw r10,584(r1)
	PPC_STORE_U32(ctx.r1.u32 + 584, ctx.r10.u32);
	// lis r29,-32256
	r29.s64 = -2113929216;
	// stfs f0,456(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lis r9,-32240
	ctx.r9.s64 = -2112880640;
	// stfd f13,1320(r1)
	PPC_STORE_U64(ctx.r1.u32 + 1320, ctx.f13.u64);
	// lis r8,-32240
	ctx.r8.s64 = -2112880640;
	// lfs f19,3752(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 3752);
	f19.f64 = double(temp.f32);
	// lis r7,-32240
	ctx.r7.s64 = -2112880640;
	// lfs f20,3748(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 3748);
	f20.f64 = double(temp.f32);
	// lis r6,-32240
	ctx.r6.s64 = -2112880640;
	// lfs f30,3080(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 3080);
	f30.f64 = double(temp.f32);
	// lis r5,-32243
	ctx.r5.s64 = -2113077248;
	// lfs f31,3084(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 3084);
	f31.f64 = double(temp.f32);
	// addi r9,r9,-344
	ctx.r9.s64 = ctx.r9.s64 + -344;
	// stfs f12,608(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// addi r8,r8,-3372
	ctx.r8.s64 = ctx.r8.s64 + -3372;
	// stfs f11,600(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// addi r7,r7,-3364
	ctx.r7.s64 = ctx.r7.s64 + -3364;
	// stfs f14,624(r1)
	temp.f32 = float(f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 624, temp.u32);
	// addi r11,r6,-3356
	r11.s64 = ctx.r6.s64 + -3356;
	// stfd f10,1264(r1)
	PPC_STORE_U64(ctx.r1.u32 + 1264, ctx.f10.u64);
	// addi r10,r5,-25032
	ctx.r10.s64 = ctx.r5.s64 + -25032;
	// stw r9,568(r1)
	PPC_STORE_U32(ctx.r1.u32 + 568, ctx.r9.u32);
	// stw r8,528(r1)
	PPC_STORE_U32(ctx.r1.u32 + 528, ctx.r8.u32);
	// stw r7,512(r1)
	PPC_STORE_U32(ctx.r1.u32 + 512, ctx.r7.u32);
	// stw r11,496(r1)
	PPC_STORE_U32(ctx.r1.u32 + 496, r11.u32);
	// stw r10,480(r1)
	PPC_STORE_U32(ctx.r1.u32 + 480, ctx.r10.u32);
loc_831A440C:
	// li r21,1
	r21.s64 = 1;
loc_831A4410:
	// lwz r11,4(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831a512c
	if (cr6.eq) goto loc_831A512C;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x831a5118
	if (cr6.eq) goto loc_831A5118;
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// beq cr6,0x831a50d4
	if (cr6.eq) goto loc_831A50D4;
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x831a4b04
	if (cr6.eq) goto loc_831A4B04;
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// beq cr6,0x831a49cc
	if (cr6.eq) goto loc_831A49CC;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// beq cr6,0x831a4954
	if (cr6.eq) goto loc_831A4954;
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x831a4454
	if (cr6.eq) goto loc_831A4454;
	// b 0x831acdf8
	goto loc_831ACDF8;
loc_831A4454:
	// addi r5,r1,424
	ctx.r5.s64 = ctx.r1.s64 + 424;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// bl 0x83195760
	sub_83195760(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r5,40
	ctx.r10.s64 = ctx.r5.s64 * 40;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// add r30,r10,r11
	r30.u64 = ctx.r10.u64 + r11.u64;
	// rlwinm r23,r9,29,18,31
	r23.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x3FFF;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a4488
	if (!cr0.eq) goto loc_831A4488;
	// b 0x831ace00
	goto loc_831ACE00;
loc_831A4488:
	// lwz r11,40(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a44c8
	if (!cr6.eq) goto loc_831A44C8;
	// lwz r10,44(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 44);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a44ac
	if (cr6.eq) goto loc_831A44AC;
	// lwz r10,24(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 24);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831a44c8
	if (!cr6.eq) goto loc_831A44C8;
loc_831A44AC:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x831a44fc
	if (!cr6.eq) goto loc_831A44FC;
	// li r4,3020
	ctx.r4.s64 = 3020;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A44C8:
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r10,r10,0,15,15
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a44e8
	if (!cr0.eq) goto loc_831A44E8;
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r10,8
	cr6.compare<int32_t>(ctx.r10.s32, 8, xer);
	// beq cr6,0x831a44e8
	if (cr6.eq) goto loc_831A44E8;
	// b 0x831ace1c
	goto loc_831ACE1C;
loc_831A44E8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a44fc
	if (cr6.eq) goto loc_831A44FC;
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a44fc
	if (cr0.eq) goto loc_831A44FC;
	// b 0x831ace28
	goto loc_831ACE28;
loc_831A44FC:
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// lwz r6,424(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a1878
	sub_831A1878(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r3,r1,168
	ctx.r3.s64 = ctx.r1.s64 + 168;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// lwz r11,40(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a47a8
	if (cr6.eq) goto loc_831A47A8;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a4544
	if (cr0.eq) goto loc_831A4544;
	// b 0x831ace3c
	goto loc_831ACE3C;
loc_831A4544:
	// lwz r4,40(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 40);
	// lwz r11,44(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a465c
	if (!cr6.eq) goto loc_831A465C;
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x831a4564
	if (cr6.eq) goto loc_831A4564;
	// b 0x831ace50
	goto loc_831ACE50;
loc_831A4564:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a457c
	if (cr0.eq) goto loc_831A457C;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r10,r11,6
	ctx.r10.s64 = r11.s64 + 6;
	// b 0x831a4580
	goto loc_831A4580;
loc_831A457C:
	// li r10,720
	ctx.r10.s64 = 720;
loc_831A4580:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r9,80(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831a45a0
	if (cr6.eq) goto loc_831A45A0;
	// rotlwi r11,r9,0
	r11.u64 = rotl32(ctx.r9.u32, 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r10,r11
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x831a45a4
	goto loc_831A45A4;
loc_831A45A0:
	// mr r29,r19
	r29.u64 = r19.u64;
loc_831A45A4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x831a45b0
	if (!cr6.eq) goto loc_831A45B0;
	// b 0x831ace74
	goto loc_831ACE74;
loc_831A45B0:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a45c0
	if (!cr6.eq) goto loc_831A45C0;
	// b 0x831ace74
	goto loc_831ACE74;
loc_831A45C0:
	// rotlwi r28,r11,0
	r28.u64 = rotl32(r11.u32, 0);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r10,28(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x831a46b4
	if (cr6.eq) goto loc_831A46B4;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdf00
	sub_831CDF00(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r11.u32);
	// lwz r5,44(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,48(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r9,r10,-36
	ctx.r9.s64 = ctx.r10.s64 + -36;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// ori r7,r9,1
	ctx.r7.u64 = ctx.r9.u64 | 1;
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// mr r28,r30
	r28.u64 = r30.u64;
	// stw r6,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r6.u32);
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r30,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r30.u32);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwimi r11,r21,0,16,14
	r11.u64 = (rotl32(r21.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
	// b 0x831a46b4
	goto loc_831A46B4;
loc_831A465C:
	// addi r5,r1,604
	ctx.r5.s64 = ctx.r1.s64 + 604;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83195760
	sub_83195760(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// lwz r6,604(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a1878
	sub_831A1878(ctx, base);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// addi r3,r1,1640
	ctx.r3.s64 = ctx.r1.s64 + 1640;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// addi r4,r1,1640
	ctx.r4.s64 = ctx.r1.s64 + 1640;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// bl 0x83197fe0
	sub_83197FE0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
loc_831A46B4:
	// lwz r26,172(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// mr r29,r19
	r29.u64 = r19.u64;
	// lwz r25,176(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831a4794
	if (cr6.eq) goto loc_831A4794;
loc_831A46C8:
	// addi r3,r1,168
	ctx.r3.s64 = ctx.r1.s64 + 168;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,125
	cr6.compare<uint32_t>(r11.u32, 125, xer);
	// beq cr6,0x831a4704
	if (cr6.eq) goto loc_831A4704;
	// cmplwi cr6,r11,124
	cr6.compare<uint32_t>(r11.u32, 124, xer);
	// mr r11,r19
	r11.u64 = r19.u64;
	// bne cr6,0x831a4708
	if (!cr6.eq) goto loc_831A4708;
loc_831A4704:
	// mr r11,r21
	r11.u64 = r21.u64;
loc_831A4708:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne 0x831a4718
	if (!cr0.eq) goto loc_831A4718;
	// b 0x831ace80
	goto loc_831ACE80;
loc_831A4718:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,118
	ctx.r6.s64 = 118;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// rlwimi r11,r21,3,27,31
	r11.u64 = (rotl32(r21.u32, 3) & 0x1F) | (r11.u64 & 0xFFFFFFFFFFFFFFE0);
	// cmplw cr6,r29,r24
	cr6.compare<uint32_t>(r29.u32, r24.u32, xer);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r11,r21,1,16,14
	r11.u64 = (rotl32(r21.u32, 1) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// blt cr6,0x831a46c8
	if (cr6.lt) goto loc_831A46C8;
loc_831A4794:
	// mr r28,r26
	r28.u64 = r26.u64;
	// mr r29,r25
	r29.u64 = r25.u64;
	// stw r28,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, r28.u32);
	// stw r29,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r29.u32);
	// b 0x831a47b0
	goto loc_831A47B0;
loc_831A47A8:
	// lwz r29,176(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r28,172(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
loc_831A47B0:
	// cmplwi cr6,r24,4
	cr6.compare<uint32_t>(r24.u32, 4, xer);
	// bge cr6,0x831a47dc
	if (!cr6.lt) goto loc_831A47DC;
	// addi r11,r29,2
	r11.s64 = r29.s64 + 2;
	// subfic r30,r24,4
	xer.ca = r24.u32 <= 4;
	r30.s64 = 4 - r24.s64;
	// rlwinm r27,r11,3,0,28
	r27.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r24,r30,r24
	r24.u64 = r30.u64 + r24.u64;
loc_831A47C8:
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// ldx r4,r27,r28
	ctx.r4.u64 = PPC_LOAD_U64(r27.u32 + r28.u32);
	// bl 0x8319fd40
	sub_8319FD40(ctx, base);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x831a47c8
	if (!cr0.eq) goto loc_831A47C8;
loc_831A47DC:
	// lwz r11,20(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a47f4
	if (cr6.eq) goto loc_831A47F4;
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a47f4
	if (cr0.eq) goto loc_831A47F4;
	// b 0x831ace90
	goto loc_831ACE90;
loc_831A47F4:
	// mr r30,r19
	r30.u64 = r19.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831a48bc
	if (cr6.eq) goto loc_831A48BC;
loc_831A4800:
	// addi r3,r1,168
	ctx.r3.s64 = ctx.r1.s64 + 168;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r10,20(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// std r9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r9.u64);
	// beq cr6,0x831a48a4
	if (cr6.eq) goto loc_831A48A4;
	// lis r9,256
	ctx.r9.s64 = 16777216;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x831a4888
	if (cr6.eq) goto loc_831A4888;
	// lis r9,2816
	ctx.r9.s64 = 184549376;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x831a487c
	if (cr6.eq) goto loc_831A487C;
	// lis r9,3072
	ctx.r9.s64 = 201326592;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x831a484c
	if (cr6.eq) goto loc_831A484C;
	// b 0x831ace9c
	goto loc_831ACE9C;
loc_831A484C:
	// ld r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x8319bc38
	sub_8319BC38(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// b 0x831a4894
	goto loc_831A4894;
loc_831A487C:
	// ld r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x8319bc38
	sub_8319BC38(ctx, base);
	// b 0x831a4890
	goto loc_831A4890;
loc_831A4888:
	// ld r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x8319bbf8
	sub_8319BBF8(ctx, base);
loc_831A4890:
	// stw r3,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r3.u32);
loc_831A4894:
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// rlwinm r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
loc_831A48A4:
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// ld r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// bl 0x8319fd40
	sub_8319FD40(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r24
	cr6.compare<uint32_t>(r30.u32, r24.u32, xer);
	// blt cr6,0x831a4800
	if (cr6.lt) goto loc_831A4800;
loc_831A48BC:
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// stw r28,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, r28.u32);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// stw r29,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r29.u32);
	// addi r3,r1,1800
	ctx.r3.s64 = ctx.r1.s64 + 1800;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r30,r19
	r30.u64 = r19.u64;
loc_831A48D8:
	// lwz r10,36(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// srw r11,r10,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (r30.u8 & 0x3F));
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// cmplwi cr6,r10,228
	cr6.compare<uint32_t>(ctx.r10.u32, 228, xer);
	// beq cr6,0x831a4908
	if (cr6.eq) goto loc_831A4908;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// blt cr6,0x831a4908
	if (cr6.lt) goto loc_831A4908;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r10,r10,0,15,15
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a4904
	if (!cr0.eq) goto loc_831A4904;
	// b 0x831acea4
	goto loc_831ACEA4;
loc_831A4904:
	// mr r11,r19
	r11.u64 = r19.u64;
loc_831A4908:
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// addi r3,r1,1800
	ctx.r3.s64 = ctx.r1.s64 + 1800;
	// bl 0x8319ae60
	sub_8319AE60(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r1,168
	ctx.r3.s64 = ctx.r1.s64 + 168;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// addi r30,r30,2
	r30.s64 = r30.s64 + 2;
	// cmplwi cr6,r30,8
	cr6.compare<uint32_t>(r30.u32, 8, xer);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// blt cr6,0x831a48d8
	if (cr6.lt) goto loc_831A48D8;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// addi r3,r1,2792
	ctx.r3.s64 = ctx.r1.s64 + 2792;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831A4954:
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a4960
	if (cr0.eq) goto loc_831A4960;
	// b 0x831acec0
	goto loc_831ACEC0;
loc_831A4960:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a05a0
	sub_831A05A0(ctx, base);
	// li r29,3
	r29.s64 = 3;
	// addi r30,r14,108
	r30.s64 = r14.s64 + 108;
loc_831A4978:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a4990
	if (cr6.eq) goto loc_831A4990;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// rotlwi r4,r11,0
	ctx.r4.u64 = rotl32(r11.u32, 0);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
loc_831A4990:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// bge 0x831a4978
	if (!cr0.lt) goto loc_831A4978;
	// mr r29,r21
	r29.u64 = r21.u64;
	// addi r30,r14,88
	r30.s64 = r14.s64 + 88;
loc_831A49A4:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a49bc
	if (cr6.eq) goto loc_831A49BC;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// rotlwi r4,r11,0
	ctx.r4.u64 = rotl32(r11.u32, 0);
	// bl 0x831a0520
	sub_831A0520(ctx, base);
loc_831A49BC:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// bge 0x831a49a4
	if (!cr0.lt) goto loc_831A49A4;
	// b 0x831a534c
	goto loc_831A534C;
loc_831A49CC:
	// lwz r11,16(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 16);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831a4ab8
	if (cr6.lt) goto loc_831A4AB8;
	// beq cr6,0x831a4a9c
	if (cr6.eq) goto loc_831A4A9C;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x831a4ab8
	if (cr6.lt) goto loc_831A4AB8;
	// beq cr6,0x831a4a64
	if (cr6.eq) goto loc_831A4A64;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// beq cr6,0x831a49f4
	if (cr6.eq) goto loc_831A49F4;
	// b 0x831acecc
	goto loc_831ACECC;
loc_831A49F4:
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// lwz r5,24(r14)
	ctx.r5.u64 = PPC_LOAD_U32(r14.u32 + 24);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// bne cr6,0x831a4a14
	if (!cr6.eq) goto loc_831A4A14;
	// b 0x831aced8
	goto loc_831ACED8;
loc_831A4A14:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r5,40
	ctx.r10.s64 = ctx.r5.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a4a30
	if (!cr0.eq) goto loc_831A4A30;
	// b 0x831acee4
	goto loc_831ACEE4;
loc_831A4A30:
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r9,80(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831a4a50
	if (cr6.eq) goto loc_831A4A50;
	// rotlwi r10,r9,0
	ctx.r10.u64 = rotl32(ctx.r9.u32, 0);
	// rlwinm r9,r5,2,0,29
	ctx.r9.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r9,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// b 0x831a4a54
	goto loc_831A4A54;
loc_831A4A50:
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
loc_831A4A54:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// rlwinm r8,r11,29,18,31
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// b 0x831acad8
	goto loc_831ACAD8;
loc_831A4A64:
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a4a70
	if (cr0.eq) goto loc_831A4A70;
	// b 0x831acf00
	goto loc_831ACF00;
loc_831A4A70:
	// lfd f0,24(r14)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r14.u32 + 24);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x83194aa8
	sub_83194AA8(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f2,f31
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,3096
	ctx.r3.s64 = ctx.r1.s64 + 3096;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// b 0x831a4af4
	goto loc_831A4AF4;
loc_831A4A9C:
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a4aa8
	if (cr0.eq) goto loc_831A4AA8;
	// b 0x831acf0c
	goto loc_831ACF0C;
loc_831A4AA8:
	// lwz r5,24(r14)
	ctx.r5.u64 = PPC_LOAD_U32(r14.u32 + 24);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r3,r1,3112
	ctx.r3.s64 = ctx.r1.s64 + 3112;
	// b 0x831a4aec
	goto loc_831A4AEC;
loc_831A4AB8:
	// clrlwi. r10,r22,24
	ctx.r10.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a4ac4
	if (cr0.eq) goto loc_831A4AC4;
	// b 0x831acf18
	goto loc_831ACF18;
loc_831A4AC4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831a4ae0
	if (!cr6.eq) goto loc_831A4AE0;
	// lwz r11,24(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 24);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r5,r11,1
	ctx.r5.u64 = r11.u64 ^ 1;
	// b 0x831a4ae4
	goto loc_831A4AE4;
loc_831A4AE0:
	// lwz r5,24(r14)
	ctx.r5.u64 = PPC_LOAD_U32(r14.u32 + 24);
loc_831A4AE4:
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r3,r1,3128
	ctx.r3.s64 = ctx.r1.s64 + 3128;
loc_831A4AEC:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x831d3eb8
	sub_831D3EB8(ctx, base);
loc_831A4AF4:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// ld r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// b 0x831ab098
	goto loc_831AB098;
loc_831A4B04:
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// mr r30,r14
	r30.u64 = r14.u64;
	// cmplwi cr6,r11,34
	cr6.compare<uint32_t>(r11.u32, 34, xer);
	// ble cr6,0x831a4b18
	if (!cr6.gt) goto loc_831A4B18;
	// b 0x831ad004
	goto loc_831AD004;
loc_831A4B18:
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,2728
	r12.s64 = r12.s64 + 2728;
	// rlwinm r0,r11,1,0,30
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31974
	r12.s64 = -2095448064;
	// addi r12,r12,19264
	r12.s64 = r12.s64 + 19264;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_831A4B40;
	case 1:
		goto loc_831A4B60;
	case 2:
		goto loc_831A4C08;
	case 3:
		goto loc_831A4C08;
	case 4:
		goto loc_831A4B40;
	case 5:
		goto loc_831A4B40;
	case 6:
		goto loc_831A4B98;
	case 7:
		goto loc_831A4B40;
	case 8:
		goto loc_831A4BD4;
	case 9:
		goto loc_831A4BD4;
	case 10:
		goto loc_831A4BD4;
	case 11:
		goto loc_831A4BD4;
	case 12:
		goto loc_831A4BD4;
	case 13:
		goto loc_831A4BD4;
	case 14:
		goto loc_831A4BD4;
	case 15:
		goto loc_831A4BD4;
	case 16:
		goto loc_831A4BD4;
	case 17:
		goto loc_831A4BD4;
	case 18:
		goto loc_831A4BD4;
	case 19:
		goto loc_831A4BD4;
	case 20:
		goto loc_831A4BD4;
	case 21:
		goto loc_831A4BD4;
	case 22:
		goto loc_831A4BD4;
	case 23:
		goto loc_831A4BD4;
	case 24:
		goto loc_831A4BD4;
	case 25:
		goto loc_831A4BD4;
	case 26:
		goto loc_831A4C24;
	case 27:
		goto loc_831A4C24;
	case 28:
		goto loc_831A4BB0;
	case 29:
		goto loc_831A4B50;
	case 30:
		goto loc_831A4EA8;
	case 31:
		goto loc_831A4F20;
	case 32:
		goto loc_831A4C48;
	case 33:
		goto loc_831A4C48;
	case 34:
		goto loc_831ACFF8;
	default:
		__builtin_unreachable();
	}
loc_831A4B40:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a4b50
	if (cr6.eq) goto loc_831A4B50;
	// b 0x831acf24
	goto loc_831ACF24;
loc_831A4B50:
	// lwz r14,32(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// b 0x831a510c
	goto loc_831A510C;
loc_831A4B60:
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a4b6c
	if (cr0.eq) goto loc_831A4B6C;
	// b 0x831acf30
	goto loc_831ACF30;
loc_831A4B6C:
	// lwz r11,40(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 40);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831a4b84
	if (cr6.eq) goto loc_831A4B84;
	// li r5,0
	ctx.r5.s64 = 0;
	// b 0x831a4bb8
	goto loc_831A4BB8;
loc_831A4B84:
	// lwz r14,36(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// lwz r4,32(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// b 0x831a5108
	goto loc_831A5108;
loc_831A4B98:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a4ba8
	if (cr6.eq) goto loc_831A4BA8;
	// b 0x831acf3c
	goto loc_831ACF3C;
loc_831A4BA8:
	// lwz r14,32(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// b 0x831a5344
	goto loc_831A5344;
loc_831A4BB0:
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_831A4BB8:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
loc_831A4BBC:
	// lwz r14,32(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// bl 0x831a05a0
	sub_831A05A0(ctx, base);
	// lwz r4,36(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 36);
loc_831A4BC8:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// b 0x831a5344
	goto loc_831A5344;
loc_831A4BD4:
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a4be0
	if (cr0.eq) goto loc_831A4BE0;
	// b 0x831acf48
	goto loc_831ACF48;
loc_831A4BE0:
	// lwz r11,40(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 40);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bne cr6,0x831a4bbc
	if (!cr6.eq) goto loc_831A4BBC;
	// lwz r14,36(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// bl 0x831a05a0
	sub_831A05A0(ctx, base);
	// lwz r4,32(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// b 0x831a4bc8
	goto loc_831A4BC8;
loc_831A4C08:
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// lwz r14,32(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a05a0
	sub_831A05A0(ctx, base);
loc_831A4C1C:
	// mr r22,r21
	r22.u64 = r21.u64;
	// b 0x831a5344
	goto loc_831A5344;
loc_831A4C24:
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// lwz r14,32(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a05a0
	sub_831A05A0(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r4,36(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// b 0x831a4c1c
	goto loc_831A4C1C;
loc_831A4C48:
	// clrlwi. r10,r22,24
	ctx.r10.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a4c54
	if (cr0.eq) goto loc_831A4C54;
	// b 0x831acf54
	goto loc_831ACF54;
loc_831A4C54:
	// mr r28,r19
	r28.u64 = r19.u64;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// bne cr6,0x831a4cfc
	if (!cr6.eq) goto loc_831A4CFC;
	// lwz r11,32(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// bne cr6,0x831a4cb8
	if (!cr6.eq) goto loc_831A4CB8;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a4c88
	if (cr6.eq) goto loc_831A4C88;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// stw r21,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r21.u32);
loc_831A4C88:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a4cfc
	if (cr0.eq) goto loc_831A4CFC;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a06b0
	sub_831A06B0(ctx, base);
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a0630
	sub_831A0630(ctx, base);
	// b 0x831a4cfc
	goto loc_831A4CFC;
loc_831A4CB8:
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x831a4cc8
	if (cr6.eq) goto loc_831A4CC8;
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// bne cr6,0x831a4cfc
	if (!cr6.eq) goto loc_831A4CFC;
loc_831A4CC8:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a4cdc
	if (cr6.eq) goto loc_831A4CDC;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// stw r21,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r21.u32);
loc_831A4CDC:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a06b0
	sub_831A06B0(ctx, base);
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a0630
	sub_831A0630(ctx, base);
	// mr r28,r21
	r28.u64 = r21.u64;
loc_831A4CFC:
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// bne cr6,0x831a4d4c
	if (!cr6.eq) goto loc_831A4D4C;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a4d18
	if (!cr6.eq) goto loc_831A4D18;
	// b 0x831acf60
	goto loc_831ACF60;
loc_831A4D18:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831a4d28
	if (cr6.eq) goto loc_831A4D28;
	// b 0x831acf60
	goto loc_831ACF60;
loc_831A4D28:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a4d40
	if (cr6.eq) goto loc_831A4D40;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831a4d68
	if (cr6.eq) goto loc_831A4D68;
loc_831A4D40:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A4D4C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a4d58
	if (!cr6.eq) goto loc_831A4D58;
	// b 0x831acfb4
	goto loc_831ACFB4;
loc_831A4D58:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831a4d68
	if (cr6.eq) goto loc_831A4D68;
	// b 0x831acfb4
	goto loc_831ACFB4;
loc_831A4D68:
	// lwz r29,8(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a4d84
	if (cr6.eq) goto loc_831A4D84;
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831a4d84
	if (cr6.eq) goto loc_831A4D84;
	// b 0x831acf6c
	goto loc_831ACF6C;
loc_831A4D84:
	// lwz r30,12(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a4da0
	if (cr6.eq) goto loc_831A4DA0;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831a4da0
	if (cr6.eq) goto loc_831A4DA0;
	// b 0x831acf78
	goto loc_831ACF78;
loc_831A4DA0:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a05a0
	sub_831A05A0(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a4e4c
	if (cr6.eq) goto loc_831A4E4C;
loc_831A4DB8:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a4e44
	if (!cr6.eq) goto loc_831A4E44;
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a4e4c
	if (cr6.eq) goto loc_831A4E4C;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831a4de0
	if (cr6.eq) goto loc_831A4DE0;
	// b 0x831acf84
	goto loc_831ACF84;
loc_831A4DE0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831a4db8
	if (!cr6.eq) goto loc_831A4DB8;
	// b 0x831a4e44
	goto loc_831A4E44;
loc_831A4DEC:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a4dfc
	if (!cr6.eq) goto loc_831A4DFC;
	// b 0x831acfa8
	goto loc_831ACFA8;
loc_831A4DFC:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// beq cr6,0x831a4e0c
	if (cr6.eq) goto loc_831A4E0C;
	// b 0x831acfa8
	goto loc_831ACFA8;
loc_831A4E0C:
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r10,27
	cr6.compare<int32_t>(ctx.r10.s32, 27, xer);
	// beq cr6,0x831a4e1c
	if (cr6.eq) goto loc_831A4E1C;
	// b 0x831acf90
	goto loc_831ACF90;
loc_831A4E1C:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r4,32(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bl 0x831a0520
	sub_831A0520(ctx, base);
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a4e4c
	if (cr6.eq) goto loc_831A4E4C;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831a4e44
	if (cr6.eq) goto loc_831A4E44;
	// b 0x831acf9c
	goto loc_831ACF9C;
loc_831A4E44:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831a4dec
	if (!cr6.eq) goto loc_831A4DEC;
loc_831A4E4C:
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// bne cr6,0x831a4e98
	if (!cr6.eq) goto loc_831A4E98;
	// lwz r11,32(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// beq cr6,0x831a4e7c
	if (cr6.eq) goto loc_831A4E7C;
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// beq cr6,0x831a4e7c
	if (cr6.eq) goto loc_831A4E7C;
	// cmpwi cr6,r11,34
	cr6.compare<int32_t>(r11.s32, 34, xer);
	// bne cr6,0x831a4e98
	if (!cr6.eq) goto loc_831A4E98;
loc_831A4E7C:
	// lwz r11,608(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 608);
	// li r5,5
	ctx.r5.s64 = 5;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// stw r11,608(r31)
	PPC_STORE_U32(r31.u32 + 608, r11.u32);
	// bl 0x831a0630
	sub_831A0630(ctx, base);
loc_831A4E98:
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// b 0x831a5330
	goto loc_831A5330;
loc_831A4EA8:
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a4eb4
	if (cr0.eq) goto loc_831A4EB4;
	// b 0x831acfc0
	goto loc_831ACFC0;
loc_831A4EB4:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a4ec4
	if (!cr6.eq) goto loc_831A4EC4;
	// b 0x831acfd8
	goto loc_831ACFD8;
loc_831A4EC4:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// beq cr6,0x831a4ed4
	if (cr6.eq) goto loc_831A4ED4;
	// b 0x831acfd8
	goto loc_831ACFD8;
loc_831A4ED4:
	// lwz r30,32(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831a4ee4
	if (!cr6.eq) goto loc_831A4EE4;
	// b 0x831acfcc
	goto loc_831ACFCC;
loc_831A4EE4:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831a4ef4
	if (cr6.eq) goto loc_831A4EF4;
	// b 0x831acfcc
	goto loc_831ACFCC;
loc_831A4EF4:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a05a0
	sub_831A05A0(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r4,12(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// b 0x831a4ba8
	goto loc_831A4BA8;
loc_831A4F20:
	// lwz r28,36(r14)
	r28.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831a4f84
	if (cr6.eq) goto loc_831A4F84;
	// lwz r29,12(r28)
	r29.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a4f84
	if (cr6.eq) goto loc_831A4F84;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831a4f48
	if (cr6.eq) goto loc_831A4F48;
	// b 0x831acfe4
	goto loc_831ACFE4;
loc_831A4F48:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a05a0
	sub_831A05A0(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a1530
	sub_831A1530(ctx, base);
	// mr. r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x831a4f84
	if (cr0.eq) goto loc_831A4F84;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
loc_831A4F84:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a05a0
	sub_831A05A0(ctx, base);
	// mr r14,r19
	r14.u64 = r19.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831a4fd8
	if (cr6.eq) goto loc_831A4FD8;
	// lwz r5,8(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831a4fd8
	if (cr6.eq) goto loc_831A4FD8;
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831a4fc0
	if (cr6.eq) goto loc_831A4FC0;
	// b 0x831acff0
	goto loc_831ACFF0;
loc_831A4FC0:
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x831a1530
	sub_831A1530(ctx, base);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
loc_831A4FD8:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831953b0
	sub_831953B0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// rlwimi r10,r11,0,0,16
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFF8000) | (ctx.r10.u64 & 0xFFFFFFFF00007FFF);
	// stw r10,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r10.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a5098
	if (!cr6.eq) goto loc_831A5098;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196fd8
	sub_83196FD8(ctx, base);
	// stw r3,12(r30)
	PPC_STORE_U32(r30.u32 + 12, ctx.r3.u32);
	// li r5,2
	ctx.r5.s64 = 2;
	// lwz r6,0(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x831a37b8
	sub_831A37B8(ctx, base);
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a3c48
	sub_831A3C48(ctx, base);
	// lwz r3,572(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 572);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a5074
	if (!cr0.eq) goto loc_831A5074;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a5074
	if (cr0.eq) goto loc_831A5074;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831a5080
	if (!cr6.gt) goto loc_831A5080;
loc_831A5074:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831A5080:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r30,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r30.u32);
loc_831A5098:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a5344
	if (cr6.eq) goto loc_831A5344;
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x831a50bc
	if (cr6.eq) goto loc_831A50BC;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
loc_831A50BC:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,44(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// b 0x831a5334
	goto loc_831A5334;
loc_831A50D4:
	// lwz r11,24(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 24);
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831ad010
	if (!cr6.eq) goto loc_831AD010;
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831ad010
	if (!cr6.eq) goto loc_831AD010;
	// lwz r11,32(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831ad010
	if (!cr6.eq) goto loc_831AD010;
	// lwz r14,20(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
loc_831A5108:
	// li r5,0
	ctx.r5.s64 = 0;
loc_831A510C:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x831a05a0
	sub_831A05A0(ctx, base);
	// b 0x831a5344
	goto loc_831A5344;
loc_831A5118:
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4150
	sub_831A4150(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831A512C:
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// bne 0x831a5320
	if (!cr0.eq) goto loc_831A5320;
loc_831A5138:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
	// mr r27,r19
	r27.u64 = r19.u64;
loc_831A5148:
	// cmplwi cr6,r27,4
	cr6.compare<uint32_t>(r27.u32, 4, xer);
	// bge cr6,0x831a51f0
	if (!cr6.lt) goto loc_831A51F0;
	// lwz r10,8(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831ad01c
	if (cr6.eq) goto loc_831AD01C;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x831a51f0
	if (!cr6.eq) goto loc_831A51F0;
	// lwz r11,28(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831a51f0
	if (!cr6.eq) goto loc_831A51F0;
	// lwz r11,32(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// bne cr6,0x831a51f0
	if (!cr6.eq) goto loc_831A51F0;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x831a51f0
	if (!cr6.eq) goto loc_831A51F0;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// bne cr6,0x831a51f0
	if (!cr6.eq) goto loc_831A51F0;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x831a51f0
	if (!cr6.eq) goto loc_831A51F0;
	// lwz r10,16(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x831a51f0
	if (!cr6.eq) goto loc_831A51F0;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// bne cr6,0x831a51f0
	if (!cr6.eq) goto loc_831A51F0;
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a51e0
	if (cr6.eq) goto loc_831A51E0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad028
	if (!cr6.eq) goto loc_831AD028;
loc_831A51E0:
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a5148
	if (!cr6.eq) goto loc_831A5148;
loc_831A51F0:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831a5320
	if (cr6.eq) goto loc_831A5320;
	// addi r11,r1,644
	r11.s64 = ctx.r1.s64 + 644;
	// stfs f31,640(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 640, temp.u32);
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r19
	r30.u64 = r19.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// stw r19,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r19.u32);
	// stw r19,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r19.u32);
	// stw r19,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r19.u32);
	// beq cr6,0x831a52c8
	if (cr6.eq) goto loc_831A52C8;
	// addi r28,r1,640
	r28.s64 = ctx.r1.s64 + 640;
loc_831A5220:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831a5280
	if (cr6.lt) goto loc_831A5280;
	// beq cr6,0x831a5268
	if (cr6.eq) goto loc_831A5268;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x831a5258
	if (cr6.lt) goto loc_831A5258;
	// bne cr6,0x831ad034
	if (!cr6.eq) goto loc_831AD034;
	// lfd f0,24(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x83194aa8
	sub_83194AA8(ctx, base);
	// b 0x831a5298
	goto loc_831A5298;
loc_831A5258:
	// lwz r11,24(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// std r11,1200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 1200, r11.u64);
	// lfd f0,1200(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1200);
	// b 0x831a5274
	goto loc_831A5274;
loc_831A5268:
	// lwa r11,24(r10)
	r11.s64 = int32_t(PPC_LOAD_U32(ctx.r10.u32 + 24));
	// std r11,1216(r1)
	PPC_STORE_U64(ctx.r1.u32 + 1216, r11.u64);
	// lfd f0,1216(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1216);
loc_831A5274:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// b 0x831a5298
	goto loc_831A5298;
loc_831A5280:
	// lwz r11,24(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831a5294
	if (cr6.eq) goto loc_831A5294;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// b 0x831a5298
	goto loc_831A5298;
loc_831A5294:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
loc_831A5298:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// stfs f1,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a52b4
	if (cr6.eq) goto loc_831A52B4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad040
	if (!cr6.eq) goto loc_831AD040;
loc_831A52B4:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// mr r29,r11
	r29.u64 = r11.u64;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r30,r27
	cr6.compare<uint32_t>(r30.u32, r27.u32, xer);
	// blt cr6,0x831a5220
	if (cr6.lt) goto loc_831A5220;
loc_831A52C8:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lfs f4,652(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f4.f64 = double(temp.f32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lfs f3,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f3.f64 = double(temp.f32);
	// addi r3,r1,464
	ctx.r3.s64 = ctx.r1.s64 + 464;
	// lfs f2,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r30,r19
	r30.u64 = r19.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831a5318
	if (cr6.eq) goto loc_831A5318;
loc_831A52F4:
	// lwz r11,468(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// rlwimi r11,r30,2,16,29
	r11.u64 = (rotl32(r30.u32, 2) & 0xFFFC) | (r11.u64 & 0xFFFFFFFFFFFF0003);
	// stw r11,468(r1)
	PPC_STORE_U32(ctx.r1.u32 + 468, r11.u32);
	// ld r4,464(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 464);
	// bl 0x8319fd40
	sub_8319FD40(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r27
	cr6.compare<uint32_t>(r30.u32, r27.u32, xer);
	// blt cr6,0x831a52f4
	if (cr6.lt) goto loc_831A52F4;
loc_831A5318:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// b 0x831a5138
	goto loc_831A5138;
loc_831A5320:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
loc_831A5330:
	// li r8,0
	ctx.r8.s64 = 0;
loc_831A5334:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a1530
	sub_831A1530(ctx, base);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
loc_831A5344:
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// bne cr6,0x831a4410
	if (!cr6.eq) goto loc_831A4410;
loc_831A534C:
	// lwz r26,440(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	// addi r11,r26,4
	r11.s64 = r26.s64 + 4;
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831ad04c
	if (!cr0.eq) goto loc_831AD04C;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831ad04c
	if (cr0.eq) goto loc_831AD04C;
	// addi r4,r1,444
	ctx.r4.s64 = ctx.r1.s64 + 444;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8319d828
	sub_8319D828(ctx, base);
	// lwz r10,444(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// clrlwi. r11,r10,31
	r11.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r22,r10,31,31,31
	r22.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	// beq 0x831acdb4
	if (cr0.eq) goto loc_831ACDB4;
	// lwz r11,4(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831acd28
	if (cr6.eq) goto loc_831ACD28;
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// beq cr6,0x831acd0c
	if (cr6.eq) goto loc_831ACD0C;
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x831a69c8
	if (cr6.eq) goto loc_831A69C8;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// bne cr6,0x831ad1b8
	if (!cr6.eq) goto loc_831AD1B8;
	// lwz r11,80(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831a53c4
	if (cr6.eq) goto loc_831A53C4;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ad1c4
	if (!cr0.eq) goto loc_831AD1C4;
loc_831A53C4:
	// lwz r11,92(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831ad1d8
	if (!cr6.eq) goto loc_831AD1D8;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r10,r14,84
	ctx.r10.s64 = r14.s64 + 84;
	// li r11,2
	r11.s64 = 2;
loc_831A53DC:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x831a53ec
	if (cr6.eq) goto loc_831A53EC;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
loc_831A53EC:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x831a53dc
	if (!cr0.eq) goto loc_831A53DC;
	// addi r15,r14,96
	r15.s64 = r14.s64 + 96;
	// li r30,0
	r30.s64 = 0;
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
	// li r11,4
	r11.s64 = 4;
loc_831A5408:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x831a5418
	if (cr6.eq) goto loc_831A5418;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
loc_831A5418:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x831a5408
	if (!cr0.eq) goto loc_831A5408;
	// lwz r29,3500(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// add r16,r30,r9
	r16.u64 = r30.u64 + ctx.r9.u64;
	// addi r3,r1,2440
	ctx.r3.s64 = ctx.r1.s64 + 2440;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,1736
	ctx.r3.s64 = ctx.r1.s64 + 1736;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// li r17,0
	r17.s64 = 0;
loc_831A5450:
	// lwz r11,0(r15)
	r11.u64 = PPC_LOAD_U32(r15.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a5468
	if (cr6.eq) goto loc_831A5468;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,28
	cr6.compare<int32_t>(ctx.r10.s32, 28, xer);
	// bne cr6,0x831ad1ec
	if (!cr6.eq) goto loc_831AD1EC;
loc_831A5468:
	// lwz r10,100(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 100);
	// mr r19,r11
	r19.u64 = r11.u64;
	// stw r19,296(r1)
	PPC_STORE_U32(ctx.r1.u32 + 296, r19.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a5488
	if (cr6.eq) goto loc_831A5488;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// bne cr6,0x831ad1f8
	if (!cr6.eq) goto loc_831AD1F8;
loc_831A5488:
	// lwz r11,104(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 104);
	// mr r20,r10
	r20.u64 = ctx.r10.u64;
	// stw r20,300(r1)
	PPC_STORE_U32(ctx.r1.u32 + 300, r20.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a54a8
	if (cr6.eq) goto loc_831A54A8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,28
	cr6.compare<int32_t>(ctx.r10.s32, 28, xer);
	// bne cr6,0x831ad204
	if (!cr6.eq) goto loc_831AD204;
loc_831A54A8:
	// lwz r9,48(r14)
	ctx.r9.u64 = PPC_LOAD_U32(r14.u32 + 48);
	// stw r11,304(r1)
	PPC_STORE_U32(ctx.r1.u32 + 304, r11.u32);
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// bne cr6,0x831a54f8
	if (!cr6.eq) goto loc_831A54F8;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x831a54f0
	if (cr6.eq) goto loc_831A54F0;
	// lwz r10,108(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 108);
	// mr r19,r11
	r19.u64 = r11.u64;
	// li r9,3
	ctx.r9.s64 = 3;
	// stw r19,296(r1)
	PPC_STORE_U32(ctx.r1.u32 + 296, r19.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a54e4
	if (cr6.eq) goto loc_831A54E4;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// bne cr6,0x831ad210
	if (!cr6.eq) goto loc_831AD210;
loc_831A54E4:
	// mr r20,r10
	r20.u64 = ctx.r10.u64;
	// stw r20,300(r1)
	PPC_STORE_U32(ctx.r1.u32 + 300, r20.u32);
	// b 0x831a5514
	goto loc_831A5514;
loc_831A54F0:
	// li r9,2
	ctx.r9.s64 = 2;
	// b 0x831a5514
	goto loc_831A5514;
loc_831A54F8:
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// bne cr6,0x831a550c
	if (!cr6.eq) goto loc_831A550C;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x831a69a0
	if (cr6.eq) goto loc_831A69A0;
	// b 0x831a5514
	goto loc_831A5514;
loc_831A550C:
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// bne cr6,0x831a69ac
	if (!cr6.eq) goto loc_831A69AC;
loc_831A5514:
	// addi r11,r17,21
	r11.s64 = r17.s64 + 21;
	// li r21,0
	r21.s64 = 0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r18,0
	r18.s64 = 0;
	// lwzx r10,r11,r14
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a5558
	if (cr6.eq) goto loc_831A5558;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad21c
	if (cr6.eq) goto loc_831AD21C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,28
	cr6.compare<int32_t>(ctx.r10.s32, 28, xer);
	// bne cr6,0x831ad21c
	if (!cr6.eq) goto loc_831AD21C;
	// li r25,4
	r25.s64 = 4;
	// mr r18,r11
	r18.u64 = r11.u64;
	// mr r21,r25
	r21.u64 = r25.u64;
	// b 0x831a555c
	goto loc_831A555C;
loc_831A5558:
	// li r25,4
	r25.s64 = 4;
loc_831A555C:
	// li r23,0
	r23.s64 = 0;
	// li r27,0
	r27.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// blt cr6,0x831a57c4
	if (cr6.lt) goto loc_831A57C4;
	// beq cr6,0x831a5794
	if (cr6.eq) goto loc_831A5794;
	// cmplwi cr6,r9,3
	cr6.compare<uint32_t>(ctx.r9.u32, 3, xer);
	// blt cr6,0x831a56fc
	if (cr6.lt) goto loc_831A56FC;
	// beq cr6,0x831a5660
	if (cr6.eq) goto loc_831A5660;
	// cmplwi cr6,r9,5
	cr6.compare<uint32_t>(ctx.r9.u32, 5, xer);
	// bne cr6,0x831ad2c0
	if (!cr6.eq) goto loc_831AD2C0;
	// addi r11,r17,13
	r11.s64 = r17.s64 + 13;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r14
	r11.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// bne cr6,0x831ad228
	if (!cr6.eq) goto loc_831AD228;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// bne cr6,0x831ad234
	if (!cr6.eq) goto loc_831AD234;
	// lwz r11,112(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 112);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad240
	if (cr6.eq) goto loc_831AD240;
	// lwz r28,8(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831ad24c
	if (cr6.eq) goto loc_831AD24C;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831ad258
	if (!cr6.eq) goto loc_831AD258;
	// lwz r29,8(r28)
	r29.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831ad284
	if (cr6.eq) goto loc_831AD284;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x831ad284
	if (!cr6.eq) goto loc_831AD284;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x831ad26c
	if (!cr6.eq) goto loc_831AD26C;
	// lwz r4,480(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	// lwz r3,24(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831a5648
	if (cr0.eq) goto loc_831A5648;
	// lwz r4,496(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	// lwz r3,24(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831a5648
	if (cr0.eq) goto loc_831A5648;
	// lwz r4,512(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	// lwz r3,24(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831a5648
	if (cr0.eq) goto loc_831A5648;
	// lwz r4,528(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	// lwz r3,24(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// bl 0x82ca6320
	sub_82CA6320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x831ad278
	if (!cr0.eq) goto loc_831AD278;
	// li r6,94
	ctx.r6.s64 = 94;
	// b 0x831a5860
	goto loc_831A5860;
loc_831A5648:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a69a0
	if (cr6.eq) goto loc_831A69A0;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A5660:
	// addi r11,r17,13
	r11.s64 = r17.s64 + 13;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r14
	r11.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// cmplwi cr6,r11,241
	cr6.compare<uint32_t>(r11.u32, 241, xer);
	// beq cr6,0x831a69a0
	if (cr6.eq) goto loc_831A69A0;
	// cmplwi cr6,r11,243
	cr6.compare<uint32_t>(r11.u32, 243, xer);
	// beq cr6,0x831a56f0
	if (cr6.eq) goto loc_831A56F0;
	// cmplwi cr6,r11,252
	cr6.compare<uint32_t>(r11.u32, 252, xer);
	// beq cr6,0x831a56e0
	if (cr6.eq) goto loc_831A56E0;
	// cmplwi cr6,r11,253
	cr6.compare<uint32_t>(r11.u32, 253, xer);
	// beq cr6,0x831a56d0
	if (cr6.eq) goto loc_831A56D0;
	// addi r6,r11,32
	ctx.r6.s64 = r11.s64 + 32;
	// cmpwi cr6,r6,32
	cr6.compare<int32_t>(ctx.r6.s32, 32, xer);
	// blt cr6,0x831ad290
	if (cr6.lt) goto loc_831AD290;
	// cmpwi cr6,r6,82
	cr6.compare<int32_t>(ctx.r6.s32, 82, xer);
	// bgt cr6,0x831ad290
	if (cr6.gt) goto loc_831AD290;
	// cmpwi cr6,r6,73
	cr6.compare<int32_t>(ctx.r6.s32, 73, xer);
	// beq cr6,0x831ad290
	if (cr6.eq) goto loc_831AD290;
	// cmpwi cr6,r6,65
	cr6.compare<int32_t>(ctx.r6.s32, 65, xer);
	// beq cr6,0x831a56c8
	if (cr6.eq) goto loc_831A56C8;
	// cmpwi cr6,r6,73
	cr6.compare<int32_t>(ctx.r6.s32, 73, xer);
	// ble cr6,0x831a5854
	if (!cr6.gt) goto loc_831A5854;
	// cmpwi cr6,r6,79
	cr6.compare<int32_t>(ctx.r6.s32, 79, xer);
	// ble cr6,0x831a575c
	if (!cr6.gt) goto loc_831A575C;
	// cmpwi cr6,r6,82
	cr6.compare<int32_t>(ctx.r6.s32, 82, xer);
	// bne cr6,0x831a5854
	if (!cr6.eq) goto loc_831A5854;
loc_831A56C8:
	// li r30,0
	r30.s64 = 0;
	// b 0x831a5858
	goto loc_831A5858;
loc_831A56D0:
	// li r23,1
	r23.s64 = 1;
	// li r30,1
	r30.s64 = 1;
	// li r6,56
	ctx.r6.s64 = 56;
	// b 0x831a5860
	goto loc_831A5860;
loc_831A56E0:
	// li r23,1
	r23.s64 = 1;
	// li r30,1
	r30.s64 = 1;
	// li r6,55
	ctx.r6.s64 = 55;
	// b 0x831a5860
	goto loc_831A5860;
loc_831A56F0:
	// li r23,1
	r23.s64 = 1;
	// li r6,37
	ctx.r6.s64 = 37;
	// b 0x831a5854
	goto loc_831A5854;
loc_831A56FC:
	// addi r11,r17,13
	r11.s64 = r17.s64 + 13;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r14
	r11.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// cmplwi cr6,r11,240
	cr6.compare<uint32_t>(r11.u32, 240, xer);
	// beq cr6,0x831a69a0
	if (cr6.eq) goto loc_831A69A0;
	// cmplwi cr6,r11,242
	cr6.compare<uint32_t>(r11.u32, 242, xer);
	// beq cr6,0x831a5780
	if (cr6.eq) goto loc_831A5780;
	// cmplwi cr6,r11,244
	cr6.compare<uint32_t>(r11.u32, 244, xer);
	// beq cr6,0x831a576c
	if (cr6.eq) goto loc_831A576C;
	// addi r6,r11,1
	ctx.r6.s64 = r11.s64 + 1;
	// cmpwi cr6,r6,1
	cr6.compare<int32_t>(ctx.r6.s32, 1, xer);
	// blt cr6,0x831ad29c
	if (cr6.lt) goto loc_831AD29C;
	// cmpwi cr6,r6,31
	cr6.compare<int32_t>(ctx.r6.s32, 31, xer);
	// bgt cr6,0x831ad29c
	if (cr6.gt) goto loc_831AD29C;
	// cmpwi cr6,r6,9
	cr6.compare<int32_t>(ctx.r6.s32, 9, xer);
	// blt cr6,0x831a575c
	if (cr6.lt) goto loc_831A575C;
	// cmpwi cr6,r6,11
	cr6.compare<int32_t>(ctx.r6.s32, 11, xer);
	// ble cr6,0x831a5854
	if (!cr6.gt) goto loc_831A5854;
	// cmpwi cr6,r6,15
	cr6.compare<int32_t>(ctx.r6.s32, 15, xer);
	// ble cr6,0x831a5764
	if (!cr6.gt) goto loc_831A5764;
	// cmpwi cr6,r6,18
	cr6.compare<int32_t>(ctx.r6.s32, 18, xer);
	// beq cr6,0x831a5764
	if (cr6.eq) goto loc_831A5764;
	// cmpwi cr6,r6,20
	cr6.compare<int32_t>(ctx.r6.s32, 20, xer);
	// beq cr6,0x831a5854
	if (cr6.eq) goto loc_831A5854;
loc_831A575C:
	// li r30,2
	r30.s64 = 2;
	// b 0x831a5858
	goto loc_831A5858;
loc_831A5764:
	// li r30,3
	r30.s64 = 3;
	// b 0x831a5858
	goto loc_831A5858;
loc_831A576C:
	// li r23,1
	r23.s64 = 1;
	// li r30,2
	r30.s64 = 2;
	// li r27,-1
	r27.s64 = -1;
	// li r6,30
	ctx.r6.s64 = 30;
	// b 0x831a5860
	goto loc_831A5860;
loc_831A5780:
	// li r23,1
	r23.s64 = 1;
	// li r30,2
	r30.s64 = 2;
	// li r27,-1
	r27.s64 = -1;
	// li r6,3
	ctx.r6.s64 = 3;
	// b 0x831a5858
	goto loc_831A5858;
loc_831A5794:
	// lwz r11,52(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 52);
	// li r6,96
	ctx.r6.s64 = 96;
	// li r26,1
	r26.s64 = 1;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831a57bc
	if (cr6.lt) goto loc_831A57BC;
	// beq cr6,0x831a5860
	if (cr6.eq) goto loc_831A5860;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bge cr6,0x831ad2a8
	if (!cr6.lt) goto loc_831AD2A8;
loc_831A57B4:
	// li r30,2
	r30.s64 = 2;
	// b 0x831a5860
	goto loc_831A5860;
loc_831A57BC:
	// li r30,1
	r30.s64 = 1;
	// b 0x831a5860
	goto loc_831A5860;
loc_831A57C4:
	// addi r11,r17,13
	r11.s64 = r17.s64 + 13;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r14
	r11.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// cmplwi cr6,r11,19
	cr6.compare<uint32_t>(r11.u32, 19, xer);
	// bgt cr6,0x831a5818
	if (cr6.gt) goto loc_831A5818;
	// beq cr6,0x831a5810
	if (cr6.eq) goto loc_831A5810;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x831a5808
	if (cr6.eq) goto loc_831A5808;
	// cmplwi cr6,r11,15
	cr6.compare<uint32_t>(r11.u32, 15, xer);
	// ble cr6,0x831ad2b4
	if (!cr6.gt) goto loc_831AD2B4;
	// cmplwi cr6,r11,17
	cr6.compare<uint32_t>(r11.u32, 17, xer);
	// ble cr6,0x831a5810
	if (!cr6.gt) goto loc_831A5810;
	// cmplwi cr6,r11,18
	cr6.compare<uint32_t>(r11.u32, 18, xer);
	// bne cr6,0x831ad2b4
	if (!cr6.eq) goto loc_831AD2B4;
	// li r6,100
	ctx.r6.s64 = 100;
loc_831A5800:
	// li r26,1
	r26.s64 = 1;
	// b 0x831a57b4
	goto loc_831A57B4;
loc_831A5808:
	// li r6,97
	ctx.r6.s64 = 97;
	// b 0x831a5800
	goto loc_831A5800;
loc_831A5810:
	// li r6,99
	ctx.r6.s64 = 99;
	// b 0x831a5800
	goto loc_831A5800;
loc_831A5818:
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// beq cr6,0x831a5850
	if (cr6.eq) goto loc_831A5850;
	// cmplwi cr6,r11,25
	cr6.compare<uint32_t>(r11.u32, 25, xer);
	// beq cr6,0x831a5848
	if (cr6.eq) goto loc_831A5848;
	// cmplwi cr6,r11,26
	cr6.compare<uint32_t>(r11.u32, 26, xer);
	// bne cr6,0x831ad2b4
	if (!cr6.eq) goto loc_831AD2B4;
	// li r6,102
	ctx.r6.s64 = 102;
loc_831A5834:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r30,1
	r30.s64 = 1;
	// oris r11,r11,64
	r11.u64 = r11.u64 | 4194304;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// b 0x831a5860
	goto loc_831A5860;
loc_831A5848:
	// li r6,101
	ctx.r6.s64 = 101;
	// b 0x831a5834
	goto loc_831A5834;
loc_831A5850:
	// li r6,98
	ctx.r6.s64 = 98;
loc_831A5854:
	// li r30,1
	r30.s64 = 1;
loc_831A5858:
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq cr6,0x831ad2c0
	if (cr6.eq) goto loc_831AD2C0;
loc_831A5860:
	// li r11,228
	r11.s64 = 228;
	// stw r25,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r25.u32);
	// stw r25,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r25.u32);
	// cmpwi cr6,r6,38
	cr6.compare<int32_t>(ctx.r6.s32, 38, xer);
	// stw r25,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r25.u32);
	// stw r11,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, r11.u32);
	// stw r11,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, r11.u32);
	// stw r11,360(r1)
	PPC_STORE_U32(ctx.r1.u32 + 360, r11.u32);
	// bgt cr6,0x831a5918
	if (cr6.gt) goto loc_831A5918;
	// cmpwi cr6,r6,37
	cr6.compare<int32_t>(ctx.r6.s32, 37, xer);
	// bge cr6,0x831a5950
	if (!cr6.lt) goto loc_831A5950;
	// cmpwi cr6,r6,33
	cr6.compare<int32_t>(ctx.r6.s32, 33, xer);
	// bgt cr6,0x831a58ec
	if (cr6.gt) goto loc_831A58EC;
	// beq cr6,0x831a5968
	if (cr6.eq) goto loc_831A5968;
	// cmpwi cr6,r6,17
	cr6.compare<int32_t>(ctx.r6.s32, 17, xer);
	// beq cr6,0x831a58dc
	if (cr6.eq) goto loc_831A58DC;
	// cmpwi cr6,r6,18
	cr6.compare<int32_t>(ctx.r6.s32, 18, xer);
	// beq cr6,0x831a58c4
	if (cr6.eq) goto loc_831A58C4;
	// cmpwi cr6,r6,20
	cr6.compare<int32_t>(ctx.r6.s32, 20, xer);
	// ble cr6,0x831a5974
	if (!cr6.gt) goto loc_831A5974;
	// cmpwi cr6,r6,24
	cr6.compare<int32_t>(ctx.r6.s32, 24, xer);
	// ble cr6,0x831a59f0
	if (!cr6.gt) goto loc_831A59F0;
	// cmpwi cr6,r6,32
	cr6.compare<int32_t>(ctx.r6.s32, 32, xer);
	// beq cr6,0x831a5950
	if (cr6.eq) goto loc_831A5950;
	// b 0x831a5974
	goto loc_831A5974;
loc_831A58C4:
	// li r11,2
	r11.s64 = 2;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r11.u32);
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r11.u32);
	// stw r10,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r10.u32);
	// b 0x831a5974
	goto loc_831A5974;
loc_831A58DC:
	// li r11,3
	r11.s64 = 3;
loc_831A58E0:
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r11.u32);
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r11.u32);
	// b 0x831a5974
	goto loc_831A5974;
loc_831A58EC:
	// cmpwi cr6,r6,34
	cr6.compare<int32_t>(ctx.r6.s32, 34, xer);
	// beq cr6,0x831a5950
	if (cr6.eq) goto loc_831A5950;
	// cmpwi cr6,r6,35
	cr6.compare<int32_t>(ctx.r6.s32, 35, xer);
	// beq cr6,0x831a5968
	if (cr6.eq) goto loc_831A5968;
	// cmpwi cr6,r6,36
	cr6.compare<int32_t>(ctx.r6.s32, 36, xer);
	// bne cr6,0x831a5974
	if (!cr6.eq) goto loc_831A5974;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3724
	ctx.r5.s64 = r11.s64 + 3724;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A5918:
	// cmpwi cr6,r6,79
	cr6.compare<int32_t>(ctx.r6.s32, 79, xer);
	// bgt cr6,0x831a59d0
	if (cr6.gt) goto loc_831A59D0;
	// cmpwi cr6,r6,74
	cr6.compare<int32_t>(ctx.r6.s32, 74, xer);
	// bge cr6,0x831a59c0
	if (!cr6.lt) goto loc_831A59C0;
	// cmpwi cr6,r6,64
	cr6.compare<int32_t>(ctx.r6.s32, 64, xer);
	// bgt cr6,0x831a5958
	if (cr6.gt) goto loc_831A5958;
	// cmpwi cr6,r6,58
	cr6.compare<int32_t>(ctx.r6.s32, 58, xer);
	// bge cr6,0x831a5968
	if (!cr6.lt) goto loc_831A5968;
	// cmpwi cr6,r6,39
	cr6.compare<int32_t>(ctx.r6.s32, 39, xer);
	// blt cr6,0x831a5974
	if (cr6.lt) goto loc_831A5974;
	// cmpwi cr6,r6,54
	cr6.compare<int32_t>(ctx.r6.s32, 54, xer);
	// ble cr6,0x831a5968
	if (!cr6.gt) goto loc_831A5968;
	// cmpwi cr6,r6,57
	cr6.compare<int32_t>(ctx.r6.s32, 57, xer);
	// bgt cr6,0x831a5974
	if (cr6.gt) goto loc_831A5974;
loc_831A5950:
	// li r10,2
	ctx.r10.s64 = 2;
	// b 0x831a596c
	goto loc_831A596C;
loc_831A5958:
	// cmpwi cr6,r6,66
	cr6.compare<int32_t>(ctx.r6.s32, 66, xer);
	// blt cr6,0x831a5974
	if (cr6.lt) goto loc_831A5974;
	// cmpwi cr6,r6,72
	cr6.compare<int32_t>(ctx.r6.s32, 72, xer);
	// bgt cr6,0x831a5974
	if (cr6.gt) goto loc_831A5974;
loc_831A5968:
	// li r10,1
	ctx.r10.s64 = 1;
loc_831A596C:
	// stw r11,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, r11.u32);
	// stw r10,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r10.u32);
loc_831A5974:
	// li r8,4
	ctx.r8.s64 = 4;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r25,r30,r27
	r25.u64 = r30.u64 + r27.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// li r22,0
	r22.s64 = 0;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,20(r24)
	PPC_STORE_U32(r24.u32 + 20, r11.u32);
	// beq cr6,0x831a59f8
	if (cr6.eq) goto loc_831A59F8;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x831a59fc
	goto loc_831A59FC;
loc_831A59C0:
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, r11.u32);
	// stw r10,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r10.u32);
	// b 0x831a596c
	goto loc_831A596C;
loc_831A59D0:
	// cmpwi cr6,r6,80
	cr6.compare<int32_t>(ctx.r6.s32, 80, xer);
	// blt cr6,0x831a5974
	if (cr6.lt) goto loc_831A5974;
	// cmpwi cr6,r6,81
	cr6.compare<int32_t>(ctx.r6.s32, 81, xer);
	// ble cr6,0x831a5968
	if (!cr6.gt) goto loc_831A5968;
	// cmpwi cr6,r6,96
	cr6.compare<int32_t>(ctx.r6.s32, 96, xer);
	// beq cr6,0x831a59f0
	if (cr6.eq) goto loc_831A59F0;
	// cmpwi cr6,r6,98
	cr6.compare<int32_t>(ctx.r6.s32, 98, xer);
	// bne cr6,0x831a5974
	if (!cr6.eq) goto loc_831A5974;
loc_831A59F0:
	// li r11,1
	r11.s64 = 1;
	// b 0x831a58e0
	goto loc_831A58E0;
loc_831A59F8:
	// li r27,0
	r27.s64 = 0;
loc_831A59FC:
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x831a5b08
	if (cr6.eq) goto loc_831A5B08;
	// li r28,0
	r28.s64 = 0;
loc_831A5A0C:
	// lwz r11,32(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 32);
	// srw r11,r11,r28
	r11.u64 = r28.u8 & 0x20 ? 0 : (r11.u32 >> (r28.u8 & 0x3F));
	// clrlwi r11,r11,29
	r11.u64 = r11.u32 & 0x7;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831a5b08
	if (cr6.lt) goto loc_831A5B08;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// blt cr6,0x831a5a40
	if (cr6.lt) goto loc_831A5A40;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// blt cr6,0x831ad2cc
	if (cr6.lt) goto loc_831AD2CC;
	// beq cr6,0x831a5af8
	if (cr6.eq) goto loc_831A5AF8;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A5A40:
	// clrlwi. r10,r26,24
	ctx.r10.u64 = r26.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// bne 0x831a5a50
	if (!cr0.eq) goto loc_831A5A50;
	// addi r30,r11,-1
	r30.s64 = r11.s64 + -1;
loc_831A5A50:
	// cmplw cr6,r30,r27
	cr6.compare<uint32_t>(r30.u32, r27.u32, xer);
	// bge cr6,0x831ad2e0
	if (!cr6.lt) goto loc_831AD2E0;
	// lwz r9,164(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r10,r17,17
	ctx.r10.s64 = r17.s64 + 17;
	// stw r24,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r24.u32);
	// rlwimi r9,r11,2,16,29
	ctx.r9.u64 = (rotl32(r11.u32, 2) & 0xFFFC) | (ctx.r9.u64 & 0xFFFFFFFFFFFF0003);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r9,0,15,29
	r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1FFFC;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// lwzx r10,r10,r14
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r14.u32);
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r11.u32);
	// rlwinm. r10,r10,0,11,11
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a5ab8
	if (cr0.eq) goto loc_831A5AB8;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// lwz r11,164(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwinm r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// stw r3,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r3.u32);
	// rlwimi r9,r10,0,27,31
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 0) & 0x1F) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFE0);
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r11.u32);
loc_831A5AB8:
	// li r11,1
	r11.s64 = 1;
	// lwz r10,48(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 48);
	// slw r11,r11,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (r11.u32 << (r30.u8 & 0x3F));
	// or r22,r11,r22
	r22.u64 = r11.u64 | r22.u64;
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// bne cr6,0x831a5adc
	if (!cr6.eq) goto loc_831A5ADC;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x831a5adc
	if (cr6.eq) goto loc_831A5ADC;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
loc_831A5ADC:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,2440
	ctx.r3.s64 = ctx.r1.s64 + 2440;
	// bl 0x8319ae60
	sub_8319AE60(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,160(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// bl 0x8319fa18
	sub_8319FA18(ctx, base);
loc_831A5AF8:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,3
	r28.s64 = r28.s64 + 3;
	// cmplw cr6,r29,r21
	cr6.compare<uint32_t>(r29.u32, r21.u32, xer);
	// blt cr6,0x831a5a0c
	if (cr6.lt) goto loc_831A5A0C;
loc_831A5B08:
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831a5b74
	if (cr6.eq) goto loc_831A5B74;
	// li r30,0
	r30.s64 = 0;
loc_831A5B18:
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,1736
	ctx.r4.s64 = ctx.r1.s64 + 1736;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// addi r11,r1,352
	r11.s64 = ctx.r1.s64 + 352;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwzx r4,r30,r11
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// rlwimi r10,r11,25,4,6
	ctx.r10.u64 = (rotl32(r11.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r10.u32);
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// blt cr6,0x831a5b18
	if (cr6.lt) goto loc_831A5B18;
loc_831A5B74:
	// clrlwi. r11,r23,24
	r11.u64 = r23.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a5c24
	if (cr0.eq) goto loc_831A5C24;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwz r5,44(r24)
	ctx.r5.u64 = PPC_LOAD_U32(r24.u32 + 44);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// blt cr6,0x831a5ba4
	if (cr6.lt) goto loc_831A5BA4;
	// cmplwi cr6,r11,82
	cr6.compare<uint32_t>(r11.u32, 82, xer);
	// bgt cr6,0x831a5ba4
	if (cr6.gt) goto loc_831A5BA4;
	// li r23,1
	r23.s64 = 1;
	// mr r11,r23
	r11.u64 = r23.u64;
	// b 0x831a5bac
	goto loc_831A5BAC;
loc_831A5BA4:
	// li r11,0
	r11.s64 = 0;
	// li r23,1
	r23.s64 = 1;
loc_831A5BAC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a5c14
	if (cr0.eq) goto loc_831A5C14;
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm r10,r11,7,29,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 7) & 0x7;
	// addic. r9,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r9.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831a5be4
	if (cr0.eq) goto loc_831A5BE4;
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// bne cr6,0x831ad2fc
	if (!cr6.eq) goto loc_831AD2FC;
	// rlwinm r10,r11,25,30,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x3;
	// li r9,224
	ctx.r9.s64 = 224;
	// rlwinm r11,r11,0,27,21
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFC1F;
	// rlwimi r9,r10,2,27,29
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 2) & 0x1C) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFE3);
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// b 0x831a5c04
	goto loc_831A5C04;
loc_831A5BE4:
	// lis r10,32
	ctx.r10.s64 = 2097152;
	// rlwinm r9,r11,27,30,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x3;
	// ori r10,r10,224
	ctx.r10.u64 = ctx.r10.u64 | 224;
	// lis r12,-2561
	r12.s64 = -167837696;
	// rlwimi r10,r9,2,27,29
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 2) & 0x1C) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFE3);
	// ori r12,r12,64543
	r12.u64 = r12.u64 | 64543;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// and r11,r11,r12
	r11.u64 = r11.u64 & r12.u64;
loc_831A5C04:
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// b 0x831a5c28
	goto loc_831A5C28;
loc_831A5C14:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// b 0x831a5c28
	goto loc_831A5C28;
loc_831A5C24:
	// li r23,1
	r23.s64 = 1;
loc_831A5C28:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// rlwinm r10,r24,0,0,30
	ctx.r10.u64 = rotl64(r24.u32 | (r24.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// addi r26,r10,36
	r26.s64 = ctx.r10.s64 + 36;
	// addi r10,r11,-36
	ctx.r10.s64 = r11.s64 + -36;
	// addi r9,r26,-36
	ctx.r9.s64 = r26.s64 + -36;
	// ori r8,r10,1
	ctx.r8.u64 = ctx.r10.u64 | 1;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r10,r26,4
	ctx.r10.s64 = r26.s64 + 4;
	// stw r7,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// stw r8,4(r26)
	PPC_STORE_U32(r26.u32 + 4, ctx.r8.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmpwi cr6,r4,94
	cr6.compare<int32_t>(ctx.r4.s32, 94, xer);
	// beq cr6,0x831a5e9c
	if (cr6.eq) goto loc_831A5E9C;
	// cmpwi cr6,r4,96
	cr6.compare<int32_t>(ctx.r4.s32, 96, xer);
	// beq cr6,0x831a5d18
	if (cr6.eq) goto loc_831A5D18;
	// cmpwi cr6,r4,97
	cr6.compare<int32_t>(ctx.r4.s32, 97, xer);
	// beq cr6,0x831a5cb4
	if (cr6.eq) goto loc_831A5CB4;
	// cmpwi cr6,r4,98
	cr6.compare<int32_t>(ctx.r4.s32, 98, xer);
	// ble cr6,0x831a5c94
	if (!cr6.gt) goto loc_831A5C94;
	// cmpwi cr6,r4,100
	cr6.compare<int32_t>(ctx.r4.s32, 100, xer);
	// ble cr6,0x831a5cb4
	if (!cr6.gt) goto loc_831A5CB4;
loc_831A5C94:
	// lwz r11,112(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 112);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a5f50
	if (cr6.eq) goto loc_831A5F50;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3704
	ctx.r5.s64 = r11.s64 + 3704;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A5CB4:
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// addi r10,r24,-24
	ctx.r10.s64 = r24.s64 + -24;
	// stb r11,105(r1)
	PPC_STORE_U8(ctx.r1.u32 + 105, r11.u8);
	// lis r11,-31984
	r11.s64 = -2096103424;
	// add r30,r3,r10
	r30.u64 = ctx.r3.u64 + ctx.r10.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// addi r6,r11,-11440
	ctx.r6.s64 = r11.s64 + -11440;
	// addi r5,r1,105
	ctx.r5.s64 = ctx.r1.s64 + 105;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x8304cdb8
	sub_8304CDB8(ctx, base);
	// lbz r11,105(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 105);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831a5db8
	if (cr0.eq) goto loc_831A5DB8;
	// addi r7,r30,20
	ctx.r7.s64 = r30.s64 + 20;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a1f20
	sub_831A1F20(ctx, base);
	// b 0x831a5db8
	goto loc_831A5DB8;
loc_831A5D18:
	// lwz r29,52(r14)
	r29.u64 = PPC_LOAD_U32(r14.u32 + 52);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r29,2
	cr6.compare<uint32_t>(r29.u32, 2, xer);
	// bgt cr6,0x831ad308
	if (cr6.gt) goto loc_831AD308;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// addi r10,r24,-20
	ctx.r10.s64 = r24.s64 + -20;
	// stb r11,104(r1)
	PPC_STORE_U8(ctx.r1.u32 + 104, r11.u8);
	// lis r11,-31984
	r11.s64 = -2096103424;
	// add r30,r3,r10
	r30.u64 = ctx.r3.u64 + ctx.r10.u64;
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// addi r8,r11,-11440
	ctx.r8.s64 = r11.s64 + -11440;
	// addi r7,r1,104
	ctx.r7.s64 = ctx.r1.s64 + 104;
	// addi r6,r1,552
	ctx.r6.s64 = ctx.r1.s64 + 552;
	// addi r5,r1,536
	ctx.r5.s64 = ctx.r1.s64 + 536;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x8304c8c0
	sub_8304C8C0(ctx, base);
	// lwz r11,536(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	// stb r11,15(r30)
	PPC_STORE_U8(r30.u32 + 15, r11.u8);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r11,552(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	// rlwimi r10,r11,16,15,15
	ctx.r10.u64 = (rotl32(r11.u32, 16) & 0x10000) | (ctx.r10.u64 & 0xFFFFFFFFFFFEFFFF);
	// stw r10,12(r30)
	PPC_STORE_U32(r30.u32 + 12, ctx.r10.u32);
	// lbz r11,104(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 104);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831a5da4
	if (cr0.eq) goto loc_831A5DA4;
	// addi r7,r30,16
	ctx.r7.s64 = r30.s64 + 16;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a1f20
	sub_831A1F20(ctx, base);
loc_831A5DA4:
	// cmplwi cr6,r29,2
	cr6.compare<uint32_t>(r29.u32, 2, xer);
	// bne cr6,0x831a5f50
	if (!cr6.eq) goto loc_831A5F50;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// stw r11,8(r24)
	PPC_STORE_U32(r24.u32 + 8, r11.u32);
loc_831A5DB8:
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831a5e18
	if (cr6.eq) goto loc_831A5E18;
	// addi r30,r1,296
	r30.s64 = ctx.r1.s64 + 296;
loc_831A5DC8:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831ad310
	if (cr6.eq) goto loc_831AD310;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// bne cr6,0x831ad310
	if (!cr6.eq) goto loc_831AD310;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83195760
	sub_83195760(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r3,40
	ctx.r10.s64 = ctx.r3.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,0,25,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x70;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x831a5e18
	if (cr6.eq) goto loc_831A5E18;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// blt cr6,0x831a5dc8
	if (cr6.lt) goto loc_831A5DC8;
loc_831A5E18:
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// beq cr6,0x831ad31c
	if (cr6.eq) goto loc_831AD31C;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r10,r11,0,18,24
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r10,12288
	cr6.compare<uint32_t>(ctx.r10.u32, 12288, xer);
	// bne cr6,0x831a5e44
	if (!cr6.eq) goto loc_831A5E44;
	// rlwinm r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	// lis r10,8
	ctx.r10.s64 = 524288;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// mr r11,r23
	r11.u64 = r23.u64;
	// bgt cr6,0x831a5e48
	if (cr6.gt) goto loc_831A5E48;
loc_831A5E44:
	// li r11,0
	r11.s64 = 0;
loc_831A5E48:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// beq cr6,0x831a5e78
	if (cr6.eq) goto loc_831A5E78;
	// lwz r11,48(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 48);
	// lwz r10,44(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 44);
	// stw r20,296(r1)
	PPC_STORE_U32(ctx.r1.u32 + 296, r20.u32);
	// stw r19,300(r1)
	PPC_STORE_U32(ctx.r1.u32 + 300, r19.u32);
	// stw r11,44(r24)
	PPC_STORE_U32(r24.u32 + 44, r11.u32);
	// stw r10,48(r24)
	PPC_STORE_U32(r24.u32 + 48, ctx.r10.u32);
loc_831A5E78:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,12800
	cr6.compare<uint32_t>(r11.u32, 12800, xer);
	// bne cr6,0x831a5f50
	if (!cr6.eq) goto loc_831A5F50;
	// lwz r11,48(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 48);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r23,26,4,6
	ctx.r10.u64 = (rotl32(r23.u32, 26) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x831a5f50
	goto loc_831A5F50;
loc_831A5E9C:
	// lwz r11,112(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 112);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad42c
	if (cr6.eq) goto loc_831AD42C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad42c
	if (!cr6.eq) goto loc_831AD42C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad420
	if (cr6.eq) goto loc_831AD420;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x831ad420
	if (!cr6.eq) goto loc_831AD420;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x831ad328
	if (!cr6.eq) goto loc_831AD328;
	// lfd f0,24(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// fctidz f13,f0
	ctx.f13.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f13,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.f13.u64);
	// lwz r30,100(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// blt cr6,0x831ad414
	if (cr6.lt) goto loc_831AD414;
	// cmplwi cr6,r30,5
	cr6.compare<uint32_t>(r30.u32, 5, xer);
	// bgt cr6,0x831ad414
	if (cr6.gt) goto loc_831AD414;
	// clrldi r11,r30,32
	r11.u64 = r30.u64 & 0xFFFFFFFF;
	// std r11,1232(r1)
	PPC_STORE_U64(ctx.r1.u32 + 1232, r11.u64);
	// lfd f13,1232(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1232);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x831ad414
	if (!cr6.eq) goto loc_831AD414;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,94
	ctx.r4.s64 = 94;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r24,-12
	r11.s64 = r24.s64 + -12;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r30,r10,0,0,28
	r30.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFF8) | (r30.u64 & 0xFFFFFFFF00000007);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x83117ff8
	sub_83117FF8(ctx, base);
loc_831A5F50:
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831a603c
	if (cr6.eq) goto loc_831A603C;
	// addi r28,r1,296
	r28.s64 = ctx.r1.s64 + 296;
	// addi r27,r24,44
	r27.s64 = r24.s64 + 44;
loc_831A5F64:
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831ad344
	if (cr6.eq) goto loc_831AD344;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// bne cr6,0x831ad344
	if (!cr6.eq) goto loc_831AD344;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83195760
	sub_83195760(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r3,40
	ctx.r10.s64 = ctx.r3.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,0,25,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x70;
	// addi r11,r11,-48
	r11.s64 = r11.s64 + -48;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r30,r11,27,31,31
	r30.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// bl 0x831686d8
	sub_831686D8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a5ffc
	if (cr0.eq) goto loc_831A5FFC;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r10,r11,0,18,24
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r10,12288
	cr6.compare<uint32_t>(ctx.r10.u32, 12288, xer);
	// bne cr6,0x831a5fdc
	if (!cr6.eq) goto loc_831A5FDC;
	// rlwinm r11,r11,0,10,12
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x380000;
	// lis r10,8
	ctx.r10.s64 = 524288;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// mr r11,r23
	r11.u64 = r23.u64;
	// bgt cr6,0x831a5fe0
	if (cr6.gt) goto loc_831A5FE0;
loc_831A5FDC:
	// li r11,0
	r11.s64 = 0;
loc_831A5FE0:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// beq cr6,0x831a6000
	if (cr6.eq) goto loc_831A6000;
loc_831A5FFC:
	// li r10,0
	ctx.r10.s64 = 0;
loc_831A6000:
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x831ad334
	if (!cr6.eq) goto loc_831AD334;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a6028
	if (cr6.eq) goto loc_831A6028;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r23,25,4,6
	ctx.r10.u64 = (rotl32(r23.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_831A6028:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// blt cr6,0x831a5f64
	if (cr6.lt) goto loc_831A5F64;
loc_831A603C:
	// lwz r11,92(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a6094
	if (cr6.eq) goto loc_831A6094;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83122e78
	sub_83122E78(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad350
	if (cr0.eq) goto loc_831AD350;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// oris r10,r11,2
	ctx.r10.u64 = r11.u64 | 131072;
	// stw r10,8(r24)
	PPC_STORE_U32(r24.u32 + 8, ctx.r10.u32);
	// lwz r11,92(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad35c
	if (cr6.eq) goto loc_831AD35C;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r9,28
	cr6.compare<int32_t>(ctx.r9.s32, 28, xer);
	// bne cr6,0x831ad35c
	if (!cr6.eq) goto loc_831AD35C;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// andis. r11,r11,3328
	r11.u64 = r11.u64 & 218103808;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x831a6094
	if (!cr0.eq) goto loc_831A6094;
	// oris r11,r10,4
	r11.u64 = ctx.r10.u64 | 262144;
	// stw r11,8(r24)
	PPC_STORE_U32(r24.u32 + 8, r11.u32);
loc_831A6094:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x831a6160
	if (cr6.eq) goto loc_831A6160;
	// lwz r11,16(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x831a6160
	if (!cr6.eq) goto loc_831A6160;
	// lwz r11,24(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// bne cr6,0x831a60dc
	if (!cr6.eq) goto loc_831A60DC;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r10,r11,0,18,24
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r10,1536
	cr6.compare<uint32_t>(ctx.r10.u32, 1536, xer);
	// bne cr6,0x831ad368
	if (!cr6.eq) goto loc_831AD368;
	// li r10,105
	ctx.r10.s64 = 105;
	// rlwimi r11,r10,7,18,24
	r11.u64 = (rotl32(ctx.r10.u32, 7) & 0x3F80) | (r11.u64 & 0xFFFFFFFFFFFFC07F);
	// stw r11,8(r24)
	PPC_STORE_U32(r24.u32 + 8, r11.u32);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// oris r11,r11,32
	r11.u64 = r11.u64 | 2097152;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
loc_831A60DC:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwz r10,24(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r11,r11,-13440
	r11.s64 = r11.s64 + -13440;
	// rlwimi r5,r10,4,0,27
	ctx.r5.u64 = (rotl32(ctx.r10.u32, 4) & 0xFFFFFFF0) | (ctx.r5.u64 & 0xFFFFFFFF0000000F);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// xori r7,r11,1
	ctx.r7.u64 = r11.u64 ^ 1;
	// bl 0x831cfba8
	sub_831CFBA8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// bl 0x83117ff8
	sub_83117FF8(ctx, base);
loc_831A6160:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,25
	cr6.compare<uint32_t>(r11.u32, 25, xer);
	// blt cr6,0x831a6178
	if (cr6.lt) goto loc_831A6178;
	// cmplwi cr6,r11,28
	cr6.compare<uint32_t>(r11.u32, 28, xer);
	// ble cr6,0x831a6188
	if (!cr6.gt) goto loc_831A6188;
loc_831A6178:
	// cmplwi cr6,r11,67
	cr6.compare<uint32_t>(r11.u32, 67, xer);
	// blt cr6,0x831a6190
	if (cr6.lt) goto loc_831A6190;
	// cmplwi cr6,r11,71
	cr6.compare<uint32_t>(r11.u32, 71, xer);
	// bgt cr6,0x831a6190
	if (cr6.gt) goto loc_831A6190;
loc_831A6188:
	// mr r11,r23
	r11.u64 = r23.u64;
	// b 0x831a6194
	goto loc_831A6194;
loc_831A6190:
	// li r11,0
	r11.s64 = 0;
loc_831A6194:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a61c4
	if (cr0.eq) goto loc_831A61C4;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x831ad374
	if (!cr6.eq) goto loc_831AD374;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83117ff8
	sub_83117FF8(ctx, base);
loc_831A61C4:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x831949f8
	sub_831949F8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a62f0
	if (cr0.eq) goto loc_831A62F0;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a61ec
	if (cr0.eq) goto loc_831A61EC;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r10,r11,7
	ctx.r10.s64 = r11.s64 + 7;
	// b 0x831a61f0
	goto loc_831A61F0;
loc_831A61EC:
	// li r10,723
	ctx.r10.s64 = 723;
loc_831A61F0:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r9,80(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831a6210
	if (cr6.eq) goto loc_831A6210;
	// rotlwi r11,r9,0
	r11.u64 = rotl32(ctx.r9.u32, 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r10,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x831a6214
	goto loc_831A6214;
loc_831A6210:
	// li r4,0
	ctx.r4.s64 = 0;
loc_831A6214:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831ad388
	if (cr6.eq) goto loc_831AD388;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad388
	if (cr6.eq) goto loc_831AD388;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r4,12(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// clrlwi. r10,r11,27
	ctx.r10.u64 = r11.u32 & 0x1F;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a627c
	if (!cr0.eq) goto loc_831A627C;
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm r10,r10,25,25,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r10,32
	cr6.compare<uint32_t>(ctx.r10.u32, 32, xer);
	// blt cr6,0x831a6260
	if (cr6.lt) goto loc_831A6260;
	// cmplwi cr6,r10,82
	cr6.compare<uint32_t>(ctx.r10.u32, 82, xer);
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// ble cr6,0x831a6264
	if (!cr6.gt) goto loc_831A6264;
loc_831A6260:
	// li r10,0
	ctx.r10.s64 = 0;
loc_831A6264:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a627c
	if (cr0.eq) goto loc_831A627C;
	// lwz r10,28(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// lwz r9,564(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x831a62d8
	if (cr6.eq) goto loc_831A62D8;
loc_831A627C:
	// rlwimi r11,r23,26,4,6
	r11.u64 = (rotl32(r23.u32, 26) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// li r10,7168
	ctx.r10.s64 = 7168;
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwimi r10,r11,2,23,24
	ctx.r10.u64 = (rotl32(r11.u32, 2) & 0x180) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFE7F);
	// rlwinm r11,r11,0,25,21
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFC7F;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x8313c900
	sub_8313C900(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// addi r8,r26,-36
	ctx.r8.s64 = r26.s64 + -36;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
loc_831A62D8:
	// li r5,6
	ctx.r5.s64 = 6;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
loc_831A62F0:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r4,97
	cr6.compare<uint32_t>(ctx.r4.u32, 97, xer);
	// beq cr6,0x831a6314
	if (cr6.eq) goto loc_831A6314;
	// cmplwi cr6,r4,99
	cr6.compare<uint32_t>(ctx.r4.u32, 99, xer);
	// beq cr6,0x831a6314
	if (cr6.eq) goto loc_831A6314;
	// cmplwi cr6,r4,100
	cr6.compare<uint32_t>(ctx.r4.u32, 100, xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// bne cr6,0x831a6318
	if (!cr6.eq) goto loc_831A6318;
loc_831A6314:
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
loc_831A6318:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831a6750
	if (cr0.eq) goto loc_831A6750;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r24,-24
	r11.s64 = r24.s64 + -24;
	// add r27,r3,r11
	r27.u64 = ctx.r3.u64 + r11.u64;
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// oris r11,r11,1
	r11.u64 = r11.u64 | 65536;
	// stw r11,12(r27)
	PPC_STORE_U32(r27.u32 + 12, r11.u32);
	// lwz r11,112(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 112);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a6444
	if (cr6.eq) goto loc_831A6444;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831a6444
	if (cr6.eq) goto loc_831A6444;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831A6368:
	// lwz r11,8(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad3c8
	if (cr6.eq) goto loc_831AD3C8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad3c8
	if (!cr6.eq) goto loc_831AD3C8;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831a642c
	if (cr6.eq) goto loc_831A642C;
	// rotlwi r10,r10,0
	ctx.r10.u64 = rotl32(ctx.r10.u32, 0);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// beq cr6,0x831a642c
	if (cr6.eq) goto loc_831A642C;
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x831ad3bc
	if (cr6.eq) goto loc_831AD3BC;
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x831ad3bc
	if (!cr6.eq) goto loc_831AD3BC;
	// lwz r11,16(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x831ad394
	if (!cr6.eq) goto loc_831AD394;
	// lwz r8,24(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 24);
	// lwz r10,568(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
loc_831A63CC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r5,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r5.s64;
	// beq 0x831a63f0
	if (cr0.eq) goto loc_831A63F0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x831a63cc
	if (cr6.eq) goto loc_831A63CC;
loc_831A63F0:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831ad3ac
	if (cr0.eq) goto loc_831AD3AC;
	// lwz r10,584(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
loc_831A6400:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x831a6424
	if (cr0.eq) goto loc_831A6424;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x831a6400
	if (cr6.eq) goto loc_831A6400;
loc_831A6424:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831ad3ac
	if (cr0.eq) goto loc_831AD3AC;
loc_831A642C:
	// lwz r11,12(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a6444
	if (cr6.eq) goto loc_831A6444;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad3a0
	if (!cr6.eq) goto loc_831AD3A0;
loc_831A6444:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// bne cr6,0x831a6368
	if (!cr6.eq) goto loc_831A6368;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// rlwinm. r11,r11,0,2,2
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6554
	if (cr0.eq) goto loc_831A6554;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6474
	if (cr0.eq) goto loc_831A6474;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// b 0x831a6478
	goto loc_831A6478;
loc_831A6474:
	// li r10,722
	ctx.r10.s64 = 722;
loc_831A6478:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r9,80(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831a6498
	if (cr6.eq) goto loc_831A6498;
	// rotlwi r11,r9,0
	r11.u64 = rotl32(ctx.r9.u32, 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r10,r11
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x831a649c
	goto loc_831A649C;
loc_831A6498:
	// li r29,0
	r29.s64 = 0;
loc_831A649C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831ad3d4
	if (cr6.eq) goto loc_831AD3D4;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad3d4
	if (cr6.eq) goto loc_831AD3D4;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b2a8
	sub_8319B2A8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r10,28(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x831a6538
	if (cr6.eq) goto loc_831A6538;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdf00
	sub_831CDF00(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r11.u32);
	// lwz r5,44(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r7,0(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r9,r26,-36
	ctx.r9.s64 = r26.s64 + -36;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// mr r28,r30
	r28.u64 = r30.u64;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// stw r30,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r30.u32);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwimi r11,r23,0,16,14
	r11.u64 = (rotl32(r23.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
loc_831A6538:
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
loc_831A6554:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6750
	if (cr0.eq) goto loc_831A6750;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6578
	if (cr0.eq) goto loc_831A6578;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r10,r11,9
	ctx.r10.s64 = r11.s64 + 9;
	// b 0x831a657c
	goto loc_831A657C;
loc_831A6578:
	// li r10,724
	ctx.r10.s64 = 724;
loc_831A657C:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r9,80(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831a659c
	if (cr6.eq) goto loc_831A659C;
	// rotlwi r11,r9,0
	r11.u64 = rotl32(ctx.r9.u32, 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r10,r11
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x831a65a0
	goto loc_831A65A0;
loc_831A659C:
	// li r29,0
	r29.s64 = 0;
loc_831A65A0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831ad3ec
	if (cr6.eq) goto loc_831AD3EC;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad3ec
	if (cr6.eq) goto loc_831AD3EC;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b2a8
	sub_8319B2A8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r10,28(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x831a663c
	if (cr6.eq) goto loc_831A663C;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdf00
	sub_831CDF00(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r11.u32);
	// lwz r5,44(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r9,0(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// addi r8,r26,-36
	ctx.r8.s64 = r26.s64 + -36;
	// addi r7,r11,-36
	ctx.r7.s64 = r11.s64 + -36;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// mr r28,r30
	r28.u64 = r30.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,0(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r9,r9,0,0,30
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// stw r30,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r30.u32);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwimi r11,r23,0,16,14
	r11.u64 = (rotl32(r23.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
loc_831A663C:
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6670
	if (cr0.eq) goto loc_831A6670;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r10,r11,10
	ctx.r10.s64 = r11.s64 + 10;
	// b 0x831a6674
	goto loc_831A6674;
loc_831A6670:
	// li r10,725
	ctx.r10.s64 = 725;
loc_831A6674:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r9,80(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831a6694
	if (cr6.eq) goto loc_831A6694;
	// rotlwi r11,r9,0
	r11.u64 = rotl32(ctx.r9.u32, 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r10,r11
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x831a6698
	goto loc_831A6698;
loc_831A6694:
	// li r29,0
	r29.s64 = 0;
loc_831A6698:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831ad3e0
	if (cr6.eq) goto loc_831AD3E0;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad3e0
	if (cr6.eq) goto loc_831AD3E0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b2a8
	sub_8319B2A8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r10,28(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x831a6734
	if (cr6.eq) goto loc_831A6734;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdf00
	sub_831CDF00(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r11.u32);
	// lwz r5,44(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r7,0(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// addi r9,r26,-36
	ctx.r9.s64 = r26.s64 + -36;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// mr r28,r30
	r28.u64 = r30.u64;
	// addi r8,r11,-36
	ctx.r8.s64 = r11.s64 + -36;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// stw r30,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r30.u32);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwimi r11,r23,0,16,14
	r11.u64 = (rotl32(r23.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
loc_831A6734:
	// li r5,3
	ctx.r5.s64 = 3;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
loc_831A6750:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,12288
	cr6.compare<uint32_t>(r11.u32, 12288, xer);
	// bne cr6,0x831a6800
	if (!cr6.eq) goto loc_831A6800;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8310ff30
	sub_8310FF30(ctx, base);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6800
	if (cr0.eq) goto loc_831A6800;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6790
	if (cr0.eq) goto loc_831A6790;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r10,r11,11
	ctx.r10.s64 = r11.s64 + 11;
	// b 0x831a6794
	goto loc_831A6794;
loc_831A6790:
	// li r10,726
	ctx.r10.s64 = 726;
loc_831A6794:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r9,80(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831a67b4
	if (cr6.eq) goto loc_831A67B4;
	// rotlwi r11,r9,0
	r11.u64 = rotl32(ctx.r9.u32, 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r10,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x831a67b8
	goto loc_831A67B8;
loc_831A67B4:
	// li r4,0
	ctx.r4.s64 = 0;
loc_831A67B8:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831ad408
	if (cr6.eq) goto loc_831AD408;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad408
	if (cr6.eq) goto loc_831AD408;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b2a8
	sub_8319B2A8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,28(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x831ad3f8
	if (!cr6.eq) goto loc_831AD3F8;
	// li r5,4
	ctx.r5.s64 = 4;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
loc_831A6800:
	// lwz r30,8(r24)
	r30.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm. r11,r30,26,31,31
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a68f8
	if (cr0.eq) goto loc_831A68F8;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8310f9d0
	sub_8310F9D0(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a683c
	if (cr0.eq) goto loc_831A683C;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6834
	if (cr0.eq) goto loc_831A6834;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r4,r11,6
	ctx.r4.s64 = r11.s64 + 6;
	// b 0x831a68dc
	goto loc_831A68DC;
loc_831A6834:
	// li r4,720
	ctx.r4.s64 = 720;
	// b 0x831a68dc
	goto loc_831A68DC;
loc_831A683C:
	// rlwinm r11,r30,25,25,31
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,98
	cr6.compare<uint32_t>(r11.u32, 98, xer);
	// bne cr6,0x831a6868
	if (!cr6.eq) goto loc_831A6868;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6860
	if (cr0.eq) goto loc_831A6860;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r4,r11,8
	ctx.r4.s64 = r11.s64 + 8;
	// b 0x831a68dc
	goto loc_831A68DC;
loc_831A6860:
	// li r4,722
	ctx.r4.s64 = 722;
	// b 0x831a68dc
	goto loc_831A68DC;
loc_831A6868:
	// cmplwi cr6,r11,101
	cr6.compare<uint32_t>(r11.u32, 101, xer);
	// bne cr6,0x831a6890
	if (!cr6.eq) goto loc_831A6890;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6888
	if (cr0.eq) goto loc_831A6888;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r4,r11,9
	ctx.r4.s64 = r11.s64 + 9;
	// b 0x831a68dc
	goto loc_831A68DC;
loc_831A6888:
	// li r4,724
	ctx.r4.s64 = 724;
	// b 0x831a68dc
	goto loc_831A68DC;
loc_831A6890:
	// cmplwi cr6,r11,102
	cr6.compare<uint32_t>(r11.u32, 102, xer);
	// bne cr6,0x831a68b8
	if (!cr6.eq) goto loc_831A68B8;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a68b0
	if (cr0.eq) goto loc_831A68B0;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r4,r11,10
	ctx.r4.s64 = r11.s64 + 10;
	// b 0x831a68dc
	goto loc_831A68DC;
loc_831A68B0:
	// li r4,725
	ctx.r4.s64 = 725;
	// b 0x831a68dc
	goto loc_831A68DC;
loc_831A68B8:
	// cmplwi cr6,r11,96
	cr6.compare<uint32_t>(r11.u32, 96, xer);
	// bne cr6,0x831a68f8
	if (!cr6.eq) goto loc_831A68F8;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a68d8
	if (cr0.eq) goto loc_831A68D8;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r4,r11,11
	ctx.r4.s64 = r11.s64 + 11;
	// b 0x831a68dc
	goto loc_831A68DC;
loc_831A68D8:
	// li r4,726
	ctx.r4.s64 = 726;
loc_831A68DC:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x83199928
	sub_83199928(ctx, base);
	// stw r24,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r24.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwimi r11,r23,0,16,14
	r11.u64 = (rotl32(r23.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
loc_831A68F8:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// blt cr6,0x831a6914
	if (cr6.lt) goto loc_831A6914;
	// cmplwi cr6,r11,82
	cr6.compare<uint32_t>(r11.u32, 82, xer);
	// mr r11,r23
	r11.u64 = r23.u64;
	// ble cr6,0x831a6918
	if (!cr6.gt) goto loc_831A6918;
loc_831A6914:
	// li r11,0
	r11.s64 = 0;
loc_831A6918:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a69a0
	if (cr0.eq) goto loc_831A69A0;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6938
	if (cr0.eq) goto loc_831A6938;
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// addi r4,r11,7
	ctx.r4.s64 = r11.s64 + 7;
	// b 0x831a693c
	goto loc_831A693C;
loc_831A6938:
	// li r4,723
	ctx.r4.s64 = 723;
loc_831A693C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x83199928
	sub_83199928(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r10,r17,17
	ctx.r10.s64 = r17.s64 + 17;
	// li r11,1
	r11.s64 = 1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r24,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r24.u32);
	// lwz r9,4(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r9,r11,0,16,14
	ctx.r9.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r9.u64 & 0x10000);
	// stw r9,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r9.u32);
	// lwzx r11,r10,r14
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r14.u32);
	// rlwinm. r11,r11,0,11,11
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x100000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a69a0
	if (cr0.eq) goto loc_831A69A0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r11,1
	r11.s64 = 1;
	// rlwimi r10,r11,0,27,31
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0x1F) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFE0);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,1,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 1) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
loc_831A69A0:
	// addi r17,r17,1
	r17.s64 = r17.s64 + 1;
	// cmplwi cr6,r17,2
	cr6.compare<uint32_t>(r17.u32, 2, xer);
	// blt cr6,0x831a5450
	if (cr6.lt) goto loc_831A5450;
loc_831A69AC:
	// cmplwi r16,0
	cr0.compare<uint32_t>(r16.u32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// addi r3,r1,3144
	ctx.r3.s64 = ctx.r1.s64 + 3144;
loc_831A69BC:
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
loc_831A69C0:
	// bl 0x8319a860
	sub_8319A860(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831A69C8:
	// lwz r11,24(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 24);
	// clrlwi. r25,r22,24
	r25.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// lwz r9,20(r14)
	ctx.r9.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// mullw r29,r11,r9
	r29.s64 = int64_t(r11.s32) * int64_t(ctx.r9.s32);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// beq 0x831a6a0c
	if (cr0.eq) goto loc_831A6A0C;
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831a6a0c
	if (cr6.eq) goto loc_831A6A0C;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// ble cr6,0x831ad438
	if (!cr6.gt) goto loc_831AD438;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// ble cr6,0x831a6a0c
	if (!cr6.gt) goto loc_831A6A0C;
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// ble cr6,0x831ad438
	if (!cr6.gt) goto loc_831AD438;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bgt cr6,0x831ad438
	if (cr6.gt) goto loc_831AD438;
loc_831A6A0C:
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// cmplwi cr6,r11,33
	cr6.compare<uint32_t>(r11.u32, 33, xer);
	// bgt cr6,0x831ad850
	if (cr6.gt) goto loc_831AD850;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,2656
	r12.s64 = r12.s64 + 2656;
	// rlwinm r0,r11,1,0,30
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31974
	r12.s64 = -2095448064;
	// addi r12,r12,27200
	r12.s64 = r12.s64 + 27200;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_831A6A5C;
	case 1:
		goto loc_831A6A40;
	case 2:
		goto loc_831A6F04;
	case 3:
		goto loc_831A6F04;
	case 4:
		goto loc_831A6E4C;
	case 5:
		goto loc_831A6E44;
	case 6:
		goto loc_831AD850;
	case 7:
		goto loc_831ACAEC;
	case 8:
		goto loc_831A7364;
	case 9:
		goto loc_831A7364;
	case 10:
		goto loc_831A70F8;
	case 11:
		goto loc_831A7364;
	case 12:
		goto loc_831A7364;
	case 13:
		goto loc_831ACB94;
	case 14:
		goto loc_831ACB9C;
	case 15:
		goto loc_831A7364;
	case 16:
		goto loc_831A7364;
	case 17:
		goto loc_831A7364;
	case 18:
		goto loc_831A7364;
	case 19:
		goto loc_831A7364;
	case 20:
		goto loc_831A7364;
	case 21:
		goto loc_831ACBA4;
	case 22:
		goto loc_831ACBAC;
	case 23:
		goto loc_831ACBB4;
	case 24:
		goto loc_831A7364;
	case 25:
		goto loc_831A7364;
	case 26:
		goto loc_831A702C;
	case 27:
		goto loc_831A702C;
	case 28:
		goto loc_831A784C;
	case 29:
		goto loc_831A6C34;
	case 30:
		goto loc_831A7D08;
	case 31:
		goto loc_831AC638;
	case 32:
		goto loc_831A7DF4;
	case 33:
		goto loc_831AC57C;
	default:
		__builtin_unreachable();
	}
loc_831A6A40:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,36(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// addi r3,r1,3160
	ctx.r3.s64 = ctx.r1.s64 + 3160;
	// b 0x831a69bc
	goto loc_831A69BC;
loc_831A6A5C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,32(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// cmplw cr6,r27,r29
	cr6.compare<uint32_t>(r27.u32, r29.u32, xer);
	// beq cr6,0x831a6bec
	if (cr6.eq) goto loc_831A6BEC;
	// bge cr6,0x831a6abc
	if (!cr6.lt) goto loc_831A6ABC;
	// cmplwi cr6,r27,1
	cr6.compare<uint32_t>(r27.u32, 1, xer);
	// bne cr6,0x831ad444
	if (!cr6.eq) goto loc_831AD444;
	// lwz r26,3500(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r3,r1,2216
	ctx.r3.s64 = ctx.r1.s64 + 2216;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// li r30,1
	r30.s64 = 1;
loc_831A6A98:
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,2216
	ctx.r5.s64 = ctx.r1.s64 + 2216;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19f8
	sub_831A19F8(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// blt cr6,0x831a6a98
	if (cr6.lt) goto loc_831A6A98;
	// b 0x831a6bf0
	goto loc_831A6BF0;
loc_831A6ABC:
	// lwz r11,20(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a6bd0
	if (cr6.eq) goto loc_831A6BD0;
	// lwz r4,32(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a6b04
	if (!cr6.eq) goto loc_831A6B04;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a6aec
	if (cr6.eq) goto loc_831A6AEC;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831a6b14
	goto loc_831A6B14;
loc_831A6AEC:
	// addi r6,r1,180
	ctx.r6.s64 = ctx.r1.s64 + 180;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r5,r1,276
	ctx.r5.s64 = ctx.r1.s64 + 276;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831a6b14
	goto loc_831A6B14;
loc_831A6B04:
	// addi r6,r1,180
	ctx.r6.s64 = ctx.r1.s64 + 180;
	// addi r5,r1,276
	ctx.r5.s64 = ctx.r1.s64 + 276;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831A6B14:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6bd0
	if (cr0.eq) goto loc_831A6BD0;
	// lwz r11,20(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// lwz r10,276(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x831ad450
	if (cr6.gt) goto loc_831AD450;
	// lwz r11,24(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 24);
	// lwz r10,180(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x831ad450
	if (cr6.gt) goto loc_831AD450;
	// bge cr6,0x831a6bd0
	if (!cr6.lt) goto loc_831A6BD0;
	// lwz r26,3500(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// addi r3,r1,1344
	ctx.r3.s64 = ctx.r1.s64 + 1344;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// lwz r11,20(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x831a6bd4
	if (!cr6.gt) goto loc_831A6BD4;
	// lwz r11,24(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 24);
loc_831A6B68:
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a6bbc
	if (cr6.eq) goto loc_831A6BBC;
loc_831A6B74:
	// mullw r11,r28,r11
	r11.s64 = int64_t(r28.s32) * int64_t(r11.s32);
	// add r4,r11,r30
	ctx.r4.u64 = r11.u64 + r30.u64;
	// addi r3,r1,1344
	ctx.r3.s64 = ctx.r1.s64 + 1344;
	// bl 0x8319ae60
	sub_8319AE60(ctx, base);
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mullw r11,r28,r11
	r11.s64 = int64_t(r28.s32) * int64_t(r11.s32);
	// add r4,r11,r30
	ctx.r4.u64 = r11.u64 + r30.u64;
	// addi r3,r1,1344
	ctx.r3.s64 = ctx.r1.s64 + 1344;
	// bl 0x8319ae60
	sub_8319AE60(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,4(r24)
	PPC_STORE_U32(r24.u32 + 4, r11.u32);
	// lwz r11,24(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 24);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x831a6b74
	if (cr6.lt) goto loc_831A6B74;
loc_831A6BBC:
	// lwz r10,20(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// blt cr6,0x831a6b68
	if (cr6.lt) goto loc_831A6B68;
	// b 0x831a6bd4
	goto loc_831A6BD4;
loc_831A6BD0:
	// lwz r26,3500(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
loc_831A6BD4:
	// subf. r5,r29,r27
	ctx.r5.s64 = r27.s64 - r29.s64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x831a6bf0
	if (cr0.eq) goto loc_831A6BF0;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,3104
	ctx.r3.s64 = ctx.r1.s64 + 3104;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
	// b 0x831a6bf0
	goto loc_831A6BF0;
loc_831A6BEC:
	// lwz r26,3500(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
loc_831A6BF0:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x831a534c
	if (!cr6.eq) goto loc_831A534C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,16(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 16);
	// bl 0x831a1e20
	sub_831A1E20(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a6c20
	if (cr0.eq) goto loc_831A6C20;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lwz r4,16(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 16);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2f48
	sub_831A2F48(ctx, base);
loc_831A6C20:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
loc_831A6C24:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
loc_831A6C28:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f8e8
	sub_8319F8E8(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831A6C34:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,32(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// lwz r28,36(r14)
	r28.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// bne cr6,0x831a6cf0
	if (!cr6.eq) goto loc_831A6CF0;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x831ad45c
	if (!cr6.eq) goto loc_831AD45C;
	// lwz r27,3500(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r3,r1,2568
	ctx.r3.s64 = ctx.r1.s64 + 2568;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,1768
	ctx.r3.s64 = ctx.r1.s64 + 1768;
	// subf r5,r11,r30
	ctx.r5.s64 = r30.s64 - r11.s64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r28,r29
	r28.u64 = r29.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a6cc4
	if (cr6.eq) goto loc_831A6CC4;
loc_831A6C94:
	// addi r3,r1,1768
	ctx.r3.s64 = ctx.r1.s64 + 1768;
	// addi r28,r28,-1
	r28.s64 = r28.s64 + -1;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r3,r1,2568
	ctx.r3.s64 = ctx.r1.s64 + 2568;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// bne cr6,0x831a6c94
	if (!cr6.eq) goto loc_831A6C94;
loc_831A6CC4:
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// ble cr6,0x831a6ce0
	if (!cr6.gt) goto loc_831A6CE0;
	// subf. r5,r29,r30
	ctx.r5.s64 = r30.s64 - r29.s64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x831a6ce0
	if (cr0.eq) goto loc_831A6CE0;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,2720
	ctx.r3.s64 = ctx.r1.s64 + 2720;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831A6CE0:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x831a534c
	if (!cr6.eq) goto loc_831A534C;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// b 0x831a6c24
	goto loc_831A6C24;
loc_831A6CF0:
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x831ad4b0
	if (cr0.eq) goto loc_831AD4B0;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831ad4b0
	if (!cr6.eq) goto loc_831AD4B0;
	// lwz r24,3500(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r3,r1,1368
	ctx.r3.s64 = ctx.r1.s64 + 1368;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// ble cr6,0x831a6d30
	if (!cr6.gt) goto loc_831A6D30;
	// rlwinm r11,r30,1,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// subf r26,r29,r11
	r26.s64 = r11.s64 - r29.s64;
	// b 0x831a6d5c
	goto loc_831A6D5C;
loc_831A6D30:
	// bge cr6,0x831a6d54
	if (!cr6.lt) goto loc_831A6D54;
	// subf r27,r30,r29
	r27.s64 = r29.s64 - r30.s64;
loc_831A6D38:
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,1368
	ctx.r5.s64 = ctx.r1.s64 + 1368;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19f8
	sub_831A19F8(ctx, base);
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// bne 0x831a6d38
	if (!cr0.eq) goto loc_831A6D38;
loc_831A6D54:
	// mr r26,r30
	r26.u64 = r30.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
loc_831A6D5C:
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,2248
	ctx.r3.s64 = ctx.r1.s64 + 2248;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// addi r5,r1,1368
	ctx.r5.s64 = ctx.r1.s64 + 1368;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19f8
	sub_831A19F8(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,1688
	ctx.r3.s64 = ctx.r1.s64 + 1688;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r27,r29
	r27.u64 = r29.u64;
loc_831A6D90:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831ad468
	if (cr6.eq) goto loc_831AD468;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad498
	if (cr6.eq) goto loc_831AD498;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// bne cr6,0x831ad498
	if (!cr6.eq) goto loc_831AD498;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x831ad474
	if (!cr6.eq) goto loc_831AD474;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplw cr6,r4,r30
	cr6.compare<uint32_t>(ctx.r4.u32, r30.u32, xer);
	// bge cr6,0x831ad480
	if (!cr6.lt) goto loc_831AD480;
	// addi r3,r1,1688
	ctx.r3.s64 = ctx.r1.s64 + 1688;
	// bl 0x8319ae60
	sub_8319AE60(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// addi r3,r1,2248
	ctx.r3.s64 = ctx.r1.s64 + 2248;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a6e04
	if (cr6.eq) goto loc_831A6E04;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad48c
	if (!cr6.eq) goto loc_831AD48C;
loc_831A6E04:
	// mr r28,r11
	r28.u64 = r11.u64;
	// addi r27,r27,-1
	r27.s64 = r27.s64 + -1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a6d90
	if (!cr6.eq) goto loc_831A6D90;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x831ad4a4
	if (!cr6.eq) goto loc_831AD4A4;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831a6e34
	if (cr6.eq) goto loc_831A6E34;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,2944
	ctx.r3.s64 = ctx.r1.s64 + 2944;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831A6E34:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x831a534c
	if (!cr6.eq) goto loc_831A534C;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// b 0x831a6c24
	goto loc_831A6C24;
loc_831A6E44:
	// li r28,4
	r28.s64 = 4;
	// b 0x831a89a0
	goto loc_831A89A0;
loc_831A6E4C:
	// li r5,4
	ctx.r5.s64 = 4;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,448
	ctx.r3.s64 = ctx.r1.s64 + 448;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,452(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// clrlwi r11,r11,15
	r11.u64 = r11.u32 & 0x1FFFF;
	// addi r3,r1,1392
	ctx.r3.s64 = ctx.r1.s64 + 1392;
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// stw r11,452(r1)
	PPC_STORE_U32(ctx.r1.u32 + 452, r11.u32);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// b 0x831a6ef8
	goto loc_831A6EF8;
loc_831A6E90:
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831a6ea0
	if (cr6.lt) goto loc_831A6EA0;
	// li r30,4
	r30.s64 = 4;
loc_831A6EA0:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1392
	ctx.r4.s64 = ctx.r1.s64 + 1392;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r4,r1,448
	ctx.r4.s64 = ctx.r1.s64 + 448;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r30,25,4,6
	ctx.r10.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x83197480
	sub_83197480(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1392
	ctx.r3.s64 = ctx.r1.s64 + 1392;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
loc_831A6EF8:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x831a6e90
	if (!cr6.eq) goto loc_831A6E90;
	// b 0x831a534c
	goto loc_831A534C;
loc_831A6F04:
	// li r5,4
	ctx.r5.s64 = 4;
	// fmr f4,f30
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f30.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f30
	ctx.f3.f64 = f30.f64;
	// addi r3,r1,544
	ctx.r3.s64 = ctx.r1.s64 + 544;
	// fmr f2,f30
	ctx.f2.f64 = f30.f64;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,548(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	// lwz r24,3500(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// clrlwi r11,r11,15
	r11.u64 = r11.u32 & 0x1FFFF;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// addi r3,r1,1416
	ctx.r3.s64 = ctx.r1.s64 + 1416;
	// stw r11,548(r1)
	PPC_STORE_U32(ctx.r1.u32 + 548, r11.u32);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r26,r29
	r26.u64 = r29.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a6e34
	if (cr6.eq) goto loc_831A6E34;
loc_831A6F54:
	// cmplwi cr6,r26,4
	cr6.compare<uint32_t>(r26.u32, 4, xer);
	// mr r30,r26
	r30.u64 = r26.u64;
	// blt cr6,0x831a6f64
	if (cr6.lt) goto loc_831A6F64;
	// li r30,4
	r30.s64 = 4;
loc_831A6F64:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1416
	ctx.r4.s64 = ctx.r1.s64 + 1416;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// subf r26,r30,r26
	r26.s64 = r26.s64 - r30.s64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r4,r1,544
	ctx.r4.s64 = ctx.r1.s64 + 544;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwimi r11,r30,25,4,6
	r11.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x831a6fc8
	if (!cr6.eq) goto loc_831A6FC8;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// lwz r5,12(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
loc_831A6FC8:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a7020
	if (cr6.eq) goto loc_831A7020;
loc_831A6FE4:
	// lwz r11,476(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// addi r3,r1,1416
	ctx.r3.s64 = ctx.r1.s64 + 1416;
	// stw r27,472(r1)
	PPC_STORE_U32(ctx.r1.u32 + 472, r27.u32);
	// rlwimi r11,r28,2,16,29
	r11.u64 = (rotl32(r28.u32, 2) & 0xFFFC) | (r11.u64 & 0xFFFFFFFFFFFF0003);
	// rlwinm r11,r11,0,15,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1FFFC;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,476(r1)
	PPC_STORE_U32(ctx.r1.u32 + 476, r11.u32);
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// ld r5,472(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 472);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319fa18
	sub_8319FA18(ctx, base);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplw cr6,r28,r30
	cr6.compare<uint32_t>(r28.u32, r30.u32, xer);
	// blt cr6,0x831a6fe4
	if (cr6.lt) goto loc_831A6FE4;
loc_831A7020:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x831a6f54
	if (!cr6.eq) goto loc_831A6F54;
	// b 0x831a6e34
	goto loc_831A6E34;
loc_831A702C:
	// lwz r28,3500(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8319f8e8
	sub_8319F8E8(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// rlwinm r5,r29,1,0,30
	ctx.r5.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,2472
	ctx.r3.s64 = ctx.r1.s64 + 2472;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,1832
	ctx.r3.s64 = ctx.r1.s64 + 1832;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r30,r29
	r30.u64 = r29.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a70a8
	if (cr6.eq) goto loc_831A70A8;
loc_831A706C:
	// addi r3,r1,1832
	ctx.r3.s64 = ctx.r1.s64 + 1832;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,2472
	ctx.r3.s64 = ctx.r1.s64 + 2472;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,0(r27)
	ctx.r5.u64 = PPC_LOAD_U64(r27.u32 + 0);
	// bl 0x8319fa18
	sub_8319FA18(ctx, base);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x831a706c
	if (!cr0.eq) goto loc_831A706C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,2736
	ctx.r3.s64 = ctx.r1.s64 + 2736;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831A70A8:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x831a70c0
	if (!cr6.eq) goto loc_831A70C0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f8e8
	sub_8319F8E8(ctx, base);
loc_831A70C0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a534c
	if (!cr0.eq) goto loc_831A534C;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
loc_831A70DC:
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831a534c
	if (!cr0.eq) goto loc_831A534C;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831a70dc
	if (!cr6.eq) goto loc_831A70DC;
	// b 0x831a534c
	goto loc_831A534C;
loc_831A70F8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,16(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 16);
	// bl 0x831a1e20
	sub_831A1E20(ctx, base);
	// clrlwi. r24,r3,24
	r24.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// li r23,0
	r23.s64 = 0;
	// beq 0x831a7128
	if (cr0.eq) goto loc_831A7128;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,16(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 16);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831385c0
	sub_831385C0(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
loc_831A7128:
	// lwz r22,3500(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// rlwinm r5,r29,1,0,30
	ctx.r5.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,1864
	ctx.r3.s64 = ctx.r1.s64 + 1864;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// addi r3,r1,2280
	ctx.r3.s64 = ctx.r1.s64 + 2280;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r25,r29
	r25.u64 = r29.u64;
loc_831A7150:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831a7318
	if (cr6.eq) goto loc_831A7318;
	// addi r3,r1,1864
	ctx.r3.s64 = ctx.r1.s64 + 1864;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r1,2280
	ctx.r3.s64 = ctx.r1.s64 + 2280;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d0e0
	sub_8319D0E0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198af8
	sub_83198AF8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c078
	sub_8319C078(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198f78
	sub_83198F78(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// mr r28,r26
	r28.u64 = r26.u64;
	// beq cr6,0x831a72c4
	if (cr6.eq) goto loc_831A72C4;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x831a0430
	sub_831A0430(ctx, base);
	// mr. r27,r3
	r27.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// ble 0x831a7244
	if (!cr0.gt) goto loc_831A7244;
	// cmpwi cr6,r27,9
	cr6.compare<int32_t>(r27.s32, 9, xer);
	// li r11,1
	r11.s64 = 1;
	// ble cr6,0x831a7248
	if (!cr6.gt) goto loc_831A7248;
loc_831A7244:
	// li r11,0
	r11.s64 = 0;
loc_831A7248:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a72c4
	if (cr0.eq) goto loc_831A72C4;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,103
	ctx.r6.s64 = 103;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cmpwi cr6,r27,2
	cr6.compare<int32_t>(r27.s32, 2, xer);
	// blt cr6,0x831a7284
	if (cr6.lt) goto loc_831A7284;
	// cmpwi cr6,r27,5
	cr6.compare<int32_t>(r27.s32, 5, xer);
	// li r27,1
	r27.s64 = 1;
	// ble cr6,0x831a7288
	if (!cr6.gt) goto loc_831A7288;
loc_831A7284:
	// li r27,0
	r27.s64 = 0;
loc_831A7288:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831687b8
	sub_831687B8(ctx, base);
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
loc_831A72C4:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198db0
	sub_83198DB0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c5d8
	sub_8319C5D8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198bd8
	sub_83198BD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// li r11,1
	r11.s64 = 1;
	// addi r25,r25,-1
	r25.s64 = r25.s64 + -1;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// b 0x831a7150
	goto loc_831A7150;
loc_831A7318:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a7330
	if (cr6.eq) goto loc_831A7330;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// addi r3,r1,3056
	ctx.r3.s64 = ctx.r1.s64 + 3056;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831A7330:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,36
	ctx.r5.s64 = 36;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83118478
	sub_83118478(ctx, base);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
loc_831A7350:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,16(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// bl 0x831a2f48
	sub_831A2F48(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831A7364:
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// rlwinm r19,r29,1,0,30
	r19.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// lwz r11,40(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 40);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831a73b0
	if (!cr6.eq) goto loc_831A73B0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r6,r1,224
	ctx.r6.s64 = ctx.r1.s64 + 224;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319dfa8
	sub_8319DFA8(ctx, base);
loc_831A73B0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r22,196(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lwz r21,200(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	// lwz r4,16(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 16);
	// bl 0x831a1e20
	sub_831A1E20(ctx, base);
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// li r20,0
	r20.s64 = 0;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x831a73e0
	if (cr6.eq) goto loc_831A73E0;
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// bne cr6,0x831a7578
	if (!cr6.eq) goto loc_831A7578;
loc_831A73E0:
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// bne cr6,0x831a7414
	if (!cr6.eq) goto loc_831A7414;
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,192
	ctx.r5.s64 = ctx.r1.s64 + 192;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19f8
	sub_831A19F8(ctx, base);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19f8
	sub_831A19F8(ctx, base);
loc_831A7414:
	// clrlwi. r23,r18,24
	r23.u64 = r18.u32 & 0xFF;
	cr0.compare<int32_t>(r23.s32, 0, xer);
	// beq 0x831a7434
	if (cr0.eq) goto loc_831A7434;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,16(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 16);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831385c0
	sub_831385C0(ctx, base);
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
loc_831A7434:
	// lwz r25,228(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// mr r26,r29
	r26.u64 = r29.u64;
	// lwz r24,232(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a7570
	if (cr6.eq) goto loc_831A7570;
loc_831A7448:
	// lwz r11,232(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	// addi r26,r26,-1
	r26.s64 = r26.s64 + -1;
	// lwz r10,228(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r27,r11,r10
	r27.u64 = r11.u64 + ctx.r10.u64;
	// beq cr6,0x831a751c
	if (cr6.eq) goto loc_831A751C;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x831a0430
	sub_831A0430(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// ble 0x831a7484
	if (!cr0.gt) goto loc_831A7484;
	// cmpwi cr6,r28,9
	cr6.compare<int32_t>(r28.s32, 9, xer);
	// li r11,1
	r11.s64 = 1;
	// ble cr6,0x831a7488
	if (!cr6.gt) goto loc_831A7488;
loc_831A7484:
	// li r11,0
	r11.s64 = 0;
loc_831A7488:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a751c
	if (cr0.eq) goto loc_831A751C;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,103
	ctx.r6.s64 = 103;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r28,2
	cr6.compare<int32_t>(r28.s32, 2, xer);
	// blt cr6,0x831a74c4
	if (cr6.lt) goto loc_831A74C4;
	// cmpwi cr6,r28,5
	cr6.compare<int32_t>(r28.s32, 5, xer);
	// li r28,1
	r28.s64 = 1;
	// ble cr6,0x831a74c8
	if (!cr6.gt) goto loc_831A74C8;
loc_831A74C4:
	// li r28,0
	r28.s64 = 0;
loc_831A74C8:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831687b8
	sub_831687B8(ctx, base);
	// clrlwi r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// lwz r11,596(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	// stw r30,592(r1)
	PPC_STORE_U32(ctx.r1.u32 + 592, r30.u32);
	// addi r27,r1,592
	r27.s64 = ctx.r1.s64 + 592;
	// rlwinm r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,596(r1)
	PPC_STORE_U32(ctx.r1.u32 + 596, r11.u32);
loc_831A751C:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c330
	sub_8319C330(ctx, base);
	// lwz r11,608(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 608);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a755c
	if (cr6.eq) goto loc_831A755C;
	// lwz r11,20(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,20(r4)
	PPC_STORE_U32(ctx.r4.u32 + 20, r11.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196cf0
	sub_83196CF0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_831A755C:
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8319aea0
	sub_8319AEA0(ctx, base);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x831a7448
	if (!cr6.eq) goto loc_831A7448;
loc_831A7570:
	// stw r25,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, r25.u32);
	// stw r24,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, r24.u32);
loc_831A7578:
	// mr r27,r29
	r27.u64 = r29.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a76e4
	if (cr6.eq) goto loc_831A76E4;
loc_831A7584:
	// cmplwi cr6,r27,4
	cr6.compare<uint32_t>(r27.u32, 4, xer);
	// mr r28,r27
	r28.u64 = r27.u64;
	// blt cr6,0x831a7594
	if (cr6.lt) goto loc_831A7594;
	// li r28,4
	r28.s64 = 4;
loc_831A7594:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// subf r27,r28,r27
	r27.s64 = r27.s64 - r28.s64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r11,r11,-8
	r11.s64 = r11.s64 + -8;
	// cmplwi cr6,r11,17
	cr6.compare<uint32_t>(r11.u32, 17, xer);
	// bgt cr6,0x831ad4bc
	if (cr6.gt) goto loc_831AD4BC;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,2616
	r12.s64 = r12.s64 + 2616;
	// rlwinm r0,r11,1,0,30
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31974
	r12.s64 = -2095448064;
	// addi r12,r12,30212
	r12.s64 = r12.s64 + 30212;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_831A7604;
	case 1:
		goto loc_831A7604;
	case 2:
		goto loc_831A7604;
	case 3:
		goto loc_831A7618;
	case 4:
		goto loc_831A7650;
	case 5:
		goto loc_831AD4BC;
	case 6:
		goto loc_831AD4BC;
	case 7:
		goto loc_831A7670;
	case 8:
		goto loc_831A7680;
	case 9:
		goto loc_831A768C;
	case 10:
		goto loc_831A769C;
	case 11:
		goto loc_831A76A8;
	case 12:
		goto loc_831A76BC;
	case 13:
		goto loc_831AD4BC;
	case 14:
		goto loc_831AD4BC;
	case 15:
		goto loc_831AD4BC;
	case 16:
		goto loc_831A7604;
	case 17:
		goto loc_831A762C;
	default:
		__builtin_unreachable();
	}
loc_831A7604:
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// b 0x831a76cc
	goto loc_831A76CC;
loc_831A7618:
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
loc_831A761C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
loc_831A7620:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// b 0x831a76cc
	goto loc_831A76CC;
loc_831A762C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319adf8
	sub_8319ADF8(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319adf8
	sub_8319ADF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// b 0x831a7620
	goto loc_831A7620;
loc_831A7650:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,12(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// b 0x831a761c
	goto loc_831A761C;
loc_831A7670:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
loc_831A7674:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197570
	sub_83197570(ctx, base);
	// b 0x831a76cc
	goto loc_831A76CC;
loc_831A7680:
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// b 0x831a7674
	goto loc_831A7674;
loc_831A768C:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
loc_831A7690:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197660
	sub_83197660(ctx, base);
	// b 0x831a76cc
	goto loc_831A76CC;
loc_831A769C:
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// b 0x831a7690
	goto loc_831A7690;
loc_831A76A8:
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197480
	sub_83197480(ctx, base);
	// b 0x831a76cc
	goto loc_831A76CC;
loc_831A76BC:
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197750
	sub_83197750(ctx, base);
loc_831A76CC:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x831a7584
	if (!cr6.eq) goto loc_831A7584;
loc_831A76E4:
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// lwz r27,3500(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// bne cr6,0x831a7808
	if (!cr6.eq) goto loc_831A7808;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// addi r3,r1,1896
	ctx.r3.s64 = ctx.r1.s64 + 1896;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,2632
	ctx.r3.s64 = ctx.r1.s64 + 2632;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// stw r22,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, r22.u32);
	// stw r21,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, r21.u32);
	// mr r28,r29
	r28.u64 = r29.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a77f0
	if (cr6.eq) goto loc_831A77F0;
loc_831A7728:
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// mr r30,r28
	r30.u64 = r28.u64;
	// blt cr6,0x831a7738
	if (cr6.lt) goto loc_831A7738;
	// li r30,4
	r30.s64 = 4;
loc_831A7738:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// subf r28,r30,r28
	r28.s64 = r28.s64 - r30.s64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1896
	ctx.r4.s64 = ctx.r1.s64 + 1896;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,2632
	ctx.r4.s64 = ctx.r1.s64 + 2632;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197900
	sub_83197900(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198858
	sub_83198858(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x831a7728
	if (!cr6.eq) goto loc_831A7728;
loc_831A77F0:
	// cmplwi r19,0
	cr0.compare<uint32_t>(r19.u32, 0, xer);
	// beq 0x831a7808
	if (cr0.eq) goto loc_831A7808;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,2752
	ctx.r3.s64 = ctx.r1.s64 + 2752;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831A7808:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a7820
	if (cr6.eq) goto loc_831A7820;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,2960
	ctx.r3.s64 = ctx.r1.s64 + 2960;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831A7820:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x831a783c
	if (cr6.eq) goto loc_831A783C;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,36
	ctx.r5.s64 = 36;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83118478
	sub_83118478(ctx, base);
loc_831A783C:
	// clrlwi. r11,r18,24
	r11.u64 = r18.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// lwz r5,3500(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// b 0x831a7350
	goto loc_831A7350;
loc_831A784C:
	// lwz r18,3500(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,32(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// twllei r29,0
	// divwu r11,r20,r29
	r11.u32 = r20.u32 / r29.u32;
	// mullw r11,r11,r29
	r11.s64 = int64_t(r11.s32) * int64_t(r29.s32);
	// subf. r11,r11,r20
	r11.s64 = r20.s64 - r11.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ad4c8
	if (!cr0.eq) goto loc_831AD4C8;
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// addi r3,r1,320
	ctx.r3.s64 = ctx.r1.s64 + 320;
	// divwu r28,r20,r29
	r28.u32 = r20.u32 / r29.u32;
	// twllei r29,0
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// addi r5,r1,1248
	ctx.r5.s64 = ctx.r1.s64 + 1248;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83195ce8
	sub_83195CE8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a7950
	if (cr0.eq) goto loc_831A7950;
	// lfd f0,1248(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1248);
	// lfd f13,1264(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1264);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x831ad4d4
	if (cr6.lt) goto loc_831AD4D4;
	// clrldi r11,r28,32
	r11.u64 = r28.u64 & 0xFFFFFFFF;
	// std r11,1280(r1)
	PPC_STORE_U64(ctx.r1.u32 + 1280, r11.u64);
	// lfd f13,1280(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1280);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x831ad4d4
	if (!cr6.lt) goto loc_831AD4D4;
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(f0.f64);
	// stfd f0,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, f0.u64);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// mullw r28,r11,r29
	r28.s64 = int64_t(r11.s32) * int64_t(r29.s32);
	// beq cr6,0x831a792c
	if (cr6.eq) goto loc_831A792C;
loc_831A78F4:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,320
	ctx.r3.s64 = ctx.r1.s64 + 320;
	// bl 0x8319ae60
	sub_8319AE60(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// add r4,r30,r28
	ctx.r4.u64 = r30.u64 + r28.u64;
	// addi r3,r1,320
	ctx.r3.s64 = ctx.r1.s64 + 320;
	// bl 0x8319ae60
	sub_8319AE60(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r11.u32);
	// blt cr6,0x831a78f4
	if (cr6.lt) goto loc_831A78F4;
loc_831A792C:
	// subf. r5,r29,r20
	ctx.r5.s64 = r20.s64 - r29.s64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x831a7940
	if (cr0.eq) goto loc_831A7940;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// addi r3,r1,2768
	ctx.r3.s64 = ctx.r1.s64 + 2768;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831A7940:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x831a534c
	if (!cr6.eq) goto loc_831A534C;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// b 0x831a6c24
	goto loc_831A6C24;
loc_831A7950:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,16(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 16);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831385c0
	sub_831385C0(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// bl 0x831a0430
	sub_831A0430(ctx, base);
	// cmpwi cr6,r3,33
	cr6.compare<int32_t>(ctx.r3.s32, 33, xer);
	// blt cr6,0x831a7984
	if (cr6.lt) goto loc_831A7984;
	// cmpwi cr6,r3,37
	cr6.compare<int32_t>(ctx.r3.s32, 37, xer);
	// bgt cr6,0x831a7984
	if (cr6.gt) goto loc_831A7984;
	// li r30,1
	r30.s64 = 1;
loc_831A7984:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831a7ac0
	if (cr6.eq) goto loc_831A7AC0;
	// clrlwi. r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ad4e0
	if (!cr0.eq) goto loc_831AD4E0;
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// ble cr6,0x831a7cf0
	if (!cr6.gt) goto loc_831A7CF0;
	// clrldi r11,r29,32
	r11.u64 = r29.u64 & 0xFFFFFFFF;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// std r11,1296(r1)
	PPC_STORE_U64(ctx.r1.u32 + 1296, r11.u64);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,3136
	ctx.r3.s64 = ctx.r1.s64 + 3136;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// lfd f0,1296(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1296);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// ld r4,144(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x8319cc98
	sub_8319CC98(ctx, base);
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// rlwinm r11,r28,3,0,28
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r3,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r3.u32);
	// li r24,0
	r24.s64 = 0;
	// rlwinm r10,r10,0,15,15
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10000;
	// addi r21,r11,12
	r21.s64 = r11.s64 + 12;
	// ori r11,r10,1
	r11.u64 = ctx.r10.u64 | 1;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r11.u32);
	// beq cr6,0x831a7ab0
	if (cr6.eq) goto loc_831A7AB0;
	// clrlwi r23,r29,18
	r23.u64 = r29.u32 & 0x3FFF;
	// rlwinm r22,r28,14,4,17
	r22.u64 = rotl64(r28.u32 | (r28.u64 << 32), 14) & 0xFFFC000;
loc_831A7A10:
	// li r5,32
	ctx.r5.s64 = 32;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83110880
	sub_83110880(ctx, base);
	// ld r11,144(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// std r11,0(r30)
	PPC_STORE_U64(r30.u32 + 0, r11.u64);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,0,17
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFC000;
	// or r11,r11,r23
	r11.u64 = r11.u64 | r23.u64;
	// rlwinm r11,r11,0,18,3
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFF0003FFF;
	// or r11,r11,r22
	r11.u64 = r11.u64 | r22.u64;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// beq cr6,0x831a7a84
	if (cr6.eq) goto loc_831A7A84;
	// mr r25,r24
	r25.u64 = r24.u64;
	// addi r27,r30,12
	r27.s64 = r30.s64 + 12;
	// mr r26,r28
	r26.u64 = r28.u64;
loc_831A7A58:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,320
	ctx.r3.s64 = ctx.r1.s64 + 320;
	// bl 0x8319ae60
	sub_8319AE60(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addic. r26,r26,-1
	xer.ca = r26.u32 > 0;
	r26.s64 = r26.s64 + -1;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// add r25,r25,r29
	r25.u64 = r25.u64 + r29.u64;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r11.u32);
	// addi r27,r27,8
	r27.s64 = r27.s64 + 8;
	// bne 0x831a7a58
	if (!cr0.eq) goto loc_831A7A58;
loc_831A7A84:
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,320
	ctx.r3.s64 = ctx.r1.s64 + 320;
	// bl 0x8319ae60
	sub_8319AE60(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// cmplw cr6,r24,r29
	cr6.compare<uint32_t>(r24.u32, r29.u32, xer);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// oris r11,r11,1
	r11.u64 = r11.u64 | 65536;
	// ori r11,r11,3
	r11.u64 = r11.u64 | 3;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// blt cr6,0x831a7a10
	if (cr6.lt) goto loc_831A7A10;
loc_831A7AB0:
	// subf. r5,r29,r20
	ctx.r5.s64 = r20.s64 - r29.s64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x831a7cf0
	if (cr0.eq) goto loc_831A7CF0;
	// addi r3,r1,2784
	ctx.r3.s64 = ctx.r1.s64 + 2784;
	// b 0x831a7ce8
	goto loc_831A7CE8;
loc_831A7AC0:
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a7cdc
	if (cr6.eq) goto loc_831A7CDC;
	// clrlwi r23,r30,24
	r23.u64 = r30.u32 & 0xFF;
	// li r22,1
	r22.s64 = 1;
loc_831A7AD4:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// bne cr6,0x831a7b00
	if (!cr6.eq) goto loc_831A7B00;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// ld r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r4,r1,320
	ctx.r4.s64 = ctx.r1.s64 + 320;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319ec18
	sub_8319EC18(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831a7cd0
	if (!cr0.eq) goto loc_831A7CD0;
loc_831A7B00:
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r4,r28,2,0,29
	ctx.r4.u64 = rotl64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831a7b54
	if (cr6.eq) goto loc_831A7B54;
	// mr r26,r25
	r26.u64 = r25.u64;
	// mr r27,r24
	r27.u64 = r24.u64;
	// mr r30,r28
	r30.u64 = r28.u64;
loc_831A7B28:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,320
	ctx.r3.s64 = ctx.r1.s64 + 320;
	// bl 0x8319ae60
	sub_8319AE60(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// stw r3,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r3.u32);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// add r27,r27,r29
	r27.u64 = r27.u64 + r29.u64;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// bne 0x831a7b28
	if (!cr0.eq) goto loc_831A7B28;
loc_831A7B54:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,119
	ctx.r6.s64 = 119;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,119
	ctx.r4.s64 = 119;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-12
	r11.s64 = r30.s64 + -12;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// stw r28,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r28.u32);
	// stw r25,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r25.u32);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// ori r11,r11,8192
	r11.u64 = r11.u64 | 8192;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// beq cr6,0x831a7bd0
	if (cr6.eq) goto loc_831A7BD0;
	// mr r27,r25
	r27.u64 = r25.u64;
	// mr r26,r28
	r26.u64 = r28.u64;
loc_831A7BB4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// bl 0x83123628
	sub_83123628(ctx, base);
	// stw r3,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r3.u32);
	// addic. r26,r26,-1
	xer.ca = r26.u32 > 0;
	r26.s64 = r26.s64 + -1;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// bne 0x831a7bb4
	if (!cr0.eq) goto loc_831A7BB4;
loc_831A7BD0:
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831979c0
	sub_831979C0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,224
	ctx.r6.s64 = 224;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123520
	sub_83123520(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198208
	sub_83198208(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,118
	ctx.r6.s64 = 118;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwimi r11,r22,3,27,31
	r11.u64 = (rotl32(r22.u32, 3) & 0x1F) | (r11.u64 & 0xFFFFFFFFFFFFFFE0);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bl 0x83168ac8
	sub_83168AC8(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// addi r11,r4,24
	r11.s64 = ctx.r4.s64 + 24;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r5,r11,3
	ctx.r5.u64 = r11.u64 | 3;
	// bl 0x831d3380
	sub_831D3380(ctx, base);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,320
	ctx.r3.s64 = ctx.r1.s64 + 320;
	// bl 0x8319ae60
	sub_8319AE60(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwimi r11,r22,1,16,14
	r11.u64 = (rotl32(r22.u32, 1) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
loc_831A7CD0:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// cmplw cr6,r24,r29
	cr6.compare<uint32_t>(r24.u32, r29.u32, xer);
	// blt cr6,0x831a7ad4
	if (cr6.lt) goto loc_831A7AD4;
loc_831A7CDC:
	// subf. r5,r29,r20
	ctx.r5.s64 = r20.s64 - r29.s64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x831a7cf0
	if (cr0.eq) goto loc_831A7CF0;
	// addi r3,r1,2976
	ctx.r3.s64 = ctx.r1.s64 + 2976;
loc_831A7CE8:
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831A7CF0:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,36
	ctx.r5.s64 = 36;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83118478
	sub_83118478(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831A7D08:
	// lwz r27,3500(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mulli r5,r29,3
	ctx.r5.s64 = r29.s64 * 3;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,720
	ctx.r3.s64 = ctx.r1.s64 + 720;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// rlwinm r28,r29,1,0,30
	r28.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r3,r1,1928
	ctx.r3.s64 = ctx.r1.s64 + 1928;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,2312
	ctx.r3.s64 = ctx.r1.s64 + 2312;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831A7D40:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a7ddc
	if (cr6.eq) goto loc_831A7DDC;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831a7d58
	if (cr6.lt) goto loc_831A7D58;
	// li r30,4
	r30.s64 = 4;
loc_831A7D58:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,720
	ctx.r4.s64 = ctx.r1.s64 + 720;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1928
	ctx.r4.s64 = ctx.r1.s64 + 1928;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,2312
	ctx.r4.s64 = ctx.r1.s64 + 2312;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197a80
	sub_83197A80(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,720
	ctx.r3.s64 = ctx.r1.s64 + 720;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,720
	ctx.r3.s64 = ctx.r1.s64 + 720;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831a7d40
	goto loc_831A7D40;
loc_831A7DDC:
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,2800
	ctx.r3.s64 = ctx.r1.s64 + 2800;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831A7DF4:
	// lwz r11,32(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r25,24(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r25,137
	cr6.compare<uint32_t>(r25.u32, 137, xer);
	// bgt cr6,0x831ad768
	if (cr6.gt) goto loc_831AD768;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,2336
	r12.s64 = r12.s64 + 2336;
	// rlwinm r0,r25,1,0,30
	r0.u64 = rotl64(r25.u32 | (r25.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31974
	r12.s64 = -2095448064;
	// addi r12,r12,32304
	r12.s64 = r12.s64 + 32304;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r25.u64) {
	case 0:
		goto loc_831A7E30;
	case 1:
		goto loc_831A7E38;
	case 2:
		goto loc_831A8158;
	case 3:
		goto loc_831A8158;
	case 4:
		goto loc_831A7E38;
	case 5:
		goto loc_831A842C;
	case 6:
		goto loc_831A847C;
	case 7:
		goto loc_831A847C;
	case 8:
		goto loc_831A88F0;
	case 9:
		goto loc_831A8A18;
	case 10:
		goto loc_831A8B14;
	case 11:
		goto loc_831A8C9C;
	case 12:
		goto loc_831A8E84;
	case 13:
		goto loc_831A8FE8;
	case 14:
		goto loc_831A90E0;
	case 15:
		goto loc_831A90E0;
	case 16:
		goto loc_831AC1F0;
	case 17:
		goto loc_831AC1F0;
	case 18:
		goto loc_831A90F8;
	case 19:
		goto loc_831A93D0;
	case 20:
		goto loc_831AD768;
	case 21:
		goto loc_831A9D70;
	case 22:
		goto loc_831A9F44;
	case 23:
		goto loc_831AA088;
	case 24:
		goto loc_831AA780;
	case 25:
		goto loc_831AA6F0;
	case 26:
		goto loc_831AA114;
	case 27:
		goto loc_831AA968;
	case 28:
		goto loc_831AA278;
	case 29:
		goto loc_831AA970;
	case 30:
		goto loc_831AAB04;
	case 31:
		goto loc_831AC354;
	case 32:
		goto loc_831AA41C;
	case 33:
		goto loc_831AA4FC;
	case 34:
		goto loc_831AA5E8;
	case 35:
		goto loc_831AA808;
	case 36:
		goto loc_831AAC80;
	case 37:
		goto loc_831AADAC;
	case 38:
		goto loc_831AAEC8;
	case 39:
		goto loc_831AD768;
	case 40:
		goto loc_831AA89C;
	case 41:
		goto loc_831AA8C8;
	case 42:
		goto loc_831AA6E8;
	case 43:
		goto loc_831AAA0C;
	case 44:
		goto loc_831AAA14;
	case 45:
		goto loc_831AB0A0;
	case 46:
		goto loc_831AB1B8;
	case 47:
		goto loc_831AB1B8;
	case 48:
		goto loc_831AB1B8;
	case 49:
		goto loc_831AB1B8;
	case 50:
		goto loc_831AB2DC;
	case 51:
		goto loc_831AB2DC;
	case 52:
		goto loc_831AB1B8;
	case 53:
		goto loc_831AB2DC;
	case 54:
		goto loc_831AB2DC;
	case 55:
		goto loc_831AD768;
	case 56:
		goto loc_831AB668;
	case 57:
		goto loc_831AB728;
	case 58:
		goto loc_831A91B8;
	case 59:
		goto loc_831AC4C4;
	case 60:
		goto loc_831AC4CC;
	case 61:
		goto loc_831AC4D4;
	case 62:
		goto loc_831AB844;
	case 63:
		goto loc_831AB97C;
	case 64:
		goto loc_831ABC94;
	case 65:
		goto loc_831AA6F8;
	case 66:
		goto loc_831A899C;
	case 67:
		goto loc_831ABD94;
	case 68:
		goto loc_831A8C9C;
	case 69:
		goto loc_831A8CEC;
	case 70:
		goto loc_831A8E84;
	case 71:
		goto loc_831ABE68;
	case 72:
		goto loc_831AA700;
	case 73:
		goto loc_831AC030;
	case 74:
		goto loc_831A8C9C;
	case 75:
		goto loc_831A8E84;
	case 76:
		goto loc_831AC5DC;
	case 77:
		goto loc_831AD768;
	case 78:
		goto loc_831AD768;
	case 79:
		goto loc_831AD768;
	case 80:
		goto loc_831AD768;
	case 81:
		goto loc_831AC5DC;
	case 82:
		goto loc_831AD768;
	case 83:
		goto loc_831AD768;
	case 84:
		goto loc_831AD768;
	case 85:
		goto loc_831AD768;
	case 86:
		goto loc_831AC5DC;
	case 87:
		goto loc_831AC5DC;
	case 88:
		goto loc_831AC5DC;
	case 89:
		goto loc_831AD768;
	case 90:
		goto loc_831AD768;
	case 91:
		goto loc_831AD768;
	case 92:
		goto loc_831AD768;
	case 93:
		goto loc_831AD768;
	case 94:
		goto loc_831AC5DC;
	case 95:
		goto loc_831AD768;
	case 96:
		goto loc_831AD768;
	case 97:
		goto loc_831AD768;
	case 98:
		goto loc_831AD768;
	case 99:
		goto loc_831AC5DC;
	case 100:
		goto loc_831AD768;
	case 101:
		goto loc_831AD768;
	case 102:
		goto loc_831AD768;
	case 103:
		goto loc_831AD768;
	case 104:
		goto loc_831AC5DC;
	case 105:
		goto loc_831AC5DC;
	case 106:
		goto loc_831AC5DC;
	case 107:
		goto loc_831AD768;
	case 108:
		goto loc_831AD768;
	case 109:
		goto loc_831AD768;
	case 110:
		goto loc_831AD768;
	case 111:
		goto loc_831AD768;
	case 112:
		goto loc_831AC5DC;
	case 113:
		goto loc_831AD768;
	case 114:
		goto loc_831AD768;
	case 115:
		goto loc_831AC5DC;
	case 116:
		goto loc_831AD768;
	case 117:
		goto loc_831AD768;
	case 118:
		goto loc_831AC5DC;
	case 119:
		goto loc_831AC5DC;
	case 120:
		goto loc_831AC5DC;
	case 121:
		goto loc_831AD768;
	case 122:
		goto loc_831AD768;
	case 123:
		goto loc_831AC5DC;
	case 124:
		goto loc_831AD768;
	case 125:
		goto loc_831AD768;
	case 126:
		goto loc_831AC5DC;
	case 127:
		goto loc_831AD768;
	case 128:
		goto loc_831AD768;
	case 129:
		goto loc_831AC5DC;
	case 130:
		goto loc_831AC5DC;
	case 131:
		goto loc_831AC5DC;
	case 132:
		goto loc_831AD768;
	case 133:
		goto loc_831AD768;
	case 134:
		goto loc_831AD768;
	case 135:
		goto loc_831AC0EC;
	case 136:
		goto loc_831AA978;
	case 137:
		goto loc_831A9278;
	default:
		__builtin_unreachable();
	}
loc_831A7E30:
	// li r28,2
	r28.s64 = 2;
	// b 0x831a89a0
	goto loc_831A89A0;
loc_831A7E38:
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,1312
	ctx.r3.s64 = ctx.r1.s64 + 1312;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,1328
	ctx.r3.s64 = ctx.r1.s64 + 1328;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f20
	ctx.f1.f64 = f20.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,1192
	ctx.r3.s64 = ctx.r1.s64 + 1192;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f19
	ctx.f1.f64 = f19.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,1408
	ctx.r3.s64 = ctx.r1.s64 + 1408;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f18
	ctx.f1.f64 = f18.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,1208
	ctx.r3.s64 = ctx.r1.s64 + 1208;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f17
	ctx.f1.f64 = f17.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,1384
	ctx.r3.s64 = ctx.r1.s64 + 1384;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,1488
	ctx.r3.s64 = ctx.r1.s64 + 1488;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f16
	ctx.f1.f64 = f16.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,1544
	ctx.r3.s64 = ctx.r1.s64 + 1544;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f28
	ctx.f1.f64 = f28.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,1960
	ctx.r3.s64 = ctx.r1.s64 + 1960;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// li r28,1
	r28.s64 = 1;
loc_831A7F4C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// addi r3,r1,1960
	ctx.r3.s64 = ctx.r1.s64 + 1960;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r5,12(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1312(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1312);
	// bl 0x8319c6a8
	sub_8319C6A8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831982b0
	sub_831982B0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r4,1328(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1328);
	// bl 0x8319bd58
	sub_8319BD58(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1192(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1192);
	// bl 0x8319ca28
	sub_8319CA28(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198858
	sub_83198858(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1408(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1408);
	// bl 0x8319ca28
	sub_8319CA28(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198858
	sub_83198858(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1208(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1208);
	// bl 0x8319ca28
	sub_8319CA28(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1384(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1384);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x8319caf8
	sub_8319CAF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1488(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1488);
	// bl 0x8319ca28
	sub_8319CA28(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319ce60
	sub_8319CE60(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,1
	cr6.compare<int32_t>(r25.s32, 1, xer);
	// bne cr6,0x831a8118
	if (!cr6.eq) goto loc_831A8118;
	// stw r4,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r4.u32);
	// b 0x831a8144
	goto loc_831A8144;
loc_831A8118:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1544(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1544);
	// bl 0x8319c6a8
	sub_8319C6A8(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
loc_831A8144:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// rlwimi r11,r28,0,16,14
	r11.u64 = (rotl32(r28.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// b 0x831a7f4c
	goto loc_831A7F4C;
loc_831A8158:
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// bne cr6,0x831ad4ec
	if (!cr6.eq) goto loc_831AD4EC;
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad504
	if (cr6.eq) goto loc_831AD504;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad504
	if (!cr6.eq) goto loc_831AD504;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad4f8
	if (cr6.eq) goto loc_831AD4F8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad4f8
	if (!cr6.eq) goto loc_831AD4F8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// lwz r27,3500(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r3,r1,1440
	ctx.r3.s64 = ctx.r1.s64 + 1440;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,488
	ctx.r3.s64 = ctx.r1.s64 + 488;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,492(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	// mr r29,r28
	r29.u64 = r28.u64;
	// clrlwi r11,r11,15
	r11.u64 = r11.u32 & 0x1FFFF;
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// stw r11,492(r1)
	PPC_STORE_U32(ctx.r1.u32 + 492, r11.u32);
loc_831A81F8:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a8278
	if (cr6.eq) goto loc_831A8278;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831a8210
	if (cr6.lt) goto loc_831A8210;
	// li r30,4
	r30.s64 = 4;
loc_831A8210:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1440
	ctx.r4.s64 = ctx.r1.s64 + 1440;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r4,r1,488
	ctx.r4.s64 = ctx.r1.s64 + 488;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r30,25,4,6
	ctx.r10.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x83197750
	sub_83197750(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1440
	ctx.r3.s64 = ctx.r1.s64 + 1440;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831a81f8
	goto loc_831A81F8;
loc_831A8278:
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// ble cr6,0x831a534c
	if (!cr6.gt) goto loc_831A534C;
	// mr r29,r28
	r29.u64 = r28.u64;
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// blt cr6,0x831a832c
	if (cr6.lt) goto loc_831A832C;
loc_831A828C:
	// subf r11,r29,r28
	r11.s64 = r28.s64 - r29.s64;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// addi r4,r11,4
	ctx.r4.s64 = r11.s64 + 4;
	// bl 0x8319d6e0
	sub_8319D6E0(ctx, base);
	// li r6,228
	ctx.r6.s64 = 228;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// bne cr6,0x831a82d8
	if (!cr6.eq) goto loc_831A82D8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,12(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
loc_831A82D8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197d60
	sub_83197D60(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// bne cr6,0x831a8314
	if (!cr6.eq) goto loc_831A8314;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,12(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
loc_831A8314:
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// bl 0x8319aef0
	sub_8319AEF0(ctx, base);
	// addi r29,r29,-3
	r29.s64 = r29.s64 + -3;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// bge cr6,0x831a828c
	if (!cr6.lt) goto loc_831A828C;
loc_831A832C:
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// ble cr6,0x831a8418
	if (!cr6.gt) goto loc_831A8418;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// bl 0x8319d6e0
	sub_8319D6E0(ctx, base);
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r4,228
	ctx.r4.s64 = 228;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// bge cr6,0x831a8390
	if (!cr6.lt) goto loc_831A8390;
	// rlwinm r11,r29,1,0,30
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// subfic r10,r29,4
	xer.ca = r29.u32 <= 4;
	ctx.r10.s64 = 4 - r29.s64;
loc_831A836C:
	// li r9,3
	ctx.r9.s64 = 3;
	// li r8,0
	ctx.r8.s64 = 0;
	// slw r9,r9,r11
	ctx.r9.u64 = r11.u8 & 0x20 ? 0 : (ctx.r9.u32 << (r11.u8 & 0x3F));
	// slw r8,r8,r11
	ctx.r8.u64 = r11.u8 & 0x20 ? 0 : (ctx.r8.u32 << (r11.u8 & 0x3F));
	// andc r9,r4,r9
	ctx.r9.u64 = ctx.r4.u64 & ~ctx.r9.u64;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// or r4,r9,r8
	ctx.r4.u64 = ctx.r9.u64 | ctx.r8.u64;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// bne 0x831a836c
	if (!cr0.eq) goto loc_831A836C;
loc_831A8390:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwimi r11,r10,27,4,6
	r11.u64 = (rotl32(ctx.r10.u32, 27) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// bne cr6,0x831a83cc
	if (!cr6.eq) goto loc_831A83CC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r5,12(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
loc_831A83CC:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197d60
	sub_83197D60(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// bne cr6,0x831a840c
	if (!cr6.eq) goto loc_831A840C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,12(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
loc_831A840C:
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// bl 0x8319aef0
	sub_8319AEF0(ctx, base);
loc_831A8418:
	// addic. r5,r28,-1
	xer.ca = r28.u32 > 0;
	ctx.r5.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,3072
	ctx.r3.s64 = ctx.r1.s64 + 3072;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831A842C:
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831a8444
	if (cr0.eq) goto loc_831A8444;
	// li r11,0
	r11.s64 = 0;
	// b 0x831a8450
	goto loc_831A8450;
loc_831A8444:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_831A8450:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x8319da00
	sub_8319DA00(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,2816
	ctx.r3.s64 = ctx.r1.s64 + 2816;
loc_831A8474:
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831A847C:
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,1432
	ctx.r3.s64 = ctx.r1.s64 + 1432;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f26
	ctx.f1.f64 = f26.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,1240
	ctx.r3.s64 = ctx.r1.s64 + 1240;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f25
	ctx.f1.f64 = f25.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,1616
	ctx.r3.s64 = ctx.r1.s64 + 1616;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f24
	ctx.f1.f64 = f24.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,1256
	ctx.r3.s64 = ctx.r1.s64 + 1256;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f23
	ctx.f1.f64 = f23.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,1456
	ctx.r3.s64 = ctx.r1.s64 + 1456;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f22
	ctx.f1.f64 = f22.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,1272
	ctx.r3.s64 = ctx.r1.s64 + 1272;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,1568
	ctx.r3.s64 = ctx.r1.s64 + 1568;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f28
	ctx.f1.f64 = f28.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,1288
	ctx.r3.s64 = ctx.r1.s64 + 1288;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f21
	ctx.f1.f64 = f21.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,1224
	ctx.r3.s64 = ctx.r1.s64 + 1224;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r26,3500(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,944
	ctx.r3.s64 = ctx.r1.s64 + 944;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,1464
	ctx.r3.s64 = ctx.r1.s64 + 1464;
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// cmpwi cr6,r25,6
	cr6.compare<int32_t>(r25.s32, 6, xer);
	// addi r3,r1,944
	ctx.r3.s64 = ctx.r1.s64 + 944;
	// beq cr6,0x831a85d0
	if (cr6.eq) goto loc_831A85D0;
	// rlwinm r4,r29,1,0,30
	ctx.r4.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// bl 0x8319d6e0
	sub_8319D6E0(ctx, base);
	// addi r3,r1,1464
	ctx.r3.s64 = ctx.r1.s64 + 1464;
loc_831A85D0:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8319d6e0
	sub_8319D6E0(ctx, base);
	// mr r27,r29
	r27.u64 = r29.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a88d0
	if (cr6.eq) goto loc_831A88D0;
loc_831A85E4:
	// addi r3,r1,944
	ctx.r3.s64 = ctx.r1.s64 + 944;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,6
	cr6.compare<int32_t>(r25.s32, 6, xer);
	// bne cr6,0x831a8600
	if (!cr6.eq) goto loc_831A8600;
	// addi r28,r1,1224
	r28.s64 = ctx.r1.s64 + 1224;
	// b 0x831a860c
	goto loc_831A860C;
loc_831A8600:
	// addi r3,r1,1464
	ctx.r3.s64 = ctx.r1.s64 + 1464;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
loc_831A860C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197390
	sub_83197390(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831972a0
	sub_831972A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198db0
	sub_83198DB0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1432(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1432);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// bl 0x8319caf8
	sub_8319CAF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1240(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1240);
	// bl 0x8319ca28
	sub_8319CA28(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1616(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1616);
	// bl 0x8319ca28
	sub_8319CA28(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1256(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1256);
	// bl 0x8319ca28
	sub_8319CA28(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1456(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1456);
	// bl 0x8319ca28
	sub_8319CA28(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197570
	sub_83197570(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// ld r5,1272(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1272);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319caf8
	sub_8319CAF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1568(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1568);
	// bl 0x8319ca28
	sub_8319CA28(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319ce60
	sub_8319CE60(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1288(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1288);
	// bl 0x8319caf8
	sub_8319CAF8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d280
	sub_8319D280(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d1b0
	sub_8319D1B0(ctx, base);
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199138
	sub_83199138(ctx, base);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198af8
	sub_83198AF8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198858
	sub_83198858(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// li r11,1
	r11.s64 = 1;
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// bne 0x831a85e4
	if (!cr0.eq) goto loc_831A85E4;
loc_831A88D0:
	// cmpwi cr6,r25,7
	cr6.compare<int32_t>(r25.s32, 7, xer);
	// bne cr6,0x831a534c
	if (!cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,2992
	ctx.r3.s64 = ctx.r1.s64 + 2992;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831A88F0:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,752
	ctx.r3.s64 = ctx.r1.s64 + 752;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831A8900:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831a8918
	if (cr6.lt) goto loc_831A8918;
	// li r30,4
	r30.s64 = 4;
loc_831A8918:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,752
	ctx.r4.s64 = ctx.r1.s64 + 752;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831979c0
	sub_831979C0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,752
	ctx.r3.s64 = ctx.r1.s64 + 752;
	// bl 0x8319af98
	sub_8319AF98(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,752
	ctx.r3.s64 = ctx.r1.s64 + 752;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831a8900
	goto loc_831A8900;
loc_831A899C:
	// li r28,1
	r28.s64 = 1;
loc_831A89A0:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,1168
	ctx.r3.s64 = ctx.r1.s64 + 1168;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r30,r29
	r30.u64 = r29.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
loc_831A89BC:
	// cmplwi cr6,r30,4
	cr6.compare<uint32_t>(r30.u32, 4, xer);
	// li r5,4
	ctx.r5.s64 = 4;
	// bgt cr6,0x831a89cc
	if (cr6.gt) goto loc_831A89CC;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
loc_831A89CC:
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r4,r1,1168
	ctx.r4.s64 = ctx.r1.s64 + 1168;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r29,r10,7,29,31
	r29.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x7;
	// bl 0x831cfaa8
	sub_831CFAA8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,1168
	ctx.r3.s64 = ctx.r1.s64 + 1168;
	// bl 0x8319af98
	sub_8319AF98(ctx, base);
	// subf. r30,r29,r30
	r30.s64 = r30.s64 - r29.s64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x831a89bc
	if (!cr0.eq) goto loc_831A89BC;
	// b 0x831a534c
	goto loc_831A534C;
loc_831A8A18:
	// lwz r27,3500(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mulli r5,r29,3
	ctx.r5.s64 = r29.s64 * 3;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,1104
	ctx.r3.s64 = ctx.r1.s64 + 1104;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// rlwinm r28,r29,1,0,30
	r28.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r3,r1,2504
	ctx.r3.s64 = ctx.r1.s64 + 2504;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,1992
	ctx.r3.s64 = ctx.r1.s64 + 1992;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831A8A50:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a8afc
	if (cr6.eq) goto loc_831A8AFC;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831a8a68
	if (cr6.lt) goto loc_831A8A68;
	// li r30,4
	r30.s64 = 4;
loc_831A8A68:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1104
	ctx.r4.s64 = ctx.r1.s64 + 1104;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,2504
	ctx.r4.s64 = ctx.r1.s64 + 2504;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1992
	ctx.r4.s64 = ctx.r1.s64 + 1992;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831972a0
	sub_831972A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198938
	sub_83198938(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1104
	ctx.r3.s64 = ctx.r1.s64 + 1104;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,1104
	ctx.r3.s64 = ctx.r1.s64 + 1104;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831a8a50
	goto loc_831A8A50;
loc_831A8AFC:
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,2832
	ctx.r3.s64 = ctx.r1.s64 + 2832;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831A8B14:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad528
	if (cr6.eq) goto loc_831AD528;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad528
	if (!cr6.eq) goto loc_831AD528;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad51c
	if (cr6.eq) goto loc_831AD51C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad51c
	if (!cr6.eq) goto loc_831AD51C;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a8b80
	if (!cr6.eq) goto loc_831A8B80;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a8b68
	if (cr6.eq) goto loc_831A8B68;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831a8b90
	goto loc_831A8B90;
loc_831A8B68:
	// addi r6,r1,268
	ctx.r6.s64 = ctx.r1.s64 + 268;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r5,r1,272
	ctx.r5.s64 = ctx.r1.s64 + 272;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831a8b90
	goto loc_831A8B90;
loc_831A8B80:
	// addi r6,r1,268
	ctx.r6.s64 = ctx.r1.s64 + 268;
	// addi r5,r1,272
	ctx.r5.s64 = ctx.r1.s64 + 272;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831A8B90:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad510
	if (cr0.eq) goto loc_831AD510;
	// lwz r11,268(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r10,272(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,560
	ctx.r3.s64 = ctx.r1.s64 + 560;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// mullw r28,r10,r11
	r28.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,564(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	// lwz r27,3500(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// clrlwi r11,r11,15
	r11.u64 = r11.u32 & 0x1FFFF;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// stw r11,564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 564, r11.u32);
	// addi r3,r1,784
	ctx.r3.s64 = ctx.r1.s64 + 784;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r29,r28
	r29.u64 = r28.u64;
loc_831A8BEC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a8c84
	if (cr6.eq) goto loc_831A8C84;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831a8c04
	if (cr6.lt) goto loc_831A8C04;
	// li r30,4
	r30.s64 = 4;
loc_831A8C04:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,784
	ctx.r4.s64 = ctx.r1.s64 + 784;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r4,r1,560
	ctx.r4.s64 = ctx.r1.s64 + 560;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r30,25,4,6
	ctx.r10.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x83197e18
	sub_83197E18(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// addi r3,r1,784
	ctx.r3.s64 = ctx.r1.s64 + 784;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83117ff8
	sub_83117FF8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,784
	ctx.r3.s64 = ctx.r1.s64 + 784;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831a8bec
	goto loc_831A8BEC;
loc_831A8C84:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,3120
	ctx.r3.s64 = ctx.r1.s64 + 3120;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831A8C9C:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,2344
	ctx.r3.s64 = ctx.r1.s64 + 2344;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831A8CAC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// addi r3,r1,2344
	ctx.r3.s64 = ctx.r1.s64 + 2344;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f138
	sub_8319F138(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// li r11,1
	r11.s64 = 1;
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// b 0x831a8cac
	goto loc_831A8CAC;
loc_831A8CEC:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad588
	if (cr6.eq) goto loc_831AD588;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad588
	if (!cr6.eq) goto loc_831AD588;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831ad57c
	if (cr6.eq) goto loc_831AD57C;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// bne cr6,0x831ad57c
	if (!cr6.eq) goto loc_831AD57C;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad570
	if (cr6.eq) goto loc_831AD570;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// bne cr6,0x831ad570
	if (!cr6.eq) goto loc_831AD570;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r4,8(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831ad564
	if (cr0.eq) goto loc_831AD564;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad564
	if (!cr6.eq) goto loc_831AD564;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r30,8(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r29,12(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// bl 0x83194ef8
	sub_83194EF8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq 0x831ad534
	if (cr0.eq) goto loc_831AD534;
	// addi r5,r1,184
	ctx.r5.s64 = ctx.r1.s64 + 184;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83194ef8
	sub_83194EF8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq 0x831ad53c
	if (cr0.eq) goto loc_831AD53C;
	// lwz r11,184(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r30,96(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x831ad544
	if (!cr6.eq) goto loc_831AD544;
	// addi r5,r1,184
	ctx.r5.s64 = ctx.r1.s64 + 184;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x83194ef8
	sub_83194EF8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad54c
	if (cr0.eq) goto loc_831AD54C;
	// lwz r11,184(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x831ad558
	if (!cr6.eq) goto loc_831AD558;
	// lwz r29,3500(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mulli r5,r30,3
	ctx.r5.s64 = r30.s64 * 3;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,2024
	ctx.r3.s64 = ctx.r1.s64 + 2024;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// rlwinm r5,r30,1,0,30
	ctx.r5.u64 = rotl64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,2600
	ctx.r3.s64 = ctx.r1.s64 + 2600;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,2056
	ctx.r3.s64 = ctx.r1.s64 + 2056;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831A8DEC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// addi r3,r1,2024
	ctx.r3.s64 = ctx.r1.s64 + 2024;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r3,r1,2600
	ctx.r3.s64 = ctx.r1.s64 + 2600;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,2056
	ctx.r3.s64 = ctx.r1.s64 + 2056;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r5,68
	ctx.r5.s64 = 68;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f138
	sub_8319F138(ctx, base);
	// lwz r11,244(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// stw r3,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, ctx.r3.u32);
	// rlwinm r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r29,r11,1
	r29.u64 = r11.u64 | 1;
	// stw r29,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, r29.u32);
	// ld r5,240(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 240);
	// bl 0x8319fa18
	sub_8319FA18(ctx, base);
	// li r5,11
	ctx.r5.s64 = 11;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f138
	sub_8319F138(ctx, base);
	// rlwinm r11,r29,0,15,15
	r11.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0x10000;
	// stw r3,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, ctx.r3.u32);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, r11.u32);
	// ld r5,240(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 240);
	// bl 0x8319fa18
	sub_8319FA18(ctx, base);
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// b 0x831a8dec
	goto loc_831A8DEC;
loc_831A8E84:
	// fmr f1,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f27.f64;
	// bl 0x821f3c80
	sub_821F3C80(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// addi r3,r1,1480
	ctx.r3.s64 = ctx.r1.s64 + 1480;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// fdivs f1,f30,f0
	ctx.f1.f64 = double(float(f30.f64 / f0.f64));
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,1304
	ctx.r3.s64 = ctx.r1.s64 + 1304;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f15
	ctx.f1.f64 = f15.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r3,r1,2376
	ctx.r3.s64 = ctx.r1.s64 + 2376;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831A8EE0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// addi r3,r1,2376
	ctx.r3.s64 = ctx.r1.s64 + 2376;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r5,r1,1480
	ctx.r5.s64 = ctx.r1.s64 + 1480;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d0e0
	sub_8319D0E0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83198c80
	sub_83198C80(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831980b8
	sub_831980B8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,12
	cr6.compare<int32_t>(r25.s32, 12, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x831a8f5c
	if (!cr6.eq) goto loc_831A8F5C;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// b 0x831a8f74
	goto loc_831A8F74;
loc_831A8F5C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
loc_831A8F74:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,75
	cr6.compare<int32_t>(r25.s32, 75, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x831a8fc0
	if (!cr6.eq) goto loc_831A8FC0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198db0
	sub_83198DB0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// b 0x831a8fcc
	goto loc_831A8FCC;
loc_831A8FC0:
	// addi r5,r1,1304
	ctx.r5.s64 = ctx.r1.s64 + 1304;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8319d010
	sub_8319D010(ctx, base);
loc_831A8FCC:
	// li r11,1
	r11.s64 = 1;
	// stw r3,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r3.u32);
	// lwz r10,4(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r26)
	PPC_STORE_U32(r26.u32 + 4, ctx.r10.u32);
	// b 0x831a8ee0
	goto loc_831A8EE0;
loc_831A8FE8:
	// cmplwi cr6,r29,3
	cr6.compare<uint32_t>(r29.u32, 3, xer);
	// bne cr6,0x831ad594
	if (!cr6.eq) goto loc_831AD594;
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// li r5,6
	ctx.r5.s64 = 6;
	// addi r3,r1,976
	ctx.r3.s64 = ctx.r1.s64 + 976;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r3,r1,1504
	ctx.r3.s64 = ctx.r1.s64 + 1504;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// li r6,210
	ctx.r6.s64 = 210;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r1,1504
	ctx.r4.s64 = ctx.r1.s64 + 1504;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r6,201
	ctx.r6.s64 = 201;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r1,976
	ctx.r4.s64 = ctx.r1.s64 + 976;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r6,201
	ctx.r6.s64 = 201;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r1,1504
	ctx.r4.s64 = ctx.r1.s64 + 1504;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r6,210
	ctx.r6.s64 = 210;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r1,976
	ctx.r4.s64 = ctx.r1.s64 + 976;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// addi r3,r1,976
	ctx.r3.s64 = ctx.r1.s64 + 976;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r5,3
	ctx.r5.s64 = 3;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,2848
	ctx.r3.s64 = ctx.r1.s64 + 2848;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831A90E0:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a08e8
	sub_831A08E8(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831A90F8:
	// li r5,4
	ctx.r5.s64 = 4;
	// fmr f4,f14
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f14.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f14
	ctx.f3.f64 = f14.f64;
	// addi r3,r1,504
	ctx.r3.s64 = ctx.r1.s64 + 504;
	// fmr f2,f14
	ctx.f2.f64 = f14.f64;
	// fmr f1,f14
	ctx.f1.f64 = f14.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,508(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// clrlwi r11,r11,15
	r11.u64 = r11.u32 & 0x1FFFF;
	// addi r3,r1,816
	ctx.r3.s64 = ctx.r1.s64 + 816;
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// stw r11,508(r1)
	PPC_STORE_U32(ctx.r1.u32 + 508, r11.u32);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831A9138:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831a9150
	if (cr6.lt) goto loc_831A9150;
	// li r30,4
	r30.s64 = 4;
loc_831A9150:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,816
	ctx.r4.s64 = ctx.r1.s64 + 816;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r4,r1,504
	ctx.r4.s64 = ctx.r1.s64 + 504;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r30,25,4,6
	ctx.r10.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,816
	ctx.r3.s64 = ctx.r1.s64 + 816;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,816
	ctx.r3.s64 = ctx.r1.s64 + 816;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831a9138
	goto loc_831A9138;
loc_831A91B8:
	// lfs f4,600(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f4.f64 = double(temp.f32);
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// addi r3,r1,616
	ctx.r3.s64 = ctx.r1.s64 + 616;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,620(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// clrlwi r11,r11,15
	r11.u64 = r11.u32 & 0x1FFFF;
	// addi r3,r1,1072
	ctx.r3.s64 = ctx.r1.s64 + 1072;
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// stw r11,620(r1)
	PPC_STORE_U32(ctx.r1.u32 + 620, r11.u32);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831A91F8:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831a9210
	if (cr6.lt) goto loc_831A9210;
	// li r30,4
	r30.s64 = 4;
loc_831A9210:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1072
	ctx.r4.s64 = ctx.r1.s64 + 1072;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r4,r1,616
	ctx.r4.s64 = ctx.r1.s64 + 616;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r30,25,4,6
	ctx.r10.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1072
	ctx.r3.s64 = ctx.r1.s64 + 1072;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,1072
	ctx.r3.s64 = ctx.r1.s64 + 1072;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831a91f8
	goto loc_831A91F8;
loc_831A9278:
	// lfs f4,608(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f4.f64 = double(temp.f32);
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// addi r3,r1,520
	ctx.r3.s64 = ctx.r1.s64 + 520;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,524(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// clrlwi r11,r11,15
	r11.u64 = r11.u32 & 0x1FFFF;
	// addi r3,r1,848
	ctx.r3.s64 = ctx.r1.s64 + 848;
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// stw r11,524(r1)
	PPC_STORE_U32(ctx.r1.u32 + 524, r11.u32);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831A92B8:
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831a92d4
	if (cr6.lt) goto loc_831A92D4;
	// li r30,4
	r30.s64 = 4;
loc_831A92D4:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,848
	ctx.r4.s64 = ctx.r1.s64 + 848;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// li r4,198
	ctx.r4.s64 = 198;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// addi r4,r1,520
	ctx.r4.s64 = ctx.r1.s64 + 520;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r30,25,4,6
	ctx.r10.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831a93bc
	if (cr6.eq) goto loc_831A93BC;
	// mr r26,r30
	r26.u64 = r30.u64;
loc_831A9334:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,103
	ctx.r6.s64 = 103;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// bl 0x831687b8
	sub_831687B8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,4
	ctx.r10.s64 = 4;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x83194b38
	sub_83194B38(ctx, base);
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// li r5,0
	ctx.r5.s64 = 0;
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// addi r3,r1,848
	ctx.r3.s64 = ctx.r1.s64 + 848;
	// bl 0x8319aea0
	sub_8319AEA0(ctx, base);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplw cr6,r28,r30
	cr6.compare<uint32_t>(r28.u32, r30.u32, xer);
	// blt cr6,0x831a9334
	if (cr6.lt) goto loc_831A9334;
loc_831A93BC:
	// subf r4,r26,r30
	ctx.r4.s64 = r30.s64 - r26.s64;
	// addi r3,r1,848
	ctx.r3.s64 = ctx.r1.s64 + 848;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831a92b8
	goto loc_831A92B8;
loc_831A93D0:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad5d0
	if (cr6.eq) goto loc_831AD5D0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad5d0
	if (!cr6.eq) goto loc_831AD5D0;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad5c4
	if (cr6.eq) goto loc_831AD5C4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad5c4
	if (!cr6.eq) goto loc_831AD5C4;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a9440
	if (!cr6.eq) goto loc_831A9440;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a9428
	if (cr6.eq) goto loc_831A9428;
	// li r30,0
	r30.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x831a9454
	goto loc_831A9454;
loc_831A9428:
	// addi r6,r1,252
	ctx.r6.s64 = ctx.r1.s64 + 252;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r5,r1,256
	ctx.r5.s64 = ctx.r1.s64 + 256;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831a9450
	goto loc_831A9450;
loc_831A9440:
	// addi r6,r1,252
	ctx.r6.s64 = ctx.r1.s64 + 252;
	// addi r5,r1,256
	ctx.r5.s64 = ctx.r1.s64 + 256;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831A9450:
	// li r30,0
	r30.s64 = 0;
loc_831A9454:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad5a0
	if (cr0.eq) goto loc_831AD5A0;
	// lwz r10,252(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// lwz r11,256(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x831ad5ac
	if (!cr6.eq) goto loc_831AD5AC;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x831a9d64
	if (cr6.eq) goto loc_831A9D64;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x831a9c98
	if (cr6.eq) goto loc_831A9C98;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x831a9af0
	if (cr6.eq) goto loc_831A9AF0;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x831ad5b8
	if (!cr6.eq) goto loc_831AD5B8;
	// lwz r29,3500(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// li r5,16
	ctx.r5.s64 = 16;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r5,12(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196b38
	sub_83196B38(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196b38
	sub_83196B38(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196b38
	sub_83196B38(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196b38
	sub_83196B38(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196b38
	sub_83196B38(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,208
	ctx.r4.s64 = ctx.r1.s64 + 208;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,208
	ctx.r4.s64 = ctx.r1.s64 + 208;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// lwz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// li r11,3
	r11.s64 = 3;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// rlwimi r10,r11,25,4,6
	ctx.r10.u64 = (rotl32(r11.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwimi r10,r11,25,4,6
	ctx.r10.u64 = (rotl32(r11.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r25)
	PPC_STORE_U32(r25.u32 + 0, ctx.r10.u32);
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// li r4,214
	ctx.r4.s64 = 214;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// li r4,239
	ctx.r4.s64 = 239;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// li r4,239
	ctx.r4.s64 = 239;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// li r4,214
	ctx.r4.s64 = 214;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// li r4,194
	ctx.r4.s64 = 194;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// li r4,239
	ctx.r4.s64 = 239;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r17,r3
	r17.u64 = ctx.r3.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// li r4,239
	ctx.r4.s64 = 239;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// li r4,194
	ctx.r4.s64 = 194;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r17,r3
	r17.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r16,r3
	r16.u64 = ctx.r3.u64;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// li r4,193
	ctx.r4.s64 = 193;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// li r4,223
	ctx.r4.s64 = 223;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r17,r3
	r17.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r16,r3
	r16.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r15,r3
	r15.u64 = ctx.r3.u64;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// li r4,223
	ctx.r4.s64 = 223;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// li r4,193
	ctx.r4.s64 = 193;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r16,r3
	r16.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r15,r3
	r15.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// li r4,193
	ctx.r4.s64 = 193;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// li r4,218
	ctx.r4.s64 = 218;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r15,r3
	r15.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// li r4,218
	ctx.r4.s64 = 218;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// li r4,193
	ctx.r4.s64 = 193;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// lwz r11,8(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// lwz r11,8(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// lwz r11,8(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 8);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831992f8
	sub_831992F8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831992f8
	sub_831992F8(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831992f8
	sub_831992F8(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831992f8
	sub_831992F8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// bl 0x83196c48
	sub_83196C48(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197ba0
	sub_83197BA0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r5,16
	ctx.r5.s64 = 16;
	// addi r3,r1,3008
	ctx.r3.s64 = ctx.r1.s64 + 3008;
loc_831A9AE0:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831A9AE8:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// b 0x831a9f30
	goto loc_831A9F30;
loc_831A9AF0:
	// lwz r29,3500(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// li r5,9
	ctx.r5.s64 = 9;
	// addi r3,r1,392
	ctx.r3.s64 = ctx.r1.s64 + 392;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// addi r3,r1,392
	ctx.r3.s64 = ctx.r1.s64 + 392;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r3,r1,392
	ctx.r3.s64 = ctx.r1.s64 + 392;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,392
	ctx.r3.s64 = ctx.r1.s64 + 392;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r5,12(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196b38
	sub_83196B38(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r1,392
	ctx.r4.s64 = ctx.r1.s64 + 392;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r1,392
	ctx.r4.s64 = ctx.r1.s64 + 392;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r5,12(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// li r4,193
	ctx.r4.s64 = 193;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// li r4,218
	ctx.r4.s64 = 218;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// li r4,218
	ctx.r4.s64 = 218;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// li r4,193
	ctx.r4.s64 = 193;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831992f8
	sub_831992F8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r5,9
	ctx.r5.s64 = 9;
	// addi r3,r1,2864
	ctx.r3.s64 = ctx.r1.s64 + 2864;
	// b 0x831a9ae0
	goto loc_831A9AE0;
loc_831A9C98:
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r3,r1,1528
	ctx.r3.s64 = ctx.r1.s64 + 1528;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,1528
	ctx.r4.s64 = ctx.r1.s64 + 1528;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,1528
	ctx.r4.s64 = ctx.r1.s64 + 1528;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123570
	sub_83123570(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r3,r1,3088
	ctx.r3.s64 = ctx.r1.s64 + 3088;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
loc_831A9D5C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// b 0x831a9f34
	goto loc_831A9F34;
loc_831A9D64:
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// li r5,1
	ctx.r5.s64 = 1;
	// b 0x831a6c28
	goto loc_831A6C28;
loc_831A9D70:
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// bne cr6,0x831ad5dc
	if (!cr6.eq) goto loc_831AD5DC;
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad60c
	if (cr6.eq) goto loc_831AD60C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad60c
	if (!cr6.eq) goto loc_831AD60C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad600
	if (cr6.eq) goto loc_831AD600;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad600
	if (!cr6.eq) goto loc_831AD600;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a9de4
	if (!cr6.eq) goto loc_831A9DE4;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a9dcc
	if (cr6.eq) goto loc_831A9DCC;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831a9df4
	goto loc_831A9DF4;
loc_831A9DCC:
	// addi r6,r1,108
	ctx.r6.s64 = ctx.r1.s64 + 108;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r5,r1,264
	ctx.r5.s64 = ctx.r1.s64 + 264;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831a9df4
	goto loc_831A9DF4;
loc_831A9DE4:
	// addi r6,r1,108
	ctx.r6.s64 = ctx.r1.s64 + 108;
	// addi r5,r1,264
	ctx.r5.s64 = ctx.r1.s64 + 264;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831A9DF4:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad5e8
	if (cr0.eq) goto loc_831AD5E8;
	// lwz r11,264(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x831ad5f4
	if (!cr6.eq) goto loc_831AD5F4;
	// lwz r11,108(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// addi r3,r1,1008
	ctx.r3.s64 = ctx.r1.s64 + 1008;
	// lwz r28,3500(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// rlwinm r5,r11,1,0,30
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,2088
	ctx.r3.s64 = ctx.r1.s64 + 2088;
	// lwz r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// lwz r29,108(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
loc_831A9E34:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a9ed0
	if (cr6.eq) goto loc_831A9ED0;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831a9e4c
	if (cr6.lt) goto loc_831A9E4C;
	// li r30,4
	r30.s64 = 4;
loc_831A9E4C:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1008
	ctx.r4.s64 = ctx.r1.s64 + 1008;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,2088
	ctx.r4.s64 = ctx.r1.s64 + 2088;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1008
	ctx.r3.s64 = ctx.r1.s64 + 1008;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,1008
	ctx.r3.s64 = ctx.r1.s64 + 1008;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831a9e34
	goto loc_831A9E34;
loc_831A9ED0:
	// lwz r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831a9eec
	if (cr6.eq) goto loc_831A9EEC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,2880
	ctx.r3.s64 = ctx.r1.s64 + 2880;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
	// lwz r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
loc_831A9EEC:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f958
	sub_8319F958(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198e48
	sub_83198E48(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198db0
	sub_83198DB0(ctx, base);
	// lwz r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831a9f2c
	if (cr6.eq) goto loc_831A9F2C;
	// addi r3,r1,3024
	ctx.r3.s64 = ctx.r1.s64 + 3024;
loc_831A9F24:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831A9F2C:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
loc_831A9F30:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
loc_831A9F34:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19b8
	sub_831A19B8(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831A9F44:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad654
	if (cr6.eq) goto loc_831AD654;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad654
	if (!cr6.eq) goto loc_831AD654;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad648
	if (cr6.eq) goto loc_831AD648;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad648
	if (!cr6.eq) goto loc_831AD648;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831ad63c
	if (cr6.eq) goto loc_831AD63C;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831ad63c
	if (!cr6.eq) goto loc_831AD63C;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r30,8(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831a9fcc
	if (!cr6.eq) goto loc_831A9FCC;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a9fb4
	if (cr6.eq) goto loc_831A9FB4;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831a9fdc
	goto loc_831A9FDC;
loc_831A9FB4:
	// addi r6,r1,188
	ctx.r6.s64 = ctx.r1.s64 + 188;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r5,r1,248
	ctx.r5.s64 = ctx.r1.s64 + 248;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831a9fdc
	goto loc_831A9FDC;
loc_831A9FCC:
	// addi r6,r1,188
	ctx.r6.s64 = ctx.r1.s64 + 188;
	// addi r5,r1,248
	ctx.r5.s64 = ctx.r1.s64 + 248;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831A9FDC:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad618
	if (cr0.eq) goto loc_831AD618;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831aa01c
	if (!cr6.eq) goto loc_831AA01C;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831aa004
	if (cr6.eq) goto loc_831AA004;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831aa030
	goto loc_831AA030;
loc_831AA004:
	// addi r6,r1,316
	ctx.r6.s64 = ctx.r1.s64 + 316;
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r5,r1,308
	ctx.r5.s64 = ctx.r1.s64 + 308;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831aa030
	goto loc_831AA030;
loc_831AA01C:
	// addi r6,r1,316
	ctx.r6.s64 = ctx.r1.s64 + 316;
	// addi r5,r1,308
	ctx.r5.s64 = ctx.r1.s64 + 308;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831AA030:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad624
	if (cr0.eq) goto loc_831AD624;
	// lwz r11,248(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x831ad630
	if (!cr6.eq) goto loc_831AD630;
	// lwz r11,308(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x831ad630
	if (!cr6.eq) goto loc_831AD630;
	// lwz r11,316(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// lwz r5,188(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// bne cr6,0x831ad630
	if (!cr6.eq) goto loc_831AD630;
	// lwz r29,3500(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8319f9b8
	sub_8319F9B8(ctx, base);
	// lwz r11,188(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// rlwinm. r5,r11,1,0,30
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x831a9ae8
	if (cr0.eq) goto loc_831A9AE8;
	// addi r3,r1,2896
	ctx.r3.s64 = ctx.r1.s64 + 2896;
	// b 0x831a9ae0
	goto loc_831A9AE0;
loc_831AA088:
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// bne cr6,0x831ad660
	if (!cr6.eq) goto loc_831AD660;
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// li r5,8
	ctx.r5.s64 = 8;
	// addi r3,r1,1552
	ctx.r3.s64 = ctx.r1.s64 + 1552;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r3,r1,2536
	ctx.r3.s64 = ctx.r1.s64 + 2536;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,2536
	ctx.r4.s64 = ctx.r1.s64 + 2536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r6,228
	ctx.r6.s64 = 228;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,1552
	ctx.r4.s64 = ctx.r1.s64 + 1552;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x83197f08
	sub_83197F08(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// addi r3,r1,1552
	ctx.r3.s64 = ctx.r1.s64 + 1552;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,3152
	ctx.r3.s64 = ctx.r1.s64 + 3152;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AA114:
	// lwz r26,3500(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mulli r5,r29,3
	ctx.r5.s64 = r29.s64 * 3;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,880
	ctx.r3.s64 = ctx.r1.s64 + 880;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// rlwinm r28,r29,1,0,30
	r28.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r3,r1,2408
	ctx.r3.s64 = ctx.r1.s64 + 2408;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,2120
	ctx.r3.s64 = ctx.r1.s64 + 2120;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,2120
	ctx.r5.s64 = ctx.r1.s64 + 2120;
	// addi r4,r1,2408
	ctx.r4.s64 = ctx.r1.s64 + 2408;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319e160
	sub_8319E160(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,2912
	ctx.r3.s64 = ctx.r1.s64 + 2912;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x8319cbc8
	sub_8319CBC8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
loc_831AA19C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831aa260
	if (cr6.eq) goto loc_831AA260;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831aa1b4
	if (cr6.lt) goto loc_831AA1B4;
	// li r30,4
	r30.s64 = 4;
loc_831AA1B4:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,880
	ctx.r4.s64 = ctx.r1.s64 + 880;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r30,25,4,6
	ctx.r10.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// rlwinm r10,r10,0,27,18
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x83198858
	sub_83198858(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198f78
	sub_83198F78(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,880
	ctx.r3.s64 = ctx.r1.s64 + 880;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,880
	ctx.r3.s64 = ctx.r1.s64 + 880;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831aa19c
	goto loc_831AA19C;
loc_831AA260:
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,3040
	ctx.r3.s64 = ctx.r1.s64 + 3040;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AA278:
	// lwz r25,3500(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// rlwinm r26,r29,1,0,30
	r26.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,1136
	ctx.r3.s64 = ctx.r1.s64 + 1136;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,376
	ctx.r3.s64 = ctx.r1.s64 + 376;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r30,r29
	r30.u64 = r29.u64;
	// lwz r28,380(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// lwz r27,384(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 384);
loc_831AA2AC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831aa2e4
	if (cr6.eq) goto loc_831AA2E4;
	// addi r3,r1,376
	ctx.r3.s64 = ctx.r1.s64 + 376;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c330
	sub_8319C330(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19b8
	sub_831A19B8(ctx, base);
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// b 0x831aa2ac
	goto loc_831AA2AC;
loc_831AA2E4:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,2152
	ctx.r3.s64 = ctx.r1.s64 + 2152;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// stw r28,380(r1)
	PPC_STORE_U32(ctx.r1.u32 + 380, r28.u32);
	// stw r27,384(r1)
	PPC_STORE_U32(ctx.r1.u32 + 384, r27.u32);
loc_831AA2FC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831aa404
	if (cr6.eq) goto loc_831AA404;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831aa314
	if (cr6.lt) goto loc_831AA314;
	// li r30,4
	r30.s64 = 4;
loc_831AA314:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1136
	ctx.r4.s64 = ctx.r1.s64 + 1136;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,376
	ctx.r4.s64 = ctx.r1.s64 + 376;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,2152
	ctx.r4.s64 = ctx.r1.s64 + 2152;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197840
	sub_83197840(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199640
	sub_83199640(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199058
	sub_83199058(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1136
	ctx.r3.s64 = ctx.r1.s64 + 1136;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1136
	ctx.r3.s64 = ctx.r1.s64 + 1136;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831aa2fc
	goto loc_831AA2FC;
loc_831AA404:
	// cmplwi r26,0
	cr0.compare<uint32_t>(r26.u32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,2928
	ctx.r3.s64 = ctx.r1.s64 + 2928;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AA41C:
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x831aa434
	if (!cr6.eq) goto loc_831AA434;
loc_831AA424:
	// lwz r11,608(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 608);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,608(r31)
	PPC_STORE_U32(r31.u32 + 608, r11.u32);
	// b 0x831a534c
	goto loc_831A534C;
loc_831AA434:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,912
	ctx.r3.s64 = ctx.r1.s64 + 912;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AA444:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831aa45c
	if (cr6.lt) goto loc_831AA45C;
	// li r30,4
	r30.s64 = 4;
loc_831AA45C:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,912
	ctx.r4.s64 = ctx.r1.s64 + 912;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196cf0
	sub_83196CF0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196cf0
	sub_83196CF0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199570
	sub_83199570(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,912
	ctx.r3.s64 = ctx.r1.s64 + 912;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,912
	ctx.r3.s64 = ctx.r1.s64 + 912;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831aa444
	goto loc_831AA444;
loc_831AA4FC:
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// beq cr6,0x831aa424
	if (cr6.eq) goto loc_831AA424;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,2664
	ctx.r3.s64 = ctx.r1.s64 + 2664;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AA514:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// addi r3,r1,2664
	ctx.r3.s64 = ctx.r1.s64 + 2664;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196cf0
	sub_83196CF0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198db0
	sub_83198DB0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196cf0
	sub_83196CF0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,2704
	ctx.r3.s64 = ctx.r1.s64 + 2704;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x8319c868
	sub_8319C868(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// b 0x831aa514
	goto loc_831AA514;
loc_831AA5E8:
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// beq cr6,0x831aa424
	if (cr6.eq) goto loc_831AA424;
	// li r5,4
	ctx.r5.s64 = 4;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,576
	ctx.r3.s64 = ctx.r1.s64 + 576;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,580(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// clrlwi r11,r11,15
	r11.u64 = r11.u32 & 0x1FFFF;
	// addi r3,r1,688
	ctx.r3.s64 = ctx.r1.s64 + 688;
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// stw r11,580(r1)
	PPC_STORE_U32(ctx.r1.u32 + 580, r11.u32);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AA630:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831aa648
	if (cr6.lt) goto loc_831AA648;
	// li r30,4
	r30.s64 = 4;
loc_831AA648:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,688
	ctx.r4.s64 = ctx.r1.s64 + 688;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x83196cf0
	sub_83196CF0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x83198a18
	sub_83198A18(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r4,r1,576
	ctx.r4.s64 = ctx.r1.s64 + 576;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwimi r11,r30,25,4,6
	r11.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196cf0
	sub_83196CF0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198a18
	sub_83198A18(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,688
	ctx.r3.s64 = ctx.r1.s64 + 688;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,688
	ctx.r3.s64 = ctx.r1.s64 + 688;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831aa630
	goto loc_831AA630;
loc_831AA6E8:
	// li r28,48
	r28.s64 = 48;
	// b 0x831aa704
	goto loc_831AA704;
loc_831AA6F0:
	// li r28,46
	r28.s64 = 46;
	// b 0x831aa704
	goto loc_831AA704;
loc_831AA6F8:
	// li r28,54
	r28.s64 = 54;
	// b 0x831aa704
	goto loc_831AA704;
loc_831AA700:
	// li r28,72
	r28.s64 = 72;
loc_831AA704:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,2184
	ctx.r3.s64 = ctx.r1.s64 + 2184;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AA714:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// addi r3,r1,2184
	ctx.r3.s64 = ctx.r1.s64 + 2184;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stw r27,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r27.u32);
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// b 0x831aa714
	goto loc_831AA714;
loc_831AA780:
	// fmr f1,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f27.f64;
	// bl 0x821f3c80
	sub_821F3C80(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// addi r3,r1,1664
	ctx.r3.s64 = ctx.r1.s64 + 1664;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// fdivs f1,f30,f0
	ctx.f1.f64 = double(float(f30.f64 / f0.f64));
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,1704
	ctx.r3.s64 = ctx.r1.s64 + 1704;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AA7BC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// addi r3,r1,1704
	ctx.r3.s64 = ctx.r1.s64 + 1704;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r4,r1,1664
	ctx.r4.s64 = ctx.r1.s64 + 1664;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d0e0
	sub_8319D0E0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198c80
	sub_83198C80(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// li r11,1
	r11.s64 = 1;
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// b 0x831aa7bc
	goto loc_831AA7BC;
loc_831AA808:
	// lwz r27,3500(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// rlwinm r5,r29,1,0,30
	ctx.r5.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,1720
	ctx.r3.s64 = ctx.r1.s64 + 1720;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,1752
	ctx.r3.s64 = ctx.r1.s64 + 1752;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r28,r29
	r28.u64 = r29.u64;
loc_831AA830:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831aa884
	if (cr6.eq) goto loc_831AA884;
	// addi r3,r1,1720
	ctx.r3.s64 = ctx.r1.s64 + 1720;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r1,1752
	ctx.r3.s64 = ctx.r1.s64 + 1752;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c200
	sub_8319C200(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d010
	sub_8319D010(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// li r11,1
	r11.s64 = 1;
	// addi r28,r28,-1
	r28.s64 = r28.s64 + -1;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// b 0x831aa830
	goto loc_831AA830;
loc_831AA884:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,2712
	ctx.r3.s64 = ctx.r1.s64 + 2712;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AA89C:
	// fmr f1,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f27.f64;
	// bl 0x821f3c80
	sub_821F3C80(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// frsp f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,2728
	ctx.r3.s64 = ctx.r1.s64 + 2728;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// b 0x831aa904
	goto loc_831AA904;
loc_831AA8C8:
	// fmr f1,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f27.f64;
	// bl 0x821f3c80
	sub_821F3C80(ctx, base);
	// frsp f14,f1
	ctx.fpscr.disableFlushMode();
	f14.f64 = double(float(ctx.f1.f64));
	// lfd f1,1320(r1)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1320);
	// bl 0x821f3c80
	sub_821F3C80(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,2744
	ctx.r3.s64 = ctx.r1.s64 + 2744;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fdivs f1,f14,f0
	ctx.f1.f64 = double(float(f14.f64 / f0.f64));
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lfs f14,624(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	f14.f64 = double(temp.f32);
loc_831AA904:
	// ld r11,0(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r3,r1,1784
	ctx.r3.s64 = ctx.r1.s64 + 1784;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AA91C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// addi r3,r1,1784
	ctx.r3.s64 = ctx.r1.s64 + 1784;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319c298
	sub_8319C298(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c5d8
	sub_8319C5D8(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// li r11,1
	r11.s64 = 1;
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// b 0x831aa91c
	goto loc_831AA91C;
loc_831AA968:
	// li r28,11
	r28.s64 = 11;
	// b 0x831aa97c
	goto loc_831AA97C;
loc_831AA970:
	// li r28,9
	r28.s64 = 9;
	// b 0x831aa97c
	goto loc_831AA97C;
loc_831AA978:
	// li r28,10
	r28.s64 = 10;
loc_831AA97C:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,704
	ctx.r3.s64 = ctx.r1.s64 + 704;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AA98C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831aa9a4
	if (cr6.lt) goto loc_831AA9A4;
	// li r30,4
	r30.s64 = 4;
loc_831AA9A4:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,704
	ctx.r4.s64 = ctx.r1.s64 + 704;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,704
	ctx.r3.s64 = ctx.r1.s64 + 704;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,704
	ctx.r3.s64 = ctx.r1.s64 + 704;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831aa98c
	goto loc_831AA98C;
loc_831AAA0C:
	// li r27,3
	r27.s64 = 3;
	// b 0x831aaa18
	goto loc_831AAA18;
loc_831AAA14:
	// li r27,4
	r27.s64 = 4;
loc_831AAA18:
	// lwz r26,3500(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// rlwinm r5,r29,1,0,30
	ctx.r5.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,736
	ctx.r3.s64 = ctx.r1.s64 + 736;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,1816
	ctx.r3.s64 = ctx.r1.s64 + 1816;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r28,r29
	r28.u64 = r29.u64;
loc_831AAA40:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831aaaec
	if (cr6.eq) goto loc_831AAAEC;
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// mr r30,r28
	r30.u64 = r28.u64;
	// blt cr6,0x831aaa58
	if (cr6.lt) goto loc_831AAA58;
	// li r30,4
	r30.s64 = 4;
loc_831AAA58:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,736
	ctx.r4.s64 = ctx.r1.s64 + 736;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1816
	ctx.r4.s64 = ctx.r1.s64 + 1816;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,736
	ctx.r3.s64 = ctx.r1.s64 + 736;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,736
	ctx.r3.s64 = ctx.r1.s64 + 736;
	// subf r28,r30,r28
	r28.s64 = r28.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831aaa40
	goto loc_831AAA40;
loc_831AAAEC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,2760
	ctx.r3.s64 = ctx.r1.s64 + 2760;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AAB04:
	// lwz r27,3500(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// rlwinm r5,r29,1,0,30
	ctx.r5.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,1848
	ctx.r3.s64 = ctx.r1.s64 + 1848;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,1880
	ctx.r3.s64 = ctx.r1.s64 + 1880;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r28,r29
	r28.u64 = r29.u64;
loc_831AAB2C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831aac68
	if (cr6.eq) goto loc_831AAC68;
	// addi r3,r1,1848
	ctx.r3.s64 = ctx.r1.s64 + 1848;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r1,1880
	ctx.r3.s64 = ctx.r1.s64 + 1880;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319cd80
	sub_8319CD80(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199218
	sub_83199218(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198d18
	sub_83198D18(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197840
	sub_83197840(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x83198c80
	sub_83198C80(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198db0
	sub_83198DB0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c5d8
	sub_8319C5D8(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,412(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	// stw r25,408(r1)
	PPC_STORE_U32(ctx.r1.u32 + 408, r25.u32);
	// rlwinm r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,412(r1)
	PPC_STORE_U32(ctx.r1.u32 + 412, r11.u32);
	// ld r5,408(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 408);
	// bl 0x8319fa18
	sub_8319FA18(ctx, base);
	// addi r28,r28,-1
	r28.s64 = r28.s64 + -1;
	// b 0x831aab2c
	goto loc_831AAB2C;
loc_831AAC68:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,2776
	ctx.r3.s64 = ctx.r1.s64 + 2776;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AAC80:
	// lwz r28,3500(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r3,r1,768
	ctx.r3.s64 = ctx.r1.s64 + 768;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// bne cr6,0x831ad66c
	if (!cr6.eq) goto loc_831AD66C;
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad694
	if (cr6.eq) goto loc_831AD694;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad694
	if (!cr6.eq) goto loc_831AD694;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad688
	if (cr6.eq) goto loc_831AD688;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad688
	if (!cr6.eq) goto loc_831AD688;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831aad08
	if (!cr6.eq) goto loc_831AAD08;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831aacf0
	if (cr6.eq) goto loc_831AACF0;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831aad18
	goto loc_831AAD18;
loc_831AACF0:
	// addi r6,r1,152
	ctx.r6.s64 = ctx.r1.s64 + 152;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r5,r1,288
	ctx.r5.s64 = ctx.r1.s64 + 288;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831aad18
	goto loc_831AAD18;
loc_831AAD08:
	// addi r6,r1,152
	ctx.r6.s64 = ctx.r1.s64 + 152;
	// addi r5,r1,288
	ctx.r5.s64 = ctx.r1.s64 + 288;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831AAD18:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq 0x831ad678
	if (cr0.eq) goto loc_831AD678;
	// lwz r11,288(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x831ad680
	if (!cr6.eq) goto loc_831AD680;
	// lwz r5,152(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// bne cr6,0x831aad74
	if (!cr6.eq) goto loc_831AAD74;
	// lwz r10,776(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	// lwz r11,772(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319adf8
	sub_8319ADF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r1,768
	ctx.r3.s64 = ctx.r1.s64 + 768;
	// bl 0x8319aef0
	sub_8319AEF0(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831AAD74:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8319f958
	sub_8319F958(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198e48
	sub_83198E48(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198db0
	sub_83198DB0(ctx, base);
	// lwz r5,152(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831a9f2c
	if (cr6.eq) goto loc_831A9F2C;
	// addi r3,r1,2696
	ctx.r3.s64 = ctx.r1.s64 + 2696;
	// b 0x831a9f24
	goto loc_831A9F24;
loc_831AADAC:
	// lwz r27,3500(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mulli r5,r29,3
	ctx.r5.s64 = r29.s64 * 3;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,800
	ctx.r3.s64 = ctx.r1.s64 + 800;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// rlwinm r28,r29,1,0,30
	r28.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r3,r1,1912
	ctx.r3.s64 = ctx.r1.s64 + 1912;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,1944
	ctx.r3.s64 = ctx.r1.s64 + 1944;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AADE4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831aaeb0
	if (cr6.eq) goto loc_831AAEB0;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831aadfc
	if (cr6.lt) goto loc_831AADFC;
	// li r30,4
	r30.s64 = 4;
loc_831AADFC:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,800
	ctx.r4.s64 = ctx.r1.s64 + 800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1912
	ctx.r4.s64 = ctx.r1.s64 + 1912;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1944
	ctx.r4.s64 = ctx.r1.s64 + 1944;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cfaa8
	sub_831CFAA8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198858
	sub_83198858(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198f78
	sub_83198F78(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,800
	ctx.r3.s64 = ctx.r1.s64 + 800;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,800
	ctx.r3.s64 = ctx.r1.s64 + 800;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831aade4
	goto loc_831AADE4;
loc_831AAEB0:
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,2808
	ctx.r3.s64 = ctx.r1.s64 + 2808;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AAEC8:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad6e0
	if (cr6.eq) goto loc_831AD6E0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad6e0
	if (!cr6.eq) goto loc_831AD6E0;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x831ad6d4
	if (cr6.eq) goto loc_831AD6D4;
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831ad6d4
	if (!cr6.eq) goto loc_831AD6D4;
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad6c8
	if (cr6.eq) goto loc_831AD6C8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad6c8
	if (!cr6.eq) goto loc_831AD6C8;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831ad6bc
	if (cr6.eq) goto loc_831AD6BC;
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r8,1
	cr6.compare<int32_t>(ctx.r8.s32, 1, xer);
	// bne cr6,0x831ad6bc
	if (!cr6.eq) goto loc_831AD6BC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,8(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r30,8(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r29,8(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x831ad6a0
	if (!cr6.eq) goto loc_831AD6A0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x831ad6a8
	if (!cr6.eq) goto loc_831AD6A8;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// bne cr6,0x831ad6b0
	if (!cr6.eq) goto loc_831AD6B0;
	// lwz r29,3500(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,1592
	ctx.r3.s64 = ctx.r1.s64 + 1592;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,1336
	ctx.r3.s64 = ctx.r1.s64 + 1336;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,1496
	ctx.r3.s64 = ctx.r1.s64 + 1496;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r30,1496(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1496);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319bbf8
	sub_8319BBF8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319be38
	sub_8319BE38(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319caf8
	sub_8319CAF8(ctx, base);
	// ld r30,1336(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1336);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319bbf8
	sub_8319BBF8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319be38
	sub_8319BE38(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319bf18
	sub_8319BF18(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,1592(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 1592);
	// bl 0x8319caf8
	sub_8319CAF8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198c80
	sub_83198C80(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,656
	ctx.r3.s64 = ctx.r1.s64 + 656;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// ld r4,656(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 656);
	// bl 0x8319fd40
	sub_8319FD40(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19b8
	sub_831A19B8(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19b8
	sub_831A19B8(ctx, base);
	// ld r4,656(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 656);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_831AB098:
	// bl 0x8319fd40
	sub_8319FD40(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831AB0A0:
	// lwz r24,3500(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// rlwinm r5,r29,1,0,30
	ctx.r5.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,832
	ctx.r3.s64 = ctx.r1.s64 + 832;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,1976
	ctx.r3.s64 = ctx.r1.s64 + 1976;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r25,r29
	r25.u64 = r29.u64;
loc_831AB0C8:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831ab1a0
	if (cr6.eq) goto loc_831AB1A0;
	// cmplwi cr6,r25,4
	cr6.compare<uint32_t>(r25.u32, 4, xer);
	// mr r30,r25
	r30.u64 = r25.u64;
	// blt cr6,0x831ab0e0
	if (cr6.lt) goto loc_831AB0E0;
	// li r30,4
	r30.s64 = 4;
loc_831AB0E0:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,832
	ctx.r4.s64 = ctx.r1.s64 + 832;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x83197900
	sub_83197900(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831ab150
	if (cr6.eq) goto loc_831AB150;
loc_831AB114:
	// lwz r11,420(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// addi r3,r1,1976
	ctx.r3.s64 = ctx.r1.s64 + 1976;
	// stw r27,416(r1)
	PPC_STORE_U32(ctx.r1.u32 + 416, r27.u32);
	// rlwimi r11,r28,2,16,29
	r11.u64 = (rotl32(r28.u32, 2) & 0xFFFC) | (r11.u64 & 0xFFFFFFFFFFFF0003);
	// rlwinm r11,r11,0,15,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1FFFC;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,420(r1)
	PPC_STORE_U32(ctx.r1.u32 + 420, r11.u32);
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// ld r5,416(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 416);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319fa18
	sub_8319FA18(ctx, base);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplw cr6,r28,r30
	cr6.compare<uint32_t>(r28.u32, r30.u32, xer);
	// blt cr6,0x831ab114
	if (cr6.lt) goto loc_831AB114;
loc_831AB150:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,832
	ctx.r3.s64 = ctx.r1.s64 + 832;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,832
	ctx.r3.s64 = ctx.r1.s64 + 832;
	// subf r25,r30,r25
	r25.s64 = r25.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831ab0c8
	goto loc_831AB0C8;
loc_831AB1A0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,2824
	ctx.r3.s64 = ctx.r1.s64 + 2824;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AB1B8:
	// lwz r24,3500(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r5,r29,1
	ctx.r5.s64 = r29.s64 + 1;
	// addi r3,r1,672
	ctx.r3.s64 = ctx.r1.s64 + 672;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// cmpwi cr6,r25,49
	cr6.compare<int32_t>(r25.s32, 49, xer);
	// beq cr6,0x831ab1f4
	if (cr6.eq) goto loc_831AB1F4;
	// cmpwi cr6,r25,52
	cr6.compare<int32_t>(r25.s32, 52, xer);
	// beq cr6,0x831ab1f4
	if (cr6.eq) goto loc_831AB1F4;
	// lwz r10,680(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	// lwz r11,676(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r26,r10,r11
	r26.u64 = ctx.r10.u64 + r11.u64;
	// b 0x831ab20c
	goto loc_831AB20C;
loc_831AB1F4:
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,2840
	ctx.r3.s64 = ctx.r1.s64 + 2840;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// ld r11,0(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// addi r26,r1,664
	r26.s64 = ctx.r1.s64 + 664;
	// std r11,664(r1)
	PPC_STORE_U64(ctx.r1.u32 + 664, r11.u64);
loc_831AB20C:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x83140e80
	sub_83140E80(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,1576
	ctx.r3.s64 = ctx.r1.s64 + 1576;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AB234:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831ab2c4
	if (cr6.eq) goto loc_831AB2C4;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r28,r29
	r28.u64 = r29.u64;
	// blt cr6,0x831ab24c
	if (cr6.lt) goto loc_831AB24C;
	// li r28,4
	r28.s64 = 4;
loc_831AB24C:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r4,r1,1576
	ctx.r4.s64 = ctx.r1.s64 + 1576;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ab284
	if (cr6.eq) goto loc_831AB284;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r5,12(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_831AB284:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// rlwimi r11,r28,25,4,6
	r11.u64 = (rotl32(r28.u32, 25) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,672
	ctx.r3.s64 = ctx.r1.s64 + 672;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,1576
	ctx.r3.s64 = ctx.r1.s64 + 1576;
	// subf r29,r28,r29
	r29.s64 = r29.s64 - r28.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831ab234
	goto loc_831AB234;
loc_831AB2C4:
	// addi r11,r1,664
	r11.s64 = ctx.r1.s64 + 664;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,2856
	ctx.r3.s64 = ctx.r1.s64 + 2856;
	// b 0x831a8474
	goto loc_831A8474;
loc_831AB2DC:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad734
	if (cr6.eq) goto loc_831AD734;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad734
	if (!cr6.eq) goto loc_831AD734;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad728
	if (cr6.eq) goto loc_831AD728;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad728
	if (!cr6.eq) goto loc_831AD728;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831ad71c
	if (cr6.eq) goto loc_831AD71C;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831ad71c
	if (!cr6.eq) goto loc_831AD71C;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r30,8(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831ab364
	if (!cr6.eq) goto loc_831AB364;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ab34c
	if (cr6.eq) goto loc_831AB34C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831ab374
	goto loc_831AB374;
loc_831AB34C:
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r5,r1,124
	ctx.r5.s64 = ctx.r1.s64 + 124;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831ab374
	goto loc_831AB374;
loc_831AB364:
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// addi r5,r1,124
	ctx.r5.s64 = ctx.r1.s64 + 124;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831AB374:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad6ec
	if (cr0.eq) goto loc_831AD6EC;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831ab3b4
	if (!cr6.eq) goto loc_831AB3B4;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ab39c
	if (cr6.eq) goto loc_831AB39C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831ab3c8
	goto loc_831AB3C8;
loc_831AB39C:
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831ab3c8
	goto loc_831AB3C8;
loc_831AB3B4:
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831AB3C8:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad6f8
	if (cr0.eq) goto loc_831AD6F8;
	// cmpwi cr6,r25,53
	cr6.compare<int32_t>(r25.s32, 53, xer);
	// beq cr6,0x831ab3e0
	if (cr6.eq) goto loc_831AB3E0;
	// cmpwi cr6,r25,50
	cr6.compare<int32_t>(r25.s32, 50, xer);
	// bne cr6,0x831ab3f4
	if (!cr6.eq) goto loc_831AB3F4;
loc_831AB3E0:
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// stw r9,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r9.u32);
	// b 0x831ab3fc
	goto loc_831AB3FC;
loc_831AB3F4:
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r9,116(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
loc_831AB3FC:
	// lwz r8,120(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// bne cr6,0x831ad704
	if (!cr6.eq) goto loc_831AD704;
	// lwz r10,124(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// mullw r7,r11,r10
	ctx.r7.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// cmplw cr6,r29,r7
	cr6.compare<uint32_t>(r29.u32, ctx.r7.u32, xer);
	// bne cr6,0x831ad710
	if (!cr6.eq) goto loc_831AD710;
	// mullw r30,r10,r8
	r30.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r8.s32);
	// mullw r26,r9,r11
	r26.s64 = int64_t(ctx.r9.s32) * int64_t(r11.s32);
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// bne cr6,0x831ab464
	if (!cr6.eq) goto loc_831AB464;
	// cmplwi cr6,r26,1
	cr6.compare<uint32_t>(r26.u32, 1, xer);
	// bne cr6,0x831ab464
	if (!cr6.eq) goto loc_831AB464;
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,1520
	ctx.r3.s64 = ctx.r1.s64 + 1520;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1360
	ctx.r3.s64 = ctx.r1.s64 + 1360;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// addi r5,r1,1360
	ctx.r5.s64 = ctx.r1.s64 + 1360;
	// addi r4,r1,1520
	ctx.r4.s64 = ctx.r1.s64 + 1520;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d0e0
	sub_8319D0E0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// b 0x831a9d5c
	goto loc_831A9D5C;
loc_831AB464:
	// lwz r24,3500(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// add r28,r26,r30
	r28.u64 = r26.u64 + r30.u64;
	// addi r3,r1,1600
	ctx.r3.s64 = ctx.r1.s64 + 1600;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r27,r28
	r27.u64 = r28.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,2008
	ctx.r3.s64 = ctx.r1.s64 + 2008;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// cmplw cr6,r29,r30
	cr6.compare<uint32_t>(r29.u32, r30.u32, xer);
	// bgt cr6,0x831ab4bc
	if (cr6.gt) goto loc_831AB4BC;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// addi r5,r1,1600
	ctx.r5.s64 = ctx.r1.s64 + 1600;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19f8
	sub_831A19F8(ctx, base);
	// mr r27,r30
	r27.u64 = r30.u64;
	// mr r26,r28
	r26.u64 = r28.u64;
	// add r25,r28,r30
	r25.u64 = r28.u64 + r30.u64;
	// b 0x831ab528
	goto loc_831AB528;
loc_831AB4BC:
	// cmplw cr6,r29,r27
	cr6.compare<uint32_t>(r29.u32, r27.u32, xer);
	// ble cr6,0x831ab4fc
	if (!cr6.gt) goto loc_831AB4FC;
	// subf r28,r27,r29
	r28.s64 = r29.s64 - r27.s64;
	// add r25,r28,r27
	r25.u64 = r28.u64 + r27.u64;
loc_831AB4CC:
	// lwz r11,372(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r10,368(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	// rlwinm r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r11,372(r1)
	PPC_STORE_U32(ctx.r1.u32 + 372, r11.u32);
	// stw r10,368(r1)
	PPC_STORE_U32(ctx.r1.u32 + 368, ctx.r10.u32);
	// ld r4,368(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 368);
	// bl 0x8319fd40
	sub_8319FD40(ctx, base);
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// bne 0x831ab4cc
	if (!cr0.eq) goto loc_831AB4CC;
	// b 0x831ab500
	goto loc_831AB500;
loc_831AB4FC:
	// rlwinm r25,r27,1,0,30
	r25.u64 = rotl64(r27.u32 | (r27.u64 << 32), 1) & 0xFFFFFFFE;
loc_831AB500:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// addi r5,r1,1600
	ctx.r5.s64 = ctx.r1.s64 + 1600;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19f8
	sub_831A19F8(ctx, base);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r1,2008
	ctx.r5.s64 = ctx.r1.s64 + 2008;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19f8
	sub_831A19F8(ctx, base);
loc_831AB528:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,2040
	ctx.r3.s64 = ctx.r1.s64 + 2040;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// addi r11,r1,2040
	r11.s64 = ctx.r1.s64 + 2040;
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// stw r11,864(r1)
	PPC_STORE_U32(ctx.r1.u32 + 864, r11.u32);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,2072
	ctx.r3.s64 = ctx.r1.s64 + 2072;
	// stw r10,872(r1)
	PPC_STORE_U32(ctx.r1.u32 + 872, ctx.r10.u32);
	// lwz r11,124(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// stw r11,868(r1)
	PPC_STORE_U32(ctx.r1.u32 + 868, r11.u32);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// addi r11,r1,2072
	r11.s64 = ctx.r1.s64 + 2072;
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// stw r11,896(r1)
	PPC_STORE_U32(ctx.r1.u32 + 896, r11.u32);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,2104
	ctx.r3.s64 = ctx.r1.s64 + 2104;
	// stw r10,904(r1)
	PPC_STORE_U32(ctx.r1.u32 + 904, ctx.r10.u32);
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stw r11,900(r1)
	PPC_STORE_U32(ctx.r1.u32 + 900, r11.u32);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// lwz r11,124(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ab654
	if (cr6.eq) goto loc_831AB654;
loc_831AB598:
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ab644
	if (cr6.eq) goto loc_831AB644;
loc_831AB5A8:
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// li r30,0
	r30.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ab624
	if (cr6.eq) goto loc_831AB624;
loc_831AB5BC:
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,864
	ctx.r3.s64 = ctx.r1.s64 + 864;
	// bl 0x8319ba10
	sub_8319BA10(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,896
	ctx.r3.s64 = ctx.r1.s64 + 896;
	// bl 0x8319ba10
	sub_8319BA10(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d0e0
	sub_8319D0E0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831ab610
	if (cr6.eq) goto loc_831AB610;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x831ab614
	goto loc_831AB614;
loc_831AB610:
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
loc_831AB614:
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x831ab5bc
	if (cr6.lt) goto loc_831AB5BC;
loc_831AB624:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,2104
	ctx.r3.s64 = ctx.r1.s64 + 2104;
	// bl 0x8319aea0
	sub_8319AEA0(ctx, base);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x831ab5a8
	if (cr6.lt) goto loc_831AB5A8;
loc_831AB644:
	// lwz r11,124(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x831ab598
	if (cr6.lt) goto loc_831AB598;
loc_831AB654:
	// subf. r5,r29,r25
	ctx.r5.s64 = r25.s64 - r29.s64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,2872
	ctx.r3.s64 = ctx.r1.s64 + 2872;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AB668:
	// cmplwi cr6,r29,1
	cr6.compare<uint32_t>(r29.u32, 1, xer);
	// beq cr6,0x831abd94
	if (cr6.eq) goto loc_831ABD94;
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319f958
	sub_8319F958(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198e48
	sub_83198E48(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,928
	ctx.r3.s64 = ctx.r1.s64 + 928;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AB6A4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831ab6bc
	if (cr6.lt) goto loc_831AB6BC;
	// li r30,4
	r30.s64 = 4;
loc_831AB6BC:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,928
	ctx.r4.s64 = ctx.r1.s64 + 928;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r30,25,4,6
	ctx.r10.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// rlwinm r10,r10,0,27,18
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,928
	ctx.r3.s64 = ctx.r1.s64 + 928;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,928
	ctx.r3.s64 = ctx.r1.s64 + 928;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831ab6a4
	goto loc_831AB6A4;
loc_831AB728:
	// lwz r25,3500(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// rlwinm r5,r29,1,0,30
	ctx.r5.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,2136
	ctx.r3.s64 = ctx.r1.s64 + 2136;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,2168
	ctx.r3.s64 = ctx.r1.s64 + 2168;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r27,r29
	r27.u64 = r29.u64;
	// li r26,1
	r26.s64 = 1;
loc_831AB754:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831ab82c
	if (cr6.eq) goto loc_831AB82C;
	// addi r3,r1,2136
	ctx.r3.s64 = ctx.r1.s64 + 2136;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r1,2168
	ctx.r3.s64 = ctx.r1.s64 + 2168;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8319b2a8
	sub_8319B2A8(ctx, base);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,15872
	cr6.compare<uint32_t>(r11.u32, 15872, xer);
	// bne cr6,0x831ab7c0
	if (!cr6.eq) goto loc_831AB7C0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319c298
	sub_8319C298(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d010
	sub_8319D010(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198c80
	sub_83198C80(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// b 0x831ab818
	goto loc_831AB818;
loc_831AB7C0:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// li r6,107
	ctx.r6.s64 = 107;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// stw r24,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r24.u32);
loc_831AB818:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r27,r27,-1
	r27.s64 = r27.s64 + -1;
	// rlwimi r11,r26,0,16,14
	r11.u64 = (rotl32(r26.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (r11.u64 & 0x10000);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// b 0x831ab754
	goto loc_831AB754;
loc_831AB82C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,2888
	ctx.r3.s64 = ctx.r1.s64 + 2888;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AB844:
	// lwz r26,3500(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8319f9b8
	sub_8319F9B8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// rlwinm r5,r29,1,0,30
	ctx.r5.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,960
	ctx.r3.s64 = ctx.r1.s64 + 960;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,2200
	ctx.r3.s64 = ctx.r1.s64 + 2200;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r28,r29
	r28.u64 = r29.u64;
loc_831AB894:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831ab964
	if (cr6.eq) goto loc_831AB964;
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// mr r30,r28
	r30.u64 = r28.u64;
	// blt cr6,0x831ab8ac
	if (cr6.lt) goto loc_831AB8AC;
	// li r30,4
	r30.s64 = 4;
loc_831AB8AC:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,960
	ctx.r4.s64 = ctx.r1.s64 + 960;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,2200
	ctx.r4.s64 = ctx.r1.s64 + 2200;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r30,25,4,6
	ctx.r10.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// rlwinm r10,r10,0,27,18
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,960
	ctx.r3.s64 = ctx.r1.s64 + 960;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,960
	ctx.r3.s64 = ctx.r1.s64 + 960;
	// subf r28,r30,r28
	r28.s64 = r28.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831ab894
	goto loc_831AB894;
loc_831AB964:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,2904
	ctx.r3.s64 = ctx.r1.s64 + 2904;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AB97C:
	// lwz r25,3500(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,280
	ctx.r3.s64 = ctx.r1.s64 + 280;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// rlwinm r28,r29,1,0,30
	r28.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r3,r1,2264
	ctx.r3.s64 = ctx.r1.s64 + 2264;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,2232
	ctx.r3.s64 = ctx.r1.s64 + 2232;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,2232
	ctx.r5.s64 = ctx.r1.s64 + 2232;
	// addi r4,r1,2264
	ctx.r4.s64 = ctx.r1.s64 + 2264;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319e160
	sub_8319E160(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// ld r30,280(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + 280);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319cc98
	sub_8319CC98(ctx, base);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// rlwinm r5,r11,18,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,2920
	ctx.r3.s64 = ctx.r1.s64 + 2920;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x8319bc78
	sub_8319BC78(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r3,r1,2936
	ctx.r3.s64 = ctx.r1.s64 + 2936;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x8319bc78
	sub_8319BC78(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// addi r3,r1,2952
	ctx.r3.s64 = ctx.r1.s64 + 2952;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// bl 0x8319cbc8
	sub_8319CBC8(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c508
	sub_8319C508(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198ee0
	sub_83198EE0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831993d0
	sub_831993D0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r3,r1,992
	ctx.r3.s64 = ctx.r1.s64 + 992;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,2296
	ctx.r3.s64 = ctx.r1.s64 + 2296;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r28,r29
	r28.u64 = r29.u64;
loc_831ABB6C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831abc7c
	if (cr6.eq) goto loc_831ABC7C;
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// mr r30,r28
	r30.u64 = r28.u64;
	// blt cr6,0x831abb84
	if (cr6.lt) goto loc_831ABB84;
	// li r30,4
	r30.s64 = 4;
loc_831ABB84:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,992
	ctx.r4.s64 = ctx.r1.s64 + 992;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,2296
	ctx.r4.s64 = ctx.r1.s64 + 2296;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// rlwinm r21,r30,25,4,6
	r21.u64 = rotl64(r30.u32 | (r30.u64 << 32), 25) & 0xE000000;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// rlwinm r11,r11,0,7,3
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// or r11,r11,r21
	r11.u64 = r11.u64 | r21.u64;
	// rlwinm r11,r11,0,27,18
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// stw r11,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r11.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// rlwinm r11,r11,0,7,3
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// or r11,r11,r21
	r11.u64 = r11.u64 | r21.u64;
	// rlwinm r11,r11,0,27,18
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFE01F;
	// stw r11,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r11.u32);
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,992
	ctx.r3.s64 = ctx.r1.s64 + 992;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,992
	ctx.r3.s64 = ctx.r1.s64 + 992;
	// subf r28,r30,r28
	r28.s64 = r28.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831abb6c
	goto loc_831ABB6C;
loc_831ABC7C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,2968
	ctx.r3.s64 = ctx.r1.s64 + 2968;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831ABC94:
	// li r5,4
	ctx.r5.s64 = 4;
	// fmr f4,f15
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f15.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f3,f15
	ctx.f3.f64 = f15.f64;
	// addi r3,r1,432
	ctx.r3.s64 = ctx.r1.s64 + 432;
	// fmr f2,f15
	ctx.f2.f64 = f15.f64;
	// fmr f1,f15
	ctx.f1.f64 = f15.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,436(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// clrlwi r11,r11,15
	r11.u64 = r11.u32 & 0x1FFFF;
	// addi r3,r1,1024
	ctx.r3.s64 = ctx.r1.s64 + 1024;
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// stw r11,436(r1)
	PPC_STORE_U32(ctx.r1.u32 + 436, r11.u32);
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831ABCD4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831abcec
	if (cr6.lt) goto loc_831ABCEC;
	// li r30,4
	r30.s64 = 4;
loc_831ABCEC:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1024
	ctx.r4.s64 = ctx.r1.s64 + 1024;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r4,r1,432
	ctx.r4.s64 = ctx.r1.s64 + 432;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r30,25,4,6
	ctx.r10.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (ctx.r10.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x83198bd8
	sub_83198BD8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1024
	ctx.r3.s64 = ctx.r1.s64 + 1024;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,1024
	ctx.r3.s64 = ctx.r1.s64 + 1024;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831abcd4
	goto loc_831ABCD4;
loc_831ABD94:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,1056
	ctx.r3.s64 = ctx.r1.s64 + 1056;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831ABDA4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831abdbc
	if (cr6.lt) goto loc_831ABDBC;
	// li r30,4
	r30.s64 = 4;
loc_831ABDBC:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1056
	ctx.r4.s64 = ctx.r1.s64 + 1056;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197570
	sub_83197570(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197570
	sub_83197570(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,4
	ctx.r6.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r5,r10,18,29,31
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1056
	ctx.r3.s64 = ctx.r1.s64 + 1056;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,1056
	ctx.r3.s64 = ctx.r1.s64 + 1056;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831abda4
	goto loc_831ABDA4;
loc_831ABE68:
	// li r5,1
	ctx.r5.s64 = 1;
	// lfs f1,456(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f1.f64 = double(temp.f32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,1184
	ctx.r3.s64 = ctx.r1.s64 + 1184;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r28,3500(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mulli r5,r29,3
	ctx.r5.s64 = r29.s64 * 3;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,2328
	ctx.r3.s64 = ctx.r1.s64 + 2328;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// rlwinm r30,r29,1,0,30
	r30.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r3,r1,2360
	ctx.r3.s64 = ctx.r1.s64 + 2360;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,2392
	ctx.r3.s64 = ctx.r1.s64 + 2392;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831ABEC0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831ac018
	if (cr6.eq) goto loc_831AC018;
	// addi r3,r1,2328
	ctx.r3.s64 = ctx.r1.s64 + 2328;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,2360
	ctx.r3.s64 = ctx.r1.s64 + 2360;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r3,r1,2392
	ctx.r3.s64 = ctx.r1.s64 + 2392;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c078
	sub_8319C078(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c078
	sub_8319C078(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198db0
	sub_83198DB0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r7,228
	ctx.r7.s64 = 228;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cb660
	sub_831CB660(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x831971b0
	sub_831971B0(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r4,r1,1184
	ctx.r4.s64 = ctx.r1.s64 + 1184;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319c078
	sub_8319C078(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r5,12(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311c590
	sub_8311C590(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x83122f18
	sub_83122F18(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83198778
	sub_83198778(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831994a0
	sub_831994A0(ctx, base);
	// stw r3,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r3.u32);
	// li r11,1
	r11.s64 = 1;
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// lwz r10,4(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r27)
	PPC_STORE_U32(r27.u32 + 4, ctx.r10.u32);
	// b 0x831abec0
	goto loc_831ABEC0;
loc_831AC018:
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,2984
	ctx.r3.s64 = ctx.r1.s64 + 2984;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AC030:
	// lwz r27,3500(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// rlwinm r5,r29,1,0,30
	ctx.r5.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,1088
	ctx.r3.s64 = ctx.r1.s64 + 1088;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,2424
	ctx.r3.s64 = ctx.r1.s64 + 2424;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r28,r29
	r28.u64 = r29.u64;
loc_831AC058:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831ac0d4
	if (cr6.eq) goto loc_831AC0D4;
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// mr r30,r28
	r30.u64 = r28.u64;
	// blt cr6,0x831ac070
	if (cr6.lt) goto loc_831AC070;
	// li r30,4
	r30.s64 = 4;
loc_831AC070:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1088
	ctx.r4.s64 = ctx.r1.s64 + 1088;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,2424
	ctx.r4.s64 = ctx.r1.s64 + 2424;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83197660
	sub_83197660(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1088
	ctx.r3.s64 = ctx.r1.s64 + 1088;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,1088
	ctx.r3.s64 = ctx.r1.s64 + 1088;
	// subf r28,r30,r28
	r28.s64 = r28.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831ac058
	goto loc_831AC058;
loc_831AC0D4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,3000
	ctx.r3.s64 = ctx.r1.s64 + 3000;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AC0EC:
	// rlwinm r21,r29,2,0,29
	r21.u64 = rotl64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83110880
	sub_83110880(ctx, base);
	// lwz r20,3500(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r3,r1,1624
	ctx.r3.s64 = ctx.r1.s64 + 1624;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,1624
	ctx.r5.s64 = ctx.r1.s64 + 1624;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a19f8
	sub_831A19F8(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// addi r3,r1,2456
	ctx.r3.s64 = ctx.r1.s64 + 2456;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831ac164
	if (cr6.eq) goto loc_831AC164;
	// mr r28,r22
	r28.u64 = r22.u64;
	// mr r30,r29
	r30.u64 = r29.u64;
loc_831AC14C:
	// addi r3,r1,2456
	ctx.r3.s64 = ctx.r1.s64 + 2456;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// stw r3,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r3.u32);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// bne 0x831ac14c
	if (!cr0.eq) goto loc_831AC14C;
loc_831AC164:
	// lwz r26,20(r14)
	r26.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// lwz r24,24(r14)
	r24.u64 = PPC_LOAD_U32(r14.u32 + 24);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831ac1c4
	if (cr6.eq) goto loc_831AC1C4;
	// mr r27,r22
	r27.u64 = r22.u64;
	// mr r23,r26
	r23.u64 = r26.u64;
loc_831AC17C:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831ac1b8
	if (cr6.eq) goto loc_831AC1B8;
	// rlwinm r25,r26,2,0,29
	r25.u64 = rotl64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r28,r27
	r28.u64 = r27.u64;
	// mr r30,r24
	r30.u64 = r24.u64;
loc_831AC190:
	// addi r3,r1,1624
	ctx.r3.s64 = ctx.r1.s64 + 1624;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// add r28,r25,r28
	r28.u64 = r25.u64 + r28.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// bne 0x831ac190
	if (!cr0.eq) goto loc_831AC190;
loc_831AC1B8:
	// addic. r23,r23,-1
	xer.ca = r23.u32 > 0;
	r23.s64 = r23.s64 + -1;
	cr0.compare<int32_t>(r23.s32, 0, xer);
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// bne 0x831ac17c
	if (!cr0.eq) goto loc_831AC17C;
loc_831AC1C4:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83118478
	sub_83118478(ctx, base);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// addi r3,r1,3016
	ctx.r3.s64 = ctx.r1.s64 + 3016;
	// b 0x831a69c0
	goto loc_831A69C0;
loc_831AC1F0:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x831ad740
	if (!cr6.eq) goto loc_831AD740;
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r3,r1,1648
	ctx.r3.s64 = ctx.r1.s64 + 1648;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,2488
	ctx.r3.s64 = ctx.r1.s64 + 2488;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AC228:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,2
	cr6.compare<uint32_t>(r29.u32, 2, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831ac240
	if (cr6.lt) goto loc_831AC240;
	// li r30,2
	r30.s64 = 2;
loc_831AC240:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1648
	ctx.r4.s64 = ctx.r1.s64 + 1648;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r5,r4,16
	ctx.r5.s64 = ctx.r4.s64 + 16;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,120
	ctx.r6.s64 = 120;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// lis r8,0
	ctx.r8.s64 = 0;
	// rlwimi r11,r10,1,27,30
	r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x1E) | (r11.u64 & 0xFFFFFFFFFFFFFFE1);
	// ori r10,r8,32769
	ctx.r10.u64 = ctx.r8.u64 | 32769;
	// stw r11,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r11.u32);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwimi r11,r10,30,7,18
	r11.u64 = (rotl32(ctx.r10.u32, 30) & 0x1FFE000) | (r11.u64 & 0xFFFFFFFFFE001FFF);
	// rlwimi r11,r10,30,1,1
	r11.u64 = (rotl32(ctx.r10.u32, 30) & 0x40000000) | (r11.u64 & 0xFFFFFFFFBFFFFFFF);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// mr r4,r9
	ctx.r4.u64 = ctx.r9.u64;
	// bl 0x83198550
	sub_83198550(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x831233b0
	sub_831233B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r9,r10,1,27,31
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 1) & 0x1F) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFE0);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// oris r10,r10,4096
	ctx.r10.u64 = ctx.r10.u64 | 268435456;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// oris r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 524288;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x83123458
	sub_83123458(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,16
	cr6.compare<int32_t>(r25.s32, 16, xer);
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwimi r11,r30,25,4,6
	r11.u64 = (rotl32(r30.u32, 25) & 0xE000000) | (r11.u64 & 0xFFFFFFFFF1FFFFFF);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// bne cr6,0x831ac328
	if (!cr6.eq) goto loc_831AC328;
	// li r10,29
	ctx.r10.s64 = 29;
	// rlwimi r11,r10,8,19,26
	r11.u64 = (rotl32(ctx.r10.u32, 8) & 0x1FE0) | (r11.u64 & 0xFFFFFFFFFFFFE01F);
	// b 0x831ac330
	goto loc_831AC330;
loc_831AC328:
	// li r10,237
	ctx.r10.s64 = 237;
	// rlwimi r11,r10,5,19,26
	r11.u64 = (rotl32(ctx.r10.u32, 5) & 0x1FE0) | (r11.u64 & 0xFFFFFFFFFFFFE01F);
loc_831AC330:
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,2488
	ctx.r3.s64 = ctx.r1.s64 + 2488;
	// bl 0x8319af98
	sub_8319AF98(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1648
	ctx.r3.s64 = ctx.r1.s64 + 1648;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831ac228
	goto loc_831AC228;
loc_831AC354:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x831ad754
	if (!cr6.eq) goto loc_831AD754;
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r3,r1,1672
	ctx.r3.s64 = ctx.r1.s64 + 1672;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,2520
	ctx.r3.s64 = ctx.r1.s64 + 2520;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AC38C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// cmplwi cr6,r29,2
	cr6.compare<uint32_t>(r29.u32, 2, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831ac3a4
	if (cr6.lt) goto loc_831AC3A4;
	// li r30,2
	r30.s64 = 2;
loc_831AC3A4:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1672
	ctx.r4.s64 = ctx.r1.s64 + 1672;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r5,r4,16
	ctx.r5.s64 = ctx.r4.s64 + 16;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,120
	ctx.r6.s64 = 120;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x83123458
	sub_83123458(ctx, base);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// rlwimi r11,r10,1,27,30
	r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x1E) | (r11.u64 & 0xFFFFFFFFFFFFFFE1);
	// lis r10,0
	ctx.r10.s64 = 0;
	// stw r11,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r11.u32);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// ori r11,r10,32769
	r11.u64 = ctx.r10.u64 | 32769;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r9
	ctx.r4.u64 = ctx.r9.u64;
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwimi r10,r11,30,7,18
	ctx.r10.u64 = (rotl32(r11.u32, 30) & 0x1FFE000) | (ctx.r10.u64 & 0xFFFFFFFFFE001FFF);
	// rlwimi r10,r11,30,1,1
	ctx.r10.u64 = (rotl32(r11.u32, 30) & 0x40000000) | (ctx.r10.u64 & 0xFFFFFFFFBFFFFFFF);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// bl 0x83198550
	sub_83198550(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x831233b0
	sub_831233B0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,232
	ctx.r6.s64 = 232;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwimi r9,r10,1,27,31
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 1) & 0x1F) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFE0);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// oris r10,r10,4096
	ctx.r10.u64 = ctx.r10.u64 | 268435456;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// oris r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 524288;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x83123520
	sub_83123520(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,237
	ctx.r6.s64 = 237;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83123520
	sub_83123520(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831970c0
	sub_831970C0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,2520
	ctx.r3.s64 = ctx.r1.s64 + 2520;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1672
	ctx.r3.s64 = ctx.r1.s64 + 1672;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831ac38c
	goto loc_831AC38C;
loc_831AC4C4:
	// li r28,12
	r28.s64 = 12;
	// b 0x831ac4d8
	goto loc_831AC4D8;
loc_831AC4CC:
	// li r28,13
	r28.s64 = 13;
	// b 0x831ac4d8
	goto loc_831AC4D8;
loc_831AC4D4:
	// li r28,14
	r28.s64 = 14;
loc_831AC4D8:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,1120
	ctx.r3.s64 = ctx.r1.s64 + 1120;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831AC4E8:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831accfc
	if (cr6.eq) goto loc_831ACCFC;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831ac500
	if (cr6.lt) goto loc_831AC500;
	// li r30,4
	r30.s64 = 4;
loc_831AC500:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1120
	ctx.r4.s64 = ctx.r1.s64 + 1120;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,103
	ctx.r6.s64 = 103;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x831687b8
	sub_831687B8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r28,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r28.u32);
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1120
	ctx.r3.s64 = ctx.r1.s64 + 1120;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,1120
	ctx.r3.s64 = ctx.r1.s64 + 1120;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831ac4e8
	goto loc_831AC4E8;
loc_831AC57C:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r25,24(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmpwi cr6,r25,197
	cr6.compare<int32_t>(r25.s32, 197, xer);
	// bgt cr6,0x831ac5bc
	if (cr6.gt) goto loc_831AC5BC;
	// cmpwi cr6,r25,190
	cr6.compare<int32_t>(r25.s32, 190, xer);
	// bge cr6,0x831ac5dc
	if (!cr6.lt) goto loc_831AC5DC;
	// cmpwi cr6,r25,142
	cr6.compare<int32_t>(r25.s32, 142, xer);
	// blt cr6,0x831ad7a4
	if (cr6.lt) goto loc_831AD7A4;
	// cmpwi cr6,r25,149
	cr6.compare<int32_t>(r25.s32, 149, xer);
	// ble cr6,0x831ac5dc
	if (!cr6.gt) goto loc_831AC5DC;
	// cmpwi cr6,r25,165
	cr6.compare<int32_t>(r25.s32, 165, xer);
	// ble cr6,0x831ad7a4
	if (!cr6.gt) goto loc_831AD7A4;
	// cmpwi cr6,r25,173
	cr6.compare<int32_t>(r25.s32, 173, xer);
	// b 0x831ac5d8
	goto loc_831AC5D8;
loc_831AC5BC:
	// cmpwi cr6,r25,200
	cr6.compare<int32_t>(r25.s32, 200, xer);
	// blt cr6,0x831ad7a4
	if (cr6.lt) goto loc_831AD7A4;
	// cmpwi cr6,r25,203
	cr6.compare<int32_t>(r25.s32, 203, xer);
	// ble cr6,0x831ac5dc
	if (!cr6.gt) goto loc_831AC5DC;
	// cmpwi cr6,r25,207
	cr6.compare<int32_t>(r25.s32, 207, xer);
	// ble cr6,0x831ad7a4
	if (!cr6.gt) goto loc_831AD7A4;
	// cmpwi cr6,r25,211
	cr6.compare<int32_t>(r25.s32, 211, xer);
loc_831AC5D8:
	// bgt cr6,0x831ad7a4
	if (cr6.gt) goto loc_831AD7A4;
loc_831AC5DC:
	// lwz r9,532(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// li r11,0
	r11.s64 = 0;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
loc_831AC5E8:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplw cr6,r8,r25
	cr6.compare<uint32_t>(ctx.r8.u32, r25.u32, xer);
	// beq cr6,0x831ac604
	if (cr6.eq) goto loc_831AC604;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,52
	cr6.compare<uint32_t>(r11.u32, 52, xer);
	// blt cr6,0x831ac5e8
	if (cr6.lt) goto loc_831AC5E8;
loc_831AC604:
	// cmplwi cr6,r11,52
	cr6.compare<uint32_t>(r11.u32, 52, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x831ad79c
	if (cr6.eq) goto loc_831AD79C;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r9,r11,15,29,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x7;
	// rlwinm r8,r11,12,31,31
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 12) & 0x1;
	// rlwinm r7,r11,11,31,31
	ctx.r7.u64 = rotl64(r11.u32 | (r11.u64 << 32), 11) & 0x1;
	// rlwinm r6,r11,10,30,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 10) & 0x3;
	// bl 0x831a1a50
	sub_831A1A50(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831AC638:
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831953b0
	sub_831953B0(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// lwz r11,24(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 24);
	// clrlwi r11,r11,17
	r11.u64 = r11.u32 & 0x7FFF;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x831ac7ec
	if (!cr6.gt) goto loc_831AC7EC;
	// lwz r10,4(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r24,16(r10)
	r24.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// beq cr6,0x831ac730
	if (cr6.eq) goto loc_831AC730;
	// li r26,0
	r26.s64 = 0;
	// li r27,0
	r27.s64 = 0;
	// mr r25,r11
	r25.u64 = r11.u64;
loc_831AC678:
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r10,80(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831ac694
	if (cr6.eq) goto loc_831AC694;
	// rotlwi r11,r10,0
	r11.u64 = rotl32(ctx.r10.u32, 0);
	// lwzx r30,r11,r27
	r30.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// b 0x831ac698
	goto loc_831AC698;
loc_831AC694:
	// li r30,0
	r30.s64 = 0;
loc_831AC698:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831ac720
	if (cr6.eq) goto loc_831AC720;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// rlwinm. r11,r11,29,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ac720
	if (cr0.eq) goto loc_831AC720;
	// mr r28,r11
	r28.u64 = r11.u64;
loc_831AC6B4:
	// ld r11,0(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ac714
	if (cr6.eq) goto loc_831AC714;
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// clrlwi. r10,r11,30
	ctx.r10.u64 = r11.u32 & 0x3;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831ac714
	if (!cr0.eq) goto loc_831AC714;
	// rlwinm r11,r11,15,17,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x7FFF;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x831ac714
	if (!cr6.eq) goto loc_831AC714;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// bl 0x831972a0
	sub_831972A0(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// li r11,1
	r11.s64 = 1;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
loc_831AC714:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// bne 0x831ac6b4
	if (!cr0.eq) goto loc_831AC6B4;
loc_831AC720:
	// addic. r25,r25,-1
	xer.ca = r25.u32 > 0;
	r25.s64 = r25.s64 + -1;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// addi r26,r26,40
	r26.s64 = r26.s64 + 40;
	// bne 0x831ac678
	if (!cr0.eq) goto loc_831AC678;
loc_831AC730:
	// lwz r20,3500(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// li r30,0
	r30.s64 = 0;
	// lwz r11,4(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831ac76c
	if (!cr0.eq) goto loc_831AC76C;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831ac76c
	if (cr0.eq) goto loc_831AC76C;
loc_831AC74C:
	// rlwinm r10,r11,0,0,30
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831ac76c
	if (!cr0.eq) goto loc_831AC76C;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831ac74c
	if (!cr6.eq) goto loc_831AC74C;
loc_831AC76C:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// addi r3,r1,2552
	ctx.r3.s64 = ctx.r1.s64 + 2552;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831ac7f0
	if (cr6.eq) goto loc_831AC7F0;
	// mr r28,r30
	r28.u64 = r30.u64;
loc_831AC788:
	// addi r3,r1,2552
	ctx.r3.s64 = ctx.r1.s64 + 2552;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r10,r11,30
	ctx.r10.u64 = r11.u32 & 0x3;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831ac7e0
	if (!cr0.eq) goto loc_831AC7E0;
	// rlwinm r11,r11,15,17,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 15) & 0x7FFF;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x831ac7e0
	if (!cr6.eq) goto loc_831AC7E0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// bl 0x831972a0
	sub_831972A0(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// li r11,1
	r11.s64 = 1;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
loc_831AC7E0:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// bne 0x831ac788
	if (!cr0.eq) goto loc_831AC788;
	// b 0x831ac7f0
	goto loc_831AC7F0;
loc_831AC7EC:
	// lwz r20,3500(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
loc_831AC7F0:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// li r6,86
	ctx.r6.s64 = 86;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,12(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8311bba0
	sub_8311BBA0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,12(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// lwz r11,24(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 24);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ac844
	if (!cr0.eq) goto loc_831AC844;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ac87c
	if (cr0.eq) goto loc_831AC87C;
loc_831AC844:
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ac860
	if (cr0.eq) goto loc_831AC860;
	// li r4,3585
	ctx.r4.s64 = 3585;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
	// b 0x831ac87c
	goto loc_831AC87C;
loc_831AC860:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8310ff78
	sub_8310FF78(ctx, base);
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// li r11,5
	r11.s64 = 5;
	// rlwimi r10,r11,2,23,31
	ctx.r10.u64 = (rotl32(r11.u32, 2) & 0x1FF) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFE00);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_831AC87C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// lwz r11,48(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 48);
	// oris r11,r11,32
	r11.u64 = r11.u64 | 2097152;
	// stw r11,48(r24)
	PPC_STORE_U32(r24.u32 + 48, r11.u32);
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// lwz r5,564(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// lwz r6,4(r21)
	ctx.r6.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319a538
	sub_8319A538(ctx, base);
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831acab4
	if (cr6.eq) goto loc_831ACAB4;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831acab4
	if (cr6.eq) goto loc_831ACAB4;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831ad7d8
	if (!cr6.eq) goto loc_831AD7D8;
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// mr. r22,r3
	r22.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r22.s32, 0, xer);
	// beq 0x831acab4
	if (cr0.eq) goto loc_831ACAB4;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// addi r3,r1,2584
	ctx.r3.s64 = ctx.r1.s64 + 2584;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// mr r25,r22
	r25.u64 = r22.u64;
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad844
	if (cr6.eq) goto loc_831AD844;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad844
	if (!cr6.eq) goto loc_831AD844;
	// mr r23,r11
	r23.u64 = r11.u64;
loc_831AC924:
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x831aca78
	if (!cr6.eq) goto loc_831ACA78;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad7e0
	if (!cr6.eq) goto loc_831AD7E0;
	// lwz r28,24(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831ad82c
	if (cr6.eq) goto loc_831AD82C;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x831ad82c
	if (!cr6.eq) goto loc_831AD82C;
	// lwz r10,4(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x831aca78
	if (cr6.eq) goto loc_831ACA78;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x831aca78
	if (cr6.eq) goto loc_831ACA78;
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831aca78
	if (cr6.eq) goto loc_831ACA78;
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// rlwinm. r9,r11,0,30,30
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831ad7ec
	if (!cr0.eq) goto loc_831AD7EC;
	// rlwinm. r9,r11,0,29,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831ad800
	if (!cr0.eq) goto loc_831AD800;
	// rlwinm. r11,r11,0,27,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831aca78
	if (cr0.eq) goto loc_831ACA78;
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831aca58
	if (cr6.eq) goto loc_831ACA58;
	// li r27,0
	r27.s64 = 0;
loc_831AC9B0:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831ad814
	if (cr6.eq) goto loc_831AD814;
	// addi r3,r1,2584
	ctx.r3.s64 = ctx.r1.s64 + 2584;
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319b2a8
	sub_8319B2A8(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r10,28(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x831aca04
	if (cr6.eq) goto loc_831ACA04;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d1b0
	sub_8319D1B0(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// li r11,1
	r11.s64 = 1;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwimi r10,r11,0,16,14
	ctx.r10.u64 = (rotl32(r11.u32, 0) & 0xFFFFFFFFFFFEFFFF) | (ctx.r10.u64 & 0x10000);
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
loc_831ACA04:
	// lwz r4,16(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r4,40
	ctx.r10.s64 = ctx.r4.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad820
	if (cr0.eq) goto loc_831AD820;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x83199928
	sub_83199928(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// add r10,r3,r27
	ctx.r10.u64 = ctx.r3.u64 + r27.u64;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r25,r25,-1
	r25.s64 = r25.s64 + -1;
	// addi r27,r27,8
	r27.s64 = r27.s64 + 8;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x831ac9b0
	if (cr6.lt) goto loc_831AC9B0;
loc_831ACA58:
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_831ACA78:
	// lwz r11,12(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831aca90
	if (cr6.eq) goto loc_831ACA90;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ad838
	if (!cr6.eq) goto loc_831AD838;
loc_831ACA90:
	// mr r23,r11
	r23.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831acaa4
	if (cr6.eq) goto loc_831ACAA4;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x831ac924
	if (!cr6.eq) goto loc_831AC924;
loc_831ACAA4:
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// addi r3,r1,3032
	ctx.r3.s64 = ctx.r1.s64 + 3032;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831ACAB4:
	// stw r24,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r24.u32);
	// lwz r11,16(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_831ACAD8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// bl 0x831a1760
	sub_831A1760(ctx, base);
	// b 0x831a534c
	goto loc_831A534C;
loc_831ACAEC:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,1152
	ctx.r3.s64 = ctx.r1.s64 + 1152;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
loc_831ACAFC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831accfc
	if (cr6.eq) goto loc_831ACCFC;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// mr r30,r29
	r30.u64 = r29.u64;
	// blt cr6,0x831acb14
	if (cr6.lt) goto loc_831ACB14;
	// li r30,4
	r30.s64 = 4;
loc_831ACB14:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1152
	ctx.r4.s64 = ctx.r1.s64 + 1152;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,103
	ctx.r6.s64 = 103;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x831687b8
	sub_831687B8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1152
	ctx.r3.s64 = ctx.r1.s64 + 1152;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,1152
	ctx.r3.s64 = ctx.r1.s64 + 1152;
	// subf r29,r30,r29
	r29.s64 = r29.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831acafc
	goto loc_831ACAFC;
loc_831ACB94:
	// li r27,7
	r27.s64 = 7;
	// b 0x831acbb8
	goto loc_831ACBB8;
loc_831ACB9C:
	// li r27,8
	r27.s64 = 8;
	// b 0x831acbb8
	goto loc_831ACBB8;
loc_831ACBA4:
	// li r27,9
	r27.s64 = 9;
	// b 0x831acbb8
	goto loc_831ACBB8;
loc_831ACBAC:
	// li r27,11
	r27.s64 = 11;
	// b 0x831acbb8
	goto loc_831ACBB8;
loc_831ACBB4:
	// li r27,10
	r27.s64 = 10;
loc_831ACBB8:
	// lwz r11,40(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 40);
	// lwz r26,3500(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x831acc00
	if (!cr6.eq) goto loc_831ACC00;
	// rlwinm r5,r29,1,0,30
	ctx.r5.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,2648
	ctx.r3.s64 = ctx.r1.s64 + 2648;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,2616
	ctx.r3.s64 = ctx.r1.s64 + 2616;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r6,r1,2616
	ctx.r6.s64 = ctx.r1.s64 + 2616;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r1,2648
	ctx.r4.s64 = ctx.r1.s64 + 2648;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319dfa8
	sub_8319DFA8(ctx, base);
loc_831ACC00:
	// rlwinm r5,r29,1,0,30
	ctx.r5.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,1040
	ctx.r3.s64 = ctx.r1.s64 + 1040;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,2680
	ctx.r3.s64 = ctx.r1.s64 + 2680;
	// bl 0x8319f358
	sub_8319F358(ctx, base);
	// mr r28,r29
	r28.u64 = r29.u64;
loc_831ACC24:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831acce4
	if (cr6.eq) goto loc_831ACCE4;
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// mr r30,r28
	r30.u64 = r28.u64;
	// blt cr6,0x831acc3c
	if (cr6.lt) goto loc_831ACC3C;
	// li r30,4
	r30.s64 = 4;
loc_831ACC3C:
	// li r6,228
	ctx.r6.s64 = 228;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,1040
	ctx.r4.s64 = ctx.r1.s64 + 1040;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b770
	sub_8319B770(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,2680
	ctx.r4.s64 = ctx.r1.s64 + 2680;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b540
	sub_8319B540(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// addi r5,r4,24
	ctx.r5.s64 = ctx.r4.s64 + 24;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,103
	ctx.r6.s64 = 103;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// bl 0x831687b8
	sub_831687B8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r27,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r27.u32);
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8311bb58
	sub_8311BB58(ctx, base);
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,1040
	ctx.r3.s64 = ctx.r1.s64 + 1040;
	// bl 0x8319af40
	sub_8319AF40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,1040
	ctx.r3.s64 = ctx.r1.s64 + 1040;
	// subf r28,r30,r28
	r28.s64 = r28.s64 - r30.s64;
	// bl 0x83196d78
	sub_83196D78(ctx, base);
	// b 0x831acc24
	goto loc_831ACC24;
loc_831ACCE4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831accfc
	if (cr6.eq) goto loc_831ACCFC;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,3048
	ctx.r3.s64 = ctx.r1.s64 + 3048;
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831ACCFC:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// ori r11,r11,512
	r11.u64 = r11.u64 | 512;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// b 0x831a534c
	goto loc_831A534C;
loc_831ACD0C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,20(r14)
	ctx.r4.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// bl 0x831963d0
	sub_831963D0(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x831a534c
	if (cr0.eq) goto loc_831A534C;
	// addi r3,r1,3064
	ctx.r3.s64 = ctx.r1.s64 + 3064;
	// b 0x831a69bc
	goto loc_831A69BC;
loc_831ACD28:
	// lwz r11,8(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831acda4
	if (cr6.eq) goto loc_831ACDA4;
	// rotlwi r4,r11,0
	ctx.r4.u64 = rotl32(r11.u32, 0);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831acd70
	if (!cr6.eq) goto loc_831ACD70;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831acd58
	if (cr6.eq) goto loc_831ACD58;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x831acd80
	goto loc_831ACD80;
loc_831ACD58:
	// addi r6,r1,260
	ctx.r6.s64 = ctx.r1.s64 + 260;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r5,r1,312
	ctx.r5.s64 = ctx.r1.s64 + 312;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831acd80
	goto loc_831ACD80;
loc_831ACD70:
	// addi r6,r1,260
	ctx.r6.s64 = ctx.r1.s64 + 260;
	// addi r5,r1,312
	ctx.r5.s64 = ctx.r1.s64 + 312;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831ACD80:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad85c
	if (cr0.eq) goto loc_831AD85C;
	// lwz r11,260(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// lwz r10,312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	// mullw. r5,r10,r11
	ctx.r5.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x831acda4
	if (cr0.eq) goto loc_831ACDA4;
	// addi r3,r1,3080
	ctx.r3.s64 = ctx.r1.s64 + 3080;
	// lwz r4,3500(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// bl 0x8319a860
	sub_8319A860(ctx, base);
loc_831ACDA4:
	// lwz r14,12(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 12);
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// bne cr6,0x831acd28
	if (!cr6.eq) goto loc_831ACD28;
	// b 0x831a534c
	goto loc_831A534C;
loc_831ACDB4:
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// bne cr6,0x831acde4
	if (!cr6.eq) goto loc_831ACDE4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d918
	sub_8319D918(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// stw r3,564(r31)
	PPC_STORE_U32(r31.u32 + 564, ctx.r3.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
loc_831ACDE4:
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x831a534c
	if (cr6.eq) goto loc_831A534C;
	// lwz r20,3500(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// li r19,0
	r19.s64 = 0;
	// b 0x831a440c
	goto loc_831A440C;
loc_831ACDF8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACE00:
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831959b0
	sub_831959B0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,3521
	ctx.r4.s64 = 3521;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACE1C:
	// li r4,3020
	ctx.r4.s64 = 3020;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACE28:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3632
	ctx.r5.s64 = r11.s64 + 3632;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACE3C:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3544
	ctx.r5.s64 = r11.s64 + 3544;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACE50:
	// cmplwi cr6,r11,15
	cr6.compare<uint32_t>(r11.u32, 15, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x831ace64
	if (cr6.eq) goto loc_831ACE64;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACE64:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3500
	ctx.r5.s64 = r11.s64 + 3500;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACE74:
	// li r4,3560
	ctx.r4.s64 = 3560;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACE80:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3440
	ctx.r5.s64 = r11.s64 + 3440;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACE90:
	// li r4,3572
	ctx.r4.s64 = 3572;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACE9C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACEA4:
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// li r4,3018
	ctx.r4.s64 = 3018;
	// addi r10,r10,-932
	ctx.r10.s64 = ctx.r10.s64 + -932;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lbzx r11,r11,r10
	r11.u64 = PPC_LOAD_U8(r11.u32 + ctx.r10.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACEC0:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACECC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACED8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACEE4:
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831959b0
	sub_831959B0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,3521
	ctx.r4.s64 = 3521;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF00:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF0C:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF18:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF24:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF30:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF3C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF48:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF54:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF60:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF6C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF78:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF84:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF90:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACF9C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACFA8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACFB4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACFC0:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACFCC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACFD8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACFE4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACFF0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ACFF8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD004:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD010:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD01C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD028:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD034:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD040:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD04C:
	// lwz r11,3516(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3516);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x831ad188
	if (cr6.lt) goto loc_831AD188;
	// beq cr6,0x831ad128
	if (cr6.eq) goto loc_831AD128;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x831ad0c0
	if (cr6.lt) goto loc_831AD0C0;
	// beq cr6,0x831ad188
	if (cr6.eq) goto loc_831AD188;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// blt cr6,0x831ad190
	if (cr6.lt) goto loc_831AD190;
	// beq cr6,0x831ad080
	if (cr6.eq) goto loc_831AD080;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD080:
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,280
	ctx.r3.s64 = ctx.r1.s64 + 280;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831ad0b0
	if (!cr0.eq) goto loc_831AD0B0;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831ad0b0
	if (cr0.eq) goto loc_831AD0B0;
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD0B0:
	// addi r4,r1,280
	ctx.r4.s64 = ctx.r1.s64 + 280;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// b 0x831ad114
	goto loc_831AD114;
loc_831AD0C0:
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// addi r3,r1,280
	ctx.r3.s64 = ctx.r1.s64 + 280;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8319d630
	sub_8319D630(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831ad0f8
	if (!cr0.eq) goto loc_831AD0F8;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831ad0f8
	if (cr0.eq) goto loc_831AD0F8;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,15,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad11c
	if (cr0.eq) goto loc_831AD11C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319a750
	sub_8319A750(ctx, base);
loc_831AD0F8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r4,280(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 280);
	// bl 0x8319bfc8
	sub_8319BFC8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r5,7
	ctx.r5.s64 = 7;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8311bbf8
	sub_8311BBF8(ctx, base);
loc_831AD114:
	// stw r3,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r3.u32);
	// b 0x831ad190
	goto loc_831AD190;
loc_831AD11C:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD128:
	// lwz r30,3500(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8319a750
	sub_8319A750(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,83
	ctx.r6.s64 = 83;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,56(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x831a2920
	sub_831A2920(ctx, base);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2d80
	sub_831A2D80(ctx, base);
	// b 0x831ad190
	goto loc_831AD190;
loc_831AD188:
	// lwz r3,3500(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	// bl 0x8319a750
	sub_8319A750(ctx, base);
loc_831AD190:
	// li r6,43
	ctx.r6.s64 = 43;
	// li r5,8
	ctx.r5.s64 = 8;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83118478
	sub_83118478(ctx, base);
	// lwz r3,156(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// addi r1,r1,3472
	ctx.r1.s64 = ctx.r1.s64 + 3472;
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82ca751c
	// b 0x82ca2c00
	return;
loc_831AD1B8:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD1C4:
	// lis r11,-32240
	r11.s64 = -2112880640;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,172
	ctx.r5.s64 = r11.s64 + 172;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD1D8:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3428
	ctx.r5.s64 = r11.s64 + 3428;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD1EC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD1F8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD204:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD210:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD21C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD228:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD234:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD240:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD24C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD258:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3412
	ctx.r5.s64 = r11.s64 + 3412;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD26C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD278:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD284:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD290:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD29C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD2A8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD2B4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD2C0:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD2CC:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3372
	ctx.r5.s64 = r11.s64 + 3372;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD2E0:
	// lis r11,-32240
	r11.s64 = -2112880640;
	// li r4,3018
	ctx.r4.s64 = 3018;
	// addi r11,r11,-932
	r11.s64 = r11.s64 + -932;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lbzx r11,r30,r11
	r11.u64 = PPC_LOAD_U8(r30.u32 + r11.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD2FC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD308:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD310:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD31C:
	// li r4,3637
	ctx.r4.s64 = 3637;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD328:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD334:
	// addi r5,r29,1
	ctx.r5.s64 = r29.s64 + 1;
	// li r4,3638
	ctx.r4.s64 = 3638;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD344:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD350:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD35C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD368:
	// li r4,3553
	ctx.r4.s64 = 3553;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD374:
	// lis r11,-32240
	r11.s64 = -2112880640;
	// li r4,3546
	ctx.r4.s64 = 3546;
	// addi r5,r11,-6744
	ctx.r5.s64 = r11.s64 + -6744;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD388:
	// li r4,3561
	ctx.r4.s64 = 3561;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD394:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD3A0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD3AC:
	// li r4,3573
	ctx.r4.s64 = 3573;
	// lwz r5,24(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD3BC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD3C8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD3D4:
	// li r4,3574
	ctx.r4.s64 = 3574;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD3E0:
	// li r4,3576
	ctx.r4.s64 = 3576;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD3EC:
	// li r4,3575
	ctx.r4.s64 = 3575;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD3F8:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3296
	ctx.r5.s64 = r11.s64 + 3296;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD408:
	// li r4,3597
	ctx.r4.s64 = 3597;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD414:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD420:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD42C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD438:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD444:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD450:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD45C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD468:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD474:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD480:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD48C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD498:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD4A4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD4B0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD4BC:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD4C8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD4D4:
	// li r4,3504
	ctx.r4.s64 = 3504;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD4E0:
	// li r4,3514
	ctx.r4.s64 = 3514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD4EC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD4F8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD504:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD510:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD51C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD528:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD534:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD53C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD544:
	// li r4,3020
	ctx.r4.s64 = 3020;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD54C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD558:
	// li r4,3020
	ctx.r4.s64 = 3020;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD564:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD570:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD57C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD588:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD594:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD5A0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD5AC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD5B8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD5C4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD5D0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD5DC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD5E8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD5F4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD600:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD60C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD618:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD624:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD630:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD63C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD648:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD654:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD660:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD66C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD678:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD680:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD688:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD694:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD6A0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD6A8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD6B0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD6BC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD6C8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD6D4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD6E0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD6EC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD6F8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD704:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD710:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD71C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD728:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD734:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD740:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r4,4532
	ctx.r4.s64 = 4532;
	// addi r5,r11,-29688
	ctx.r5.s64 = r11.s64 + -29688;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD754:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r4,4532
	ctx.r4.s64 = 4532;
	// addi r5,r11,-29688
	ctx.r5.s64 = r11.s64 + -29688;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD768:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x831ad788
	if (cr6.eq) goto loc_831AD788;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r5,r11,-29688
	ctx.r5.s64 = r11.s64 + -29688;
	// b 0x831ad790
	goto loc_831AD790;
loc_831AD788:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r5,r11,-29696
	ctx.r5.s64 = r11.s64 + -29696;
loc_831AD790:
	// li r4,4532
	ctx.r4.s64 = 4532;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD79C:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD7A4:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x831ad7c4
	if (cr6.eq) goto loc_831AD7C4;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r5,r11,-29688
	ctx.r5.s64 = r11.s64 + -29688;
	// b 0x831ad7cc
	goto loc_831AD7CC;
loc_831AD7C4:
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r5,r11,-29696
	ctx.r5.s64 = r11.s64 + -29696;
loc_831AD7CC:
	// li r4,4532
	ctx.r4.s64 = 4532;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD7D8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD7E0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD7EC:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3240
	ctx.r5.s64 = r11.s64 + 3240;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD800:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3264
	ctx.r5.s64 = r11.s64 + 3264;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD814:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD820:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD82C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD838:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD844:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD850:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AD85C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831A4278) {
	__imp__sub_831A4278(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831AD868) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r10,r11,12
	ctx.r10.s64 = r11.s64 + 12;
	// mulli r4,r10,40
	ctx.r4.s64 = ctx.r10.s64 * 40;
	// stw r11,600(r31)
	PPC_STORE_U32(r31.u32 + 600, r11.u32);
	// bl 0x83137570
	sub_83137570(ctx, base);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831ad8c4
	if (cr6.eq) goto loc_831AD8C4;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mulli r5,r11,40
	ctx.r5.s64 = r11.s64 * 40;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mulli r5,r11,40
	ctx.r5.s64 = r11.s64 * 40;
	// bl 0x831104e0
	sub_831104E0(ctx, base);
loc_831AD8C4:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lis r10,-31952
	ctx.r10.s64 = -2094006272;
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// li r29,0
	r29.s64 = 0;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// addi r28,r10,14072
	r28.s64 = ctx.r10.s64 + 14072;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// li r27,1
	r27.s64 = 1;
loc_831AD8E4:
	// lwz r11,600(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 600);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,4
	ctx.r9.s64 = 4;
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// add r30,r11,r29
	r30.u64 = r11.u64 + r29.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,12
	ctx.r7.s64 = 12;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199ed0
	sub_83199ED0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r6,24(r5)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r5.u32 + 24);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x831ad9a0
	if (cr6.eq) goto loc_831AD9A0;
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x831ad9a0
	if (!cr6.eq) goto loc_831AD9A0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,3
	ctx.r7.s64 = 3;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a3978
	sub_831A3978(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r11,r30,40
	r11.s64 = r30.s64 * 40;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r29,5
	cr6.compare<uint32_t>(r29.u32, 5, xer);
	// bgt cr6,0x831ad95c
	if (cr6.gt) goto loc_831AD95C;
	// rlwimi r9,r27,2,29,31
	ctx.r9.u64 = (rotl32(r27.u32, 2) & 0x7) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFF8);
	// b 0x831ad960
	goto loc_831AD960;
loc_831AD95C:
	// rlwimi r9,r27,1,29,31
	ctx.r9.u64 = (rotl32(r27.u32, 1) & 0x7) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFF8);
loc_831AD960:
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// cmplwi cr6,r29,12
	cr6.compare<uint32_t>(r29.u32, 12, xer);
	// blt cr6,0x831ad8e4
	if (cr6.lt) goto loc_831AD8E4;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// oris r11,r11,4
	r11.u64 = r11.u64 | 262144;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_831AD9A0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831AD868) {
	__imp__sub_831AD868(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831AD9B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ad9f4
	if (cr0.eq) goto loc_831AD9F4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ad9f4
	if (cr6.eq) goto loc_831AD9F4;
	// lwz r5,20(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831ad9f4
	if (cr6.eq) goto loc_831AD9F4;
	// li r6,5
	ctx.r6.s64 = 5;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
loc_831AD9F4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_831AD9B0) {
	__imp__sub_831AD9B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831ADA08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bcc
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r21,r4
	r21.u64 = ctx.r4.u64;
	// li r5,15
	ctx.r5.s64 = 15;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r22,r26,4
	r22.s64 = r26.s64 + 4;
	// ori r11,r26,1
	r11.u64 = r26.u64 | 1;
	// ori r10,r22,1
	ctx.r10.u64 = r22.u64 | 1;
	// stw r11,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r11.u32);
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831adaf4
	if (cr0.eq) goto loc_831ADAF4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831adb08
	if (cr6.eq) goto loc_831ADB08;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831adb08
	if (!cr6.eq) goto loc_831ADB08;
	// mr r29,r11
	r29.u64 = r11.u64;
loc_831ADA6C:
	// lwz r30,8(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// bne cr6,0x831adad0
	if (!cr6.eq) goto loc_831ADAD0;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831adaac
	if (!cr0.eq) goto loc_831ADAAC;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831adaac
	if (cr0.eq) goto loc_831ADAAC;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831adab8
	if (!cr6.gt) goto loc_831ADAB8;
loc_831ADAAC:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831ADAB8:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
loc_831ADAD0:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831adae8
	if (cr6.eq) goto loc_831ADAE8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831adafc
	if (!cr6.eq) goto loc_831ADAFC;
loc_831ADAE8:
	// mr r29,r11
	r29.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831ada6c
	if (!cr6.eq) goto loc_831ADA6C;
loc_831ADAF4:
	// lwz r27,568(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 568);
	// b 0x831adc90
	goto loc_831ADC90;
loc_831ADAFC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ADB08:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ADB14:
	// lwz r28,4(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831adc20
	if (cr6.eq) goto loc_831ADC20;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831adc20
	if (cr6.eq) goto loc_831ADC20;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ADB3C:
	// lwz r30,8(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x831adbb4
	if (!cr6.eq) goto loc_831ADBB4;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831add64
	if (!cr6.eq) goto loc_831ADD64;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831add70
	if (cr6.eq) goto loc_831ADD70;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,11
	cr6.compare<int32_t>(ctx.r10.s32, 11, xer);
	// bne cr6,0x831add70
	if (!cr6.eq) goto loc_831ADD70;
	// cmplw cr6,r21,r27
	cr6.compare<uint32_t>(r21.u32, r27.u32, xer);
	// bne cr6,0x831adb90
	if (!cr6.eq) goto loc_831ADB90;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r10,r10,0,20,20
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831adc08
	if (cr0.eq) goto loc_831ADC08;
	// lwz r10,44(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831adc08
	if (cr0.eq) goto loc_831ADC08;
loc_831ADB90:
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// b 0x831adc08
	goto loc_831ADC08;
loc_831ADBB4:
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831adbe4
	if (!cr0.eq) goto loc_831ADBE4;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831adbe4
	if (cr0.eq) goto loc_831ADBE4;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831adbf0
	if (!cr6.gt) goto loc_831ADBF0;
loc_831ADBE4:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831ADBF0:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
loc_831ADC08:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831adc20
	if (cr6.eq) goto loc_831ADC20;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831add7c
	if (!cr6.eq) goto loc_831ADD7C;
loc_831ADC20:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r29,r11
	r29.u64 = r11.u64;
	// bne cr6,0x831adb3c
	if (!cr6.eq) goto loc_831ADB3C;
	// lwz r30,48(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831adc8c
	if (cr6.eq) goto loc_831ADC8C;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831adc68
	if (!cr0.eq) goto loc_831ADC68;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831adc68
	if (cr0.eq) goto loc_831ADC68;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831adc74
	if (!cr6.gt) goto loc_831ADC74;
loc_831ADC68:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831ADC74:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
loc_831ADC8C:
	// lwz r27,8(r27)
	r27.u64 = PPC_LOAD_U32(r27.u32 + 8);
loc_831ADC90:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x831adb14
	if (!cr6.eq) goto loc_831ADB14;
	// li r23,0
	r23.s64 = 0;
	// li r25,1
	r25.s64 = 1;
	// mr r27,r23
	r27.u64 = r23.u64;
	// mr r24,r23
	r24.u64 = r23.u64;
loc_831ADCA8:
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831ae0e4
	if (!cr0.eq) goto loc_831AE0E4;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831ae0e4
	if (cr0.eq) goto loc_831AE0E4;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r10,r4
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831add1c
	if (!cr0.eq) goto loc_831ADD1C;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831ADD1C:
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831ae020
	if (cr6.eq) goto loc_831AE020;
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// beq cr6,0x831ade8c
	if (cr6.eq) goto loc_831ADE8C;
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x831addc4
	if (cr6.eq) goto loc_831ADDC4;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// beq cr6,0x831add88
	if (cr6.eq) goto loc_831ADD88;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x831adca8
	if (!cr6.eq) goto loc_831ADCA8;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831add5c
	if (!cr0.eq) goto loc_831ADD5C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ad868
	sub_831AD868(ctx, base);
loc_831ADD5C:
	// lwz r30,16(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// b 0x831ae08c
	goto loc_831AE08C;
loc_831ADD64:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ADD70:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ADD7C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831ADD88:
	// lwz r11,48(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// beq cr6,0x831ae080
	if (cr6.eq) goto loc_831AE080;
	// addi r30,r28,84
	r30.s64 = r28.s64 + 84;
	// li r29,2
	r29.s64 = 2;
loc_831ADD9C:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831addb4
	if (cr6.eq) goto loc_831ADDB4;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a11a8
	sub_831A11A8(ctx, base);
loc_831ADDB4:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x831add9c
	if (!cr0.eq) goto loc_831ADD9C;
	// b 0x831ae080
	goto loc_831AE080;
loc_831ADDC4:
	// lwz r11,28(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// blt cr6,0x831ade10
	if (cr6.lt) goto loc_831ADE10;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// ble cr6,0x831ade78
	if (!cr6.gt) goto loc_831ADE78;
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// ble cr6,0x831ade10
	if (!cr6.gt) goto loc_831ADE10;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// ble cr6,0x831ade78
	if (!cr6.gt) goto loc_831ADE78;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// bne cr6,0x831ade10
	if (!cr6.eq) goto loc_831ADE10;
	// lwz r11,32(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r11,14
	cr6.compare<uint32_t>(r11.u32, 14, xer);
	// beq cr6,0x831ade0c
	if (cr6.eq) goto loc_831ADE0C;
	// cmplwi cr6,r11,15
	cr6.compare<uint32_t>(r11.u32, 15, xer);
	// bne cr6,0x831ade10
	if (!cr6.eq) goto loc_831ADE10;
loc_831ADE0C:
	// mr r24,r25
	r24.u64 = r25.u64;
loc_831ADE10:
	// lwz r30,32(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831ade70
	if (cr6.eq) goto loc_831ADE70;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ade4c
	if (!cr0.eq) goto loc_831ADE4C;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831ade4c
	if (cr0.eq) goto loc_831ADE4C;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831ade58
	if (!cr6.gt) goto loc_831ADE58;
loc_831ADE4C:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831ADE58:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
loc_831ADE70:
	// lwz r30,36(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 36);
	// b 0x831ae084
	goto loc_831AE084;
loc_831ADE78:
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// lwz r4,32(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a11a8
	sub_831A11A8(ctx, base);
	// b 0x831ade70
	goto loc_831ADE70;
loc_831ADE8C:
	// lwz r30,20(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831adeec
	if (cr6.eq) goto loc_831ADEEC;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831adec8
	if (!cr0.eq) goto loc_831ADEC8;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831adec8
	if (cr0.eq) goto loc_831ADEC8;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831aded4
	if (!cr6.gt) goto loc_831ADED4;
loc_831ADEC8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831ADED4:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
loc_831ADEEC:
	// lwz r30,24(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831adf4c
	if (cr6.eq) goto loc_831ADF4C;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831adf28
	if (!cr0.eq) goto loc_831ADF28;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831adf28
	if (cr0.eq) goto loc_831ADF28;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831adf34
	if (!cr6.gt) goto loc_831ADF34;
loc_831ADF28:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831ADF34:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
loc_831ADF4C:
	// lwz r30,28(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831adfac
	if (cr6.eq) goto loc_831ADFAC;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831adf88
	if (!cr0.eq) goto loc_831ADF88;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831adf88
	if (cr0.eq) goto loc_831ADF88;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831adf94
	if (!cr6.gt) goto loc_831ADF94;
loc_831ADF88:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831ADF94:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
loc_831ADFAC:
	// lwz r30,32(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831ae00c
	if (cr6.eq) goto loc_831AE00C;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831adfe8
	if (!cr0.eq) goto loc_831ADFE8;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831adfe8
	if (cr0.eq) goto loc_831ADFE8;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831adff4
	if (!cr6.gt) goto loc_831ADFF4;
loc_831ADFE8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831ADFF4:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
loc_831AE00C:
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// bne cr6,0x831adca8
	if (!cr6.eq) goto loc_831ADCA8;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// b 0x831adca8
	goto loc_831ADCA8;
loc_831AE020:
	// lwz r30,8(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831ae080
	if (cr6.eq) goto loc_831AE080;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ae05c
	if (!cr0.eq) goto loc_831AE05C;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831ae05c
	if (cr0.eq) goto loc_831AE05C;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831ae068
	if (!cr6.gt) goto loc_831AE068;
loc_831AE05C:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831AE068:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
loc_831AE080:
	// lwz r30,12(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 12);
loc_831AE084:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831adca8
	if (cr6.eq) goto loc_831ADCA8;
loc_831AE08C:
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ae0bc
	if (!cr0.eq) goto loc_831AE0BC;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831ae0bc
	if (cr0.eq) goto loc_831AE0BC;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831ae0c8
	if (!cr6.gt) goto loc_831AE0C8;
loc_831AE0BC:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831AE0C8:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
	// b 0x831adca8
	goto loc_831ADCA8;
loc_831AE0E4:
	// lwz r10,976(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 976);
	// addi r11,r31,972
	r11.s64 = r31.s64 + 972;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// stw r26,976(r31)
	PPC_STORE_U32(r31.u32 + 976, r26.u32);
	// beq cr6,0x831ae15c
	if (cr6.eq) goto loc_831AE15C;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r30,r27,1
	r30.s64 = r27.s64 + 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mulli r4,r11,40
	ctx.r4.s64 = r11.s64 * 40;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r5,r11,40
	ctx.r5.s64 = r11.s64 * 40;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r5,r11,40
	ctx.r5.s64 = r11.s64 * 40;
	// bl 0x831104e0
	sub_831104E0(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r29,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r29.u32);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// stw r10,604(r31)
	PPC_STORE_U32(r31.u32 + 604, ctx.r10.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
loc_831AE15C:
	// clrlwi. r11,r24,24
	r11.u64 = r24.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ae2bc
	if (cr0.eq) goto loc_831AE2BC;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ae180
	if (cr6.eq) goto loc_831AE180;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r25
	r11.u64 = r25.u64;
	// bne 0x831ae184
	if (!cr0.eq) goto loc_831AE184;
loc_831AE180:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_831AE184:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ae2bc
	if (cr0.eq) goto loc_831AE2BC;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// mulli r4,r11,40
	ctx.r4.s64 = r11.s64 * 40;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r5,r11,40
	ctx.r5.s64 = r11.s64 * 40;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r5,r11,40
	ctx.r5.s64 = r11.s64 * 40;
	// bl 0x831104e0
	sub_831104E0(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r10,612(r31)
	PPC_STORE_U32(r31.u32 + 612, ctx.r10.u32);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r8,r10,-3780
	ctx.r8.s64 = ctx.r10.s64 + -3780;
	// lwz r4,612(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 612);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83195c20
	sub_83195C20(ctx, base);
	// lwz r10,612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 612);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 * 40;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r11,r31,812
	r11.s64 = r31.s64 + 812;
	// add r31,r10,r9
	r31.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwimi r8,r25,1,29,31
	ctx.r8.u64 = (rotl32(r25.u32, 1) & 0x7) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFF8);
	// stwx r8,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r8.u32);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwimi r10,r25,5,25,27
	ctx.r10.u64 = (rotl32(r25.u32, 5) & 0x70) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFF8F);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// lwz r10,144(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 144);
	// lwz r9,140(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 140);
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// addi r9,r9,4096
	ctx.r9.s64 = ctx.r9.s64 + 4096;
	// cmplwi cr6,r9,8
	cr6.compare<uint32_t>(ctx.r9.u32, 8, xer);
	// blt cr6,0x831ae258
	if (cr6.lt) goto loc_831AE258;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// stw r9,144(r11)
	PPC_STORE_U32(r11.u32 + 144, ctx.r9.u32);
	// b 0x831ae288
	goto loc_831AE288;
loc_831AE258:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831ae278
	if (cr6.eq) goto loc_831AE278;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// stw r23,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r23.u32);
	// stw r23,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r23.u32);
	// b 0x831ae288
	goto loc_831AE288;
loc_831AE278:
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x8310fe28
	sub_8310FE28(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
loc_831AE288:
	// stw r10,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r10.u32);
	// li r11,3
	r11.s64 = 3;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwimi r9,r25,0,28,31
	ctx.r9.u64 = (rotl32(r25.u32, 0) & 0xF) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFF0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// oris r9,r9,12
	ctx.r9.u64 = ctx.r9.u64 | 786432;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwimi r9,r11,21,6,11
	ctx.r9.u64 = (rotl32(r11.u32, 21) & 0x3F00000) | (ctx.r9.u64 & 0xFFFFFFFFFC0FFFFF);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
loc_831AE2BC:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c1c
	return;
}

PPC_WEAK_FUNC(sub_831ADA08) {
	__imp__sub_831ADA08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831AE2C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-528(r1)
	ea = -528 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// addi r11,r31,100
	r11.s64 = r31.s64 + 100;
	// li r16,0
	r16.s64 = 0;
	// stw r25,556(r1)
	PPC_STORE_U32(ctx.r1.u32 + 556, r25.u32);
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// stw r25,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r25.u32);
	// li r5,31
	ctx.r5.s64 = 31;
	// lwz r26,4(r25)
	r26.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r11,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r11.u32);
	// stw r16,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r16.u32);
	// stw r26,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r26.u32);
	// stw r26,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r26.u32);
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r5,6
	ctx.r5.s64 = 6;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r11,572(r31)
	PPC_STORE_U32(r31.u32 + 572, r11.u32);
	// ori r9,r11,1
	ctx.r9.u64 = r11.u64 | 1;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// li r5,43
	ctx.r5.s64 = 43;
	// addi r20,r19,4
	r20.s64 = r19.s64 + 4;
	// ori r11,r19,1
	r11.u64 = r19.u64 | 1;
	// ori r10,r20,1
	ctx.r10.u64 = r20.u64 | 1;
	// stw r11,4(r19)
	PPC_STORE_U32(r19.u32 + 4, r11.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r10,0(r19)
	PPC_STORE_U32(r19.u32 + 0, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r19,592(r31)
	PPC_STORE_U32(r31.u32 + 592, r19.u32);
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// li r5,55
	ctx.r5.s64 = 55;
	// addi r11,r21,4
	r11.s64 = r21.s64 + 4;
	// ori r10,r21,1
	ctx.r10.u64 = r21.u64 | 1;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r10,4(r21)
	PPC_STORE_U32(r21.u32 + 4, ctx.r10.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r11,0(r21)
	PPC_STORE_U32(r21.u32 + 0, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r21,588(r31)
	PPC_STORE_U32(r31.u32 + 588, r21.u32);
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r11,r18,4
	r11.s64 = r18.s64 + 4;
	// ori r10,r18,1
	ctx.r10.u64 = r18.u64 | 1;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r10,4(r18)
	PPC_STORE_U32(r18.u32 + 4, ctx.r10.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r11,0(r18)
	PPC_STORE_U32(r18.u32 + 0, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r17,r3
	r17.u64 = ctx.r3.u64;
	// li r5,42
	ctx.r5.s64 = 42;
	// addi r11,r17,4
	r11.s64 = r17.s64 + 4;
	// ori r10,r17,1
	ctx.r10.u64 = r17.u64 | 1;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r10,4(r17)
	PPC_STORE_U32(r17.u32 + 4, ctx.r10.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// stw r11,0(r17)
	PPC_STORE_U32(r17.u32 + 0, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// addi r11,r3,4
	r11.s64 = ctx.r3.s64 + 4;
	// ori r10,r3,1
	ctx.r10.u64 = ctx.r3.u64 | 1;
	// stw r3,584(r31)
	PPC_STORE_U32(r31.u32 + 584, ctx.r3.u32);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// lwz r11,68(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 68);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ae49c
	if (cr6.eq) goto loc_831AE49C;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_831AE410:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// beq cr6,0x831ae6e0
	if (cr6.eq) goto loc_831AE6E0;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831ae700
	if (!cr6.eq) goto loc_831AE700;
	// lwz r5,8(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831ae6f4
	if (cr6.eq) goto loc_831AE6F4;
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831ae6f4
	if (!cr6.eq) goto loc_831AE6F4;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f410
	sub_8319F410(ctx, base);
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831ae410
	if (!cr6.eq) goto loc_831AE410;
loc_831AE454:
	// lis r5,219
	ctx.r5.s64 = 14352384;
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,2048
	ctx.r6.s64 = 2048;
	// ori r5,r5,57346
	ctx.r5.u64 = ctx.r5.u64 | 57346;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
	// lwz r11,576(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 576);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831ae49c
	if (!cr0.eq) goto loc_831AE49C;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831ae49c
	if (cr0.eq) goto loc_831AE49C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a07c0
	sub_831A07C0(ctx, base);
loc_831AE49C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// stw r3,564(r31)
	PPC_STORE_U32(r31.u32 + 564, ctx.r3.u32);
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r6,0(r25)
	ctx.r6.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a37b8
	sub_831A37B8(ctx, base);
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,3
	ctx.r5.s64 = 3;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a3c48
	sub_831A3C48(ctx, base);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r15,1
	r15.s64 = 1;
	// rlwinm. r11,r11,0,16,16
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ae52c
	if (!cr0.eq) goto loc_831AE52C;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ae504
	if (cr0.eq) goto loc_831AE504;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x831ae52c
	if (!cr6.eq) goto loc_831AE52C;
loc_831AE504:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ae520
	if (cr6.eq) goto loc_831AE520;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r15
	r11.u64 = r15.u64;
	// bne 0x831ae524
	if (!cr0.eq) goto loc_831AE524;
loc_831AE520:
	// mr r11,r16
	r11.u64 = r16.u64;
loc_831AE524:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ae54c
	if (cr0.eq) goto loc_831AE54C;
loc_831AE52C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
loc_831AE54C:
	// lwz r11,744(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 744);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ae568
	if (cr6.eq) goto loc_831AE568;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196778
	sub_83196778(ctx, base);
loc_831AE568:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ae5e0
	if (cr0.eq) goto loc_831AE5E0;
	// lwz r28,16(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r30,r16
	r30.u64 = r16.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831ae5e0
	if (cr6.eq) goto loc_831AE5E0;
	// mr r29,r16
	r29.u64 = r16.u64;
loc_831AE588:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r10,r10,29
	ctx.r10.u64 = ctx.r10.u32 & 0x7;
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// bne cr6,0x831ae5d0
	if (!cr6.eq) goto loc_831AE5D0;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r6,52(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x831ae5c0
	if (!cr6.eq) goto loc_831AE5C0;
	// lwz r10,44(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// rlwinm. r10,r10,0,24,24
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831ae5d0
	if (cr0.eq) goto loc_831AE5D0;
	// lwz r6,56(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 56);
loc_831AE5C0:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319de30
	sub_8319DE30(ctx, base);
loc_831AE5D0:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,40
	r29.s64 = r29.s64 + 40;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// blt cr6,0x831ae588
	if (cr6.lt) goto loc_831AE588;
loc_831AE5E0:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ae684
	if (cr0.eq) goto loc_831AE684;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ae730
	if (cr6.eq) goto loc_831AE730;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ae730
	if (!cr6.eq) goto loc_831AE730;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_831AE60C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,12
	cr6.compare<int32_t>(ctx.r10.s32, 12, xer);
	// bne cr6,0x831ae660
	if (!cr6.eq) goto loc_831AE660;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x831ae70c
	if (!cr6.eq) goto loc_831AE70C;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831ae718
	if (!cr6.eq) goto loc_831AE718;
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831ae718
	if (!cr6.eq) goto loc_831AE718;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x831ae718
	if (!cr6.eq) goto loc_831AE718;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,20(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
loc_831AE660:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ae678
	if (cr6.eq) goto loc_831AE678;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831ae724
	if (!cr6.eq) goto loc_831AE724;
loc_831AE678:
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831ae60c
	if (!cr6.eq) goto loc_831AE60C;
loc_831AE684:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831ae6a0
	if (cr6.eq) goto loc_831AE6A0;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f7d8
	sub_8319F7D8(ctx, base);
loc_831AE6A0:
	// lwz r27,604(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 604);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r11,r11,20824
	r11.s64 = r11.s64 + 20824;
	// addi r10,r10,17000
	ctx.r10.s64 = ctx.r10.s64 + 17000;
	// mr r14,r25
	r14.u64 = r25.u64;
	// stw r11,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r11.u32);
	// stw r27,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r27.u32);
	// stw r10,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r10.u32);
loc_831AE6C4:
	// mr r29,r16
	r29.u64 = r16.u64;
	// lwz r23,48(r26)
	r23.u64 = PPC_LOAD_U32(r26.u32 + 48);
	// mr r22,r15
	r22.u64 = r15.u64;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
loc_831AE6D4:
	// mr r24,r16
	r24.u64 = r16.u64;
	// stw r24,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r24.u32);
	// b 0x831aec58
	goto loc_831AEC58;
loc_831AE6E0:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f410
	sub_8319F410(ctx, base);
	// b 0x831ae454
	goto loc_831AE454;
loc_831AE6F4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AE700:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AE70C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AE718:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AE724:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AE730:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AE73C:
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ae800
	if (cr0.eq) goto loc_831AE800;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831ae760
	if (cr6.eq) goto loc_831AE760;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// b 0x831ae800
	goto loc_831AE800;
loc_831AE760:
	// lwz r11,584(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831ae7d8
	if (!cr0.eq) goto loc_831AE7D8;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x831ae7d8
	if (cr0.eq) goto loc_831AE7D8;
	// rotlwi r10,r10,0
	ctx.r10.u64 = rotl32(ctx.r10.u32, 0);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831ae78c
	if (cr0.eq) goto loc_831AE78C;
	// mr r11,r16
	r11.u64 = r16.u64;
	// b 0x831ae798
	goto loc_831AE798;
loc_831AE78C:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_831AE798:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,-16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -16);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x831b0f68
	if (!cr6.eq) goto loc_831B0F68;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ae7cc
	if (cr6.eq) goto loc_831AE7CC;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831ae800
	if (!cr6.eq) goto loc_831AE800;
loc_831AE7CC:
	// li r4,3624
	ctx.r4.s64 = 3624;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AE7D8:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm. r11,r11,0,28,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ae7f8
	if (!cr0.eq) goto loc_831AE7F8;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// bl 0x831a2e58
	sub_831A2E58(ctx, base);
	// b 0x831ae800
	goto loc_831AE800;
loc_831AE7F8:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831969c8
	sub_831969C8(ctx, base);
loc_831AE800:
	// addi r11,r21,4
	r11.s64 = r21.s64 + 4;
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b0d80
	if (!cr0.eq) goto loc_831B0D80;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b0d80
	if (cr0.eq) goto loc_831B0D80;
	// addi r4,r1,188
	ctx.r4.s64 = ctx.r1.s64 + 188;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8319d828
	sub_8319D828(ctx, base);
	// lwz r11,188(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831aeb54
	if (cr6.eq) goto loc_831AEB54;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// beq cr6,0x831aeb44
	if (cr6.eq) goto loc_831AEB44;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// beq cr6,0x831aea38
	if (cr6.eq) goto loc_831AEA38;
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// beq cr6,0x831ae924
	if (cr6.eq) goto loc_831AE924;
	// cmpwi cr6,r11,16
	cr6.compare<int32_t>(r11.s32, 16, xer);
	// bne cr6,0x831b14d0
	if (!cr6.eq) goto loc_831B14D0;
	// lwz r11,580(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 580);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831ae86c
	if (cr0.eq) goto loc_831AE86C;
	// mr r11,r16
	r11.u64 = r16.u64;
	// b 0x831ae878
	goto loc_831AE878;
loc_831AE86C:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_831AE878:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r3,576(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 576);
	// mulli r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 * 12;
	// add r30,r10,r11
	r30.u64 = ctx.r10.u64 + r11.u64;
	// addi r28,r30,4
	r28.s64 = r30.s64 + 4;
	// bl 0x8319a750
	sub_8319A750(ctx, base);
	// addi r11,r31,972
	r11.s64 = r31.s64 + 972;
	// lwz r10,976(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 976);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r11,576(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 576);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// stw r11,976(r31)
	PPC_STORE_U32(r31.u32 + 976, r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r11,576(r31)
	PPC_STORE_U32(r31.u32 + 576, r11.u32);
	// bl 0x83195ba0
	sub_83195BA0(ctx, base);
	// lwz r3,580(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 580);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ae8d0
	if (cr0.eq) goto loc_831AE8D0;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// b 0x831ae8dc
	goto loc_831AE8DC;
loc_831AE8D0:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_831AE8DC:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831aeb4c
	if (!cr0.eq) goto loc_831AEB4C;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
	// b 0x831aeb4c
	goto loc_831AEB4C;
loc_831AE924:
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x831aea30
	if (cr6.eq) goto loc_831AEA30;
	// lwz r11,584(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831ae948
	if (cr0.eq) goto loc_831AE948;
	// mr r11,r16
	r11.u64 = r16.u64;
	// b 0x831ae954
	goto loc_831AE954;
loc_831AE948:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
loc_831AE954:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// lwz r11,-16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -16);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x831ae9c8
	if (!cr6.eq) goto loc_831AE9C8;
	// lwz r3,12(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831ae988
	if (cr6.eq) goto loc_831AE988;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831ae9c8
	if (!cr6.eq) goto loc_831AE9C8;
loc_831AE988:
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831ae9bc
	if (!cr0.eq) goto loc_831AE9BC;
	// lwz r11,32(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-40
	xer.ca = r11.u32 > 39;
	r11.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ae9bc
	if (cr0.eq) goto loc_831AE9BC;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,88
	cr6.compare<uint32_t>(r11.u32, 88, xer);
	// beq cr6,0x831ae9c8
	if (cr6.eq) goto loc_831AE9C8;
	// cmplwi cr6,r11,83
	cr6.compare<uint32_t>(r11.u32, 83, xer);
	// beq cr6,0x831ae9c8
	if (cr6.eq) goto loc_831AE9C8;
loc_831AE9BC:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,8(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
loc_831AE9C8:
	// lwz r3,584(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831ae9e0
	if (cr0.eq) goto loc_831AE9E0;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// b 0x831ae9ec
	goto loc_831AE9EC;
loc_831AE9E0:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_831AE9EC:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831aea30
	if (!cr0.eq) goto loc_831AEA30;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// rlwinm r11,r11,5,0,26
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831AEA30:
	// mr r22,r16
	r22.u64 = r16.u64;
	// b 0x831ae73c
	goto loc_831AE73C;
loc_831AEA38:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831aea4c
	if (cr0.eq) goto loc_831AEA4C;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// b 0x831aea58
	goto loc_831AEA58;
loc_831AEA4C:
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_831AEA58:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r10,r4
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831aeaac
	if (!cr0.eq) goto loc_831AEAAC;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831AEAAC:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// mr r29,r30
	r29.u64 = r30.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// beq 0x831aeac8
	if (cr0.eq) goto loc_831AEAC8;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// b 0x831aead4
	goto loc_831AEAD4;
loc_831AEAC8:
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_831AEAD4:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r10,r4
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831aeb28
	if (!cr0.eq) goto loc_831AEB28;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831AEB28:
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
	// mr r22,r15
	r22.u64 = r15.u64;
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// stw r23,752(r31)
	PPC_STORE_U32(r31.u32 + 752, r23.u32);
	// clrlwi r11,r11,13
	r11.u64 = r11.u32 & 0x7FFFF;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// b 0x831ae73c
	goto loc_831AE73C;
loc_831AEB44:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319d918
	sub_8319D918(ctx, base);
loc_831AEB4C:
	// mr r22,r16
	r22.u64 = r16.u64;
	// b 0x831aec58
	goto loc_831AEC58;
loc_831AEB54:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831aeb68
	if (cr0.eq) goto loc_831AEB68;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// b 0x831aeb74
	goto loc_831AEB74;
loc_831AEB68:
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_831AEB74:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r10,r4
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831aebc8
	if (!cr0.eq) goto loc_831AEBC8;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831AEBC8:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// mr r29,r30
	r29.u64 = r30.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// beq 0x831aebe4
	if (cr0.eq) goto loc_831AEBE4;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// b 0x831aebf0
	goto loc_831AEBF0;
loc_831AEBE4:
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_831AEBF0:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r10,r4
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831aec44
	if (!cr0.eq) goto loc_831AEC44;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831AEC44:
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
	// mr r22,r15
	r22.u64 = r15.u64;
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// clrlwi r11,r11,13
	r11.u64 = r11.u32 & 0x7FFFF;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
loc_831AEC58:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x831ae73c
	if (cr6.eq) goto loc_831AE73C;
loc_831AEC60:
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831aefb8
	if (!cr6.eq) goto loc_831AEFB8;
loc_831AEC6C:
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831aec84
	if (!cr6.eq) goto loc_831AEC84;
	// lwz r23,12(r23)
	r23.u64 = PPC_LOAD_U32(r23.u32 + 12);
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// bne cr6,0x831aec6c
	if (!cr6.eq) goto loc_831AEC6C;
loc_831AEC84:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x831b0c94
	if (cr6.eq) goto loc_831B0C94;
	// lwz r11,12(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 12);
	// lwz r28,8(r23)
	r28.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831aed78
	if (cr6.eq) goto loc_831AED78;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831aed70
	if (cr6.eq) goto loc_831AED70;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831aece0
	if (!cr0.eq) goto loc_831AECE0;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831aece0
	if (cr0.eq) goto loc_831AECE0;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831aecec
	if (!cr6.gt) goto loc_831AECEC;
loc_831AECE0:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831AECEC:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831aed34
	if (!cr0.eq) goto loc_831AED34;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831aed34
	if (cr0.eq) goto loc_831AED34;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831aed44
	if (!cr6.gt) goto loc_831AED44;
loc_831AED34:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831AED44:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r29,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r29.u32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// mr r29,r30
	r29.u64 = r30.u64;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
loc_831AED70:
	// lwz r24,12(r23)
	r24.u64 = PPC_LOAD_U32(r23.u32 + 12);
	// stw r24,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r24.u32);
loc_831AED78:
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// mr r23,r28
	r23.u64 = r28.u64;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831aec60
	if (!cr6.eq) goto loc_831AEC60;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r10,180(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_831AED90:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x831aedb4
	if (cr0.eq) goto loc_831AEDB4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x831aed90
	if (cr6.eq) goto loc_831AED90;
loc_831AEDB4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831aec60
	if (cr0.eq) goto loc_831AEC60;
	// lwz r11,744(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 744);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831aef70
	if (cr6.eq) goto loc_831AEF70;
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// rlwinm. r11,r11,0,2,2
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b1634
	if (!cr0.eq) goto loc_831B1634;
	// lwz r30,752(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 752);
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// lwz r11,748(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 748);
	// lis r10,7
	ctx.r10.s64 = 458752;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// ori r10,r10,65534
	ctx.r10.u64 = ctx.r10.u64 | 65534;
	// stw r11,748(r31)
	PPC_STORE_U32(r31.u32 + 748, r11.u32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// stw r11,752(r31)
	PPC_STORE_U32(r31.u32 + 752, r11.u32);
	// bgt cr6,0x831b163c
	if (cr6.gt) goto loc_831B163C;
	// lwz r3,744(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 744);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831aee3c
	if (!cr0.eq) goto loc_831AEE3C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831aee3c
	if (cr0.eq) goto loc_831AEE3C;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831aee48
	if (!cr6.gt) goto loc_831AEE48;
loc_831AEE3C:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8319ab78
	sub_8319AB78(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831AEE48:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r9,r8,0,0,12
	ctx.r9.u64 = (rotl32(ctx.r8.u32, 0) & 0xFFF80000) | (ctx.r9.u64 & 0xFFFFFFFF0007FFFF);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,752(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 752);
	// rlwimi r9,r10,0,0,12
	ctx.r9.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFF80000) | (ctx.r9.u64 & 0xFFFFFFFF0007FFFF);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// bl 0x8319ad98
	sub_8319AD98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// stw r25,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r25.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831aeed8
	if (!cr0.eq) goto loc_831AEED8;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831aeed8
	if (cr0.eq) goto loc_831AEED8;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831aeee4
	if (!cr6.gt) goto loc_831AEEE4;
loc_831AEED8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831AEEE4:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r28,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r28.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831aef2c
	if (!cr0.eq) goto loc_831AEF2C;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831aef2c
	if (cr0.eq) goto loc_831AEF2C;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831aef3c
	if (!cr6.gt) goto loc_831AEF3C;
loc_831AEF2C:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831AEF3C:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r5,8
	ctx.r5.s64 = 8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// stwx r29,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r29.u32);
	// bl 0x831a0630
	sub_831A0630(ctx, base);
	// mr r29,r28
	r29.u64 = r28.u64;
	// lwz r25,556(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
loc_831AEF70:
	// addi r11,r17,4
	r11.s64 = r17.s64 + 4;
	// lwz r11,4(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831aec60
	if (!cr0.eq) goto loc_831AEC60;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831aec60
	if (cr0.eq) goto loc_831AEC60;
	// addi r10,r1,288
	ctx.r10.s64 = ctx.r1.s64 + 288;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r8,r1,100
	ctx.r8.s64 = ctx.r1.s64 + 100;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,6
	ctx.r5.s64 = 6;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
	// lwz r29,96(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r24,100(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// b 0x831aec60
	goto loc_831AEC60;
loc_831AEFB8:
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x831b0c94
	if (cr6.eq) goto loc_831B0C94;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x831b0b88
	if (cr6.eq) goto loc_831B0B88;
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// beq cr6,0x831af190
	if (cr6.eq) goto loc_831AF190;
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// beq cr6,0x831af16c
	if (cr6.eq) goto loc_831AF16C;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// bne cr6,0x831b14dc
	if (!cr6.eq) goto loc_831B14DC;
	// lwz r11,48(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 48);
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// blt cr6,0x831af154
	if (cr6.lt) goto loc_831AF154;
	// beq cr6,0x831af004
	if (cr6.eq) goto loc_831AF004;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// blt cr6,0x831b0c94
	if (cr6.lt) goto loc_831B0C94;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AF004:
	// lwz r11,52(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 52);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// blt cr6,0x831b0c94
	if (cr6.lt) goto loc_831B0C94;
	// beq cr6,0x831af13c
	if (cr6.eq) goto loc_831AF13C;
	// cmplwi cr6,r11,11
	cr6.compare<uint32_t>(r11.u32, 11, xer);
	// beq cr6,0x831af09c
	if (cr6.eq) goto loc_831AF09C;
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// beq cr6,0x831af154
	if (cr6.eq) goto loc_831AF154;
	// cmplwi cr6,r11,30
	cr6.compare<uint32_t>(r11.u32, 30, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x831b14e8
	if (!cr6.eq) goto loc_831B14E8;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b14f0
	if (!cr0.eq) goto loc_831B14F0;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
	// addi r5,r30,24
	ctx.r5.s64 = r30.s64 + 24;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,126
	ctx.r6.s64 = 126;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,96(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 96);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b14f8
	if (cr6.eq) goto loc_831B14F8;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r9,28
	cr6.compare<int32_t>(ctx.r9.s32, 28, xer);
	// bne cr6,0x831b14f8
	if (!cr6.eq) goto loc_831B14F8;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r11,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, r11.u32);
	// b 0x831af118
	goto loc_831AF118;
loc_831AF09C:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b1504
	if (!cr0.eq) goto loc_831B1504;
	// lwz r11,92(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b150c
	if (!cr6.eq) goto loc_831B150C;
	// li r6,2
	ctx.r6.s64 = 2;
	// lwz r5,96(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 96);
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8316c778
	sub_8316C778(ctx, base);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// oris r11,r11,6
	r11.u64 = r11.u64 | 393216;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// lwz r30,100(r23)
	r30.u64 = PPC_LOAD_U32(r23.u32 + 100);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831b1514
	if (cr6.eq) goto loc_831B1514;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// bne cr6,0x831b1514
	if (!cr6.eq) goto loc_831B1514;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8310ff78
	sub_8310FF78(ctx, base);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
loc_831AF118:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
	// b 0x831b0c94
	goto loc_831B0C94;
loc_831AF13C:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b0c94
	if (cr0.eq) goto loc_831B0C94;
	// li r4,3636
	ctx.r4.s64 = 3636;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831AF154:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// b 0x831b0c94
	goto loc_831B0C94;
loc_831AF16C:
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f410
	sub_8319F410(ctx, base);
loc_831AF17C:
	// lwz r27,128(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r23,r24
	r23.u64 = r24.u64;
	// lwz r26,120(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r25,556(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	// b 0x831ae6d4
	goto loc_831AE6D4;
loc_831AF190:
	// lwz r4,44(r23)
	ctx.r4.u64 = PPC_LOAD_U32(r23.u32 + 44);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831af1f8
	if (cr6.eq) goto loc_831AF1F8;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// bl 0x8319fdc0
	sub_8319FDC0(ctx, base);
	// b 0x831af1d0
	goto loc_831AF1D0;
loc_831AF1AC:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831b1520
	if (cr6.eq) goto loc_831B1520;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831b1520
	if (!cr6.eq) goto loc_831B1520;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f410
	sub_8319F410(ctx, base);
loc_831AF1D0:
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831af1ac
	if (!cr0.eq) goto loc_831AF1AC;
	// lwz r11,152(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lwz r9,156(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// addi r10,r11,972
	ctx.r10.s64 = r11.s64 + 972;
	// lwz r10,976(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 976);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// stw r9,976(r11)
	PPC_STORE_U32(r11.u32 + 976, ctx.r9.u32);
loc_831AF1F8:
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// cmplwi cr6,r11,13
	cr6.compare<uint32_t>(r11.u32, 13, xer);
	// bgt cr6,0x831b1628
	if (cr6.gt) goto loc_831B1628;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,2800
	r12.s64 = r12.s64 + 2800;
	// rlwinm r0,r11,1,0,30
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-31973
	r12.s64 = -2095382528;
	// addi r12,r12,-3540
	r12.s64 = r12.s64 + -3540;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_831AF22C;
	case 1:
		goto loc_831AF3CC;
	case 2:
		goto loc_831AF508;
	case 3:
		goto loc_831B0044;
	case 4:
		goto loc_831B036C;
	case 5:
		goto loc_831B0630;
	case 6:
		goto loc_831B1614;
	case 7:
		goto loc_831B1628;
	case 8:
		goto loc_831B1628;
	case 9:
		goto loc_831AF4F4;
	case 10:
		goto loc_831B0880;
	case 11:
		goto loc_831B09F4;
	case 12:
		goto loc_831AFA30;
	case 13:
		goto loc_831AFE38;
	default:
		__builtin_unreachable();
	}
loc_831AF22C:
	// lwz r11,24(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b152c
	if (!cr6.eq) goto loc_831B152C;
	// lwz r11,28(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b152c
	if (!cr6.eq) goto loc_831B152C;
	// lwz r11,32(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b152c
	if (!cr6.eq) goto loc_831B152C;
	// lwz r11,40(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b152c
	if (!cr6.eq) goto loc_831B152C;
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b0c94
	if (cr6.eq) goto loc_831B0C94;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x831af374
	if (!cr6.eq) goto loc_831AF374;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r11,48(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// oris r11,r11,8192
	r11.u64 = r11.u64 | 536870912;
	// stw r11,48(r28)
	PPC_STORE_U32(r28.u32 + 48, r11.u32);
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831af370
	if (cr6.eq) goto loc_831AF370;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af2e0
	if (!cr0.eq) goto loc_831AF2E0;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831af2e0
	if (cr0.eq) goto loc_831AF2E0;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831af2ec
	if (!cr6.gt) goto loc_831AF2EC;
loc_831AF2E0:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831AF2EC:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af334
	if (!cr0.eq) goto loc_831AF334;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831af334
	if (cr0.eq) goto loc_831AF334;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831af344
	if (!cr6.gt) goto loc_831AF344;
loc_831AF334:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831AF344:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r29,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r29.u32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r30.u32);
	// stw r16,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r16.u32);
loc_831AF370:
	// stw r28,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r28.u32);
loc_831AF374:
	// addi r10,r1,336
	ctx.r10.s64 = ctx.r1.s64 + 336;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r8,r1,100
	ctx.r8.s64 = ctx.r1.s64 + 100;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,2054
	ctx.r5.s64 = 2054;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
	// lwz r5,20(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x831af3bc
	if (!cr6.eq) goto loc_831AF3BC;
	// lwz r4,16(r5)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// bl 0x83196468
	sub_83196468(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// b 0x831b0c90
	goto loc_831B0C90;
loc_831AF3BC:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// b 0x831b0c8c
	goto loc_831B0C8C;
loc_831AF3CC:
	// lwz r11,28(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b1544
	if (!cr6.eq) goto loc_831B1544;
	// lwz r11,32(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b1544
	if (!cr6.eq) goto loc_831B1544;
	// addi r10,r1,304
	ctx.r10.s64 = ctx.r1.s64 + 304;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r8,r1,100
	ctx.r8.s64 = ctx.r1.s64 + 100;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,2054
	ctx.r5.s64 = 2054;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lwz r10,40(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 40);
	// rlwinm r11,r11,30,30,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0x2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ori r30,r11,1
	r30.u64 = r11.u64 | 1;
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// beq cr6,0x831af4b8
	if (cr6.eq) goto loc_831AF4B8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x831af4a0
	if (!cr6.eq) goto loc_831AF4A0;
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r10,27
	cr6.compare<int32_t>(ctx.r10.s32, 27, xer);
	// bne cr6,0x831af4a0
	if (!cr6.eq) goto loc_831AF4A0;
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x831af4a0
	if (!cr6.eq) goto loc_831AF4A0;
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x831af4a0
	if (!cr6.eq) goto loc_831AF4A0;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x831af4a0
	if (!cr6.eq) goto loc_831AF4A0;
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831af4a0
	if (!cr6.eq) goto loc_831AF4A0;
	// lwz r3,40(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 40);
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x831af4a0
	if (!cr0.eq) goto loc_831AF4A0;
	// li r4,3571
	ctx.r4.s64 = 3571;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
loc_831AF4A0:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// lwz r5,20(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// b 0x831af4c0
	goto loc_831AF4C0;
loc_831AF4B8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b1538
	if (!cr6.eq) goto loc_831B1538;
loc_831AF4C0:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm. r11,r11,0,28,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af4e0
	if (!cr0.eq) goto loc_831AF4E0;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// bl 0x831a2e58
	sub_831A2E58(ctx, base);
	// b 0x831af4e8
	goto loc_831AF4E8;
loc_831AF4E0:
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831969c8
	sub_831969C8(ctx, base);
loc_831AF4E8:
	// lwz r24,100(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lwz r29,96(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// b 0x831b0ab0
	goto loc_831B0AB0;
loc_831AF4F4:
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2e58
	sub_831A2E58(ctx, base);
	// b 0x831b0ab0
	goto loc_831B0AB0;
loc_831AF508:
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b1550
	if (!cr6.eq) goto loc_831B1550;
	// lwz r11,40(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b1550
	if (!cr6.eq) goto loc_831B1550;
	// addi r10,r1,272
	ctx.r10.s64 = ctx.r1.s64 + 272;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r8,r1,100
	ctx.r8.s64 = ctx.r1.s64 + 100;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,2558
	ctx.r5.s64 = 2558;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
	// addi r5,r1,272
	ctx.r5.s64 = ctx.r1.s64 + 272;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ad9b0
	sub_831AD9B0(ctx, base);
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// lwz r5,24(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// lwz r11,28(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 28);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x831af6c8
	if (!cr6.eq) goto loc_831AF6C8;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// bl 0x8316c778
	sub_8316C778(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// oris r11,r11,6
	r11.u64 = r11.u64 | 393216;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// stw r11,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r11.u32);
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r27,-16
	r11.s64 = r27.s64 + -16;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af630
	if (!cr0.eq) goto loc_831AF630;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831af630
	if (cr0.eq) goto loc_831AF630;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831af63c
	if (!cr6.gt) goto loc_831AF63C;
loc_831AF630:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831AF63C:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r29,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r29.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af684
	if (!cr0.eq) goto loc_831AF684;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831af684
	if (cr0.eq) goto loc_831AF684;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831af694
	if (!cr6.gt) goto loc_831AF694;
loc_831AF684:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831AF694:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r8,r10,4
	ctx.r8.s64 = ctx.r10.s64 + 4;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
	// lwz r24,32(r23)
	r24.u64 = PPC_LOAD_U32(r23.u32 + 32);
	// b 0x831afa18
	goto loc_831AFA18;
loc_831AF6C8:
	// lwz r11,32(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831af810
	if (!cr6.eq) goto loc_831AF810;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// bl 0x8316c778
	sub_8316C778(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwimi r11,r15,17,13,14
	r11.u64 = (rotl32(r15.u32, 17) & 0x60000) | (r11.u64 & 0xFFFFFFFFFFF9FFFF);
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// stw r11,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r11.u32);
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r27,-16
	r11.s64 = r27.s64 + -16;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// rlwinm r10,r10,0,30,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af77c
	if (!cr0.eq) goto loc_831AF77C;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831af77c
	if (cr0.eq) goto loc_831AF77C;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831af788
	if (!cr6.gt) goto loc_831AF788;
loc_831AF77C:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831AF788:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r29,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r29.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af7d0
	if (!cr0.eq) goto loc_831AF7D0;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831af7d0
	if (cr0.eq) goto loc_831AF7D0;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831af7e0
	if (!cr6.gt) goto loc_831AF7E0;
loc_831AF7D0:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831AF7E0:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r8,r10,4
	ctx.r8.s64 = ctx.r10.s64 + 4;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
	// b 0x831afa14
	goto loc_831AFA14;
loc_831AF810:
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8316c778
	sub_8316C778(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x83195d98
	sub_83195D98(ctx, base);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r27,-4
	r11.s64 = r27.s64 + -4;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af8cc
	if (!cr0.eq) goto loc_831AF8CC;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831af8cc
	if (cr0.eq) goto loc_831AF8CC;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831af8d8
	if (!cr6.gt) goto loc_831AF8D8;
loc_831AF8CC:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831AF8D8:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r29,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r29.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af920
	if (!cr0.eq) goto loc_831AF920;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831af920
	if (cr0.eq) goto loc_831AF920;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831af930
	if (!cr6.gt) goto loc_831AF930;
loc_831AF920:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831AF930:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r8,r10,4
	ctx.r8.s64 = ctx.r10.s64 + 4;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af988
	if (!cr0.eq) goto loc_831AF988;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831af988
	if (cr0.eq) goto loc_831AF988;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831af994
	if (!cr6.gt) goto loc_831AF994;
loc_831AF988:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831AF994:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r28,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r28.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af9dc
	if (!cr0.eq) goto loc_831AF9DC;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831af9dc
	if (cr0.eq) goto loc_831AF9DC;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831af9ec
	if (!cr6.gt) goto loc_831AF9EC;
loc_831AF9DC:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831AF9EC:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r29,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r29.u32);
	// lwz r4,32(r23)
	ctx.r4.u64 = PPC_LOAD_U32(r23.u32 + 32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// stw r26,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r26.u32);
loc_831AFA14:
	// lwz r24,28(r23)
	r24.u64 = PPC_LOAD_U32(r23.u32 + 28);
loc_831AFA18:
	// addi r5,r1,272
	ctx.r5.s64 = ctx.r1.s64 + 272;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196618
	sub_83196618(ctx, base);
	// b 0x831b0c94
	goto loc_831B0C94;
loc_831AFA30:
	// lwz r11,32(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b15b8
	if (!cr6.eq) goto loc_831B15B8;
	// lwz r11,40(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b15b8
	if (!cr6.eq) goto loc_831B15B8;
	// addi r11,r27,-1
	r11.s64 = r27.s64 + -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r28,r27
	r28.u64 = r27.u64;
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r11.u32);
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r3,584(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// bl 0x8319fc60
	sub_8319FC60(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r11,2
	r11.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// stw r28,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r28.u32);
	// stw r27,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r27.u32);
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// stw r3,28(r30)
	PPC_STORE_U32(r30.u32 + 28, ctx.r3.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r16.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r16,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r16.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,21
	ctx.r3.s64 = 21;
	// addi r29,r30,4
	r29.s64 = r30.s64 + 4;
	// addi r26,r1,96
	r26.s64 = ctx.r1.s64 + 96;
	// addi r25,r1,100
	r25.s64 = ctx.r1.s64 + 100;
	// bl 0x83194a38
	sub_83194A38(ctx, base);
	// li r11,11
	r11.s64 = 11;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r16.u32);
	// li r10,8
	ctx.r10.s64 = 8;
	// li r9,7
	ctx.r9.s64 = 7;
	// li r8,6
	ctx.r8.s64 = 6;
	// li r7,5
	ctx.r7.s64 = 5;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x83194a38
	sub_83194A38(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// li r7,3
	ctx.r7.s64 = 3;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ad9b0
	sub_831AD9B0(ctx, base);
	// lwz r4,24(r23)
	ctx.r4.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831afb64
	if (!cr6.eq) goto loc_831AFB64;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831afb4c
	if (cr6.eq) goto loc_831AFB4C;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// b 0x831afb74
	goto loc_831AFB74;
loc_831AFB4C:
	// addi r6,r1,132
	ctx.r6.s64 = ctx.r1.s64 + 132;
	// lwz r4,8(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r5,r1,124
	ctx.r5.s64 = ctx.r1.s64 + 124;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194ec8
	sub_83194EC8(ctx, base);
	// b 0x831afb74
	goto loc_831AFB74;
loc_831AFB64:
	// addi r6,r1,132
	ctx.r6.s64 = ctx.r1.s64 + 132;
	// addi r5,r1,124
	ctx.r5.s64 = ctx.r1.s64 + 124;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83194e48
	sub_83194E48(ctx, base);
loc_831AFB74:
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq 0x831b155c
	if (cr0.eq) goto loc_831B155C;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// li r7,3
	ctx.r7.s64 = 3;
	// lwz r10,124(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r8,184(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// mullw r29,r10,r11
	r29.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// bl 0x83195c20
	sub_83195C20(ctx, base);
	// lwz r5,24(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// bl 0x831960e8
	sub_831960E8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831afbf0
	if (!cr0.eq) goto loc_831AFBF0;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831afbf0
	if (cr0.eq) goto loc_831AFBF0;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831afbfc
	if (!cr6.gt) goto loc_831AFBFC;
loc_831AFBF0:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831AFBFC:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r27,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r27.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831afc44
	if (!cr0.eq) goto loc_831AFC44;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831afc44
	if (cr0.eq) goto loc_831AFC44;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831afc54
	if (!cr6.gt) goto loc_831AFC54;
loc_831AFC44:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831AFC54:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r8,r10,4
	ctx.r8.s64 = ctx.r10.s64 + 4;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// li r5,12
	ctx.r5.s64 = 12;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x831a0630
	sub_831A0630(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r25,r16
	r25.u64 = r16.u64;
	// lwz r29,28(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r24,28(r23)
	r24.u64 = PPC_LOAD_U32(r23.u32 + 28);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// bl 0x83110880
	sub_83110880(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r27,r30,4
	r27.s64 = r30.s64 + 4;
	// ori r11,r30,1
	r11.u64 = r30.u64 | 1;
	// ori r10,r27,1
	ctx.r10.u64 = r27.u64 | 1;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// lwz r4,28(r23)
	ctx.r4.u64 = PPC_LOAD_U32(r23.u32 + 28);
	// bl 0x8319fdc0
	sub_8319FDC0(ctx, base);
	// b 0x831afdf4
	goto loc_831AFDF4;
loc_831AFCD8:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831b15ac
	if (cr6.eq) goto loc_831B15AC;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// bne cr6,0x831b15ac
	if (!cr6.eq) goto loc_831B15AC;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmpwi cr6,r11,13
	cr6.compare<int32_t>(r11.s32, 13, xer);
	// bne cr6,0x831b1564
	if (!cr6.eq) goto loc_831B1564;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x831a0058
	sub_831A0058(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831afd1c
	if (cr0.eq) goto loc_831AFD1C;
	// clrlwi. r11,r25,24
	r11.u64 = r25.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b156c
	if (!cr0.eq) goto loc_831B156C;
	// mr r25,r15
	r25.u64 = r15.u64;
	// b 0x831afdf4
	goto loc_831AFDF4;
loc_831AFD1C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,24(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8319fdc0
	sub_8319FDC0(ctx, base);
	// b 0x831afdd0
	goto loc_831AFDD0;
loc_831AFD30:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// bne cr6,0x831b1578
	if (!cr6.eq) goto loc_831B1578;
	// lwz r28,16(r3)
	r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831b15a0
	if (cr6.eq) goto loc_831B15A0;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// bne cr6,0x831b15a0
	if (!cr6.eq) goto loc_831B15A0;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x831b1584
	if (!cr6.eq) goto loc_831B1584;
	// lwz r26,24(r28)
	r26.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8319a7e8
	sub_8319A7E8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b1590
	if (!cr0.eq) goto loc_831B1590;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831afda8
	if (!cr0.eq) goto loc_831AFDA8;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831afda8
	if (cr0.eq) goto loc_831AFDA8;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831afdb8
	if (!cr6.gt) goto loc_831AFDB8;
loc_831AFDA8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831AFDB8:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r26,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r26.u32);
loc_831AFDD0:
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831afd30
	if (!cr0.eq) goto loc_831AFD30;
	// li r6,15
	ctx.r6.s64 = 15;
	// lwz r4,164(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// li r5,8
	ctx.r5.s64 = 8;
	// lwz r3,160(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// bl 0x83118478
	sub_83118478(ctx, base);
loc_831AFDF4:
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// bne 0x831afcd8
	if (!cr0.eq) goto loc_831AFCD8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83171fa0
	sub_83171FA0(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,8
	ctx.r5.s64 = 8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83118478
	sub_83118478(ctx, base);
	// li r6,15
	ctx.r6.s64 = 15;
	// li r5,8
	ctx.r5.s64 = 8;
	// lwz r4,116(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// bl 0x83118478
	sub_83118478(ctx, base);
	// b 0x831b0c94
	goto loc_831B0C94;
loc_831AFE38:
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a0058
	sub_831A0058(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// lwz r4,584(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8319bbb0
	sub_8319BBB0(ctx, base);
loc_831AFE5C:
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8319ab18
	sub_8319AB18(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x831afe5c
	if (!cr6.eq) goto loc_831AFE5C;
	// clrlwi. r27,r28,24
	r27.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// beq 0x831afe84
	if (cr0.eq) goto loc_831AFE84;
	// lwz r28,28(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// b 0x831afe90
	goto loc_831AFE90;
loc_831AFE84:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
loc_831AFE90:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x831aff74
	if (!cr6.eq) goto loc_831AFF74;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,24(r23)
	ctx.r4.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x8319fdc0
	sub_8319FDC0(ctx, base);
	// b 0x831aff50
	goto loc_831AFF50;
loc_831AFEAC:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// bne cr6,0x831b15c4
	if (!cr6.eq) goto loc_831B15C4;
	// lwz r5,16(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831b15d0
	if (cr6.eq) goto loc_831B15D0;
	// lwz r4,20(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// bl 0x831961d8
	sub_831961D8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8316c778
	sub_8316C778(ctx, base);
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x83195d98
	sub_83195D98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// addi r5,r30,4
	ctx.r5.s64 = r30.s64 + 4;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196618
	sub_83196618(ctx, base);
	// stw r26,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r26.u32);
loc_831AFF50:
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831afeac
	if (!cr0.eq) goto loc_831AFEAC;
	// li r6,15
	ctx.r6.s64 = 15;
	// lwz r4,108(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// li r5,8
	ctx.r5.s64 = 8;
	// lwz r3,104(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// bl 0x83118478
	sub_83118478(ctx, base);
loc_831AFF74:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// lwz r30,564(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831affa8
	if (!cr0.eq) goto loc_831AFFA8;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831affa8
	if (cr0.eq) goto loc_831AFFA8;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831affb4
	if (!cr6.gt) goto loc_831AFFB4;
loc_831AFFA8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831AFFB4:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831afffc
	if (!cr0.eq) goto loc_831AFFFC;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831afffc
	if (cr0.eq) goto loc_831AFFFC;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831b000c
	if (!cr6.gt) goto loc_831B000C;
loc_831AFFFC:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831B000C:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r29,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r29.u32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// mr r29,r16
	r29.u64 = r16.u64;
loc_831B0034:
	// stw r28,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r28.u32);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// lwz r24,28(r23)
	r24.u64 = PPC_LOAD_U32(r23.u32 + 28);
	// b 0x831b0c94
	goto loc_831B0C94;
loc_831B0044:
	// lwz r11,32(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b15d8
	if (!cr6.eq) goto loc_831B15D8;
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r16.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r16,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r16.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,11
	ctx.r7.s64 = 11;
	// li r6,10
	ctx.r6.s64 = 10;
	// li r5,9
	ctx.r5.s64 = 9;
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r30,r1,256
	r30.s64 = ctx.r1.s64 + 256;
	// addi r29,r1,96
	r29.s64 = ctx.r1.s64 + 96;
	// addi r28,r1,100
	r28.s64 = ctx.r1.s64 + 100;
	// bl 0x83194a38
	sub_83194A38(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r7,3
	ctx.r7.s64 = 3;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r24,28(r23)
	r24.u64 = PPC_LOAD_U32(r23.u32 + 28);
	// lwz r25,40(r23)
	r25.u64 = PPC_LOAD_U32(r23.u32 + 40);
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b0114
	if (!cr0.eq) goto loc_831B0114;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831b0114
	if (cr0.eq) goto loc_831B0114;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831b0120
	if (!cr6.gt) goto loc_831B0120;
loc_831B0114:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831B0120:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r29,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r29.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b0168
	if (!cr0.eq) goto loc_831B0168;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b0168
	if (cr0.eq) goto loc_831B0168;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831b0178
	if (!cr6.gt) goto loc_831B0178;
loc_831B0168:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831B0178:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r8,r10,4
	ctx.r8.s64 = ctx.r10.s64 + 4;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// lwz r3,584(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// bl 0x8319fc60
	sub_8319FC60(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r5,12
	ctx.r5.s64 = 12;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// stw r15,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r15.u32);
	// stw r29,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r29.u32);
	// stw r28,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r28.u32);
	// bl 0x831a0630
	sub_831A0630(ctx, base);
	// lwz r5,20(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831b01e4
	if (cr6.eq) goto loc_831B01E4;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
loc_831B01E4:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// stw r26,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r26.u32);
	// addi r5,r1,256
	ctx.r5.s64 = ctx.r1.s64 + 256;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ad9b0
	sub_831AD9B0(ctx, base);
	// lwz r5,24(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831b02d8
	if (cr6.eq) goto loc_831B02D8;
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// mr. r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x831b02d8
	if (cr0.eq) goto loc_831B02D8;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// bl 0x8316c778
	sub_8316C778(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwimi r11,r15,17,13,14
	r11.u64 = (rotl32(r15.u32, 17) & 0x60000) | (r11.u64 & 0xFFFFFFFFFFF9FFFF);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// bl 0x8311bba0
	sub_8311BBA0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// addi r5,r1,256
	ctx.r5.s64 = ctx.r1.s64 + 256;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196618
	sub_83196618(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-16
	r11.s64 = r30.s64 + -16;
	// add r10,r3,r11
	ctx.r10.u64 = ctx.r3.u64 + r11.u64;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// clrlwi. r9,r11,30
	ctx.r9.u64 = r11.u32 & 0x3;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831b02c8
	if (!cr0.eq) goto loc_831B02C8;
	// rlwinm. r9,r11,30,28,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0xF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831b02c8
	if (!cr0.eq) goto loc_831B02C8;
	// li r9,29
	ctx.r9.s64 = 29;
	// rlwimi r11,r9,3,23,31
	r11.u64 = (rotl32(ctx.r9.u32, 3) & 0x1FF) | (r11.u64 & 0xFFFFFFFFFFFFFE00);
	// stw r11,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r11.u32);
loc_831B02C8:
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r11.u32);
	// b 0x831b032c
	goto loc_831B032C;
loc_831B02D8:
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r16.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r16,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r16.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,10
	ctx.r4.s64 = 10;
	// li r3,9
	ctx.r3.s64 = 9;
	// bl 0x83194a38
	sub_83194A38(ctx, base);
	// lwz r11,256(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	// and. r11,r3,r11
	r11.u64 = ctx.r3.u64 & r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b031c
	if (cr0.eq) goto loc_831B031C;
	// li r4,3584
	ctx.r4.s64 = 3584;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
loc_831B031C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
loc_831B032C:
	// stw r28,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r28.u32);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x831b034c
	if (cr6.eq) goto loc_831B034C;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
loc_831B034C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r29,r28
	r29.u64 = r28.u64;
	// stw r27,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r27.u32);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// b 0x831b0c94
	goto loc_831B0C94;
loc_831B036C:
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b15e4
	if (!cr6.eq) goto loc_831B15E4;
	// lwz r11,32(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b15e4
	if (!cr6.eq) goto loc_831B15E4;
	// lwz r11,40(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b15e4
	if (!cr6.eq) goto loc_831B15E4;
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r16.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r16,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r16.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,11
	ctx.r7.s64 = 11;
	// li r6,10
	ctx.r6.s64 = 10;
	// li r5,9
	ctx.r5.s64 = 9;
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r30,r1,208
	r30.s64 = ctx.r1.s64 + 208;
	// addi r29,r1,96
	r29.s64 = ctx.r1.s64 + 96;
	// addi r28,r1,100
	r28.s64 = ctx.r1.s64 + 100;
	// bl 0x83194a38
	sub_83194A38(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r7,3
	ctx.r7.s64 = 3;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// stw r28,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r28.u32);
	// addi r5,r1,208
	ctx.r5.s64 = ctx.r1.s64 + 208;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ad9b0
	sub_831AD9B0(ctx, base);
	// lwz r5,24(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831b04e4
	if (cr6.eq) goto loc_831B04E4;
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// mr. r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x831b04e4
	if (cr0.eq) goto loc_831B04E4;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// bl 0x8316c778
	sub_8316C778(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwimi r11,r15,17,13,14
	r11.u64 = (rotl32(r15.u32, 17) & 0x60000) | (r11.u64 & 0xFFFFFFFFFFF9FFFF);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// bl 0x8311bba0
	sub_8311BBA0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// addi r5,r1,208
	ctx.r5.s64 = ctx.r1.s64 + 208;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196618
	sub_83196618(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-4
	r11.s64 = r30.s64 + -4;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x831b0538
	goto loc_831B0538;
loc_831B04E4:
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r16.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r16,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r16.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,10
	ctx.r4.s64 = 10;
	// li r3,9
	ctx.r3.s64 = 9;
	// bl 0x83194a38
	sub_83194A38(ctx, base);
	// lwz r11,208(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	// and. r11,r3,r11
	r11.u64 = ctx.r3.u64 & r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b0528
	if (cr0.eq) goto loc_831B0528;
	// li r4,3584
	ctx.r4.s64 = 3584;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
loc_831B0528:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
loc_831B0538:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b0568
	if (!cr0.eq) goto loc_831B0568;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831b0568
	if (cr0.eq) goto loc_831B0568;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831b0574
	if (!cr6.gt) goto loc_831B0574;
loc_831B0568:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831B0574:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r29,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r29.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b05bc
	if (!cr0.eq) goto loc_831B05BC;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b05bc
	if (cr0.eq) goto loc_831B05BC;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831b05cc
	if (!cr6.gt) goto loc_831B05CC;
loc_831B05BC:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831B05CC:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r8,r10,4
	ctx.r8.s64 = ctx.r10.s64 + 4;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// lwz r3,584(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// bl 0x8319fc60
	sub_8319FC60(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r5,12
	ctx.r5.s64 = 12;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// stw r15,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r15.u32);
	// stw r29,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r29.u32);
	// stw r28,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r28.u32);
	// bl 0x831a0630
	sub_831A0630(ctx, base);
	// mr r29,r28
	r29.u64 = r28.u64;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// lwz r24,28(r23)
	r24.u64 = PPC_LOAD_U32(r23.u32 + 28);
	// stw r27,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r27.u32);
	// b 0x831b0c94
	goto loc_831B0C94;
loc_831B0630:
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b15f0
	if (!cr6.eq) goto loc_831B15F0;
	// lwz r11,32(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b15f0
	if (!cr6.eq) goto loc_831B15F0;
	// lwz r11,40(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b15f0
	if (!cr6.eq) goto loc_831B15F0;
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r16.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r16,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r16.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,10
	ctx.r6.s64 = 10;
	// li r5,9
	ctx.r5.s64 = 9;
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r30,r1,240
	r30.s64 = ctx.r1.s64 + 240;
	// addi r29,r1,96
	r29.s64 = ctx.r1.s64 + 96;
	// addi r28,r1,100
	r28.s64 = ctx.r1.s64 + 100;
	// bl 0x83194a38
	sub_83194A38(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r7,3
	ctx.r7.s64 = 3;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// stw r29,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r29.u32);
	// addi r5,r1,240
	ctx.r5.s64 = ctx.r1.s64 + 240;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ad9b0
	sub_831AD9B0(ctx, base);
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// lwz r5,24(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4278
	sub_831A4278(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8316c778
	sub_8316C778(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// oris r11,r11,6
	r11.u64 = r11.u64 | 393216;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// bl 0x8311bba0
	sub_8311BBA0(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// addi r5,r1,240
	ctx.r5.s64 = ctx.r1.s64 + 240;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196618
	sub_83196618(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r11,r30,-4
	r11.s64 = r30.s64 + -4;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b07c8
	if (!cr0.eq) goto loc_831B07C8;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831b07c8
	if (cr0.eq) goto loc_831B07C8;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831b07d4
	if (!cr6.gt) goto loc_831B07D4;
loc_831B07C8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831B07D4:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stwx r27,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r27.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b081c
	if (!cr0.eq) goto loc_831B081C;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b081c
	if (cr0.eq) goto loc_831B081C;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831b082c
	if (!cr6.gt) goto loc_831B082C;
loc_831B081C:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831B082C:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r8,r10,4
	ctx.r8.s64 = ctx.r10.s64 + 4;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// lwz r3,584(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// bl 0x8319fc60
	sub_8319FC60(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r5,12
	ctx.r5.s64 = 12;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// stw r15,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r15.u32);
	// stw r27,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r27.u32);
	// stw r29,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r29.u32);
	// bl 0x831a0630
	sub_831A0630(ctx, base);
	// b 0x831b0034
	goto loc_831B0034;
loc_831B0880:
	// addi r3,r1,168
	ctx.r3.s64 = ctx.r1.s64 + 168;
	// lwz r4,584(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// addi r3,r1,168
	ctx.r3.s64 = ctx.r1.s64 + 168;
	// bl 0x8319bbb0
	sub_8319BBB0(ctx, base);
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
loc_831B0898:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b08c8
	if (!cr6.eq) goto loc_831B08C8;
	// lwz r11,168(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831b08b8
	if (cr0.eq) goto loc_831B08B8;
	// mr r11,r16
	r11.u64 = r16.u64;
loc_831B08B8:
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// mr r11,r15
	r11.u64 = r15.u64;
	// beq cr6,0x831b08cc
	if (cr6.eq) goto loc_831B08CC;
loc_831B08C8:
	// mr r11,r16
	r11.u64 = r16.u64;
loc_831B08CC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b08f0
	if (!cr0.eq) goto loc_831B08F0;
	// addi r3,r1,168
	ctx.r3.s64 = ctx.r1.s64 + 168;
	// bl 0x8319ab18
	sub_8319AB18(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x831b08f0
	if (cr6.eq) goto loc_831B08F0;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831b0898
	if (!cr6.eq) goto loc_831B0898;
loc_831B08F0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831b15fc
	if (cr6.eq) goto loc_831B15FC;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// bne cr6,0x831b0948
	if (!cr6.eq) goto loc_831B0948;
loc_831B090C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b0934
	if (cr6.eq) goto loc_831B0934;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,24(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x831b092c
	if (cr6.eq) goto loc_831B092C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831b090c
	goto loc_831B090C;
loc_831B092C:
	// mr r11,r15
	r11.u64 = r15.u64;
	// b 0x831b0938
	goto loc_831B0938;
loc_831B0934:
	// mr r11,r16
	r11.u64 = r16.u64;
loc_831B0938:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b098c
	if (!cr0.eq) goto loc_831B098C;
	// lwz r4,24(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// b 0x831b0980
	goto loc_831B0980;
loc_831B0948:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b0970
	if (cr6.eq) goto loc_831B0970;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,4(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x831b0968
	if (cr6.eq) goto loc_831B0968;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831b0948
	goto loc_831B0948;
loc_831B0968:
	// mr r11,r15
	r11.u64 = r15.u64;
	// b 0x831b0974
	goto loc_831B0974;
loc_831B0970:
	// mr r11,r16
	r11.u64 = r16.u64;
loc_831B0974:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b098c
	if (!cr0.eq) goto loc_831B098C;
	// lwz r4,4(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
loc_831B0980:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
loc_831B098C:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831b0b80
	if (cr6.eq) goto loc_831B0B80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b09d0
	if (!cr0.eq) goto loc_831B09D0;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831b09d0
	if (cr0.eq) goto loc_831B09D0;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831b09dc
	if (!cr6.gt) goto loc_831B09DC;
loc_831B09D0:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831B09DC:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// b 0x831b0b14
	goto loc_831B0B14;
loc_831B09F4:
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// lwz r4,584(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 584);
	// bl 0x8319f2f8
	sub_8319F2F8(ctx, base);
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x8319bbb0
	sub_8319BBB0(ctx, base);
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
loc_831B0A0C:
	// lwz r11,200(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b0a3c
	if (!cr6.eq) goto loc_831B0A3C;
	// lwz r11,192(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831b0a2c
	if (cr0.eq) goto loc_831B0A2C;
	// mr r11,r16
	r11.u64 = r16.u64;
loc_831B0A2C:
	// lwz r10,196(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// mr r11,r15
	r11.u64 = r15.u64;
	// beq cr6,0x831b0a40
	if (cr6.eq) goto loc_831B0A40;
loc_831B0A3C:
	// mr r11,r16
	r11.u64 = r16.u64;
loc_831B0A40:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b0a5c
	if (!cr0.eq) goto loc_831B0A5C;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x8319ab18
	sub_8319AB18(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831b0a0c
	if (!cr6.eq) goto loc_831B0A0C;
loc_831B0A5C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831b1608
	if (cr6.eq) goto loc_831B1608;
	// lwz r10,564(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
loc_831B0A6C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b0a94
	if (cr6.eq) goto loc_831B0A94;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x831b0a8c
	if (cr6.eq) goto loc_831B0A8C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831b0a6c
	goto loc_831B0A6C;
loc_831B0A8C:
	// mr r11,r15
	r11.u64 = r15.u64;
	// b 0x831b0a98
	goto loc_831B0A98;
loc_831B0A94:
	// mr r11,r16
	r11.u64 = r16.u64;
loc_831B0A98:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b0ab0
	if (!cr0.eq) goto loc_831B0AB0;
	// lwz r4,8(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
loc_831B0AB0:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831b0b80
	if (cr6.eq) goto loc_831B0B80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b0af4
	if (!cr0.eq) goto loc_831B0AF4;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r3,r11,-4
	xer.ca = r11.u32 > 3;
	ctx.r3.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x831b0af4
	if (cr0.eq) goto loc_831B0AF4;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x831b0b00
	if (!cr6.gt) goto loc_831B0B00;
loc_831B0AF4:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
loc_831B0B00:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// rlwinm r11,r10,2,0,29
	r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_831B0B14:
	// stwx r30,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, r30.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b0b48
	if (!cr0.eq) goto loc_831B0B48;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b0b48
	if (cr0.eq) goto loc_831B0B48;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x831b0b58
	if (!cr6.gt) goto loc_831B0B58;
loc_831B0B48:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x83172038
	sub_83172038(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_831B0B58:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stwx r29,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r29.u32);
	// bl 0x831a04a0
	sub_831A04A0(ctx, base);
	// mr r24,r16
	r24.u64 = r16.u64;
loc_831B0B80:
	// mr r22,r16
	r22.u64 = r16.u64;
	// b 0x831b0c94
	goto loc_831B0C94;
loc_831B0B88:
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831b0c94
	if (!cr6.eq) goto loc_831B0C94;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a4150
	sub_831A4150(ctx, base);
	// li r5,12
	ctx.r5.s64 = 12;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x831a0630
	sub_831A0630(ctx, base);
	// addi r11,r17,4
	r11.s64 = r17.s64 + 4;
	// lwz r11,4(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b0c94
	if (!cr0.eq) goto loc_831B0C94;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b0c94
	if (cr0.eq) goto loc_831B0C94;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831b0c68
	if (cr6.eq) goto loc_831B0C68;
	// lwz r10,4(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// cmpwi cr6,r10,12
	cr6.compare<int32_t>(ctx.r10.s32, 12, xer);
	// bne cr6,0x831b0c0c
	if (!cr6.eq) goto loc_831B0C0C;
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b0c0c
	if (cr6.eq) goto loc_831B0C0C;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r9,14
	cr6.compare<int32_t>(ctx.r9.s32, 14, xer);
	// bne cr6,0x831b0c0c
	if (!cr6.eq) goto loc_831B0C0C;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// addi r11,r11,-26
	r11.s64 = r11.s64 + -26;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x831b0c10
	goto loc_831B0C10;
loc_831B0C0C:
	// mr r11,r16
	r11.u64 = r16.u64;
loc_831B0C10:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af17c
	if (!cr0.eq) goto loc_831AF17C;
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831b0c68
	if (!cr6.eq) goto loc_831B0C68;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,12
	cr6.compare<int32_t>(ctx.r10.s32, 12, xer);
	// bne cr6,0x831b0c5c
	if (!cr6.eq) goto loc_831B0C5C;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b0c5c
	if (cr6.eq) goto loc_831B0C5C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x831b0c5c
	if (!cr6.eq) goto loc_831B0C5C;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// addi r11,r11,-26
	r11.s64 = r11.s64 + -26;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x831b0c60
	goto loc_831B0C60;
loc_831B0C5C:
	// mr r11,r16
	r11.u64 = r16.u64;
loc_831B0C60:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af17c
	if (!cr0.eq) goto loc_831AF17C;
loc_831B0C68:
	// addi r10,r1,320
	ctx.r10.s64 = ctx.r1.s64 + 320;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r8,r1,100
	ctx.r8.s64 = ctx.r1.s64 + 100;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
loc_831B0C8C:
	// lwz r24,100(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
loc_831B0C90:
	// lwz r29,96(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_831B0C94:
	// li r11,10
	r11.s64 = 10;
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r16.u32);
	// li r10,9
	ctx.r10.s64 = 9;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r9,11
	ctx.r9.s64 = 11;
	// li r8,8
	ctx.r8.s64 = 8;
	// li r7,7
	ctx.r7.s64 = 7;
	// li r6,6
	ctx.r6.s64 = 6;
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,3
	ctx.r3.s64 = 3;
	// bl 0x83194a38
	sub_83194A38(ctx, base);
	// lwz r11,576(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 576);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// stw r11,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831b0ce0
	if (cr0.eq) goto loc_831B0CE0;
	// mr r11,r16
	r11.u64 = r16.u64;
loc_831B0CE0:
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r11.u32);
	// stw r16,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r16.u32);
loc_831B0CE8:
	// lwz r6,140(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x831b0d08
	if (cr6.eq) goto loc_831B0D08;
	// lwz r11,8(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// lwz r10,144(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// mr r11,r16
	r11.u64 = r16.u64;
	// bne cr6,0x831b0d0c
	if (!cr6.eq) goto loc_831B0D0C;
loc_831B0D08:
	// mr r11,r15
	r11.u64 = r15.u64;
loc_831B0D0C:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831af17c
	if (!cr0.eq) goto loc_831AF17C;
	// stw r16,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r16.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r16.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r11,r11,3,0,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwzx r30,r11,r6
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x83194a38
	sub_83194A38(ctx, base);
	// and. r11,r3,r28
	r11.u64 = ctx.r3.u64 & r28.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// beq 0x831b0d78
	if (cr0.eq) goto loc_831B0D78;
	// bl 0x8319ba60
	sub_8319BA60(ctx, base);
	// cmpwi cr6,r30,11
	cr6.compare<int32_t>(r30.s32, 11, xer);
	// bne cr6,0x831b0ce8
	if (!cr6.eq) goto loc_831B0CE8;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// b 0x831b0ce8
	goto loc_831B0CE8;
loc_831B0D78:
	// bl 0x8316b960
	sub_8316B960(ctx, base);
	// b 0x831b0ce8
	goto loc_831B0CE8;
loc_831B0D80:
	// lwz r3,572(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 572);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b0f74
	if (!cr0.eq) goto loc_831B0F74;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b0f74
	if (cr0.eq) goto loc_831B0F74;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b0dac
	if (cr0.eq) goto loc_831B0DAC;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// b 0x831b0db8
	goto loc_831B0DB8;
loc_831B0DAC:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_831B0DB8:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r10,r4
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831b0e08
	if (!cr0.eq) goto loc_831B0E08;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831B0E08:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r14,r30
	r14.u64 = r30.u64;
	// stw r11,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r11.u32);
	// lwz r26,4(r30)
	r26.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r30,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r30.u32);
	// stw r26,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r26.u32);
	// stw r26,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r26.u32);
	// lwz r11,68(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 68);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b0f58
	if (cr6.eq) goto loc_831B0F58;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,28,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b0e50
	if (cr0.eq) goto loc_831B0E50;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f688
	sub_8319F688(ctx, base);
	// lwz r3,580(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 580);
	// bl 0x8319aa80
	sub_8319AA80(ctx, base);
loc_831B0E50:
	// lwz r30,68(r26)
	r30.u64 = PPC_LOAD_U32(r26.u32 + 68);
	// b 0x831b0ea8
	goto loc_831B0EA8;
loc_831B0E58:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831b0e78
	if (!cr6.eq) goto loc_831B0E78;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f410
	sub_8319F410(ctx, base);
	// b 0x831b0ea8
	goto loc_831B0EA8;
loc_831B0E78:
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831b14c4
	if (!cr6.eq) goto loc_831B14C4;
	// lwz r5,8(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x831b14b8
	if (cr6.eq) goto loc_831B14B8;
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831b14b8
	if (!cr6.eq) goto loc_831B14B8;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319f410
	sub_8319F410(ctx, base);
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
loc_831B0EA8:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831b0e58
	if (!cr6.eq) goto loc_831B0E58;
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r16.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r16,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r16.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,11
	ctx.r3.s64 = 11;
	// addi r30,r1,352
	r30.s64 = ctx.r1.s64 + 352;
	// bl 0x83194a38
	sub_83194A38(ctx, base);
	// oris r29,r3,219
	r29.u64 = ctx.r3.u64 | 14352384;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r16.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r16,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r16.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// ori r29,r29,57344
	r29.u64 = r29.u64 | 57344;
	// bl 0x83194a38
	sub_83194A38(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// bl 0x831a2160
	sub_831A2160(ctx, base);
	// lwz r11,576(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 576);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b0f58
	if (!cr0.eq) goto loc_831B0F58;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b0f58
	if (cr0.eq) goto loc_831B0F58;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a07c0
	sub_831A07C0(ctx, base);
loc_831B0F58:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// b 0x831ae6c4
	goto loc_831AE6C4;
loc_831B0F68:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B0F74:
	// stw r25,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r25.u32);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lwz r11,792(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 792);
	// rlwinm r9,r10,0,29,27
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r9,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r9.u32);
	// lwz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// stw r10,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r10.u32);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// stw r16,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r16.u32);
	// bne cr6,0x831b0fa4
	if (!cr6.eq) goto loc_831B0FA4;
	// li r10,32
	ctx.r10.s64 = 32;
loc_831B0FA4:
	// lwz r6,796(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 796);
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// ble cr6,0x831b0fcc
	if (!cr6.gt) goto loc_831B0FCC;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b0fbc
	if (!cr6.eq) goto loc_831B0FBC;
	// li r11,32
	r11.s64 = 32;
loc_831B0FBC:
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// li r4,3603
	ctx.r4.s64 = 3603;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B0FCC:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831b0fe8
	if (cr0.eq) goto loc_831B0FE8;
	// rlwinm. r10,r9,0,16,16
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b0fe8
	if (!cr0.eq) goto loc_831B0FE8;
	// addi r11,r11,-16
	r11.s64 = r11.s64 + -16;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
loc_831B0FE8:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lfs f31,3084(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3084);
	f31.f64 = double(temp.f32);
	// beq cr6,0x831b1210
	if (cr6.eq) goto loc_831B1210;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// andi. r11,r11,1280
	r11.u64 = r11.u64 & 1280;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b1210
	if (cr0.eq) goto loc_831B1210;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b1210
	if (!cr0.eq) goto loc_831B1210;
	// mr r27,r11
	r27.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b1210
	if (cr0.eq) goto loc_831B1210;
loc_831B1024:
	// lwz r11,68(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 68);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b11f4
	if (cr0.eq) goto loc_831B11F4;
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b1044
	if (!cr6.eq) goto loc_831B1044;
	// mr r11,r16
	r11.u64 = r16.u64;
	// b 0x831b1048
	goto loc_831B1048;
loc_831B1044:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
loc_831B1048:
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831b105c
	if (cr0.eq) goto loc_831B105C;
	// mr r28,r16
	r28.u64 = r16.u64;
	// b 0x831b1068
	goto loc_831B1068;
loc_831B105C:
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r28,r10,-40
	r28.s64 = ctx.r10.s64 + -40;
loc_831B1068:
	// stw r11,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r11.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b10e0
	if (cr6.eq) goto loc_831B10E0;
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mulli r11,r4,40
	r11.s64 = ctx.r4.s64 * 40;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r30,r11,29,18,31
	r30.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// bl 0x83199928
	sub_83199928(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831b10e0
	if (cr6.eq) goto loc_831B10E0;
loc_831B10CC:
	// ld r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// bne 0x831b10cc
	if (!cr0.eq) goto loc_831B10CC;
loc_831B10E0:
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b11a0
	if (cr6.eq) goto loc_831B11A0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831b11a0
	if (cr6.eq) goto loc_831B11A0;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1108:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x831b1188
	if (!cr6.eq) goto loc_831B1188;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b1350
	if (cr6.eq) goto loc_831B1350;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,11
	cr6.compare<int32_t>(ctx.r10.s32, 11, xer);
	// bne cr6,0x831b1350
	if (!cr6.eq) goto loc_831B1350;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x831b1188
	if (cr6.eq) goto loc_831B1188;
	// lwz r10,44(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831b1188
	if (cr0.eq) goto loc_831B1188;
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mulli r10,r4,40
	ctx.r10.s64 = ctx.r4.s64 * 40;
	// lwz r3,564(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r30,r11,29,18,31
	r30.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// bl 0x83199928
	sub_83199928(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831b1188
	if (cr6.eq) goto loc_831B1188;
loc_831B1174:
	// ld r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// bne 0x831b1174
	if (!cr0.eq) goto loc_831B1174;
loc_831B1188:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b11a0
	if (cr6.eq) goto loc_831B11A0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831b135c
	if (!cr6.eq) goto loc_831B135C;
loc_831B11A0:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r29,r11
	r29.u64 = r11.u64;
	// bne cr6,0x831b1108
	if (!cr6.eq) goto loc_831B1108;
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b11d8
	if (cr6.eq) goto loc_831B11D8;
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,56(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x831a2920
	sub_831A2920(ctx, base);
loc_831B11D8:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// lwz r4,4(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831a2d80
	sub_831A2D80(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// stw r16,80(r11)
	PPC_STORE_U32(r11.u32 + 80, r16.u32);
loc_831B11F4:
	// rlwinm r11,r27,0,0,30
	r11.u64 = rotl64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b1210
	if (!cr0.eq) goto loc_831B1210;
	// mr r27,r11
	r27.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b1024
	if (!cr6.eq) goto loc_831B1024;
loc_831B1210:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// rlwinm. r11,r11,0,7,7
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b14ac
	if (cr0.eq) goto loc_831B14AC;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r11,r3,31
	r11.u64 = ctx.r3.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b122c
	if (cr0.eq) goto loc_831B122C;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
loc_831B122C:
	// stw r3,564(r31)
	PPC_STORE_U32(r31.u32 + 564, ctx.r3.u32);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,612(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 612);
	// bl 0x83199928
	sub_83199928(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// li r5,1
	ctx.r5.s64 = 1;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// lfs f1,3080(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x831d0120
	sub_831D0120(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// lwz r30,4(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b14ac
	if (!cr0.eq) goto loc_831B14AC;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x831b14ac
	if (cr0.eq) goto loc_831B14AC;
loc_831B1288:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b13ec
	if (!cr0.eq) goto loc_831B13EC;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r11,r11,-40
	xer.ca = r11.u32 > 39;
	r11.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b13ec
	if (cr0.eq) goto loc_831B13EC;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,10624
	cr6.compare<uint32_t>(r11.u32, 10624, xer);
	// bne cr6,0x831b13ec
	if (!cr6.eq) goto loc_831B13EC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319ad98
	sub_8319AD98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83196ef0
	sub_83196EF0(ctx, base);
	// stw r16,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r16.u32);
	// addi r26,r30,8
	r26.s64 = r30.s64 + 8;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r27,8(r30)
	r27.u64 = PPC_LOAD_U32(r30.u32 + 8);
loc_831B12D4:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831b1368
	if (cr6.eq) goto loc_831B1368;
	// lwz r28,4(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831d8cf8
	sub_831D8CF8(ctx, base);
	// lwz r11,36(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 36);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b1338
	if (!cr0.eq) goto loc_831B1338;
	// lwz r11,32(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r28,r11,-40
	xer.ca = r11.u32 > 39;
	r28.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x831b1338
	if (cr0.eq) goto loc_831B1338;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8310fac8
	sub_8310FAC8(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b1338
	if (cr0.eq) goto loc_831B1338;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8310ff78
	sub_8310FF78(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x831b1338
	if (!cr6.eq) goto loc_831B1338;
	// stw r29,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r29.u32);
loc_831B1338:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x831b1348
	if (!cr6.eq) goto loc_831B1348;
	// addi r26,r27,12
	r26.s64 = r27.s64 + 12;
loc_831B1348:
	// lwz r27,0(r26)
	r27.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// b 0x831b12d4
	goto loc_831B12D4;
loc_831B1350:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B135C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1368:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
	// lwz r10,48(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lwz r11,48(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwimi r11,r10,0,10,10
	r11.u64 = (rotl32(ctx.r10.u32, 0) & 0x200000) | (r11.u64 & 0xFFFFFFFFFFDFFFFF);
	// stw r11,48(r29)
	PPC_STORE_U32(r29.u32 + 48, r11.u32);
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// rlwinm r11,r11,0,11,9
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFDFFFFF;
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
	// bl 0x8310fc20
	sub_8310FC20(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b1494
	if (cr0.eq) goto loc_831B1494;
	// stw r29,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r29.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r6,612(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 612);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x831ced48
	sub_831CED48(ctx, base);
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r5,r4,32
	ctx.r5.s64 = ctx.r4.s64 + 32;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,117
	ctx.r6.s64 = 117;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// b 0x831b1474
	goto loc_831B1474;
loc_831B13EC:
	// lwz r11,68(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 68);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b1494
	if (cr0.eq) goto loc_831B1494;
	// stw r30,564(r31)
	PPC_STORE_U32(r31.u32 + 564, r30.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r6,612(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 612);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x831ced48
	sub_831CED48(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r4,564(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// li r6,117
	ctx.r6.s64 = 117;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831cdcf8
	sub_831CDCF8(ctx, base);
	// lwz r11,564(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 564);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// rlwinm r10,r29,0,0,30
	ctx.r10.u64 = rotl64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// ori r8,r9,1
	ctx.r8.u64 = ctx.r9.u64 | 1;
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// addi r6,r10,-36
	ctx.r6.s64 = ctx.r10.s64 + -36;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// stw r7,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r7.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r7,r7,0,0,30
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,36(r7)
	PPC_STORE_U32(ctx.r7.u32 + 36, ctx.r9.u32);
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// stw r6,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r6.u32);
loc_831B1474:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319b3a0
	sub_8319B3A0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x83123628
	sub_83123628(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
loc_831B1494:
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r30,4(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b14ac
	if (!cr0.eq) goto loc_831B14AC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831b1288
	if (!cr6.eq) goto loc_831B1288;
loc_831B14AC:
	// addi r1,r1,528
	ctx.r1.s64 = ctx.r1.s64 + 528;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82ca2c00
	return;
loc_831B14B8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B14C4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B14D0:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B14DC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B14E8:
	// li r4,3636
	ctx.r4.s64 = 3636;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B14F0:
	// li r4,3636
	ctx.r4.s64 = 3636;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B14F8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1504:
	// li r4,3636
	ctx.r4.s64 = 3636;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B150C:
	// li r4,3636
	ctx.r4.s64 = 3636;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1514:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1520:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B152C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1538:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1544:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1550:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B155C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1564:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B156C:
	// li r4,3642
	ctx.r4.s64 = 3642;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1578:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1584:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1590:
	// li r4,3532
	ctx.r4.s64 = 3532;
	// lwz r5,24(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B15A0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B15AC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B15B8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B15C4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B15D0:
	// li r4,4800
	ctx.r4.s64 = 4800;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B15D8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B15E4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B15F0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B15FC:
	// li r4,3626
	ctx.r4.s64 = 3626;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1608:
	// li r4,3625
	ctx.r4.s64 = 3625;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1614:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,3788
	ctx.r5.s64 = r11.s64 + 3788;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1628:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1634:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B163C:
	// li r4,3529
	ctx.r4.s64 = 3529;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831AE2C8) {
	__imp__sub_831AE2C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831B1648) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc4
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r21,r5
	r21.u64 = ctx.r5.u64;
	// li r19,0
	r19.s64 = 0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831b2280
	if (cr6.eq) goto loc_831B2280;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x831b2280
	if (!cr6.eq) goto loc_831B2280;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// stw r27,8(r28)
	PPC_STORE_U32(r28.u32 + 8, r27.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b1774
	if (!cr6.eq) goto loc_831B1774;
	// lwz r31,28(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831b1720
	if (!cr6.eq) goto loc_831B1720;
	// lwz r11,40(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b1714
	if (cr6.eq) goto loc_831B1714;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831b1714
	if (cr6.eq) goto loc_831B1714;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B16B4:
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x831b16fc
	if (!cr6.eq) goto loc_831B16FC;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b1734
	if (cr0.eq) goto loc_831B1734;
	// rotlwi r10,r10,0
	ctx.r10.u64 = rotl32(ctx.r10.u32, 0);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x831b1734
	if (!cr6.eq) goto loc_831B1734;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x831b16fc
	if (!cr6.eq) goto loc_831B16FC;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// ble cr6,0x831b16fc
	if (!cr6.gt) goto loc_831B16FC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// add r31,r11,r10
	r31.u64 = r11.u64 + ctx.r10.u64;
loc_831B16FC:
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b1714
	if (cr6.eq) goto loc_831B1714;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831b1740
	if (!cr6.eq) goto loc_831B1740;
loc_831B1714:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// bne cr6,0x831b16b4
	if (!cr6.eq) goto loc_831B16B4;
loc_831B1720:
	// cmplwi cr6,r31,32767
	cr6.compare<uint32_t>(r31.u32, 32767, xer);
	// ble cr6,0x831b174c
	if (!cr6.gt) goto loc_831B174C;
	// li r4,3519
	ctx.r4.s64 = 3519;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1734:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1740:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B174C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831b1774
	if (cr6.eq) goto loc_831B1774;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,20(r28)
	PPC_STORE_U32(r28.u32 + 20, r11.u32);
	// mulli r4,r11,40
	ctx.r4.s64 = r11.s64 * 40;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// stw r3,12(r28)
	PPC_STORE_U32(r28.u32 + 12, ctx.r3.u32);
	// stw r31,16(r28)
	PPC_STORE_U32(r28.u32 + 16, r31.u32);
loc_831B1774:
	// lwz r11,40(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b18f8
	if (cr6.eq) goto loc_831B18F8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831b18f8
	if (cr6.eq) goto loc_831B18F8;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B1798:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x831b18e0
	if (!cr6.eq) goto loc_831B18E0;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b19d4
	if (cr0.eq) goto loc_831B19D4;
	// rotlwi r10,r10,0
	ctx.r10.u64 = rotl32(ctx.r10.u32, 0);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x831b19d4
	if (!cr6.eq) goto loc_831B19D4;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x831b18e0
	if (!cr6.eq) goto loc_831B18E0;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// bne cr6,0x831b18e0
	if (!cr6.eq) goto loc_831B18E0;
	// lwz r31,68(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// b 0x831b182c
	goto loc_831B182C;
loc_831B17DC:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831b17f4
	if (!cr6.eq) goto loc_831B17F4;
	// mr r30,r31
	r30.u64 = r31.u64;
	// li r31,0
	r31.s64 = 0;
	// b 0x831b1818
	goto loc_831B1818;
loc_831B17F4:
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831b19c8
	if (!cr6.eq) goto loc_831B19C8;
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831b19bc
	if (cr6.eq) goto loc_831B19BC;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831b19bc
	if (!cr6.eq) goto loc_831B19BC;
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_831B1818:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83195b00
	sub_83195B00(ctx, base);
	// cmpwi cr6,r3,15
	cr6.compare<int32_t>(ctx.r3.s32, 15, xer);
	// beq cr6,0x831b1838
	if (cr6.eq) goto loc_831B1838;
loc_831B182C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831b17dc
	if (!cr6.eq) goto loc_831B17DC;
	// b 0x831b18e0
	goto loc_831B18E0;
loc_831B1838:
	// addi r5,r28,800
	ctx.r5.s64 = r28.s64 + 800;
	// lwz r4,20(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831952a8
	sub_831952A8(ctx, base);
	// lwz r10,800(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 800);
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// blt cr6,0x831b19a8
	if (cr6.lt) goto loc_831B19A8;
	// cmplwi cr6,r7,32
	cr6.compare<uint32_t>(ctx.r7.u32, 32, xer);
	// bge cr6,0x831b19a8
	if (!cr6.lt) goto loc_831B19A8;
	// subf r9,r10,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r10.s64;
	// lwz r11,56(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 56);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r9,804(r28)
	PPC_STORE_U32(r28.u32 + 804, ctx.r9.u32);
	// beq cr6,0x831b18e0
	if (cr6.eq) goto loc_831B18E0;
	// lwz r8,36(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x831b1894
	if (!cr6.eq) goto loc_831B1894;
	// lwz r7,44(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x831b18e0
	if (cr6.eq) goto loc_831B18E0;
loc_831B1894:
	// lwz r7,48(r28)
	ctx.r7.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// lis r6,-1
	ctx.r6.s64 = -65536;
	// rlwinm r7,r7,0,0,15
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// bne cr6,0x831b18bc
	if (!cr6.eq) goto loc_831B18BC;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x831b18d4
	if (!cr6.eq) goto loc_831B18D4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// b 0x831b18d0
	goto loc_831B18D0;
loc_831B18BC:
	// lwz r8,40(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x831b18d4
	if (!cr6.eq) goto loc_831B18D4;
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
loc_831B18D0:
	// beq cr6,0x831b18e0
	if (cr6.eq) goto loc_831B18E0;
loc_831B18D4:
	// li r4,3582
	ctx.r4.s64 = 3582;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
loc_831B18E0:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b18f8
	if (cr6.eq) goto loc_831B18F8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831b19e0
	if (!cr6.eq) goto loc_831B19E0;
loc_831B18F8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r29,r11
	r29.u64 = r11.u64;
	// bne cr6,0x831b1798
	if (!cr6.eq) goto loc_831B1798;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// addi r11,r3,4
	r11.s64 = ctx.r3.s64 + 4;
	// ori r10,r3,1
	ctx.r10.u64 = ctx.r3.u64 | 1;
	// stw r3,576(r28)
	PPC_STORE_U32(r28.u32 + 576, ctx.r3.u32);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// li r5,4
	ctx.r5.s64 = 4;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// addi r11,r3,4
	r11.s64 = ctx.r3.s64 + 4;
	// ori r10,r3,1
	ctx.r10.u64 = ctx.r3.u64 | 1;
	// stw r3,580(r28)
	PPC_STORE_U32(r28.u32 + 580, ctx.r3.u32);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// li r24,0
	r24.s64 = 0;
	// li r22,0
	r22.s64 = 0;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r23,r26,4
	r23.s64 = r26.s64 + 4;
	// ori r11,r26,1
	r11.u64 = r26.u64 | 1;
	// ori r10,r23,1
	ctx.r10.u64 = r23.u64 | 1;
	// stw r11,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r11.u32);
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// lwz r11,40(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b19ec
	if (cr6.eq) goto loc_831B19EC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x831b19ec
	if (cr6.eq) goto loc_831B19EC;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B19A8:
	// li r5,31
	ctx.r5.s64 = 31;
	// lwz r6,800(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 800);
	// li r4,3590
	ctx.r4.s64 = 3590;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B19BC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B19C8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B19D4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B19E0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B19EC:
	// mr r25,r11
	r25.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b1f24
	if (cr6.eq) goto loc_831B1F24;
loc_831B19F8:
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// b 0x831b1cd4
	goto loc_831B1CD4;
loc_831B1A04:
	// lwz r27,8(r25)
	r27.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x831b21a0
	if (cr6.eq) goto loc_831B21A0;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x831b21a0
	if (!cr6.eq) goto loc_831B21A0;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x831b1e10
	if (cr6.eq) goto loc_831B1E10;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x831b1e04
	if (cr6.eq) goto loc_831B1E04;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x831b1cf4
	if (cr6.eq) goto loc_831B1CF4;
	// ble cr6,0x831b2158
	if (!cr6.gt) goto loc_831B2158;
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// ble cr6,0x831b1e10
	if (!cr6.gt) goto loc_831B1E10;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// ble cr6,0x831b2158
	if (!cr6.gt) goto loc_831B2158;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bgt cr6,0x831b2158
	if (cr6.gt) goto loc_831B2158;
	// lwz r29,32(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x831b214c
	if (cr6.eq) goto loc_831B214C;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// bne cr6,0x831b214c
	if (!cr6.eq) goto loc_831B214C;
	// lwz r31,20(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831b20c0
	if (cr6.eq) goto loc_831B20C0;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x831b2140
	if (!cr6.eq) goto loc_831B2140;
	// lwz r5,24(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831b1ad8
	if (cr6.eq) goto loc_831B1AD8;
loc_831B1A94:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
loc_831B1AA0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r9,r7,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r7.s64;
	// beq 0x831b1ac4
	if (cr0.eq) goto loc_831B1AC4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x831b1aa0
	if (cr6.eq) goto loc_831B1AA0;
loc_831B1AC4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x831b20cc
	if (cr0.eq) goto loc_831B20CC;
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x831b1a94
	if (!cr6.eq) goto loc_831B1A94;
loc_831B1AD8:
	// li r5,7
	ctx.r5.s64 = 7;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83110128
	sub_83110128(ctx, base);
	// stw r24,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r24.u32);
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// li r30,0
	r30.s64 = 0;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// lwz r4,36(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 36);
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bne cr6,0x831b1be4
	if (!cr6.eq) goto loc_831B1BE4;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319fdc0
	sub_8319FDC0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x831b1bd4
	if (cr0.eq) goto loc_831B1BD4;
loc_831B1B24:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831b2108
	if (cr6.eq) goto loc_831B2108;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831b2108
	if (!cr6.eq) goto loc_831B2108;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83195b00
	sub_83195B00(ctx, base);
	// cmpwi cr6,r3,18
	cr6.compare<int32_t>(ctx.r3.s32, 18, xer);
	// beq cr6,0x831b1b84
	if (cr6.eq) goto loc_831B1B84;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b20ec
	if (cr6.eq) goto loc_831B20EC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x831b20ec
	if (!cr6.eq) goto loc_831B20EC;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x831b20e4
	if (!cr6.eq) goto loc_831B20E4;
	// li r4,3606
	ctx.r4.s64 = 3606;
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x830fd220
	sub_830FD220(ctx, base);
	// b 0x831b1bbc
	goto loc_831B1BBC;
loc_831B1B84:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831b1b98
	if (cr6.eq) goto loc_831B1B98;
	// li r4,3577
	ctx.r4.s64 = 3577;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd220
	sub_830FD220(ctx, base);
loc_831B1B98:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// bl 0x83195220
	sub_83195220(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// blt cr6,0x831b20f8
	if (cr6.lt) goto loc_831B20F8;
	// lis r11,1
	r11.s64 = 65536;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bge cr6,0x831b20f8
	if (!cr6.lt) goto loc_831B20F8;
loc_831B1BBC:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x831b1b24
	if (!cr0.eq) goto loc_831B1B24;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831b1bd8
	if (!cr6.eq) goto loc_831B1BD8;
loc_831B1BD4:
	// mr r30,r29
	r30.u64 = r29.u64;
loc_831B1BD8:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// b 0x831b1c54
	goto loc_831B1C54;
loc_831B1BE4:
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x8319fdc0
	sub_8319FDC0(ctx, base);
	// b 0x831b1c38
	goto loc_831B1C38;
loc_831B1BF0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x831b2128
	if (cr6.eq) goto loc_831B2128;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831b2128
	if (!cr6.eq) goto loc_831B2128;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b211c
	if (cr6.eq) goto loc_831B211C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x831b211c
	if (!cr6.eq) goto loc_831B211C;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x831b2114
	if (!cr6.eq) goto loc_831B2114;
	// li r4,3606
	ctx.r4.s64 = 3606;
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x830fd220
	sub_830FD220(ctx, base);
loc_831B1C38:
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x8319fe80
	sub_8319FE80(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x831b1bf0
	if (!cr0.eq) goto loc_831B1BF0;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r30,r27
	r30.u64 = r27.u64;
	// lwz r9,92(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
loc_831B1C54:
	// addi r10,r11,972
	ctx.r10.s64 = r11.s64 + 972;
	// lwz r10,976(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 976);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// stw r9,976(r11)
	PPC_STORE_U32(r11.u32 + 976, ctx.r9.u32);
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b1e10
	if (cr6.eq) goto loc_831B1E10;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8319fcd0
	sub_8319FCD0(ctx, base);
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// lwz r11,596(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 596);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r30,596(r28)
	PPC_STORE_U32(r28.u32 + 596, r30.u32);
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x831b1cb0
	if (!cr6.eq) goto loc_831B1CB0;
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// li r22,1
	r22.s64 = 1;
	// ori r11,r11,2048
	r11.u64 = r11.u64 | 2048;
	// stw r11,44(r28)
	PPC_STORE_U32(r28.u32 + 44, r11.u32);
loc_831B1CB0:
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b2134
	if (cr6.eq) goto loc_831B2134;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831b2134
	if (!cr6.eq) goto loc_831B2134;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r25,r11
	r25.u64 = r11.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
loc_831B1CD4:
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x831b1a04
	if (cr6.eq) goto loc_831B1A04;
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// bne cr6,0x831b20b4
	if (!cr6.eq) goto loc_831B20B4;
	// lwz r11,40(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 40);
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// stw r11,40(r28)
	PPC_STORE_U32(r28.u32 + 40, r11.u32);
	// b 0x831b1e10
	goto loc_831B1E10;
loc_831B1CF4:
	// lwz r31,24(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831b217c
	if (cr6.eq) goto loc_831B217C;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// bne cr6,0x831b217c
	if (!cr6.eq) goto loc_831B217C;
	// lwz r11,568(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 568);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b1d38
	if (cr6.eq) goto loc_831B1D38;
	// lwz r10,40(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 40);
loc_831B1D1C:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r9,40(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 40);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x831b1d98
	if (cr6.eq) goto loc_831B1D98;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b1d1c
	if (!cr6.eq) goto loc_831B1D1C;
loc_831B1D38:
	// li r30,0
	r30.s64 = 0;
loc_831B1D3C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x831b1d64
	if (!cr6.eq) goto loc_831B1D64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,28
	ctx.r4.s64 = 28;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83137570
	sub_83137570(ctx, base);
	// lwz r11,568(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 568);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// stw r30,568(r28)
	PPC_STORE_U32(r28.u32 + 568, r30.u32);
loc_831B1D64:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b1d7c
	if (cr6.eq) goto loc_831B1D7C;
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b1d84
	if (!cr6.eq) goto loc_831B1D84;
loc_831B1D7C:
	// stw r27,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r27.u32);
	// stw r31,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r31.u32);
loc_831B1D84:
	// cmplw cr6,r21,r31
	cr6.compare<uint32_t>(r21.u32, r31.u32, xer);
	// bne cr6,0x831b1d90
	if (!cr6.eq) goto loc_831B1D90;
	// mr r19,r30
	r19.u64 = r30.u64;
loc_831B1D90:
	// lwz r31,68(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// b 0x831b1df8
	goto loc_831B1DF8;
loc_831B1D98:
	// mr r30,r11
	r30.u64 = r11.u64;
	// b 0x831b1d3c
	goto loc_831B1D3C;
loc_831B1DA0:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831b1db8
	if (!cr6.eq) goto loc_831B1DB8;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// li r31,0
	r31.s64 = 0;
	// b 0x831b1ddc
	goto loc_831B1DDC;
loc_831B1DB8:
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x831b2170
	if (!cr6.eq) goto loc_831B2170;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x831b2164
	if (cr6.eq) goto loc_831B2164;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x831b2164
	if (!cr6.eq) goto loc_831B2164;
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_831B1DDC:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83195b00
	sub_83195B00(ctx, base);
	// cmpwi cr6,r3,11
	cr6.compare<int32_t>(ctx.r3.s32, 11, xer);
	// bne cr6,0x831b1df8
	if (!cr6.eq) goto loc_831B1DF8;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// oris r11,r11,16384
	r11.u64 = r11.u64 | 1073741824;
	// stw r11,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r11.u32);
loc_831B1DF8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x831b1da0
	if (!cr6.eq) goto loc_831B1DA0;
	// b 0x831b1e10
	goto loc_831B1E10;
loc_831B1E04:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831a3ae8
	sub_831A3AE8(ctx, base);
loc_831B1E10:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b1e28
	if (cr6.eq) goto loc_831B1E28;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831b2188
	if (!cr6.eq) goto loc_831B2188;
loc_831B1E28:
	// mr r25,r11
	r25.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b19f8
	if (!cr6.eq) goto loc_831B19F8;
loc_831B1E34:
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b1f10
	if (!cr0.eq) goto loc_831B1F10;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b1f10
	if (cr0.eq) goto loc_831B1F10;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mulli r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 * 12;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r10,596(r28)
	PPC_STORE_U32(r28.u32 + 596, ctx.r10.u32);
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831b1e80
	if (cr6.eq) goto loc_831B1E80;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x831b2194
	if (!cr6.eq) goto loc_831B2194;
loc_831B1E80:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r25,r31
	r25.u64 = r31.u64;
	// rlwinm. r11,r11,0,20,20
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b1e9c
	if (!cr0.eq) goto loc_831B1E9C;
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// rlwinm r11,r11,0,21,19
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFF7FF;
	// stw r11,44(r28)
	PPC_STORE_U32(r28.u32 + 44, r11.u32);
loc_831B1E9C:
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b1eb0
	if (cr0.eq) goto loc_831B1EB0;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x831b1ebc
	goto loc_831B1EBC;
loc_831B1EB0:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
loc_831B1EBC:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// bne 0x831b1f04
	if (!cr0.eq) goto loc_831B1F04;
	// rlwinm r11,r4,0,0,30
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,30
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// bl 0x830fd2b8
	sub_830FD2B8(ctx, base);
loc_831B1F04:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831b1e34
	if (cr6.eq) goto loc_831B1E34;
	// b 0x831b19f8
	goto loc_831B19F8;
loc_831B1F10:
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// rlwinm r11,r11,0,21,19
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFF7FF;
	// stw r11,44(r28)
	PPC_STORE_U32(r28.u32 + 44, r11.u32);
	// bne cr6,0x831b19f8
	if (!cr6.eq) goto loc_831B19F8;
loc_831B1F24:
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831ada08
	sub_831ADA08(ctx, base);
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b2274
	if (cr0.eq) goto loc_831B2274;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// li r21,0
	r21.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x831b2274
	if (!cr6.gt) goto loc_831B2274;
	// li r20,0
	r20.s64 = 0;
loc_831B1F4C:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// add r22,r20,r11
	r22.u64 = r20.u64 + r11.u64;
	// lwz r10,4(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 4);
	// rlwinm. r10,r10,0,0,0
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831b2260
	if (cr0.eq) goto loc_831B2260;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x831b1f98
	if (cr6.eq) goto loc_831B1F98;
	// lwz r9,36(r22)
	ctx.r9.u64 = PPC_LOAD_U32(r22.u32 + 36);
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
loc_831B1F74:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x831b1f90
	if (cr6.eq) goto loc_831B1F90;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,40
	r11.s64 = r11.s64 + 40;
	// cmplw cr6,r10,r21
	cr6.compare<uint32_t>(ctx.r10.u32, r21.u32, xer);
	// blt cr6,0x831b1f74
	if (cr6.lt) goto loc_831B1F74;
loc_831B1F90:
	// cmplw cr6,r10,r21
	cr6.compare<uint32_t>(ctx.r10.u32, r21.u32, xer);
	// blt cr6,0x831b2260
	if (cr6.lt) goto loc_831B2260;
loc_831B1F98:
	// lwz r10,28(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 28);
	// addi r11,r21,1
	r11.s64 = r21.s64 + 1;
	// lwz r9,16(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// li r27,1
	r27.s64 = 1;
	// mr r23,r11
	r23.u64 = r11.u64;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r26,r11,28,18,31
	r26.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0x3FFF;
	// bge cr6,0x831b2260
	if (!cr6.lt) goto loc_831B2260;
	// addi r24,r20,40
	r24.s64 = r20.s64 + 40;
loc_831B1FC0:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// lwz r10,36(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 36);
	// add r30,r11,r24
	r30.u64 = r11.u64 + r24.u64;
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x831b224c
	if (!cr6.eq) goto loc_831B224C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// rlwinm r31,r11,29,18,31
	r31.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// rlwinm r25,r31,2,0,29
	r25.u64 = rotl64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x83110880
	sub_83110880(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x831b2028
	if (cr6.eq) goto loc_831B2028;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// mr r11,r31
	r11.u64 = r31.u64;
loc_831B200C:
	// lwz r8,28(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 + ctx.r8.u64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x831b200c
	if (!cr0.eq) goto loc_831B200C;
loc_831B2028:
	// lis r11,-31975
	r11.s64 = -2095513600;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r6,r11,23536
	ctx.r6.s64 = r11.s64 + 23536;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82ca5868
	sub_82CA5868(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// rlwinm. r11,r11,0,15,28
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x1FFF8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b222c
	if (cr0.eq) goto loc_831B222C;
loc_831B2050:
	// rlwinm r11,r8,2,0,29
	r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// cmplw cr6,r8,r31
	cr6.compare<uint32_t>(ctx.r8.u32, r31.u32, xer);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bge cr6,0x831b2098
	if (!cr6.lt) goto loc_831B2098;
	// lwz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// rlwinm r6,r6,28,18,31
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 28) & 0x3FFF;
loc_831B2074:
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r5,0(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm r5,r5,28,18,31
	ctx.r5.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 28) & 0x3FFF;
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// bne cr6,0x831b2098
	if (!cr6.eq) goto loc_831B2098;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r7,r31
	cr6.compare<uint32_t>(ctx.r7.u32, r31.u32, xer);
	// blt cr6,0x831b2074
	if (cr6.lt) goto loc_831B2074;
loc_831B2098:
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// subf r6,r8,r7
	ctx.r6.s64 = ctx.r7.s64 - ctx.r8.s64;
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x831b21ac
	if (cr0.eq) goto loc_831B21AC;
	// cmplwi cr6,r27,1
	cr6.compare<uint32_t>(r27.u32, 1, xer);
	// beq cr6,0x831b21c0
	if (cr6.eq) goto loc_831B21C0;
	// b 0x831b21b8
	goto loc_831B21B8;
loc_831B20B4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B20C0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B20CC:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// li r4,3610
	ctx.r4.s64 = 3610;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r7,36(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// lwz r6,32(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B20E4:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B20EC:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B20F8:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,3611
	ctx.r4.s64 = 3611;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2108:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2114:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B211C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2128:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2134:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2140:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B214C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2158:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2164:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2170:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B217C:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2188:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2194:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B21A0:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B21AC:
	// slw r10,r27,r6
	ctx.r10.u64 = ctx.r6.u8 & 0x20 ? 0 : (r27.u32 << (ctx.r6.u8 & 0x3F));
	// cmplwi cr6,r10,16
	cr6.compare<uint32_t>(ctx.r10.u32, 16, xer);
	// ble cr6,0x831b21c0
	if (!cr6.gt) goto loc_831B21C0;
loc_831B21B8:
	// li r27,1
	r27.s64 = 1;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
loc_831B21C0:
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bge cr6,0x831b2208
	if (!cr6.lt) goto loc_831B2208;
	// rlwinm r9,r26,4,14,27
	ctx.r9.u64 = rotl64(r26.u32 | (r26.u64 << 32), 4) & 0x3FFF0;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
loc_831B21D0:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r27,r27,1,0,30
	r27.u64 = rotl64(r27.u32 | (r27.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r4,0(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r4,r4,0,28,13
	ctx.r4.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFFFFFC000F;
	// or r4,r4,r9
	ctx.r4.u64 = ctx.r4.u64 | ctx.r9.u64;
	// stw r4,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r4.u32);
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r4,0(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwimi r5,r4,0,0,27
	ctx.r5.u64 = (rotl32(ctx.r4.u32, 0) & 0xFFFFFFF0) | (ctx.r5.u64 & 0xFFFFFFFF0000000F);
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
	// bne 0x831b21d0
	if (!cr0.eq) goto loc_831B21D0;
loc_831B2208:
	// cmplwi cr6,r27,15
	cr6.compare<uint32_t>(r27.u32, 15, xer);
	// ble cr6,0x831b2218
	if (!cr6.gt) goto loc_831B2218;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// li r27,1
	r27.s64 = 1;
loc_831B2218:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// add r8,r6,r8
	ctx.r8.u64 = ctx.r6.u64 + ctx.r8.u64;
	// rlwinm r11,r11,29,18,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 29) & 0x3FFF;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x831b2050
	if (cr6.lt) goto loc_831B2050;
loc_831B222C:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x83118478
	sub_83118478(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// oris r11,r11,16384
	r11.u64 = r11.u64 | 1073741824;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_831B224C:
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r24,r24,40
	r24.s64 = r24.s64 + 40;
	// cmplw cr6,r23,r11
	cr6.compare<uint32_t>(r23.u32, r11.u32, xer);
	// blt cr6,0x831b1fc0
	if (cr6.lt) goto loc_831B1FC0;
loc_831B2260:
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r20,r20,40
	r20.s64 = r20.s64 + 40;
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// blt cr6,0x831b1f4c
	if (cr6.lt) goto loc_831B1F4C;
loc_831B2274:
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	return;
loc_831B2280:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831B1648) {
	__imp__sub_831B1648(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_831B2290) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb8
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r11,4138
	r11.s64 = 271187968;
	// rlwinm r10,r9,0,0,23
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFF00;
	// ori r11,r11,4352
	r11.u64 = r11.u64 | 4352;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x831b22e0
	if (cr6.eq) goto loc_831B22E0;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B22E0:
	// lwz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// li r26,0
	r26.s64 = 0;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// add r20,r10,r3
	r20.u64 = ctx.r10.u64 + ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b2300
	if (cr6.eq) goto loc_831B2300;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r26,r11,4
	r26.s64 = r11.s64 + 4;
loc_831B2300:
	// clrlwi r11,r9,31
	r11.u64 = ctx.r9.u32 & 0x1;
	// lis r18,-1
	r18.s64 = -65536;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x831b231c
	if (!cr6.eq) goto loc_831B231C;
	// lis r11,-2
	r11.s64 = -131072;
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// b 0x831b2320
	goto loc_831B2320;
loc_831B231C:
	// stw r18,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r18.u32);
loc_831B2320:
	// lwz r11,12(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm. r11,r11,0,30,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b2340
	if (cr0.eq) goto loc_831B2340;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,4012
	ctx.r5.s64 = r11.s64 + 4012;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2340:
	// lwz r11,8(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b235c
	if (cr0.eq) goto loc_831B235C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r4,3500
	ctx.r4.s64 = 3500;
	// addi r5,r11,4000
	ctx.r5.s64 = r11.s64 + 4000;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B235C:
	// li r5,11
	ctx.r5.s64 = 11;
	// li r4,80
	ctx.r4.s64 = 80;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x83048308
	sub_83048308(ctx, base);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// li r11,10
	r11.s64 = 10;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r11,4(r19)
	PPC_STORE_U32(r19.u32 + 4, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r21,r19,48
	r21.s64 = r19.s64 + 48;
	// stw r10,0(r19)
	PPC_STORE_U32(r19.u32 + 0, ctx.r10.u32);
	// bl 0x83196468
	sub_83196468(ctx, base);
	// stw r3,48(r19)
	PPC_STORE_U32(r19.u32 + 48, ctx.r3.u32);
	// li r5,13
	ctx.r5.s64 = 13;
	// li r4,44
	ctx.r4.s64 = 44;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831181d0
	sub_831181D0(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r3.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83046e68
	sub_83046E68(ctx, base);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lis r9,-32251
	ctx.r9.s64 = -2113601536;
	// addi r5,r10,3984
	ctx.r5.s64 = ctx.r10.s64 + 3984;
	// addi r28,r9,20620
	r28.s64 = ctx.r9.s64 + 20620;
	// li r11,4
	r11.s64 = 4;
	// li r30,727
	r30.s64 = 727;
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r30,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r30.u32);
	// bl 0x83195e78
	sub_83195E78(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// bl 0x83195ee0
	sub_83195EE0(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,29080
	ctx.r4.s64 = 29080;
	// stw r3,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r3.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// bl 0x83137570
	sub_83137570(ctx, base);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lis r10,-31974
	ctx.r10.s64 = -2095448064;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r30,r10,-20312
	r30.s64 = ctx.r10.s64 + -20312;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x82b983d8
	sub_82B983D8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x831b246c
	if (!cr0.lt) goto loc_831B246C;
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B246C:
	// li r17,1
	r17.s64 = 1;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x831b2650
	if (cr6.eq) goto loc_831B2650;
	// lwz r24,12(r26)
	r24.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x831b2650
	if (cr6.eq) goto loc_831B2650;
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// add r29,r11,r26
	r29.u64 = r11.u64 + r26.u64;
	// beq cr6,0x831b2650
	if (cr6.eq) goto loc_831B2650;
	// lis r11,-32244
	r11.s64 = -2113142784;
	// li r22,2
	r22.s64 = 2;
	// addi r23,r11,23124
	r23.s64 = r11.s64 + 23124;
loc_831B24A4:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lhz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U16(r29.u32 + 4);
	// add r28,r11,r26
	r28.u64 = r11.u64 + r26.u64;
	// lhz r11,6(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 6);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// blt cr6,0x831b2510
	if (cr6.lt) goto loc_831B2510;
	// beq cr6,0x831b24ec
	if (cr6.eq) goto loc_831B24EC;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// blt cr6,0x831b24dc
	if (cr6.lt) goto loc_831B24DC;
	// bne cr6,0x831b2868
	if (!cr6.eq) goto loc_831B2868;
	// addi r5,r11,688
	ctx.r5.s64 = r11.s64 + 688;
	// li r7,33
	ctx.r7.s64 = 33;
	// li r27,115
	r27.s64 = 115;
	// b 0x831b2530
	goto loc_831B2530;
loc_831B24DC:
	// addi r5,r11,64
	ctx.r5.s64 = r11.s64 + 64;
	// li r7,12
	ctx.r7.s64 = 12;
	// li r27,99
	r27.s64 = 99;
	// b 0x831b2530
	goto loc_831B2530;
loc_831B24EC:
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r10,r10,0,0,15
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r10,r18
	cr6.compare<uint32_t>(ctx.r10.u32, r18.u32, xer);
	// bne cr6,0x831b2500
	if (!cr6.eq) goto loc_831B2500;
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
loc_831B2500:
	// addi r5,r11,320
	ctx.r5.s64 = r11.s64 + 320;
	// li r7,5
	ctx.r7.s64 = 5;
	// li r27,105
	r27.s64 = 105;
	// b 0x831b2530
	goto loc_831B2530;
loc_831B2510:
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r10,r10,0,0,15
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r10,r18
	cr6.compare<uint32_t>(ctx.r10.u32, r18.u32, xer);
	// bne cr6,0x831b2524
	if (!cr6.eq) goto loc_831B2524;
	// addi r11,r11,128
	r11.s64 = r11.s64 + 128;
loc_831B2524:
	// addi r5,r11,352
	ctx.r5.s64 = r11.s64 + 352;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r27,98
	r27.s64 = 98;
loc_831B2530:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r4,r11,r26
	ctx.r4.u64 = r11.u64 + r26.u64;
	// lhz r8,8(r28)
	ctx.r8.u64 = PPC_LOAD_U16(r28.u32 + 8);
	// lhz r11,4(r28)
	r11.u64 = PPC_LOAD_U16(r28.u32 + 4);
	// addi r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 + 40;
	// lhz r9,6(r28)
	ctx.r9.u64 = PPC_LOAD_U16(r28.u32 + 6);
	// mullw r8,r8,r11
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(r11.s32);
	// lhz r6,8(r29)
	ctx.r6.u64 = PPC_LOAD_U16(r29.u32 + 8);
	// bl 0x83199ed0
	sub_83199ED0(ctx, base);
	// lwz r30,24(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831b2880
	if (cr6.eq) goto loc_831B2880;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x831b2880
	if (!cr6.eq) goto loc_831B2880;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b25a8
	if (cr6.eq) goto loc_831B25A8;
	// lwz r16,20(r30)
	r16.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// add r4,r11,r26
	ctx.r4.u64 = r11.u64 + r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// bl 0x83195f38
	sub_83195F38(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// bl 0x83196038
	sub_83196038(ctx, base);
	// stw r3,56(r30)
	PPC_STORE_U32(r30.u32 + 56, ctx.r3.u32);
loc_831B25A8:
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b2874
	if (cr6.eq) goto loc_831B2874;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x831b2874
	if (!cr6.eq) goto loc_831B2874;
	// lhz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U16(r28.u32 + 0);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// blt cr6,0x831b2610
	if (cr6.lt) goto loc_831B2610;
	// beq cr6,0x831b2608
	if (cr6.eq) goto loc_831B2608;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// blt cr6,0x831b2600
	if (cr6.lt) goto loc_831B2600;
	// beq cr6,0x831b25ec
	if (cr6.eq) goto loc_831B25EC;
	// cmplwi cr6,r10,5
	cr6.compare<uint32_t>(ctx.r10.u32, 5, xer);
	// bge cr6,0x831b2618
	if (!cr6.lt) goto loc_831B2618;
	// li r10,3
	ctx.r10.s64 = 3;
	// b 0x831b2614
	goto loc_831B2614;
loc_831B25EC:
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// stw r22,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r22.u32);
	// rlwimi r10,r17,11,20,21
	ctx.r10.u64 = (rotl32(r17.u32, 11) & 0xC00) | (ctx.r10.u64 & 0xFFFFFFFFFFFFF3FF);
	// stw r10,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r10.u32);
	// b 0x831b2618
	goto loc_831B2618;
loc_831B2600:
	// stw r22,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r22.u32);
	// b 0x831b2618
	goto loc_831B2618;
loc_831B2608:
	// stw r17,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r17.u32);
	// b 0x831b2618
	goto loc_831B2618;
loc_831B2610:
	// li r10,0
	ctx.r10.s64 = 0;
loc_831B2614:
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
loc_831B2618:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lhz r5,6(r29)
	ctx.r5.u64 = PPC_LOAD_U16(r29.u32 + 6);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831999b0
	sub_831999B0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// bl 0x83195ee0
	sub_83195EE0(ctx, base);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// stw r3,64(r30)
	PPC_STORE_U32(r30.u32 + 64, ctx.r3.u32);
	// addi r29,r29,20
	r29.s64 = r29.s64 + 20;
	// cmplw cr6,r25,r24
	cr6.compare<uint32_t>(r25.u32, r24.u32, xer);
	// blt cr6,0x831b24a4
	if (cr6.lt) goto loc_831B24A4;
loc_831B2650:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// lwz r11,8(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// rlwinm r29,r11,24,26,31
	r29.u64 = rotl64(r11.u32 | (r11.u64 << 32), 24) & 0x3F;
	// beq cr6,0x831b266c
	if (cr6.eq) goto loc_831B266C;
	// clrlwi r29,r11,26
	r29.u64 = r11.u32 & 0x3F;
loc_831B266C:
	// li r30,0
	r30.s64 = 0;
loc_831B2670:
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,12
	ctx.r7.s64 = 12;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199ed0
	sub_83199ED0(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// ble cr6,0x831b2670
	if (!cr6.gt) goto loc_831B2670;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// li r9,1
	ctx.r9.s64 = 1;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,12
	ctx.r7.s64 = 12;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,723
	ctx.r5.s64 = 723;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x83199ed0
	sub_83199ED0(ctx, base);
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// bne cr6,0x831b2728
	if (!cr6.eq) goto loc_831B2728;
	// lwz r11,20(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 20);
	// addi r29,r20,32
	r29.s64 = r20.s64 + 32;
	// li r30,0
	r30.s64 = 0;
	// rlwinm. r28,r11,27,27,31
	r28.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1F;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x831b2728
	if (cr0.eq) goto loc_831B2728;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r26,r19,44
	r26.s64 = r19.s64 + 44;
	// addi r27,r11,3948
	r27.s64 = r11.s64 + 3948;
loc_831B26F4:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// clrlwi r7,r11,24
	ctx.r7.u64 = r11.u32 & 0xFF;
	// rlwinm r6,r11,20,28,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319a088
	sub_8319A088(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// blt cr6,0x831b26f4
	if (cr6.lt) goto loc_831B26F4;
loc_831B2728:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// beq cr6,0x831b278c
	if (cr6.eq) goto loc_831B278C;
	// lwz r28,24(r20)
	r28.u64 = PPC_LOAD_U32(r20.u32 + 24);
	// addi r29,r20,36
	r29.s64 = r20.s64 + 36;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x831b278c
	if (cr6.eq) goto loc_831B278C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r26,r19,44
	r26.s64 = r19.s64 + 44;
	// addi r27,r11,3924
	r27.s64 = r11.s64 + 3924;
loc_831B2758:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// clrlwi r7,r11,24
	ctx.r7.u64 = r11.u32 & 0xFF;
	// rlwinm r6,r11,23,28,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 23) & 0xF;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319a088
	sub_8319A088(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// blt cr6,0x831b2758
	if (cr6.lt) goto loc_831B2758;
loc_831B278C:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// beq cr6,0x831b2804
	if (cr6.eq) goto loc_831B2804;
	// lwz r10,28(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 28);
	// li r30,0
	r30.s64 = 0;
	// lwz r11,24(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 24);
	// lwz r9,20(r20)
	ctx.r9.u64 = PPC_LOAD_U32(r20.u32 + 20);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// rlwinm. r28,r9,27,27,31
	r28.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1F;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r11,r11,9
	r11.s64 = r11.s64 + 9;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r29,r11,r20
	r29.u64 = r11.u64 + r20.u64;
	// beq 0x831b2804
	if (cr0.eq) goto loc_831B2804;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r26,r19,44
	r26.s64 = r19.s64 + 44;
	// addi r27,r11,3888
	r27.s64 = r11.s64 + 3888;
loc_831B27D0:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// clrlwi r8,r11,28
	ctx.r8.u64 = r11.u32 & 0xF;
	// rlwinm r7,r11,28,28,31
	ctx.r7.u64 = rotl64(r11.u32 | (r11.u64 << 32), 28) & 0xF;
	// rlwinm r6,r11,20,28,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319a188
	sub_8319A188(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// blt cr6,0x831b27d0
	if (cr6.lt) goto loc_831B27D0;
loc_831B2804:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r11,r11,0,0,15
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// bne cr6,0x831b28b0
	if (!cr6.eq) goto loc_831B28B0;
	// lwz r11,28(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 28);
	// clrlwi r30,r11,28
	r30.u64 = r11.u32 & 0xF;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r29,r11,3860
	r29.s64 = r11.s64 + 3860;
loc_831B2824:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831b288c
	if (cr6.eq) goto loc_831B288C;
	// addi r11,r30,-1
	r11.s64 = r30.s64 + -1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// andc r11,r30,r11
	r11.u64 = r30.u64 & ~r11.u64;
	// addi r9,r19,44
	ctx.r9.s64 = r19.s64 + 44;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// li r7,10
	ctx.r7.s64 = 10;
	// subfic r8,r11,31
	xer.ca = r11.u32 <= 31;
	ctx.r8.s64 = 31 - r11.s64;
	// li r6,15
	ctx.r6.s64 = 15;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r8
	ctx.r5.u64 = ctx.r8.u64;
	// bl 0x8319a188
	sub_8319A188(ctx, base);
	// addi r11,r30,-1
	r11.s64 = r30.s64 + -1;
	// andc r11,r30,r11
	r11.u64 = r30.u64 & ~r11.u64;
	// subf r30,r11,r30
	r30.s64 = r30.s64 - r11.s64;
	// b 0x831b2824
	goto loc_831B2824;
loc_831B2868:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2874:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B2880:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
loc_831B288C:
	// lwz r11,28(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 28);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b28d4
	if (cr0.eq) goto loc_831B28D4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r7,12
	ctx.r7.s64 = 12;
	// addi r4,r11,3832
	ctx.r4.s64 = r11.s64 + 3832;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,61
	ctx.r5.s64 = 61;
	// b 0x831b28c4
	goto loc_831B28C4;
loc_831B28B0:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r4,r11,3808
	ctx.r4.s64 = r11.s64 + 3808;
	// li r6,15
	ctx.r6.s64 = 15;
	// li r5,62
	ctx.r5.s64 = 62;
loc_831B28C4:
	// addi r9,r19,44
	ctx.r9.s64 = r19.s64 + 44;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8319a188
	sub_8319A188(ctx, base);
loc_831B28D4:
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831b1648
	sub_831B1648(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831ae2c8
	sub_831AE2C8(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b2a68
	if (!cr0.eq) goto loc_831B2A68;
	// mr r28,r11
	r28.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b2a68
	if (cr0.eq) goto loc_831B2A68;
loc_831B290C:
	// lwz r11,36(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 36);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b2a4c
	if (!cr0.eq) goto loc_831B2A4C;
	// lwz r11,32(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addic. r30,r11,-40
	xer.ca = r11.u32 > 39;
	r30.s64 = r11.s64 + -40;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x831b2a4c
	if (cr0.eq) goto loc_831B2A4C;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,25,25,31
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// cmplwi cr6,r11,86
	cr6.compare<uint32_t>(r11.u32, 86, xer);
	// beq cr6,0x831b2964
	if (cr6.eq) goto loc_831B2964;
	// cmplwi cr6,r11,87
	cr6.compare<uint32_t>(r11.u32, 87, xer);
	// beq cr6,0x831b2964
	if (cr6.eq) goto loc_831B2964;
	// cmplwi cr6,r11,89
	cr6.compare<uint32_t>(r11.u32, 89, xer);
	// beq cr6,0x831b2964
	if (cr6.eq) goto loc_831B2964;
	// cmplwi cr6,r11,90
	cr6.compare<uint32_t>(r11.u32, 90, xer);
	// beq cr6,0x831b2964
	if (cr6.eq) goto loc_831B2964;
	// cmplwi cr6,r11,84
	cr6.compare<uint32_t>(r11.u32, 84, xer);
	// beq cr6,0x831b2964
	if (cr6.eq) goto loc_831B2964;
	// cmplwi cr6,r11,85
	cr6.compare<uint32_t>(r11.u32, 85, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x831b2968
	if (!cr6.eq) goto loc_831B2968;
loc_831B2964:
	// mr r11,r17
	r11.u64 = r17.u64;
loc_831B2968:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x831b2a4c
	if (cr0.eq) goto loc_831B2A4C;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r6,r11,18,29,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 18) & 0x7;
	// rlwinm r5,r11,13,29,31
	ctx.r5.u64 = rotl64(r11.u32 | (r11.u64 << 32), 13) & 0x7;
	// rlwinm r4,r11,25,25,31
	ctx.r4.u64 = rotl64(r11.u32 | (r11.u64 << 32), 25) & 0x7F;
	// bl 0x8310fc68
	sub_8310FC68(ctx, base);
	// addi r10,r30,-16
	ctx.r10.s64 = r30.s64 + -16;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// add r29,r3,r10
	r29.u64 = ctx.r3.u64 + ctx.r10.u64;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// bne 0x831b2ad8
	if (!cr0.eq) goto loc_831B2AD8;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b2ad8
	if (cr0.eq) goto loc_831B2AD8;
loc_831B29B0:
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831b29e0
	if (!cr0.eq) goto loc_831B29E0;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b29e0
	if (cr0.eq) goto loc_831B29E0;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r9,r9,0,18,24
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r9,16128
	cr6.compare<uint32_t>(ctx.r9.u32, 16128, xer);
	// bne cr6,0x831b29e0
	if (!cr6.eq) goto loc_831B29E0;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x831b29fc
	if (cr6.eq) goto loc_831B29FC;
loc_831B29E0:
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x831b2ad8
	if (!cr0.eq) goto loc_831B2AD8;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b29b0
	if (!cr6.eq) goto loc_831B29B0;
loc_831B29FC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x831b2ad8
	if (cr6.eq) goto loc_831B2AD8;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
loc_831B2A08:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x831b2a2c
	if (cr6.eq) goto loc_831B2A2C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r30,r10
	cr6.compare<uint32_t>(r30.u32, ctx.r10.u32, xer);
	// beq cr6,0x831b2a24
	if (cr6.eq) goto loc_831B2A24;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x831b2a08
	goto loc_831B2A08;
loc_831B2A24:
	// mr r11,r17
	r11.u64 = r17.u64;
	// b 0x831b2a30
	goto loc_831B2A30;
loc_831B2A2C:
	// li r11,0
	r11.s64 = 0;
loc_831B2A30:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b2a48
	if (!cr0.eq) goto loc_831B2A48;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x831d8eb0
	sub_831D8EB0(ctx, base);
loc_831B2A48:
	// stw r30,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r30.u32);
loc_831B2A4C:
	// rlwinm r11,r28,0,0,30
	r11.u64 = rotl64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b2a68
	if (!cr0.eq) goto loc_831B2A68;
	// mr r28,r11
	r28.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b290c
	if (!cr6.eq) goto loc_831B290C;
loc_831B2A68:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b2ad0
	if (!cr0.eq) goto loc_831B2AD0;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x831b2ad0
	if (cr0.eq) goto loc_831B2AD0;
loc_831B2A80:
	// lwz r4,28(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// clrlwi. r11,r4,31
	r11.u64 = ctx.r4.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x831b2ab4
	if (!cr0.eq) goto loc_831B2AB4;
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x831b2ab4
	if (cr0.eq) goto loc_831B2AB4;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm r11,r11,0,18,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0x3F80;
	// cmplwi cr6,r11,16128
	cr6.compare<uint32_t>(r11.u32, 16128, xer);
	// bne cr6,0x831b2ab4
	if (!cr6.eq) goto loc_831B2AB4;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x831d4770
	sub_831D4770(ctx, base);
loc_831B2AB4:
	// rlwinm r11,r30,0,0,30
	r11.u64 = rotl64(r30.u32 | (r30.u64 << 32), 0) & 0xFFFFFFFE;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x831b2ad0
	if (!cr0.eq) goto loc_831B2AD0;
	// mr r30,r11
	r30.u64 = r11.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x831b2a80
	if (!cr6.eq) goto loc_831B2A80;
loc_831B2AD0:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// b 0x82ca2c08
	return;
loc_831B2AD8:
	// li r4,4801
	ctx.r4.s64 = 4801;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x830fd318
	sub_830FD318(ctx, base);
}

PPC_WEAK_FUNC(sub_831B2290) {
	__imp__sub_831B2290(ctx, base);
}

