#include "ppc_recomp_shared.h"

PPC_FUNC_IMPL(__imp__sub_82C85FD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c85dc0
	sub_82C85DC0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// bl 0x82ca3b30
	sub_82CA3B30(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C85FD0) {
	__imp__sub_82C85FD0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86040) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c85dc0
	sub_82C85DC0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// bl 0x82c85b88
	sub_82C85B88(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86040) {
	__imp__sub_82C86040(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C860B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c85dc0
	sub_82C85DC0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// bl 0x82c85c20
	sub_82C85C20(ctx, base);
	// stfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C860B0) {
	__imp__sub_82C860B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86120) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c85dc0
	sub_82C85DC0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c825a0
	sub_82C825A0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86120) {
	__imp__sub_82C86120(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86190) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c85dc0
	sub_82C85DC0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r4,r10,3900
	ctx.r4.s64 = ctx.r10.s64 + 3900;
	// bl 0x82caaf80
	sub_82CAAF80(ctx, base);
	// cntlzw r9,r3
	ctx.r9.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// stb r8,0(r30)
	PPC_STORE_U8(r30.u32 + 0, ctx.r8.u8);
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86190) {
	__imp__sub_82C86190(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86210) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,76(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 76);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r8,68(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 68);
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86210) {
	__imp__sub_82C86210(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86260) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86274
	if (cr6.eq) goto loc_82C86274;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// b 0x82c81e58
	sub_82C81E58(ctx, base);
	return;
loc_82C86274:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86260) {
	__imp__sub_82C86260(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86280) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82C862B4:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c862b4
	if (!cr6.eq) goto loc_82C862B4;
	// subf r11,r31,r11
	r11.s64 = r11.s64 - r31.s64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r11,r31
	r11.u64 = r31.u64;
	// subf r10,r31,r3
	ctx.r10.s64 = ctx.r3.s64 - r31.s64;
loc_82C862EC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// stbx r9,r10,r11
	PPC_STORE_U8(ctx.r10.u32 + r11.u32, ctx.r9.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne cr6,0x82c862ec
	if (!cr6.eq) goto loc_82C862EC;
	// bl 0x82c85c98
	sub_82C85C98(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c823d8
	sub_82C823D8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86280) {
	__imp__sub_82C86280(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86338) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82c81ba8
	sub_82C81BA8(ctx, base);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// li r11,0
	r11.s64 = 0;
	// addi r9,r10,-5816
	ctx.r9.s64 = ctx.r10.s64 + -5816;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// stb r11,20(r31)
	PPC_STORE_U8(r31.u32 + 20, r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86338) {
	__imp__sub_82C86338(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86388) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r10,r11,-5816
	ctx.r10.s64 = r11.s64 + -5816;
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c863c8
	if (cr6.eq) goto loc_82C863C8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c88a58
	sub_82C88A58(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82ca29e8
	sub_82CA29E8(ctx, base);
loc_82C863C8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c81bf8
	sub_82C81BF8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86388) {
	__imp__sub_82C86388(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C863E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86490
	if (cr6.eq) goto loc_82C86490;
	// clrlwi r27,r6,24
	r27.u64 = ctx.r6.u32 & 0xFF;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82c86424
	if (cr6.eq) goto loc_82C86424;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x82c8642c
	if (!cr6.eq) goto loc_82C8642C;
	// lwz r29,20(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 20);
loc_82C86424:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82c8646c
	if (cr6.eq) goto loc_82C8646C;
loc_82C8642C:
	// mr r31,r29
	r31.u64 = r29.u64;
loc_82C86430:
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82caaf08
	sub_82CAAF08(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c86478
	if (cr6.eq) goto loc_82C86478;
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82c86464
	if (!cr6.eq) goto loc_82C86464;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82c8646c
	if (cr6.eq) goto loc_82C8646C;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r31,20(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 20);
loc_82C86464:
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bne cr6,0x82c86430
	if (!cr6.eq) goto loc_82C86430;
loc_82C8646C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C86478:
	// stw r31,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r31.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C86490:
	// clrlwi r11,r6,24
	r11.u64 = ctx.r6.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c864a8
	if (!cr6.eq) goto loc_82C864A8;
	// lbz r11,20(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c8646c
	if (!cr6.eq) goto loc_82C8646C;
loc_82C864A8:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c8646c
	if (cr6.eq) goto loc_82C8646C;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82caaf08
	sub_82CAAF08(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8646c
	if (!cr6.eq) goto loc_82C8646C;
	// li r11,1
	r11.s64 = 1;
	// stw r31,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r31.u32);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r10,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r10.u32);
	// stb r11,20(r30)
	PPC_STORE_U8(r30.u32 + 20, r11.u8);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C863E8) {
	__imp__sub_82C863E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C864F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r10,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r10.u32);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C864F0) {
	__imp__sub_82C864F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86508) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c86558
	if (cr6.eq) goto loc_82C86558;
	// bl 0x82c88ee8
	sub_82C88EE8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c86558
	if (cr6.eq) goto loc_82C86558;
	// bl 0x82ca3b30
	sub_82CA3B30(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C86558:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86508) {
	__imp__sub_82C86508(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86570) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c865c0
	if (cr6.eq) goto loc_82C865C0;
	// bl 0x82c88ee8
	sub_82C88EE8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c865c0
	if (cr6.eq) goto loc_82C865C0;
	// bl 0x82c85b88
	sub_82C85B88(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C865C0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86570) {
	__imp__sub_82C86570(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C865D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c86624
	if (cr6.eq) goto loc_82C86624;
	// bl 0x82c88ee8
	sub_82C88EE8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c86624
	if (cr6.eq) goto loc_82C86624;
	// bl 0x82c85c20
	sub_82C85C20(ctx, base);
	// stfs f1,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C86624:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C865D8) {
	__imp__sub_82C865D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86640) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c8669c
	if (cr6.eq) goto loc_82C8669C;
	// bl 0x82c88ee8
	sub_82C88EE8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c8669c
	if (cr6.eq) goto loc_82C8669C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r11,3900
	ctx.r4.s64 = r11.s64 + 3900;
	// bl 0x82caaf80
	sub_82CAAF80(ctx, base);
	// cntlzw r10,r3
	ctx.r10.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// stb r9,0(r31)
	PPC_STORE_U8(r31.u32 + 0, ctx.r9.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C8669C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86640) {
	__imp__sub_82C86640(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C866B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c86710
	if (cr6.eq) goto loc_82C86710;
	// bl 0x82c88ee8
	sub_82C88EE8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82c86710
	if (cr6.eq) goto loc_82C86710;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c823d8
	sub_82C823D8(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C86710:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C866B8) {
	__imp__sub_82C866B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86728) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c8676c
	if (cr6.eq) goto loc_82C8676C;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c8674c
	if (cr6.eq) goto loc_82C8674C;
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// b 0x82c86798
	goto loc_82C86798;
loc_82C8674C:
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c867b4
	if (cr6.eq) goto loc_82C867B4;
	// lwz r10,20(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c867b4
	if (cr6.eq) goto loc_82C867B4;
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// b 0x82c86798
	goto loc_82C86798;
loc_82C8676C:
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c86784
	if (!cr6.eq) goto loc_82C86784;
	// lbz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c86798
	if (!cr6.eq) goto loc_82C86798;
loc_82C86784:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stb r9,20(r11)
	PPC_STORE_U8(r11.u32 + 20, ctx.r9.u8);
	// stw r8,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r8.u32);
loc_82C86798:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c867b4
	if (cr6.eq) goto loc_82C867B4;
	// lwz r9,20(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// addi r3,r10,8
	ctx.r3.s64 = ctx.r10.s64 + 8;
	// stw r9,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r9.u32);
	// b 0x82c81e58
	sub_82C81E58(ctx, base);
	return;
loc_82C867B4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86728) {
	__imp__sub_82C86728(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C867C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c867d4
	if (cr6.eq) goto loc_82C867D4;
	// lwz r5,20(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// b 0x82c867d8
	goto loc_82C867D8;
loc_82C867D4:
	// li r5,0
	ctx.r5.s64 = 0;
loc_82C867D8:
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82c863e8
	sub_82C863E8(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C867C0) {
	__imp__sub_82C867C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C867E0) {
	PPC_FUNC_PROLOGUE();
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x82c86728
	sub_82C86728(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C867E0) {
	__imp__sub_82C867E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C867E8) {
	PPC_FUNC_PROLOGUE();
	// lwz r5,16(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82c863e8
	sub_82C863E8(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C867E8) {
	__imp__sub_82C867E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C867F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// xori r3,r8,1
	ctx.r3.u64 = ctx.r8.u64 ^ 1;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C867F8) {
	__imp__sub_82C867F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86810) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86810) {
	__imp__sub_82C86810(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86828) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r10,r11,-5816
	ctx.r10.s64 = r11.s64 + -5816;
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c86864
	if (cr6.eq) goto loc_82C86864;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c88a58
	sub_82C88A58(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82ca29e8
	sub_82CA29E8(ctx, base);
loc_82C86864:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c81bf8
	sub_82C81BF8(ctx, base);
	// clrlwi r11,r29,31
	r11.u64 = r29.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86884
	if (cr6.eq) goto loc_82C86884;
	// bl 0x824fe010
	sub_824FE010(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82C86884:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C86828) {
	__imp__sub_82C86828(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86890) {
	PPC_FUNC_PROLOGUE();
	// lwz r5,16(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// li r6,1
	ctx.r6.s64 = 1;
	// b 0x82c863e8
	sub_82C863E8(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C86890) {
	__imp__sub_82C86890(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C868A0) {
	PPC_FUNC_PROLOGUE();
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x82c86728
	sub_82C86728(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C868A0) {
	__imp__sub_82C868A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C868A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// li r4,128
	ctx.r4.s64 = 128;
	// stfs f31,132(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// lis r11,-32255
	r11.s64 = -2113863680;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r31,r11,-5728
	r31.s64 = r11.s64 + -5728;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// stfd f1,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.f1.u64);
	// ld r6,40(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 40);
	// li r4,128
	ctx.r4.s64 = 128;
	// lwz r7,132(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C868A8) {
	__imp__sub_82C868A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86918) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86960
	if (cr6.eq) goto loc_82C86960;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r5,r11,-22980
	ctx.r5.s64 = r11.s64 + -22980;
	// b 0x82c86968
	goto loc_82C86968;
loc_82C86960:
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r5,r11,-22988
	ctx.r5.s64 = r11.s64 + -22988;
loc_82C86968:
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86918) {
	__imp__sub_82C86918(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86988) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c869d0
	if (!cr6.eq) goto loc_82C869D0;
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x82c88628
	sub_82C88628(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c869c8
	if (cr6.eq) goto loc_82C869C8;
	// bl 0x82c88678
	sub_82C88678(ctx, base);
	// b 0x82c869cc
	goto loc_82C869CC;
loc_82C869C8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C869CC:
	// stw r3,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r3.u32);
loc_82C869D0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// bl 0x82c89270
	sub_82C89270(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// beq cr6,0x82c869fc
	if (cr6.eq) goto loc_82C869FC;
	// bl 0x82c88d78
	sub_82C88D78(ctx, base);
	// b 0x82c86a04
	goto loc_82C86A04;
loc_82C869FC:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x82c88630
	sub_82C88630(ctx, base);
loc_82C86A04:
	// li r11,0
	r11.s64 = 0;
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86988) {
	__imp__sub_82C86988(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86A30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86A30) {
	__imp__sub_82C86A30(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86A40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82c892c8
	sub_82C892C8(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c892c8
	sub_82C892C8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c823d8
	sub_82C823D8(ctx, base);
	// lbz r11,20(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86aa0
	if (cr6.eq) goto loc_82C86AA0;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r10,-9784
	ctx.r4.s64 = ctx.r10.s64 + -9784;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r9,40(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82C86AA0:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x82c88cf0
	sub_82C88CF0(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C86A40) {
	__imp__sub_82C86A40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86AC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86b48
	if (cr6.eq) goto loc_82C86B48;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r28,r11,2864
	r28.s64 = r11.s64 + 2864;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r10,88(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
loc_82C86B48:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82C86AC0) {
	__imp__sub_82C86AC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86B50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86bd8
	if (cr6.eq) goto loc_82C86BD8;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r28,r11,30568
	r28.s64 = r11.s64 + 30568;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r10,88(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
loc_82C86BD8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82C86B50) {
	__imp__sub_82C86B50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86BE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86c44
	if (cr6.eq) goto loc_82C86C44;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82c868a8
	sub_82C868A8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
loc_82C86C44:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C86BE0) {
	__imp__sub_82C86BE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86C50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r3,12(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// b 0x82c88e68
	sub_82C88E68(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C86C50) {
	__imp__sub_82C86C50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86C6C) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86C6C) {
	__imp__sub_82C86C6C(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86C70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r31,0(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C86C70) {
	__imp__sub_82C86C70(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86CB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86d14
	if (cr6.eq) goto loc_82C86D14;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// bl 0x82c86918
	sub_82C86918(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
loc_82C86D14:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C86CB0) {
	__imp__sub_82C86CB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86D20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86da8
	if (cr6.eq) goto loc_82C86DA8;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r28,r11,2864
	r28.s64 = r11.s64 + 2864;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r10,88(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
loc_82C86DA8:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82C86D20) {
	__imp__sub_82C86D20(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86DB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86e40
	if (cr6.eq) goto loc_82C86E40;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r28,r11,30568
	r28.s64 = r11.s64 + 30568;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r10,88(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
loc_82C86E40:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82C86DB8) {
	__imp__sub_82C86DB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86E50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86eb4
	if (cr6.eq) goto loc_82C86EB4;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82c868a8
	sub_82C868A8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
loc_82C86EB4:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C86E50) {
	__imp__sub_82C86E50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86EC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r31,0(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C86EC0) {
	__imp__sub_82C86EC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86F08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c86f6c
	if (cr6.eq) goto loc_82C86F6C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// bl 0x82c86918
	sub_82C86918(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
loc_82C86F6C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C86F08) {
	__imp__sub_82C86F08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86F78) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// b 0x82c88cf8
	sub_82C88CF8(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C86F78) {
	__imp__sub_82C86F78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86F80) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,8(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// b 0x82c886f0
	sub_82C886F0(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C86F80) {
	__imp__sub_82C86F80(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86F88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,84(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86F88) {
	__imp__sub_82C86F88(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C86FC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,80(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C86FC8) {
	__imp__sub_82C86FC8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87008) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r10,76(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 76);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87008) {
	__imp__sub_82C87008(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87040) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87040) {
	__imp__sub_82C87040(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87088) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lwz r8,64(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// stb r9,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r9.u8);
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87088) {
	__imp__sub_82C87088(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C870C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r29,r11,2864
	r29.s64 = r11.s64 + 2864;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82c86a40
	sub_82C86A40(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C870C8) {
	__imp__sub_82C870C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87140) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r29,r11,30568
	r29.s64 = r11.s64 + 30568;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// bl 0x82c86a40
	sub_82C86A40(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C87140) {
	__imp__sub_82C87140(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C871B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// li r4,128
	ctx.r4.s64 = 128;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f31,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f31.f64 = double(temp.f32);
	// stfs f31,84(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r30,r11,-5728
	r30.s64 = r11.s64 + -5728;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// stfd f1,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.f1.u64);
	// ld r6,40(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 40);
	// li r4,128
	ctx.r4.s64 = 128;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// bl 0x82c86a40
	sub_82C86A40(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C871B8) {
	__imp__sub_82C871B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87260) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r31,0(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87260) {
	__imp__sub_82C87260(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C872B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lbz r30,0(r30)
	r30.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c87300
	if (cr6.eq) goto loc_82C87300;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r5,r11,-22980
	ctx.r5.s64 = r11.s64 + -22980;
	// b 0x82c87308
	goto loc_82C87308;
loc_82C87300:
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r5,r11,-22988
	ctx.r5.s64 = r11.s64 + -22988;
loc_82C87308:
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,5
	ctx.r5.s64 = 5;
	// bl 0x82c86a40
	sub_82C86A40(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C872B0) {
	__imp__sub_82C872B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87348) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,3224
	ctx.r4.s64 = r11.s64 + 3224;
	// bl 0x82c823d8
	sub_82C823D8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82C87378:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c87378
	if (!cr6.eq) goto loc_82C87378;
	// subf r11,r11,r3
	r11.s64 = ctx.r3.s64 - r11.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r27,r11,0
	r27.u64 = rotl32(r11.u32, 0);
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82c8747c
	if (cr6.eq) goto loc_82C8747C;
	// lis r11,-31953
	r11.s64 = -2094071808;
	// li r25,0
	r25.s64 = 0;
	// addi r26,r11,-5996
	r26.s64 = r11.s64 + -5996;
loc_82C873B4:
	// li r31,5
	r31.s64 = 5;
	// mr r28,r29
	r28.u64 = r29.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82c87410
	if (cr6.eq) goto loc_82C87410;
loc_82C873C4:
	// cmplwi cr6,r31,5
	cr6.compare<uint32_t>(r31.u32, 5, xer);
	// bne cr6,0x82c87418
	if (!cr6.eq) goto loc_82C87418;
	// lbz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r31,r25
	r31.u64 = r25.u64;
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
loc_82C873DC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// extsb r8,r9
	ctx.r8.s64 = ctx.r9.s8;
	// cmpw cr6,r10,r8
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r8.s32, xer);
	// beq cr6,0x82c873fc
	if (cr6.eq) goto loc_82C873FC;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// cmplwi cr6,r31,5
	cr6.compare<uint32_t>(r31.u32, 5, xer);
	// blt cr6,0x82c873dc
	if (cr6.lt) goto loc_82C873DC;
loc_82C873FC:
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// bne 0x82c873c4
	if (!cr0.eq) goto loc_82C873C4;
	// cmplwi cr6,r31,5
	cr6.compare<uint32_t>(r31.u32, 5, xer);
	// bne cr6,0x82c87418
	if (!cr6.eq) goto loc_82C87418;
loc_82C87410:
	// subf r30,r28,r29
	r30.s64 = r29.s64 - r28.s64;
	// b 0x82c87420
	goto loc_82C87420;
loc_82C87418:
	// subf r11,r28,r29
	r11.s64 = r29.s64 - r28.s64;
	// addi r30,r11,-1
	r30.s64 = r11.s64 + -1;
loc_82C87420:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// ble cr6,0x82c87458
	if (!cr6.gt) goto loc_82C87458;
	// addi r3,r30,1
	ctx.r3.s64 = r30.s64 + 1;
	// bl 0x82c87a50
	sub_82C87A50(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// stbx r25,r23,r30
	PPC_STORE_U8(r23.u32 + r30.u32, r25.u8);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c824d8
	sub_82C824D8(ctx, base);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
loc_82C87458:
	// cmplwi cr6,r31,5
	cr6.compare<uint32_t>(r31.u32, 5, xer);
	// beq cr6,0x82c87474
	if (cr6.eq) goto loc_82C87474;
	// rlwinm r11,r31,3,0,28
	r11.u64 = rotl64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r26,4
	ctx.r10.s64 = r26.s64 + 4;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x82c824d8
	sub_82C824D8(ctx, base);
loc_82C87474:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x82c873b4
	if (!cr6.eq) goto loc_82C873B4;
loc_82C8747C:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82C87488:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c87488
	if (!cr6.eq) goto loc_82C87488;
	// subf r11,r11,r3
	r11.s64 = ctx.r3.s64 - r11.s64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = rotl32(r11.u32, 0);
	// addi r31,r11,1
	r31.s64 = r11.s64 + 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x82ca3eb8
	sub_82CA3EB8(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	return;
}

PPC_WEAK_FUNC(sub_82C87348) {
	__imp__sub_82C87348(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C874E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82c81ba8
	sub_82C81BA8(ctx, base);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// li r11,0
	r11.s64 = 0;
	// addi r9,r10,-5720
	ctx.r9.s64 = ctx.r10.s64 + -5720;
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// stb r8,20(r31)
	PPC_STORE_U8(r31.u32 + 20, ctx.r8.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C874E0) {
	__imp__sub_82C874E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87538) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r10,r11,-5720
	ctx.r10.s64 = r11.s64 + -5720;
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c87578
	if (cr6.eq) goto loc_82C87578;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c88a58
	sub_82C88A58(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82ca29e8
	sub_82CA29E8(ctx, base);
loc_82C87578:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c81bf8
	sub_82C81BF8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87538) {
	__imp__sub_82C87538(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87598) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82c823d8
	sub_82C823D8(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82c87348
	sub_82C87348(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// bl 0x82c86a40
	sub_82C86A40(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87598) {
	__imp__sub_82C87598(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87610) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r10,r11,-5720
	ctx.r10.s64 = r11.s64 + -5720;
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c8764c
	if (cr6.eq) goto loc_82C8764C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c88a58
	sub_82C88A58(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82ca29e8
	sub_82CA29E8(ctx, base);
loc_82C8764C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c81bf8
	sub_82C81BF8(ctx, base);
	// clrlwi r11,r29,31
	r11.u64 = r29.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c8766c
	if (cr6.eq) goto loc_82C8766C;
	// bl 0x824fe010
	sub_824FE010(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82C8766C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C87610) {
	__imp__sub_82C87610(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87678) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87678) {
	__imp__sub_82C87678(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87688) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r3,r11,-1
	ctx.r3.s64 = r11.s64 + -1;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87688) {
	__imp__sub_82C87688(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87698) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// li r3,4096
	ctx.r3.s64 = 4096;
	// stw r31,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r31.u32);
	// stw r31,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r31.u32);
	// stw r31,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r31.u32);
	// bl 0x82c87a50
	sub_82C87A50(ctx, base);
	// lwz r5,8(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
	// li r11,4096
	r11.s64 = 4096;
	// stw r30,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r30.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
	// lwz r30,8(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r4,r30,1
	ctx.r4.s64 = r30.s64 + 1;
	// bl 0x82c81ed0
	sub_82C81ED0(ctx, base);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stbx r31,r10,r30
	PPC_STORE_U8(ctx.r10.u32 + r30.u32, r31.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C87698) {
	__imp__sub_82C87698(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87708) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// li r3,12
	ctx.r3.s64 = 12;
	// addi r10,r11,-5608
	ctx.r10.s64 = r11.s64 + -5608;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// bl 0x82c87a50
	sub_82C87A50(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c87744
	if (cr6.eq) goto loc_82C87744;
	// bl 0x82c87698
	sub_82C87698(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x82c87748
	goto loc_82C87748;
loc_82C87744:
	// li r11,0
	r11.s64 = 0;
loc_82C87748:
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87708) {
	__imp__sub_82C87708(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87768) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// li r4,1024
	ctx.r4.s64 = 1024;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// li r30,1024
	r30.s64 = 1024;
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// addi r11,r1,84
	r11.s64 = ctx.r1.s64 + 84;
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// li r27,-1
	r27.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r28,84(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82C877C8:
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82ca46e8
	sub_82CA46E8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x82c87804
	if (!cr6.eq) goto loc_82C87804;
	// rlwinm r30,r30,1,0,30
	r30.u64 = rotl64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// b 0x82c877c8
	goto loc_82C877C8;
loc_82C87804:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_82C87808:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c87808
	if (!cr6.eq) goto loc_82C87808;
	// subf r11,r31,r11
	r11.s64 = r11.s64 - r31.s64;
	// lwz r28,4(r26)
	r28.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// rotlwi r29,r11,0
	r29.u64 = rotl32(r11.u32, 0);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r30,r11,-1
	r30.s64 = r11.s64 + -1;
	// add r4,r29,r30
	ctx.r4.u64 = r29.u64 + r30.u64;
	// bl 0x82c81ed0
	sub_82C81ED0(ctx, base);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// add r3,r30,r11
	ctx.r3.u64 = r30.u64 + r11.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r31,8(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// bl 0x82c81ed0
	sub_82C81ED0(ctx, base);
	// lwz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stbx r10,r31,r9
	PPC_STORE_U8(r31.u32 + ctx.r9.u32, ctx.r10.u8);
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C87768) {
	__imp__sub_82C87768(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87880) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r28,4(r3)
	r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r31,r11,-1
	r31.s64 = r11.s64 + -1;
	// add r4,r31,r30
	ctx.r4.u64 = r31.u64 + r30.u64;
	// bl 0x82c81ed0
	sub_82C81ED0(ctx, base);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// add r3,r11,r31
	ctx.r3.u64 = r11.u64 + r31.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r31,8(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// bl 0x82c81ed0
	sub_82C81ED0(ctx, base);
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// li r11,0
	r11.s64 = 0;
	// stbx r11,r10,r31
	PPC_STORE_U8(ctx.r10.u32 + r31.u32, r11.u8);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82C87880) {
	__imp__sub_82C87880(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C878E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r10,r11,-5608
	ctx.r10.s64 = r11.s64 + -5608;
	// lwz r31,4(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c87938
	if (cr6.eq) goto loc_82C87938;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
loc_82C87938:
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r10,r11,-12180
	ctx.r10.s64 = r11.s64 + -12180;
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C878E8) {
	__imp__sub_82C878E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87960) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82c878e8
	sub_82C878E8(ctx, base);
	// clrlwi r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c87998
	if (cr6.eq) goto loc_82C87998;
	// bl 0x824fe010
	sub_824FE010(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82C87998:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87960) {
	__imp__sub_82C87960(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C879B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31949
	r11.s64 = -2093809664;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r31,r11,22648
	r31.s64 = r11.s64 + 22648;
	// lbz r11,37(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 37);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c879ec
	if (!cr6.eq) goto loc_82C879EC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x832b258c
	__imp__RtlInitializeCriticalSection(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stb r11,37(r31)
	PPC_STORE_U8(r31.u32 + 37, r11.u8);
loc_82C879EC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x832b227c
	__imp__RtlEnterCriticalSection(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C879B0) {
	__imp__sub_82C879B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87A10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// li r11,0
	r11.s64 = 0;
	// addi r3,r10,22648
	ctx.r3.s64 = ctx.r10.s64 + 22648;
	// stb r11,36(r3)
	PPC_STORE_U8(ctx.r3.u32 + 36, r11.u8);
	// b 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C87A10) {
	__imp__sub_82C87A10(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87A28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// lwz r11,22688(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 22688);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,22688(r10)
	PPC_STORE_U32(ctx.r10.u32 + 22688, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87A28) {
	__imp__sub_82C87A28(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87A40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-31949
	r11.s64 = -2093809664;
	// lwz r3,22676(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 22676);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87A40) {
	__imp__sub_82C87A40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87A50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// lwz r11,22692(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 22692);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,22692(r10)
	PPC_STORE_U32(ctx.r10.u32 + 22692, r11.u32);
	// b 0x8221f388
	sub_8221F388(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C87A50) {
	__imp__sub_82C87A50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87A68) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c87a90
	if (cr6.eq) goto loc_82C87A90;
	// bl 0x824fe010
	sub_824FE010(ctx, base);
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// lwz r11,22692(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 22692);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,22692(r10)
	PPC_STORE_U32(ctx.r10.u32 + 22692, r11.u32);
loc_82C87A90:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87A68) {
	__imp__sub_82C87A68(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87AA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31949
	r11.s64 = -2093809664;
	// addi r31,r11,22692
	r31.s64 = r11.s64 + 22692;
	// lwz r11,-4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -4);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,-4(r31)
	PPC_STORE_U32(r31.u32 + -4, r11.u32);
	// bne 0x82c87af4
	if (!cr0.eq) goto loc_82C87AF4;
	// lwz r3,-16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + -16);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c87ae4
	if (cr6.eq) goto loc_82C87AE4;
	// bl 0x824fe010
	sub_824FE010(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82C87AE4:
	// li r11,0
	r11.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,-16(r31)
	PPC_STORE_U32(r31.u32 + -16, r11.u32);
	// stw r10,-12(r31)
	PPC_STORE_U32(r31.u32 + -12, ctx.r10.u32);
loc_82C87AF4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87AA0) {
	__imp__sub_82C87AA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87B08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31949
	r11.s64 = -2093809664;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r31,r11,22692
	r31.s64 = r11.s64 + 22692;
	// lwz r3,-16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + -16);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c87b50
	if (cr6.eq) goto loc_82C87B50;
	// lwz r11,-12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -12);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bge cr6,0x82c87b6c
	if (!cr6.lt) goto loc_82C87B6C;
	// bl 0x824fe010
	sub_824FE010(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// b 0x82c87b54
	goto loc_82C87B54;
loc_82C87B50:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_82C87B54:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// stw r30,-12(r31)
	PPC_STORE_U32(r31.u32 + -12, r30.u32);
	// stw r3,-16(r31)
	PPC_STORE_U32(r31.u32 + -16, ctx.r3.u32);
loc_82C87B6C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87B08) {
	__imp__sub_82C87B08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87B88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82240578
	sub_82240578(ctx, base);
	// addi r3,r3,64
	ctx.r3.s64 = ctx.r3.s64 + 64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82ca7120
	sub_82CA7120(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87B88) {
	__imp__sub_82C87B88(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87BC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r9,r11,-5580
	ctx.r9.s64 = r11.s64 + -5580;
	// addi r30,r10,3224
	r30.s64 = ctx.r10.s64 + 3224;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82c823d8
	sub_82C823D8(ctx, base);
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82c823d8
	sub_82C823D8(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stb r11,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r11.u8);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87BC0) {
	__imp__sub_82C87BC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87C30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82C87C54:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c87c54
	if (!cr6.eq) goto loc_82C87C54;
	// subf r11,r11,r3
	r11.s64 = ctx.r3.s64 - r11.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r10,r11,0
	ctx.r10.u64 = rotl32(r11.u32, 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c87c94
	if (!cr6.eq) goto loc_82C87C94;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82C87C94:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C87C30) {
	__imp__sub_82C87C30(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87CA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r30,r31,12
	r30.s64 = r31.s64 + 12;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82C87CC4:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c87cc4
	if (!cr6.eq) goto loc_82C87CC4;
	// subf r11,r11,r3
	r11.s64 = ctx.r3.s64 - r11.s64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r10,r11,0
	ctx.r10.u64 = rotl32(r11.u32, 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c87d1c
	if (cr6.eq) goto loc_82C87D1C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c823d8
	sub_82C823D8(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82c87d30
	if (!cr6.eq) goto loc_82C87D30;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r4,r11,3224
	ctx.r4.s64 = r11.s64 + 3224;
	// bl 0x82c825a0
	sub_82C825A0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
loc_82C87D1C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82C87D30:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C87CA0) {
	__imp__sub_82C87CA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87D38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// li r11,1
	r11.s64 = 1;
	// stb r11,16(r3)
	PPC_STORE_U8(ctx.r3.u32 + 16, r11.u8);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87D38) {
	__imp__sub_82C87D38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87D48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// ble cr6,0x82c87da0
	if (!cr6.gt) goto loc_82C87DA0;
loc_82C87D54:
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// beq cr6,0x82c87d80
	if (cr6.eq) goto loc_82C87D80;
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// beq cr6,0x82c87d80
	if (cr6.eq) goto loc_82C87D80;
	// cmpwi cr6,r11,13
	cr6.compare<int32_t>(r11.s32, 13, xer);
	// beq cr6,0x82c87d80
	if (cr6.eq) goto loc_82C87D80;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x82c87d84
	if (!cr6.eq) goto loc_82C87D84;
loc_82C87D80:
	// li r11,1
	r11.s64 = 1;
loc_82C87D84:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c87da8
	if (cr6.eq) goto loc_82C87DA8;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmpw cr6,r10,r4
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r4.s32, xer);
	// blt cr6,0x82c87d54
	if (cr6.lt) goto loc_82C87D54;
loc_82C87DA0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C87DA8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87D48) {
	__imp__sub_82C87D48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87DB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-31953
	r11.s64 = -2094071808;
	// stw r3,-5940(r11)
	PPC_STORE_U32(r11.u32 + -5940, ctx.r3.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C87DB0) {
	__imp__sub_82C87DB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87DC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// std r4,24(r1)
	PPC_STORE_U64(ctx.r1.u32 + 24, ctx.r4.u64);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,152
	ctx.r10.s64 = ctx.r1.s64 + 152;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r28,80(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82ca6e88
	sub_82CA6E88(ctx, base);
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// lis r11,-31949
	r11.s64 = -2093809664;
	// addi r30,r3,1
	r30.s64 = ctx.r3.s64 + 1;
	// addi r31,r11,22696
	r31.s64 = r11.s64 + 22696;
	// lwz r11,22704(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 22704);
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c87e44
	if (!cr6.eq) goto loc_82C87E44;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r11,22704(r10)
	PPC_STORE_U32(ctx.r10.u32 + 22704, r11.u32);
	// lis r11,-31957
	r11.s64 = -2094333952;
	// stw r8,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r8.u32);
	// addi r3,r11,1792
	ctx.r3.s64 = r11.s64 + 1792;
	// bl 0x82ca3700
	sub_82CA3700(ctx, base);
loc_82C87E44:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// ble cr6,0x82c87e68
	if (!cr6.gt) goto loc_82C87E68;
	// bl 0x824fe010
	sub_824FE010(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
loc_82C87E68:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82ca4578
	sub_82CA4578(ctx, base);
	// lis r11,-31953
	r11.s64 = -2094071808;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,-5940(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -5940);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82C87DC0) {
	__imp__sub_82C87DC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87E98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82C87EBC:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c87ebc
	if (!cr6.eq) goto loc_82C87EBC;
	// subf r11,r11,r3
	r11.s64 = ctx.r3.s64 - r11.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r10,r11,0
	ctx.r10.u64 = rotl32(r11.u32, 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c87f28
	if (!cr6.eq) goto loc_82C87F28;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c87f28
	if (cr6.eq) goto loc_82C87F28;
	// lbz r11,16(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c87f0c
	if (!cr6.eq) goto loc_82C87F0C;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c87d48
	sub_82C87D48(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c87f28
	if (!cr6.eq) goto loc_82C87F28;
loc_82C87F0C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82C87F28:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C87E98) {
	__imp__sub_82C87E98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C87F30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// addi r10,r1,208
	ctx.r10.s64 = ctx.r1.s64 + 208;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r27,112(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x82ca6e88
	sub_82CA6E88(ctx, base);
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// lis r11,-31949
	r11.s64 = -2093809664;
	// addi r29,r3,1
	r29.s64 = ctx.r3.s64 + 1;
	// addi r31,r11,22708
	r31.s64 = r11.s64 + 22708;
	// lwz r11,22716(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 22716);
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c87fb8
	if (!cr6.eq) goto loc_82C87FB8;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r11,22716(r10)
	PPC_STORE_U32(ctx.r10.u32 + 22716, r11.u32);
	// lis r11,-31957
	r11.s64 = -2094333952;
	// stw r8,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r8.u32);
	// addi r3,r11,1808
	ctx.r3.s64 = r11.s64 + 1808;
	// bl 0x82ca3700
	sub_82CA3700(ctx, base);
loc_82C87FB8:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// ble cr6,0x82c87fdc
	if (!cr6.gt) goto loc_82C87FDC;
	// bl 0x824fe010
	sub_824FE010(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8221f388
	sub_8221F388(ctx, base);
	// stw r29,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r29.u32);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
loc_82C87FDC:
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x82ca4578
	sub_82CA4578(ctx, base);
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x82c988d8
	sub_82C988D8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r30,8
	ctx.r3.s64 = r30.s64 + 8;
	// lwz r31,0(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// lis r11,-32255
	r11.s64 = -2113863680;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r11,-5568
	ctx.r3.s64 = r11.s64 + -5568;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// bl 0x82c87dc0
	sub_82C87DC0(ctx, base);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// stw r10,20(r30)
	PPC_STORE_U32(r30.u32 + 20, ctx.r10.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C87F30) {
	__imp__sub_82C87F30(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88030) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31953
	r11.s64 = -2094071808;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r11,-5952
	ctx.r4.s64 = r11.s64 + -5952;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82ca2968
	sub_82CA2968(ctx, base);
	// stw r3,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r3.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82c986b0
	sub_82C986B0(ctx, base);
	// lis r10,-32056
	ctx.r10.s64 = -2100822016;
	// lis r9,-32056
	ctx.r9.s64 = -2100822016;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r5,r10,31904
	ctx.r5.s64 = ctx.r10.s64 + 31904;
	// addi r4,r9,31792
	ctx.r4.s64 = ctx.r9.s64 + 31792;
	// bl 0x82c986d0
	sub_82C986D0(ctx, base);
	// lis r8,-32056
	ctx.r8.s64 = -2100822016;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r4,r8,32408
	ctx.r4.s64 = ctx.r8.s64 + 32408;
	// bl 0x82c986e0
	sub_82C986E0(ctx, base);
	// lis r7,-32024
	ctx.r7.s64 = -2098724864;
	// lis r6,-32056
	ctx.r6.s64 = -2100822016;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r5,r7,22088
	ctx.r5.s64 = ctx.r7.s64 + 22088;
	// addi r4,r6,32056
	ctx.r4.s64 = ctx.r6.s64 + 32056;
	// bl 0x82c986e8
	sub_82C986E8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C88030) {
	__imp__sub_82C88030(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C880B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// clrlwi r6,r6,24
	ctx.r6.u64 = ctx.r6.u32 & 0xFF;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// bl 0x82c9b8f8
	sub_82C9B8F8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8824c
	if (!cr6.eq) goto loc_82C8824C;
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// bl 0x8233d248
	sub_8233D248(ctx, base);
	// bl 0x82c98940
	sub_82C98940(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r3,r27,8
	ctx.r3.s64 = r27.s64 + 8;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x82c87f30
	sub_82C87F30(ctx, base);
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// bl 0x82c988b0
	sub_82C988B0(ctx, base);
	// cmplw cr6,r3,r30
	cr6.compare<uint32_t>(ctx.r3.u32, r30.u32, xer);
	// bge cr6,0x82c88240
	if (!cr6.lt) goto loc_82C88240;
	// add r11,r3,r31
	r11.u64 = ctx.r3.u64 + r31.u64;
	// li r28,0
	r28.s64 = 0;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// mr r29,r28
	r29.u64 = r28.u64;
	// beq cr6,0x82c88158
	if (cr6.eq) goto loc_82C88158;
loc_82C88130:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,10
	cr6.compare<int32_t>(ctx.r10.s32, 10, xer);
	// beq cr6,0x82c88158
	if (cr6.eq) goto loc_82C88158;
	// cmpwi cr6,r10,13
	cr6.compare<int32_t>(ctx.r10.s32, 13, xer);
	// beq cr6,0x82c88158
	if (cr6.eq) goto loc_82C88158;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x82c88130
	if (!cr6.eq) goto loc_82C88130;
loc_82C88158:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c88168
	if (cr6.eq) goto loc_82C88168;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_82C88168:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lis r7,-31949
	ctx.r7.s64 = -2093809664;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// addi r31,r7,22720
	r31.s64 = ctx.r7.s64 + 22720;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x82c881bc
	if (cr6.eq) goto loc_82C881BC;
	// subf r7,r11,r31
	ctx.r7.s64 = r31.s64 - r11.s64;
loc_82C88188:
	// cmpwi cr6,r9,10
	cr6.compare<int32_t>(ctx.r9.s32, 10, xer);
	// beq cr6,0x82c881bc
	if (cr6.eq) goto loc_82C881BC;
	// cmpwi cr6,r9,13
	cr6.compare<int32_t>(ctx.r9.s32, 13, xer);
	// beq cr6,0x82c881bc
	if (cr6.eq) goto loc_82C881BC;
	// cmpwi cr6,r8,4096
	cr6.compare<int32_t>(ctx.r8.s32, 4096, xer);
	// bge cr6,0x82c881bc
	if (!cr6.lt) goto loc_82C881BC;
	// stbx r10,r7,r11
	PPC_STORE_U8(ctx.r7.u32 + r11.u32, ctx.r10.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c88188
	if (!cr6.eq) goto loc_82C88188;
loc_82C881BC:
	// stbx r28,r8,r31
	PPC_STORE_U8(ctx.r8.u32 + r31.u32, r28.u8);
	// lis r11,-32240
	r11.s64 = -2112880640;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r30,r11,-21148
	r30.s64 = r11.s64 + -21148;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c87dc0
	sub_82C87DC0(ctx, base);
	// cmpwi cr6,r29,4094
	cr6.compare<int32_t>(r29.s32, 4094, xer);
	// ble cr6,0x82c881e0
	if (!cr6.gt) goto loc_82C881E0;
	// li r29,4094
	r29.s64 = 4094;
loc_82C881E0:
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// ble cr6,0x82c88224
	if (!cr6.gt) goto loc_82C88224;
	// mr r11,r31
	r11.u64 = r31.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r8,32
	ctx.r8.s64 = 32;
loc_82C881FC:
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r7,9
	cr6.compare<uint32_t>(ctx.r7.u32, 9, xer);
	// beq cr6,0x82c8820c
	if (cr6.eq) goto loc_82C8820C;
	// stb r8,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r8.u8);
loc_82C8820C:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne 0x82c881fc
	if (!cr0.eq) goto loc_82C881FC;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x82c88224
	if (cr6.eq) goto loc_82C88224;
	// addi r9,r29,-1
	ctx.r9.s64 = r29.s64 + -1;
loc_82C88224:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r10,94
	ctx.r10.s64 = 94;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stbx r10,r9,r31
	PPC_STORE_U8(ctx.r9.u32 + r31.u32, ctx.r10.u8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stbx r28,r9,r11
	PPC_STORE_U8(ctx.r9.u32 + r11.u32, r28.u8);
	// bl 0x82c87dc0
	sub_82C87DC0(ctx, base);
loc_82C88240:
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,20(r27)
	PPC_STORE_U32(r27.u32 + 20, r11.u32);
loc_82C8824C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C880B8) {
	__imp__sub_82C880B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88258) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// addi r3,r29,8
	ctx.r3.s64 = r29.s64 + 8;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// bl 0x82c825a0
	sub_82C825A0(ctx, base);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,11936
	ctx.r4.s64 = r11.s64 + 11936;
	// bl 0x82ca4890
	sub_82CA4890(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82c882b8
	if (!cr6.eq) goto loc_82C882B8;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r11,-5504
	ctx.r3.s64 = r11.s64 + -5504;
	// bl 0x82c87dc0
	sub_82C87DC0(ctx, base);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// stw r10,20(r29)
	PPC_STORE_U32(r29.u32 + 20, ctx.r10.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c30
	return;
loc_82C882B8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82ca5338
	sub_82CA5338(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82ca5670
	sub_82CA5670(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82ca5338
	sub_82CA5338(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82c87a50
	sub_82C87A50(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c88030
	sub_82C88030(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c88350
	if (cr6.eq) goto loc_82C88350;
loc_82C88300:
	// cmplw cr6,r31,r26
	cr6.compare<uint32_t>(r31.u32, r26.u32, xer);
	// mr r30,r31
	r30.u64 = r31.u64;
	// blt cr6,0x82c88310
	if (cr6.lt) goto loc_82C88310;
	// mr r30,r26
	r30.u64 = r26.u64;
loc_82C88310:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82cab340
	sub_82CAB340(ctx, base);
	// cmpw cr6,r3,r30
	cr6.compare<int32_t>(ctx.r3.s32, r30.s32, xer);
	// bne cr6,0x82c88370
	if (!cr6.eq) goto loc_82C88370;
	// subf r31,r30,r31
	r31.s64 = r31.s64 - r30.s64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// cntlzw r11,r31
	r11.u64 = r31.u32 == 0 ? 32 : __builtin_clz(r31.u32);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// rlwinm r6,r11,27,31,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c880b8
	sub_82C880B8(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82c88300
	if (!cr6.eq) goto loc_82C88300;
loc_82C88350:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82ca49d8
	sub_82CA49D8(ctx, base);
	// lwz r3,4(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// bl 0x82c9b770
	sub_82C9B770(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c30
	return;
loc_82C88370:
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r3,r11,-5544
	ctx.r3.s64 = r11.s64 + -5544;
	// bl 0x82c87dc0
	sub_82C87DC0(ctx, base);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// stw r10,20(r29)
	PPC_STORE_U32(r29.u32 + 20, ctx.r10.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C88258) {
	__imp__sub_82C88258(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88390) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82c883d0
	if (!cr6.eq) goto loc_82C883D0;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r3,r11,-5464
	ctx.r3.s64 = r11.s64 + -5464;
	// bl 0x82c87dc0
	sub_82C87DC0(ctx, base);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// stw r10,20(r26)
	PPC_STORE_U32(r26.u32 + 20, ctx.r10.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	return;
loc_82C883D0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r3,r26,8
	ctx.r3.s64 = r26.s64 + 8;
	// addi r4,r11,5792
	ctx.r4.s64 = r11.s64 + 5792;
	// bl 0x82c825a0
	sub_82C825A0(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82c88030
	sub_82C88030(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82c87a50
	sub_82C87A50(ctx, base);
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r9,24(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// rotlwi r31,r3,0
	r31.u64 = rotl32(ctx.r3.u32, 0);
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// mr r29,r24
	r29.u64 = r24.u64;
	// beq cr6,0x82c88488
	if (cr6.eq) goto loc_82C88488;
loc_82C8841C:
	// cmplw cr6,r31,r25
	cr6.compare<uint32_t>(r31.u32, r25.u32, xer);
	// mr r30,r31
	r30.u64 = r31.u64;
	// blt cr6,0x82c8842c
	if (cr6.lt) goto loc_82C8842C;
	// mr r30,r25
	r30.u64 = r25.u64;
loc_82C8842C:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r27,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r27.u32);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// stw r24,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r24.u32);
	// clrldi r5,r29,32
	ctx.r5.u64 = r29.u64 & 0xFFFFFFFF;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c884a0
	if (!cr6.eq) goto loc_82C884A0;
	// subf r31,r30,r31
	r31.s64 = r31.s64 - r30.s64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// cntlzw r11,r31
	r11.u64 = r31.u32 == 0 ? 32 : __builtin_clz(r31.u32);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// rlwinm r6,r11,27,31,31
	ctx.r6.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// add r29,r30,r29
	r29.u64 = r30.u64 + r29.u64;
	// bl 0x82c880b8
	sub_82C880B8(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82c8841c
	if (!cr6.eq) goto loc_82C8841C;
loc_82C88488:
	// lwz r3,4(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// bl 0x82c9b770
	sub_82C9B770(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	return;
loc_82C884A0:
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r3,r11,-5544
	ctx.r3.s64 = r11.s64 + -5544;
	// bl 0x82c87dc0
	sub_82C87DC0(ctx, base);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// stw r10,20(r26)
	PPC_STORE_U32(r26.u32 + 20, ctx.r10.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_82C88390) {
	__imp__sub_82C88390(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C884C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x82c884e8
	if (!cr6.eq) goto loc_82C884E8;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r6,r11,-5600
	ctx.r6.s64 = r11.s64 + -5600;
loc_82C884E8:
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// bl 0x82c825a0
	sub_82C825A0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c88030
	sub_82C88030(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c880b8
	sub_82C880B8(ctx, base);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x82c9b770
	sub_82C9B770(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C884C0) {
	__imp__sub_82C884C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88520) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,28(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// addi r30,r3,28
	r30.s64 = ctx.r3.s64 + 28;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c8859c
	if (cr6.eq) goto loc_82C8859C;
loc_82C88554:
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// mr r29,r11
	r29.u64 = r11.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82c8859c
	if (cr6.eq) goto loc_82C8859C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c823d8
	sub_82C823D8(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c88554
	if (!cr6.eq) goto loc_82C88554;
loc_82C8859C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C88520) {
	__imp__sub_82C88520(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C885A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	// lwz r11,28(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// addi r3,r3,28
	ctx.r3.s64 = ctx.r3.s64 + 28;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	return;
}

PPC_WEAK_FUNC(sub_82C885A8) {
	__imp__sub_82C885A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C885C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// bl 0x82c879b0
	sub_82C879B0(ctx, base);
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87b08
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	sub_82C87A40(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x82cab3c8
	sub_82CAB3C8(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// addi r3,r30,28
	ctx.r3.s64 = r30.s64 + 28;
	// stbx r11,r28,r31
	PPC_STORE_U8(r28.u32 + r31.u32, r11.u8);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82c86f78
	sub_82C86F78(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	sub_82C87A10(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82C885C0) {
	__imp__sub_82C885C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88628) {
	PPC_FUNC_PROLOGUE();
	// b 0x82c87a50
	sub_82C87A50(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C88628) {
	__imp__sub_82C88628(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88630) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c89208
	sub_82C89208(ctx, base);
	// stw r30,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C88630) {
	__imp__sub_82C88630(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88678) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// li r3,4096
	ctx.r3.s64 = 4096;
	// stw r31,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r31.u32);
	// bl 0x82c87a50
	sub_82C87A50(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c886d0
	if (cr6.eq) goto loc_82C886D0;
	// li r10,4096
	ctx.r10.s64 = 4096;
	// stw r31,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r31.u32);
	// li r9,-1
	ctx.r9.s64 = -1;
	// stw r31,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r31.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r9.u32);
	// stw r31,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r31.u32);
	// stw r31,20(r11)
	PPC_STORE_U32(r11.u32 + 20, r31.u32);
	// stw r31,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r31.u32);
loc_82C886D0:
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C88678) {
	__imp__sub_82C88678(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C886F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bb0
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// addi r4,r11,-5392
	ctx.r4.s64 = r11.s64 + -5392;
	// bl 0x82c87768
	sub_82C87768(ctx, base);
	// li r22,0
	r22.s64 = 0;
	// li r23,0
	r23.s64 = 0;
	// li r25,0
	r25.s64 = 0;
	// lwz r26,0(r31)
	r26.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x82c88934
	if (cr6.eq) goto loc_82C88934;
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// lis r8,-32255
	ctx.r8.s64 = -2113863680;
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lis r6,-32245
	ctx.r6.s64 = -2113208320;
	// lis r5,-32245
	ctx.r5.s64 = -2113208320;
	// lis r4,-32244
	ctx.r4.s64 = -2113142784;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r21,r9,-27472
	r21.s64 = ctx.r9.s64 + -27472;
	// addi r20,r8,-5400
	r20.s64 = ctx.r8.s64 + -5400;
	// addi r15,r7,-5404
	r15.s64 = ctx.r7.s64 + -5404;
	// addi r14,r6,-17152
	r14.s64 = ctx.r6.s64 + -17152;
	// addi r16,r5,-6332
	r16.s64 = ctx.r5.s64 + -6332;
	// addi r17,r4,22552
	r17.s64 = ctx.r4.s64 + 22552;
	// addi r19,r10,-5416
	r19.s64 = ctx.r10.s64 + -5416;
	// addi r18,r11,-5420
	r18.s64 = r11.s64 + -5420;
loc_82C8876C:
	// addi r27,r26,8
	r27.s64 = r26.s64 + 8;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// ble cr6,0x82c8879c
	if (!cr6.gt) goto loc_82C8879C;
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82C88788:
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82c87768
	sub_82C87768(ctx, base);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x82c88788
	if (!cr0.eq) goto loc_82C88788;
loc_82C8879C:
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82c87768
	sub_82C87768(ctx, base);
	// lwz r29,40(r26)
	r29.u64 = PPC_LOAD_U32(r26.u32 + 40);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x82c88804
	if (cr6.eq) goto loc_82C88804;
	// li r31,0
	r31.s64 = 0;
	// ble cr6,0x82c88804
	if (!cr6.gt) goto loc_82C88804;
loc_82C887C0:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82c88f58
	sub_82C88F58(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r30,12
	ctx.r3.s64 = r30.s64 + 12;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r3,r30,8
	ctx.r3.s64 = r30.s64 + 8;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// bl 0x82c87768
	sub_82C87768(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmpw cr6,r31,r29
	cr6.compare<int32_t>(r31.s32, r29.s32, xer);
	// blt cr6,0x82c887c0
	if (cr6.lt) goto loc_82C887C0;
loc_82C88804:
	// addi r31,r26,12
	r31.s64 = r26.s64 + 12;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82baa130
	sub_82BAA130(ctx, base);
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// rlwinm r10,r11,27,31,31
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r29,r10,1
	r29.u64 = ctx.r10.u64 ^ 1;
	// bne cr6,0x82c88844
	if (!cr6.eq) goto loc_82C88844;
	// clrlwi r30,r29,24
	r30.u64 = r29.u32 & 0xFF;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82c88844
	if (!cr6.eq) goto loc_82C88844;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// b 0x82c888a8
	goto loc_82C888A8;
loc_82C88844:
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82c87768
	sub_82C87768(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x82c88898
	if (cr6.eq) goto loc_82C88898;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
loc_82C88868:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c88868
	if (!cr6.eq) goto loc_82C88868;
	// subf r11,r5,r11
	r11.s64 = r11.s64 - ctx.r5.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r10,r11,0
	ctx.r10.u64 = rotl32(r11.u32, 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c88898
	if (cr6.eq) goto loc_82C88898;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82c87768
	sub_82C87768(ctx, base);
loc_82C88898:
	// clrlwi r30,r29,24
	r30.u64 = r29.u32 & 0xFF;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c888b0
	if (cr6.eq) goto loc_82C888B0;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
loc_82C888A8:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82c87768
	sub_82C87768(ctx, base);
loc_82C888B0:
	// lwz r28,20(r26)
	r28.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82c88944
	if (cr6.eq) goto loc_82C88944;
	// addi r29,r25,1
	r29.s64 = r25.s64 + 1;
	// mr r31,r23
	r31.u64 = r23.u64;
	// cmplw cr6,r23,r29
	cr6.compare<uint32_t>(r23.u32, r29.u32, xer);
	// bge cr6,0x82c8891c
	if (!cr6.lt) goto loc_82C8891C;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// bne cr6,0x82c888d8
	if (!cr6.eq) goto loc_82C888D8;
	// li r31,1
	r31.s64 = 1;
loc_82C888D8:
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bge cr6,0x82c888ec
	if (!cr6.lt) goto loc_82C888EC;
loc_82C888E0:
	// rlwinm r31,r31,1,0,30
	r31.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// blt cr6,0x82c888e0
	if (cr6.lt) goto loc_82C888E0;
loc_82C888EC:
	// cmplw cr6,r31,r23
	cr6.compare<uint32_t>(r31.u32, r23.u32, xer);
	// ble cr6,0x82c8891c
	if (!cr6.gt) goto loc_82C8891C;
	// rlwinm r3,r31,2,0,29
	ctx.r3.u64 = rotl64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82c87a50
	sub_82C87A50(ctx, base);
	// rlwinm r5,r25,2,0,29
	ctx.r5.u64 = rotl64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
	// mr r22,r30
	r22.u64 = r30.u64;
	// mr r23,r31
	r23.u64 = r31.u64;
loc_82C8891C:
	// rlwinm r11,r25,2,0,29
	r11.u64 = rotl64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r25,r29
	r25.u64 = r29.u64;
	// stwx r26,r11,r22
	PPC_STORE_U32(r11.u32 + r22.u32, r26.u32);
	// mr r26,r28
	r26.u64 = r28.u64;
loc_82C8892C:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x82c8876c
	if (!cr6.eq) goto loc_82C8876C;
loc_82C88934:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c00
	return;
loc_82C88944:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c88968
	if (cr6.eq) goto loc_82C88968;
	// addic. r31,r25,-1
	xer.ca = r25.u32 > 0;
	r31.s64 = r25.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// ble 0x82c88968
	if (!cr0.gt) goto loc_82C88968;
loc_82C88954:
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82c87768
	sub_82C87768(ctx, base);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x82c88954
	if (!cr0.eq) goto loc_82C88954;
loc_82C88968:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82c87768
	sub_82C87768(ctx, base);
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c88994
	if (cr6.eq) goto loc_82C88994;
	// mr r26,r11
	r26.u64 = r11.u64;
	// b 0x82c8892c
	goto loc_82C8892C;
loc_82C88994:
	// li r26,0
	r26.s64 = 0;
loc_82C88998:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82c8892c
	if (cr6.eq) goto loc_82C8892C;
	// rlwinm r28,r25,2,0,29
	r28.u64 = rotl64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r25,-1
	r30.s64 = r25.s64 + -1;
	// add r11,r28,r22
	r11.u64 = r28.u64 + r22.u64;
	// mr r31,r23
	r31.u64 = r23.u64;
	// cmplw cr6,r23,r30
	cr6.compare<uint32_t>(r23.u32, r30.u32, xer);
	// lwz r27,-4(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// bge cr6,0x82c88a0c
	if (!cr6.lt) goto loc_82C88A0C;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// bne cr6,0x82c889c8
	if (!cr6.eq) goto loc_82C889C8;
	// li r31,1
	r31.s64 = 1;
loc_82C889C8:
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// bge cr6,0x82c889dc
	if (!cr6.lt) goto loc_82C889DC;
loc_82C889D0:
	// rlwinm r31,r31,1,0,30
	r31.u64 = rotl64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// blt cr6,0x82c889d0
	if (cr6.lt) goto loc_82C889D0;
loc_82C889DC:
	// cmplw cr6,r31,r23
	cr6.compare<uint32_t>(r31.u32, r23.u32, xer);
	// ble cr6,0x82c88a0c
	if (!cr6.gt) goto loc_82C88A0C;
	// rlwinm r3,r31,2,0,29
	ctx.r3.u64 = rotl64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82c87a50
	sub_82C87A50(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
	// mr r22,r29
	r22.u64 = r29.u64;
	// mr r23,r31
	r23.u64 = r31.u64;
loc_82C88A0C:
	// lwz r26,4(r27)
	r26.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// mr r25,r30
	r25.u64 = r30.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// ble cr6,0x82c88a34
	if (!cr6.gt) goto loc_82C88A34;
	// mr r31,r30
	r31.u64 = r30.u64;
loc_82C88A20:
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82c87768
	sub_82C87768(ctx, base);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x82c88a20
	if (!cr0.eq) goto loc_82C88A20;
loc_82C88A34:
	// addi r3,r27,8
	ctx.r3.s64 = r27.s64 + 8;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82c87768
	sub_82C87768(ctx, base);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x82c88998
	if (cr6.eq) goto loc_82C88998;
	// b 0x82c8876c
	goto loc_82C8876C;
}

PPC_WEAK_FUNC(sub_82C886F0) {
	__imp__sub_82C886F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88A58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82c89208
	sub_82C89208(ctx, base);
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c88aac
	if (cr6.eq) goto loc_82C88AAC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c82038
	sub_82C82038(ctx, base);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
loc_82C88AAC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C88A58) {
	__imp__sub_82C88A58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88AC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x82c89208
	sub_82C89208(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// li r28,0
	r28.s64 = 0;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r28,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r28.u32);
	// lwz r30,4(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c88b20
	if (cr6.eq) goto loc_82C88B20;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c82038
	sub_82C82038(ctx, base);
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
	// stw r28,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r28.u32);
	// stw r28,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r28.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r28,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r28.u32);
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
loc_82C88B20:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r28,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r28.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82C88AC0) {
	__imp__sub_82C88AC0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88B38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x82c87bc0
	sub_82C87BC0(ctx, base);
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// addi r10,r11,-5432
	ctx.r10.s64 = r11.s64 + -5432;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x82c874e0
	sub_82C874E0(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c88258
	sub_82C88258(ctx, base);
	// lwz r9,100(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c88bb0
	if (!cr6.eq) goto loc_82C88BB0;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x830418a8
	sub_830418A8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82c88ac0
	sub_82C88AC0(ctx, base);
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,1
	r31.s64 = 1;
	// bl 0x82c87538
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	return;
loc_82C88BB0:
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,0
	r31.s64 = 0;
	// bl 0x82c87538
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C88B38) {
	__imp__sub_82C88B38(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88BC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x82c87bc0
	sub_82C87BC0(ctx, base);
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// addi r10,r11,-5432
	ctx.r10.s64 = r11.s64 + -5432;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x82c874e0
	sub_82C874E0(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c88390
	sub_82C88390(ctx, base);
	// lwz r9,100(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c88c40
	if (!cr6.eq) goto loc_82C88C40;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x830418a8
	sub_830418A8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82c88ac0
	sub_82C88AC0(ctx, base);
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,1
	r31.s64 = 1;
	// bl 0x82c87538
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	return;
loc_82C88C40:
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,0
	r31.s64 = 0;
	// bl 0x82c87538
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C88BC8) {
	__imp__sub_82C88BC8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88C58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x82c87bc0
	sub_82C87BC0(ctx, base);
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// addi r10,r11,-5432
	ctx.r10.s64 = r11.s64 + -5432;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x82c874e0
	sub_82C874E0(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c884c0
	sub_82C884C0(ctx, base);
	// lwz r9,100(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c88cd4
	if (!cr6.eq) goto loc_82C88CD4;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x830418a8
	sub_830418A8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82c88ac0
	sub_82C88AC0(ctx, base);
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,1
	r31.s64 = 1;
	// bl 0x82c87538
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	return;
loc_82C88CD4:
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,0
	r31.s64 = 0;
	// bl 0x82c87538
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C88C58) {
	__imp__sub_82C88C58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88CF0) {
	PPC_FUNC_PROLOGUE();
	// addi r3,r3,12
	ctx.r3.s64 = ctx.r3.s64 + 12;
	// b 0x82c825a0
	sub_82C825A0(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C88CF0) {
	__imp__sub_82C88CF0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88CF8) {
	PPC_FUNC_PROLOGUE();
	// addi r3,r3,12
	ctx.r3.s64 = ctx.r3.s64 + 12;
	// b 0x82c824d8
	sub_82C824D8(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C88CF8) {
	__imp__sub_82C88CF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88D00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// stw r30,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r30.u32);
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// bl 0x82c823d8
	sub_82C823D8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// addi r4,r11,3224
	ctx.r4.s64 = r11.s64 + 3224;
	// bl 0x82c823d8
	sub_82C823D8(ctx, base);
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r30,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r30.u32);
	// stw r30,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r30.u32);
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// stw r30,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r30.u32);
	// stw r30,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C88D00) {
	__imp__sub_82C88D00(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88D78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// addi r11,r3,20
	r11.s64 = ctx.r3.s64 + 20;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c88db4
	if (cr6.eq) goto loc_82C88DB4;
	// stw r4,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r4.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r8,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r8.u32);
	// stw r9,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r9.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r4,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r4.u32);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// stw r3,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r3.u32);
	// blr 
	return;
loc_82C88DB4:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r4,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r4.u32);
	// stw r4,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r4.u32);
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// stw r10,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// stw r3,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r3.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C88D78) {
	__imp__sub_82C88D78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88DE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// bl 0x82ca2a08
	sub_82CA2A08(ctx, base);
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// addi r11,r31,32
	r11.s64 = r31.s64 + 32;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c88e30
	if (cr6.eq) goto loc_82C88E30;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r3,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r3.u32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r3,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r3.u32);
	// b 0x82c88e44
	goto loc_82C88E44;
loc_82C88E30:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r3,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r3.u32);
	// stw r3,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r3.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
loc_82C88E44:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C88DE0) {
	__imp__sub_82C88DE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88E68) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// lwz r31,32(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c88eb4
	if (cr6.eq) goto loc_82C88EB4;
loc_82C88E90:
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82caaf08
	sub_82CAAF08(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c88ed0
	if (cr6.eq) goto loc_82C88ED0;
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82c88e90
	if (!cr6.eq) goto loc_82C88E90;
loc_82C88EB4:
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c88de0
	sub_82C88DE0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C88ED0:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// bl 0x82c825a0
	sub_82C825A0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C88E68) {
	__imp__sub_82C88E68(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88EE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,32(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c88f30
	if (cr6.eq) goto loc_82C88F30;
loc_82C88F0C:
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82caaf08
	sub_82CAAF08(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c88f4c
	if (cr6.eq) goto loc_82C88F4C;
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82c88f0c
	if (!cr6.eq) goto loc_82C88F0C;
loc_82C88F30:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C88F34:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C88F4C:
	// addi r3,r31,12
	ctx.r3.s64 = r31.s64 + 12;
	// bl 0x82c81e58
	sub_82C81E58(ctx, base);
	// b 0x82c88f34
	goto loc_82C88F34;
}

PPC_WEAK_FUNC(sub_82C88EE8) {
	__imp__sub_82C88EE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88F58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r3,32(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
loc_82C88F68:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwz r3,4(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// blt cr6,0x82c88f68
	if (cr6.lt) goto loc_82C88F68;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C88F58) {
	__imp__sub_82C88F58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C88F88) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r31,r3,32
	r31.s64 = ctx.r3.s64 + 32;
	// lwz r3,32(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c8901c
	if (cr6.eq) goto loc_82C8901C;
	// li r30,0
	r30.s64 = 0;
loc_82C88FAC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// bne cr6,0x82c88fc4
	if (!cr6.eq) goto loc_82C88FC4;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x82c88fd0
	goto loc_82C88FD0;
loc_82C88FC4:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_82C88FD0:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// bne cr6,0x82c88fe8
	if (!cr6.eq) goto loc_82C88FE8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// b 0x82c88ff4
	goto loc_82C88FF4;
loc_82C88FE8:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_82C88FF4:
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r30.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// bl 0x82ca29f0
	sub_82CA29F0(ctx, base);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c88fac
	if (!cr6.eq) goto loc_82C88FAC;
loc_82C8901C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C88F88) {
	__imp__sub_82C88F88(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89028) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r31,0(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c89064
	if (cr6.eq) goto loc_82C89064;
loc_82C89044:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r30,4(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82ca29e8
	sub_82CA29E8(ctx, base);
	// mr r31,r30
	r31.u64 = r30.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82c89044
	if (!cr6.eq) goto loc_82C89044;
loc_82C89064:
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C89028) {
	__imp__sub_82C89028(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89080) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r27,0
	r27.s64 = 0;
	// lwz r31,0(r26)
	r31.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c890f8
	if (cr6.eq) goto loc_82C890F8;
loc_82C890A0:
	// lwz r30,32(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r28,4(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c890d0
	if (cr6.eq) goto loc_82C890D0;
loc_82C890B0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r29,4(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82ca29e8
	sub_82CA29E8(ctx, base);
	// mr r30,r29
	r30.u64 = r29.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x82c890b0
	if (!cr6.eq) goto loc_82C890B0;
loc_82C890D0:
	// stw r27,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r27.u32);
	// addi r3,r31,20
	ctx.r3.s64 = r31.s64 + 20;
	// stw r27,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r27.u32);
	// stw r27,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r27.u32);
	// bl 0x82c89080
	sub_82C89080(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c87a68
	sub_82C87A68(ctx, base);
	// mr r31,r28
	r31.u64 = r28.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82c890a0
	if (!cr6.eq) goto loc_82C890A0;
loc_82C890F8:
	// stw r27,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r27.u32);
	// stw r27,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r27.u32);
	// stw r27,8(r26)
	PPC_STORE_U32(r26.u32 + 8, r27.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C89080) {
	__imp__sub_82C89080(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89110) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,20(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// addi r29,r3,20
	r29.s64 = ctx.r3.s64 + 20;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c89200
	if (cr6.eq) goto loc_82C89200;
	// li r27,0
	r27.s64 = 0;
loc_82C89134:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c89110
	sub_82C89110(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bne cr6,0x82c89158
	if (!cr6.eq) goto loc_82C89158;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// b 0x82c89164
	goto loc_82C89164;
loc_82C89158:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_82C89164:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bne cr6,0x82c8917c
	if (!cr6.eq) goto loc_82C8917C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
	// b 0x82c89188
	goto loc_82C89188;
loc_82C8917C:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_82C89188:
	// stw r27,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r27.u32);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// stw r27,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r27.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// bl 0x82c88f88
	sub_82C88F88(ctx, base);
	// lwz r30,32(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c891d4
	if (cr6.eq) goto loc_82C891D4;
loc_82C891B4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r28,4(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x829ce870
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82ca29e8
	sub_82CA29E8(ctx, base);
	// mr r30,r28
	r30.u64 = r28.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82c891b4
	if (!cr6.eq) goto loc_82C891B4;
loc_82C891D4:
	// stw r27,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r27.u32);
	// addi r3,r31,20
	ctx.r3.s64 = r31.s64 + 20;
	// stw r27,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r27.u32);
	// stw r27,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r27.u32);
	// bl 0x82c89080
	sub_82C89080(ctx, base);
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,12(r26)
	PPC_STORE_U32(r26.u32 + 12, r11.u32);
	// lwz r31,0(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82c89134
	if (!cr6.eq) goto loc_82C89134;
loc_82C89200:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C89110) {
	__imp__sub_82C89110(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89208) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c89258
	if (cr6.eq) goto loc_82C89258;
	// bl 0x82c89110
	sub_82C89110(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c88f88
	sub_82C88F88(ctx, base);
	// addi r3,r31,32
	ctx.r3.s64 = r31.s64 + 32;
	// bl 0x82c89028
	sub_82C89028(ctx, base);
	// addi r3,r31,20
	ctx.r3.s64 = r31.s64 + 20;
	// bl 0x82c89080
	sub_82C89080(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
loc_82C89258:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C89208) {
	__imp__sub_82C89208(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89270) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// li r4,44
	ctx.r4.s64 = 44;
	// bl 0x82c82220
	sub_82C82220(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c892ac
	if (cr6.eq) goto loc_82C892AC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82c88d00
	sub_82C88D00(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82C892AC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C89270) {
	__imp__sub_82C89270(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C892C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32255
	r11.s64 = -2113863680;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,-5348
	ctx.r9.s64 = r11.s64 + -5348;
	// lwzx r3,r10,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C892C8) {
	__imp__sub_82C892C8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C892E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// addi r31,r11,-5348
	r31.s64 = r11.s64 + -5348;
loc_82C892FC:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82caaf80
	sub_82CAAF80(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8932c
	if (cr6.eq) goto loc_82C8932C;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi cr6,r30,7
	cr6.compare<uint32_t>(r30.u32, 7, xer);
	// blt cr6,0x82c892fc
	if (cr6.lt) goto loc_82C892FC;
	// li r3,6
	ctx.r3.s64 = 6;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C8932C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C892E0) {
	__imp__sub_82C892E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89338) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32255
	r11.s64 = -2113863680;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// lbz r9,1(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r11,r11,-4144
	r11.s64 = r11.s64 + -4144;
	// rlwinm r6,r10,30,29,31
	ctx.r6.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x7;
	// addi r5,r11,1536
	ctx.r5.s64 = r11.s64 + 1536;
	// clrlwi r4,r9,27
	ctx.r4.u64 = ctx.r9.u32 & 0x1F;
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// slw r7,r7,r4
	ctx.r7.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r3,r6,r5
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r6.u32 + ctx.r5.u32);
	// rotlwi r9,r3,2
	ctx.r9.u64 = rotl32(ctx.r3.u32, 2);
	// add r6,r9,r10
	ctx.r6.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r10,r6,1,0,30
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// add r5,r10,r8
	ctx.r5.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r4,r5,2,0,29
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r4,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + r11.u32);
	// and r3,r3,r7
	ctx.r3.u64 = ctx.r3.u64 & ctx.r7.u64;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C89338) {
	__imp__sub_82C89338(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89388) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lbz r8,1(r4)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lbz r6,0(r4)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r7,-4144
	r11.s64 = ctx.r7.s64 + -4144;
	// lbz r4,2(r4)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// rlwinm r9,r6,4,24,27
	ctx.r9.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xF0;
	// rlwinm r10,r8,30,28,31
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 30) & 0xF;
	// addi r3,r11,1536
	ctx.r3.s64 = r11.s64 + 1536;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// clrlwi r8,r8,30
	ctx.r8.u64 = ctx.r8.u32 & 0x3;
	// rlwinm r9,r4,27,31,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x1;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r6,r10,r3
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r3.u32);
	// slw r5,r5,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r7.u8 & 0x3F));
	// rotlwi r10,r6,2
	ctx.r10.u64 = rotl32(ctx.r6.u32, 2);
	// add r4,r10,r8
	ctx.r4.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r10,r4,1,0,30
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 1) & 0xFFFFFFFE;
	// add r3,r10,r9
	ctx.r3.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// and r3,r9,r5
	ctx.r3.u64 = ctx.r9.u64 & ctx.r5.u64;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C89388) {
	__imp__sub_82C89388(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C893E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32255
	r11.s64 = -2113863680;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// lbz r9,1(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r11,r11,-4144
	r11.s64 = r11.s64 + -4144;
	// rlwinm r6,r10,30,29,31
	ctx.r6.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x7;
	// addi r5,r11,1280
	ctx.r5.s64 = r11.s64 + 1280;
	// clrlwi r4,r9,27
	ctx.r4.u64 = ctx.r9.u32 & 0x1F;
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// slw r7,r7,r4
	ctx.r7.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r3,r6,r5
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r6.u32 + ctx.r5.u32);
	// rotlwi r9,r3,2
	ctx.r9.u64 = rotl32(ctx.r3.u32, 2);
	// add r6,r9,r10
	ctx.r6.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r10,r6,1,0,30
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// add r5,r10,r8
	ctx.r5.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r4,r5,2,0,29
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r4,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + r11.u32);
	// and r3,r3,r7
	ctx.r3.u64 = ctx.r3.u64 & ctx.r7.u64;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C893E8) {
	__imp__sub_82C893E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89438) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lbz r8,1(r4)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lbz r6,0(r4)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r7,-4144
	r11.s64 = ctx.r7.s64 + -4144;
	// lbz r4,2(r4)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// rlwinm r9,r6,4,24,27
	ctx.r9.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xF0;
	// rlwinm r10,r8,30,28,31
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 30) & 0xF;
	// addi r3,r11,1280
	ctx.r3.s64 = r11.s64 + 1280;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// clrlwi r8,r8,30
	ctx.r8.u64 = ctx.r8.u32 & 0x3;
	// rlwinm r9,r4,27,31,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x1;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r6,r10,r3
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r3.u32);
	// slw r5,r5,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r7.u8 & 0x3F));
	// rotlwi r10,r6,2
	ctx.r10.u64 = rotl32(ctx.r6.u32, 2);
	// add r4,r10,r8
	ctx.r4.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r10,r4,1,0,30
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 1) & 0xFFFFFFFE;
	// add r3,r10,r9
	ctx.r3.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// and r3,r9,r5
	ctx.r3.u64 = ctx.r9.u64 & ctx.r5.u64;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C89438) {
	__imp__sub_82C89438(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89498) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,194
	cr6.compare<uint32_t>(r11.u32, 194, xer);
	// blt cr6,0x82c894c4
	if (cr6.lt) goto loc_82C894C4;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c894c4
	if (cr6.eq) goto loc_82C894C4;
	// rlwinm r11,r11,0,24,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xC0;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r11,192
	cr6.compare<uint32_t>(r11.u32, 192, xer);
	// bnelr cr6
	if (!cr6.eq) return;
loc_82C894C4:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C89498) {
	__imp__sub_82C89498(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C894D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,2(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c89500
	if (cr6.eq) goto loc_82C89500;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r10,239
	cr6.compare<uint32_t>(ctx.r10.u32, 239, xer);
	// bne cr6,0x82c89508
	if (!cr6.eq) goto loc_82C89508;
	// lbz r9,1(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r9,191
	cr6.compare<uint32_t>(ctx.r9.u32, 191, xer);
	// bne cr6,0x82c89508
	if (!cr6.eq) goto loc_82C89508;
	// cmplwi cr6,r11,189
	cr6.compare<uint32_t>(r11.u32, 189, xer);
	// ble cr6,0x82c89520
	if (!cr6.gt) goto loc_82C89520;
loc_82C89500:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C89508:
	// rlwinm r11,r11,0,24,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xC0;
	// addi r11,r11,-192
	r11.s64 = r11.s64 + -192;
	// cntlzw r9,r11
	ctx.r9.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x82c89500
	if (!cr6.eq) goto loc_82C89500;
loc_82C89520:
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r10,224
	cr6.compare<uint32_t>(ctx.r10.u32, 224, xer);
	// bne cr6,0x82c89548
	if (!cr6.eq) goto loc_82C89548;
	// cmplwi cr6,r11,160
	cr6.compare<uint32_t>(r11.u32, 160, xer);
	// blt cr6,0x82c89500
	if (cr6.lt) goto loc_82C89500;
	// rlwinm r11,r11,0,24,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xC0;
	// cmplwi cr6,r11,192
	cr6.compare<uint32_t>(r11.u32, 192, xer);
	// bne cr6,0x82c89584
	if (!cr6.eq) goto loc_82C89584;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C89548:
	// rlwinm r9,r11,0,0,24
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c89500
	if (cr6.eq) goto loc_82C89500;
	// cmplwi cr6,r10,237
	cr6.compare<uint32_t>(ctx.r10.u32, 237, xer);
	// bne cr6,0x82c8956c
	if (!cr6.eq) goto loc_82C8956C;
	// cmplwi cr6,r11,159
	cr6.compare<uint32_t>(r11.u32, 159, xer);
	// bgt cr6,0x82c89500
	if (cr6.gt) goto loc_82C89500;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8956C:
	// rlwinm r11,r11,0,24,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xC0;
	// addi r11,r11,-192
	r11.s64 = r11.s64 + -192;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c89500
	if (!cr6.eq) goto loc_82C89500;
loc_82C89584:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C894D0) {
	__imp__sub_82C894D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89590) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,3(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c895ec
	if (cr6.eq) goto loc_82C895EC;
	// rlwinm r11,r11,0,24,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xC0;
	// cmplwi cr6,r11,192
	cr6.compare<uint32_t>(r11.u32, 192, xer);
	// beq cr6,0x82c895ec
	if (cr6.eq) goto loc_82C895EC;
	// lbz r11,2(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c895ec
	if (cr6.eq) goto loc_82C895EC;
	// rlwinm r11,r11,0,24,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xC0;
	// cmplwi cr6,r11,192
	cr6.compare<uint32_t>(r11.u32, 192, xer);
	// beq cr6,0x82c895ec
	if (cr6.eq) goto loc_82C895EC;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r10,240
	cr6.compare<uint32_t>(ctx.r10.u32, 240, xer);
	// bne cr6,0x82c895f4
	if (!cr6.eq) goto loc_82C895F4;
	// cmplwi cr6,r11,144
	cr6.compare<uint32_t>(r11.u32, 144, xer);
	// blt cr6,0x82c895ec
	if (cr6.lt) goto loc_82C895EC;
	// rlwinm r11,r11,0,24,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xC0;
	// cmplwi cr6,r11,192
	cr6.compare<uint32_t>(r11.u32, 192, xer);
	// bne cr6,0x82c89630
	if (!cr6.eq) goto loc_82C89630;
loc_82C895EC:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C895F4:
	// rlwinm r9,r11,0,0,24
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c895ec
	if (cr6.eq) goto loc_82C895EC;
	// cmplwi cr6,r10,244
	cr6.compare<uint32_t>(ctx.r10.u32, 244, xer);
	// bne cr6,0x82c89618
	if (!cr6.eq) goto loc_82C89618;
	// cmplwi cr6,r11,143
	cr6.compare<uint32_t>(r11.u32, 143, xer);
	// bgt cr6,0x82c895ec
	if (cr6.gt) goto loc_82C895EC;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C89618:
	// rlwinm r11,r11,0,24,25
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xC0;
	// addi r11,r11,-192
	r11.s64 = r11.s64 + -192;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c895ec
	if (!cr6.eq) goto loc_82C895EC;
loc_82C89630:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C89590) {
	__imp__sub_82C89590(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89638) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// cmplw cr6,r4,r28
	cr6.compare<uint32_t>(ctx.r4.u32, r28.u32, xer);
	// beq cr6,0x82c89804
	if (cr6.eq) goto loc_82C89804;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,45
	cr6.compare<uint32_t>(r11.u32, 45, xer);
	// beq cr6,0x82c89674
	if (cr6.eq) goto loc_82C89674;
	// stw r4,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C89674:
	// addi r31,r4,1
	r31.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c89804
	if (cr6.eq) goto loc_82C89804;
	// subf r30,r31,r28
	r30.s64 = r28.s64 - r31.s64;
loc_82C89684:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmplwi cr6,r11,27
	cr6.compare<uint32_t>(r11.u32, 27, xer);
	// bgt cr6,0x82c897f4
	if (cr6.gt) goto loc_82C897F4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-26960
	r12.s64 = r12.s64 + -26960;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8981C;
	case 1:
		goto loc_82C8981C;
	case 2:
		goto loc_82C897F4;
	case 3:
		goto loc_82C897F4;
	case 4:
		goto loc_82C897F4;
	case 5:
		goto loc_82C89720;
	case 6:
		goto loc_82C89750;
	case 7:
		goto loc_82C89780;
	case 8:
		goto loc_82C8981C;
	case 9:
		goto loc_82C897F4;
	case 10:
		goto loc_82C897F4;
	case 11:
		goto loc_82C897F4;
	case 12:
		goto loc_82C897F4;
	case 13:
		goto loc_82C897F4;
	case 14:
		goto loc_82C897F4;
	case 15:
		goto loc_82C897F4;
	case 16:
		goto loc_82C897F4;
	case 17:
		goto loc_82C897F4;
	case 18:
		goto loc_82C897F4;
	case 19:
		goto loc_82C897F4;
	case 20:
		goto loc_82C897F4;
	case 21:
		goto loc_82C897F4;
	case 22:
		goto loc_82C897F4;
	case 23:
		goto loc_82C897F4;
	case 24:
		goto loc_82C897F4;
	case 25:
		goto loc_82C897F4;
	case 26:
		goto loc_82C897F4;
	case 27:
		goto loc_82C897B0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-26596(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26596);
	// lwz r22,-26596(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26596);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26848(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26848);
	// lwz r22,-26800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26800);
	// lwz r22,-26752(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26752);
	// lwz r22,-26596(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26596);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26704(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26704);
loc_82C89720:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c89810
	if (cr6.lt) goto loc_82C89810;
	// lwz r11,356(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8981c
	if (!cr6.eq) goto loc_82C8981C;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c897fc
	goto loc_82C897FC;
loc_82C89750:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c89810
	if (cr6.lt) goto loc_82C89810;
	// lwz r11,360(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8981c
	if (!cr6.eq) goto loc_82C8981C;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c897fc
	goto loc_82C897FC;
loc_82C89780:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c89810
	if (cr6.lt) goto loc_82C89810;
	// lwz r11,364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8981c
	if (!cr6.eq) goto loc_82C8981C;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// b 0x82c897fc
	goto loc_82C897FC;
loc_82C897B0:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c89804
	if (cr6.eq) goto loc_82C89804;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,45
	cr6.compare<uint32_t>(r11.u32, 45, xer);
	// bne cr6,0x82c897fc
	if (!cr6.eq) goto loc_82C897FC;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x82c89804
	if (cr6.eq) goto loc_82C89804;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// beq cr6,0x82c8982c
	if (cr6.eq) goto loc_82C8982C;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C897F4:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
loc_82C897FC:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c89684
	if (!cr6.eq) goto loc_82C89684;
loc_82C89804:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C89810:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8981C:
	// stw r31,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8982C:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// li r3,13
	ctx.r3.s64 = 13;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C89638) {
	__imp__sub_82C89638(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89840) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c89850
	if (!cr6.eq) goto loc_82C89850;
loc_82C89848:
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
loc_82C89850:
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-20
	r11.s64 = r11.s64 + -20;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bgt cr6,0x82c89a0c
	if (cr6.gt) goto loc_82C89A0C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-26496
	r12.s64 = r12.s64 + -26496;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C898A8;
	case 1:
		goto loc_82C89A0C;
	case 2:
		goto loc_82C898B8;
	case 3:
		goto loc_82C89A0C;
	case 4:
		goto loc_82C898B8;
	case 5:
		goto loc_82C89A0C;
	case 6:
		goto loc_82C89A0C;
	case 7:
		goto loc_82C898A0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-26456(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26456);
	// lwz r22,-26100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26100);
	// lwz r22,-26440(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26440);
	// lwz r22,-26100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26100);
	// lwz r22,-26440(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26440);
	// lwz r22,-26100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26100);
	// lwz r22,-26100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26100);
	// lwz r22,-26464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26464);
loc_82C898A0:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c89638
	sub_82C89638(ctx, base);
	return;
loc_82C898A8:
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// li r3,33
	ctx.r3.s64 = 33;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// blr 
	return;
loc_82C898B8:
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c89848
	if (cr6.eq) goto loc_82C89848;
loc_82C898C4:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-9
	ctx.r10.s64 = ctx.r10.s64 + -9;
	// cmplwi cr6,r10,21
	cr6.compare<uint32_t>(ctx.r10.u32, 21, xer);
	// bgt cr6,0x82c899f4
	if (cr6.gt) goto loc_82C899F4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-26380
	r12.s64 = r12.s64 + -26380;
	// rlwinm r0,r10,2,0,29
	r0.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C89A00;
	case 1:
		goto loc_82C89A00;
	case 2:
		goto loc_82C899F4;
	case 3:
		goto loc_82C899F4;
	case 4:
		goto loc_82C899F4;
	case 5:
		goto loc_82C899F4;
	case 6:
		goto loc_82C899F4;
	case 7:
		goto loc_82C899F4;
	case 8:
		goto loc_82C899F4;
	case 9:
		goto loc_82C899F4;
	case 10:
		goto loc_82C899F4;
	case 11:
		goto loc_82C899F4;
	case 12:
		goto loc_82C89A00;
	case 13:
		goto loc_82C8994C;
	case 14:
		goto loc_82C899F4;
	case 15:
		goto loc_82C8994C;
	case 16:
		goto loc_82C899F4;
	case 17:
		goto loc_82C899F4;
	case 18:
		goto loc_82C899F4;
	case 19:
		goto loc_82C899F4;
	case 20:
		goto loc_82C899F4;
	case 21:
		goto loc_82C89960;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26292(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26292);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26292(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26292);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26272);
loc_82C8994C:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c898c4
	if (!cr6.eq) goto loc_82C898C4;
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
loc_82C89960:
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c89848
	if (cr6.eq) goto loc_82C89848;
	// lbz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-9
	ctx.r10.s64 = ctx.r10.s64 + -9;
	// cmplwi cr6,r10,21
	cr6.compare<uint32_t>(ctx.r10.u32, 21, xer);
	// bgt cr6,0x82c89a00
	if (cr6.gt) goto loc_82C89A00;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-26212
	r12.s64 = r12.s64 + -26212;
	// rlwinm r0,r10,2,0,29
	r0.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C899F4;
	case 1:
		goto loc_82C899F4;
	case 2:
		goto loc_82C89A00;
	case 3:
		goto loc_82C89A00;
	case 4:
		goto loc_82C89A00;
	case 5:
		goto loc_82C89A00;
	case 6:
		goto loc_82C89A00;
	case 7:
		goto loc_82C89A00;
	case 8:
		goto loc_82C89A00;
	case 9:
		goto loc_82C89A00;
	case 10:
		goto loc_82C89A00;
	case 11:
		goto loc_82C89A00;
	case 12:
		goto loc_82C899F4;
	case 13:
		goto loc_82C89A00;
	case 14:
		goto loc_82C89A00;
	case 15:
		goto loc_82C89A00;
	case 16:
		goto loc_82C89A00;
	case 17:
		goto loc_82C89A00;
	case 18:
		goto loc_82C89A00;
	case 19:
		goto loc_82C89A00;
	case 20:
		goto loc_82C89A00;
	case 21:
		goto loc_82C899F4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26124(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
loc_82C899F4:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C89A00:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,16
	ctx.r3.s64 = 16;
	// blr 
	return;
loc_82C89A0C:
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C89840) {
	__imp__sub_82C89840(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89A18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r11,11
	r11.s64 = 11;
	// subf r9,r4,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r4.s64;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// bne cr6,0x82c89aa8
	if (!cr6.eq) goto loc_82C89AA8;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,88
	cr6.compare<int32_t>(r11.s32, 88, xer);
	// beq cr6,0x82c89a50
	if (cr6.eq) goto loc_82C89A50;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// beq cr6,0x82c89a54
	if (cr6.eq) goto loc_82C89A54;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C89A50:
	// li r10,1
	ctx.r10.s64 = 1;
loc_82C89A54:
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,77
	cr6.compare<int32_t>(r11.s32, 77, xer);
	// beq cr6,0x82c89a74
	if (cr6.eq) goto loc_82C89A74;
	// cmpwi cr6,r11,109
	cr6.compare<int32_t>(r11.s32, 109, xer);
	// beq cr6,0x82c89a78
	if (cr6.eq) goto loc_82C89A78;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C89A74:
	// li r10,1
	ctx.r10.s64 = 1;
loc_82C89A78:
	// lbz r11,2(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,76
	cr6.compare<int32_t>(r11.s32, 76, xer);
	// beq cr6,0x82c89a98
	if (cr6.eq) goto loc_82C89A98;
	// cmpwi cr6,r11,108
	cr6.compare<int32_t>(r11.s32, 108, xer);
	// bne cr6,0x82c89aa8
	if (!cr6.eq) goto loc_82C89AA8;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x82c89aa0
	if (cr6.eq) goto loc_82C89AA0;
loc_82C89A98:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C89AA0:
	// li r11,12
	r11.s64 = 12;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
loc_82C89AA8:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C89A18) {
	__imp__sub_82C89A18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89AB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r28,r31
	r28.u64 = r31.u64;
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// bne cr6,0x82c89ae4
	if (!cr6.eq) goto loc_82C89AE4;
loc_82C89AD8:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C89AE4:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c89f0c
	if (cr6.gt) goto loc_82C89F0C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-25836
	r12.s64 = r12.s64 + -25836;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C89B80;
	case 1:
		goto loc_82C89BBC;
	case 2:
		goto loc_82C89BEC;
	case 3:
		goto loc_82C89F0C;
	case 4:
		goto loc_82C89F0C;
	case 5:
		goto loc_82C89F0C;
	case 6:
		goto loc_82C89F0C;
	case 7:
		goto loc_82C89F0C;
	case 8:
		goto loc_82C89F0C;
	case 9:
		goto loc_82C89F0C;
	case 10:
		goto loc_82C89F0C;
	case 11:
		goto loc_82C89F0C;
	case 12:
		goto loc_82C89F0C;
	case 13:
		goto loc_82C89F0C;
	case 14:
		goto loc_82C89F0C;
	case 15:
		goto loc_82C89F0C;
	case 16:
		goto loc_82C89F0C;
	case 17:
		goto loc_82C89B78;
	case 18:
		goto loc_82C89F0C;
	case 19:
		goto loc_82C89B78;
	case 20:
		goto loc_82C89F0C;
	case 21:
		goto loc_82C89F0C;
	case 22:
		goto loc_82C89F0C;
	case 23:
		goto loc_82C89F0C;
	case 24:
		goto loc_82C89F0C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-25728(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25728);
	// lwz r22,-25668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25668);
	// lwz r22,-25620(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25620);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-25736(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25736);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-25736(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25736);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
loc_82C89B78:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// b 0x82c89c18
	goto loc_82C89C18;
loc_82C89B80:
	// subf r11,r31,r27
	r11.s64 = r27.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c89b98
	if (!cr6.lt) goto loc_82C89B98;
loc_82C89B8C:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C89B98:
	// lwz r11,344(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c89f0c
	if (cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c89c18
	goto loc_82C89C18;
loc_82C89BBC:
	// subf r11,r31,r27
	r11.s64 = r27.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c89b8c
	if (cr6.lt) goto loc_82C89B8C;
	// lwz r11,348(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c89f0c
	if (cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c89c18
	goto loc_82C89C18;
loc_82C89BEC:
	// subf r11,r31,r27
	r11.s64 = r27.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c89b8c
	if (cr6.lt) goto loc_82C89B8C;
	// lwz r11,352(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c89f0c
	if (cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_82C89C18:
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// beq cr6,0x82c89ad8
	if (cr6.eq) goto loc_82C89AD8;
	// subf r30,r31,r27
	r30.s64 = r27.s64 - r31.s64;
loc_82C89C24:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c89f0c
	if (cr6.gt) goto loc_82C89F0C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-25516
	r12.s64 = r12.s64 + -25516;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C89CC4;
	case 1:
		goto loc_82C89CF4;
	case 2:
		goto loc_82C89D24;
	case 3:
		goto loc_82C89F0C;
	case 4:
		goto loc_82C89D64;
	case 5:
		goto loc_82C89D64;
	case 6:
		goto loc_82C89F0C;
	case 7:
		goto loc_82C89F0C;
	case 8:
		goto loc_82C89F0C;
	case 9:
		goto loc_82C89F0C;
	case 10:
		goto loc_82C89ED8;
	case 11:
		goto loc_82C89F0C;
	case 12:
		goto loc_82C89F0C;
	case 13:
		goto loc_82C89F0C;
	case 14:
		goto loc_82C89F0C;
	case 15:
		goto loc_82C89F0C;
	case 16:
		goto loc_82C89D64;
	case 17:
		goto loc_82C89CB8;
	case 18:
		goto loc_82C89F0C;
	case 19:
		goto loc_82C89CB8;
	case 20:
		goto loc_82C89CB8;
	case 21:
		goto loc_82C89CB8;
	case 22:
		goto loc_82C89CB8;
	case 23:
		goto loc_82C89F0C;
	case 24:
		goto loc_82C89F0C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-25404(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25404);
	// lwz r22,-25356(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25356);
	// lwz r22,-25308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25308);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-25244(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25244);
	// lwz r22,-25244(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25244);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24872(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24872);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-25244(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25244);
	// lwz r22,-25416(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25416);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-25416(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25416);
	// lwz r22,-25416(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25416);
	// lwz r22,-25416(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25416);
	// lwz r22,-25416(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25416);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
loc_82C89CB8:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// b 0x82c89d50
	goto loc_82C89D50;
loc_82C89CC4:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c89b8c
	if (cr6.lt) goto loc_82C89B8C;
	// lwz r11,332(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c89f0c
	if (cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c89d50
	goto loc_82C89D50;
loc_82C89CF4:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c89b8c
	if (cr6.lt) goto loc_82C89B8C;
	// lwz r11,336(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c89f0c
	if (cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c89d50
	goto loc_82C89D50;
loc_82C89D24:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c89b8c
	if (cr6.lt) goto loc_82C89B8C;
	// lwz r11,340(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c89f0c
	if (cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
loc_82C89D50:
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// bne cr6,0x82c89c24
	if (!cr6.eq) goto loc_82C89C24;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C89D64:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c89a18
	sub_82C89A18(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c89f0c
	if (cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// beq cr6,0x82c89ad8
	if (cr6.eq) goto loc_82C89AD8;
	// subf r30,r31,r27
	r30.s64 = r27.s64 - r31.s64;
loc_82C89D90:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmplwi cr6,r11,15
	cr6.compare<uint32_t>(r11.u32, 15, xer);
	// bgt cr6,0x82c89ebc
	if (cr6.gt) goto loc_82C89EBC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-25156
	r12.s64 = r12.s64 + -25156;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C89F0C;
	case 1:
		goto loc_82C89F0C;
	case 2:
		goto loc_82C89EBC;
	case 3:
		goto loc_82C89EBC;
	case 4:
		goto loc_82C89EBC;
	case 5:
		goto loc_82C89DFC;
	case 6:
		goto loc_82C89E2C;
	case 7:
		goto loc_82C89E5C;
	case 8:
		goto loc_82C89F0C;
	case 9:
		goto loc_82C89EBC;
	case 10:
		goto loc_82C89EBC;
	case 11:
		goto loc_82C89EBC;
	case 12:
		goto loc_82C89EBC;
	case 13:
		goto loc_82C89EBC;
	case 14:
		goto loc_82C89EBC;
	case 15:
		goto loc_82C89E8C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24900(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-25092(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25092);
	// lwz r22,-25044(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25044);
	// lwz r22,-24996(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24996);
	// lwz r22,-24820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24900(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24948(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24948);
loc_82C89DFC:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c89b8c
	if (cr6.lt) goto loc_82C89B8C;
	// lwz r11,356(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c89f0c
	if (!cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c89ec4
	goto loc_82C89EC4;
loc_82C89E2C:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c89b8c
	if (cr6.lt) goto loc_82C89B8C;
	// lwz r11,360(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c89f0c
	if (!cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c89ec4
	goto loc_82C89EC4;
loc_82C89E5C:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c89b8c
	if (cr6.lt) goto loc_82C89B8C;
	// lwz r11,364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c89f0c
	if (!cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// b 0x82c89ec4
	goto loc_82C89EC4;
loc_82C89E8C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// beq cr6,0x82c89ad8
	if (cr6.eq) goto loc_82C89AD8;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// bne cr6,0x82c89ec4
	if (!cr6.eq) goto loc_82C89EC4;
loc_82C89EA8:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C89EBC:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
loc_82C89EC4:
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// bne cr6,0x82c89d90
	if (!cr6.eq) goto loc_82C89D90;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C89ED8:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c89a18
	sub_82C89A18(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c89f0c
	if (cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// beq cr6,0x82c89ad8
	if (cr6.eq) goto loc_82C89AD8;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// beq cr6,0x82c89ea8
	if (cr6.eq) goto loc_82C89EA8;
loc_82C89F0C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C89AB0) {
	__imp__sub_82C89AB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C89F20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c89f50
	if (!cr6.eq) goto loc_82C89F50;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C89F50:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bgt cr6,0x82c8a0f4
	if (cr6.gt) goto loc_82C8A0F4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-24708
	r12.s64 = r12.s64 + -24708;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8A07C;
	case 1:
		goto loc_82C8A07C;
	case 2:
		goto loc_82C8A0F4;
	case 3:
		goto loc_82C8A0F4;
	case 4:
		goto loc_82C89FA8;
	case 5:
		goto loc_82C8A048;
	case 6:
		goto loc_82C8A094;
	case 7:
		goto loc_82C8A0C4;
	case 8:
		goto loc_82C8A07C;
	case 9:
		goto loc_82C8A000;
	case 10:
		goto loc_82C8A034;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-24452(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24452);
	// lwz r22,-24452(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24452);
	// lwz r22,-24332(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24332);
	// lwz r22,-24332(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24332);
	// lwz r22,-24664(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24664);
	// lwz r22,-24504(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24504);
	// lwz r22,-24428(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24428);
	// lwz r22,-24380(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24380);
	// lwz r22,-24452(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24452);
	// lwz r22,-24576(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24576);
	// lwz r22,-24524(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24524);
loc_82C89FA8:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c89fc0
	if (!cr6.eq) goto loc_82C89FC0;
loc_82C89FB4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C89FC0:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c8a0f8
	if (!cr6.eq) goto loc_82C8A0F8;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x82c89fb4
	if (cr6.eq) goto loc_82C89FB4;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// beq cr6,0x82c89fec
	if (cr6.eq) goto loc_82C89FEC;
	// addi r31,r11,-1
	r31.s64 = r11.s64 + -1;
	// b 0x82c8a0f8
	goto loc_82C8A0F8;
loc_82C89FEC:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// li r3,40
	ctx.r3.s64 = 40;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A000:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x82c89fb4
	if (cr6.eq) goto loc_82C89FB4;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + r29.u64;
	// lbz r9,76(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmplwi cr6,r9,10
	cr6.compare<uint32_t>(ctx.r9.u32, 10, xer);
	// bne cr6,0x82c8a024
	if (!cr6.eq) goto loc_82C8A024;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_82C8A024:
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// li r3,7
	ctx.r3.s64 = 7;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A034:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A048:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8a060
	if (!cr6.lt) goto loc_82C8A060;
loc_82C8A054:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A060:
	// lwz r11,356(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a08c
	if (cr6.eq) goto loc_82C8A08C;
loc_82C8A07C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A08C:
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c8a0f8
	goto loc_82C8A0F8;
loc_82C8A094:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8a054
	if (cr6.lt) goto loc_82C8A054;
	// lwz r11,360(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8a07c
	if (!cr6.eq) goto loc_82C8A07C;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c8a0f8
	goto loc_82C8A0F8;
loc_82C8A0C4:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8a054
	if (cr6.lt) goto loc_82C8A054;
	// lwz r11,364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8a07c
	if (!cr6.eq) goto loc_82C8A07C;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// b 0x82c8a0f8
	goto loc_82C8A0F8;
loc_82C8A0F4:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_82C8A0F8:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8a1fc
	if (cr6.eq) goto loc_82C8A1FC;
	// subf r30,r31,r28
	r30.s64 = r28.s64 - r31.s64;
loc_82C8A104:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bgt cr6,0x82c8a1ec
	if (cr6.gt) goto loc_82C8A1EC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-24272
	r12.s64 = r12.s64 + -24272;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8A1FC;
	case 1:
		goto loc_82C8A1FC;
	case 2:
		goto loc_82C8A1EC;
	case 3:
		goto loc_82C8A1EC;
	case 4:
		goto loc_82C8A1FC;
	case 5:
		goto loc_82C8A15C;
	case 6:
		goto loc_82C8A18C;
	case 7:
		goto loc_82C8A1BC;
	case 8:
		goto loc_82C8A1FC;
	case 9:
		goto loc_82C8A1FC;
	case 10:
		goto loc_82C8A1FC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-24068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
	// lwz r22,-24068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
	// lwz r22,-24084(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24084);
	// lwz r22,-24084(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24084);
	// lwz r22,-24068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
	// lwz r22,-24228(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24228);
	// lwz r22,-24180(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24180);
	// lwz r22,-24132(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24132);
	// lwz r22,-24068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
	// lwz r22,-24068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
	// lwz r22,-24068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
loc_82C8A15C:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c8a1fc
	if (cr6.lt) goto loc_82C8A1FC;
	// lwz r11,356(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8a1fc
	if (!cr6.eq) goto loc_82C8A1FC;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c8a1f4
	goto loc_82C8A1F4;
loc_82C8A18C:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c8a1fc
	if (cr6.lt) goto loc_82C8A1FC;
	// lwz r11,360(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8a1fc
	if (!cr6.eq) goto loc_82C8A1FC;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c8a1f4
	goto loc_82C8A1F4;
loc_82C8A1BC:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c8a1fc
	if (cr6.lt) goto loc_82C8A1FC;
	// lwz r11,364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8a1fc
	if (!cr6.eq) goto loc_82C8A1FC;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// b 0x82c8a1f4
	goto loc_82C8A1F4;
loc_82C8A1EC:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
loc_82C8A1F4:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8a104
	if (!cr6.eq) goto loc_82C8A104;
loc_82C8A1FC:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r31,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C89F20) {
	__imp__sub_82C89F20(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8A210) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8a240
	if (!cr6.eq) goto loc_82C8A240;
loc_82C8A234:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A240:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8a580
	if (cr6.gt) goto loc_82C8A580;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-23952
	r12.s64 = r12.s64 + -23952;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8A2DC;
	case 1:
		goto loc_82C8A318;
	case 2:
		goto loc_82C8A348;
	case 3:
		goto loc_82C8A580;
	case 4:
		goto loc_82C8A580;
	case 5:
		goto loc_82C8A580;
	case 6:
		goto loc_82C8A580;
	case 7:
		goto loc_82C8A580;
	case 8:
		goto loc_82C8A580;
	case 9:
		goto loc_82C8A580;
	case 10:
		goto loc_82C8A580;
	case 11:
		goto loc_82C8A580;
	case 12:
		goto loc_82C8A580;
	case 13:
		goto loc_82C8A580;
	case 14:
		goto loc_82C8A580;
	case 15:
		goto loc_82C8A580;
	case 16:
		goto loc_82C8A580;
	case 17:
		goto loc_82C8A2D4;
	case 18:
		goto loc_82C8A580;
	case 19:
		goto loc_82C8A2D4;
	case 20:
		goto loc_82C8A580;
	case 21:
		goto loc_82C8A580;
	case 22:
		goto loc_82C8A580;
	case 23:
		goto loc_82C8A580;
	case 24:
		goto loc_82C8A580;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-23844(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23844);
	// lwz r22,-23784(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23784);
	// lwz r22,-23736(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23736);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23852(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23852);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23852(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23852);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
loc_82C8A2D4:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// b 0x82c8a374
	goto loc_82C8A374;
loc_82C8A2DC:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8a2f4
	if (!cr6.lt) goto loc_82C8A2F4;
loc_82C8A2E8:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A2F4:
	// lwz r11,344(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a580
	if (cr6.eq) goto loc_82C8A580;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c8a374
	goto loc_82C8A374;
loc_82C8A318:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8a2e8
	if (cr6.lt) goto loc_82C8A2E8;
	// lwz r11,348(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a580
	if (cr6.eq) goto loc_82C8A580;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c8a374
	goto loc_82C8A374;
loc_82C8A348:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8a2e8
	if (cr6.lt) goto loc_82C8A2E8;
	// lwz r11,352(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a580
	if (cr6.eq) goto loc_82C8A580;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_82C8A374:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8a234
	if (cr6.eq) goto loc_82C8A234;
	// subf r30,r31,r28
	r30.s64 = r28.s64 - r31.s64;
loc_82C8A380:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8a580
	if (cr6.gt) goto loc_82C8A580;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-23632
	r12.s64 = r12.s64 + -23632;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8A414;
	case 1:
		goto loc_82C8A444;
	case 2:
		goto loc_82C8A474;
	case 3:
		goto loc_82C8A580;
	case 4:
		goto loc_82C8A4C0;
	case 5:
		goto loc_82C8A4C0;
	case 6:
		goto loc_82C8A56C;
	case 7:
		goto loc_82C8A580;
	case 8:
		goto loc_82C8A580;
	case 9:
		goto loc_82C8A580;
	case 10:
		goto loc_82C8A580;
	case 11:
		goto loc_82C8A580;
	case 12:
		goto loc_82C8A580;
	case 13:
		goto loc_82C8A580;
	case 14:
		goto loc_82C8A580;
	case 15:
		goto loc_82C8A580;
	case 16:
		goto loc_82C8A4C0;
	case 17:
		goto loc_82C8A4A4;
	case 18:
		goto loc_82C8A4A4;
	case 19:
		goto loc_82C8A4A4;
	case 20:
		goto loc_82C8A4A4;
	case 21:
		goto loc_82C8A4A4;
	case 22:
		goto loc_82C8A4A4;
	case 23:
		goto loc_82C8A580;
	case 24:
		goto loc_82C8A580;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-23532(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23532);
	// lwz r22,-23484(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23484);
	// lwz r22,-23436(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23436);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23360(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23360);
	// lwz r22,-23360(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23360);
	// lwz r22,-23188(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23188);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23360(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23360);
	// lwz r22,-23388(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23388(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23388(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23388(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23388(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23388(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
loc_82C8A414:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c8a2e8
	if (cr6.lt) goto loc_82C8A2E8;
	// lwz r11,332(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a580
	if (cr6.eq) goto loc_82C8A580;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c8a4ac
	goto loc_82C8A4AC;
loc_82C8A444:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c8a2e8
	if (cr6.lt) goto loc_82C8A2E8;
	// lwz r11,336(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a580
	if (cr6.eq) goto loc_82C8A580;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c8a4ac
	goto loc_82C8A4AC;
loc_82C8A474:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c8a2e8
	if (cr6.lt) goto loc_82C8A2E8;
	// lwz r11,340(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a580
	if (cr6.eq) goto loc_82C8A580;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// b 0x82c8a4ac
	goto loc_82C8A4AC;
loc_82C8A4A4:
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_82C8A4AC:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8a380
	if (!cr6.eq) goto loc_82C8A380;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A4C0:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x82c8a234
	if (cr6.eq) goto loc_82C8A234;
loc_82C8A4CC:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + r29.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-9
	ctx.r10.s64 = ctx.r10.s64 + -9;
	// cmplwi cr6,r10,12
	cr6.compare<uint32_t>(ctx.r10.u32, 12, xer);
	// bgt cr6,0x82c8a55c
	if (cr6.gt) goto loc_82C8A55C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-23300
	r12.s64 = r12.s64 + -23300;
	// rlwinm r0,r10,2,0,29
	r0.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C8A530;
	case 1:
		goto loc_82C8A530;
	case 2:
		goto loc_82C8A548;
	case 3:
		goto loc_82C8A55C;
	case 4:
		goto loc_82C8A55C;
	case 5:
		goto loc_82C8A55C;
	case 6:
		goto loc_82C8A55C;
	case 7:
		goto loc_82C8A55C;
	case 8:
		goto loc_82C8A55C;
	case 9:
		goto loc_82C8A55C;
	case 10:
		goto loc_82C8A55C;
	case 11:
		goto loc_82C8A55C;
	case 12:
		goto loc_82C8A530;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-23248(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23248);
	// lwz r22,-23248(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23248);
	// lwz r22,-23224(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23224);
	// lwz r22,-23204(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23248(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23248);
loc_82C8A530:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x82c8a4cc
	if (!cr6.eq) goto loc_82C8A4CC;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A548:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// li r3,5
	ctx.r3.s64 = 5;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A55C:
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A56C:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,5
	ctx.r3.s64 = 5;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A580:
	// stw r31,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C8A210) {
	__imp__sub_82C8A210(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8A590) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8a608
	if (cr6.eq) goto loc_82C8A608;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,120
	cr6.compare<uint32_t>(r11.u32, 120, xer);
	// bne cr6,0x82c8a61c
	if (!cr6.eq) goto loc_82C8A61C;
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8a608
	if (cr6.eq) goto loc_82C8A608;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmpwi cr6,r10,24
	cr6.compare<int32_t>(ctx.r10.s32, 24, xer);
	// blt cr6,0x82c8a610
	if (cr6.lt) goto loc_82C8A610;
	// cmpwi cr6,r10,25
	cr6.compare<int32_t>(ctx.r10.s32, 25, xer);
	// bgt cr6,0x82c8a610
	if (cr6.gt) goto loc_82C8A610;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8a608
	if (cr6.eq) goto loc_82C8A608;
loc_82C8A5D8:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmpwi cr6,r10,18
	cr6.compare<int32_t>(ctx.r10.s32, 18, xer);
	// beq cr6,0x82c8a684
	if (cr6.eq) goto loc_82C8A684;
	// cmpwi cr6,r10,23
	cr6.compare<int32_t>(ctx.r10.s32, 23, xer);
	// ble cr6,0x82c8a678
	if (!cr6.gt) goto loc_82C8A678;
	// cmpwi cr6,r10,25
	cr6.compare<int32_t>(ctx.r10.s32, 25, xer);
	// bgt cr6,0x82c8a678
	if (cr6.gt) goto loc_82C8A678;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8a5d8
	if (!cr6.eq) goto loc_82C8A5D8;
loc_82C8A608:
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
loc_82C8A610:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// blr 
	return;
loc_82C8A61C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lbz r10,76(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmplwi cr6,r10,25
	cr6.compare<uint32_t>(ctx.r10.u32, 25, xer);
	// beq cr6,0x82c8a63c
	if (cr6.eq) goto loc_82C8A63C;
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8A63C:
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8a608
	if (cr6.eq) goto loc_82C8A608;
loc_82C8A648:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmpwi cr6,r10,18
	cr6.compare<int32_t>(ctx.r10.s32, 18, xer);
	// beq cr6,0x82c8a684
	if (cr6.eq) goto loc_82C8A684;
	// cmpwi cr6,r10,25
	cr6.compare<int32_t>(ctx.r10.s32, 25, xer);
	// bne cr6,0x82c8a678
	if (!cr6.eq) goto loc_82C8A678;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8a648
	if (!cr6.eq) goto loc_82C8A648;
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
loc_82C8A678:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8A684:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8A590) {
	__imp__sub_82C8A590(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8A698) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8a6c8
	if (!cr6.eq) goto loc_82C8A6C8;
loc_82C8A6BC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A6C8:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8a978
	if (cr6.gt) goto loc_82C8A978;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-22792
	r12.s64 = r12.s64 + -22792;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8A764;
	case 1:
		goto loc_82C8A7A0;
	case 2:
		goto loc_82C8A7D0;
	case 3:
		goto loc_82C8A978;
	case 4:
		goto loc_82C8A978;
	case 5:
		goto loc_82C8A978;
	case 6:
		goto loc_82C8A978;
	case 7:
		goto loc_82C8A978;
	case 8:
		goto loc_82C8A978;
	case 9:
		goto loc_82C8A978;
	case 10:
		goto loc_82C8A978;
	case 11:
		goto loc_82C8A978;
	case 12:
		goto loc_82C8A978;
	case 13:
		goto loc_82C8A978;
	case 14:
		goto loc_82C8A95C;
	case 15:
		goto loc_82C8A978;
	case 16:
		goto loc_82C8A978;
	case 17:
		goto loc_82C8A75C;
	case 18:
		goto loc_82C8A978;
	case 19:
		goto loc_82C8A75C;
	case 20:
		goto loc_82C8A978;
	case 21:
		goto loc_82C8A978;
	case 22:
		goto loc_82C8A978;
	case 23:
		goto loc_82C8A978;
	case 24:
		goto loc_82C8A978;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-22684(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22684);
	// lwz r22,-22624(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22624);
	// lwz r22,-22576(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22576);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22180(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22180);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22692(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22692);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22692(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22692);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
loc_82C8A75C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// b 0x82c8a7fc
	goto loc_82C8A7FC;
loc_82C8A764:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8a77c
	if (!cr6.lt) goto loc_82C8A77C;
loc_82C8A770:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A77C:
	// lwz r11,344(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a978
	if (cr6.eq) goto loc_82C8A978;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c8a7fc
	goto loc_82C8A7FC;
loc_82C8A7A0:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8a770
	if (cr6.lt) goto loc_82C8A770;
	// lwz r11,348(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a978
	if (cr6.eq) goto loc_82C8A978;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c8a7fc
	goto loc_82C8A7FC;
loc_82C8A7D0:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8a770
	if (cr6.lt) goto loc_82C8A770;
	// lwz r11,352(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a978
	if (cr6.eq) goto loc_82C8A978;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_82C8A7FC:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8a6bc
	if (cr6.eq) goto loc_82C8A6BC;
	// subf r30,r31,r28
	r30.s64 = r28.s64 - r31.s64;
loc_82C8A808:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8a978
	if (cr6.gt) goto loc_82C8A978;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-22472
	r12.s64 = r12.s64 + -22472;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8A8A8;
	case 1:
		goto loc_82C8A8D8;
	case 2:
		goto loc_82C8A908;
	case 3:
		goto loc_82C8A978;
	case 4:
		goto loc_82C8A978;
	case 5:
		goto loc_82C8A978;
	case 6:
		goto loc_82C8A978;
	case 7:
		goto loc_82C8A978;
	case 8:
		goto loc_82C8A978;
	case 9:
		goto loc_82C8A978;
	case 10:
		goto loc_82C8A978;
	case 11:
		goto loc_82C8A978;
	case 12:
		goto loc_82C8A978;
	case 13:
		goto loc_82C8A948;
	case 14:
		goto loc_82C8A978;
	case 15:
		goto loc_82C8A978;
	case 16:
		goto loc_82C8A978;
	case 17:
		goto loc_82C8A89C;
	case 18:
		goto loc_82C8A978;
	case 19:
		goto loc_82C8A89C;
	case 20:
		goto loc_82C8A89C;
	case 21:
		goto loc_82C8A89C;
	case 22:
		goto loc_82C8A89C;
	case 23:
		goto loc_82C8A978;
	case 24:
		goto loc_82C8A978;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-22360(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22360);
	// lwz r22,-22312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22312);
	// lwz r22,-22264(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22264);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22200(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22200);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22372(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22372);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22372(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22372);
	// lwz r22,-22372(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22372);
	// lwz r22,-22372(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22372);
	// lwz r22,-22372(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22372);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
loc_82C8A89C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// b 0x82c8a934
	goto loc_82C8A934;
loc_82C8A8A8:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c8a770
	if (cr6.lt) goto loc_82C8A770;
	// lwz r11,332(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a978
	if (cr6.eq) goto loc_82C8A978;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c8a934
	goto loc_82C8A934;
loc_82C8A8D8:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c8a770
	if (cr6.lt) goto loc_82C8A770;
	// lwz r11,336(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a978
	if (cr6.eq) goto loc_82C8A978;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c8a934
	goto loc_82C8A934;
loc_82C8A908:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c8a770
	if (cr6.lt) goto loc_82C8A770;
	// lwz r11,340(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8a978
	if (cr6.eq) goto loc_82C8A978;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
loc_82C8A934:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8a808
	if (!cr6.eq) goto loc_82C8A808;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A948:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,9
	ctx.r3.s64 = 9;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A95C:
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8a590
	sub_82C8A590(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8A978:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C8A698) {
	__imp__sub_82C8A698(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8A988) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// li r27,0
	r27.s64 = 0;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8aec8
	if (cr6.eq) goto loc_82C8AEC8;
loc_82C8A9B0:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8ab9c
	if (cr6.gt) goto loc_82C8AB9C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-22048
	r12.s64 = r12.s64 + -22048;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8AA44;
	case 1:
		goto loc_82C8AA74;
	case 2:
		goto loc_82C8AAA4;
	case 3:
		goto loc_82C8AB9C;
	case 4:
		goto loc_82C8AB64;
	case 5:
		goto loc_82C8AB64;
	case 6:
		goto loc_82C8AB9C;
	case 7:
		goto loc_82C8AB9C;
	case 8:
		goto loc_82C8AB9C;
	case 9:
		goto loc_82C8ABAC;
	case 10:
		goto loc_82C8AB9C;
	case 11:
		goto loc_82C8AB9C;
	case 12:
		goto loc_82C8AB9C;
	case 13:
		goto loc_82C8AB9C;
	case 14:
		goto loc_82C8AB9C;
	case 15:
		goto loc_82C8AB9C;
	case 16:
		goto loc_82C8AB64;
	case 17:
		goto loc_82C8AE2C;
	case 18:
		goto loc_82C8AAB8;
	case 19:
		goto loc_82C8AE2C;
	case 20:
		goto loc_82C8AE2C;
	case 21:
		goto loc_82C8AE2C;
	case 22:
		goto loc_82C8AE2C;
	case 23:
		goto loc_82C8AB9C;
	case 24:
		goto loc_82C8AB9C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-21948(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21948);
	// lwz r22,-21900(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21900);
	// lwz r22,-21852(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21852);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21660(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21660);
	// lwz r22,-21660(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21660);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21588(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21588);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21660(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21660);
	// lwz r22,-20948(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21832(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21832);
	// lwz r22,-20948(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-20948(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-20948(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-20948(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
loc_82C8AA44:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// blt cr6,0x82c8aed4
	if (cr6.lt) goto loc_82C8AED4;
	// lwz r11,332(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8ab9c
	if (cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c8aec0
	goto loc_82C8AEC0;
loc_82C8AA74:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8aed4
	if (cr6.lt) goto loc_82C8AED4;
	// lwz r11,336(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8ab9c
	if (cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c8aec0
	goto loc_82C8AEC0;
loc_82C8AAA4:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8aed4
	if (cr6.lt) goto loc_82C8AED4;
	// lwz r11,340(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 340);
	// b 0x82c8aea4
	goto loc_82C8AEA4;
loc_82C8AAB8:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x82c8ab9c
	if (!cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// li r27,1
	r27.s64 = 1;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8aec8
	if (cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8ab9c
	if (cr6.gt) goto loc_82C8AB9C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-21760
	r12.s64 = r12.s64 + -21760;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8AE34;
	case 1:
		goto loc_82C8AE64;
	case 2:
		goto loc_82C8AE94;
	case 3:
		goto loc_82C8AB9C;
	case 4:
		goto loc_82C8AB9C;
	case 5:
		goto loc_82C8AB9C;
	case 6:
		goto loc_82C8AB9C;
	case 7:
		goto loc_82C8AB9C;
	case 8:
		goto loc_82C8AB9C;
	case 9:
		goto loc_82C8AB9C;
	case 10:
		goto loc_82C8AB9C;
	case 11:
		goto loc_82C8AB9C;
	case 12:
		goto loc_82C8AB9C;
	case 13:
		goto loc_82C8AB9C;
	case 14:
		goto loc_82C8AB9C;
	case 15:
		goto loc_82C8AB9C;
	case 16:
		goto loc_82C8AB9C;
	case 17:
		goto loc_82C8AE2C;
	case 18:
		goto loc_82C8AB9C;
	case 19:
		goto loc_82C8AE2C;
	case 20:
		goto loc_82C8AB9C;
	case 21:
		goto loc_82C8AB9C;
	case 22:
		goto loc_82C8AB9C;
	case 23:
		goto loc_82C8AB9C;
	case 24:
		goto loc_82C8AB9C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-20940(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20940);
	// lwz r22,-20892(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20892);
	// lwz r22,-20844(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20844);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-20948(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-20948(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
loc_82C8AB64:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8aec8
	if (cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x82c8abac
	if (cr6.eq) goto loc_82C8ABAC;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// blt cr6,0x82c8ab9c
	if (cr6.lt) goto loc_82C8AB9C;
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// ble cr6,0x82c8ab64
	if (!cr6.gt) goto loc_82C8AB64;
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// beq cr6,0x82c8ab64
	if (cr6.eq) goto loc_82C8AB64;
loc_82C8AB9C:
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8ABAC:
	// li r27,0
	r27.s64 = 0;
loc_82C8ABB0:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8aec8
	if (cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r29,76(r11)
	r29.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmpwi cr6,r29,12
	cr6.compare<int32_t>(r29.s32, 12, xer);
	// beq cr6,0x82c8ac00
	if (cr6.eq) goto loc_82C8AC00;
	// cmpwi cr6,r29,13
	cr6.compare<int32_t>(r29.s32, 13, xer);
	// beq cr6,0x82c8ac00
	if (cr6.eq) goto loc_82C8AC00;
	// cmpwi cr6,r29,9
	cr6.compare<int32_t>(r29.s32, 9, xer);
	// blt cr6,0x82c8ab9c
	if (cr6.lt) goto loc_82C8AB9C;
	// cmpwi cr6,r29,10
	cr6.compare<int32_t>(r29.s32, 10, xer);
	// ble cr6,0x82c8abb0
	if (!cr6.gt) goto loc_82C8ABB0;
	// cmpwi cr6,r29,21
	cr6.compare<int32_t>(r29.s32, 21, xer);
	// beq cr6,0x82c8abb0
	if (cr6.eq) goto loc_82C8ABB0;
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8AC00:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_82C8AC04:
	// stw r31,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, r31.u32);
loc_82C8AC08:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8aec8
	if (cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmpw cr6,r11,r29
	cr6.compare<int32_t>(r11.s32, r29.s32, xer);
	// beq cr6,0x82c8ad1c
	if (cr6.eq) goto loc_82C8AD1C;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bgt cr6,0x82c8ac00
	if (cr6.gt) goto loc_82C8AC00;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-21436
	r12.s64 = r12.s64 + -21436;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8AB9C;
	case 1:
		goto loc_82C8AB9C;
	case 2:
		goto loc_82C8AB9C;
	case 3:
		goto loc_82C8ACF8;
	case 4:
		goto loc_82C8AC00;
	case 5:
		goto loc_82C8AC68;
	case 6:
		goto loc_82C8AC98;
	case 7:
		goto loc_82C8ACC8;
	case 8:
		goto loc_82C8AB9C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21256);
	// lwz r22,-21504(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21504);
	// lwz r22,-21400(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21400);
	// lwz r22,-21352(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21352);
	// lwz r22,-21304(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21304);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
loc_82C8AC68:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// blt cr6,0x82c8aed4
	if (cr6.lt) goto loc_82C8AED4;
	// lwz r11,356(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8ab9c
	if (!cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c8ac04
	goto loc_82C8AC04;
loc_82C8AC98:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8aed4
	if (cr6.lt) goto loc_82C8AED4;
	// lwz r11,360(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8ab9c
	if (!cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c8ac04
	goto loc_82C8AC04;
loc_82C8ACC8:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8aed4
	if (cr6.lt) goto loc_82C8AED4;
	// lwz r11,364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8ab9c
	if (!cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// b 0x82c8ac04
	goto loc_82C8AC04;
loc_82C8ACF8:
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c8a698
	sub_82C8A698(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x82c8af30
	if (!cr6.gt) goto loc_82C8AF30;
	// lwz r31,172(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// b 0x82c8ac08
	goto loc_82C8AC08;
loc_82C8AD1C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8aec8
	if (cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-9
	r11.s64 = r11.s64 + -9;
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// bgt cr6,0x82c8ab9c
	if (cr6.gt) goto loc_82C8AB9C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-21160
	r12.s64 = r12.s64 + -21160;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8AD8C;
	case 1:
		goto loc_82C8AD8C;
	case 2:
		goto loc_82C8AF1C;
	case 3:
		goto loc_82C8AB9C;
	case 4:
		goto loc_82C8AB9C;
	case 5:
		goto loc_82C8AB9C;
	case 6:
		goto loc_82C8AB9C;
	case 7:
		goto loc_82C8AB9C;
	case 8:
		goto loc_82C8AEE0;
	case 9:
		goto loc_82C8AB9C;
	case 10:
		goto loc_82C8AB9C;
	case 11:
		goto loc_82C8AB9C;
	case 12:
		goto loc_82C8AD8C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-21108(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
	// lwz r22,-21108(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
	// lwz r22,-20708(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20708);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-20768(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20768);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21108(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
loc_82C8AD8C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8aec8
	if (cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8ab9c
	if (cr6.gt) goto loc_82C8AB9C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-21048
	r12.s64 = r12.s64 + -21048;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8AE34;
	case 1:
		goto loc_82C8AE64;
	case 2:
		goto loc_82C8AE94;
	case 3:
		goto loc_82C8AB9C;
	case 4:
		goto loc_82C8AD8C;
	case 5:
		goto loc_82C8AD8C;
	case 6:
		goto loc_82C8AF1C;
	case 7:
		goto loc_82C8AB9C;
	case 8:
		goto loc_82C8AB9C;
	case 9:
		goto loc_82C8AB9C;
	case 10:
		goto loc_82C8AB9C;
	case 11:
		goto loc_82C8AB9C;
	case 12:
		goto loc_82C8AEE0;
	case 13:
		goto loc_82C8AB9C;
	case 14:
		goto loc_82C8AB9C;
	case 15:
		goto loc_82C8AB9C;
	case 16:
		goto loc_82C8AD8C;
	case 17:
		goto loc_82C8AE2C;
	case 18:
		goto loc_82C8AB9C;
	case 19:
		goto loc_82C8AE2C;
	case 20:
		goto loc_82C8AB9C;
	case 21:
		goto loc_82C8AB9C;
	case 22:
		goto loc_82C8AB9C;
	case 23:
		goto loc_82C8AB9C;
	case 24:
		goto loc_82C8AB9C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-20940(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20940);
	// lwz r22,-20892(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20892);
	// lwz r22,-20844(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20844);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21108(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
	// lwz r22,-21108(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
	// lwz r22,-20708(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20708);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-20768(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20768);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21108(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
	// lwz r22,-20948(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-20948(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
loc_82C8AE2C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// b 0x82c8aec0
	goto loc_82C8AEC0;
loc_82C8AE34:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// blt cr6,0x82c8aed4
	if (cr6.lt) goto loc_82C8AED4;
	// lwz r11,344(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 344);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8ab9c
	if (cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c8aec0
	goto loc_82C8AEC0;
loc_82C8AE64:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8aed4
	if (cr6.lt) goto loc_82C8AED4;
	// lwz r11,348(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 348);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8ab9c
	if (cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c8aec0
	goto loc_82C8AEC0;
loc_82C8AE94:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8aed4
	if (cr6.lt) goto loc_82C8AED4;
	// lwz r11,352(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 352);
loc_82C8AEA4:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8ab9c
	if (cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_82C8AEC0:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8a9b0
	if (!cr6.eq) goto loc_82C8A9B0;
loc_82C8AEC8:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82C8AECC:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8AED4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8AEE0:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x82c8aec8
	if (cr6.eq) goto loc_82C8AEC8;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// beq cr6,0x82c8af08
	if (cr6.eq) goto loc_82C8AF08;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8AF08:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// li r3,3
	ctx.r3.s64 = 3;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8AF1C:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8AF30:
	// bne cr6,0x82c8aecc
	if (!cr6.eq) goto loc_82C8AECC;
	// lwz r11,172(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C8A988) {
	__imp__sub_82C8A988(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8AF48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8af78
	if (!cr6.eq) goto loc_82C8AF78;
loc_82C8AF6C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8AF78:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8b5e4
	if (cr6.gt) goto loc_82C8B5E4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-20568
	r12.s64 = r12.s64 + -20568;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8B014;
	case 1:
		goto loc_82C8B050;
	case 2:
		goto loc_82C8B080;
	case 3:
		goto loc_82C8B5E4;
	case 4:
		goto loc_82C8B5E4;
	case 5:
		goto loc_82C8B5E4;
	case 6:
		goto loc_82C8B5E4;
	case 7:
		goto loc_82C8B5E4;
	case 8:
		goto loc_82C8B5E4;
	case 9:
		goto loc_82C8B5E4;
	case 10:
		goto loc_82C8B5AC;
	case 11:
		goto loc_82C8B50C;
	case 12:
		goto loc_82C8B5C8;
	case 13:
		goto loc_82C8B5E4;
	case 14:
		goto loc_82C8B5E4;
	case 15:
		goto loc_82C8B5E4;
	case 16:
		goto loc_82C8B5E4;
	case 17:
		goto loc_82C8B00C;
	case 18:
		goto loc_82C8B5E4;
	case 19:
		goto loc_82C8B00C;
	case 20:
		goto loc_82C8B5E4;
	case 21:
		goto loc_82C8B5E4;
	case 22:
		goto loc_82C8B5E4;
	case 23:
		goto loc_82C8B5E4;
	case 24:
		goto loc_82C8B5E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-20460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20460);
	// lwz r22,-20400(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20400);
	// lwz r22,-20352(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20352);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19028(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19028);
	// lwz r22,-19188(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19188);
	// lwz r22,-19000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19000);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-20468(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20468);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-20468(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20468);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
loc_82C8B00C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// b 0x82c8b0ac
	goto loc_82C8B0AC;
loc_82C8B014:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8b02c
	if (!cr6.lt) goto loc_82C8B02C;
loc_82C8B020:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B02C:
	// lwz r11,344(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b5e4
	if (cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c8b0ac
	goto loc_82C8B0AC;
loc_82C8B050:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8b020
	if (cr6.lt) goto loc_82C8B020;
	// lwz r11,348(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b5e4
	if (cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c8b0ac
	goto loc_82C8B0AC;
loc_82C8B080:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8b020
	if (cr6.lt) goto loc_82C8B020;
	// lwz r11,352(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b5e4
	if (cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_82C8B0AC:
	// li r27,0
	r27.s64 = 0;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8af6c
	if (cr6.eq) goto loc_82C8AF6C;
	// subf r30,r31,r28
	r30.s64 = r28.s64 - r31.s64;
loc_82C8B0BC:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8b5e4
	if (cr6.gt) goto loc_82C8B5E4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-20244
	r12.s64 = r12.s64 + -20244;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8B150;
	case 1:
		goto loc_82C8B180;
	case 2:
		goto loc_82C8B1B0;
	case 3:
		goto loc_82C8B5E4;
	case 4:
		goto loc_82C8B31C;
	case 5:
		goto loc_82C8B31C;
	case 6:
		goto loc_82C8B4BC;
	case 7:
		goto loc_82C8B5E4;
	case 8:
		goto loc_82C8B5E4;
	case 9:
		goto loc_82C8B5E4;
	case 10:
		goto loc_82C8B5E4;
	case 11:
		goto loc_82C8B5E4;
	case 12:
		goto loc_82C8B4D0;
	case 13:
		goto loc_82C8B5E4;
	case 14:
		goto loc_82C8B5E4;
	case 15:
		goto loc_82C8B5E4;
	case 16:
		goto loc_82C8B31C;
	case 17:
		goto loc_82C8B270;
	case 18:
		goto loc_82C8B1C0;
	case 19:
		goto loc_82C8B270;
	case 20:
		goto loc_82C8B270;
	case 21:
		goto loc_82C8B270;
	case 22:
		goto loc_82C8B270;
	case 23:
		goto loc_82C8B5E4;
	case 24:
		goto loc_82C8B5E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-20144(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20144);
	// lwz r22,-20096(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20096);
	// lwz r22,-20048(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20048);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19684(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19684);
	// lwz r22,-19684(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19684);
	// lwz r22,-19268(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19268);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19248(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19248);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19684(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19684);
	// lwz r22,-19856(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-20032(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20032);
	// lwz r22,-19856(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-19856(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-19856(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-19856(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
loc_82C8B150:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c8b020
	if (cr6.lt) goto loc_82C8B020;
	// lwz r11,332(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b5e4
	if (cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c8b308
	goto loc_82C8B308;
loc_82C8B180:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c8b020
	if (cr6.lt) goto loc_82C8B020;
	// lwz r11,336(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b5e4
	if (cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c8b308
	goto loc_82C8B308;
loc_82C8B1B0:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c8b020
	if (cr6.lt) goto loc_82C8B020;
	// lwz r11,340(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 340);
	// b 0x82c8b2e8
	goto loc_82C8B2E8;
loc_82C8B1C0:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x82c8b5e4
	if (!cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// li r27,1
	r27.s64 = 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8af6c
	if (cr6.eq) goto loc_82C8AF6C;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8b5e4
	if (cr6.gt) goto loc_82C8B5E4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-19956
	r12.s64 = r12.s64 + -19956;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8B27C;
	case 1:
		goto loc_82C8B2AC;
	case 2:
		goto loc_82C8B2DC;
	case 3:
		goto loc_82C8B5E4;
	case 4:
		goto loc_82C8B5E4;
	case 5:
		goto loc_82C8B5E4;
	case 6:
		goto loc_82C8B5E4;
	case 7:
		goto loc_82C8B5E4;
	case 8:
		goto loc_82C8B5E4;
	case 9:
		goto loc_82C8B5E4;
	case 10:
		goto loc_82C8B5E4;
	case 11:
		goto loc_82C8B5E4;
	case 12:
		goto loc_82C8B5E4;
	case 13:
		goto loc_82C8B5E4;
	case 14:
		goto loc_82C8B5E4;
	case 15:
		goto loc_82C8B5E4;
	case 16:
		goto loc_82C8B5E4;
	case 17:
		goto loc_82C8B270;
	case 18:
		goto loc_82C8B5E4;
	case 19:
		goto loc_82C8B270;
	case 20:
		goto loc_82C8B5E4;
	case 21:
		goto loc_82C8B5E4;
	case 22:
		goto loc_82C8B5E4;
	case 23:
		goto loc_82C8B5E4;
	case 24:
		goto loc_82C8B5E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-19844(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19844);
	// lwz r22,-19796(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19796);
	// lwz r22,-19748(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19748);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19856(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19856(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
loc_82C8B270:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// b 0x82c8b308
	goto loc_82C8B308;
loc_82C8B27C:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c8b020
	if (cr6.lt) goto loc_82C8B020;
	// lwz r11,344(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b5e4
	if (cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c8b308
	goto loc_82C8B308;
loc_82C8B2AC:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c8b020
	if (cr6.lt) goto loc_82C8B020;
	// lwz r11,348(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b5e4
	if (cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c8b308
	goto loc_82C8B308;
loc_82C8B2DC:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c8b020
	if (cr6.lt) goto loc_82C8B020;
	// lwz r11,352(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 352);
loc_82C8B2E8:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b5e4
	if (cr6.eq) goto loc_82C8B5E4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_82C8B308:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8b0bc
	if (!cr6.eq) goto loc_82C8B0BC;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B31C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8af6c
	if (cr6.eq) goto loc_82C8AF6C;
loc_82C8B328:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8b5e4
	if (cr6.gt) goto loc_82C8B5E4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-19624
	r12.s64 = r12.s64 + -19624;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8B3F0;
	case 1:
		goto loc_82C8B434;
	case 2:
		goto loc_82C8B478;
	case 3:
		goto loc_82C8B5E4;
	case 4:
		goto loc_82C8B3BC;
	case 5:
		goto loc_82C8B3BC;
	case 6:
		goto loc_82C8B4BC;
	case 7:
		goto loc_82C8B5E4;
	case 8:
		goto loc_82C8B5E4;
	case 9:
		goto loc_82C8B5E4;
	case 10:
		goto loc_82C8B5E4;
	case 11:
		goto loc_82C8B5E4;
	case 12:
		goto loc_82C8B4D0;
	case 13:
		goto loc_82C8B5E4;
	case 14:
		goto loc_82C8B5E4;
	case 15:
		goto loc_82C8B5E4;
	case 16:
		goto loc_82C8B3BC;
	case 17:
		goto loc_82C8B3D4;
	case 18:
		goto loc_82C8B5E4;
	case 19:
		goto loc_82C8B3D4;
	case 20:
		goto loc_82C8B5E4;
	case 21:
		goto loc_82C8B5E4;
	case 22:
		goto loc_82C8B5E4;
	case 23:
		goto loc_82C8B5E4;
	case 24:
		goto loc_82C8B5E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-19472(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19472);
	// lwz r22,-19404(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19404);
	// lwz r22,-19336(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19336);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19524(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19524);
	// lwz r22,-19524(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19524);
	// lwz r22,-19268(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19268);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19248(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19248);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19524(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19524);
	// lwz r22,-19500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19500);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19500);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
loc_82C8B3BC:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8b328
	if (!cr6.eq) goto loc_82C8B328;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B3D4:
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8a988
	sub_82C8A988(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B3F0:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// blt cr6,0x82c8b020
	if (cr6.lt) goto loc_82C8B020;
	// lwz r11,344(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b5e4
	if (cr6.eq) goto loc_82C8B5E4;
	// addi r4,r31,2
	ctx.r4.s64 = r31.s64 + 2;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8a988
	sub_82C8A988(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B434:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8b020
	if (cr6.lt) goto loc_82C8B020;
	// lwz r11,348(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b5e4
	if (cr6.eq) goto loc_82C8B5E4;
	// addi r4,r31,3
	ctx.r4.s64 = r31.s64 + 3;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8a988
	sub_82C8A988(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B478:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8b020
	if (cr6.lt) goto loc_82C8B020;
	// lwz r11,352(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b5e4
	if (cr6.eq) goto loc_82C8B5E4;
	// addi r4,r31,4
	ctx.r4.s64 = r31.s64 + 4;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8a988
	sub_82C8A988(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B4BC:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B4D0:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x82c8af6c
	if (cr6.eq) goto loc_82C8AF6C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// beq cr6,0x82c8b4f8
	if (cr6.eq) goto loc_82C8B4F8;
loc_82C8B4E8:
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B4F8:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// li r3,4
	ctx.r3.s64 = 4;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B50C:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x82c8af6c
	if (cr6.eq) goto loc_82C8AF6C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + r29.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmpwi cr6,r10,20
	cr6.compare<int32_t>(ctx.r10.s32, 20, xer);
	// beq cr6,0x82c8b550
	if (cr6.eq) goto loc_82C8B550;
	// cmpwi cr6,r10,27
	cr6.compare<int32_t>(ctx.r10.s32, 27, xer);
	// bne cr6,0x82c8b4e8
	if (!cr6.eq) goto loc_82C8B4E8;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c89638
	sub_82C89638(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B550:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// subf r10,r11,r28
	ctx.r10.s64 = r28.s64 - r11.s64;
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// blt cr6,0x82c8af6c
	if (cr6.lt) goto loc_82C8AF6C;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r9,-2352
	ctx.r9.s64 = ctx.r9.s64 + -2352;
loc_82C8B56C:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbzx r7,r10,r9
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r9.u32);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x82c8b59c
	if (!cr6.eq) goto loc_82C8B59C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// blt cr6,0x82c8b56c
	if (cr6.lt) goto loc_82C8B56C;
	// li r3,8
	ctx.r3.s64 = 8;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B59C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B5AC:
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c89ab0
	sub_82C89AB0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B5C8:
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8a210
	sub_82C8A210(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8B5E4:
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C8AF48) {
	__imp__sub_82C8AF48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8B5F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r26
	cr6.compare<uint32_t>(r31.u32, r26.u32, xer);
	// bne cr6,0x82c8b628
	if (!cr6.eq) goto loc_82C8B628;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_82C8B628:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bgt cr6,0x82c8b80c
	if (cr6.gt) goto loc_82C8B80C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-18860
	r12.s64 = r12.s64 + -18860;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8B794;
	case 1:
		goto loc_82C8B794;
	case 2:
		goto loc_82C8B680;
	case 3:
		goto loc_82C8B69C;
	case 4:
		goto loc_82C8B70C;
	case 5:
		goto loc_82C8B760;
	case 6:
		goto loc_82C8B7AC;
	case 7:
		goto loc_82C8B7DC;
	case 8:
		goto loc_82C8B794;
	case 9:
		goto loc_82C8B6B8;
	case 10:
		goto loc_82C8B6F8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-18540(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18540);
	// lwz r22,-18540(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18540);
	// lwz r22,-18816(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18816);
	// lwz r22,-18788(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18788);
	// lwz r22,-18676(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18676);
	// lwz r22,-18592(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18592);
	// lwz r22,-18516(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18516);
	// lwz r22,-18468(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18468);
	// lwz r22,-18540(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18540);
	// lwz r22,-18760(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18760);
	// lwz r22,-18696(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18696);
loc_82C8B680:
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82c8af48
	sub_82C8AF48(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_82C8B69C:
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82c8a698
	sub_82C8A698(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_82C8B6B8:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bne cr6,0x82c8b6d0
	if (!cr6.eq) goto loc_82C8B6D0;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_82C8B6D0:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r27
	ctx.r10.u64 = ctx.r10.u64 + r27.u64;
	// lbz r9,76(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmplwi cr6,r9,10
	cr6.compare<uint32_t>(ctx.r9.u32, 10, xer);
	// bne cr6,0x82c8b6e8
	if (!cr6.eq) goto loc_82C8B6E8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_82C8B6E8:
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// li r3,7
	ctx.r3.s64 = 7;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_82C8B6F8:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_82C8B70C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r26
	cr6.compare<uint32_t>(r31.u32, r26.u32, xer);
	// bne cr6,0x82c8b724
	if (!cr6.eq) goto loc_82C8B724;
loc_82C8B718:
	// li r3,-5
	ctx.r3.s64 = -5;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_82C8B724:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c8b810
	if (!cr6.eq) goto loc_82C8B810;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// beq cr6,0x82c8b718
	if (cr6.eq) goto loc_82C8B718;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// beq cr6,0x82c8b750
	if (cr6.eq) goto loc_82C8B750;
	// addi r31,r11,-1
	r31.s64 = r11.s64 + -1;
	// b 0x82c8b810
	goto loc_82C8B810;
loc_82C8B750:
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_82C8B760:
	// subf r11,r31,r26
	r11.s64 = r26.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8b778
	if (!cr6.lt) goto loc_82C8B778;
loc_82C8B76C:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_82C8B778:
	// lwz r11,356(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8b7a4
	if (cr6.eq) goto loc_82C8B7A4;
loc_82C8B794:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r31.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_82C8B7A4:
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c8b810
	goto loc_82C8B810;
loc_82C8B7AC:
	// subf r11,r31,r26
	r11.s64 = r26.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8b76c
	if (cr6.lt) goto loc_82C8B76C;
	// lwz r11,360(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8b794
	if (!cr6.eq) goto loc_82C8B794;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c8b810
	goto loc_82C8B810;
loc_82C8B7DC:
	// subf r11,r31,r26
	r11.s64 = r26.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8b76c
	if (cr6.lt) goto loc_82C8B76C;
	// lwz r11,364(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8b794
	if (!cr6.eq) goto loc_82C8B794;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// b 0x82c8b810
	goto loc_82C8B810;
loc_82C8B80C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_82C8B810:
	// cmplw cr6,r31,r26
	cr6.compare<uint32_t>(r31.u32, r26.u32, xer);
	// beq cr6,0x82c8b964
	if (cr6.eq) goto loc_82C8B964;
	// addi r28,r31,2
	r28.s64 = r31.s64 + 2;
	// addi r29,r31,1
	r29.s64 = r31.s64 + 1;
	// subf r30,r31,r26
	r30.s64 = r26.s64 - r31.s64;
loc_82C8B824:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bgt cr6,0x82c8b94c
	if (cr6.gt) goto loc_82C8B94C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-18352
	r12.s64 = r12.s64 + -18352;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8B964;
	case 1:
		goto loc_82C8B964;
	case 2:
		goto loc_82C8B964;
	case 3:
		goto loc_82C8B964;
	case 4:
		goto loc_82C8B924;
	case 5:
		goto loc_82C8B87C;
	case 6:
		goto loc_82C8B8B4;
	case 7:
		goto loc_82C8B8EC;
	case 8:
		goto loc_82C8B964;
	case 9:
		goto loc_82C8B964;
	case 10:
		goto loc_82C8B964;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-18076(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18076(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18076(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18076(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18140(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18140);
	// lwz r22,-18308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18308);
	// lwz r22,-18252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18252);
	// lwz r22,-18196(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18196);
	// lwz r22,-18076(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18076(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18076(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
loc_82C8B87C:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c8b964
	if (cr6.lt) goto loc_82C8B964;
	// lwz r11,356(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8b964
	if (!cr6.eq) goto loc_82C8B964;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// addi r29,r29,2
	r29.s64 = r29.s64 + 2;
	// addi r28,r28,2
	r28.s64 = r28.s64 + 2;
	// b 0x82c8b95c
	goto loc_82C8B95C;
loc_82C8B8B4:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c8b964
	if (cr6.lt) goto loc_82C8B964;
	// lwz r11,360(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8b964
	if (!cr6.eq) goto loc_82C8B964;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// addi r29,r29,3
	r29.s64 = r29.s64 + 3;
	// addi r28,r28,3
	r28.s64 = r28.s64 + 3;
	// b 0x82c8b95c
	goto loc_82C8B95C;
loc_82C8B8EC:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c8b964
	if (cr6.lt) goto loc_82C8B964;
	// lwz r11,364(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8b964
	if (!cr6.eq) goto loc_82C8B964;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// b 0x82c8b95c
	goto loc_82C8B95C;
loc_82C8B924:
	// cmplw cr6,r29,r26
	cr6.compare<uint32_t>(r29.u32, r26.u32, xer);
	// beq cr6,0x82c8b964
	if (cr6.eq) goto loc_82C8B964;
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c8b94c
	if (!cr6.eq) goto loc_82C8B94C;
	// cmplw cr6,r28,r26
	cr6.compare<uint32_t>(r28.u32, r26.u32, xer);
	// beq cr6,0x82c8b964
	if (cr6.eq) goto loc_82C8B964;
	// lbz r11,0(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 0);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// beq cr6,0x82c8b974
	if (cr6.eq) goto loc_82C8B974;
loc_82C8B94C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
loc_82C8B95C:
	// cmplw cr6,r31,r26
	cr6.compare<uint32_t>(r31.u32, r26.u32, xer);
	// bne cr6,0x82c8b824
	if (!cr6.eq) goto loc_82C8B824;
loc_82C8B964:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r31,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r31.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
loc_82C8B974:
	// addi r11,r31,2
	r11.s64 = r31.s64 + 2;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_82C8B5F8) {
	__imp__sub_82C8B5F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8B988) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8b9b8
	if (!cr6.eq) goto loc_82C8B9B8;
	// li r3,-22
	ctx.r3.s64 = -22;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8B9B8:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,25
	cr6.compare<uint32_t>(r11.u32, 25, xer);
	// bgt cr6,0x82c8bc60
	if (cr6.gt) goto loc_82C8BC60;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-17944
	r12.s64 = r12.s64 + -17944;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8BA58;
	case 1:
		goto loc_82C8BA94;
	case 2:
		goto loc_82C8BAC4;
	case 3:
		goto loc_82C8BC60;
	case 4:
		goto loc_82C8BC50;
	case 5:
		goto loc_82C8BC50;
	case 6:
		goto loc_82C8BC60;
	case 7:
		goto loc_82C8BC60;
	case 8:
		goto loc_82C8BC60;
	case 9:
		goto loc_82C8BC60;
	case 10:
		goto loc_82C8BC60;
	case 11:
		goto loc_82C8BC60;
	case 12:
		goto loc_82C8BC60;
	case 13:
		goto loc_82C8BC60;
	case 14:
		goto loc_82C8BC60;
	case 15:
		goto loc_82C8BC60;
	case 16:
		goto loc_82C8BC50;
	case 17:
		goto loc_82C8BA50;
	case 18:
		goto loc_82C8BC60;
	case 19:
		goto loc_82C8BA50;
	case 20:
		goto loc_82C8BC60;
	case 21:
		goto loc_82C8BC60;
	case 22:
		goto loc_82C8BC60;
	case 23:
		goto loc_82C8BC60;
	case 24:
		goto loc_82C8BC60;
	case 25:
		goto loc_82C8BC50;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-17832(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17832);
	// lwz r22,-17772(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17772);
	// lwz r22,-17724(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17724);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17328);
	// lwz r22,-17328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17328);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17328);
	// lwz r22,-17840(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17840);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17840(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17840);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17328);
loc_82C8BA50:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// b 0x82c8baf0
	goto loc_82C8BAF0;
loc_82C8BA58:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8ba70
	if (!cr6.lt) goto loc_82C8BA70;
loc_82C8BA64:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8BA70:
	// lwz r11,344(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bc60
	if (cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c8baf0
	goto loc_82C8BAF0;
loc_82C8BA94:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8ba64
	if (cr6.lt) goto loc_82C8BA64;
	// lwz r11,348(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bc60
	if (cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c8baf0
	goto loc_82C8BAF0;
loc_82C8BAC4:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8ba64
	if (cr6.lt) goto loc_82C8BA64;
	// lwz r11,352(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bc60
	if (cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_82C8BAF0:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8bc30
	if (cr6.eq) goto loc_82C8BC30;
	// subf r30,r31,r28
	r30.s64 = r28.s64 - r31.s64;
loc_82C8BAFC:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8bc60
	if (cr6.gt) goto loc_82C8BC60;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-17620
	r12.s64 = r12.s64 + -17620;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8BB9C;
	case 1:
		goto loc_82C8BBCC;
	case 2:
		goto loc_82C8BBFC;
	case 3:
		goto loc_82C8BC60;
	case 4:
		goto loc_82C8BC60;
	case 5:
		goto loc_82C8BC60;
	case 6:
		goto loc_82C8BC60;
	case 7:
		goto loc_82C8BC60;
	case 8:
		goto loc_82C8BC60;
	case 9:
		goto loc_82C8BC60;
	case 10:
		goto loc_82C8BC60;
	case 11:
		goto loc_82C8BC60;
	case 12:
		goto loc_82C8BC60;
	case 13:
		goto loc_82C8BC3C;
	case 14:
		goto loc_82C8BC60;
	case 15:
		goto loc_82C8BC60;
	case 16:
		goto loc_82C8BC60;
	case 17:
		goto loc_82C8BB90;
	case 18:
		goto loc_82C8BC60;
	case 19:
		goto loc_82C8BB90;
	case 20:
		goto loc_82C8BB90;
	case 21:
		goto loc_82C8BB90;
	case 22:
		goto loc_82C8BB90;
	case 23:
		goto loc_82C8BC60;
	case 24:
		goto loc_82C8BC60;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-17508(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17508);
	// lwz r22,-17460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17460);
	// lwz r22,-17412(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17412);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17348(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17348);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17520(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17520);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17520(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17520);
	// lwz r22,-17520(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17520);
	// lwz r22,-17520(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17520);
	// lwz r22,-17520(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17520);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
loc_82C8BB90:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// b 0x82c8bc28
	goto loc_82C8BC28;
loc_82C8BB9C:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c8ba64
	if (cr6.lt) goto loc_82C8BA64;
	// lwz r11,332(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bc60
	if (cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c8bc28
	goto loc_82C8BC28;
loc_82C8BBCC:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c8ba64
	if (cr6.lt) goto loc_82C8BA64;
	// lwz r11,336(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bc60
	if (cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c8bc28
	goto loc_82C8BC28;
loc_82C8BBFC:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c8ba64
	if (cr6.lt) goto loc_82C8BA64;
	// lwz r11,340(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bc60
	if (cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
loc_82C8BC28:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8bafc
	if (!cr6.eq) goto loc_82C8BAFC;
loc_82C8BC30:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8BC3C:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,28
	ctx.r3.s64 = 28;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8BC50:
	// li r3,22
	ctx.r3.s64 = 22;
	// stw r31,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8BC60:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C8B988) {
	__imp__sub_82C8B988(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8BC70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8bca0
	if (!cr6.eq) goto loc_82C8BCA0;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8BCA0:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8bf4c
	if (cr6.gt) goto loc_82C8BF4C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-17200
	r12.s64 = r12.s64 + -17200;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8BD3C;
	case 1:
		goto loc_82C8BD78;
	case 2:
		goto loc_82C8BDA8;
	case 3:
		goto loc_82C8BF4C;
	case 4:
		goto loc_82C8BF4C;
	case 5:
		goto loc_82C8BF4C;
	case 6:
		goto loc_82C8BF4C;
	case 7:
		goto loc_82C8BF4C;
	case 8:
		goto loc_82C8BF4C;
	case 9:
		goto loc_82C8BF4C;
	case 10:
		goto loc_82C8BF4C;
	case 11:
		goto loc_82C8BF4C;
	case 12:
		goto loc_82C8BF4C;
	case 13:
		goto loc_82C8BF4C;
	case 14:
		goto loc_82C8BF4C;
	case 15:
		goto loc_82C8BF4C;
	case 16:
		goto loc_82C8BF4C;
	case 17:
		goto loc_82C8BD34;
	case 18:
		goto loc_82C8BF4C;
	case 19:
		goto loc_82C8BD34;
	case 20:
		goto loc_82C8BF4C;
	case 21:
		goto loc_82C8BF4C;
	case 22:
		goto loc_82C8BF4C;
	case 23:
		goto loc_82C8BF4C;
	case 24:
		goto loc_82C8BF4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-17092(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17092);
	// lwz r22,-17032(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17032);
	// lwz r22,-16984(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16984);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-17100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17100);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-17100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17100);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
loc_82C8BD34:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// b 0x82c8bdd4
	goto loc_82C8BDD4;
loc_82C8BD3C:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8bd54
	if (!cr6.lt) goto loc_82C8BD54;
loc_82C8BD48:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8BD54:
	// lwz r11,344(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bf4c
	if (cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c8bdd4
	goto loc_82C8BDD4;
loc_82C8BD78:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8bd48
	if (cr6.lt) goto loc_82C8BD48;
	// lwz r11,348(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bf4c
	if (cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c8bdd4
	goto loc_82C8BDD4;
loc_82C8BDA8:
	// subf r11,r31,r28
	r11.s64 = r28.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8bd48
	if (cr6.lt) goto loc_82C8BD48;
	// lwz r11,352(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bf4c
	if (cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_82C8BDD4:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8bf30
	if (cr6.eq) goto loc_82C8BF30;
	// subf r30,r31,r28
	r30.s64 = r28.s64 - r31.s64;
loc_82C8BDE0:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,31
	cr6.compare<uint32_t>(r11.u32, 31, xer);
	// bgt cr6,0x82c8bf4c
	if (cr6.gt) goto loc_82C8BF4C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-16880
	r12.s64 = r12.s64 + -16880;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8BE9C;
	case 1:
		goto loc_82C8BECC;
	case 2:
		goto loc_82C8BEFC;
	case 3:
		goto loc_82C8BF4C;
	case 4:
		goto loc_82C8BF3C;
	case 5:
		goto loc_82C8BF3C;
	case 6:
		goto loc_82C8BF3C;
	case 7:
		goto loc_82C8BF4C;
	case 8:
		goto loc_82C8BF4C;
	case 9:
		goto loc_82C8BF4C;
	case 10:
		goto loc_82C8BF4C;
	case 11:
		goto loc_82C8BF4C;
	case 12:
		goto loc_82C8BF4C;
	case 13:
		goto loc_82C8BF4C;
	case 14:
		goto loc_82C8BF4C;
	case 15:
		goto loc_82C8BF4C;
	case 16:
		goto loc_82C8BF3C;
	case 17:
		goto loc_82C8BE90;
	case 18:
		goto loc_82C8BF4C;
	case 19:
		goto loc_82C8BE90;
	case 20:
		goto loc_82C8BE90;
	case 21:
		goto loc_82C8BE90;
	case 22:
		goto loc_82C8BE90;
	case 23:
		goto loc_82C8BF4C;
	case 24:
		goto loc_82C8BF4C;
	case 25:
		goto loc_82C8BF3C;
	case 26:
		goto loc_82C8BF4C;
	case 27:
		goto loc_82C8BF3C;
	case 28:
		goto loc_82C8BF4C;
	case 29:
		goto loc_82C8BF4C;
	case 30:
		goto loc_82C8BF4C;
	case 31:
		goto loc_82C8BF3C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-16740(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16740);
	// lwz r22,-16692(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16692);
	// lwz r22,-16644(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16644);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16580(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16580(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16580(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16580(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16752(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16752);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16752(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16752);
	// lwz r22,-16752(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16752);
	// lwz r22,-16752(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16752);
	// lwz r22,-16752(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16752);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16580(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16580(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16580(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
loc_82C8BE90:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// b 0x82c8bf28
	goto loc_82C8BF28;
loc_82C8BE9C:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c8bd48
	if (cr6.lt) goto loc_82C8BD48;
	// lwz r11,332(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bf4c
	if (cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c8bf28
	goto loc_82C8BF28;
loc_82C8BECC:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c8bd48
	if (cr6.lt) goto loc_82C8BD48;
	// lwz r11,336(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bf4c
	if (cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c8bf28
	goto loc_82C8BF28;
loc_82C8BEFC:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c8bd48
	if (cr6.lt) goto loc_82C8BD48;
	// lwz r11,340(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8bf4c
	if (cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
loc_82C8BF28:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8bde0
	if (!cr6.eq) goto loc_82C8BDE0;
loc_82C8BF30:
	// li r3,-20
	ctx.r3.s64 = -20;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8BF3C:
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r31,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C8BF4C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C8BC70) {
	__imp__sub_82C8BC70(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8BF60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// beq cr6,0x82c8c0b4
	if (cr6.eq) goto loc_82C8C0B4;
	// subf r30,r31,r28
	r30.s64 = r28.s64 - r31.s64;
loc_82C8BF8C:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmplwi cr6,r11,13
	cr6.compare<uint32_t>(r11.u32, 13, xer);
	// bgt cr6,0x82c8c0a4
	if (cr6.gt) goto loc_82C8C0A4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-16456
	r12.s64 = r12.s64 + -16456;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8C0CC;
	case 1:
		goto loc_82C8C0CC;
	case 2:
		goto loc_82C8C0A4;
	case 3:
		goto loc_82C8C0A4;
	case 4:
		goto loc_82C8C0A4;
	case 5:
		goto loc_82C8BFF0;
	case 6:
		goto loc_82C8C020;
	case 7:
		goto loc_82C8C050;
	case 8:
		goto loc_82C8C0CC;
	case 9:
		goto loc_82C8C0A4;
	case 10:
		goto loc_82C8C0A4;
	case 11:
		goto loc_82C8C0A4;
	case 12:
		goto loc_82C8C080;
	case 13:
		goto loc_82C8C080;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-16180(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16180);
	// lwz r22,-16180(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16180);
	// lwz r22,-16220(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16220(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16220(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16400(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16400);
	// lwz r22,-16352(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16352);
	// lwz r22,-16304(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16304);
	// lwz r22,-16180(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16180);
	// lwz r22,-16220(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16220(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16220(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16256);
	// lwz r22,-16256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16256);
loc_82C8BFF0:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c8c0c0
	if (cr6.lt) goto loc_82C8C0C0;
	// lwz r11,356(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8c0cc
	if (!cr6.eq) goto loc_82C8C0CC;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c8c0ac
	goto loc_82C8C0AC;
loc_82C8C020:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c8c0c0
	if (cr6.lt) goto loc_82C8C0C0;
	// lwz r11,360(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8c0cc
	if (!cr6.eq) goto loc_82C8C0CC;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c8c0ac
	goto loc_82C8C0AC;
loc_82C8C050:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c8c0c0
	if (cr6.lt) goto loc_82C8C0C0;
	// lwz r11,364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8c0cc
	if (!cr6.eq) goto loc_82C8C0CC;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// b 0x82c8c0ac
	goto loc_82C8C0AC;
loc_82C8C080:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// cmpw cr6,r11,r27
	cr6.compare<int32_t>(r11.s32, r27.s32, xer);
	// bne cr6,0x82c8c0ac
	if (!cr6.eq) goto loc_82C8C0AC;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8c0dc
	if (!cr6.eq) goto loc_82C8C0DC;
	// li r3,-27
	ctx.r3.s64 = -27;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C0A4:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
loc_82C8C0AC:
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// bne cr6,0x82c8bf8c
	if (!cr6.eq) goto loc_82C8BF8C;
loc_82C8C0B4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C0C0:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C0CC:
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
loc_82C8C0D0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C0DC:
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-9
	r11.s64 = r11.s64 + -9;
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// bgt cr6,0x82c8c0d0
	if (cr6.gt) goto loc_82C8C0D0;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-16112
	r12.s64 = r12.s64 + -16112;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8C168;
	case 1:
		goto loc_82C8C168;
	case 2:
		goto loc_82C8C168;
	case 3:
		goto loc_82C8C0D0;
	case 4:
		goto loc_82C8C0D0;
	case 5:
		goto loc_82C8C0D0;
	case 6:
		goto loc_82C8C0D0;
	case 7:
		goto loc_82C8C0D0;
	case 8:
		goto loc_82C8C0D0;
	case 9:
		goto loc_82C8C0D0;
	case 10:
		goto loc_82C8C0D0;
	case 11:
		goto loc_82C8C168;
	case 12:
		goto loc_82C8C168;
	case 13:
		goto loc_82C8C0D0;
	case 14:
		goto loc_82C8C0D0;
	case 15:
		goto loc_82C8C0D0;
	case 16:
		goto loc_82C8C0D0;
	case 17:
		goto loc_82C8C0D0;
	case 18:
		goto loc_82C8C0D0;
	case 19:
		goto loc_82C8C0D0;
	case 20:
		goto loc_82C8C0D0;
	case 21:
		goto loc_82C8C168;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-16024(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
	// lwz r22,-16024(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
	// lwz r22,-16024(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16024(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
	// lwz r22,-16024(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16024(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
loc_82C8C168:
	// li r3,27
	ctx.r3.s64 = 27;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C8BF60) {
	__imp__sub_82C8BF60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8C178) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// bne cr6,0x82c8c1a8
	if (!cr6.eq) goto loc_82C8C1A8;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C1A8:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
	// cmplwi cr6,r11,34
	cr6.compare<uint32_t>(r11.u32, 34, xer);
	// bgt cr6,0x82c8c9dc
	if (cr6.gt) goto loc_82C8C9DC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-15912
	r12.s64 = r12.s64 + -15912;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8C2A4;
	case 1:
		goto loc_82C8C9DC;
	case 2:
		goto loc_82C8C46C;
	case 3:
		goto loc_82C8C628;
	case 4:
		goto loc_82C8C68C;
	case 5:
		goto loc_82C8C6E4;
	case 6:
		goto loc_82C8C9DC;
	case 7:
		goto loc_82C8C3AC;
	case 8:
		goto loc_82C8C3C8;
	case 9:
		goto loc_82C8C5F8;
	case 10:
		goto loc_82C8C264;
	case 11:
		goto loc_82C8C284;
	case 12:
		goto loc_82C8C9DC;
	case 13:
		goto loc_82C8C9DC;
	case 14:
		goto loc_82C8C9DC;
	case 15:
		goto loc_82C8C9DC;
	case 16:
		goto loc_82C8C9DC;
	case 17:
		goto loc_82C8C60C;
	case 18:
		goto loc_82C8C458;
	case 19:
		goto loc_82C8C3C8;
	case 20:
		goto loc_82C8C73C;
	case 21:
		goto loc_82C8C748;
	case 22:
		goto loc_82C8C73C;
	case 23:
		goto loc_82C8C748;
	case 24:
		goto loc_82C8C748;
	case 25:
		goto loc_82C8C748;
	case 26:
		goto loc_82C8C9DC;
	case 27:
		goto loc_82C8C9DC;
	case 28:
		goto loc_82C8C428;
	case 29:
		goto loc_82C8C4CC;
	case 30:
		goto loc_82C8C4E0;
	case 31:
		goto loc_82C8C9DC;
	case 32:
		goto loc_82C8C9DC;
	case 33:
		goto loc_82C8C444;
	case 34:
		goto loc_82C8C5E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-15708(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15708);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-15252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15252);
	// lwz r22,-14808(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14808);
	// lwz r22,-14708(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14708);
	// lwz r22,-14620(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14620);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-15444(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15444);
	// lwz r22,-15416(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15416);
	// lwz r22,-14856(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14856);
	// lwz r22,-15772(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15772);
	// lwz r22,-15740(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15740);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-14836(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14836);
	// lwz r22,-15272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15272);
	// lwz r22,-15416(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15416);
	// lwz r22,-14532(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14532);
	// lwz r22,-14520(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14520);
	// lwz r22,-14532(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14532);
	// lwz r22,-14520(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14520);
	// lwz r22,-14520(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14520);
	// lwz r22,-14520(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14520);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-15320(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15320);
	// lwz r22,-15156(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15156);
	// lwz r22,-15136(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15136);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-15292(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15292);
	// lwz r22,-14876(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14876);
loc_82C8C264:
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r31,1
	ctx.r5.s64 = r31.s64 + 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x82c8bf60
	sub_82C8BF60(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C284:
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r31,1
	ctx.r5.s64 = r31.s64 + 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r3,13
	ctx.r3.s64 = 13;
	// bl 0x82c8bf60
	sub_82C8BF60(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C2A4:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x82c8c2bc
	if (!cr6.eq) goto loc_82C8C2BC;
loc_82C8C2B0:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C2BC:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + r29.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-5
	ctx.r10.s64 = ctx.r10.s64 + -5;
	// cmplwi cr6,r10,24
	cr6.compare<uint32_t>(ctx.r10.u32, 24, xer);
	// bgt cr6,0x82c8c39c
	if (cr6.gt) goto loc_82C8C39C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-15636
	r12.s64 = r12.s64 + -15636;
	// rlwinm r0,r10,2,0,29
	r0.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C8C388;
	case 1:
		goto loc_82C8C388;
	case 2:
		goto loc_82C8C388;
	case 3:
		goto loc_82C8C39C;
	case 4:
		goto loc_82C8C39C;
	case 5:
		goto loc_82C8C39C;
	case 6:
		goto loc_82C8C39C;
	case 7:
		goto loc_82C8C39C;
	case 8:
		goto loc_82C8C39C;
	case 9:
		goto loc_82C8C39C;
	case 10:
		goto loc_82C8C36C;
	case 11:
		goto loc_82C8C350;
	case 12:
		goto loc_82C8C39C;
	case 13:
		goto loc_82C8C39C;
	case 14:
		goto loc_82C8C39C;
	case 15:
		goto loc_82C8C39C;
	case 16:
		goto loc_82C8C39C;
	case 17:
		goto loc_82C8C388;
	case 18:
		goto loc_82C8C39C;
	case 19:
		goto loc_82C8C388;
	case 20:
		goto loc_82C8C39C;
	case 21:
		goto loc_82C8C39C;
	case 22:
		goto loc_82C8C39C;
	case 23:
		goto loc_82C8C39C;
	case 24:
		goto loc_82C8C388;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-15480(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
	// lwz r22,-15480(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
	// lwz r22,-15480(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15508(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15508);
	// lwz r22,-15536(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15536);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15480(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15480(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15480(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
loc_82C8C350:
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c89840
	sub_82C89840(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C36C:
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c89ab0
	sub_82C89AB0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C388:
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// li r3,29
	ctx.r3.s64 = 29;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C39C:
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C3AC:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x82c8c3c8
	if (!cr6.eq) goto loc_82C8C3C8;
	// stw r27,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r27.u32);
	// li r3,-15
	ctx.r3.s64 = -15;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C3C8:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// beq cr6,0x82c8c418
	if (cr6.eq) goto loc_82C8C418;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
loc_82C8C3D8:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + r29.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// beq cr6,0x82c8c400
	if (cr6.eq) goto loc_82C8C400;
	// cmpwi cr6,r10,10
	cr6.compare<int32_t>(ctx.r10.s32, 10, xer);
	// beq cr6,0x82c8c408
	if (cr6.eq) goto loc_82C8C408;
	// cmpwi cr6,r10,21
	cr6.compare<int32_t>(ctx.r10.s32, 21, xer);
	// bne cr6,0x82c8c418
	if (!cr6.eq) goto loc_82C8C418;
	// b 0x82c8c408
	goto loc_82C8C408;
loc_82C8C400:
	// cmplw cr6,r9,r27
	cr6.compare<uint32_t>(ctx.r9.u32, r27.u32, xer);
	// beq cr6,0x82c8c418
	if (cr6.eq) goto loc_82C8C418;
loc_82C8C408:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x82c8c3d8
	if (!cr6.eq) goto loc_82C8C3D8;
loc_82C8C418:
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// li r3,15
	ctx.r3.s64 = 15;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C428:
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8b988
	sub_82C8B988(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C444:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,38
	ctx.r3.s64 = 38;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C458:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,25
	ctx.r3.s64 = 25;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C46C:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x82c8c484
	if (!cr6.eq) goto loc_82C8C484;
	// li r3,-26
	ctx.r3.s64 = -26;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C484:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,93
	cr6.compare<uint32_t>(ctx.r10.u32, 93, xer);
	// bne cr6,0x82c8c4bc
	if (!cr6.eq) goto loc_82C8C4BC;
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// cmplw cr6,r10,r27
	cr6.compare<uint32_t>(ctx.r10.u32, r27.u32, xer);
	// beq cr6,0x82c8c2b0
	if (cr6.eq) goto loc_82C8C2B0;
	// lbz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c8c4bc
	if (!cr6.eq) goto loc_82C8C4BC;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// li r3,34
	ctx.r3.s64 = 34;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C4BC:
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// li r3,26
	ctx.r3.s64 = 26;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C4CC:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,23
	ctx.r3.s64 = 23;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C4E0:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x82c8c4f8
	if (!cr6.eq) goto loc_82C8C4F8;
	// li r3,-24
	ctx.r3.s64 = -24;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C4F8:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + r29.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-9
	ctx.r10.s64 = ctx.r10.s64 + -9;
	// cmplwi cr6,r10,27
	cr6.compare<uint32_t>(ctx.r10.u32, 27, xer);
	// bgt cr6,0x82c8c39c
	if (cr6.gt) goto loc_82C8C39C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-15064
	r12.s64 = r12.s64 + -15064;
	// rlwinm r0,r10,2,0,29
	r0.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C8C5D4;
	case 1:
		goto loc_82C8C5D4;
	case 2:
		goto loc_82C8C5D4;
	case 3:
		goto loc_82C8C39C;
	case 4:
		goto loc_82C8C39C;
	case 5:
		goto loc_82C8C39C;
	case 6:
		goto loc_82C8C5AC;
	case 7:
		goto loc_82C8C39C;
	case 8:
		goto loc_82C8C39C;
	case 9:
		goto loc_82C8C39C;
	case 10:
		goto loc_82C8C39C;
	case 11:
		goto loc_82C8C39C;
	case 12:
		goto loc_82C8C5D4;
	case 13:
		goto loc_82C8C39C;
	case 14:
		goto loc_82C8C39C;
	case 15:
		goto loc_82C8C39C;
	case 16:
		goto loc_82C8C39C;
	case 17:
		goto loc_82C8C39C;
	case 18:
		goto loc_82C8C39C;
	case 19:
		goto loc_82C8C39C;
	case 20:
		goto loc_82C8C39C;
	case 21:
		goto loc_82C8C39C;
	case 22:
		goto loc_82C8C39C;
	case 23:
		goto loc_82C8C5D4;
	case 24:
		goto loc_82C8C598;
	case 25:
		goto loc_82C8C5C0;
	case 26:
		goto loc_82C8C5D4;
	case 27:
		goto loc_82C8C5D4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-14892(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-14892(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-14892(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-14932(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14932);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-14892(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-14892(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-14952(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14952);
	// lwz r22,-14912(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14912);
	// lwz r22,-14892(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-14892(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
loc_82C8C598:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// li r3,36
	ctx.r3.s64 = 36;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C5AC:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// li r3,35
	ctx.r3.s64 = 35;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C5C0:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// li r3,37
	ctx.r3.s64 = 37;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C5D4:
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// li r3,24
	ctx.r3.s64 = 24;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C5E4:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,21
	ctx.r3.s64 = 21;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C5F8:
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,17
	ctx.r3.s64 = 17;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C60C:
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8bc70
	sub_82C8BC70(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C628:
	// subf r11,r31,r27
	r11.s64 = r27.s64 - r31.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8c640
	if (!cr6.lt) goto loc_82C8C640;
loc_82C8C634:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C640:
	// lwz r11,344(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8c668
	if (cr6.eq) goto loc_82C8C668;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// li r28,18
	r28.s64 = 18;
	// b 0x82c8c750
	goto loc_82C8C750;
loc_82C8C668:
	// lwz r11,332(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8c9dc
	if (cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c8c74c
	goto loc_82C8C74C;
loc_82C8C68C:
	// subf r11,r31,r27
	r11.s64 = r27.s64 - r31.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8c634
	if (cr6.lt) goto loc_82C8C634;
	// lwz r11,348(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8c6c0
	if (cr6.eq) goto loc_82C8C6C0;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// li r28,18
	r28.s64 = 18;
	// b 0x82c8c750
	goto loc_82C8C750;
loc_82C8C6C0:
	// lwz r11,336(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8c9dc
	if (cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// b 0x82c8c74c
	goto loc_82C8C74C;
loc_82C8C6E4:
	// subf r11,r31,r27
	r11.s64 = r27.s64 - r31.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8c634
	if (cr6.lt) goto loc_82C8C634;
	// lwz r11,352(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8c718
	if (cr6.eq) goto loc_82C8C718;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// li r28,18
	r28.s64 = 18;
	// b 0x82c8c750
	goto loc_82C8C750;
loc_82C8C718:
	// lwz r11,340(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8c9dc
	if (cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// b 0x82c8c74c
	goto loc_82C8C74C;
loc_82C8C73C:
	// li r28,18
	r28.s64 = 18;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// b 0x82c8c750
	goto loc_82C8C750;
loc_82C8C748:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_82C8C74C:
	// li r28,19
	r28.s64 = 19;
loc_82C8C750:
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// beq cr6,0x82c8c860
	if (cr6.eq) goto loc_82C8C860;
	// subf r30,r31,r27
	r30.s64 = r27.s64 - r31.s64;
loc_82C8C75C:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,31
	cr6.compare<uint32_t>(r11.u32, 31, xer);
	// bgt cr6,0x82c8c9dc
	if (cr6.gt) goto loc_82C8C9DC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-14452
	r12.s64 = r12.s64 + -14452;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8C80C;
	case 1:
		goto loc_82C8C918;
	case 2:
		goto loc_82C8C948;
	case 3:
		goto loc_82C8C9DC;
	case 4:
		goto loc_82C8C978;
	case 5:
		goto loc_82C8C978;
	case 6:
		goto loc_82C8C978;
	case 7:
		goto loc_82C8C9DC;
	case 8:
		goto loc_82C8C9DC;
	case 9:
		goto loc_82C8C9DC;
	case 10:
		goto loc_82C8C9C0;
	case 11:
		goto loc_82C8C9DC;
	case 12:
		goto loc_82C8C9DC;
	case 13:
		goto loc_82C8C9DC;
	case 14:
		goto loc_82C8C9DC;
	case 15:
		goto loc_82C8C978;
	case 16:
		goto loc_82C8C978;
	case 17:
		goto loc_82C8C90C;
	case 18:
		goto loc_82C8C83C;
	case 19:
		goto loc_82C8C90C;
	case 20:
		goto loc_82C8C90C;
	case 21:
		goto loc_82C8C90C;
	case 22:
		goto loc_82C8C90C;
	case 23:
		goto loc_82C8C9DC;
	case 24:
		goto loc_82C8C9DC;
	case 25:
		goto loc_82C8C978;
	case 26:
		goto loc_82C8C9DC;
	case 27:
		goto loc_82C8C978;
	case 28:
		goto loc_82C8C9A4;
	case 29:
		goto loc_82C8C988;
	case 30:
		goto loc_82C8C978;
	case 31:
		goto loc_82C8C978;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-14324(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14324);
	// lwz r22,-14056(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14056);
	// lwz r22,-14008(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14008);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13960(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13960(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13960(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13888(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13888);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13960(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13960(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-14068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14276);
	// lwz r22,-14068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13960(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13960(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13916(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13916);
	// lwz r22,-13944(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13944);
	// lwz r22,-13960(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13960(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
loc_82C8C80C:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c8c634
	if (cr6.lt) goto loc_82C8C634;
	// lwz r11,332(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8c9dc
	if (cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c8c858
	goto loc_82C8C858;
loc_82C8C83C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// cmpwi cr6,r28,18
	cr6.compare<int32_t>(r28.s32, 18, xer);
	// beq cr6,0x82c8c86c
	if (cr6.eq) goto loc_82C8C86C;
	// cmpwi cr6,r28,41
	cr6.compare<int32_t>(r28.s32, 41, xer);
	// bne cr6,0x82c8c858
	if (!cr6.eq) goto loc_82C8C858;
loc_82C8C854:
	// li r28,19
	r28.s64 = 19;
loc_82C8C858:
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// bne cr6,0x82c8c75c
	if (!cr6.eq) goto loc_82C8C75C;
loc_82C8C860:
	// neg r3,r28
	ctx.r3.s64 = -r28.s64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C86C:
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// beq cr6,0x82c8c2b0
	if (cr6.eq) goto loc_82C8C2B0;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// li r28,41
	r28.s64 = 41;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8c854
	if (cr6.gt) goto loc_82C8C854;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-14168
	r12.s64 = r12.s64 + -14168;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8C80C;
	case 1:
		goto loc_82C8C918;
	case 2:
		goto loc_82C8C948;
	case 3:
		goto loc_82C8C854;
	case 4:
		goto loc_82C8C854;
	case 5:
		goto loc_82C8C854;
	case 6:
		goto loc_82C8C854;
	case 7:
		goto loc_82C8C854;
	case 8:
		goto loc_82C8C854;
	case 9:
		goto loc_82C8C854;
	case 10:
		goto loc_82C8C854;
	case 11:
		goto loc_82C8C854;
	case 12:
		goto loc_82C8C854;
	case 13:
		goto loc_82C8C854;
	case 14:
		goto loc_82C8C854;
	case 15:
		goto loc_82C8C854;
	case 16:
		goto loc_82C8C854;
	case 17:
		goto loc_82C8C90C;
	case 18:
		goto loc_82C8C854;
	case 19:
		goto loc_82C8C90C;
	case 20:
		goto loc_82C8C90C;
	case 21:
		goto loc_82C8C90C;
	case 22:
		goto loc_82C8C90C;
	case 23:
		goto loc_82C8C854;
	case 24:
		goto loc_82C8C9DC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-14324(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14324);
	// lwz r22,-14056(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14056);
	// lwz r22,-14008(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14008);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-13860(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
loc_82C8C90C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// b 0x82c8c858
	goto loc_82C8C858;
loc_82C8C918:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c8c634
	if (cr6.lt) goto loc_82C8C634;
	// lwz r11,336(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8c9dc
	if (cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c8c858
	goto loc_82C8C858;
loc_82C8C948:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c8c634
	if (cr6.lt) goto loc_82C8C634;
	// lwz r11,340(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8c9dc
	if (cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// b 0x82c8c858
	goto loc_82C8C858;
loc_82C8C978:
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C988:
	// cmpwi cr6,r28,19
	cr6.compare<int32_t>(r28.s32, 19, xer);
	// beq cr6,0x82c8c9dc
	if (cr6.eq) goto loc_82C8C9DC;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,32
	ctx.r3.s64 = 32;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C9A4:
	// cmpwi cr6,r28,19
	cr6.compare<int32_t>(r28.s32, 19, xer);
	// beq cr6,0x82c8c9dc
	if (cr6.eq) goto loc_82C8C9DC;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,31
	ctx.r3.s64 = 31;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C9C0:
	// cmpwi cr6,r28,19
	cr6.compare<int32_t>(r28.s32, 19, xer);
	// beq cr6,0x82c8c9dc
	if (cr6.eq) goto loc_82C8C9DC;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// li r3,30
	ctx.r3.s64 = 30;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8C9DC:
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C8C178) {
	__imp__sub_82C8C178(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8C9F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8ca00
	if (!cr6.eq) goto loc_82C8CA00;
	// li r3,-4
	ctx.r3.s64 = -4;
	// blr 
	return;
loc_82C8CA00:
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C8CA04:
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
	// cmplwi cr6,r11,19
	cr6.compare<uint32_t>(r11.u32, 19, xer);
	// bgt cr6,0x82c8ca9c
	if (cr6.gt) goto loc_82C8CA9C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-13772
	r12.s64 = r12.s64 + -13772;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8CAC4;
	case 1:
		goto loc_82C8CAB4;
	case 2:
		goto loc_82C8CA9C;
	case 3:
		goto loc_82C8CA84;
	case 4:
		goto loc_82C8CA8C;
	case 5:
		goto loc_82C8CA94;
	case 6:
		goto loc_82C8CA9C;
	case 7:
		goto loc_82C8CAE8;
	case 8:
		goto loc_82C8CAD0;
	case 9:
		goto loc_82C8CA9C;
	case 10:
		goto loc_82C8CA9C;
	case 11:
		goto loc_82C8CA9C;
	case 12:
		goto loc_82C8CA9C;
	case 13:
		goto loc_82C8CA9C;
	case 14:
		goto loc_82C8CA9C;
	case 15:
		goto loc_82C8CA9C;
	case 16:
		goto loc_82C8CA9C;
	case 17:
		goto loc_82C8CA9C;
	case 18:
		goto loc_82C8CA9C;
	case 19:
		goto loc_82C8CB28;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-13628(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13628);
	// lwz r22,-13644(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13644);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13692(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13692);
	// lwz r22,-13684(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13684);
	// lwz r22,-13676(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13676);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13592(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13592);
	// lwz r22,-13616(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13616);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13528(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13528);
loc_82C8CA84:
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// b 0x82c8caa0
	goto loc_82C8CAA0;
loc_82C8CA8C:
	// addi r4,r4,3
	ctx.r4.s64 = ctx.r4.s64 + 3;
	// b 0x82c8caa0
	goto loc_82C8CAA0;
loc_82C8CA94:
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// b 0x82c8caa0
	goto loc_82C8CAA0;
loc_82C8CA9C:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_82C8CAA0:
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8ca04
	if (!cr6.eq) goto loc_82C8CA04;
loc_82C8CAA8:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// blr 
	return;
loc_82C8CAB4:
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bne cr6,0x82c8caa8
	if (!cr6.eq) goto loc_82C8CAA8;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8a698
	sub_82C8A698(ctx, base);
	return;
loc_82C8CAC4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// blr 
	return;
loc_82C8CAD0:
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bne cr6,0x82c8caa8
	if (!cr6.eq) goto loc_82C8CAA8;
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// blr 
	return;
loc_82C8CAE8:
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bne cr6,0x82c8caa8
	if (!cr6.eq) goto loc_82C8CAA8;
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8cb04
	if (!cr6.eq) goto loc_82C8CB04;
	// li r3,-3
	ctx.r3.s64 = -3;
	// blr 
	return;
loc_82C8CB04:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r9,76(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmplwi cr6,r9,10
	cr6.compare<uint32_t>(ctx.r9.u32, 10, xer);
	// bne cr6,0x82c8cb1c
	if (!cr6.eq) goto loc_82C8CB1C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_82C8CB1C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,7
	ctx.r3.s64 = 7;
	// blr 
	return;
loc_82C8CB28:
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bne cr6,0x82c8caa8
	if (!cr6.eq) goto loc_82C8CAA8;
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// li r3,39
	ctx.r3.s64 = 39;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8C9F0) {
	__imp__sub_82C8C9F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8CB40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8cb68
	if (!cr6.eq) goto loc_82C8CB68;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8CB68:
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C8CB6C:
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-3
	r11.s64 = r11.s64 + -3;
	// cmplwi cr6,r11,27
	cr6.compare<uint32_t>(r11.u32, 27, xer);
	// bgt cr6,0x82c8cc24
	if (cr6.gt) goto loc_82C8CC24;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-13412
	r12.s64 = r12.s64 + -13412;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8CC48;
	case 1:
		goto loc_82C8CC24;
	case 2:
		goto loc_82C8CC0C;
	case 3:
		goto loc_82C8CC14;
	case 4:
		goto loc_82C8CC1C;
	case 5:
		goto loc_82C8CC24;
	case 6:
		goto loc_82C8CCB8;
	case 7:
		goto loc_82C8CC94;
	case 8:
		goto loc_82C8CC24;
	case 9:
		goto loc_82C8CC24;
	case 10:
		goto loc_82C8CC24;
	case 11:
		goto loc_82C8CC24;
	case 12:
		goto loc_82C8CC24;
	case 13:
		goto loc_82C8CC24;
	case 14:
		goto loc_82C8CC24;
	case 15:
		goto loc_82C8CC24;
	case 16:
		goto loc_82C8CC24;
	case 17:
		goto loc_82C8CC24;
	case 18:
		goto loc_82C8CC24;
	case 19:
		goto loc_82C8CC24;
	case 20:
		goto loc_82C8CC24;
	case 21:
		goto loc_82C8CC24;
	case 22:
		goto loc_82C8CC24;
	case 23:
		goto loc_82C8CC24;
	case 24:
		goto loc_82C8CC24;
	case 25:
		goto loc_82C8CC24;
	case 26:
		goto loc_82C8CC24;
	case 27:
		goto loc_82C8CC68;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-13240(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13240);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13300(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13300);
	// lwz r22,-13292(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13292);
	// lwz r22,-13284(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13284);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13128);
	// lwz r22,-13164(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13164);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13208(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13208);
loc_82C8CC0C:
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// b 0x82c8cc28
	goto loc_82C8CC28;
loc_82C8CC14:
	// addi r4,r4,3
	ctx.r4.s64 = ctx.r4.s64 + 3;
	// b 0x82c8cc28
	goto loc_82C8CC28;
loc_82C8CC1C:
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// b 0x82c8cc28
	goto loc_82C8CC28;
loc_82C8CC24:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_82C8CC28:
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8cb6c
	if (!cr6.eq) goto loc_82C8CB6C;
loc_82C8CC30:
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,6
	ctx.r3.s64 = 6;
loc_82C8CC38:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8CC48:
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bne cr6,0x82c8cc30
	if (!cr6.eq) goto loc_82C8CC30;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// bl 0x82c8a698
	sub_82C8A698(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8CC68:
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bne cr6,0x82c8cc30
	if (!cr6.eq) goto loc_82C8CC30;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// bl 0x82c8b988
	sub_82C8B988(ctx, base);
	// cmpwi cr6,r3,22
	cr6.compare<int32_t>(ctx.r3.s32, 22, xer);
	// bne cr6,0x82c8cc38
	if (!cr6.eq) goto loc_82C8CC38;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8CC94:
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bne cr6,0x82c8cc30
	if (!cr6.eq) goto loc_82C8CC30;
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8CCB8:
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bne cr6,0x82c8cc30
	if (!cr6.eq) goto loc_82C8CC30;
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8cce0
	if (!cr6.eq) goto loc_82C8CCE0;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8CCE0:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r9,76(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmplwi cr6,r9,10
	cr6.compare<uint32_t>(ctx.r9.u32, 10, xer);
	// bne cr6,0x82c8ccf8
	if (!cr6.eq) goto loc_82C8CCF8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_82C8CCF8:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,7
	ctx.r3.s64 = 7;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8CB40) {
	__imp__sub_82C8CB40(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8CD10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// li r27,0
	r27.s64 = 0;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// beq cr6,0x82c8ce68
	if (cr6.eq) goto loc_82C8CE68;
	// subf r30,r31,r29
	r30.s64 = r29.s64 - r31.s64;
loc_82C8CD3C:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bgt cr6,0x82c8ce58
	if (cr6.gt) goto loc_82C8CE58;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-12952
	r12.s64 = r12.s64 + -12952;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8CEE0;
	case 1:
		goto loc_82C8CEE0;
	case 2:
		goto loc_82C8CE1C;
	case 3:
		goto loc_82C8CE58;
	case 4:
		goto loc_82C8CE74;
	case 5:
		goto loc_82C8CD8C;
	case 6:
		goto loc_82C8CDBC;
	case 7:
		goto loc_82C8CDEC;
	case 8:
		goto loc_82C8CEE0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-12576(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12576);
	// lwz r22,-12576(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12576);
	// lwz r22,-12772(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12772);
	// lwz r22,-12712(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12712);
	// lwz r22,-12684(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12684);
	// lwz r22,-12916(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12916);
	// lwz r22,-12868(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12868);
	// lwz r22,-12820(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12820);
	// lwz r22,-12576(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12576);
loc_82C8CD8C:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// blt cr6,0x82c8cec4
	if (cr6.lt) goto loc_82C8CEC4;
	// lwz r11,356(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8ced0
	if (!cr6.eq) goto loc_82C8CED0;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r30,r30,-2
	r30.s64 = r30.s64 + -2;
	// b 0x82c8ce60
	goto loc_82C8CE60;
loc_82C8CDBC:
	// cmpwi cr6,r30,3
	cr6.compare<int32_t>(r30.s32, 3, xer);
	// blt cr6,0x82c8cec4
	if (cr6.lt) goto loc_82C8CEC4;
	// lwz r11,360(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8ced0
	if (!cr6.eq) goto loc_82C8CED0;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r30,r30,-3
	r30.s64 = r30.s64 + -3;
	// b 0x82c8ce60
	goto loc_82C8CE60;
loc_82C8CDEC:
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x82c8cec4
	if (cr6.lt) goto loc_82C8CEC4;
	// lwz r11,364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c8ced0
	if (!cr6.eq) goto loc_82C8CED0;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// b 0x82c8ce60
	goto loc_82C8CE60;
loc_82C8CE1C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// beq cr6,0x82c8ce68
	if (cr6.eq) goto loc_82C8CE68;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,33
	cr6.compare<uint32_t>(r11.u32, 33, xer);
	// bne cr6,0x82c8ce60
	if (!cr6.eq) goto loc_82C8CE60;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// beq cr6,0x82c8ce68
	if (cr6.eq) goto loc_82C8CE68;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,91
	cr6.compare<uint32_t>(r11.u32, 91, xer);
	// bne cr6,0x82c8ce60
	if (!cr6.eq) goto loc_82C8CE60;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
loc_82C8CE58:
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_82C8CE60:
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bne cr6,0x82c8cd3c
	if (!cr6.eq) goto loc_82C8CD3C;
loc_82C8CE68:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8CE74:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// beq cr6,0x82c8ce68
	if (cr6.eq) goto loc_82C8CE68;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c8ce60
	if (!cr6.eq) goto loc_82C8CE60;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// beq cr6,0x82c8ce68
	if (cr6.eq) goto loc_82C8CE68;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// bne cr6,0x82c8ce60
	if (!cr6.eq) goto loc_82C8CE60;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x82c8cef0
	if (cr6.eq) goto loc_82C8CEF0;
	// addi r27,r27,-1
	r27.s64 = r27.s64 + -1;
	// b 0x82c8ce60
	goto loc_82C8CE60;
loc_82C8CEC4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8CED0:
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8CEE0:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8CEF0:
	// li r3,42
	ctx.r3.s64 = 42;
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C8CD10) {
	__imp__sub_82C8CD10(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8CF00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	// addi r10,r4,1
	ctx.r10.s64 = ctx.r4.s64 + 1;
	// addi r8,r5,-1
	ctx.r8.s64 = ctx.r5.s64 + -1;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// beq cr6,0x82c8cff8
	if (cr6.eq) goto loc_82C8CFF8;
loc_82C8CF10:
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r9,r11,r3
	ctx.r9.u64 = r11.u64 + ctx.r3.u64;
	// lbz r9,76(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 76);
	// addi r9,r9,-9
	ctx.r9.s64 = ctx.r9.s64 + -9;
	// cmplwi cr6,r9,26
	cr6.compare<uint32_t>(ctx.r9.u32, 26, xer);
	// bgt cr6,0x82c8cfd8
	if (cr6.gt) goto loc_82C8CFD8;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-12480
	r12.s64 = r12.s64 + -12480;
	// rlwinm r0,r9,2,0,29
	r0.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82C8CFEC;
	case 1:
		goto loc_82C8CFEC;
	case 2:
		goto loc_82C8CFD8;
	case 3:
		goto loc_82C8CFD8;
	case 4:
		goto loc_82C8CFEC;
	case 5:
		goto loc_82C8CFEC;
	case 6:
		goto loc_82C8CFEC;
	case 7:
		goto loc_82C8CFEC;
	case 8:
		goto loc_82C8CFEC;
	case 9:
		goto loc_82C8CFEC;
	case 10:
		goto loc_82C8CFEC;
	case 11:
		goto loc_82C8CFD8;
	case 12:
		goto loc_82C8CFAC;
	case 13:
		goto loc_82C8CFC4;
	case 14:
		goto loc_82C8CFEC;
	case 15:
		goto loc_82C8CFEC;
	case 16:
		goto loc_82C8CFEC;
	case 17:
		goto loc_82C8CFC4;
	case 18:
		goto loc_82C8CFEC;
	case 19:
		goto loc_82C8CFD8;
	case 20:
		goto loc_82C8CFD8;
	case 21:
		goto loc_82C8CFEC;
	case 22:
		goto loc_82C8CFEC;
	case 23:
		goto loc_82C8CFEC;
	case 24:
		goto loc_82C8CFEC;
	case 25:
		goto loc_82C8CFEC;
	case 26:
		goto loc_82C8CFEC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12328);
	// lwz r22,-12328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12328);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12328);
	// lwz r22,-12372(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12372);
	// lwz r22,-12348(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12348);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12348(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12348);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12328);
	// lwz r22,-12328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12328);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
loc_82C8CFAC:
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82c8cfec
	if (!cr6.eq) goto loc_82C8CFEC;
loc_82C8CFB8:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8CFC4:
	// extsb r9,r11
	ctx.r9.s64 = r11.s8;
	// rlwinm r7,r9,0,0,24
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFF80;
	// extsb r4,r7
	ctx.r4.s64 = ctx.r7.s8;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq cr6,0x82c8cfec
	if (cr6.eq) goto loc_82C8CFEC;
loc_82C8CFD8:
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,36
	cr6.compare<int32_t>(r11.s32, 36, xer);
	// beq cr6,0x82c8cfec
	if (cr6.eq) goto loc_82C8CFEC;
	// cmpwi cr6,r11,64
	cr6.compare<int32_t>(r11.s32, 64, xer);
	// bne cr6,0x82c8cfb8
	if (!cr6.eq) goto loc_82C8CFB8;
loc_82C8CFEC:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c8cf10
	if (!cr6.eq) goto loc_82C8CF10;
loc_82C8CFF8:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8CF00) {
	__imp__sub_82C8CF00(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8D000) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2bec
	// li r29,0
	r29.s64 = 0;
	// addi r8,r4,1
	ctx.r8.s64 = ctx.r4.s64 + 1;
	// li r30,1
	r30.s64 = 1;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// mr r31,r29
	r31.u64 = r29.u64;
	// addi r4,r8,1
	ctx.r4.s64 = ctx.r8.s64 + 1;
loc_82C8D024:
	// lbz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// add r11,r10,r3
	r11.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-3
	r11.s64 = r11.s64 + -3;
	// cmplwi cr6,r11,26
	cr6.compare<uint32_t>(r11.u32, 26, xer);
	// bgt cr6,0x82c8d2dc
	if (cr6.gt) goto loc_82C8D2DC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-12204
	r12.s64 = r12.s64 + -12204;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8D2BC;
	case 1:
		goto loc_82C8D2DC;
	case 2:
		goto loc_82C8D0C0;
	case 3:
		goto loc_82C8D0F0;
	case 4:
		goto loc_82C8D120;
	case 5:
		goto loc_82C8D2DC;
	case 6:
		goto loc_82C8D29C;
	case 7:
		goto loc_82C8D29C;
	case 8:
		goto loc_82C8D2D4;
	case 9:
		goto loc_82C8D178;
	case 10:
		goto loc_82C8D1CC;
	case 11:
		goto loc_82C8D2DC;
	case 12:
		goto loc_82C8D2DC;
	case 13:
		goto loc_82C8D2DC;
	case 14:
		goto loc_82C8D2D4;
	case 15:
		goto loc_82C8D2DC;
	case 16:
		goto loc_82C8D2DC;
	case 17:
		goto loc_82C8D2DC;
	case 18:
		goto loc_82C8D220;
	case 19:
		goto loc_82C8D150;
	case 20:
		goto loc_82C8D2DC;
	case 21:
		goto loc_82C8D150;
	case 22:
		goto loc_82C8D2DC;
	case 23:
		goto loc_82C8D2DC;
	case 24:
		goto loc_82C8D2DC;
	case 25:
		goto loc_82C8D2DC;
	case 26:
		goto loc_82C8D150;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-11588(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11588);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-12096(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12096);
	// lwz r22,-12048(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12048);
	// lwz r22,-12000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12000);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11620(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11620);
	// lwz r22,-11620(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11620);
	// lwz r22,-11564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11564);
	// lwz r22,-11912(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11912);
	// lwz r22,-11828(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11828);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11564(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11564);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11744(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11744);
	// lwz r22,-11952(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11952);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11952(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11952);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11952(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11952);
loc_82C8D0C0:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c8d0dc
	if (!cr6.eq) goto loc_82C8D0DC;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c8d0d8
	if (!cr6.lt) goto loc_82C8D0D8;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r30,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r30.u8);
loc_82C8D0D8:
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
loc_82C8D0DC:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D0F0:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c8d10c
	if (!cr6.eq) goto loc_82C8D10C;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c8d108
	if (!cr6.lt) goto loc_82C8D108;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r30,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r30.u8);
loc_82C8D108:
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
loc_82C8D10C:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D120:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c8d13c
	if (!cr6.eq) goto loc_82C8D13C;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c8d138
	if (!cr6.lt) goto loc_82C8D138;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r30,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r30.u8);
loc_82C8D138:
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
loc_82C8D13C:
	// addi r8,r8,3
	ctx.r8.s64 = ctx.r8.s64 + 3;
	// addi r4,r4,3
	ctx.r4.s64 = ctx.r4.s64 + 3;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D150:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c8d2dc
	if (!cr6.eq) goto loc_82C8D2DC;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c8d168
	if (!cr6.lt) goto loc_82C8D168;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r30,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r30.u8);
loc_82C8D168:
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D178:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// beq cr6,0x82c8d1a0
	if (cr6.eq) goto loc_82C8D1A0;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c8d18c
	if (!cr6.lt) goto loc_82C8D18C;
	// stw r4,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r4.u32);
loc_82C8D18C:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r31,12
	r31.s64 = 12;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D1A0:
	// cmpwi cr6,r31,12
	cr6.compare<int32_t>(r31.s32, 12, xer);
	// bne cr6,0x82c8d2dc
	if (!cr6.eq) goto loc_82C8D2DC;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c8d1b8
	if (!cr6.lt) goto loc_82C8D1B8;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
loc_82C8D1B8:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D1CC:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// beq cr6,0x82c8d1f4
	if (cr6.eq) goto loc_82C8D1F4;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c8d1e0
	if (!cr6.lt) goto loc_82C8D1E0;
	// stw r4,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r4.u32);
loc_82C8D1E0:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r31,13
	r31.s64 = 13;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D1F4:
	// cmpwi cr6,r31,13
	cr6.compare<int32_t>(r31.s32, 13, xer);
	// bne cr6,0x82c8d2dc
	if (!cr6.eq) goto loc_82C8D2DC;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c8d1b8
	if (!cr6.lt) goto loc_82C8D1B8;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D220:
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// bne cr6,0x82c8d238
	if (!cr6.eq) goto loc_82C8D238;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D238:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bne cr6,0x82c8d2dc
	if (!cr6.eq) goto loc_82C8D2DC;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c8d2dc
	if (!cr6.lt) goto loc_82C8D2DC;
	// lbz r11,12(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c8d2dc
	if (cr6.eq) goto loc_82C8D2DC;
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// beq cr6,0x82c8d28c
	if (cr6.eq) goto loc_82C8D28C;
	// extsb r11,r10
	r11.s64 = ctx.r10.s8;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// bne cr6,0x82c8d28c
	if (!cr6.eq) goto loc_82C8D28C;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// beq cr6,0x82c8d28c
	if (cr6.eq) goto loc_82C8D28C;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lbz r10,76(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmpw cr6,r10,r31
	cr6.compare<int32_t>(ctx.r10.s32, r31.s32, xer);
	// bne cr6,0x82c8d2dc
	if (!cr6.eq) goto loc_82C8D2DC;
loc_82C8D28C:
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r29.u8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D29C:
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// bne cr6,0x82c8d2b4
	if (!cr6.eq) goto loc_82C8D2B4;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D2B4:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bne cr6,0x82c8d2dc
	if (!cr6.eq) goto loc_82C8D2DC;
loc_82C8D2BC:
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c8d2dc
	if (!cr6.lt) goto loc_82C8D2DC;
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r29.u8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D2D4:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bne cr6,0x82c8d2e8
	if (!cr6.eq) goto loc_82C8D2E8;
loc_82C8D2DC:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D2E8:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C8D000) {
	__imp__sub_82C8D000(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8D2F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// subf r11,r4,r5
	r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82c8d3b0
	if (cr6.eq) goto loc_82C8D3B0;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x82c8d384
	if (cr6.eq) goto loc_82C8D384;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,97
	cr6.compare<int32_t>(r11.s32, 97, xer);
	// beq cr6,0x82c8d354
	if (cr6.eq) goto loc_82C8D354;
	// cmpwi cr6,r11,113
	cr6.compare<int32_t>(r11.s32, 113, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// lbz r10,1(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// cmplwi cr6,r10,117
	cr6.compare<uint32_t>(ctx.r10.u32, 117, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,111
	cr6.compare<uint32_t>(ctx.r10.u32, 111, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// lbz r11,2(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// cmplwi cr6,r11,116
	cr6.compare<uint32_t>(r11.u32, 116, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// li r3,34
	ctx.r3.s64 = 34;
	// blr 
	return;
loc_82C8D354:
	// lbz r10,1(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// cmplwi cr6,r10,112
	cr6.compare<uint32_t>(ctx.r10.u32, 112, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,111
	cr6.compare<uint32_t>(ctx.r10.u32, 111, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// lbz r11,2(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// cmplwi cr6,r11,115
	cr6.compare<uint32_t>(r11.u32, 115, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// li r3,39
	ctx.r3.s64 = 39;
	// blr 
	return;
loc_82C8D384:
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,97
	cr6.compare<uint32_t>(r11.u32, 97, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,109
	cr6.compare<uint32_t>(r11.u32, 109, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// lbz r11,2(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// cmplwi cr6,r11,112
	cr6.compare<uint32_t>(r11.u32, 112, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// li r3,38
	ctx.r3.s64 = 38;
	// blr 
	return;
loc_82C8D3B0:
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,116
	cr6.compare<uint32_t>(r11.u32, 116, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,103
	cr6.compare<int32_t>(r11.s32, 103, xer);
	// beq cr6,0x82c8d3dc
	if (cr6.eq) goto loc_82C8D3DC;
	// cmpwi cr6,r11,108
	cr6.compare<int32_t>(r11.s32, 108, xer);
	// bne cr6,0x82c8d3e4
	if (!cr6.eq) goto loc_82C8D3E4;
	// li r3,60
	ctx.r3.s64 = 60;
	// blr 
	return;
loc_82C8D3DC:
	// li r3,62
	ctx.r3.s64 = 62;
	// blr 
	return;
loc_82C8D3E4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8D2F0) {
	__imp__sub_82C8D2F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8D3F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r10,r11,r3
	ctx.r10.u64 = r11.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-5
	ctx.r10.s64 = ctx.r10.s64 + -5;
	// cmplwi cr6,r10,24
	cr6.compare<uint32_t>(ctx.r10.u32, 24, xer);
	// bgt cr6,0x82c8d51c
	if (cr6.gt) goto loc_82C8D51C;
loc_82C8D408:
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-11232
	r12.s64 = r12.s64 + -11232;
	// rlwinm r0,r10,2,0,29
	r0.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C8D4B8;
	case 1:
		goto loc_82C8D4A0;
	case 2:
		goto loc_82C8D484;
	case 3:
		goto loc_82C8D51C;
	case 4:
		goto loc_82C8D51C;
	case 5:
		goto loc_82C8D51C;
	case 6:
		goto loc_82C8D51C;
	case 7:
		goto loc_82C8D51C;
	case 8:
		goto loc_82C8D51C;
	case 9:
		goto loc_82C8D51C;
	case 10:
		goto loc_82C8D51C;
	case 11:
		goto loc_82C8D51C;
	case 12:
		goto loc_82C8D51C;
	case 13:
		goto loc_82C8D51C;
	case 14:
		goto loc_82C8D51C;
	case 15:
		goto loc_82C8D51C;
	case 16:
		goto loc_82C8D51C;
	case 17:
		goto loc_82C8D4E8;
	case 18:
		goto loc_82C8D4E8;
	case 19:
		goto loc_82C8D4E8;
	case 20:
		goto loc_82C8D4E8;
	case 21:
		goto loc_82C8D4E8;
	case 22:
		goto loc_82C8D4E8;
	case 23:
		goto loc_82C8D51C;
	case 24:
		goto loc_82C8D4E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-11080(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11080);
	// lwz r22,-11104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11104);
	// lwz r22,-11132(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11132);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-11032(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-11032(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-11032(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-11032(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-11032(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-11032(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-10980(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-11032(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
loc_82C8D484:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r9,r11
	ctx.r9.s64 = r11.s8;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// extsb r8,r10
	ctx.r8.s64 = ctx.r10.s8;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// cmpw cr6,r9,r8
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, xer);
	// bne cr6,0x82c8d5c8
	if (!cr6.eq) goto loc_82C8D5C8;
loc_82C8D4A0:
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82c8d5c8
	if (!cr6.eq) goto loc_82C8D5C8;
loc_82C8D4B8:
	// lbz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// lbz r8,0(r5)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r10,r5,1
	ctx.r10.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c8d5c8
	if (!cr6.eq) goto loc_82C8D5C8;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r5,r10,1
	ctx.r5.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// b 0x82c8d500
	goto loc_82C8D500;
loc_82C8D4E8:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r9,r11
	ctx.r9.s64 = r11.s8;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// extsb r8,r10
	ctx.r8.s64 = ctx.r10.s8;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmpw cr6,r8,r9
	cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, xer);
loc_82C8D500:
	// bne cr6,0x82c8d5c8
	if (!cr6.eq) goto loc_82C8D5C8;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r10,r11,r3
	ctx.r10.u64 = r11.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-5
	ctx.r10.s64 = ctx.r10.s64 + -5;
	// cmplwi cr6,r10,24
	cr6.compare<uint32_t>(ctx.r10.u32, 24, xer);
	// ble cr6,0x82c8d408
	if (!cr6.gt) goto loc_82C8D408;
loc_82C8D51C:
	// lbz r11,0(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r9,r11
	ctx.r9.s64 = r11.s8;
	// extsb r8,r10
	ctx.r8.s64 = ctx.r10.s8;
	// cmpw cr6,r8,r9
	cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, xer);
	// beq cr6,0x82c8d5d0
	if (cr6.eq) goto loc_82C8D5D0;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8d5d0
	if (cr6.gt) goto loc_82C8D5D0;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-10908
	r12.s64 = r12.s64 + -10908;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8D5C8;
	case 1:
		goto loc_82C8D5C8;
	case 2:
		goto loc_82C8D5C8;
	case 3:
		goto loc_82C8D5D0;
	case 4:
		goto loc_82C8D5D0;
	case 5:
		goto loc_82C8D5D0;
	case 6:
		goto loc_82C8D5D0;
	case 7:
		goto loc_82C8D5D0;
	case 8:
		goto loc_82C8D5D0;
	case 9:
		goto loc_82C8D5D0;
	case 10:
		goto loc_82C8D5D0;
	case 11:
		goto loc_82C8D5D0;
	case 12:
		goto loc_82C8D5D0;
	case 13:
		goto loc_82C8D5D0;
	case 14:
		goto loc_82C8D5D0;
	case 15:
		goto loc_82C8D5D0;
	case 16:
		goto loc_82C8D5D0;
	case 17:
		goto loc_82C8D5C8;
	case 18:
		goto loc_82C8D5C8;
	case 19:
		goto loc_82C8D5C8;
	case 20:
		goto loc_82C8D5C8;
	case 21:
		goto loc_82C8D5C8;
	case 22:
		goto loc_82C8D5C8;
	case 23:
		goto loc_82C8D5D0;
	case 24:
		goto loc_82C8D5C8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-10808(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10808(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10800(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10808(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
loc_82C8D5C8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8D5D0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
	// lbz r11,0(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82c8d618
	if (cr6.eq) goto loc_82C8D618;
loc_82C8D5E8:
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8d628
	if (cr6.eq) goto loc_82C8D628;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// cmpw cr6,r9,r11
	cr6.compare<int32_t>(ctx.r9.s32, r11.s32, xer);
	// bne cr6,0x82c8d628
	if (!cr6.eq) goto loc_82C8D628;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// lbz r11,0(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c8d5e8
	if (!cr6.eq) goto loc_82C8D5E8;
loc_82C8D618:
	// subf r11,r4,r5
	r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r10,27,31,31
	ctx.r3.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// blr 
	return;
loc_82C8D628:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8d6fc
	if (cr6.gt) goto loc_82C8D6FC;
loc_82C8D64C:
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-10652
	r12.s64 = r12.s64 + -10652;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8D6C8;
	case 1:
		goto loc_82C8D6D0;
	case 2:
		goto loc_82C8D6D8;
	case 3:
		goto loc_82C8D6FC;
	case 4:
		goto loc_82C8D6FC;
	case 5:
		goto loc_82C8D6FC;
	case 6:
		goto loc_82C8D6FC;
	case 7:
		goto loc_82C8D6FC;
	case 8:
		goto loc_82C8D6FC;
	case 9:
		goto loc_82C8D6FC;
	case 10:
		goto loc_82C8D6FC;
	case 11:
		goto loc_82C8D6FC;
	case 12:
		goto loc_82C8D6FC;
	case 13:
		goto loc_82C8D6FC;
	case 14:
		goto loc_82C8D6FC;
	case 15:
		goto loc_82C8D6FC;
	case 16:
		goto loc_82C8D6FC;
	case 17:
		goto loc_82C8D6E0;
	case 18:
		goto loc_82C8D6E0;
	case 19:
		goto loc_82C8D6E0;
	case 20:
		goto loc_82C8D6E0;
	case 21:
		goto loc_82C8D6E0;
	case 22:
		goto loc_82C8D6E0;
	case 23:
		goto loc_82C8D6FC;
	case 24:
		goto loc_82C8D6E0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-10552(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10552);
	// lwz r22,-10544(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10544);
	// lwz r22,-10536(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10536);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10528(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10528(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10528(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10528(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10528(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10528(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10528(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
loc_82C8D6C8:
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// b 0x82c8d6e4
	goto loc_82C8D6E4;
loc_82C8D6D0:
	// addi r4,r4,3
	ctx.r4.s64 = ctx.r4.s64 + 3;
	// b 0x82c8d6e4
	goto loc_82C8D6E4;
loc_82C8D6D8:
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// b 0x82c8d6e4
	goto loc_82C8D6E4;
loc_82C8D6E0:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_82C8D6E4:
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// ble cr6,0x82c8d64c
	if (!cr6.gt) goto loc_82C8D64C;
loc_82C8D6FC:
	// subf r3,r10,r4
	ctx.r3.s64 = ctx.r4.s64 - ctx.r10.s64;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8D3F0) {
	__imp__sub_82C8D3F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8D708) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bltlr cr6
	if (cr6.lt) return;
loc_82C8D724:
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// ble cr6,0x82c8d734
	if (!cr6.gt) goto loc_82C8D734;
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// bnelr cr6
	if (!cr6.eq) return;
loc_82C8D734:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bge cr6,0x82c8d724
	if (!cr6.lt) goto loc_82C8D724;
	// blr 
	return;
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// li r10,-1
	ctx.r10.s64 = -1;
loc_82C8D75C:
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// addi r11,r11,-5
	r11.s64 = r11.s64 + -5;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// bgt cr6,0x82c8d7cc
	if (cr6.gt) goto loc_82C8D7CC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-10356
	r12.s64 = r12.s64 + -10356;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8D7A4;
	case 1:
		goto loc_82C8D7AC;
	case 2:
		goto loc_82C8D7B4;
	case 3:
		goto loc_82C8D7CC;
	case 4:
		goto loc_82C8D7E8;
	case 5:
		goto loc_82C8D7BC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-10332(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10332);
	// lwz r22,-10324(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10324);
	// lwz r22,-10316(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10316);
	// lwz r22,-10292(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10292);
	// lwz r22,-10264(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10264);
	// lwz r22,-10308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10308);
loc_82C8D7A4:
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// b 0x82c8d7d0
	goto loc_82C8D7D0;
loc_82C8D7AC:
	// addi r4,r4,3
	ctx.r4.s64 = ctx.r4.s64 + 3;
	// b 0x82c8d7d0
	goto loc_82C8D7D0;
loc_82C8D7B4:
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// b 0x82c8d7d0
	goto loc_82C8D7D0;
loc_82C8D7BC:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// stw r10,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r10.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
loc_82C8D7CC:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_82C8D7D0:
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, r11.u32);
	// bne cr6,0x82c8d75c
	if (!cr6.eq) goto loc_82C8D75C;
	// blr 
	return;
loc_82C8D7E8:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// beq cr6,0x82c8d818
	if (cr6.eq) goto loc_82C8D818;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lbz r9,76(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// cmplwi cr6,r9,10
	cr6.compare<uint32_t>(ctx.r9.u32, 10, xer);
	// bne cr6,0x82c8d818
	if (!cr6.eq) goto loc_82C8D818;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_82C8D818:
	// stw r10,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r10.u32);
	// b 0x82c8d7d0
	goto loc_82C8D7D0;
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// subf r9,r10,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r10.s64;
	// subf r8,r11,r5
	ctx.r8.s64 = ctx.r5.s64 - r11.s64;
	// cmpw cr6,r8,r9
	cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, xer);
	// ble cr6,0x82c8d86c
	if (!cr6.gt) goto loc_82C8D86C;
	// subf r9,r10,r11
	ctx.r9.s64 = r11.s64 - ctx.r10.s64;
	// add r5,r9,r7
	ctx.r5.u64 = ctx.r9.u64 + ctx.r7.u64;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bge cr6,0x82c8d870
	if (!cr6.lt) goto loc_82C8D870;
loc_82C8D848:
	// lbz r8,-1(r5)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r5.u32 + -1);
	// addi r9,r5,-1
	ctx.r9.s64 = ctx.r5.s64 + -1;
	// rlwinm r7,r8,0,0,25
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFC0;
	// cmplwi cr6,r7,128
	cr6.compare<uint32_t>(ctx.r7.u32, 128, xer);
	// bne cr6,0x82c8d86c
	if (!cr6.eq) goto loc_82C8D86C;
	// lwz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bgt cr6,0x82c8d848
	if (cr6.gt) goto loc_82C8D848;
loc_82C8D86C:
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
loc_82C8D870:
	// beq cr6,0x82c8d88c
	if (cr6.eq) goto loc_82C8D88C;
loc_82C8D874:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// stb r9,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r9.u8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// bne cr6,0x82c8d874
	if (!cr6.eq) goto loc_82C8D874;
loc_82C8D88C:
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8D708) {
	__imp__sub_82C8D708(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8D898) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2bec
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8d98c
	if (cr6.eq) goto loc_82C8D98C;
	// addi r9,r10,2
	ctx.r9.s64 = ctx.r10.s64 + 2;
	// lis r30,1
	r30.s64 = 65536;
loc_82C8D8B8:
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// beq cr6,0x82c8d98c
	if (cr6.eq) goto loc_82C8D98C;
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r31,r8,r3
	r31.u64 = ctx.r8.u64 + ctx.r3.u64;
	// lbz r31,76(r31)
	r31.u64 = PPC_LOAD_U8(r31.u32 + 76);
	// cmpwi cr6,r31,5
	cr6.compare<int32_t>(r31.s32, 5, xer);
	// beq cr6,0x82c8d964
	if (cr6.eq) goto loc_82C8D964;
	// cmpwi cr6,r31,6
	cr6.compare<int32_t>(r31.s32, 6, xer);
	// beq cr6,0x82c8d944
	if (cr6.eq) goto loc_82C8D944;
	// cmpwi cr6,r31,7
	cr6.compare<int32_t>(r31.s32, 7, xer);
	// beq cr6,0x82c8d8f0
	if (cr6.eq) goto loc_82C8D8F0;
	// extsb r8,r8
	ctx.r8.s64 = ctx.r8.s8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// b 0x82c8d978
	goto loc_82C8D978;
loc_82C8D8F0:
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// beq cr6,0x82c8d98c
	if (cr6.eq) goto loc_82C8D98C;
	// lbz r31,1(r11)
	r31.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// extsb r8,r8
	ctx.r8.s64 = ctx.r8.s8;
	// lbz r29,2(r11)
	r29.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// rlwimi r31,r8,6,23,25
	r31.u64 = (rotl32(ctx.r8.u32, 6) & 0x1C0) | (r31.u64 & 0xFFFFFFFFFFFFFE3F);
	// lbz r8,3(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// clrlwi r31,r31,23
	r31.u64 = r31.u32 & 0x1FF;
	// rlwimi r29,r31,6,0,25
	r29.u64 = (rotl32(r31.u32, 6) & 0xFFFFFFC0) | (r29.u64 & 0xFFFFFFFF0000003F);
	// rlwimi r8,r29,6,0,25
	ctx.r8.u64 = (rotl32(r29.u32, 6) & 0xFFFFFFC0) | (ctx.r8.u64 & 0xFFFFFFFF0000003F);
	// subf r8,r30,r8
	ctx.r8.s64 = ctx.r8.s64 - r30.s64;
	// rlwinm r31,r8,22,16,31
	r31.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 22) & 0xFFFF;
	// clrlwi r8,r8,22
	ctx.r8.u64 = ctx.r8.u32 & 0x3FF;
	// ori r31,r31,55296
	r31.u64 = r31.u64 | 55296;
	// ori r8,r8,56320
	ctx.r8.u64 = ctx.r8.u64 | 56320;
	// sth r31,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r31.u16);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// sth r8,0(r9)
	PPC_STORE_U16(ctx.r9.u32 + 0, ctx.r8.u16);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// b 0x82c8d984
	goto loc_82C8D984;
loc_82C8D944:
	// lbz r31,1(r11)
	r31.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// extsb r8,r8
	ctx.r8.s64 = ctx.r8.s8;
	// lbz r29,2(r11)
	r29.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// rlwimi r31,r8,6,0,25
	r31.u64 = (rotl32(ctx.r8.u32, 6) & 0xFFFFFFC0) | (r31.u64 & 0xFFFFFFFF0000003F);
	// rlwimi r29,r31,6,0,25
	r29.u64 = (rotl32(r31.u32, 6) & 0xFFFFFFC0) | (r29.u64 & 0xFFFFFFFF0000003F);
	// sth r29,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r29.u16);
	// b 0x82c8d97c
	goto loc_82C8D97C;
loc_82C8D964:
	// lbz r31,1(r11)
	r31.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// extsb r8,r8
	ctx.r8.s64 = ctx.r8.s8;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwimi r31,r8,6,21,25
	r31.u64 = (rotl32(ctx.r8.u32, 6) & 0x7C0) | (r31.u64 & 0xFFFFFFFFFFFFF83F);
	// clrlwi r8,r31,21
	ctx.r8.u64 = r31.u32 & 0x7FF;
loc_82C8D978:
	// sth r8,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r8.u16);
loc_82C8D97C:
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8D984:
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8d8b8
	if (!cr6.eq) goto loc_82C8D8B8;
loc_82C8D98C:
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C8D898) {
	__imp__sub_82C8D898(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8D998) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lis r11,511
	r11.s64 = 33488896;
	// ori r9,r11,65535
	ctx.r9.u64 = r11.u64 | 65535;
loc_82C8D9AC:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lbz r11,0(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// beq cr6,0x82c8da10
	if (cr6.eq) goto loc_82C8DA10;
	// subf r8,r10,r7
	ctx.r8.s64 = ctx.r7.s64 - ctx.r10.s64;
	// cmpwi cr6,r8,2
	cr6.compare<int32_t>(ctx.r8.s32, 2, xer);
	// bltlr cr6
	if (cr6.lt) return;
	// li r8,-64
	ctx.r8.s64 = -64;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// rlwimi r8,r11,26,30,31
	ctx.r8.u64 = (rotl32(r11.u32, 26) & 0x3) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFFC);
	// rlwimi r3,r9,7,0,25
	ctx.r3.u64 = (rotl32(ctx.r9.u32, 7) & 0xFFFFFFC0) | (ctx.r3.u64 & 0xFFFFFFFF0000003F);
	// stb r8,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r8.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// stb r3,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r8,r11,1
	ctx.r8.s64 = r11.s64 + 1;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// b 0x82c8da34
	goto loc_82C8DA34;
loc_82C8DA10:
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, r11.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
loc_82C8DA34:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8d9ac
	if (!cr6.eq) goto loc_82C8D9AC;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8D998) {
	__imp__sub_82C8D998(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8DA48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beqlr cr6
	if (cr6.eq) return;
loc_82C8DA54:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// sth r9,0(r11)
	PPC_STORE_U16(r11.u32 + 0, ctx.r9.u16);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r8,r11,2
	ctx.r8.s64 = r11.s64 + 2;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// rotlwi r11,r3,0
	r11.u64 = rotl32(ctx.r3.u32, 0);
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8da54
	if (!cr6.eq) goto loc_82C8DA54;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8DA48) {
	__imp__sub_82C8DA48(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8DA98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beqlr cr6
	if (cr6.eq) return;
loc_82C8DAA4:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// stb r9,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r8,r11,1
	ctx.r8.s64 = r11.s64 + 1;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// rotlwi r11,r3,0
	r11.u64 = rotl32(ctx.r3.u32, 0);
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8daa4
	if (!cr6.eq) goto loc_82C8DAA4;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8DA98) {
	__imp__sub_82C8DA98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8DAE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// addi r11,r11,-216
	r11.s64 = r11.s64 + -216;
	// cmplwi cr6,r11,39
	cr6.compare<uint32_t>(r11.u32, 39, xer);
	// bgt cr6,0x82c8dbd8
	if (cr6.gt) goto loc_82C8DBD8;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-9456
	r12.s64 = r12.s64 + -9456;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8DBB0;
	case 1:
		goto loc_82C8DBB0;
	case 2:
		goto loc_82C8DBB0;
	case 3:
		goto loc_82C8DBB0;
	case 4:
		goto loc_82C8DBB8;
	case 5:
		goto loc_82C8DBB8;
	case 6:
		goto loc_82C8DBB8;
	case 7:
		goto loc_82C8DBB8;
	case 8:
		goto loc_82C8DBD8;
	case 9:
		goto loc_82C8DBD8;
	case 10:
		goto loc_82C8DBD8;
	case 11:
		goto loc_82C8DBD8;
	case 12:
		goto loc_82C8DBD8;
	case 13:
		goto loc_82C8DBD8;
	case 14:
		goto loc_82C8DBD8;
	case 15:
		goto loc_82C8DBD8;
	case 16:
		goto loc_82C8DBD8;
	case 17:
		goto loc_82C8DBD8;
	case 18:
		goto loc_82C8DBD8;
	case 19:
		goto loc_82C8DBD8;
	case 20:
		goto loc_82C8DBD8;
	case 21:
		goto loc_82C8DBD8;
	case 22:
		goto loc_82C8DBD8;
	case 23:
		goto loc_82C8DBD8;
	case 24:
		goto loc_82C8DBD8;
	case 25:
		goto loc_82C8DBD8;
	case 26:
		goto loc_82C8DBD8;
	case 27:
		goto loc_82C8DBD8;
	case 28:
		goto loc_82C8DBD8;
	case 29:
		goto loc_82C8DBD8;
	case 30:
		goto loc_82C8DBD8;
	case 31:
		goto loc_82C8DBD8;
	case 32:
		goto loc_82C8DBD8;
	case 33:
		goto loc_82C8DBD8;
	case 34:
		goto loc_82C8DBD8;
	case 35:
		goto loc_82C8DBD8;
	case 36:
		goto loc_82C8DBD8;
	case 37:
		goto loc_82C8DBD8;
	case 38:
		goto loc_82C8DBD8;
	case 39:
		goto loc_82C8DBC0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-9296(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9296);
	// lwz r22,-9296(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9296);
	// lwz r22,-9296(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9296);
	// lwz r22,-9296(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9296);
	// lwz r22,-9288(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9288);
	// lwz r22,-9288(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9288);
	// lwz r22,-9288(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9288);
	// lwz r22,-9288(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9288);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9280(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9280);
loc_82C8DBB0:
	// li r3,7
	ctx.r3.s64 = 7;
	// blr 
	return;
loc_82C8DBB8:
	// li r3,8
	ctx.r3.s64 = 8;
	// blr 
	return;
loc_82C8DBC0:
	// clrlwi r11,r4,24
	r11.u64 = ctx.r4.u32 & 0xFF;
	// cmpwi cr6,r11,254
	cr6.compare<int32_t>(r11.s32, 254, xer);
	// blt cr6,0x82c8dbd8
	if (cr6.lt) goto loc_82C8DBD8;
	// cmpwi cr6,r11,255
	cr6.compare<int32_t>(r11.s32, 255, xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// blelr cr6
	if (!cr6.gt) return;
loc_82C8DBD8:
	// li r3,29
	ctx.r3.s64 = 29;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8DAE8) {
	__imp__sub_82C8DAE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8DBE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2be4
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8e130
	if (cr6.eq) goto loc_82C8E130;
	// lis r11,511
	r11.s64 = 33488896;
	// li r30,-16
	r30.s64 = -16;
	// ori r8,r11,65535
	ctx.r8.u64 = r11.u64 | 65535;
loc_82C8DC00:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// mr r31,r9
	r31.u64 = ctx.r9.u64;
	// cmplwi cr6,r31,219
	cr6.compare<uint32_t>(r31.u32, 219, xer);
	// bgt cr6,0x82c8e0c0
	if (cr6.gt) goto loc_82C8E0C0;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-9172
	r12.s64 = r12.s64 + -9172;
	// rlwinm r0,r31,2,0,29
	r0.u64 = rotl64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r31.u64) {
	case 0:
		goto loc_82C8DF9C;
	case 1:
		goto loc_82C8DFBC;
	case 2:
		goto loc_82C8DFBC;
	case 3:
		goto loc_82C8DFBC;
	case 4:
		goto loc_82C8DFBC;
	case 5:
		goto loc_82C8DFBC;
	case 6:
		goto loc_82C8DFBC;
	case 7:
		goto loc_82C8DFBC;
	case 8:
		goto loc_82C8E0C0;
	case 9:
		goto loc_82C8E0C0;
	case 10:
		goto loc_82C8E0C0;
	case 11:
		goto loc_82C8E0C0;
	case 12:
		goto loc_82C8E0C0;
	case 13:
		goto loc_82C8E0C0;
	case 14:
		goto loc_82C8E0C0;
	case 15:
		goto loc_82C8E0C0;
	case 16:
		goto loc_82C8E0C0;
	case 17:
		goto loc_82C8E0C0;
	case 18:
		goto loc_82C8E0C0;
	case 19:
		goto loc_82C8E0C0;
	case 20:
		goto loc_82C8E0C0;
	case 21:
		goto loc_82C8E0C0;
	case 22:
		goto loc_82C8E0C0;
	case 23:
		goto loc_82C8E0C0;
	case 24:
		goto loc_82C8E0C0;
	case 25:
		goto loc_82C8E0C0;
	case 26:
		goto loc_82C8E0C0;
	case 27:
		goto loc_82C8E0C0;
	case 28:
		goto loc_82C8E0C0;
	case 29:
		goto loc_82C8E0C0;
	case 30:
		goto loc_82C8E0C0;
	case 31:
		goto loc_82C8E0C0;
	case 32:
		goto loc_82C8E0C0;
	case 33:
		goto loc_82C8E0C0;
	case 34:
		goto loc_82C8E0C0;
	case 35:
		goto loc_82C8E0C0;
	case 36:
		goto loc_82C8E0C0;
	case 37:
		goto loc_82C8E0C0;
	case 38:
		goto loc_82C8E0C0;
	case 39:
		goto loc_82C8E0C0;
	case 40:
		goto loc_82C8E0C0;
	case 41:
		goto loc_82C8E0C0;
	case 42:
		goto loc_82C8E0C0;
	case 43:
		goto loc_82C8E0C0;
	case 44:
		goto loc_82C8E0C0;
	case 45:
		goto loc_82C8E0C0;
	case 46:
		goto loc_82C8E0C0;
	case 47:
		goto loc_82C8E0C0;
	case 48:
		goto loc_82C8E0C0;
	case 49:
		goto loc_82C8E0C0;
	case 50:
		goto loc_82C8E0C0;
	case 51:
		goto loc_82C8E0C0;
	case 52:
		goto loc_82C8E0C0;
	case 53:
		goto loc_82C8E0C0;
	case 54:
		goto loc_82C8E0C0;
	case 55:
		goto loc_82C8E0C0;
	case 56:
		goto loc_82C8E0C0;
	case 57:
		goto loc_82C8E0C0;
	case 58:
		goto loc_82C8E0C0;
	case 59:
		goto loc_82C8E0C0;
	case 60:
		goto loc_82C8E0C0;
	case 61:
		goto loc_82C8E0C0;
	case 62:
		goto loc_82C8E0C0;
	case 63:
		goto loc_82C8E0C0;
	case 64:
		goto loc_82C8E0C0;
	case 65:
		goto loc_82C8E0C0;
	case 66:
		goto loc_82C8E0C0;
	case 67:
		goto loc_82C8E0C0;
	case 68:
		goto loc_82C8E0C0;
	case 69:
		goto loc_82C8E0C0;
	case 70:
		goto loc_82C8E0C0;
	case 71:
		goto loc_82C8E0C0;
	case 72:
		goto loc_82C8E0C0;
	case 73:
		goto loc_82C8E0C0;
	case 74:
		goto loc_82C8E0C0;
	case 75:
		goto loc_82C8E0C0;
	case 76:
		goto loc_82C8E0C0;
	case 77:
		goto loc_82C8E0C0;
	case 78:
		goto loc_82C8E0C0;
	case 79:
		goto loc_82C8E0C0;
	case 80:
		goto loc_82C8E0C0;
	case 81:
		goto loc_82C8E0C0;
	case 82:
		goto loc_82C8E0C0;
	case 83:
		goto loc_82C8E0C0;
	case 84:
		goto loc_82C8E0C0;
	case 85:
		goto loc_82C8E0C0;
	case 86:
		goto loc_82C8E0C0;
	case 87:
		goto loc_82C8E0C0;
	case 88:
		goto loc_82C8E0C0;
	case 89:
		goto loc_82C8E0C0;
	case 90:
		goto loc_82C8E0C0;
	case 91:
		goto loc_82C8E0C0;
	case 92:
		goto loc_82C8E0C0;
	case 93:
		goto loc_82C8E0C0;
	case 94:
		goto loc_82C8E0C0;
	case 95:
		goto loc_82C8E0C0;
	case 96:
		goto loc_82C8E0C0;
	case 97:
		goto loc_82C8E0C0;
	case 98:
		goto loc_82C8E0C0;
	case 99:
		goto loc_82C8E0C0;
	case 100:
		goto loc_82C8E0C0;
	case 101:
		goto loc_82C8E0C0;
	case 102:
		goto loc_82C8E0C0;
	case 103:
		goto loc_82C8E0C0;
	case 104:
		goto loc_82C8E0C0;
	case 105:
		goto loc_82C8E0C0;
	case 106:
		goto loc_82C8E0C0;
	case 107:
		goto loc_82C8E0C0;
	case 108:
		goto loc_82C8E0C0;
	case 109:
		goto loc_82C8E0C0;
	case 110:
		goto loc_82C8E0C0;
	case 111:
		goto loc_82C8E0C0;
	case 112:
		goto loc_82C8E0C0;
	case 113:
		goto loc_82C8E0C0;
	case 114:
		goto loc_82C8E0C0;
	case 115:
		goto loc_82C8E0C0;
	case 116:
		goto loc_82C8E0C0;
	case 117:
		goto loc_82C8E0C0;
	case 118:
		goto loc_82C8E0C0;
	case 119:
		goto loc_82C8E0C0;
	case 120:
		goto loc_82C8E0C0;
	case 121:
		goto loc_82C8E0C0;
	case 122:
		goto loc_82C8E0C0;
	case 123:
		goto loc_82C8E0C0;
	case 124:
		goto loc_82C8E0C0;
	case 125:
		goto loc_82C8E0C0;
	case 126:
		goto loc_82C8E0C0;
	case 127:
		goto loc_82C8E0C0;
	case 128:
		goto loc_82C8E0C0;
	case 129:
		goto loc_82C8E0C0;
	case 130:
		goto loc_82C8E0C0;
	case 131:
		goto loc_82C8E0C0;
	case 132:
		goto loc_82C8E0C0;
	case 133:
		goto loc_82C8E0C0;
	case 134:
		goto loc_82C8E0C0;
	case 135:
		goto loc_82C8E0C0;
	case 136:
		goto loc_82C8E0C0;
	case 137:
		goto loc_82C8E0C0;
	case 138:
		goto loc_82C8E0C0;
	case 139:
		goto loc_82C8E0C0;
	case 140:
		goto loc_82C8E0C0;
	case 141:
		goto loc_82C8E0C0;
	case 142:
		goto loc_82C8E0C0;
	case 143:
		goto loc_82C8E0C0;
	case 144:
		goto loc_82C8E0C0;
	case 145:
		goto loc_82C8E0C0;
	case 146:
		goto loc_82C8E0C0;
	case 147:
		goto loc_82C8E0C0;
	case 148:
		goto loc_82C8E0C0;
	case 149:
		goto loc_82C8E0C0;
	case 150:
		goto loc_82C8E0C0;
	case 151:
		goto loc_82C8E0C0;
	case 152:
		goto loc_82C8E0C0;
	case 153:
		goto loc_82C8E0C0;
	case 154:
		goto loc_82C8E0C0;
	case 155:
		goto loc_82C8E0C0;
	case 156:
		goto loc_82C8E0C0;
	case 157:
		goto loc_82C8E0C0;
	case 158:
		goto loc_82C8E0C0;
	case 159:
		goto loc_82C8E0C0;
	case 160:
		goto loc_82C8E0C0;
	case 161:
		goto loc_82C8E0C0;
	case 162:
		goto loc_82C8E0C0;
	case 163:
		goto loc_82C8E0C0;
	case 164:
		goto loc_82C8E0C0;
	case 165:
		goto loc_82C8E0C0;
	case 166:
		goto loc_82C8E0C0;
	case 167:
		goto loc_82C8E0C0;
	case 168:
		goto loc_82C8E0C0;
	case 169:
		goto loc_82C8E0C0;
	case 170:
		goto loc_82C8E0C0;
	case 171:
		goto loc_82C8E0C0;
	case 172:
		goto loc_82C8E0C0;
	case 173:
		goto loc_82C8E0C0;
	case 174:
		goto loc_82C8E0C0;
	case 175:
		goto loc_82C8E0C0;
	case 176:
		goto loc_82C8E0C0;
	case 177:
		goto loc_82C8E0C0;
	case 178:
		goto loc_82C8E0C0;
	case 179:
		goto loc_82C8E0C0;
	case 180:
		goto loc_82C8E0C0;
	case 181:
		goto loc_82C8E0C0;
	case 182:
		goto loc_82C8E0C0;
	case 183:
		goto loc_82C8E0C0;
	case 184:
		goto loc_82C8E0C0;
	case 185:
		goto loc_82C8E0C0;
	case 186:
		goto loc_82C8E0C0;
	case 187:
		goto loc_82C8E0C0;
	case 188:
		goto loc_82C8E0C0;
	case 189:
		goto loc_82C8E0C0;
	case 190:
		goto loc_82C8E0C0;
	case 191:
		goto loc_82C8E0C0;
	case 192:
		goto loc_82C8E0C0;
	case 193:
		goto loc_82C8E0C0;
	case 194:
		goto loc_82C8E0C0;
	case 195:
		goto loc_82C8E0C0;
	case 196:
		goto loc_82C8E0C0;
	case 197:
		goto loc_82C8E0C0;
	case 198:
		goto loc_82C8E0C0;
	case 199:
		goto loc_82C8E0C0;
	case 200:
		goto loc_82C8E0C0;
	case 201:
		goto loc_82C8E0C0;
	case 202:
		goto loc_82C8E0C0;
	case 203:
		goto loc_82C8E0C0;
	case 204:
		goto loc_82C8E0C0;
	case 205:
		goto loc_82C8E0C0;
	case 206:
		goto loc_82C8E0C0;
	case 207:
		goto loc_82C8E0C0;
	case 208:
		goto loc_82C8E0C0;
	case 209:
		goto loc_82C8E0C0;
	case 210:
		goto loc_82C8E0C0;
	case 211:
		goto loc_82C8E0C0;
	case 212:
		goto loc_82C8E0C0;
	case 213:
		goto loc_82C8E0C0;
	case 214:
		goto loc_82C8E0C0;
	case 215:
		goto loc_82C8E0C0;
	case 216:
		goto loc_82C8E010;
	case 217:
		goto loc_82C8E010;
	case 218:
		goto loc_82C8E010;
	case 219:
		goto loc_82C8E010;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-8292(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8292);
	// lwz r22,-8260(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8176);
	// lwz r22,-8176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8176);
	// lwz r22,-8176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8176);
	// lwz r22,-8176(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8176);
loc_82C8DF9C:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r3,128
	cr6.compare<uint32_t>(ctx.r3.u32, 128, xer);
	// bge cr6,0x82c8dfbc
	if (!cr6.lt) goto loc_82C8DFBC;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// beq cr6,0x82c8e130
	if (cr6.eq) goto loc_82C8E130;
	// stb r11,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, r11.u8);
	// b 0x82c8e118
	goto loc_82C8E118;
loc_82C8DFBC:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r31,r3,r7
	r31.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r31,2
	cr6.compare<int32_t>(r31.s32, 2, xer);
	// blt cr6,0x82c8e130
	if (cr6.lt) goto loc_82C8E130;
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// li r31,-64
	r31.s64 = -64;
	// rlwinm r29,r11,26,30,31
	r29.u64 = rotl64(r11.u32 | (r11.u64 << 32), 26) & 0x3;
	// rlwimi r31,r9,2,26,29
	r31.u64 = (rotl32(ctx.r9.u32, 2) & 0x3C) | (r31.u64 & 0xFFFFFFFFFFFFFFC3);
	// rlwimi r11,r8,7,0,25
	r11.u64 = (rotl32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (r11.u64 & 0xFFFFFFFF0000003F);
	// extsb r9,r31
	ctx.r9.s64 = r31.s8;
	// mr r31,r11
	r31.u64 = r11.u64;
	// or r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 | r29.u64;
	// stb r9,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// stb r31,0(r11)
	PPC_STORE_U8(r11.u32 + 0, r31.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// stw r3,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r3.u32);
	// b 0x82c8e124
	goto loc_82C8E124;
loc_82C8E010:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r9,r3,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c8e130
	if (cr6.lt) goto loc_82C8E130;
	// rlwinm r9,r11,26,30,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 26) & 0x3;
	// rlwinm r31,r31,2,28,29
	r31.u64 = rotl64(r31.u32 | (r31.u64 << 32), 2) & 0xC;
	// li r29,-128
	r29.s64 = -128;
	// or r9,r9,r31
	ctx.r9.u64 = ctx.r9.u64 | r31.u64;
	// rlwinm r31,r11,30,28,31
	r31.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0xF;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// li r28,-32
	r28.s64 = -32;
	// srawi r27,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	r27.s64 = ctx.r9.s32 >> 2;
	// rlwimi r29,r9,4,26,27
	r29.u64 = (rotl32(ctx.r9.u32, 4) & 0x30) | (r29.u64 & 0xFFFFFFFFFFFFFFCF);
	// or r9,r27,r30
	ctx.r9.u64 = r27.u64 | r30.u64;
	// extsb r29,r29
	r29.s64 = r29.s8;
	// stb r9,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r9.u8);
	// rlwimi r28,r11,2,28,29
	r28.u64 = (rotl32(r11.u32, 2) & 0xC) | (r28.u64 & 0xFFFFFFFFFFFFFFF3);
	// or r3,r31,r29
	ctx.r3.u64 = r31.u64 | r29.u64;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r9.u32);
	// stb r3,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// clrlwi r3,r3,30
	ctx.r3.u64 = ctx.r3.u32 & 0x3;
	// or r3,r28,r3
	ctx.r3.u64 = r28.u64 | ctx.r3.u64;
	// rlwinm r31,r9,26,6,31
	r31.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwimi r9,r8,7,0,25
	ctx.r9.u64 = (rotl32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (ctx.r9.u64 & 0xFFFFFFFF0000003F);
	// extsb r3,r3
	ctx.r3.s64 = ctx.r3.s8;
	// or r3,r3,r31
	ctx.r3.u64 = ctx.r3.u64 | r31.u64;
	// stb r3,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// stb r9,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// stw r3,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r3.u32);
	// b 0x82c8e124
	goto loc_82C8E124;
loc_82C8E0C0:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r31,r3,r7
	r31.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r31,3
	cr6.compare<int32_t>(r31.s32, 3, xer);
	// blt cr6,0x82c8e130
	if (cr6.lt) goto loc_82C8E130;
	// li r31,-32
	r31.s64 = -32;
	// li r29,-128
	r29.s64 = -128;
	// rlwimi r31,r9,28,28,31
	r31.u64 = (rotl32(ctx.r9.u32, 28) & 0xF) | (r31.u64 & 0xFFFFFFFFFFFFFFF0);
	// rlwimi r29,r9,2,26,29
	r29.u64 = (rotl32(ctx.r9.u32, 2) & 0x3C) | (r29.u64 & 0xFFFFFFFFFFFFFFC3);
	// stb r31,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, r31.u8);
	// rlwinm r3,r11,26,30,31
	ctx.r3.u64 = rotl64(r11.u32 | (r11.u64 << 32), 26) & 0x3;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// mr r31,r11
	r31.u64 = r11.u64;
	// addi r11,r9,1
	r11.s64 = ctx.r9.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// extsb r11,r29
	r11.s64 = r29.s8;
	// rlwimi r31,r8,7,0,25
	r31.u64 = (rotl32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (r31.u64 & 0xFFFFFFFF0000003F);
	// or r3,r11,r3
	ctx.r3.u64 = r11.u64 | ctx.r3.u64;
	// stb r3,1(r9)
	PPC_STORE_U8(ctx.r9.u32 + 1, ctx.r3.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// stb r31,0(r11)
	PPC_STORE_U8(r11.u32 + 0, r31.u8);
loc_82C8E118:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
loc_82C8E124:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8dc00
	if (!cr6.eq) goto loc_82C8DC00;
loc_82C8E130:
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C8DBE0) {
	__imp__sub_82C8DBE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8E138) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// subf r9,r10,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r10.s64;
	// subf r8,r11,r5
	ctx.r8.s64 = ctx.r5.s64 - r11.s64;
	// rlwinm r3,r9,0,0,30
	ctx.r3.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// cmpw cr6,r8,r3
	cr6.compare<int32_t>(ctx.r8.s32, ctx.r3.s32, xer);
	// ble cr6,0x82c8e168
	if (!cr6.gt) goto loc_82C8E168;
	// lbz r10,-1(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + -1);
	// rlwinm r9,r10,0,0,28
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF8;
	// cmplwi cr6,r9,216
	cr6.compare<uint32_t>(ctx.r9.u32, 216, xer);
	// bne cr6,0x82c8e168
	if (!cr6.eq) goto loc_82C8E168;
	// addi r5,r5,-2
	ctx.r5.s64 = ctx.r5.s64 + -2;
loc_82C8E168:
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beqlr cr6
	if (cr6.eq) return;
loc_82C8E170:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// rotlwi r3,r9,8
	ctx.r3.u64 = rotl32(ctx.r9.u32, 8);
	// or r10,r3,r8
	ctx.r10.u64 = ctx.r3.u64 | ctx.r8.u64;
	// sth r10,0(r11)
	PPC_STORE_U16(r11.u32 + 0, ctx.r10.u16);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r8,r11,2
	ctx.r8.s64 = r11.s64 + 2;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r3,r11,2
	ctx.r3.s64 = r11.s64 + 2;
	// rotlwi r11,r3,0
	r11.u64 = rotl32(ctx.r3.u32, 0);
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8e170
	if (!cr6.eq) goto loc_82C8E170;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8E138) {
	__imp__sub_82C8E138(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8E1C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x82ca2be4
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8e710
	if (cr6.eq) goto loc_82C8E710;
	// lis r11,511
	r11.s64 = 33488896;
	// li r30,-16
	r30.s64 = -16;
	// ori r8,r11,65535
	ctx.r8.u64 = r11.u64 | 65535;
loc_82C8E1E0:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// mr r31,r9
	r31.u64 = ctx.r9.u64;
	// cmplwi cr6,r31,219
	cr6.compare<uint32_t>(r31.u32, 219, xer);
	// bgt cr6,0x82c8e6a0
	if (cr6.gt) goto loc_82C8E6A0;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-7668
	r12.s64 = r12.s64 + -7668;
	// rlwinm r0,r31,2,0,29
	r0.u64 = rotl64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r31.u64) {
	case 0:
		goto loc_82C8E57C;
	case 1:
		goto loc_82C8E59C;
	case 2:
		goto loc_82C8E59C;
	case 3:
		goto loc_82C8E59C;
	case 4:
		goto loc_82C8E59C;
	case 5:
		goto loc_82C8E59C;
	case 6:
		goto loc_82C8E59C;
	case 7:
		goto loc_82C8E59C;
	case 8:
		goto loc_82C8E6A0;
	case 9:
		goto loc_82C8E6A0;
	case 10:
		goto loc_82C8E6A0;
	case 11:
		goto loc_82C8E6A0;
	case 12:
		goto loc_82C8E6A0;
	case 13:
		goto loc_82C8E6A0;
	case 14:
		goto loc_82C8E6A0;
	case 15:
		goto loc_82C8E6A0;
	case 16:
		goto loc_82C8E6A0;
	case 17:
		goto loc_82C8E6A0;
	case 18:
		goto loc_82C8E6A0;
	case 19:
		goto loc_82C8E6A0;
	case 20:
		goto loc_82C8E6A0;
	case 21:
		goto loc_82C8E6A0;
	case 22:
		goto loc_82C8E6A0;
	case 23:
		goto loc_82C8E6A0;
	case 24:
		goto loc_82C8E6A0;
	case 25:
		goto loc_82C8E6A0;
	case 26:
		goto loc_82C8E6A0;
	case 27:
		goto loc_82C8E6A0;
	case 28:
		goto loc_82C8E6A0;
	case 29:
		goto loc_82C8E6A0;
	case 30:
		goto loc_82C8E6A0;
	case 31:
		goto loc_82C8E6A0;
	case 32:
		goto loc_82C8E6A0;
	case 33:
		goto loc_82C8E6A0;
	case 34:
		goto loc_82C8E6A0;
	case 35:
		goto loc_82C8E6A0;
	case 36:
		goto loc_82C8E6A0;
	case 37:
		goto loc_82C8E6A0;
	case 38:
		goto loc_82C8E6A0;
	case 39:
		goto loc_82C8E6A0;
	case 40:
		goto loc_82C8E6A0;
	case 41:
		goto loc_82C8E6A0;
	case 42:
		goto loc_82C8E6A0;
	case 43:
		goto loc_82C8E6A0;
	case 44:
		goto loc_82C8E6A0;
	case 45:
		goto loc_82C8E6A0;
	case 46:
		goto loc_82C8E6A0;
	case 47:
		goto loc_82C8E6A0;
	case 48:
		goto loc_82C8E6A0;
	case 49:
		goto loc_82C8E6A0;
	case 50:
		goto loc_82C8E6A0;
	case 51:
		goto loc_82C8E6A0;
	case 52:
		goto loc_82C8E6A0;
	case 53:
		goto loc_82C8E6A0;
	case 54:
		goto loc_82C8E6A0;
	case 55:
		goto loc_82C8E6A0;
	case 56:
		goto loc_82C8E6A0;
	case 57:
		goto loc_82C8E6A0;
	case 58:
		goto loc_82C8E6A0;
	case 59:
		goto loc_82C8E6A0;
	case 60:
		goto loc_82C8E6A0;
	case 61:
		goto loc_82C8E6A0;
	case 62:
		goto loc_82C8E6A0;
	case 63:
		goto loc_82C8E6A0;
	case 64:
		goto loc_82C8E6A0;
	case 65:
		goto loc_82C8E6A0;
	case 66:
		goto loc_82C8E6A0;
	case 67:
		goto loc_82C8E6A0;
	case 68:
		goto loc_82C8E6A0;
	case 69:
		goto loc_82C8E6A0;
	case 70:
		goto loc_82C8E6A0;
	case 71:
		goto loc_82C8E6A0;
	case 72:
		goto loc_82C8E6A0;
	case 73:
		goto loc_82C8E6A0;
	case 74:
		goto loc_82C8E6A0;
	case 75:
		goto loc_82C8E6A0;
	case 76:
		goto loc_82C8E6A0;
	case 77:
		goto loc_82C8E6A0;
	case 78:
		goto loc_82C8E6A0;
	case 79:
		goto loc_82C8E6A0;
	case 80:
		goto loc_82C8E6A0;
	case 81:
		goto loc_82C8E6A0;
	case 82:
		goto loc_82C8E6A0;
	case 83:
		goto loc_82C8E6A0;
	case 84:
		goto loc_82C8E6A0;
	case 85:
		goto loc_82C8E6A0;
	case 86:
		goto loc_82C8E6A0;
	case 87:
		goto loc_82C8E6A0;
	case 88:
		goto loc_82C8E6A0;
	case 89:
		goto loc_82C8E6A0;
	case 90:
		goto loc_82C8E6A0;
	case 91:
		goto loc_82C8E6A0;
	case 92:
		goto loc_82C8E6A0;
	case 93:
		goto loc_82C8E6A0;
	case 94:
		goto loc_82C8E6A0;
	case 95:
		goto loc_82C8E6A0;
	case 96:
		goto loc_82C8E6A0;
	case 97:
		goto loc_82C8E6A0;
	case 98:
		goto loc_82C8E6A0;
	case 99:
		goto loc_82C8E6A0;
	case 100:
		goto loc_82C8E6A0;
	case 101:
		goto loc_82C8E6A0;
	case 102:
		goto loc_82C8E6A0;
	case 103:
		goto loc_82C8E6A0;
	case 104:
		goto loc_82C8E6A0;
	case 105:
		goto loc_82C8E6A0;
	case 106:
		goto loc_82C8E6A0;
	case 107:
		goto loc_82C8E6A0;
	case 108:
		goto loc_82C8E6A0;
	case 109:
		goto loc_82C8E6A0;
	case 110:
		goto loc_82C8E6A0;
	case 111:
		goto loc_82C8E6A0;
	case 112:
		goto loc_82C8E6A0;
	case 113:
		goto loc_82C8E6A0;
	case 114:
		goto loc_82C8E6A0;
	case 115:
		goto loc_82C8E6A0;
	case 116:
		goto loc_82C8E6A0;
	case 117:
		goto loc_82C8E6A0;
	case 118:
		goto loc_82C8E6A0;
	case 119:
		goto loc_82C8E6A0;
	case 120:
		goto loc_82C8E6A0;
	case 121:
		goto loc_82C8E6A0;
	case 122:
		goto loc_82C8E6A0;
	case 123:
		goto loc_82C8E6A0;
	case 124:
		goto loc_82C8E6A0;
	case 125:
		goto loc_82C8E6A0;
	case 126:
		goto loc_82C8E6A0;
	case 127:
		goto loc_82C8E6A0;
	case 128:
		goto loc_82C8E6A0;
	case 129:
		goto loc_82C8E6A0;
	case 130:
		goto loc_82C8E6A0;
	case 131:
		goto loc_82C8E6A0;
	case 132:
		goto loc_82C8E6A0;
	case 133:
		goto loc_82C8E6A0;
	case 134:
		goto loc_82C8E6A0;
	case 135:
		goto loc_82C8E6A0;
	case 136:
		goto loc_82C8E6A0;
	case 137:
		goto loc_82C8E6A0;
	case 138:
		goto loc_82C8E6A0;
	case 139:
		goto loc_82C8E6A0;
	case 140:
		goto loc_82C8E6A0;
	case 141:
		goto loc_82C8E6A0;
	case 142:
		goto loc_82C8E6A0;
	case 143:
		goto loc_82C8E6A0;
	case 144:
		goto loc_82C8E6A0;
	case 145:
		goto loc_82C8E6A0;
	case 146:
		goto loc_82C8E6A0;
	case 147:
		goto loc_82C8E6A0;
	case 148:
		goto loc_82C8E6A0;
	case 149:
		goto loc_82C8E6A0;
	case 150:
		goto loc_82C8E6A0;
	case 151:
		goto loc_82C8E6A0;
	case 152:
		goto loc_82C8E6A0;
	case 153:
		goto loc_82C8E6A0;
	case 154:
		goto loc_82C8E6A0;
	case 155:
		goto loc_82C8E6A0;
	case 156:
		goto loc_82C8E6A0;
	case 157:
		goto loc_82C8E6A0;
	case 158:
		goto loc_82C8E6A0;
	case 159:
		goto loc_82C8E6A0;
	case 160:
		goto loc_82C8E6A0;
	case 161:
		goto loc_82C8E6A0;
	case 162:
		goto loc_82C8E6A0;
	case 163:
		goto loc_82C8E6A0;
	case 164:
		goto loc_82C8E6A0;
	case 165:
		goto loc_82C8E6A0;
	case 166:
		goto loc_82C8E6A0;
	case 167:
		goto loc_82C8E6A0;
	case 168:
		goto loc_82C8E6A0;
	case 169:
		goto loc_82C8E6A0;
	case 170:
		goto loc_82C8E6A0;
	case 171:
		goto loc_82C8E6A0;
	case 172:
		goto loc_82C8E6A0;
	case 173:
		goto loc_82C8E6A0;
	case 174:
		goto loc_82C8E6A0;
	case 175:
		goto loc_82C8E6A0;
	case 176:
		goto loc_82C8E6A0;
	case 177:
		goto loc_82C8E6A0;
	case 178:
		goto loc_82C8E6A0;
	case 179:
		goto loc_82C8E6A0;
	case 180:
		goto loc_82C8E6A0;
	case 181:
		goto loc_82C8E6A0;
	case 182:
		goto loc_82C8E6A0;
	case 183:
		goto loc_82C8E6A0;
	case 184:
		goto loc_82C8E6A0;
	case 185:
		goto loc_82C8E6A0;
	case 186:
		goto loc_82C8E6A0;
	case 187:
		goto loc_82C8E6A0;
	case 188:
		goto loc_82C8E6A0;
	case 189:
		goto loc_82C8E6A0;
	case 190:
		goto loc_82C8E6A0;
	case 191:
		goto loc_82C8E6A0;
	case 192:
		goto loc_82C8E6A0;
	case 193:
		goto loc_82C8E6A0;
	case 194:
		goto loc_82C8E6A0;
	case 195:
		goto loc_82C8E6A0;
	case 196:
		goto loc_82C8E6A0;
	case 197:
		goto loc_82C8E6A0;
	case 198:
		goto loc_82C8E6A0;
	case 199:
		goto loc_82C8E6A0;
	case 200:
		goto loc_82C8E6A0;
	case 201:
		goto loc_82C8E6A0;
	case 202:
		goto loc_82C8E6A0;
	case 203:
		goto loc_82C8E6A0;
	case 204:
		goto loc_82C8E6A0;
	case 205:
		goto loc_82C8E6A0;
	case 206:
		goto loc_82C8E6A0;
	case 207:
		goto loc_82C8E6A0;
	case 208:
		goto loc_82C8E6A0;
	case 209:
		goto loc_82C8E6A0;
	case 210:
		goto loc_82C8E6A0;
	case 211:
		goto loc_82C8E6A0;
	case 212:
		goto loc_82C8E6A0;
	case 213:
		goto loc_82C8E6A0;
	case 214:
		goto loc_82C8E6A0;
	case 215:
		goto loc_82C8E6A0;
	case 216:
		goto loc_82C8E5F0;
	case 217:
		goto loc_82C8E5F0;
	case 218:
		goto loc_82C8E5F0;
	case 219:
		goto loc_82C8E5F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-6788(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6788);
	// lwz r22,-6756(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6672(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
	// lwz r22,-6672(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
	// lwz r22,-6672(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
	// lwz r22,-6672(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
loc_82C8E57C:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r3,128
	cr6.compare<uint32_t>(ctx.r3.u32, 128, xer);
	// bge cr6,0x82c8e59c
	if (!cr6.lt) goto loc_82C8E59C;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// beq cr6,0x82c8e710
	if (cr6.eq) goto loc_82C8E710;
	// stb r11,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, r11.u8);
	// b 0x82c8e6f8
	goto loc_82C8E6F8;
loc_82C8E59C:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r31,r3,r7
	r31.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r31,2
	cr6.compare<int32_t>(r31.s32, 2, xer);
	// blt cr6,0x82c8e710
	if (cr6.lt) goto loc_82C8E710;
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// li r31,-64
	r31.s64 = -64;
	// rlwinm r29,r11,26,30,31
	r29.u64 = rotl64(r11.u32 | (r11.u64 << 32), 26) & 0x3;
	// rlwimi r31,r9,2,26,29
	r31.u64 = (rotl32(ctx.r9.u32, 2) & 0x3C) | (r31.u64 & 0xFFFFFFFFFFFFFFC3);
	// rlwimi r11,r8,7,0,25
	r11.u64 = (rotl32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (r11.u64 & 0xFFFFFFFF0000003F);
	// extsb r9,r31
	ctx.r9.s64 = r31.s8;
	// mr r31,r11
	r31.u64 = r11.u64;
	// or r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 | r29.u64;
	// stb r9,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// stb r31,0(r11)
	PPC_STORE_U8(r11.u32 + 0, r31.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// stw r3,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r3.u32);
	// b 0x82c8e704
	goto loc_82C8E704;
loc_82C8E5F0:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r9,r3,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c8e710
	if (cr6.lt) goto loc_82C8E710;
	// rlwinm r9,r11,26,30,31
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 26) & 0x3;
	// rlwinm r31,r31,2,28,29
	r31.u64 = rotl64(r31.u32 | (r31.u64 << 32), 2) & 0xC;
	// li r29,-128
	r29.s64 = -128;
	// or r9,r9,r31
	ctx.r9.u64 = ctx.r9.u64 | r31.u64;
	// rlwinm r31,r11,30,28,31
	r31.u64 = rotl64(r11.u32 | (r11.u64 << 32), 30) & 0xF;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// li r28,-32
	r28.s64 = -32;
	// srawi r27,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	r27.s64 = ctx.r9.s32 >> 2;
	// rlwimi r29,r9,4,26,27
	r29.u64 = (rotl32(ctx.r9.u32, 4) & 0x30) | (r29.u64 & 0xFFFFFFFFFFFFFFCF);
	// or r9,r27,r30
	ctx.r9.u64 = r27.u64 | r30.u64;
	// extsb r29,r29
	r29.s64 = r29.s8;
	// stb r9,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r9.u8);
	// rlwimi r28,r11,2,28,29
	r28.u64 = (rotl32(r11.u32, 2) & 0xC) | (r28.u64 & 0xFFFFFFFFFFFFFFF3);
	// or r3,r31,r29
	ctx.r3.u64 = r31.u64 | r29.u64;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r9.u32);
	// stb r3,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// clrlwi r3,r3,30
	ctx.r3.u64 = ctx.r3.u32 & 0x3;
	// or r3,r28,r3
	ctx.r3.u64 = r28.u64 | ctx.r3.u64;
	// rlwinm r31,r9,26,6,31
	r31.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwimi r9,r8,7,0,25
	ctx.r9.u64 = (rotl32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (ctx.r9.u64 & 0xFFFFFFFF0000003F);
	// extsb r3,r3
	ctx.r3.s64 = ctx.r3.s8;
	// or r3,r3,r31
	ctx.r3.u64 = ctx.r3.u64 | r31.u64;
	// stb r3,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// stb r9,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// stw r3,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r3.u32);
	// b 0x82c8e704
	goto loc_82C8E704;
loc_82C8E6A0:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r31,r3,r7
	r31.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r31,3
	cr6.compare<int32_t>(r31.s32, 3, xer);
	// blt cr6,0x82c8e710
	if (cr6.lt) goto loc_82C8E710;
	// li r31,-32
	r31.s64 = -32;
	// li r29,-128
	r29.s64 = -128;
	// rlwimi r31,r9,28,28,31
	r31.u64 = (rotl32(ctx.r9.u32, 28) & 0xF) | (r31.u64 & 0xFFFFFFFFFFFFFFF0);
	// rlwimi r29,r9,2,26,29
	r29.u64 = (rotl32(ctx.r9.u32, 2) & 0x3C) | (r29.u64 & 0xFFFFFFFFFFFFFFC3);
	// stb r31,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, r31.u8);
	// rlwinm r3,r11,26,30,31
	ctx.r3.u64 = rotl64(r11.u32 | (r11.u64 << 32), 26) & 0x3;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// mr r31,r11
	r31.u64 = r11.u64;
	// addi r11,r9,1
	r11.s64 = ctx.r9.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// extsb r11,r29
	r11.s64 = r29.s8;
	// rlwimi r31,r8,7,0,25
	r31.u64 = (rotl32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (r31.u64 & 0xFFFFFFFF0000003F);
	// or r3,r11,r3
	ctx.r3.u64 = r11.u64 | ctx.r3.u64;
	// stb r3,1(r9)
	PPC_STORE_U8(ctx.r9.u32 + 1, ctx.r3.u8);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// stb r31,0(r11)
	PPC_STORE_U8(r11.u32 + 0, r31.u8);
loc_82C8E6F8:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
loc_82C8E704:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8e1e0
	if (!cr6.eq) goto loc_82C8E1E0;
loc_82C8E710:
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C8E1C0) {
	__imp__sub_82C8E1C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8E718) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// subf r9,r10,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r10.s64;
	// subf r8,r11,r5
	ctx.r8.s64 = ctx.r5.s64 - r11.s64;
	// rlwinm r3,r9,0,0,30
	ctx.r3.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// cmpw cr6,r8,r3
	cr6.compare<int32_t>(ctx.r8.s32, ctx.r3.s32, xer);
	// ble cr6,0x82c8e748
	if (!cr6.gt) goto loc_82C8E748;
	// lbz r10,-2(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + -2);
	// rlwinm r9,r10,0,0,28
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF8;
	// cmplwi cr6,r9,216
	cr6.compare<uint32_t>(ctx.r9.u32, 216, xer);
	// bne cr6,0x82c8e748
	if (!cr6.eq) goto loc_82C8E748;
	// addi r5,r5,-2
	ctx.r5.s64 = ctx.r5.s64 + -2;
loc_82C8E748:
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beqlr cr6
	if (cr6.eq) return;
loc_82C8E750:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rotlwi r3,r9,8
	ctx.r3.u64 = rotl32(ctx.r9.u32, 8);
	// or r10,r3,r8
	ctx.r10.u64 = ctx.r3.u64 | ctx.r8.u64;
	// sth r10,0(r11)
	PPC_STORE_U16(r11.u32 + 0, ctx.r10.u16);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r8,r11,2
	ctx.r8.s64 = r11.s64 + 2;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r3,r11,2
	ctx.r3.s64 = r11.s64 + 2;
	// rotlwi r11,r3,0
	r11.u64 = rotl32(ctx.r3.u32, 0);
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8e750
	if (!cr6.eq) goto loc_82C8E750;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8E718) {
	__imp__sub_82C8E718(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8E7A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8e8ac
	if (cr6.eq) goto loc_82C8E8AC;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c8e994
	if (!cr6.eq) goto loc_82C8E994;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,45
	cr6.compare<uint32_t>(r11.u32, 45, xer);
	// bne cr6,0x82c8e994
	if (!cr6.eq) goto loc_82C8E994;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8e8ac
	if (cr6.eq) goto loc_82C8E8AC;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C8E7E0:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8e7fc
	if (!cr6.eq) goto loc_82C8E7FC;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8e804
	goto loc_82C8E804;
loc_82C8E7FC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8E804:
	// cmplwi cr6,r3,27
	cr6.compare<uint32_t>(ctx.r3.u32, 27, xer);
	// bgt cr6,0x82c8e89c
	if (cr6.gt) goto loc_82C8E89C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-6108
	r12.s64 = r12.s64 + -6108;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8E964;
	case 1:
		goto loc_82C8E964;
	case 2:
		goto loc_82C8E89C;
	case 3:
		goto loc_82C8E89C;
	case 4:
		goto loc_82C8E89C;
	case 5:
		goto loc_82C8E894;
	case 6:
		goto loc_82C8E8C0;
	case 7:
		goto loc_82C8E8D4;
	case 8:
		goto loc_82C8E964;
	case 9:
		goto loc_82C8E89C;
	case 10:
		goto loc_82C8E89C;
	case 11:
		goto loc_82C8E89C;
	case 12:
		goto loc_82C8E89C;
	case 13:
		goto loc_82C8E89C;
	case 14:
		goto loc_82C8E89C;
	case 15:
		goto loc_82C8E89C;
	case 16:
		goto loc_82C8E89C;
	case 17:
		goto loc_82C8E89C;
	case 18:
		goto loc_82C8E89C;
	case 19:
		goto loc_82C8E89C;
	case 20:
		goto loc_82C8E89C;
	case 21:
		goto loc_82C8E89C;
	case 22:
		goto loc_82C8E89C;
	case 23:
		goto loc_82C8E89C;
	case 24:
		goto loc_82C8E89C;
	case 25:
		goto loc_82C8E89C;
	case 26:
		goto loc_82C8E89C;
	case 27:
		goto loc_82C8E8E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5788(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5788);
	// lwz r22,-5788(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5788);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5996(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5996);
	// lwz r22,-5952(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5952);
	// lwz r22,-5932(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5932);
	// lwz r22,-5788(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5788);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5912(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5912);
loc_82C8E894:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// blt cr6,0x82c8e950
	if (cr6.lt) goto loc_82C8E950;
loc_82C8E89C:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8E8A4:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8e7e0
	if (!cr6.eq) goto loc_82C8E7E0;
loc_82C8E8AC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8E8C0:
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// blt cr6,0x82c8e950
	if (cr6.lt) goto loc_82C8E950;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c8e8a4
	goto loc_82C8E8A4;
loc_82C8E8D4:
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c8e950
	if (cr6.lt) goto loc_82C8E950;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c8e8a4
	goto loc_82C8E8A4;
loc_82C8E8E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8e8ac
	if (cr6.eq) goto loc_82C8E8AC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c8e8a4
	if (!cr6.eq) goto loc_82C8E8A4;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,45
	cr6.compare<uint32_t>(r11.u32, 45, xer);
	// bne cr6,0x82c8e8a4
	if (!cr6.eq) goto loc_82C8E8A4;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8e8ac
	if (cr6.eq) goto loc_82C8E8AC;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c8e97c
	if (!cr6.eq) goto loc_82C8E97C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c8e97c
	if (!cr6.eq) goto loc_82C8E97C;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// li r3,13
	ctx.r3.s64 = 13;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8E950:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8E964:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8E97C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8E994:
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8E7A0) {
	__imp__sub_82C8E7A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8E9B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8e9e0
	if (!cr6.eq) goto loc_82C8E9E0;
loc_82C8E9CC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8E9E0:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8e9fc
	if (!cr6.eq) goto loc_82C8E9FC;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8ea04
	goto loc_82C8EA04;
loc_82C8E9FC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8EA04:
	// addi r11,r3,-20
	r11.s64 = ctx.r3.s64 + -20;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bgt cr6,0x82c8ec10
	if (cr6.gt) goto loc_82C8EC10;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-5592
	r12.s64 = r12.s64 + -5592;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8EA64;
	case 1:
		goto loc_82C8EC10;
	case 2:
		goto loc_82C8EA80;
	case 3:
		goto loc_82C8EC10;
	case 4:
		goto loc_82C8EA80;
	case 5:
		goto loc_82C8EC10;
	case 6:
		goto loc_82C8EC10;
	case 7:
		goto loc_82C8EA48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5532(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5532);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5504(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5504);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5504(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5504);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5560(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5560);
loc_82C8EA48:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8e7a0
	sub_82C8E7A0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8EA64:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,33
	ctx.r3.s64 = 33;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8EA80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8e9cc
	if (cr6.eq) goto loc_82C8E9CC;
loc_82C8EA8C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8eaa8
	if (!cr6.eq) goto loc_82C8EAA8;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8eab0
	goto loc_82C8EAB0;
loc_82C8EAA8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8EAB0:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// bgt cr6,0x82c8ec10
	if (cr6.gt) goto loc_82C8EC10;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-5420
	r12.s64 = r12.s64 + -5420;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8EBF8;
	case 1:
		goto loc_82C8EBF8;
	case 2:
		goto loc_82C8EC10;
	case 3:
		goto loc_82C8EC10;
	case 4:
		goto loc_82C8EC10;
	case 5:
		goto loc_82C8EC10;
	case 6:
		goto loc_82C8EC10;
	case 7:
		goto loc_82C8EC10;
	case 8:
		goto loc_82C8EC10;
	case 9:
		goto loc_82C8EC10;
	case 10:
		goto loc_82C8EC10;
	case 11:
		goto loc_82C8EC10;
	case 12:
		goto loc_82C8EBF8;
	case 13:
		goto loc_82C8EB2C;
	case 14:
		goto loc_82C8EC10;
	case 15:
		goto loc_82C8EB2C;
	case 16:
		goto loc_82C8EC10;
	case 17:
		goto loc_82C8EC10;
	case 18:
		goto loc_82C8EC10;
	case 19:
		goto loc_82C8EC10;
	case 20:
		goto loc_82C8EC10;
	case 21:
		goto loc_82C8EB4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5332(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5332);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5332(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5332);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5300(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5300);
loc_82C8EB2C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8ea8c
	if (!cr6.eq) goto loc_82C8EA8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8EB4C:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8e9cc
	if (cr6.eq) goto loc_82C8E9CC;
	// lbz r3,3(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8eb74
	if (!cr6.eq) goto loc_82C8EB74;
	// lbz r11,0(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8eb7c
	goto loc_82C8EB7C;
loc_82C8EB74:
	// lbz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8EB7C:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// bgt cr6,0x82c8ebf8
	if (cr6.gt) goto loc_82C8EBF8;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-5216
	r12.s64 = r12.s64 + -5216;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8EC10;
	case 1:
		goto loc_82C8EC10;
	case 2:
		goto loc_82C8EBF8;
	case 3:
		goto loc_82C8EBF8;
	case 4:
		goto loc_82C8EBF8;
	case 5:
		goto loc_82C8EBF8;
	case 6:
		goto loc_82C8EBF8;
	case 7:
		goto loc_82C8EBF8;
	case 8:
		goto loc_82C8EBF8;
	case 9:
		goto loc_82C8EBF8;
	case 10:
		goto loc_82C8EBF8;
	case 11:
		goto loc_82C8EBF8;
	case 12:
		goto loc_82C8EC10;
	case 13:
		goto loc_82C8EBF8;
	case 14:
		goto loc_82C8EBF8;
	case 15:
		goto loc_82C8EBF8;
	case 16:
		goto loc_82C8EBF8;
	case 17:
		goto loc_82C8EBF8;
	case 18:
		goto loc_82C8EBF8;
	case 19:
		goto loc_82C8EBF8;
	case 20:
		goto loc_82C8EBF8;
	case 21:
		goto loc_82C8EC10;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
loc_82C8EBF8:
	// li r3,16
	ctx.r3.s64 = 16;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8EC10:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8E9B0) {
	__imp__sub_82C8E9B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8EC28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r11,11
	r11.s64 = 11;
	// subf r10,r4,r5
	ctx.r10.s64 = ctx.r5.s64 - ctx.r4.s64;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x82c8ece0
	if (!cr6.eq) goto loc_82C8ECE0;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c8ece0
	if (!cr6.eq) goto loc_82C8ECE0;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,88
	cr6.compare<int32_t>(r11.s32, 88, xer);
	// beq cr6,0x82c8ec6c
	if (cr6.eq) goto loc_82C8EC6C;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// beq cr6,0x82c8ec70
	if (cr6.eq) goto loc_82C8EC70;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C8EC6C:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C8EC70:
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c8ece0
	if (!cr6.eq) goto loc_82C8ECE0;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,77
	cr6.compare<int32_t>(ctx.r10.s32, 77, xer);
	// beq cr6,0x82c8eca0
	if (cr6.eq) goto loc_82C8ECA0;
	// cmpwi cr6,r10,109
	cr6.compare<int32_t>(ctx.r10.s32, 109, xer);
	// beq cr6,0x82c8eca4
	if (cr6.eq) goto loc_82C8ECA4;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C8ECA0:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C8ECA4:
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c8ece0
	if (!cr6.eq) goto loc_82C8ECE0;
	// lbz r11,2(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,76
	cr6.compare<int32_t>(r11.s32, 76, xer);
	// beq cr6,0x82c8ecd0
	if (cr6.eq) goto loc_82C8ECD0;
	// cmpwi cr6,r11,108
	cr6.compare<int32_t>(r11.s32, 108, xer);
	// bne cr6,0x82c8ece0
	if (!cr6.eq) goto loc_82C8ECE0;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x82c8ecd8
	if (cr6.eq) goto loc_82C8ECD8;
loc_82C8ECD0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8ECD8:
	// li r11,12
	r11.s64 = 12;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
loc_82C8ECE0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8EC28) {
	__imp__sub_82C8EC28(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8ECE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r31,r10
	r31.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x82c8ed1c
	if (!cr6.eq) goto loc_82C8ED1C;
loc_82C8ED10:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C8ED1C:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82c8ed38
	if (!cr6.eq) goto loc_82C8ED38;
	// add r11,r4,r29
	r11.u64 = ctx.r4.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8ed40
	goto loc_82C8ED40;
loc_82C8ED38:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8ED40:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8f124
	if (cr6.gt) goto loc_82C8F124;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-4752
	r12.s64 = r12.s64 + -4752;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8F0E8;
	case 1:
		goto loc_82C8F100;
	case 2:
		goto loc_82C8F118;
	case 3:
		goto loc_82C8F124;
	case 4:
		goto loc_82C8F124;
	case 5:
		goto loc_82C8F124;
	case 6:
		goto loc_82C8F124;
	case 7:
		goto loc_82C8F124;
	case 8:
		goto loc_82C8F124;
	case 9:
		goto loc_82C8F124;
	case 10:
		goto loc_82C8F124;
	case 11:
		goto loc_82C8F124;
	case 12:
		goto loc_82C8F124;
	case 13:
		goto loc_82C8F124;
	case 14:
		goto loc_82C8F124;
	case 15:
		goto loc_82C8F124;
	case 16:
		goto loc_82C8F124;
	case 17:
		goto loc_82C8EE08;
	case 18:
		goto loc_82C8F124;
	case 19:
		goto loc_82C8EE08;
	case 20:
		goto loc_82C8F124;
	case 21:
		goto loc_82C8F124;
	case 22:
		goto loc_82C8F124;
	case 23:
		goto loc_82C8F124;
	case 24:
		goto loc_82C8EDD4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3864(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3864);
	// lwz r22,-3840(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3840);
	// lwz r22,-3816(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3816);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4600(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4600);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4600(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4600);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4652(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4652);
loc_82C8EDD4:
	// addi r11,r8,1280
	r11.s64 = ctx.r8.s64 + 1280;
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r5,r4,27
	ctx.r5.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r6,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r5.u8 & 0x3F));
	// lbzx r3,r7,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r7.u32 + r11.u32);
	// rotlwi r11,r3,3
	r11.u64 = rotl32(ctx.r3.u32, 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r5,r7,r4
	ctx.r5.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x82c8f124
	if (cr6.eq) goto loc_82C8F124;
loc_82C8EE08:
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r5,r30
	cr6.compare<uint32_t>(ctx.r5.u32, r30.u32, xer);
	// beq cr6,0x82c8ed10
	if (cr6.eq) goto loc_82C8ED10;
loc_82C8EE14:
	// lbz r10,1(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c8ee30
	if (!cr6.eq) goto loc_82C8EE30;
	// add r11,r4,r29
	r11.u64 = ctx.r4.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8ee38
	goto loc_82C8EE38;
loc_82C8EE30:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8EE38:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8ef0c
	if (cr6.gt) goto loc_82C8EF0C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-4516
	r12.s64 = r12.s64 + -4516;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8EF1C;
	case 1:
		goto loc_82C8EF34;
	case 2:
		goto loc_82C8EF4C;
	case 3:
		goto loc_82C8EF0C;
	case 4:
		goto loc_82C8EF64;
	case 5:
		goto loc_82C8EF64;
	case 6:
		goto loc_82C8EF0C;
	case 7:
		goto loc_82C8EF0C;
	case 8:
		goto loc_82C8EF0C;
	case 9:
		goto loc_82C8EF0C;
	case 10:
		goto loc_82C8F098;
	case 11:
		goto loc_82C8EF0C;
	case 12:
		goto loc_82C8EF0C;
	case 13:
		goto loc_82C8EF0C;
	case 14:
		goto loc_82C8EF0C;
	case 15:
		goto loc_82C8EF0C;
	case 16:
		goto loc_82C8EF64;
	case 17:
		goto loc_82C8EEF4;
	case 18:
		goto loc_82C8EF0C;
	case 19:
		goto loc_82C8EEF4;
	case 20:
		goto loc_82C8EEF4;
	case 21:
		goto loc_82C8EEF4;
	case 22:
		goto loc_82C8EEF4;
	case 23:
		goto loc_82C8EF0C;
	case 24:
		goto loc_82C8EEC0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-4324(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4324);
	// lwz r22,-4300(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4300);
	// lwz r22,-4276(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4276);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4252);
	// lwz r22,-4252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4252);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-3944(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3944);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4252(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4252);
	// lwz r22,-4364(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4364(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4364(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4364(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4364(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4340(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4416(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4416);
loc_82C8EEC0:
	// clrlwi r11,r10,24
	r11.u64 = ctx.r10.u32 & 0xFF;
	// addi r9,r8,1536
	ctx.r9.s64 = ctx.r8.s64 + 1536;
	// rlwinm r10,r4,27,29,31
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r6,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r11,r9
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + ctx.r9.u32);
	// rotlwi r11,r3,3
	r11.u64 = rotl32(ctx.r3.u32, 3);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// and r7,r9,r4
	ctx.r7.u64 = ctx.r9.u64 & ctx.r4.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82c8ef0c
	if (cr6.eq) goto loc_82C8EF0C;
loc_82C8EEF4:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	cr6.compare<uint32_t>(ctx.r5.u32, r30.u32, xer);
	// bne cr6,0x82c8ee14
	if (!cr6.eq) goto loc_82C8EE14;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C8EF0C:
	// stw r5,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r5.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C8EF1C:
	// subf r11,r5,r30
	r11.s64 = r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8ef0c
	if (!cr6.lt) goto loc_82C8EF0C;
loc_82C8EF28:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C8EF34:
	// subf r11,r5,r30
	r11.s64 = r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c8ef0c
	if (!cr6.lt) goto loc_82C8EF0C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C8EF4C:
	// subf r11,r5,r30
	r11.s64 = r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c8ef0c
	if (!cr6.lt) goto loc_82C8EF0C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C8EF64:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8ec28
	sub_82C8EC28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8ef0c
	if (cr6.eq) goto loc_82C8EF0C;
	// addi r10,r5,2
	ctx.r10.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// beq cr6,0x82c8ed10
	if (cr6.eq) goto loc_82C8ED10;
	// subf r9,r10,r30
	ctx.r9.s64 = r30.s64 - ctx.r10.s64;
loc_82C8EF8C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8efa8
	if (!cr6.eq) goto loc_82C8EFA8;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8efb0
	goto loc_82C8EFB0;
loc_82C8EFA8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8EFB0:
	// cmplwi cr6,r3,15
	cr6.compare<uint32_t>(ctx.r3.u32, 15, xer);
	// bgt cr6,0x82c8f018
	if (cr6.gt) goto loc_82C8F018;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-4144
	r12.s64 = r12.s64 + -4144;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8F124;
	case 1:
		goto loc_82C8F124;
	case 2:
		goto loc_82C8F018;
	case 3:
		goto loc_82C8F018;
	case 4:
		goto loc_82C8F018;
	case 5:
		goto loc_82C8F010;
	case 6:
		goto loc_82C8F034;
	case 7:
		goto loc_82C8F048;
	case 8:
		goto loc_82C8F124;
	case 9:
		goto loc_82C8F018;
	case 10:
		goto loc_82C8F018;
	case 11:
		goto loc_82C8F018;
	case 12:
		goto loc_82C8F018;
	case 13:
		goto loc_82C8F018;
	case 14:
		goto loc_82C8F018;
	case 15:
		goto loc_82C8F05C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4072(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4080(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4080);
	// lwz r22,-4044(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4044);
	// lwz r22,-4024(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4024);
	// lwz r22,-3804(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4072(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4004(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4004);
loc_82C8F010:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// blt cr6,0x82c8ef28
	if (cr6.lt) goto loc_82C8EF28;
loc_82C8F018:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F020:
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x82c8ef8c
	if (!cr6.eq) goto loc_82C8EF8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C8F034:
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// blt cr6,0x82c8ef28
	if (cr6.lt) goto loc_82C8EF28;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c8f020
	goto loc_82C8F020;
loc_82C8F048:
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c8ef28
	if (cr6.lt) goto loc_82C8EF28;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c8f020
	goto loc_82C8F020;
loc_82C8F05C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// beq cr6,0x82c8ed10
	if (cr6.eq) goto loc_82C8ED10;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c8f020
	if (!cr6.eq) goto loc_82C8F020;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// bne cr6,0x82c8f020
	if (!cr6.eq) goto loc_82C8F020;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C8F098:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8ec28
	sub_82C8EC28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c8ef0c
	if (cr6.eq) goto loc_82C8EF0C;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	cr6.compare<uint32_t>(ctx.r5.u32, r30.u32, xer);
	// beq cr6,0x82c8ed10
	if (cr6.eq) goto loc_82C8ED10;
	// lbz r11,1(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c8ef0c
	if (!cr6.eq) goto loc_82C8EF0C;
	// lbz r11,0(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// bne cr6,0x82c8ef0c
	if (!cr6.eq) goto loc_82C8EF0C;
	// addi r11,r5,2
	r11.s64 = ctx.r5.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C8F0E8:
	// subf r11,r10,r30
	r11.s64 = r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8f124
	if (!cr6.lt) goto loc_82C8F124;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C8F100:
	// subf r11,r10,r30
	r11.s64 = r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c8f124
	if (!cr6.lt) goto loc_82C8F124;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C8F118:
	// subf r11,r10,r30
	r11.s64 = r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8ef28
	if (cr6.lt) goto loc_82C8EF28;
loc_82C8F124:
	// stw r10,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82C8ECE8) {
	__imp__sub_82C8ECE8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8F138) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8f168
	if (!cr6.eq) goto loc_82C8F168;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F168:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c8f19c
	if (cr6.eq) goto loc_82C8F19C;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c8f198
	if (!cr6.eq) goto loc_82C8F198;
loc_82C8F184:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F198:
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
loc_82C8F19C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8f1b8
	if (!cr6.eq) goto loc_82C8F1B8;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8f1c0
	goto loc_82C8F1C0;
loc_82C8F1B8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8F1C0:
	// cmplwi cr6,r3,10
	cr6.compare<uint32_t>(ctx.r3.u32, 10, xer);
	// bgt cr6,0x82c8f348
	if (cr6.gt) goto loc_82C8F348;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-3616
	r12.s64 = r12.s64 + -3616;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8F330;
	case 1:
		goto loc_82C8F330;
	case 2:
		goto loc_82C8F348;
	case 3:
		goto loc_82C8F348;
	case 4:
		goto loc_82C8F20C;
	case 5:
		goto loc_82C8F2E8;
	case 6:
		goto loc_82C8F308;
	case 7:
		goto loc_82C8F31C;
	case 8:
		goto loc_82C8F330;
	case 9:
		goto loc_82C8F278;
	case 10:
		goto loc_82C8F2CC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3280(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3280);
	// lwz r22,-3280(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3280);
	// lwz r22,-3256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3256);
	// lwz r22,-3256(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3256);
	// lwz r22,-3572(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3572);
	// lwz r22,-3352(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3352);
	// lwz r22,-3320(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3320);
	// lwz r22,-3300(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3300);
	// lwz r22,-3280(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3280);
	// lwz r22,-3464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3464);
	// lwz r22,-3380(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3380);
loc_82C8F20C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8f184
	if (cr6.eq) goto loc_82C8F184;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c8f34c
	if (!cr6.eq) goto loc_82C8F34C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c8f34c
	if (!cr6.eq) goto loc_82C8F34C;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8f184
	if (cr6.eq) goto loc_82C8F184;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c8f270
	if (!cr6.eq) goto loc_82C8F270;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c8f270
	if (!cr6.eq) goto loc_82C8F270;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// li r3,40
	ctx.r3.s64 = 40;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F270:
	// addi r10,r11,-2
	ctx.r10.s64 = r11.s64 + -2;
	// b 0x82c8f34c
	goto loc_82C8F34C;
loc_82C8F278:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8f184
	if (cr6.eq) goto loc_82C8F184;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8f2a0
	if (!cr6.eq) goto loc_82C8F2A0;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8f2a8
	goto loc_82C8F2A8;
loc_82C8F2A0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8F2A8:
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bne cr6,0x82c8f2b4
	if (!cr6.eq) goto loc_82C8F2B4;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F2B4:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F2CC:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F2E8:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8f348
	if (!cr6.lt) goto loc_82C8F348;
loc_82C8F2F4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F308:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c8f2f4
	if (cr6.lt) goto loc_82C8F2F4;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c8f34c
	goto loc_82C8F34C;
loc_82C8F31C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c8f2f4
	if (cr6.lt) goto loc_82C8F2F4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c8f34c
	goto loc_82C8F34C;
loc_82C8F330:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F348:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F34C:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8f3e0
	if (cr6.eq) goto loc_82C8F3E0;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C8F358:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8f374
	if (!cr6.eq) goto loc_82C8F374;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8f37c
	goto loc_82C8F37C;
loc_82C8F374:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8F37C:
	// cmplwi cr6,r3,10
	cr6.compare<uint32_t>(ctx.r3.u32, 10, xer);
	// bgt cr6,0x82c8f3d0
	if (cr6.gt) goto loc_82C8F3D0;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-3172
	r12.s64 = r12.s64 + -3172;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8F3E0;
	case 1:
		goto loc_82C8F3E0;
	case 2:
		goto loc_82C8F3D0;
	case 3:
		goto loc_82C8F3D0;
	case 4:
		goto loc_82C8F3E0;
	case 5:
		goto loc_82C8F3C8;
	case 6:
		goto loc_82C8F3F8;
	case 7:
		goto loc_82C8F40C;
	case 8:
		goto loc_82C8F3E0;
	case 9:
		goto loc_82C8F3E0;
	case 10:
		goto loc_82C8F3E0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3120(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3120);
	// lwz r22,-3120(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3120);
	// lwz r22,-3104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3128(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3128);
	// lwz r22,-3080(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3080);
	// lwz r22,-3060(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3060);
	// lwz r22,-3104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3104(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
loc_82C8F3C8:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// blt cr6,0x82c8f3e0
	if (cr6.lt) goto loc_82C8F3E0;
loc_82C8F3D0:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F3D8:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8f358
	if (!cr6.eq) goto loc_82C8F358;
loc_82C8F3E0:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F3F8:
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// blt cr6,0x82c8f3e0
	if (cr6.lt) goto loc_82C8F3E0;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c8f3d8
	goto loc_82C8F3D8;
loc_82C8F40C:
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c8f3e0
	if (cr6.lt) goto loc_82C8F3E0;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c8f3d8
	goto loc_82C8F3D8;
}

PPC_WEAK_FUNC(sub_82C8F138) {
	__imp__sub_82C8F138(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8F420) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8f44c
	if (!cr6.eq) goto loc_82C8F44C;
loc_82C8F444:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F44C:
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82c8f468
	if (!cr6.eq) goto loc_82C8F468;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8f470
	goto loc_82C8F470;
loc_82C8F468:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8F470:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8f720
	if (cr6.gt) goto loc_82C8F720;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	r31.s64 = 1;
	// addi r7,r9,-4144
	ctx.r7.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-2912
	r12.s64 = r12.s64 + -2912;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8F638;
	case 1:
		goto loc_82C8F64C;
	case 2:
		goto loc_82C8F70C;
	case 3:
		goto loc_82C8F720;
	case 4:
		goto loc_82C8F720;
	case 5:
		goto loc_82C8F720;
	case 6:
		goto loc_82C8F720;
	case 7:
		goto loc_82C8F720;
	case 8:
		goto loc_82C8F720;
	case 9:
		goto loc_82C8F720;
	case 10:
		goto loc_82C8F720;
	case 11:
		goto loc_82C8F720;
	case 12:
		goto loc_82C8F720;
	case 13:
		goto loc_82C8F720;
	case 14:
		goto loc_82C8F720;
	case 15:
		goto loc_82C8F720;
	case 16:
		goto loc_82C8F720;
	case 17:
		goto loc_82C8F538;
	case 18:
		goto loc_82C8F720;
	case 19:
		goto loc_82C8F538;
	case 20:
		goto loc_82C8F720;
	case 21:
		goto loc_82C8F720;
	case 22:
		goto loc_82C8F720;
	case 23:
		goto loc_82C8F720;
	case 24:
		goto loc_82C8F504;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-2504(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2504);
	// lwz r22,-2484(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2484);
	// lwz r22,-2292(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2292);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2760(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2760);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2760(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2760);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2812(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2812);
loc_82C8F504:
	// clrlwi r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	// addi r11,r7,1280
	r11.s64 = ctx.r7.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r8,r11
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + r11.u32);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r8,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c8f720
	if (cr6.eq) goto loc_82C8F720;
loc_82C8F538:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8f444
	if (cr6.eq) goto loc_82C8F444;
loc_82C8F544:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c8f560
	if (!cr6.eq) goto loc_82C8F560;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8f568
	goto loc_82C8F568;
loc_82C8F560:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8F568:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8f720
	if (cr6.gt) goto loc_82C8F720;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-2676
	r12.s64 = r12.s64 + -2676;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8F638;
	case 1:
		goto loc_82C8F64C;
	case 2:
		goto loc_82C8F70C;
	case 3:
		goto loc_82C8F720;
	case 4:
		goto loc_82C8F660;
	case 5:
		goto loc_82C8F660;
	case 6:
		goto loc_82C8F6FC;
	case 7:
		goto loc_82C8F720;
	case 8:
		goto loc_82C8F720;
	case 9:
		goto loc_82C8F720;
	case 10:
		goto loc_82C8F720;
	case 11:
		goto loc_82C8F720;
	case 12:
		goto loc_82C8F720;
	case 13:
		goto loc_82C8F720;
	case 14:
		goto loc_82C8F720;
	case 15:
		goto loc_82C8F720;
	case 16:
		goto loc_82C8F660;
	case 17:
		goto loc_82C8F624;
	case 18:
		goto loc_82C8F624;
	case 19:
		goto loc_82C8F624;
	case 20:
		goto loc_82C8F624;
	case 21:
		goto loc_82C8F624;
	case 22:
		goto loc_82C8F624;
	case 23:
		goto loc_82C8F720;
	case 24:
		goto loc_82C8F5F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-2504(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2504);
	// lwz r22,-2484(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2484);
	// lwz r22,-2292(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2292);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2464);
	// lwz r22,-2464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2464);
	// lwz r22,-2308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2308);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2464);
	// lwz r22,-2524(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2576(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2576);
loc_82C8F5F0:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r8,r7,1536
	ctx.r8.s64 = ctx.r7.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r8
	r11.u64 = PPC_LOAD_U8(r11.u32 + ctx.r8.u32);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r8,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c8f720
	if (cr6.eq) goto loc_82C8F720;
loc_82C8F624:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8f544
	if (!cr6.eq) goto loc_82C8F544;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F638:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8f720
	if (!cr6.lt) goto loc_82C8F720;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F64C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c8f720
	if (!cr6.lt) goto loc_82C8F720;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F660:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8f444
	if (cr6.eq) goto loc_82C8F444;
loc_82C8F66C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8f688
	if (!cr6.eq) goto loc_82C8F688;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8f690
	goto loc_82C8F690;
loc_82C8F688:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8F690:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// bgt cr6,0x82c8f720
	if (cr6.gt) goto loc_82C8F720;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-2380
	r12.s64 = r12.s64 + -2380;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8F6E8;
	case 1:
		goto loc_82C8F6E8;
	case 2:
		goto loc_82C8F6FC;
	case 3:
		goto loc_82C8F720;
	case 4:
		goto loc_82C8F720;
	case 5:
		goto loc_82C8F720;
	case 6:
		goto loc_82C8F720;
	case 7:
		goto loc_82C8F720;
	case 8:
		goto loc_82C8F720;
	case 9:
		goto loc_82C8F720;
	case 10:
		goto loc_82C8F720;
	case 11:
		goto loc_82C8F720;
	case 12:
		goto loc_82C8F6E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-2328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2328);
	// lwz r22,-2328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2328);
	// lwz r22,-2308(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2308);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2328(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2328);
loc_82C8F6E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8f66c
	if (!cr6.eq) goto loc_82C8F66C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F6FC:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,5
	ctx.r3.s64 = 5;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F70C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c8f720
	if (!cr6.lt) goto loc_82C8F720;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F720:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C8F728:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8F420) {
	__imp__sub_82C8F420(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8F740) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8f7e4
	if (cr6.eq) goto loc_82C8F7E4;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8f778
	if (!cr6.eq) goto loc_82C8F778;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8f780
	goto loc_82C8F780;
loc_82C8F778:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8F780:
	// cmpwi cr6,r3,24
	cr6.compare<int32_t>(ctx.r3.s32, 24, xer);
	// blt cr6,0x82c8f814
	if (cr6.lt) goto loc_82C8F814;
	// cmpwi cr6,r3,25
	cr6.compare<int32_t>(ctx.r3.s32, 25, xer);
	// bgt cr6,0x82c8f814
	if (cr6.gt) goto loc_82C8F814;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8f7e4
	if (cr6.eq) goto loc_82C8F7E4;
loc_82C8F79C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8f7b8
	if (!cr6.eq) goto loc_82C8F7B8;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8f7c0
	goto loc_82C8F7C0;
loc_82C8F7B8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8F7C0:
	// cmpwi cr6,r3,18
	cr6.compare<int32_t>(ctx.r3.s32, 18, xer);
	// beq cr6,0x82c8f7f8
	if (cr6.eq) goto loc_82C8F7F8;
	// cmpwi cr6,r3,23
	cr6.compare<int32_t>(ctx.r3.s32, 23, xer);
	// ble cr6,0x82c8f814
	if (!cr6.gt) goto loc_82C8F814;
	// cmpwi cr6,r3,25
	cr6.compare<int32_t>(ctx.r3.s32, 25, xer);
	// bgt cr6,0x82c8f814
	if (cr6.gt) goto loc_82C8F814;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8f79c
	if (!cr6.eq) goto loc_82C8F79C;
loc_82C8F7E4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F7F8:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F814:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8F740) {
	__imp__sub_82C8F740(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8F830) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8f910
	if (cr6.eq) goto loc_82C8F910;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// extsb r11,r3
	r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c8f89c
	if (!cr6.eq) goto loc_82C8F89C;
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,120
	cr6.compare<uint32_t>(ctx.r8.u32, 120, xer);
	// bne cr6,0x82c8f884
	if (!cr6.eq) goto loc_82C8F884;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8f740
	sub_82C8F740(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F884:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c8f89c
	if (!cr6.eq) goto loc_82C8F89C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8f8a4
	goto loc_82C8F8A4;
loc_82C8F89C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8F8A4:
	// cmpwi cr6,r3,25
	cr6.compare<int32_t>(ctx.r3.s32, 25, xer);
	// beq cr6,0x82c8f8c4
	if (cr6.eq) goto loc_82C8F8C4;
loc_82C8F8AC:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F8C4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8f910
	if (cr6.eq) goto loc_82C8F910;
loc_82C8F8D0:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8f8ec
	if (!cr6.eq) goto loc_82C8F8EC;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8f8f4
	goto loc_82C8F8F4;
loc_82C8F8EC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8F8F4:
	// cmpwi cr6,r3,18
	cr6.compare<int32_t>(ctx.r3.s32, 18, xer);
	// beq cr6,0x82c8f924
	if (cr6.eq) goto loc_82C8F924;
	// cmpwi cr6,r3,25
	cr6.compare<int32_t>(ctx.r3.s32, 25, xer);
	// bne cr6,0x82c8f8ac
	if (!cr6.eq) goto loc_82C8F8AC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8f8d0
	if (!cr6.eq) goto loc_82C8F8D0;
loc_82C8F910:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C8F924:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8F830) {
	__imp__sub_82C8F830(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8F940) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8f96c
	if (!cr6.eq) goto loc_82C8F96C;
loc_82C8F964:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8F96C:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82c8f988
	if (!cr6.eq) goto loc_82C8F988;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8f990
	goto loc_82C8F990;
loc_82C8F988:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8F990:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8fbb4
	if (cr6.gt) goto loc_82C8FBB4;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-1600
	r12.s64 = r12.s64 + -1600;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8FB58;
	case 1:
		goto loc_82C8FB6C;
	case 2:
		goto loc_82C8FB80;
	case 3:
		goto loc_82C8FBB4;
	case 4:
		goto loc_82C8FBB4;
	case 5:
		goto loc_82C8FBB4;
	case 6:
		goto loc_82C8FBB4;
	case 7:
		goto loc_82C8FBB4;
	case 8:
		goto loc_82C8FBB4;
	case 9:
		goto loc_82C8FBB4;
	case 10:
		goto loc_82C8FBB4;
	case 11:
		goto loc_82C8FBB4;
	case 12:
		goto loc_82C8FBB4;
	case 13:
		goto loc_82C8FBB4;
	case 14:
		goto loc_82C8FBA4;
	case 15:
		goto loc_82C8FBB4;
	case 16:
		goto loc_82C8FBB4;
	case 17:
		goto loc_82C8FA58;
	case 18:
		goto loc_82C8FBB4;
	case 19:
		goto loc_82C8FA58;
	case 20:
		goto loc_82C8FBB4;
	case 21:
		goto loc_82C8FBB4;
	case 22:
		goto loc_82C8FBB4;
	case 23:
		goto loc_82C8FBB4;
	case 24:
		goto loc_82C8FA24;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-1192(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1192);
	// lwz r22,-1172(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1172);
	// lwz r22,-1152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1152);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1116(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1116);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1448(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1448);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1448(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1448);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1500(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1500);
loc_82C8FA24:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// addi r11,r8,1280
	r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r7,r11
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + r11.u32);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c8fbb4
	if (cr6.eq) goto loc_82C8FBB4;
loc_82C8FA58:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c8f964
	if (cr6.eq) goto loc_82C8F964;
loc_82C8FA64:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c8fa80
	if (!cr6.eq) goto loc_82C8FA80;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8fa88
	goto loc_82C8FA88;
loc_82C8FA80:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8FA88:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8fbb4
	if (cr6.gt) goto loc_82C8FBB4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-1364
	r12.s64 = r12.s64 + -1364;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C8FB58;
	case 1:
		goto loc_82C8FB6C;
	case 2:
		goto loc_82C8FB80;
	case 3:
		goto loc_82C8FBB4;
	case 4:
		goto loc_82C8FBB4;
	case 5:
		goto loc_82C8FBB4;
	case 6:
		goto loc_82C8FBB4;
	case 7:
		goto loc_82C8FBB4;
	case 8:
		goto loc_82C8FBB4;
	case 9:
		goto loc_82C8FBB4;
	case 10:
		goto loc_82C8FBB4;
	case 11:
		goto loc_82C8FBB4;
	case 12:
		goto loc_82C8FBB4;
	case 13:
		goto loc_82C8FB94;
	case 14:
		goto loc_82C8FBB4;
	case 15:
		goto loc_82C8FBB4;
	case 16:
		goto loc_82C8FBB4;
	case 17:
		goto loc_82C8FB44;
	case 18:
		goto loc_82C8FBB4;
	case 19:
		goto loc_82C8FB44;
	case 20:
		goto loc_82C8FB44;
	case 21:
		goto loc_82C8FB44;
	case 22:
		goto loc_82C8FB44;
	case 23:
		goto loc_82C8FBB4;
	case 24:
		goto loc_82C8FB10;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-1192(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1192);
	// lwz r22,-1172(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1172);
	// lwz r22,-1152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1152);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1132(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1132);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1212(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1212(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1212(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1212(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1212(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1100(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1264(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1264);
loc_82C8FB10:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	r11.u64 = PPC_LOAD_U8(r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c8fbb4
	if (cr6.eq) goto loc_82C8FBB4;
loc_82C8FB44:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8fa64
	if (!cr6.eq) goto loc_82C8FA64;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB58:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8fbb4
	if (!cr6.lt) goto loc_82C8FBB4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB6C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c8fbb4
	if (!cr6.lt) goto loc_82C8FBB4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB80:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c8fbb4
	if (!cr6.lt) goto loc_82C8FBB4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB94:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,9
	ctx.r3.s64 = 9;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FBA4:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c8f830
	sub_82C8F830(ctx, base);
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FBB4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C8FBBC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C8F940) {
	__imp__sub_82C8F940(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C8FBD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// li r28,0
	r28.s64 = 0;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9010c
	if (cr6.eq) goto loc_82C9010C;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// li r27,1
	r27.s64 = 1;
	// addi r29,r11,-4144
	r29.s64 = r11.s64 + -4144;
loc_82C8FC08:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c8fc24
	if (!cr6.eq) goto loc_82C8FC24;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8fc2c
	goto loc_82C8FC2C;
loc_82C8FC24:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8FC2C:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8fe30
	if (cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-944
	r12.s64 = r12.s64 + -944;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C90118;
	case 1:
		goto loc_82C90130;
	case 2:
		goto loc_82C90148;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C8FDE0;
	case 5:
		goto loc_82C8FDE0;
	case 6:
		goto loc_82C8FE30;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C8FE30;
	case 9:
		goto loc_82C8FE40;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C8FE30;
	case 13:
		goto loc_82C8FE30;
	case 14:
		goto loc_82C8FE30;
	case 15:
		goto loc_82C8FE30;
	case 16:
		goto loc_82C8FDE0;
	case 17:
		goto loc_82C90100;
	case 18:
		goto loc_82C8FCE8;
	case 19:
		goto loc_82C90100;
	case 20:
		goto loc_82C90100;
	case 21:
		goto loc_82C90100;
	case 22:
		goto loc_82C90100;
	case 23:
		goto loc_82C8FE30;
	case 24:
		goto loc_82C8FCB4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 280);
	// lwz r22,304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 304);
	// lwz r22,328(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-544(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -544);
	// lwz r22,-544(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -544);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-448(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -448);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-544(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -544);
	// lwz r22,256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-792(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -792);
	// lwz r22,256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-844(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -844);
loc_82C8FCB4:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r8,r29,1536
	ctx.r8.s64 = r29.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r6,r27,r7
	ctx.r6.u64 = ctx.r7.u8 & 0x20 ? 0 : (r27.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + ctx.r8.u32);
	// rotlwi r11,r4,3
	r11.u64 = rotl32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r29
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// and r8,r9,r6
	ctx.r8.u64 = ctx.r9.u64 & ctx.r6.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// b 0x82c900fc
	goto loc_82C900FC;
loc_82C8FCE8:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x82c8fe30
	if (!cr6.eq) goto loc_82C8FE30;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r28,r27
	r28.u64 = r27.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9010c
	if (cr6.eq) goto loc_82C9010C;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c8fd1c
	if (!cr6.eq) goto loc_82C8FD1C;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8fd24
	goto loc_82C8FD24;
loc_82C8FD1C:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8FD24:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8fe30
	if (cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-696
	r12.s64 = r12.s64 + -696;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C90118;
	case 1:
		goto loc_82C90130;
	case 2:
		goto loc_82C90148;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C8FE30;
	case 5:
		goto loc_82C8FE30;
	case 6:
		goto loc_82C8FE30;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C8FE30;
	case 9:
		goto loc_82C8FE30;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C8FE30;
	case 13:
		goto loc_82C8FE30;
	case 14:
		goto loc_82C8FE30;
	case 15:
		goto loc_82C8FE30;
	case 16:
		goto loc_82C8FE30;
	case 17:
		goto loc_82C90100;
	case 18:
		goto loc_82C8FE30;
	case 19:
		goto loc_82C90100;
	case 20:
		goto loc_82C8FE30;
	case 21:
		goto loc_82C8FE30;
	case 22:
		goto loc_82C8FE30;
	case 23:
		goto loc_82C8FE30;
	case 24:
		goto loc_82C8FDAC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 280);
	// lwz r22,304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 304);
	// lwz r22,328(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-596(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -596);
loc_82C8FDAC:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r8,r29,1280
	ctx.r8.s64 = r29.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r6,r27,r7
	ctx.r6.u64 = ctx.r7.u8 & 0x20 ? 0 : (r27.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + ctx.r8.u32);
	// rotlwi r11,r4,3
	r11.u64 = rotl32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r29
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// and r8,r9,r6
	ctx.r8.u64 = ctx.r9.u64 & ctx.r6.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// b 0x82c900fc
	goto loc_82C900FC;
loc_82C8FDE0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9010c
	if (cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8fe08
	if (!cr6.eq) goto loc_82C8FE08;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8fe10
	goto loc_82C8FE10;
loc_82C8FE08:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8FE10:
	// cmpwi cr6,r3,14
	cr6.compare<int32_t>(ctx.r3.s32, 14, xer);
	// beq cr6,0x82c8fe40
	if (cr6.eq) goto loc_82C8FE40;
	// cmpwi cr6,r3,9
	cr6.compare<int32_t>(ctx.r3.s32, 9, xer);
	// blt cr6,0x82c8fe30
	if (cr6.lt) goto loc_82C8FE30;
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// ble cr6,0x82c8fde0
	if (!cr6.gt) goto loc_82C8FDE0;
	// cmpwi cr6,r3,21
	cr6.compare<int32_t>(ctx.r3.s32, 21, xer);
	// beq cr6,0x82c8fde0
	if (cr6.eq) goto loc_82C8FDE0;
loc_82C8FE30:
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8FE40:
	// li r28,0
	r28.s64 = 0;
loc_82C8FE44:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9010c
	if (cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8fe6c
	if (!cr6.eq) goto loc_82C8FE6C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r31,76(r11)
	r31.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8fe78
	goto loc_82C8FE78;
loc_82C8FE6C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_82C8FE78:
	// cmpwi cr6,r31,12
	cr6.compare<int32_t>(r31.s32, 12, xer);
	// beq cr6,0x82c8feb0
	if (cr6.eq) goto loc_82C8FEB0;
	// cmpwi cr6,r31,13
	cr6.compare<int32_t>(r31.s32, 13, xer);
	// beq cr6,0x82c8feb0
	if (cr6.eq) goto loc_82C8FEB0;
	// cmpwi cr6,r31,9
	cr6.compare<int32_t>(r31.s32, 9, xer);
	// blt cr6,0x82c8fe30
	if (cr6.lt) goto loc_82C8FE30;
	// cmpwi cr6,r31,10
	cr6.compare<int32_t>(r31.s32, 10, xer);
	// ble cr6,0x82c8fe44
	if (!cr6.gt) goto loc_82C8FE44;
	// cmpwi cr6,r31,21
	cr6.compare<int32_t>(r31.s32, 21, xer);
	// beq cr6,0x82c8fe44
	if (cr6.eq) goto loc_82C8FE44;
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C8FEB0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8FEB4:
	// stw r10,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r10.u32);
loc_82C8FEB8:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9010c
	if (cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8fedc
	if (!cr6.eq) goto loc_82C8FEDC;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8fee4
	goto loc_82C8FEE4;
loc_82C8FEDC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8FEE4:
	// cmpw cr6,r3,r31
	cr6.compare<int32_t>(ctx.r3.s32, r31.s32, xer);
	// beq cr6,0x82c8ff88
	if (cr6.eq) goto loc_82C8FF88;
	// cmplwi cr6,r3,8
	cr6.compare<uint32_t>(ctx.r3.u32, 8, xer);
	// bgt cr6,0x82c8feb0
	if (cr6.gt) goto loc_82C8FEB0;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-244
	r12.s64 = r12.s64 + -244;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8FE30;
	case 1:
		goto loc_82C8FE30;
	case 2:
		goto loc_82C8FE30;
	case 3:
		goto loc_82C8FF68;
	case 4:
		goto loc_82C8FEB0;
	case 5:
		goto loc_82C8FF30;
	case 6:
		goto loc_82C8FF40;
	case 7:
		goto loc_82C8FF54;
	case 8:
		goto loc_82C8FE30;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-152(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -152);
	// lwz r22,-336(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -336);
	// lwz r22,-208(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -208);
	// lwz r22,-192(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -192);
	// lwz r22,-172(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -172);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
loc_82C8FF30:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// blt cr6,0x82c90124
	if (cr6.lt) goto loc_82C90124;
	// b 0x82c8feb0
	goto loc_82C8FEB0;
loc_82C8FF40:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c90124
	if (cr6.lt) goto loc_82C90124;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c8feb4
	goto loc_82C8FEB4;
loc_82C8FF54:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c90124
	if (cr6.lt) goto loc_82C90124;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c8feb4
	goto loc_82C8FEB4;
loc_82C8FF68:
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c8f940
	sub_82C8F940(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x82c901bc
	if (!cr6.gt) goto loc_82C901BC;
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// b 0x82c8feb8
	goto loc_82C8FEB8;
loc_82C8FF88:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9010c
	if (cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c8ffb0
	if (!cr6.eq) goto loc_82C8FFB0;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c8ffb8
	goto loc_82C8FFB8;
loc_82C8FFB0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C8FFB8:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// bgt cr6,0x82c8fe30
	if (cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,-36
	r12.s64 = r12.s64 + -36;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C90010;
	case 1:
		goto loc_82C90010;
	case 2:
		goto loc_82C901A8;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C8FE30;
	case 5:
		goto loc_82C8FE30;
	case 6:
		goto loc_82C8FE30;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C90160;
	case 9:
		goto loc_82C8FE30;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C90010;
	default:
		__builtin_unreachable();
	}
	// lwz r22,16(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,16(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,424(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 424);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 352);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,16(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_82C90010:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9010c
	if (cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c90038
	if (!cr6.eq) goto loc_82C90038;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c90040
	goto loc_82C90040;
loc_82C90038:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C90040:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c8fe30
	if (cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,100
	r12.s64 = r12.s64 + 100;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C90118;
	case 1:
		goto loc_82C90130;
	case 2:
		goto loc_82C90148;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C90010;
	case 5:
		goto loc_82C90010;
	case 6:
		goto loc_82C901A8;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C8FE30;
	case 9:
		goto loc_82C8FE30;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C90160;
	case 13:
		goto loc_82C8FE30;
	case 14:
		goto loc_82C8FE30;
	case 15:
		goto loc_82C8FE30;
	case 16:
		goto loc_82C90010;
	case 17:
		goto loc_82C90100;
	case 18:
		goto loc_82C8FE30;
	case 19:
		goto loc_82C90100;
	case 20:
		goto loc_82C8FE30;
	case 21:
		goto loc_82C8FE30;
	case 22:
		goto loc_82C8FE30;
	case 23:
		goto loc_82C8FE30;
	case 24:
		goto loc_82C900C8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 280);
	// lwz r22,304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 304);
	// lwz r22,328(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,16(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,16(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,424(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 424);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 352);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,16(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,200(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 200);
loc_82C900C8:
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r8,r29,1280
	ctx.r8.s64 = r29.s64 + 1280;
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r7,27
	ctx.r6.u64 = ctx.r7.u32 & 0x1F;
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + ctx.r8.u32);
	// slw r3,r27,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (r27.u32 << (ctx.r6.u8 & 0x3F));
	// rotlwi r11,r4,3
	r11.u64 = rotl32(ctx.r4.u32, 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// and r7,r8,r3
	ctx.r7.u64 = ctx.r8.u64 & ctx.r3.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
loc_82C900FC:
	// beq cr6,0x82c8fe30
	if (cr6.eq) goto loc_82C8FE30;
loc_82C90100:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c8fc08
	if (!cr6.eq) goto loc_82C8FC08;
loc_82C9010C:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82C90110:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C90118:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c8fe30
	if (!cr6.lt) goto loc_82C8FE30;
loc_82C90124:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C90130:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c8fe30
	if (!cr6.lt) goto loc_82C8FE30;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C90148:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c8fe30
	if (!cr6.lt) goto loc_82C8FE30;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C90160:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9010c
	if (cr6.eq) goto loc_82C9010C;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c90198
	if (!cr6.eq) goto loc_82C90198;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c90198
	if (!cr6.eq) goto loc_82C90198;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// li r3,3
	ctx.r3.s64 = 3;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C90198:
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C901A8:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C901BC:
	// bne cr6,0x82c90110
	if (!cr6.eq) goto loc_82C90110;
	// lwz r11,172(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C8FBD8) {
	__imp__sub_82C8FBD8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C901D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c901fc
	if (!cr6.eq) goto loc_82C901FC;
loc_82C901F4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C901FC:
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82c90218
	if (!cr6.eq) goto loc_82C90218;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c90220
	goto loc_82C90220;
loc_82C90218:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C90220:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c90728
	if (cr6.gt) goto loc_82C90728;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	r31.s64 = 1;
	// addi r7,r9,-4144
	ctx.r7.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,592
	r12.s64 = r12.s64 + 592;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C90728;
	case 5:
		goto loc_82C90728;
	case 6:
		goto loc_82C90728;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90708;
	case 11:
		goto loc_82C90654;
	case 12:
		goto loc_82C90718;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C90728;
	case 17:
		goto loc_82C902E8;
	case 18:
		goto loc_82C90728;
	case 19:
		goto loc_82C902E8;
	case 20:
		goto loc_82C90728;
	case 21:
		goto loc_82C90728;
	case 22:
		goto loc_82C90728;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C902B4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1800(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1800);
	// lwz r22,1620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1620);
	// lwz r22,1816(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1816);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,744(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 744);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,744(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 744);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,692(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 692);
loc_82C902B4:
	// clrlwi r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	// addi r11,r7,1280
	r11.s64 = ctx.r7.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r8,r11
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + r11.u32);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r8,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c90728
	if (cr6.eq) goto loc_82C90728;
loc_82C902E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c901f4
	if (cr6.eq) goto loc_82C901F4;
loc_82C902F8:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c90314
	if (!cr6.eq) goto loc_82C90314;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c9031c
	goto loc_82C9031C;
loc_82C90314:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C9031C:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c90728
	if (cr6.gt) goto loc_82C90728;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,832
	r12.s64 = r12.s64 + 832;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C904F4;
	case 5:
		goto loc_82C904F4;
	case 6:
		goto loc_82C90608;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90728;
	case 11:
		goto loc_82C90728;
	case 12:
		goto loc_82C90618;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C904F4;
	case 17:
		goto loc_82C904A4;
	case 18:
		goto loc_82C903AC;
	case 19:
		goto loc_82C904A4;
	case 20:
		goto loc_82C904A4;
	case 21:
		goto loc_82C904A4;
	case 22:
		goto loc_82C904A4;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C903A4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1268(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1268);
	// lwz r22,1268(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1268);
	// lwz r22,1544(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1544);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1560(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1560);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1268(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1268);
	// lwz r22,1188(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,940(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 940);
	// lwz r22,1188(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1188(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1188(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1188(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,932(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 932);
loc_82C903A4:
	// addi r3,r7,1536
	ctx.r3.s64 = ctx.r7.s64 + 1536;
	// b 0x82c90474
	goto loc_82C90474;
loc_82C903AC:
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x82c90728
	if (!cr6.eq) goto loc_82C90728;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c901f4
	if (cr6.eq) goto loc_82C901F4;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c903e0
	if (!cr6.eq) goto loc_82C903E0;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c903e8
	goto loc_82C903E8;
loc_82C903E0:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C903E8:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c90728
	if (cr6.gt) goto loc_82C90728;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,1036
	r12.s64 = r12.s64 + 1036;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C90728;
	case 5:
		goto loc_82C90728;
	case 6:
		goto loc_82C90728;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90728;
	case 11:
		goto loc_82C90728;
	case 12:
		goto loc_82C90728;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C90728;
	case 17:
		goto loc_82C904A4;
	case 18:
		goto loc_82C90728;
	case 19:
		goto loc_82C904A4;
	case 20:
		goto loc_82C90728;
	case 21:
		goto loc_82C90728;
	case 22:
		goto loc_82C90728;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C90470;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1188(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1188(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1136);
loc_82C90470:
	// addi r3,r7,1280
	ctx.r3.s64 = ctx.r7.s64 + 1280;
loc_82C90474:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r4
	ctx.r4.u64 = ctx.r4.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r3,r11,r3
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + ctx.r3.u32);
	// rotlwi r11,r3,3
	r11.u64 = rotl32(ctx.r3.u32, 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r9,r7
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// and r11,r3,r4
	r11.u64 = ctx.r3.u64 & ctx.r4.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c90728
	if (cr6.eq) goto loc_82C90728;
loc_82C904A4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c902f8
	if (!cr6.eq) goto loc_82C902F8;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904B8:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c90728
	if (!cr6.lt) goto loc_82C90728;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904CC:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c90728
	if (!cr6.lt) goto loc_82C90728;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904E0:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c90728
	if (!cr6.lt) goto loc_82C90728;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904F4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c901f4
	if (cr6.eq) goto loc_82C901F4;
loc_82C90500:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c9051c
	if (!cr6.eq) goto loc_82C9051C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c90524
	goto loc_82C90524;
loc_82C9051C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C90524:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c90728
	if (cr6.gt) goto loc_82C90728;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,1352
	r12.s64 = r12.s64 + 1352;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C905AC;
	case 5:
		goto loc_82C905AC;
	case 6:
		goto loc_82C90608;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90728;
	case 11:
		goto loc_82C90728;
	case 12:
		goto loc_82C90618;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C905AC;
	case 17:
		goto loc_82C905F8;
	case 18:
		goto loc_82C90728;
	case 19:
		goto loc_82C905F8;
	case 20:
		goto loc_82C90728;
	case 21:
		goto loc_82C90728;
	case 22:
		goto loc_82C90728;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C905C0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1452(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1452);
	// lwz r22,1452(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1452);
	// lwz r22,1544(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1544);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1560(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1560);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1452(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1452);
	// lwz r22,1528(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1528);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1528(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1528);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1472);
loc_82C905AC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c90500
	if (!cr6.eq) goto loc_82C90500;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C905C0:
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r8,r7,1280
	ctx.r8.s64 = ctx.r7.s64 + 1280;
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r3,r4,27
	ctx.r3.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r11,r11,r8
	r11.u64 = PPC_LOAD_U8(r11.u32 + ctx.r8.u32);
	// slw r8,r31,r3
	ctx.r8.u64 = ctx.r3.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r3.u8 & 0x3F));
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r4,r11,r9
	ctx.r4.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r3,r4,2,0,29
	ctx.r3.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r3,r7
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r7.u32);
	// and r9,r11,r8
	ctx.r9.u64 = r11.u64 & ctx.r8.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c90728
	if (cr6.eq) goto loc_82C90728;
loc_82C905F8:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c8fbd8
	sub_82C8FBD8(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90608:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90618:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c901f4
	if (cr6.eq) goto loc_82C901F4;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c9064c
	if (!cr6.eq) goto loc_82C9064C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c9064c
	if (!cr6.eq) goto loc_82C9064C;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// li r3,4
	ctx.r3.s64 = 4;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C9064C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c9072c
	goto loc_82C9072C;
loc_82C90654:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c901f4
	if (cr6.eq) goto loc_82C901F4;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c9067c
	if (!cr6.eq) goto loc_82C9067C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c90684
	goto loc_82C90684;
loc_82C9067C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C90684:
	// cmpwi cr6,r3,20
	cr6.compare<int32_t>(ctx.r3.s32, 20, xer);
	// beq cr6,0x82c906a4
	if (cr6.eq) goto loc_82C906A4;
	// cmpwi cr6,r3,27
	cr6.compare<int32_t>(ctx.r3.s32, 27, xer);
	// bne cr6,0x82c90728
	if (!cr6.eq) goto loc_82C90728;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c8e7a0
	sub_82C8E7A0(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C906A4:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// subf r10,r11,r5
	ctx.r10.s64 = ctx.r5.s64 - r11.s64;
	// cmpwi cr6,r10,12
	cr6.compare<int32_t>(ctx.r10.s32, 12, xer);
	// blt cr6,0x82c901f4
	if (cr6.lt) goto loc_82C901F4;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r9,-4144
	ctx.r9.s64 = ctx.r9.s64 + -4144;
loc_82C906C0:
	// lbz r8,1(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82c906fc
	if (!cr6.eq) goto loc_82C906FC;
	// addi r8,r9,4744
	ctx.r8.s64 = ctx.r9.s64 + 4744;
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbzx r5,r10,r8
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r8.u32);
	// cmplw cr6,r7,r5
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c906fc
	if (!cr6.eq) goto loc_82C906FC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// blt cr6,0x82c906c0
	if (cr6.lt) goto loc_82C906C0;
	// li r3,8
	ctx.r3.s64 = 8;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C906FC:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90708:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c8ece8
	sub_82C8ECE8(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90718:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c8f420
	sub_82C8F420(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90728:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C9072C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C90730:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C901D0) {
	__imp__sub_82C901D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C90748) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c90780
	if (!cr6.eq) goto loc_82C90780;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90780:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c907b8
	if (cr6.eq) goto loc_82C907B8;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c907b4
	if (!cr6.eq) goto loc_82C907B4;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C907B4:
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
loc_82C907B8:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c907d4
	if (!cr6.eq) goto loc_82C907D4;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c907dc
	goto loc_82C907DC;
loc_82C907D4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C907DC:
	// cmplwi cr6,r3,10
	cr6.compare<uint32_t>(ctx.r3.u32, 10, xer);
	// bgt cr6,0x82c909bc
	if (cr6.gt) goto loc_82C909BC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,2044
	r12.s64 = r12.s64 + 2044;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C909B4;
	case 1:
		goto loc_82C909B4;
	case 2:
		goto loc_82C90828;
	case 3:
		goto loc_82C90848;
	case 4:
		goto loc_82C908E4;
	case 5:
		goto loc_82C90968;
	case 6:
		goto loc_82C9098C;
	case 7:
		goto loc_82C909A0;
	case 8:
		goto loc_82C909B4;
	case 9:
		goto loc_82C90868;
	case 10:
		goto loc_82C908C4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,2484(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2484);
	// lwz r22,2484(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2484);
	// lwz r22,2088(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2088);
	// lwz r22,2120(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2120);
	// lwz r22,2276(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2276);
	// lwz r22,2408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2408);
	// lwz r22,2444(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2444);
	// lwz r22,2464(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2464);
	// lwz r22,2484(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2484);
	// lwz r22,2152(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2152);
	// lwz r22,2244(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2244);
loc_82C90828:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c901d0
	sub_82C901D0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90848:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c8f940
	sub_82C8F940(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90868:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c9088c
	if (!cr6.eq) goto loc_82C9088C;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9088C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c908a8
	if (!cr6.eq) goto loc_82C908A8;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c908b0
	goto loc_82C908B0;
loc_82C908A8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C908B0:
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bne cr6,0x82c908bc
	if (!cr6.eq) goto loc_82C908BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C908BC:
	// li r3,7
	ctx.r3.s64 = 7;
	// b 0x82c90a50
	goto loc_82C90A50;
loc_82C908C4:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C908E4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c90908
	if (!cr6.eq) goto loc_82C90908;
loc_82C908F0:
	// li r3,-5
	ctx.r3.s64 = -5;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90908:
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c909c0
	if (!cr6.eq) goto loc_82C909C0;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c909c0
	if (!cr6.eq) goto loc_82C909C0;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c908f0
	if (cr6.eq) goto loc_82C908F0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c90960
	if (!cr6.eq) goto loc_82C90960;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c90960
	if (!cr6.eq) goto loc_82C90960;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90960:
	// addi r10,r11,-2
	ctx.r10.s64 = r11.s64 + -2;
	// b 0x82c909c0
	goto loc_82C909C0;
loc_82C90968:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c909bc
	if (!cr6.lt) goto loc_82C909BC;
loc_82C90974:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9098C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c90974
	if (cr6.lt) goto loc_82C90974;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c909c0
	goto loc_82C909C0;
loc_82C909A0:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c90974
	if (cr6.lt) goto loc_82C90974;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c909c0
	goto loc_82C909C0;
loc_82C909B4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c90a50
	goto loc_82C90A50;
loc_82C909BC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C909C0:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c90a4c
	if (cr6.eq) goto loc_82C90A4C;
	// addi r7,r10,4
	ctx.r7.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C909D4:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c909f0
	if (!cr6.eq) goto loc_82C909F0;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c909f8
	goto loc_82C909F8;
loc_82C909F0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C909F8:
	// cmplwi cr6,r3,10
	cr6.compare<uint32_t>(ctx.r3.u32, 10, xer);
	// bgt cr6,0x82c90ae0
	if (cr6.gt) goto loc_82C90AE0;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,2584
	r12.s64 = r12.s64 + 2584;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C90A4C;
	case 1:
		goto loc_82C90A4C;
	case 2:
		goto loc_82C90A4C;
	case 3:
		goto loc_82C90A4C;
	case 4:
		goto loc_82C90AA0;
	case 5:
		goto loc_82C90A44;
	case 6:
		goto loc_82C90A68;
	case 7:
		goto loc_82C90A84;
	case 8:
		goto loc_82C90A4C;
	case 9:
		goto loc_82C90A4C;
	case 10:
		goto loc_82C90A4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,2636(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2720(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2720);
	// lwz r22,2628(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2628);
	// lwz r22,2664(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2664);
	// lwz r22,2692(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2692);
	// lwz r22,2636(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
loc_82C90A44:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bge cr6,0x82c90ae0
	if (!cr6.lt) goto loc_82C90AE0;
loc_82C90A4C:
	// li r3,6
	ctx.r3.s64 = 6;
loc_82C90A50:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90A68:
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// blt cr6,0x82c90a4c
	if (cr6.lt) goto loc_82C90A4C;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// addi r8,r8,3
	ctx.r8.s64 = ctx.r8.s64 + 3;
	// addi r7,r7,3
	ctx.r7.s64 = ctx.r7.s64 + 3;
	// b 0x82c90af0
	goto loc_82C90AF0;
loc_82C90A84:
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c90a4c
	if (cr6.lt) goto loc_82C90A4C;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// b 0x82c90af0
	goto loc_82C90AF0;
loc_82C90AA0:
	// cmplw cr6,r8,r5
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c90a4c
	if (cr6.eq) goto loc_82C90A4C;
	// lbz r11,3(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c90ae0
	if (!cr6.eq) goto loc_82C90AE0;
	// lbz r11,0(r8)
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c90ae0
	if (!cr6.eq) goto loc_82C90AE0;
	// cmplw cr6,r7,r5
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c90a4c
	if (cr6.eq) goto loc_82C90A4C;
	// lbz r11,5(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 5);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c90ae0
	if (!cr6.eq) goto loc_82C90AE0;
	// lbz r11,0(r7)
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// beq cr6,0x82c90afc
	if (cr6.eq) goto loc_82C90AFC;
loc_82C90AE0:
	// addi r7,r7,2
	ctx.r7.s64 = ctx.r7.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C90AF0:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c909d4
	if (!cr6.eq) goto loc_82C909D4;
	// b 0x82c90a4c
	goto loc_82C90A4C;
loc_82C90AFC:
	// addi r11,r10,4
	r11.s64 = ctx.r10.s64 + 4;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C90748) {
	__imp__sub_82C90748(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C90B20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c90b4c
	if (!cr6.eq) goto loc_82C90B4C;
	// li r3,-22
	ctx.r3.s64 = -22;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90B4C:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82c90b68
	if (!cr6.eq) goto loc_82C90B68;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c90b70
	goto loc_82C90B70;
loc_82C90B68:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C90B70:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,25
	cr6.compare<uint32_t>(r11.u32, 25, xer);
	// bgt cr6,0x82c90d90
	if (cr6.gt) goto loc_82C90D90;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,2976
	r12.s64 = r12.s64 + 2976;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C90D3C;
	case 1:
		goto loc_82C90D50;
	case 2:
		goto loc_82C90D64;
	case 3:
		goto loc_82C90D90;
	case 4:
		goto loc_82C90D88;
	case 5:
		goto loc_82C90D88;
	case 6:
		goto loc_82C90D90;
	case 7:
		goto loc_82C90D90;
	case 8:
		goto loc_82C90D90;
	case 9:
		goto loc_82C90D90;
	case 10:
		goto loc_82C90D90;
	case 11:
		goto loc_82C90D90;
	case 12:
		goto loc_82C90D90;
	case 13:
		goto loc_82C90D90;
	case 14:
		goto loc_82C90D90;
	case 15:
		goto loc_82C90D90;
	case 16:
		goto loc_82C90D88;
	case 17:
		goto loc_82C90C3C;
	case 18:
		goto loc_82C90D90;
	case 19:
		goto loc_82C90C3C;
	case 20:
		goto loc_82C90D90;
	case 21:
		goto loc_82C90D90;
	case 22:
		goto loc_82C90D90;
	case 23:
		goto loc_82C90D90;
	case 24:
		goto loc_82C90C08;
	case 25:
		goto loc_82C90D88;
	default:
		__builtin_unreachable();
	}
	// lwz r22,3388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3388);
	// lwz r22,3408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3408);
	// lwz r22,3428(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3428);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3464(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
	// lwz r22,3464(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3464(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
	// lwz r22,3132(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3132);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3132(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3132);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3080(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3080);
	// lwz r22,3464(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
loc_82C90C08:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// addi r11,r8,1280
	r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r7,r11
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + r11.u32);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c90d90
	if (cr6.eq) goto loc_82C90D90;
loc_82C90C3C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c90d34
	if (cr6.eq) goto loc_82C90D34;
loc_82C90C48:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c90c64
	if (!cr6.eq) goto loc_82C90C64;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c90c6c
	goto loc_82C90C6C;
loc_82C90C64:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C90C6C:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c90d90
	if (cr6.gt) goto loc_82C90D90;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,3216
	r12.s64 = r12.s64 + 3216;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C90D3C;
	case 1:
		goto loc_82C90D50;
	case 2:
		goto loc_82C90D64;
	case 3:
		goto loc_82C90D90;
	case 4:
		goto loc_82C90D90;
	case 5:
		goto loc_82C90D90;
	case 6:
		goto loc_82C90D90;
	case 7:
		goto loc_82C90D90;
	case 8:
		goto loc_82C90D90;
	case 9:
		goto loc_82C90D90;
	case 10:
		goto loc_82C90D90;
	case 11:
		goto loc_82C90D90;
	case 12:
		goto loc_82C90D90;
	case 13:
		goto loc_82C90D78;
	case 14:
		goto loc_82C90D90;
	case 15:
		goto loc_82C90D90;
	case 16:
		goto loc_82C90D90;
	case 17:
		goto loc_82C90D28;
	case 18:
		goto loc_82C90D90;
	case 19:
		goto loc_82C90D28;
	case 20:
		goto loc_82C90D28;
	case 21:
		goto loc_82C90D28;
	case 22:
		goto loc_82C90D28;
	case 23:
		goto loc_82C90D90;
	case 24:
		goto loc_82C90CF4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,3388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3388);
	// lwz r22,3408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3408);
	// lwz r22,3428(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3428);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3448(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3448);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3368(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3368(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3368(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3368(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3368(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3316);
loc_82C90CF4:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	r11.u64 = PPC_LOAD_U8(r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c90d90
	if (cr6.eq) goto loc_82C90D90;
loc_82C90D28:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c90c48
	if (!cr6.eq) goto loc_82C90C48;
loc_82C90D34:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D3C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c90d90
	if (!cr6.lt) goto loc_82C90D90;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D50:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c90d90
	if (!cr6.lt) goto loc_82C90D90;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D64:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c90d90
	if (!cr6.lt) goto loc_82C90D90;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D78:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,28
	ctx.r3.s64 = 28;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D88:
	// li r3,22
	ctx.r3.s64 = 22;
	// b 0x82c90d94
	goto loc_82C90D94;
loc_82C90D90:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C90D94:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C90D98:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C90B20) {
	__imp__sub_82C90B20(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C90DB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c90ddc
	if (!cr6.eq) goto loc_82C90DDC;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C90DDC:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82c90df8
	if (!cr6.eq) goto loc_82C90DF8;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c90e00
	goto loc_82C90E00;
loc_82C90DF8:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C90E00:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c91028
	if (cr6.gt) goto loc_82C91028;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,3632
	r12.s64 = r12.s64 + 3632;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C90FE4;
	case 1:
		goto loc_82C90FF8;
	case 2:
		goto loc_82C91014;
	case 3:
		goto loc_82C91028;
	case 4:
		goto loc_82C91028;
	case 5:
		goto loc_82C91028;
	case 6:
		goto loc_82C91028;
	case 7:
		goto loc_82C91028;
	case 8:
		goto loc_82C91028;
	case 9:
		goto loc_82C91028;
	case 10:
		goto loc_82C91028;
	case 11:
		goto loc_82C91028;
	case 12:
		goto loc_82C91028;
	case 13:
		goto loc_82C91028;
	case 14:
		goto loc_82C91028;
	case 15:
		goto loc_82C91028;
	case 16:
		goto loc_82C91028;
	case 17:
		goto loc_82C90EC8;
	case 18:
		goto loc_82C91028;
	case 19:
		goto loc_82C90EC8;
	case 20:
		goto loc_82C91028;
	case 21:
		goto loc_82C91028;
	case 22:
		goto loc_82C91028;
	case 23:
		goto loc_82C91028;
	case 24:
		goto loc_82C90E94;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4068(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4068);
	// lwz r22,4088(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4088);
	// lwz r22,4116(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4116);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3784(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3784);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3784(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3784);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3732);
loc_82C90E94:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// addi r11,r8,1280
	r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r7,r11
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + r11.u32);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c91028
	if (cr6.eq) goto loc_82C91028;
loc_82C90EC8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c90fdc
	if (cr6.eq) goto loc_82C90FDC;
loc_82C90ED4:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c90ef0
	if (!cr6.eq) goto loc_82C90EF0;
	// add r11,r4,r30
	r11.u64 = ctx.r4.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c90ef8
	goto loc_82C90EF8;
loc_82C90EF0:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C90EF8:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	cr6.compare<uint32_t>(r11.u32, 31, xer);
	// bgt cr6,0x82c91028
	if (cr6.gt) goto loc_82C91028;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,3868
	r12.s64 = r12.s64 + 3868;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C90FE4;
	case 1:
		goto loc_82C90FF8;
	case 2:
		goto loc_82C91014;
	case 3:
		goto loc_82C91028;
	case 4:
		goto loc_82C9100C;
	case 5:
		goto loc_82C9100C;
	case 6:
		goto loc_82C9100C;
	case 7:
		goto loc_82C91028;
	case 8:
		goto loc_82C91028;
	case 9:
		goto loc_82C91028;
	case 10:
		goto loc_82C91028;
	case 11:
		goto loc_82C91028;
	case 12:
		goto loc_82C91028;
	case 13:
		goto loc_82C91028;
	case 14:
		goto loc_82C91028;
	case 15:
		goto loc_82C91028;
	case 16:
		goto loc_82C9100C;
	case 17:
		goto loc_82C90FD0;
	case 18:
		goto loc_82C91028;
	case 19:
		goto loc_82C90FD0;
	case 20:
		goto loc_82C90FD0;
	case 21:
		goto loc_82C90FD0;
	case 22:
		goto loc_82C90FD0;
	case 23:
		goto loc_82C91028;
	case 24:
		goto loc_82C90F9C;
	case 25:
		goto loc_82C9100C;
	case 26:
		goto loc_82C91028;
	case 27:
		goto loc_82C9100C;
	case 28:
		goto loc_82C91028;
	case 29:
		goto loc_82C91028;
	case 30:
		goto loc_82C91028;
	case 31:
		goto loc_82C9100C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4068(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4068);
	// lwz r22,4088(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4088);
	// lwz r22,4116(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4116);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4108(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4108(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4048(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4048(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4048(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4048(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4048(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3996);
	// lwz r22,4108(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
loc_82C90F9C:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	r11.u64 = PPC_LOAD_U8(r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c91028
	if (cr6.eq) goto loc_82C91028;
loc_82C90FD0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c90ed4
	if (!cr6.eq) goto loc_82C90ED4;
loc_82C90FDC:
	// li r3,-20
	ctx.r3.s64 = -20;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C90FE4:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c91028
	if (!cr6.lt) goto loc_82C91028;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C90FF8:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c91028
	if (!cr6.lt) goto loc_82C91028;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C9100C:
	// li r3,20
	ctx.r3.s64 = 20;
	// b 0x82c9102c
	goto loc_82C9102C;
loc_82C91014:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c91028
	if (!cr6.lt) goto loc_82C91028;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C91028:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C9102C:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C91030:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C90DB0) {
	__imp__sub_82C90DB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C91048) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// beq cr6,0x82c910fc
	if (cr6.eq) goto loc_82C910FC;
	// subf r10,r5,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r5.s64;
loc_82C91068:
	// lbz r3,1(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c91084
	if (!cr6.eq) goto loc_82C91084;
	// lbz r11,0(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c9108c
	goto loc_82C9108C;
loc_82C91084:
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C9108C:
	// cmplwi cr6,r3,13
	cr6.compare<uint32_t>(ctx.r3.u32, 13, xer);
	// bgt cr6,0x82c910ec
	if (cr6.gt) goto loc_82C910EC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,4268
	r12.s64 = r12.s64 + 4268;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C91178;
	case 1:
		goto loc_82C91178;
	case 2:
		goto loc_82C910EC;
	case 3:
		goto loc_82C910EC;
	case 4:
		goto loc_82C910EC;
	case 5:
		goto loc_82C910E4;
	case 6:
		goto loc_82C91110;
	case 7:
		goto loc_82C91124;
	case 8:
		goto loc_82C91178;
	case 9:
		goto loc_82C910EC;
	case 10:
		goto loc_82C910EC;
	case 11:
		goto loc_82C910EC;
	case 12:
		goto loc_82C91138;
	case 13:
		goto loc_82C91138;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4472);
	// lwz r22,4472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4472);
	// lwz r22,4332(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4324(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4324);
	// lwz r22,4368(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4368);
	// lwz r22,4388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4388);
	// lwz r22,4472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4472);
	// lwz r22,4332(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4408);
	// lwz r22,4408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4408);
loc_82C910E4:
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// blt cr6,0x82c91164
	if (cr6.lt) goto loc_82C91164;
loc_82C910EC:
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
loc_82C910F4:
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// bne cr6,0x82c91068
	if (!cr6.eq) goto loc_82C91068;
loc_82C910FC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91110:
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// blt cr6,0x82c91164
	if (cr6.lt) goto loc_82C91164;
	// addi r5,r5,3
	ctx.r5.s64 = ctx.r5.s64 + 3;
	// addi r10,r10,-3
	ctx.r10.s64 = ctx.r10.s64 + -3;
	// b 0x82c910f4
	goto loc_82C910F4;
loc_82C91124:
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// blt cr6,0x82c91164
	if (cr6.lt) goto loc_82C91164;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// b 0x82c910f4
	goto loc_82C910F4;
loc_82C91138:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// cmpw cr6,r3,r9
	cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, xer);
	// bne cr6,0x82c910f4
	if (!cr6.eq) goto loc_82C910F4;
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// bne cr6,0x82c91190
	if (!cr6.eq) goto loc_82C91190;
	// li r3,-27
	ctx.r3.s64 = -27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91164:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91178:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
loc_82C9117C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91190:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
	// lbz r3,1(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c911b0
	if (!cr6.eq) goto loc_82C911B0;
	// lbz r11,0(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c911b8
	goto loc_82C911B8;
loc_82C911B0:
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C911B8:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// bgt cr6,0x82c9117c
	if (cr6.gt) goto loc_82C9117C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,4572
	r12.s64 = r12.s64 + 4572;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C91234;
	case 1:
		goto loc_82C91234;
	case 2:
		goto loc_82C91234;
	case 3:
		goto loc_82C9117C;
	case 4:
		goto loc_82C9117C;
	case 5:
		goto loc_82C9117C;
	case 6:
		goto loc_82C9117C;
	case 7:
		goto loc_82C9117C;
	case 8:
		goto loc_82C9117C;
	case 9:
		goto loc_82C9117C;
	case 10:
		goto loc_82C9117C;
	case 11:
		goto loc_82C91234;
	case 12:
		goto loc_82C91234;
	case 13:
		goto loc_82C9117C;
	case 14:
		goto loc_82C9117C;
	case 15:
		goto loc_82C9117C;
	case 16:
		goto loc_82C9117C;
	case 17:
		goto loc_82C9117C;
	case 18:
		goto loc_82C9117C;
	case 19:
		goto loc_82C9117C;
	case 20:
		goto loc_82C9117C;
	case 21:
		goto loc_82C91234;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4660(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4660(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4660(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4660(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4660(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4660(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
loc_82C91234:
	// li r3,27
	ctx.r3.s64 = 27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C91048) {
	__imp__sub_82C91048(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C91248) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c91270
	if (!cr6.eq) goto loc_82C91270;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91270:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c9129c
	if (cr6.eq) goto loc_82C9129C;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c91298
	if (!cr6.eq) goto loc_82C91298;
loc_82C9128C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91298:
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
loc_82C9129C:
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82c912b8
	if (!cr6.eq) goto loc_82C912B8;
	// add r11,r4,r29
	r11.u64 = ctx.r4.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c912c0
	goto loc_82C912C0;
loc_82C912B8:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C912C0:
	// addi r9,r3,-2
	ctx.r9.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r9,34
	cr6.compare<uint32_t>(ctx.r9.u32, 34, xer);
	// bgt cr6,0x82c91a64
	if (cr6.gt) goto loc_82C91A64;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// li r30,1
	r30.s64 = 1;
	// addi r31,r11,-4144
	r31.s64 = r11.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,4848
	r12.s64 = r12.s64 + 4848;
	// rlwinm r0,r9,2,0,29
	r0.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82C913BC;
	case 1:
		goto loc_82C91A64;
	case 2:
		goto loc_82C9157C;
	case 3:
		goto loc_82C91760;
	case 4:
		goto loc_82C91778;
	case 5:
		goto loc_82C91790;
	case 6:
		goto loc_82C91A64;
	case 7:
		goto loc_82C914B0;
	case 8:
		goto loc_82C914CC;
	case 9:
		goto loc_82C91738;
	case 10:
		goto loc_82C9137C;
	case 11:
		goto loc_82C9139C;
	case 12:
		goto loc_82C91A64;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A64;
	case 16:
		goto loc_82C91A64;
	case 17:
		goto loc_82C9174C;
	case 18:
		goto loc_82C91568;
	case 19:
		goto loc_82C914CC;
	case 20:
		goto loc_82C917DC;
	case 21:
		goto loc_82C91808;
	case 22:
		goto loc_82C917DC;
	case 23:
		goto loc_82C91808;
	case 24:
		goto loc_82C91808;
	case 25:
		goto loc_82C91808;
	case 26:
		goto loc_82C91A64;
	case 27:
		goto loc_82C917A8;
	case 28:
		goto loc_82C91540;
	case 29:
		goto loc_82C915F4;
	case 30:
		goto loc_82C91608;
	case 31:
		goto loc_82C91A64;
	case 32:
		goto loc_82C91A64;
	case 33:
		goto loc_82C91554;
	case 34:
		goto loc_82C91724;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5052(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5052);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5500(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5500);
	// lwz r22,5984(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5984);
	// lwz r22,6008(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6008);
	// lwz r22,6032(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6032);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5296(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5296);
	// lwz r22,5324(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5324);
	// lwz r22,5944(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5944);
	// lwz r22,4988(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4988);
	// lwz r22,5020(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5020);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5964(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5964);
	// lwz r22,5480(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5480);
	// lwz r22,5324(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5324);
	// lwz r22,6108(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6108);
	// lwz r22,6152(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6108(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6108);
	// lwz r22,6152(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6152(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6152(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6056(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6056);
	// lwz r22,5440(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5440);
	// lwz r22,5620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5620);
	// lwz r22,5640(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5640);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5460(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5460);
	// lwz r22,5924(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5924);
loc_82C9137C:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x82c91048
	sub_82C91048(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C9139C:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r3,13
	ctx.r3.s64 = 13;
	// bl 0x82c91048
	sub_82C91048(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C913BC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9128c
	if (cr6.eq) goto loc_82C9128C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c913e4
	if (!cr6.eq) goto loc_82C913E4;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c913ec
	goto loc_82C913EC;
loc_82C913E4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C913EC:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c91a64
	if (cr6.gt) goto loc_82C91A64;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,5136
	r12.s64 = r12.s64 + 5136;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C9149C;
	case 1:
		goto loc_82C9149C;
	case 2:
		goto loc_82C9149C;
	case 3:
		goto loc_82C91A64;
	case 4:
		goto loc_82C91A64;
	case 5:
		goto loc_82C91A64;
	case 6:
		goto loc_82C91A64;
	case 7:
		goto loc_82C91A64;
	case 8:
		goto loc_82C91A64;
	case 9:
		goto loc_82C91A64;
	case 10:
		goto loc_82C91488;
	case 11:
		goto loc_82C91474;
	case 12:
		goto loc_82C91A64;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A64;
	case 16:
		goto loc_82C91A64;
	case 17:
		goto loc_82C9149C;
	case 18:
		goto loc_82C91A64;
	case 19:
		goto loc_82C9149C;
	case 20:
		goto loc_82C91A64;
	case 21:
		goto loc_82C91A64;
	case 22:
		goto loc_82C91A64;
	case 23:
		goto loc_82C91A64;
	case 24:
		goto loc_82C9149C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5276(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,5276(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,5276(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5256);
	// lwz r22,5236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5236);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5276(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5276(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5276(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
loc_82C91474:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8e9b0
	sub_82C8E9B0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91488:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c8ece8
	sub_82C8ECE8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C9149C:
	// addi r11,r10,-2
	r11.s64 = ctx.r10.s64 + -2;
	// li r3,29
	ctx.r3.s64 = 29;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C914B0:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c914cc
	if (!cr6.eq) goto loc_82C914CC;
	// stw r5,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r5.u32);
	// li r3,-15
	ctx.r3.s64 = -15;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C914CC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c91530
	if (cr6.eq) goto loc_82C91530;
loc_82C914D8:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c914f4
	if (!cr6.eq) goto loc_82C914F4;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c914fc
	goto loc_82C914FC;
loc_82C914F4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C914FC:
	// cmpwi cr6,r3,9
	cr6.compare<int32_t>(ctx.r3.s32, 9, xer);
	// beq cr6,0x82c91518
	if (cr6.eq) goto loc_82C91518;
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// beq cr6,0x82c91524
	if (cr6.eq) goto loc_82C91524;
	// cmpwi cr6,r3,21
	cr6.compare<int32_t>(ctx.r3.s32, 21, xer);
	// bne cr6,0x82c91530
	if (!cr6.eq) goto loc_82C91530;
	// b 0x82c91524
	goto loc_82C91524;
loc_82C91518:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c91530
	if (cr6.eq) goto loc_82C91530;
loc_82C91524:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c914d8
	if (!cr6.eq) goto loc_82C914D8;
loc_82C91530:
	// li r3,15
	ctx.r3.s64 = 15;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91540:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c90b20
	sub_82C90B20(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91554:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,38
	ctx.r3.s64 = 38;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91568:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,25
	ctx.r3.s64 = 25;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C9157C:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c91594
	if (!cr6.eq) goto loc_82C91594;
	// li r3,-26
	ctx.r3.s64 = -26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91594:
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c915e4
	if (!cr6.eq) goto loc_82C915E4;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,93
	cr6.compare<uint32_t>(ctx.r10.u32, 93, xer);
	// bne cr6,0x82c915e4
	if (!cr6.eq) goto loc_82C915E4;
	// addi r10,r11,2
	ctx.r10.s64 = r11.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9128c
	if (cr6.eq) goto loc_82C9128C;
	// lbz r9,3(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c915e4
	if (!cr6.eq) goto loc_82C915E4;
	// lbz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c915e4
	if (!cr6.eq) goto loc_82C915E4;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// li r3,34
	ctx.r3.s64 = 34;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C915E4:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,26
	ctx.r3.s64 = 26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C915F4:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,23
	ctx.r3.s64 = 23;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91608:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c91620
	if (!cr6.eq) goto loc_82C91620;
	// li r3,-24
	ctx.r3.s64 = -24;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91620:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c9163c
	if (!cr6.eq) goto loc_82C9163C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c91644
	goto loc_82C91644;
loc_82C9163C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C91644:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,27
	cr6.compare<uint32_t>(r11.u32, 27, xer);
	// bgt cr6,0x82c91a64
	if (cr6.gt) goto loc_82C91A64;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,5736
	r12.s64 = r12.s64 + 5736;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C91714;
	case 1:
		goto loc_82C91714;
	case 2:
		goto loc_82C91714;
	case 3:
		goto loc_82C91A64;
	case 4:
		goto loc_82C91A64;
	case 5:
		goto loc_82C91A64;
	case 6:
		goto loc_82C916EC;
	case 7:
		goto loc_82C91A64;
	case 8:
		goto loc_82C91A64;
	case 9:
		goto loc_82C91A64;
	case 10:
		goto loc_82C91A64;
	case 11:
		goto loc_82C91A64;
	case 12:
		goto loc_82C91714;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A64;
	case 16:
		goto loc_82C91A64;
	case 17:
		goto loc_82C91A64;
	case 18:
		goto loc_82C91A64;
	case 19:
		goto loc_82C91A64;
	case 20:
		goto loc_82C91A64;
	case 21:
		goto loc_82C91A64;
	case 22:
		goto loc_82C91A64;
	case 23:
		goto loc_82C91714;
	case 24:
		goto loc_82C916D8;
	case 25:
		goto loc_82C91700;
	case 26:
		goto loc_82C91714;
	case 27:
		goto loc_82C91714;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5908(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5908(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5908(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5868(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5868);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5908(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5908(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5848(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5848);
	// lwz r22,5888(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5888);
	// lwz r22,5908(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5908(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
loc_82C916D8:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,36
	ctx.r3.s64 = 36;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C916EC:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,35
	ctx.r3.s64 = 35;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91700:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,37
	ctx.r3.s64 = 37;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91714:
	// li r3,24
	ctx.r3.s64 = 24;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91724:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,21
	ctx.r3.s64 = 21;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91738:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,17
	ctx.r3.s64 = 17;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C9174C:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c90db0
	sub_82C90DB0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91760:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c91a64
	if (!cr6.lt) goto loc_82C91A64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91778:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c91a64
	if (!cr6.lt) goto loc_82C91A64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91790:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c91a64
	if (!cr6.lt) goto loc_82C91A64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C917A8:
	// clrlwi r11,r8,24
	r11.u64 = ctx.r8.u32 & 0xFF;
	// addi r7,r31,1280
	ctx.r7.s64 = r31.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r8,r30,r4
	ctx.r8.u64 = ctx.r4.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r3,r11,r7
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + ctx.r7.u32);
	// rotlwi r4,r3,3
	ctx.r4.u64 = rotl32(ctx.r3.u32, 3);
	// add r7,r4,r9
	ctx.r7.u64 = ctx.r4.u64 + ctx.r9.u64;
	// rlwinm r4,r7,2,0,29
	ctx.r4.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r4,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + r31.u32);
	// and r7,r3,r8
	ctx.r7.u64 = ctx.r3.u64 & ctx.r8.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82c917e4
	if (cr6.eq) goto loc_82C917E4;
loc_82C917DC:
	// li r8,18
	ctx.r8.s64 = 18;
	// b 0x82c9180c
	goto loc_82C9180C;
loc_82C917E4:
	// addi r7,r31,1536
	ctx.r7.s64 = r31.s64 + 1536;
	// lbzx r4,r11,r7
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + ctx.r7.u32);
	// rotlwi r11,r4,3
	r11.u64 = rotl32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r31
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// and r8,r9,r8
	ctx.r8.u64 = ctx.r9.u64 & ctx.r8.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82c91a64
	if (cr6.eq) goto loc_82C91A64;
loc_82C91808:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C9180C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c91900
	if (cr6.eq) goto loc_82C91900;
loc_82C91818:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c91834
	if (!cr6.eq) goto loc_82C91834;
	// add r11,r4,r29
	r11.u64 = ctx.r4.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c9183c
	goto loc_82C9183C;
loc_82C91834:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C9183C:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	cr6.compare<uint32_t>(r11.u32, 31, xer);
	// bgt cr6,0x82c91a64
	if (cr6.gt) goto loc_82C91A64;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,6240
	r12.s64 = r12.s64 + 6240;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C91760;
	case 1:
		goto loc_82C91778;
	case 2:
		goto loc_82C91790;
	case 3:
		goto loc_82C91A64;
	case 4:
		goto loc_82C91A00;
	case 5:
		goto loc_82C91A00;
	case 6:
		goto loc_82C91A00;
	case 7:
		goto loc_82C91A64;
	case 8:
		goto loc_82C91A64;
	case 9:
		goto loc_82C91A64;
	case 10:
		goto loc_82C91A48;
	case 11:
		goto loc_82C91A64;
	case 12:
		goto loc_82C91A64;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A00;
	case 16:
		goto loc_82C91A00;
	case 17:
		goto loc_82C919F8;
	case 18:
		goto loc_82C918E0;
	case 19:
		goto loc_82C919F8;
	case 20:
		goto loc_82C919F8;
	case 21:
		goto loc_82C919F8;
	case 22:
		goto loc_82C919F8;
	case 23:
		goto loc_82C91A64;
	case 24:
		goto loc_82C919C4;
	case 25:
		goto loc_82C91A00;
	case 26:
		goto loc_82C91A64;
	case 27:
		goto loc_82C91A00;
	case 28:
		goto loc_82C91A2C;
	case 29:
		goto loc_82C91A10;
	case 30:
		goto loc_82C91A00;
	case 31:
		goto loc_82C91A00;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5984(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5984);
	// lwz r22,6008(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6008);
	// lwz r22,6032(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6032);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6728(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6728);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6648(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6368(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6368);
	// lwz r22,6648(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6596(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6596);
	// lwz r22,6656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6700(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6700);
	// lwz r22,6672(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6672);
	// lwz r22,6656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
loc_82C918E0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmpwi cr6,r8,18
	cr6.compare<int32_t>(ctx.r8.s32, 18, xer);
	// beq cr6,0x82c9190c
	if (cr6.eq) goto loc_82C9190C;
	// cmpwi cr6,r8,41
	cr6.compare<int32_t>(ctx.r8.s32, 41, xer);
	// bne cr6,0x82c918f8
	if (!cr6.eq) goto loc_82C918F8;
loc_82C918F4:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C918F8:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c91818
	if (!cr6.eq) goto loc_82C91818;
loc_82C91900:
	// neg r3,r8
	ctx.r3.s64 = -ctx.r8.s64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C9190C:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9128c
	if (cr6.eq) goto loc_82C9128C;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// li r8,41
	ctx.r8.s64 = 41;
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c91934
	if (!cr6.eq) goto loc_82C91934;
	// add r11,r4,r29
	r11.u64 = ctx.r4.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c9193c
	goto loc_82C9193C;
loc_82C91934:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C9193C:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c918f4
	if (cr6.gt) goto loc_82C918F4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,6496
	r12.s64 = r12.s64 + 6496;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C91760;
	case 1:
		goto loc_82C91778;
	case 2:
		goto loc_82C91790;
	case 3:
		goto loc_82C918F4;
	case 4:
		goto loc_82C918F4;
	case 5:
		goto loc_82C918F4;
	case 6:
		goto loc_82C918F4;
	case 7:
		goto loc_82C918F4;
	case 8:
		goto loc_82C918F4;
	case 9:
		goto loc_82C918F4;
	case 10:
		goto loc_82C918F4;
	case 11:
		goto loc_82C918F4;
	case 12:
		goto loc_82C918F4;
	case 13:
		goto loc_82C918F4;
	case 14:
		goto loc_82C918F4;
	case 15:
		goto loc_82C918F4;
	case 16:
		goto loc_82C918F4;
	case 17:
		goto loc_82C919F8;
	case 18:
		goto loc_82C918F4;
	case 19:
		goto loc_82C919F8;
	case 20:
		goto loc_82C919F8;
	case 21:
		goto loc_82C919F8;
	case 22:
		goto loc_82C919F8;
	case 23:
		goto loc_82C918F4;
	case 24:
		goto loc_82C919C4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5984(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5984);
	// lwz r22,6008(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6008);
	// lwz r22,6032(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6032);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6648(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6648(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6388(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6596(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6596);
loc_82C919C4:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r31,1536
	ctx.r7.s64 = r31.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r30,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	r11.u64 = PPC_LOAD_U8(r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r31
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + r31.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c91a64
	if (cr6.eq) goto loc_82C91A64;
loc_82C919F8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c918f8
	goto loc_82C918F8;
loc_82C91A00:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91A10:
	// cmpwi cr6,r8,19
	cr6.compare<int32_t>(ctx.r8.s32, 19, xer);
	// beq cr6,0x82c91a64
	if (cr6.eq) goto loc_82C91A64;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,32
	ctx.r3.s64 = 32;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91A2C:
	// cmpwi cr6,r8,19
	cr6.compare<int32_t>(ctx.r8.s32, 19, xer);
	// beq cr6,0x82c91a64
	if (cr6.eq) goto loc_82C91A64;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,31
	ctx.r3.s64 = 31;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91A48:
	// cmpwi cr6,r8,19
	cr6.compare<int32_t>(ctx.r8.s32, 19, xer);
	// beq cr6,0x82c91a64
	if (cr6.eq) goto loc_82C91A64;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,30
	ctx.r3.s64 = 30;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C91A64:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C91248) {
	__imp__sub_82C91248(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C91A78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c91aa8
	if (!cr6.eq) goto loc_82C91AA8;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91AA8:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C91AAC:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c91ac8
	if (!cr6.eq) goto loc_82C91AC8;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c91ad0
	goto loc_82C91AD0;
loc_82C91AC8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C91AD0:
	// addi r11,r3,-2
	r11.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r11,19
	cr6.compare<uint32_t>(r11.u32, 19, xer);
	// bgt cr6,0x82c91b54
	if (cr6.gt) goto loc_82C91B54;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,6900
	r12.s64 = r12.s64 + 6900;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C91B9C;
	case 1:
		goto loc_82C91B78;
	case 2:
		goto loc_82C91B54;
	case 3:
		goto loc_82C91B54;
	case 4:
		goto loc_82C91B44;
	case 5:
		goto loc_82C91B4C;
	case 6:
		goto loc_82C91B54;
	case 7:
		goto loc_82C91BD8;
	case 8:
		goto loc_82C91BB4;
	case 9:
		goto loc_82C91B54;
	case 10:
		goto loc_82C91B54;
	case 11:
		goto loc_82C91B54;
	case 12:
		goto loc_82C91B54;
	case 13:
		goto loc_82C91B54;
	case 14:
		goto loc_82C91B54;
	case 15:
		goto loc_82C91B54;
	case 16:
		goto loc_82C91B54;
	case 17:
		goto loc_82C91B54;
	case 18:
		goto loc_82C91B54;
	case 19:
		goto loc_82C91C48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,7068(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7068);
	// lwz r22,7032(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7032);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6980(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6980);
	// lwz r22,6988(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6988);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,7128(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7128);
	// lwz r22,7092(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7092);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,7240(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7240);
loc_82C91B44:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c91b58
	goto loc_82C91B58;
loc_82C91B4C:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c91b58
	goto loc_82C91B58;
loc_82C91B54:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91B58:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c91aac
	if (!cr6.eq) goto loc_82C91AAC;
loc_82C91B60:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91B78:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c91b60
	if (!cr6.eq) goto loc_82C91B60;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8f940
	sub_82C8F940(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91B9C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91BB4:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c91b60
	if (!cr6.eq) goto loc_82C91B60;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91BD8:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c91b60
	if (!cr6.eq) goto loc_82C91B60;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c91c00
	if (!cr6.eq) goto loc_82C91C00;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91C00:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c91c1c
	if (!cr6.eq) goto loc_82C91C1C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c91c24
	goto loc_82C91C24;
loc_82C91C1C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C91C24:
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bne cr6,0x82c91c30
	if (!cr6.eq) goto loc_82C91C30;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91C30:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91C48:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c91b60
	if (!cr6.eq) goto loc_82C91B60;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,39
	ctx.r3.s64 = 39;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C91A78) {
	__imp__sub_82C91A78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C91C70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c91ca0
	if (!cr6.eq) goto loc_82C91CA0;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91CA0:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C91CA4:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c91cc0
	if (!cr6.eq) goto loc_82C91CC0;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c91cc8
	goto loc_82C91CC8;
loc_82C91CC0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C91CC8:
	// addi r11,r3,-3
	r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,27
	cr6.compare<uint32_t>(r11.u32, 27, xer);
	// bgt cr6,0x82c91d6c
	if (cr6.gt) goto loc_82C91D6C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,7404
	r12.s64 = r12.s64 + 7404;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C91D90;
	case 1:
		goto loc_82C91D6C;
	case 2:
		goto loc_82C91D6C;
	case 3:
		goto loc_82C91D5C;
	case 4:
		goto loc_82C91D64;
	case 5:
		goto loc_82C91D6C;
	case 6:
		goto loc_82C91E08;
	case 7:
		goto loc_82C91DE4;
	case 8:
		goto loc_82C91D6C;
	case 9:
		goto loc_82C91D6C;
	case 10:
		goto loc_82C91D6C;
	case 11:
		goto loc_82C91D6C;
	case 12:
		goto loc_82C91D6C;
	case 13:
		goto loc_82C91D6C;
	case 14:
		goto loc_82C91D6C;
	case 15:
		goto loc_82C91D6C;
	case 16:
		goto loc_82C91D6C;
	case 17:
		goto loc_82C91D6C;
	case 18:
		goto loc_82C91D6C;
	case 19:
		goto loc_82C91D6C;
	case 20:
		goto loc_82C91D6C;
	case 21:
		goto loc_82C91D6C;
	case 22:
		goto loc_82C91D6C;
	case 23:
		goto loc_82C91D6C;
	case 24:
		goto loc_82C91D6C;
	case 25:
		goto loc_82C91D6C;
	case 26:
		goto loc_82C91D6C;
	case 27:
		goto loc_82C91DB4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,7568(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7568);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7516(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7516);
	// lwz r22,7524(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7524);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7688(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7688);
	// lwz r22,7652(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7652);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7604(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7604);
loc_82C91D5C:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c91d70
	goto loc_82C91D70;
loc_82C91D64:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c91d70
	goto loc_82C91D70;
loc_82C91D6C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91D70:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c91ca4
	if (!cr6.eq) goto loc_82C91CA4;
loc_82C91D78:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C91D80:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91D90:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c91d78
	if (!cr6.eq) goto loc_82C91D78;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8f940
	sub_82C8F940(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91DB4:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c91d78
	if (!cr6.eq) goto loc_82C91D78;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c90b20
	sub_82C90B20(ctx, base);
	// cmpwi cr6,r3,22
	cr6.compare<int32_t>(ctx.r3.s32, 22, xer);
	// bne cr6,0x82c91d80
	if (!cr6.eq) goto loc_82C91D80;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91DE4:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c91d78
	if (!cr6.eq) goto loc_82C91D78;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91E08:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c91d78
	if (!cr6.eq) goto loc_82C91D78;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c91e30
	if (!cr6.eq) goto loc_82C91E30;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91E30:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c91e4c
	if (!cr6.eq) goto loc_82C91E4C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c91e54
	goto loc_82C91E54;
loc_82C91E4C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C91E54:
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bne cr6,0x82c91e60
	if (!cr6.eq) goto loc_82C91E60;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91E60:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C91C70) {
	__imp__sub_82C91C70(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C91E78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// li r8,0
	ctx.r8.s64 = 0;
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c91ea8
	if (cr6.eq) goto loc_82C91EA8;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
loc_82C91EA8:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c91f34
	if (cr6.eq) goto loc_82C91F34;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C91EB4:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c91ed0
	if (!cr6.eq) goto loc_82C91ED0;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r7
	r11.u64 = r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c91ed8
	goto loc_82C91ED8;
loc_82C91ED0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C91ED8:
	// cmplwi cr6,r3,8
	cr6.compare<uint32_t>(ctx.r3.u32, 8, xer);
	// bgt cr6,0x82c91f24
	if (cr6.gt) goto loc_82C91F24;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,7928
	r12.s64 = r12.s64 + 7928;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C92044;
	case 1:
		goto loc_82C92044;
	case 2:
		goto loc_82C91F70;
	case 3:
		goto loc_82C91F24;
	case 4:
		goto loc_82C91FC8;
	case 5:
		goto loc_82C91F1C;
	case 6:
		goto loc_82C91F48;
	case 7:
		goto loc_82C91F5C;
	case 8:
		goto loc_82C92044;
	default:
		__builtin_unreachable();
	}
	// lwz r22,8260(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8260);
	// lwz r22,8260(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8260);
	// lwz r22,8048(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8048);
	// lwz r22,7972(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7972);
	// lwz r22,8136(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8136);
	// lwz r22,7964(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7964);
	// lwz r22,8008(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8008);
	// lwz r22,8028(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8028);
	// lwz r22,8260(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8260);
loc_82C91F1C:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// blt cr6,0x82c92030
	if (cr6.lt) goto loc_82C92030;
loc_82C91F24:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
loc_82C91F2C:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c91eb4
	if (!cr6.eq) goto loc_82C91EB4;
loc_82C91F34:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C91F48:
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// blt cr6,0x82c92030
	if (cr6.lt) goto loc_82C92030;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c91f2c
	goto loc_82C91F2C;
loc_82C91F5C:
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c92030
	if (cr6.lt) goto loc_82C92030;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c91f2c
	goto loc_82C91F2C;
loc_82C91F70:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c91f34
	if (cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c91f2c
	if (!cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,33
	cr6.compare<uint32_t>(r11.u32, 33, xer);
	// bne cr6,0x82c91f2c
	if (!cr6.eq) goto loc_82C91F2C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c91f34
	if (cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c91f2c
	if (!cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,91
	cr6.compare<uint32_t>(r11.u32, 91, xer);
	// bne cr6,0x82c91f2c
	if (!cr6.eq) goto loc_82C91F2C;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// b 0x82c91f24
	goto loc_82C91F24;
loc_82C91FC8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c91f34
	if (cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c91f2c
	if (!cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c91f2c
	if (!cr6.eq) goto loc_82C91F2C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c91f34
	if (cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c91f2c
	if (!cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// bne cr6,0x82c91f2c
	if (!cr6.eq) goto loc_82C91F2C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82c9205c
	if (cr6.eq) goto loc_82C9205C;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// b 0x82c91f2c
	goto loc_82C91F2C;
loc_82C92030:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92044:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C9205C:
	// li r3,42
	ctx.r3.s64 = 42;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C91E78) {
	__imp__sub_82C91E78(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C92078) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// addi r7,r5,-2
	ctx.r7.s64 = ctx.r5.s64 + -2;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// beq cr6,0x82c921bc
	if (cr6.eq) goto loc_82C921BC;
loc_82C92098:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// extsb r9,r3
	ctx.r9.s64 = ctx.r3.s8;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c920b8
	if (!cr6.eq) goto loc_82C920B8;
	// add r11,r4,r8
	r11.u64 = ctx.r4.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c920bc
	goto loc_82C920BC;
loc_82C920B8:
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C920BC:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,26
	cr6.compare<uint32_t>(r11.u32, 26, xer);
	// bgt cr6,0x82c92194
	if (cr6.gt) goto loc_82C92194;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,8416
	r12.s64 = r12.s64 + 8416;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C921B0;
	case 1:
		goto loc_82C921B0;
	case 2:
		goto loc_82C92194;
	case 3:
		goto loc_82C92194;
	case 4:
		goto loc_82C921B0;
	case 5:
		goto loc_82C921B0;
	case 6:
		goto loc_82C921B0;
	case 7:
		goto loc_82C921B0;
	case 8:
		goto loc_82C921B0;
	case 9:
		goto loc_82C921B0;
	case 10:
		goto loc_82C921B0;
	case 11:
		goto loc_82C92194;
	case 12:
		goto loc_82C9214C;
	case 13:
		goto loc_82C92178;
	case 14:
		goto loc_82C921B0;
	case 15:
		goto loc_82C921B0;
	case 16:
		goto loc_82C921B0;
	case 17:
		goto loc_82C92178;
	case 18:
		goto loc_82C921B0;
	case 19:
		goto loc_82C92194;
	case 20:
		goto loc_82C92194;
	case 21:
		goto loc_82C921B0;
	case 22:
		goto loc_82C921B0;
	case 23:
		goto loc_82C921B0;
	case 24:
		goto loc_82C921B0;
	case 25:
		goto loc_82C921B0;
	case 26:
		goto loc_82C921B0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8596(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8596(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8596(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8524(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8524);
	// lwz r22,8568(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8568);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8568(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8568);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8596(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8596(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
loc_82C9214C:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c921b0
	if (!cr6.eq) goto loc_82C921B0;
	// extsb r11,r4
	r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82c921b0
	if (!cr6.eq) goto loc_82C921B0;
loc_82C92160:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92178:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// extsb r11,r4
	r11.s64 = ctx.r4.s8;
	// beq cr6,0x82c92188
	if (cr6.eq) goto loc_82C92188;
	// li r11,-1
	r11.s64 = -1;
loc_82C92188:
	// rlwinm r11,r11,0,0,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82c921b0
	if (cr6.eq) goto loc_82C921B0;
loc_82C92194:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c92160
	if (!cr6.eq) goto loc_82C92160;
	// extsb r11,r4
	r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,36
	cr6.compare<int32_t>(r11.s32, 36, xer);
	// beq cr6,0x82c921b0
	if (cr6.eq) goto loc_82C921B0;
	// cmpwi cr6,r11,64
	cr6.compare<int32_t>(r11.s32, 64, xer);
	// bne cr6,0x82c92160
	if (!cr6.eq) goto loc_82C92160;
loc_82C921B0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// bne cr6,0x82c92098
	if (!cr6.eq) goto loc_82C92098;
loc_82C921BC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C92078) {
	__imp__sub_82C92078(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C921D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r27,0
	r27.s64 = 0;
	// addi r8,r4,2
	ctx.r8.s64 = ctx.r4.s64 + 2;
	// li r29,1
	r29.s64 = 1;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// mr r30,r27
	r30.u64 = r27.u64;
	// addi r31,r8,2
	r31.s64 = ctx.r8.s64 + 2;
loc_82C921FC:
	// lbz r3,1(r8)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// lbz r4,0(r8)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// extsb r10,r3
	ctx.r10.s64 = ctx.r3.s8;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x82c9221c
	if (!cr6.eq) goto loc_82C9221C;
	// add r11,r4,r28
	r11.u64 = ctx.r4.u64 + r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c92220
	goto loc_82C92220;
loc_82C9221C:
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C92220:
	// addi r11,r3,-3
	r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,26
	cr6.compare<uint32_t>(r11.u32, 26, xer);
	// bgt cr6,0x82c924c8
	if (cr6.gt) goto loc_82C924C8;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,8772
	r12.s64 = r12.s64 + 8772;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C924A8;
	case 1:
		goto loc_82C924C8;
	case 2:
		goto loc_82C922B0;
	case 3:
		goto loc_82C922D8;
	case 4:
		goto loc_82C92308;
	case 5:
		goto loc_82C924C8;
	case 6:
		goto loc_82C92488;
	case 7:
		goto loc_82C92488;
	case 8:
		goto loc_82C924C0;
	case 9:
		goto loc_82C92338;
	case 10:
		goto loc_82C9238C;
	case 11:
		goto loc_82C924C8;
	case 12:
		goto loc_82C924C8;
	case 13:
		goto loc_82C924C8;
	case 14:
		goto loc_82C924C0;
	case 15:
		goto loc_82C924C8;
	case 16:
		goto loc_82C924C8;
	case 17:
		goto loc_82C924C8;
	case 18:
		goto loc_82C923E0;
	case 19:
		goto loc_82C922B0;
	case 20:
		goto loc_82C924C8;
	case 21:
		goto loc_82C922B0;
	case 22:
		goto loc_82C924C8;
	case 23:
		goto loc_82C924C8;
	case 24:
		goto loc_82C924C8;
	case 25:
		goto loc_82C924C8;
	case 26:
		goto loc_82C922B0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,9384(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9384);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,8880(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
	// lwz r22,8920(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8920);
	// lwz r22,8968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8968);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9352);
	// lwz r22,9352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9352);
	// lwz r22,9408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9408);
	// lwz r22,9016(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9016);
	// lwz r22,9100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9100);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9408);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9184(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9184);
	// lwz r22,8880(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,8880(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,8880(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
loc_82C922B0:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c924c8
	if (!cr6.eq) goto loc_82C924C8;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c922c8
	if (!cr6.lt) goto loc_82C922C8;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r29.u8);
loc_82C922C8:
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C922D8:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c922f4
	if (!cr6.eq) goto loc_82C922F4;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c922f0
	if (!cr6.lt) goto loc_82C922F0;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r29.u8);
loc_82C922F0:
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_82C922F4:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92308:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c92324
	if (!cr6.eq) goto loc_82C92324;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c92320
	if (!cr6.lt) goto loc_82C92320;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r29.u8);
loc_82C92320:
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_82C92324:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92338:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// beq cr6,0x82c92360
	if (cr6.eq) goto loc_82C92360;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c9234c
	if (!cr6.lt) goto loc_82C9234C;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, r31.u32);
loc_82C9234C:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,12
	r30.s64 = 12;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92360:
	// cmpwi cr6,r30,12
	cr6.compare<int32_t>(r30.s32, 12, xer);
	// bne cr6,0x82c924c8
	if (!cr6.eq) goto loc_82C924C8;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c92378
	if (!cr6.lt) goto loc_82C92378;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
loc_82C92378:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C9238C:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// beq cr6,0x82c923b4
	if (cr6.eq) goto loc_82C923B4;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c923a0
	if (!cr6.lt) goto loc_82C923A0;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, r31.u32);
loc_82C923A0:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,13
	r30.s64 = 13;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C923B4:
	// cmpwi cr6,r30,13
	cr6.compare<int32_t>(r30.s32, 13, xer);
	// bne cr6,0x82c924c8
	if (!cr6.eq) goto loc_82C924C8;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c92378
	if (!cr6.lt) goto loc_82C92378;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C923E0:
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// bne cr6,0x82c923f8
	if (!cr6.eq) goto loc_82C923F8;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C923F8:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bne cr6,0x82c924c8
	if (!cr6.eq) goto loc_82C924C8;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c924c8
	if (!cr6.lt) goto loc_82C924C8;
	// lbz r11,12(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c924c8
	if (cr6.eq) goto loc_82C924C8;
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// beq cr6,0x82c92478
	if (cr6.eq) goto loc_82C92478;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x82c92478
	if (!cr6.eq) goto loc_82C92478;
	// extsb r11,r4
	r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// bne cr6,0x82c92478
	if (!cr6.eq) goto loc_82C92478;
	// lbz r3,3(r8)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r8.u32 + 3);
	// extsb r11,r3
	r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c92468
	if (!cr6.eq) goto loc_82C92468;
	// lbz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r10,32
	cr6.compare<uint32_t>(ctx.r10.u32, 32, xer);
	// beq cr6,0x82c92478
	if (cr6.eq) goto loc_82C92478;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c92468
	if (!cr6.eq) goto loc_82C92468;
	// clrlwi r11,r10,24
	r11.u64 = ctx.r10.u32 & 0xFF;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c92470
	goto loc_82C92470;
loc_82C92468:
	// lbz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C92470:
	// cmpw cr6,r3,r30
	cr6.compare<int32_t>(ctx.r3.s32, r30.s32, xer);
	// bne cr6,0x82c924c8
	if (!cr6.eq) goto loc_82C924C8;
loc_82C92478:
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92488:
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// bne cr6,0x82c924a0
	if (!cr6.eq) goto loc_82C924A0;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C924A0:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bne cr6,0x82c924c8
	if (!cr6.eq) goto loc_82C924C8;
loc_82C924A8:
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c924c8
	if (!cr6.lt) goto loc_82C924C8;
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C924C0:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bne cr6,0x82c924d4
	if (!cr6.eq) goto loc_82C924D4;
loc_82C924C8:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C924D4:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C921D0) {
	__imp__sub_82C921D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C924E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// subf r11,r4,r5
	r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// srawi r10,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r10.s64 = r11.s32 >> 1;
	// addze r11,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	r11.s64 = temp.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82c9262c
	if (cr6.eq) goto loc_82C9262C;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x82c925d8
	if (cr6.eq) goto loc_82C925D8;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,97
	cr6.compare<int32_t>(r11.s32, 97, xer);
	// beq cr6,0x82c92580
	if (cr6.eq) goto loc_82C92580;
	// cmpwi cr6,r11,113
	cr6.compare<int32_t>(r11.s32, 113, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,117
	cr6.compare<uint32_t>(ctx.r10.u32, 117, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,111
	cr6.compare<uint32_t>(ctx.r10.u32, 111, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r11,2(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// cmplwi cr6,r11,116
	cr6.compare<uint32_t>(r11.u32, 116, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// li r3,34
	ctx.r3.s64 = 34;
	// blr 
	return;
loc_82C92580:
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,112
	cr6.compare<uint32_t>(ctx.r10.u32, 112, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,111
	cr6.compare<uint32_t>(ctx.r10.u32, 111, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r11,2(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// cmplwi cr6,r11,115
	cr6.compare<uint32_t>(r11.u32, 115, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// li r3,39
	ctx.r3.s64 = 39;
	// blr 
	return;
loc_82C925D8:
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,97
	cr6.compare<uint32_t>(r11.u32, 97, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,109
	cr6.compare<uint32_t>(ctx.r10.u32, 109, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r11,2(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// cmplwi cr6,r11,112
	cr6.compare<uint32_t>(r11.u32, 112, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// li r3,38
	ctx.r3.s64 = 38;
	// blr 
	return;
loc_82C9262C:
	// lbz r11,3(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r11,2(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// cmplwi cr6,r11,116
	cr6.compare<uint32_t>(r11.u32, 116, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,103
	cr6.compare<int32_t>(r11.s32, 103, xer);
	// beq cr6,0x82c92670
	if (cr6.eq) goto loc_82C92670;
	// cmpwi cr6,r11,108
	cr6.compare<int32_t>(r11.s32, 108, xer);
	// bne cr6,0x82c92678
	if (!cr6.eq) goto loc_82C92678;
	// li r3,60
	ctx.r3.s64 = 60;
	// blr 
	return;
loc_82C92670:
	// li r3,62
	ctx.r3.s64 = 62;
	// blr 
	return;
loc_82C92678:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C924E0) {
	__imp__sub_82C924E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C92680) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C92694:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r9,r10,1
	ctx.r9.s64 = ctx.r10.s64 + 1;
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c926b4
	if (!cr6.eq) goto loc_82C926B4;
	// add r11,r4,r8
	r11.u64 = ctx.r4.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c926b8
	goto loc_82C926B8;
loc_82C926B4:
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C926B8:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c927fc
	if (cr6.gt) goto loc_82C927FC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,9948
	r12.s64 = r12.s64 + 9948;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C92774;
	case 1:
		goto loc_82C9275C;
	case 2:
		goto loc_82C92740;
	case 3:
		goto loc_82C927FC;
	case 4:
		goto loc_82C927FC;
	case 5:
		goto loc_82C927FC;
	case 6:
		goto loc_82C927FC;
	case 7:
		goto loc_82C927FC;
	case 8:
		goto loc_82C927FC;
	case 9:
		goto loc_82C927FC;
	case 10:
		goto loc_82C927FC;
	case 11:
		goto loc_82C927FC;
	case 12:
		goto loc_82C927FC;
	case 13:
		goto loc_82C927FC;
	case 14:
		goto loc_82C927FC;
	case 15:
		goto loc_82C927FC;
	case 16:
		goto loc_82C927FC;
	case 17:
		goto loc_82C927B8;
	case 18:
		goto loc_82C927B8;
	case 19:
		goto loc_82C927B8;
	case 20:
		goto loc_82C927B8;
	case 21:
		goto loc_82C927B8;
	case 22:
		goto loc_82C927B8;
	case 23:
		goto loc_82C927FC;
	case 24:
		goto loc_82C927B8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,10100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10100);
	// lwz r22,10076(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10076);
	// lwz r22,10048(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10048);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10236(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
loc_82C92740:
	// lbz r11,0(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r7,r4
	ctx.r7.s64 = ctx.r4.s8;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// extsb r6,r11
	ctx.r6.s64 = r11.s8;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// cmpw cr6,r7,r6
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r6.s32, xer);
	// bne cr6,0x82c927a4
	if (!cr6.eq) goto loc_82C927A4;
loc_82C9275C:
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lbz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x82c927a4
	if (!cr6.eq) goto loc_82C927A4;
loc_82C92774:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r11,r10,1
	r11.s64 = ctx.r10.s64 + 1;
	// lbz r6,0(r5)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r9,r5,1
	ctx.r9.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// bne cr6,0x82c927a4
	if (!cr6.eq) goto loc_82C927A4;
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// lbz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r5,r9,1
	ctx.r5.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// beq cr6,0x82c92694
	if (cr6.eq) goto loc_82C92694;
loc_82C927A4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C927B8:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r7,r4
	ctx.r7.s64 = ctx.r4.s8;
	// addi r11,r5,1
	r11.s64 = ctx.r5.s64 + 1;
	// extsb r6,r10
	ctx.r6.s64 = ctx.r10.s8;
	// cmpw cr6,r6,r7
	cr6.compare<int32_t>(ctx.r6.s32, ctx.r7.s32, xer);
	// bne cr6,0x82c927a4
	if (!cr6.eq) goto loc_82C927A4;
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r10,r9,1
	ctx.r10.s64 = ctx.r9.s64 + 1;
	// lbz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r5,r11,1
	ctx.r5.s64 = r11.s64 + 1;
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// beq cr6,0x82c92694
	if (cr6.eq) goto loc_82C92694;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C927FC:
	// lbz r3,1(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c92818
	if (!cr6.eq) goto loc_82C92818;
	// lbz r11,0(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c92820
	goto loc_82C92820;
loc_82C92818:
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C92820:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c928a8
	if (cr6.gt) goto loc_82C928A8;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,10308
	r12.s64 = r12.s64 + 10308;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C927A4;
	case 1:
		goto loc_82C927A4;
	case 2:
		goto loc_82C927A4;
	case 3:
		goto loc_82C928A8;
	case 4:
		goto loc_82C928A8;
	case 5:
		goto loc_82C928A8;
	case 6:
		goto loc_82C928A8;
	case 7:
		goto loc_82C928A8;
	case 8:
		goto loc_82C928A8;
	case 9:
		goto loc_82C928A8;
	case 10:
		goto loc_82C928A8;
	case 11:
		goto loc_82C928A8;
	case 12:
		goto loc_82C928A8;
	case 13:
		goto loc_82C928A8;
	case 14:
		goto loc_82C928A8;
	case 15:
		goto loc_82C928A8;
	case 16:
		goto loc_82C928A8;
	case 17:
		goto loc_82C927A4;
	case 18:
		goto loc_82C927A4;
	case 19:
		goto loc_82C927A4;
	case 20:
		goto loc_82C927A4;
	case 21:
		goto loc_82C927A4;
	case 22:
		goto loc_82C927A4;
	case 23:
		goto loc_82C928A8;
	case 24:
		goto loc_82C927A4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,10148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
loc_82C928A8:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C92680) {
	__imp__sub_82C92680(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C928C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,0(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82c9290c
	if (cr6.eq) goto loc_82C9290C;
loc_82C928D0:
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9291c
	if (cr6.eq) goto loc_82C9291C;
	// lbz r10,1(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c9291c
	if (!cr6.eq) goto loc_82C9291C;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// cmpw cr6,r9,r11
	cr6.compare<int32_t>(ctx.r9.s32, r11.s32, xer);
	// bne cr6,0x82c9291c
	if (!cr6.eq) goto loc_82C9291C;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// lbz r11,0(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c928d0
	if (!cr6.eq) goto loc_82C928D0;
loc_82C9290C:
	// subf r11,r4,r5
	r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r10,27,31,31
	ctx.r3.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// blr 
	return;
loc_82C9291C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C928C0) {
	__imp__sub_82C928C0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C92928) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C92940:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c9295c
	if (!cr6.eq) goto loc_82C9295C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c92964
	goto loc_82C92964;
loc_82C9295C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C92964:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c92a04
	if (cr6.gt) goto loc_82C92A04;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,10632
	r12.s64 = r12.s64 + 10632;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C929EC;
	case 1:
		goto loc_82C929F4;
	case 2:
		goto loc_82C929FC;
	case 3:
		goto loc_82C92A04;
	case 4:
		goto loc_82C92A04;
	case 5:
		goto loc_82C92A04;
	case 6:
		goto loc_82C92A04;
	case 7:
		goto loc_82C92A04;
	case 8:
		goto loc_82C92A04;
	case 9:
		goto loc_82C92A04;
	case 10:
		goto loc_82C92A04;
	case 11:
		goto loc_82C92A04;
	case 12:
		goto loc_82C92A04;
	case 13:
		goto loc_82C92A04;
	case 14:
		goto loc_82C92A04;
	case 15:
		goto loc_82C92A04;
	case 16:
		goto loc_82C92A04;
	case 17:
		goto loc_82C929EC;
	case 18:
		goto loc_82C929EC;
	case 19:
		goto loc_82C929EC;
	case 20:
		goto loc_82C929EC;
	case 21:
		goto loc_82C929EC;
	case 22:
		goto loc_82C929EC;
	case 23:
		goto loc_82C92A04;
	case 24:
		goto loc_82C929EC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,10732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10740(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10740);
	// lwz r22,10748(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10748);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10756(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
loc_82C929EC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c92940
	goto loc_82C92940;
loc_82C929F4:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c92940
	goto loc_82C92940;
loc_82C929FC:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c92940
	goto loc_82C92940;
loc_82C92A04:
	// subf r3,r8,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r8.s64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C92928) {
	__imp__sub_82C92928(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C92A18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C92A2C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c92a48
	if (!cr6.eq) goto loc_82C92A48;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c92a50
	goto loc_82C92A50;
loc_82C92A48:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C92A50:
	// cmpwi cr6,r3,9
	cr6.compare<int32_t>(ctx.r3.s32, 9, xer);
	// blt cr6,0x82c92a70
	if (cr6.lt) goto loc_82C92A70;
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// ble cr6,0x82c92a68
	if (!cr6.gt) goto loc_82C92A68;
	// cmpwi cr6,r3,21
	cr6.compare<int32_t>(ctx.r3.s32, 21, xer);
	// bne cr6,0x82c92a70
	if (!cr6.eq) goto loc_82C92A70;
loc_82C92A68:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c92a2c
	goto loc_82C92A2C;
loc_82C92A70:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C92A18) {
	__imp__sub_82C92A18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C92A88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c92b40
	if (cr6.eq) goto loc_82C92B40;
	// li r9,-1
	ctx.r9.s64 = -1;
loc_82C92AA8:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c92ac4
	if (!cr6.eq) goto loc_82C92AC4;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c92acc
	goto loc_82C92ACC;
loc_82C92AC4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C92ACC:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// bgt cr6,0x82c92b28
	if (cr6.gt) goto loc_82C92B28;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,10992
	r12.s64 = r12.s64 + 10992;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C92B28;
	case 1:
		goto loc_82C92B08;
	case 2:
		goto loc_82C92B10;
	case 3:
		goto loc_82C92B28;
	case 4:
		goto loc_82C92B50;
	case 5:
		goto loc_82C92B18;
	default:
		__builtin_unreachable();
	}
	// lwz r22,11048(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11048);
	// lwz r22,11016(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11016);
	// lwz r22,11024(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11024);
	// lwz r22,11048(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11048);
	// lwz r22,11088(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11088);
	// lwz r22,11032(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11032);
loc_82C92B08:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c92b2c
	goto loc_82C92B2C;
loc_82C92B10:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c92b2c
	goto loc_82C92B2C;
loc_82C92B18:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
loc_82C92B28:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C92B2C:
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, r11.u32);
	// bne cr6,0x82c92aa8
	if (!cr6.eq) goto loc_82C92AA8;
loc_82C92B40:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92B50:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// beq cr6,0x82c92b98
	if (cr6.eq) goto loc_82C92B98;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c92b84
	if (!cr6.eq) goto loc_82C92B84;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c92b8c
	goto loc_82C92B8C;
loc_82C92B84:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C92B8C:
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bne cr6,0x82c92b98
	if (!cr6.eq) goto loc_82C92B98;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C92B98:
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// b 0x82c92b2c
	goto loc_82C92B2C;
}

PPC_WEAK_FUNC(sub_82C92A88) {
	__imp__sub_82C92A88(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C92BA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c92cac
	if (cr6.eq) goto loc_82C92CAC;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c92d94
	if (!cr6.eq) goto loc_82C92D94;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,45
	cr6.compare<uint32_t>(r11.u32, 45, xer);
	// bne cr6,0x82c92d94
	if (!cr6.eq) goto loc_82C92D94;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c92cac
	if (cr6.eq) goto loc_82C92CAC;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C92BE0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c92bfc
	if (!cr6.eq) goto loc_82C92BFC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c92c04
	goto loc_82C92C04;
loc_82C92BFC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C92C04:
	// cmplwi cr6,r3,27
	cr6.compare<uint32_t>(ctx.r3.u32, 27, xer);
	// bgt cr6,0x82c92c9c
	if (cr6.gt) goto loc_82C92C9C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,11300
	r12.s64 = r12.s64 + 11300;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C92D64;
	case 1:
		goto loc_82C92D64;
	case 2:
		goto loc_82C92C9C;
	case 3:
		goto loc_82C92C9C;
	case 4:
		goto loc_82C92C9C;
	case 5:
		goto loc_82C92C94;
	case 6:
		goto loc_82C92CC0;
	case 7:
		goto loc_82C92CD4;
	case 8:
		goto loc_82C92D64;
	case 9:
		goto loc_82C92C9C;
	case 10:
		goto loc_82C92C9C;
	case 11:
		goto loc_82C92C9C;
	case 12:
		goto loc_82C92C9C;
	case 13:
		goto loc_82C92C9C;
	case 14:
		goto loc_82C92C9C;
	case 15:
		goto loc_82C92C9C;
	case 16:
		goto loc_82C92C9C;
	case 17:
		goto loc_82C92C9C;
	case 18:
		goto loc_82C92C9C;
	case 19:
		goto loc_82C92C9C;
	case 20:
		goto loc_82C92C9C;
	case 21:
		goto loc_82C92C9C;
	case 22:
		goto loc_82C92C9C;
	case 23:
		goto loc_82C92C9C;
	case 24:
		goto loc_82C92C9C;
	case 25:
		goto loc_82C92C9C;
	case 26:
		goto loc_82C92C9C;
	case 27:
		goto loc_82C92CE8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,11620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11620);
	// lwz r22,11620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11620);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11412(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11412);
	// lwz r22,11456(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11456);
	// lwz r22,11476(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11476);
	// lwz r22,11620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11620);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11496(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11496);
loc_82C92C94:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// blt cr6,0x82c92d50
	if (cr6.lt) goto loc_82C92D50;
loc_82C92C9C:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C92CA4:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c92be0
	if (!cr6.eq) goto loc_82C92BE0;
loc_82C92CAC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92CC0:
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// blt cr6,0x82c92d50
	if (cr6.lt) goto loc_82C92D50;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c92ca4
	goto loc_82C92CA4;
loc_82C92CD4:
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c92d50
	if (cr6.lt) goto loc_82C92D50;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c92ca4
	goto loc_82C92CA4;
loc_82C92CE8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c92cac
	if (cr6.eq) goto loc_82C92CAC;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c92ca4
	if (!cr6.eq) goto loc_82C92CA4;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,45
	cr6.compare<uint32_t>(r11.u32, 45, xer);
	// bne cr6,0x82c92ca4
	if (!cr6.eq) goto loc_82C92CA4;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c92cac
	if (cr6.eq) goto loc_82C92CAC;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c92d7c
	if (!cr6.eq) goto loc_82C92D7C;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c92d7c
	if (!cr6.eq) goto loc_82C92D7C;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// li r3,13
	ctx.r3.s64 = 13;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92D50:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92D64:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92D7C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92D94:
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C92BA0) {
	__imp__sub_82C92BA0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C92DB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c92de0
	if (!cr6.eq) goto loc_82C92DE0;
loc_82C92DCC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92DE0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c92dfc
	if (!cr6.eq) goto loc_82C92DFC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c92e04
	goto loc_82C92E04;
loc_82C92DFC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C92E04:
	// addi r11,r3,-20
	r11.s64 = ctx.r3.s64 + -20;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bgt cr6,0x82c93010
	if (cr6.gt) goto loc_82C93010;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,11816
	r12.s64 = r12.s64 + 11816;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C92E64;
	case 1:
		goto loc_82C93010;
	case 2:
		goto loc_82C92E80;
	case 3:
		goto loc_82C93010;
	case 4:
		goto loc_82C92E80;
	case 5:
		goto loc_82C93010;
	case 6:
		goto loc_82C93010;
	case 7:
		goto loc_82C92E48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,11876(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11876);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,11904(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11904);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,11904(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11904);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,11848(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11848);
loc_82C92E48:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c92ba0
	sub_82C92BA0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92E64:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,33
	ctx.r3.s64 = 33;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92E80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c92dcc
	if (cr6.eq) goto loc_82C92DCC;
loc_82C92E8C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c92ea8
	if (!cr6.eq) goto loc_82C92EA8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c92eb0
	goto loc_82C92EB0;
loc_82C92EA8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C92EB0:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// bgt cr6,0x82c93010
	if (cr6.gt) goto loc_82C93010;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,11988
	r12.s64 = r12.s64 + 11988;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C92FF8;
	case 1:
		goto loc_82C92FF8;
	case 2:
		goto loc_82C93010;
	case 3:
		goto loc_82C93010;
	case 4:
		goto loc_82C93010;
	case 5:
		goto loc_82C93010;
	case 6:
		goto loc_82C93010;
	case 7:
		goto loc_82C93010;
	case 8:
		goto loc_82C93010;
	case 9:
		goto loc_82C93010;
	case 10:
		goto loc_82C93010;
	case 11:
		goto loc_82C93010;
	case 12:
		goto loc_82C92FF8;
	case 13:
		goto loc_82C92F2C;
	case 14:
		goto loc_82C93010;
	case 15:
		goto loc_82C92F2C;
	case 16:
		goto loc_82C93010;
	case 17:
		goto loc_82C93010;
	case 18:
		goto loc_82C93010;
	case 19:
		goto loc_82C93010;
	case 20:
		goto loc_82C93010;
	case 21:
		goto loc_82C92F4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12076(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12076);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12076(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12076);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12108(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12108);
loc_82C92F2C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c92e8c
	if (!cr6.eq) goto loc_82C92E8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C92F4C:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c92dcc
	if (cr6.eq) goto loc_82C92DCC;
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c92f74
	if (!cr6.eq) goto loc_82C92F74;
	// lbz r11,3(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c92f7c
	goto loc_82C92F7C;
loc_82C92F74:
	// lbz r4,3(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C92F7C:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// bgt cr6,0x82c92ff8
	if (cr6.gt) goto loc_82C92FF8;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,12192
	r12.s64 = r12.s64 + 12192;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C93010;
	case 1:
		goto loc_82C93010;
	case 2:
		goto loc_82C92FF8;
	case 3:
		goto loc_82C92FF8;
	case 4:
		goto loc_82C92FF8;
	case 5:
		goto loc_82C92FF8;
	case 6:
		goto loc_82C92FF8;
	case 7:
		goto loc_82C92FF8;
	case 8:
		goto loc_82C92FF8;
	case 9:
		goto loc_82C92FF8;
	case 10:
		goto loc_82C92FF8;
	case 11:
		goto loc_82C92FF8;
	case 12:
		goto loc_82C93010;
	case 13:
		goto loc_82C92FF8;
	case 14:
		goto loc_82C92FF8;
	case 15:
		goto loc_82C92FF8;
	case 16:
		goto loc_82C92FF8;
	case 17:
		goto loc_82C92FF8;
	case 18:
		goto loc_82C92FF8;
	case 19:
		goto loc_82C92FF8;
	case 20:
		goto loc_82C92FF8;
	case 21:
		goto loc_82C93010;
	default:
		__builtin_unreachable();
	}
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
loc_82C92FF8:
	// li r3,16
	ctx.r3.s64 = 16;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C93010:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C92DB0) {
	__imp__sub_82C92DB0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C93028) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r11,11
	r11.s64 = 11;
	// subf r10,r4,r5
	ctx.r10.s64 = ctx.r5.s64 - ctx.r4.s64;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x82c930e0
	if (!cr6.eq) goto loc_82C930E0;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c930e0
	if (!cr6.eq) goto loc_82C930E0;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,88
	cr6.compare<int32_t>(r11.s32, 88, xer);
	// beq cr6,0x82c9306c
	if (cr6.eq) goto loc_82C9306C;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// beq cr6,0x82c93070
	if (cr6.eq) goto loc_82C93070;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C9306C:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C93070:
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c930e0
	if (!cr6.eq) goto loc_82C930E0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,77
	cr6.compare<int32_t>(ctx.r10.s32, 77, xer);
	// beq cr6,0x82c930a0
	if (cr6.eq) goto loc_82C930A0;
	// cmpwi cr6,r10,109
	cr6.compare<int32_t>(ctx.r10.s32, 109, xer);
	// beq cr6,0x82c930a4
	if (cr6.eq) goto loc_82C930A4;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C930A0:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C930A4:
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c930e0
	if (!cr6.eq) goto loc_82C930E0;
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,76
	cr6.compare<int32_t>(r11.s32, 76, xer);
	// beq cr6,0x82c930d0
	if (cr6.eq) goto loc_82C930D0;
	// cmpwi cr6,r11,108
	cr6.compare<int32_t>(r11.s32, 108, xer);
	// bne cr6,0x82c930e0
	if (!cr6.eq) goto loc_82C930E0;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x82c930d8
	if (cr6.eq) goto loc_82C930D8;
loc_82C930D0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C930D8:
	// li r11,12
	r11.s64 = 12;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
loc_82C930E0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C93028) {
	__imp__sub_82C93028(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C930E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r31,r10
	r31.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x82c9311c
	if (!cr6.eq) goto loc_82C9311C;
loc_82C93110:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C9311C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82c93138
	if (!cr6.eq) goto loc_82C93138;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c93144
	goto loc_82C93144;
loc_82C93138:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C93144:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c93534
	if (cr6.gt) goto loc_82C93534;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,12660
	r12.s64 = r12.s64 + 12660;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C934F8;
	case 1:
		goto loc_82C93510;
	case 2:
		goto loc_82C93528;
	case 3:
		goto loc_82C93534;
	case 4:
		goto loc_82C93534;
	case 5:
		goto loc_82C93534;
	case 6:
		goto loc_82C93534;
	case 7:
		goto loc_82C93534;
	case 8:
		goto loc_82C93534;
	case 9:
		goto loc_82C93534;
	case 10:
		goto loc_82C93534;
	case 11:
		goto loc_82C93534;
	case 12:
		goto loc_82C93534;
	case 13:
		goto loc_82C93534;
	case 14:
		goto loc_82C93534;
	case 15:
		goto loc_82C93534;
	case 16:
		goto loc_82C93534;
	case 17:
		goto loc_82C93210;
	case 18:
		goto loc_82C93534;
	case 19:
		goto loc_82C93210;
	case 20:
		goto loc_82C93534;
	case 21:
		goto loc_82C93534;
	case 22:
		goto loc_82C93534;
	case 23:
		goto loc_82C93534;
	case 24:
		goto loc_82C931D8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,13560(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13560);
	// lwz r22,13584(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13584);
	// lwz r22,13608(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13608);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,12816(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12816);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,12816(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12816);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,12760(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12760);
loc_82C931D8:
	// clrlwi r4,r7,24
	ctx.r4.u64 = ctx.r7.u32 & 0xFF;
	// lbz r5,1(r10)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r5,27,5,31
	ctx.r9.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r3,r5,27
	ctx.r3.u64 = ctx.r5.u32 & 0x1F;
	// slw r7,r6,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r5,r4,r11
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r4.u32 + r11.u32);
	// rotlwi r11,r5,3
	r11.u64 = rotl32(ctx.r5.u32, 3);
	// add r4,r11,r9
	ctx.r4.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r3,r4,2,0,29
	ctx.r3.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r3,r8
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r8.u32);
	// and r9,r11,r7
	ctx.r9.u64 = r11.u64 & ctx.r7.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c93534
	if (cr6.eq) goto loc_82C93534;
loc_82C93210:
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r5,r30
	cr6.compare<uint32_t>(ctx.r5.u32, r30.u32, xer);
	// beq cr6,0x82c93110
	if (cr6.eq) goto loc_82C93110;
loc_82C9321C:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c93238
	if (!cr6.eq) goto loc_82C93238;
	// lbz r11,1(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c93244
	goto loc_82C93244;
loc_82C93238:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C93244:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c9331c
	if (cr6.gt) goto loc_82C9331C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,12904
	r12.s64 = r12.s64 + 12904;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C9332C;
	case 1:
		goto loc_82C93344;
	case 2:
		goto loc_82C9335C;
	case 3:
		goto loc_82C9331C;
	case 4:
		goto loc_82C93374;
	case 5:
		goto loc_82C93374;
	case 6:
		goto loc_82C9331C;
	case 7:
		goto loc_82C9331C;
	case 8:
		goto loc_82C9331C;
	case 9:
		goto loc_82C9331C;
	case 10:
		goto loc_82C934A8;
	case 11:
		goto loc_82C9331C;
	case 12:
		goto loc_82C9331C;
	case 13:
		goto loc_82C9331C;
	case 14:
		goto loc_82C9331C;
	case 15:
		goto loc_82C9331C;
	case 16:
		goto loc_82C93374;
	case 17:
		goto loc_82C93304;
	case 18:
		goto loc_82C9331C;
	case 19:
		goto loc_82C93304;
	case 20:
		goto loc_82C93304;
	case 21:
		goto loc_82C93304;
	case 22:
		goto loc_82C93304;
	case 23:
		goto loc_82C9331C;
	case 24:
		goto loc_82C932CC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,13100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13100);
	// lwz r22,13124(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13124);
	// lwz r22,13148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13148);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13172(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13172);
	// lwz r22,13172(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13172);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13480(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13480);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13172(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13172);
	// lwz r22,13060(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13060(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13060(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13060(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13060(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13004(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13004);
loc_82C932CC:
	// clrlwi r11,r10,24
	r11.u64 = ctx.r10.u32 & 0xFF;
	// lbz r9,1(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r10,r9,27,5,31
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r4,r9,27
	ctx.r4.u64 = ctx.r9.u32 & 0x1F;
	// slw r3,r6,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	r11.u64 = PPC_LOAD_U8(r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r3
	ctx.r4.u64 = ctx.r7.u64 & ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82c9331c
	if (cr6.eq) goto loc_82C9331C;
loc_82C93304:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	cr6.compare<uint32_t>(ctx.r5.u32, r30.u32, xer);
	// bne cr6,0x82c9321c
	if (!cr6.eq) goto loc_82C9321C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C9331C:
	// stw r5,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r5.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C9332C:
	// subf r11,r5,r30
	r11.s64 = r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c9331c
	if (!cr6.lt) goto loc_82C9331C;
loc_82C93338:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C93344:
	// subf r11,r5,r30
	r11.s64 = r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c9331c
	if (!cr6.lt) goto loc_82C9331C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C9335C:
	// subf r11,r5,r30
	r11.s64 = r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c9331c
	if (!cr6.lt) goto loc_82C9331C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C93374:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c93028
	sub_82C93028(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c9331c
	if (cr6.eq) goto loc_82C9331C;
	// addi r10,r5,2
	ctx.r10.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// beq cr6,0x82c93110
	if (cr6.eq) goto loc_82C93110;
	// subf r9,r10,r30
	ctx.r9.s64 = r30.s64 - ctx.r10.s64;
loc_82C9339C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c933b8
	if (!cr6.eq) goto loc_82C933B8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c933c0
	goto loc_82C933C0;
loc_82C933B8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C933C0:
	// cmplwi cr6,r3,15
	cr6.compare<uint32_t>(ctx.r3.u32, 15, xer);
	// bgt cr6,0x82c93428
	if (cr6.gt) goto loc_82C93428;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,13280
	r12.s64 = r12.s64 + 13280;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C93534;
	case 1:
		goto loc_82C93534;
	case 2:
		goto loc_82C93428;
	case 3:
		goto loc_82C93428;
	case 4:
		goto loc_82C93428;
	case 5:
		goto loc_82C93420;
	case 6:
		goto loc_82C93444;
	case 7:
		goto loc_82C93458;
	case 8:
		goto loc_82C93534;
	case 9:
		goto loc_82C93428;
	case 10:
		goto loc_82C93428;
	case 11:
		goto loc_82C93428;
	case 12:
		goto loc_82C93428;
	case 13:
		goto loc_82C93428;
	case 14:
		goto loc_82C93428;
	case 15:
		goto loc_82C9346C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13344(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13344);
	// lwz r22,13380(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13380);
	// lwz r22,13400(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13400);
	// lwz r22,13620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13420(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13420);
loc_82C93420:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// blt cr6,0x82c93338
	if (cr6.lt) goto loc_82C93338;
loc_82C93428:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C93430:
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x82c9339c
	if (!cr6.eq) goto loc_82C9339C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C93444:
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// blt cr6,0x82c93338
	if (cr6.lt) goto loc_82C93338;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c93430
	goto loc_82C93430;
loc_82C93458:
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c93338
	if (cr6.lt) goto loc_82C93338;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c93430
	goto loc_82C93430;
loc_82C9346C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// beq cr6,0x82c93110
	if (cr6.eq) goto loc_82C93110;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c93430
	if (!cr6.eq) goto loc_82C93430;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// bne cr6,0x82c93430
	if (!cr6.eq) goto loc_82C93430;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C934A8:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c93028
	sub_82C93028(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c9331c
	if (cr6.eq) goto loc_82C9331C;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	cr6.compare<uint32_t>(ctx.r5.u32, r30.u32, xer);
	// beq cr6,0x82c93110
	if (cr6.eq) goto loc_82C93110;
	// lbz r11,0(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c9331c
	if (!cr6.eq) goto loc_82C9331C;
	// lbz r11,1(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// bne cr6,0x82c9331c
	if (!cr6.eq) goto loc_82C9331C;
	// addi r11,r5,2
	r11.s64 = ctx.r5.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C934F8:
	// subf r11,r10,r30
	r11.s64 = r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c93534
	if (!cr6.lt) goto loc_82C93534;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C93510:
	// subf r11,r10,r30
	r11.s64 = r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c93534
	if (!cr6.lt) goto loc_82C93534;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
loc_82C93528:
	// subf r11,r10,r30
	r11.s64 = r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c93338
	if (cr6.lt) goto loc_82C93338;
loc_82C93534:
	// stw r10,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	return;
}

PPC_WEAK_FUNC(sub_82C930E8) {
	__imp__sub_82C930E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C93548) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c93578
	if (!cr6.eq) goto loc_82C93578;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C93578:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c935ac
	if (cr6.eq) goto loc_82C935AC;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c935a8
	if (!cr6.eq) goto loc_82C935A8;
loc_82C93594:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C935A8:
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
loc_82C935AC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c935c8
	if (!cr6.eq) goto loc_82C935C8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c935d0
	goto loc_82C935D0;
loc_82C935C8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C935D0:
	// cmplwi cr6,r3,10
	cr6.compare<uint32_t>(ctx.r3.u32, 10, xer);
	// bgt cr6,0x82c93758
	if (cr6.gt) goto loc_82C93758;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,13808
	r12.s64 = r12.s64 + 13808;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C93740;
	case 1:
		goto loc_82C93740;
	case 2:
		goto loc_82C93758;
	case 3:
		goto loc_82C93758;
	case 4:
		goto loc_82C9361C;
	case 5:
		goto loc_82C936F8;
	case 6:
		goto loc_82C93718;
	case 7:
		goto loc_82C9372C;
	case 8:
		goto loc_82C93740;
	case 9:
		goto loc_82C93688;
	case 10:
		goto loc_82C936DC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14144(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14144);
	// lwz r22,14144(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14144);
	// lwz r22,14168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14168);
	// lwz r22,14168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14168);
	// lwz r22,13852(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13852);
	// lwz r22,14072(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14072);
	// lwz r22,14104(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14104);
	// lwz r22,14124(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14124);
	// lwz r22,14144(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14144);
	// lwz r22,13960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13960);
	// lwz r22,14044(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14044);
loc_82C9361C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c93594
	if (cr6.eq) goto loc_82C93594;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c9375c
	if (!cr6.eq) goto loc_82C9375C;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c9375c
	if (!cr6.eq) goto loc_82C9375C;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c93594
	if (cr6.eq) goto loc_82C93594;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c93680
	if (!cr6.eq) goto loc_82C93680;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c93680
	if (!cr6.eq) goto loc_82C93680;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// li r3,40
	ctx.r3.s64 = 40;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C93680:
	// addi r10,r11,-2
	ctx.r10.s64 = r11.s64 + -2;
	// b 0x82c9375c
	goto loc_82C9375C;
loc_82C93688:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c93594
	if (cr6.eq) goto loc_82C93594;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c936b0
	if (!cr6.eq) goto loc_82C936B0;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c936b8
	goto loc_82C936B8;
loc_82C936B0:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C936B8:
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bne cr6,0x82c936c4
	if (!cr6.eq) goto loc_82C936C4;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C936C4:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C936DC:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C936F8:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c93758
	if (!cr6.lt) goto loc_82C93758;
loc_82C93704:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C93718:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c93704
	if (cr6.lt) goto loc_82C93704;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c9375c
	goto loc_82C9375C;
loc_82C9372C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c93704
	if (cr6.lt) goto loc_82C93704;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c9375c
	goto loc_82C9375C;
loc_82C93740:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C93758:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C9375C:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c937f0
	if (cr6.eq) goto loc_82C937F0;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C93768:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c93784
	if (!cr6.eq) goto loc_82C93784;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c9378c
	goto loc_82C9378C;
loc_82C93784:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C9378C:
	// cmplwi cr6,r3,10
	cr6.compare<uint32_t>(ctx.r3.u32, 10, xer);
	// bgt cr6,0x82c937e0
	if (cr6.gt) goto loc_82C937E0;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,14252
	r12.s64 = r12.s64 + 14252;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C937F0;
	case 1:
		goto loc_82C937F0;
	case 2:
		goto loc_82C937E0;
	case 3:
		goto loc_82C937E0;
	case 4:
		goto loc_82C937F0;
	case 5:
		goto loc_82C937D8;
	case 6:
		goto loc_82C93808;
	case 7:
		goto loc_82C9381C;
	case 8:
		goto loc_82C937F0;
	case 9:
		goto loc_82C937F0;
	case 10:
		goto loc_82C937F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14320(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14320(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14304);
	// lwz r22,14304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14304);
	// lwz r22,14320(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14296(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14296);
	// lwz r22,14344(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14344);
	// lwz r22,14364(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14364);
	// lwz r22,14320(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14320(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14320(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
loc_82C937D8:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// blt cr6,0x82c937f0
	if (cr6.lt) goto loc_82C937F0;
loc_82C937E0:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C937E8:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c93768
	if (!cr6.eq) goto loc_82C93768;
loc_82C937F0:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C93808:
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// blt cr6,0x82c937f0
	if (cr6.lt) goto loc_82C937F0;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c937e8
	goto loc_82C937E8;
loc_82C9381C:
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c937f0
	if (cr6.lt) goto loc_82C937F0;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c937e8
	goto loc_82C937E8;
}

PPC_WEAK_FUNC(sub_82C93548) {
	__imp__sub_82C93548(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C93830) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c9385c
	if (!cr6.eq) goto loc_82C9385C;
loc_82C93854:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C9385C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82c93878
	if (!cr6.eq) goto loc_82C93878;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c93884
	goto loc_82C93884;
loc_82C93878:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C93884:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c93b40
	if (cr6.gt) goto loc_82C93B40;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,14516
	r12.s64 = r12.s64 + 14516;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C93A58;
	case 1:
		goto loc_82C93A6C;
	case 2:
		goto loc_82C93B2C;
	case 3:
		goto loc_82C93B40;
	case 4:
		goto loc_82C93B40;
	case 5:
		goto loc_82C93B40;
	case 6:
		goto loc_82C93B40;
	case 7:
		goto loc_82C93B40;
	case 8:
		goto loc_82C93B40;
	case 9:
		goto loc_82C93B40;
	case 10:
		goto loc_82C93B40;
	case 11:
		goto loc_82C93B40;
	case 12:
		goto loc_82C93B40;
	case 13:
		goto loc_82C93B40;
	case 14:
		goto loc_82C93B40;
	case 15:
		goto loc_82C93B40;
	case 16:
		goto loc_82C93B40;
	case 17:
		goto loc_82C93950;
	case 18:
		goto loc_82C93B40;
	case 19:
		goto loc_82C93950;
	case 20:
		goto loc_82C93B40;
	case 21:
		goto loc_82C93B40;
	case 22:
		goto loc_82C93B40;
	case 23:
		goto loc_82C93B40;
	case 24:
		goto loc_82C93918;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14936);
	// lwz r22,14956(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14956);
	// lwz r22,15148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15148);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14672(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14672);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14672(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14672);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14616(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14616);
loc_82C93918:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + r11.u32);
	// rotlwi r11,r3,3
	r11.u64 = rotl32(ctx.r3.u32, 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82c93b40
	if (cr6.eq) goto loc_82C93B40;
loc_82C93950:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c93854
	if (cr6.eq) goto loc_82C93854;
loc_82C9395C:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c93978
	if (!cr6.eq) goto loc_82C93978;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c93984
	goto loc_82C93984;
loc_82C93978:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C93984:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c93b40
	if (cr6.gt) goto loc_82C93B40;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,14760
	r12.s64 = r12.s64 + 14760;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C93A58;
	case 1:
		goto loc_82C93A6C;
	case 2:
		goto loc_82C93B2C;
	case 3:
		goto loc_82C93B40;
	case 4:
		goto loc_82C93A80;
	case 5:
		goto loc_82C93A80;
	case 6:
		goto loc_82C93B1C;
	case 7:
		goto loc_82C93B40;
	case 8:
		goto loc_82C93B40;
	case 9:
		goto loc_82C93B40;
	case 10:
		goto loc_82C93B40;
	case 11:
		goto loc_82C93B40;
	case 12:
		goto loc_82C93B40;
	case 13:
		goto loc_82C93B40;
	case 14:
		goto loc_82C93B40;
	case 15:
		goto loc_82C93B40;
	case 16:
		goto loc_82C93A80;
	case 17:
		goto loc_82C93A44;
	case 18:
		goto loc_82C93A44;
	case 19:
		goto loc_82C93A44;
	case 20:
		goto loc_82C93A44;
	case 21:
		goto loc_82C93A44;
	case 22:
		goto loc_82C93A44;
	case 23:
		goto loc_82C93B40;
	case 24:
		goto loc_82C93A0C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14936);
	// lwz r22,14956(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14956);
	// lwz r22,15148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15148);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14976);
	// lwz r22,14976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14976);
	// lwz r22,15132(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15132);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14976);
	// lwz r22,14916(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14860(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14860);
loc_82C93A0C:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	r11.u64 = rotl32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82c93b40
	if (cr6.eq) goto loc_82C93B40;
loc_82C93A44:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c9395c
	if (!cr6.eq) goto loc_82C9395C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93A58:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c93b40
	if (!cr6.lt) goto loc_82C93B40;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93A6C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c93b40
	if (!cr6.lt) goto loc_82C93B40;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93A80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c93854
	if (cr6.eq) goto loc_82C93854;
loc_82C93A8C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c93aa8
	if (!cr6.eq) goto loc_82C93AA8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c93ab0
	goto loc_82C93AB0;
loc_82C93AA8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C93AB0:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// bgt cr6,0x82c93b40
	if (cr6.gt) goto loc_82C93B40;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,15060
	r12.s64 = r12.s64 + 15060;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C93B08;
	case 1:
		goto loc_82C93B08;
	case 2:
		goto loc_82C93B1C;
	case 3:
		goto loc_82C93B40;
	case 4:
		goto loc_82C93B40;
	case 5:
		goto loc_82C93B40;
	case 6:
		goto loc_82C93B40;
	case 7:
		goto loc_82C93B40;
	case 8:
		goto loc_82C93B40;
	case 9:
		goto loc_82C93B40;
	case 10:
		goto loc_82C93B40;
	case 11:
		goto loc_82C93B40;
	case 12:
		goto loc_82C93B08;
	default:
		__builtin_unreachable();
	}
	// lwz r22,15112(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15112);
	// lwz r22,15112(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15112);
	// lwz r22,15132(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15132);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15112(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15112);
loc_82C93B08:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c93a8c
	if (!cr6.eq) goto loc_82C93A8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93B1C:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,5
	ctx.r3.s64 = 5;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93B2C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c93b40
	if (!cr6.lt) goto loc_82C93B40;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93B40:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C93B48:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C93830) {
	__imp__sub_82C93830(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C93B60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c93c04
	if (cr6.eq) goto loc_82C93C04;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c93b98
	if (!cr6.eq) goto loc_82C93B98;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c93ba0
	goto loc_82C93BA0;
loc_82C93B98:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C93BA0:
	// cmpwi cr6,r3,24
	cr6.compare<int32_t>(ctx.r3.s32, 24, xer);
	// blt cr6,0x82c93c34
	if (cr6.lt) goto loc_82C93C34;
	// cmpwi cr6,r3,25
	cr6.compare<int32_t>(ctx.r3.s32, 25, xer);
	// bgt cr6,0x82c93c34
	if (cr6.gt) goto loc_82C93C34;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c93c04
	if (cr6.eq) goto loc_82C93C04;
loc_82C93BBC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c93bd8
	if (!cr6.eq) goto loc_82C93BD8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c93be0
	goto loc_82C93BE0;
loc_82C93BD8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C93BE0:
	// cmpwi cr6,r3,18
	cr6.compare<int32_t>(ctx.r3.s32, 18, xer);
	// beq cr6,0x82c93c18
	if (cr6.eq) goto loc_82C93C18;
	// cmpwi cr6,r3,23
	cr6.compare<int32_t>(ctx.r3.s32, 23, xer);
	// ble cr6,0x82c93c34
	if (!cr6.gt) goto loc_82C93C34;
	// cmpwi cr6,r3,25
	cr6.compare<int32_t>(ctx.r3.s32, 25, xer);
	// bgt cr6,0x82c93c34
	if (cr6.gt) goto loc_82C93C34;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c93bbc
	if (!cr6.eq) goto loc_82C93BBC;
loc_82C93C04:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C93C18:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C93C34:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C93B60) {
	__imp__sub_82C93B60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C93C50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c93d30
	if (cr6.eq) goto loc_82C93D30;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// extsb r11,r3
	r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c93cbc
	if (!cr6.eq) goto loc_82C93CBC;
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r8,120
	cr6.compare<uint32_t>(ctx.r8.u32, 120, xer);
	// bne cr6,0x82c93ca4
	if (!cr6.eq) goto loc_82C93CA4;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c93b60
	sub_82C93B60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C93CA4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c93cbc
	if (!cr6.eq) goto loc_82C93CBC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c93cc4
	goto loc_82C93CC4;
loc_82C93CBC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C93CC4:
	// cmpwi cr6,r3,25
	cr6.compare<int32_t>(ctx.r3.s32, 25, xer);
	// beq cr6,0x82c93ce4
	if (cr6.eq) goto loc_82C93CE4;
loc_82C93CCC:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C93CE4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c93d30
	if (cr6.eq) goto loc_82C93D30;
loc_82C93CF0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c93d0c
	if (!cr6.eq) goto loc_82C93D0C;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c93d14
	goto loc_82C93D14;
loc_82C93D0C:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C93D14:
	// cmpwi cr6,r3,18
	cr6.compare<int32_t>(ctx.r3.s32, 18, xer);
	// beq cr6,0x82c93d44
	if (cr6.eq) goto loc_82C93D44;
	// cmpwi cr6,r3,25
	cr6.compare<int32_t>(ctx.r3.s32, 25, xer);
	// bne cr6,0x82c93ccc
	if (!cr6.eq) goto loc_82C93CCC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c93cf0
	if (!cr6.eq) goto loc_82C93CF0;
loc_82C93D30:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C93D44:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C93C50) {
	__imp__sub_82C93C50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C93D60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c93d8c
	if (!cr6.eq) goto loc_82C93D8C;
loc_82C93D84:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93D8C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82c93da8
	if (!cr6.eq) goto loc_82C93DA8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c93db4
	goto loc_82C93DB4;
loc_82C93DA8:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C93DB4:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c93fe4
	if (cr6.gt) goto loc_82C93FE4;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,15844
	r12.s64 = r12.s64 + 15844;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C93F88;
	case 1:
		goto loc_82C93F9C;
	case 2:
		goto loc_82C93FB0;
	case 3:
		goto loc_82C93FE4;
	case 4:
		goto loc_82C93FE4;
	case 5:
		goto loc_82C93FE4;
	case 6:
		goto loc_82C93FE4;
	case 7:
		goto loc_82C93FE4;
	case 8:
		goto loc_82C93FE4;
	case 9:
		goto loc_82C93FE4;
	case 10:
		goto loc_82C93FE4;
	case 11:
		goto loc_82C93FE4;
	case 12:
		goto loc_82C93FE4;
	case 13:
		goto loc_82C93FE4;
	case 14:
		goto loc_82C93FD4;
	case 15:
		goto loc_82C93FE4;
	case 16:
		goto loc_82C93FE4;
	case 17:
		goto loc_82C93E80;
	case 18:
		goto loc_82C93FE4;
	case 19:
		goto loc_82C93E80;
	case 20:
		goto loc_82C93FE4;
	case 21:
		goto loc_82C93FE4;
	case 22:
		goto loc_82C93FE4;
	case 23:
		goto loc_82C93FE4;
	case 24:
		goto loc_82C93E48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,16264(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16264);
	// lwz r22,16284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16284);
	// lwz r22,16304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16304);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16340(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16340);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16000);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16000);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,15944(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15944);
loc_82C93E48:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + r11.u32);
	// rotlwi r11,r3,3
	r11.u64 = rotl32(ctx.r3.u32, 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82c93fe4
	if (cr6.eq) goto loc_82C93FE4;
loc_82C93E80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c93d84
	if (cr6.eq) goto loc_82C93D84;
loc_82C93E8C:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c93ea8
	if (!cr6.eq) goto loc_82C93EA8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c93eb4
	goto loc_82C93EB4;
loc_82C93EA8:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C93EB4:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c93fe4
	if (cr6.gt) goto loc_82C93FE4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,16088
	r12.s64 = r12.s64 + 16088;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C93F88;
	case 1:
		goto loc_82C93F9C;
	case 2:
		goto loc_82C93FB0;
	case 3:
		goto loc_82C93FE4;
	case 4:
		goto loc_82C93FE4;
	case 5:
		goto loc_82C93FE4;
	case 6:
		goto loc_82C93FE4;
	case 7:
		goto loc_82C93FE4;
	case 8:
		goto loc_82C93FE4;
	case 9:
		goto loc_82C93FE4;
	case 10:
		goto loc_82C93FE4;
	case 11:
		goto loc_82C93FE4;
	case 12:
		goto loc_82C93FE4;
	case 13:
		goto loc_82C93FC4;
	case 14:
		goto loc_82C93FE4;
	case 15:
		goto loc_82C93FE4;
	case 16:
		goto loc_82C93FE4;
	case 17:
		goto loc_82C93F74;
	case 18:
		goto loc_82C93FE4;
	case 19:
		goto loc_82C93F74;
	case 20:
		goto loc_82C93F74;
	case 21:
		goto loc_82C93F74;
	case 22:
		goto loc_82C93F74;
	case 23:
		goto loc_82C93FE4;
	case 24:
		goto loc_82C93F3C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,16264(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16264);
	// lwz r22,16284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16284);
	// lwz r22,16304(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16304);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16324(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16324);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16244(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16244(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16244(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16244(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16244(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16356(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16188(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16188);
loc_82C93F3C:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	r11.u64 = rotl32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82c93fe4
	if (cr6.eq) goto loc_82C93FE4;
loc_82C93F74:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c93e8c
	if (!cr6.eq) goto loc_82C93E8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93F88:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c93fe4
	if (!cr6.lt) goto loc_82C93FE4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93F9C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c93fe4
	if (!cr6.lt) goto loc_82C93FE4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FB0:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c93fe4
	if (!cr6.lt) goto loc_82C93FE4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FC4:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,9
	ctx.r3.s64 = 9;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FD4:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c93c50
	sub_82C93C50(ctx, base);
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FE4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C93FEC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C93D60) {
	__imp__sub_82C93D60(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C94008) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// li r28,0
	r28.s64 = 0;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94544
	if (cr6.eq) goto loc_82C94544;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// li r27,1
	r27.s64 = 1;
	// addi r29,r11,-4144
	r29.s64 = r11.s64 + -4144;
loc_82C94038:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c94054
	if (!cr6.eq) goto loc_82C94054;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c94060
	goto loc_82C94060;
loc_82C94054:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C94060:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c94268
	if (cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,16516
	r12.s64 = r12.s64 + 16516;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C94550;
	case 1:
		goto loc_82C94568;
	case 2:
		goto loc_82C94580;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94218;
	case 5:
		goto loc_82C94218;
	case 6:
		goto loc_82C94268;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94268;
	case 9:
		goto loc_82C94278;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94268;
	case 13:
		goto loc_82C94268;
	case 14:
		goto loc_82C94268;
	case 15:
		goto loc_82C94268;
	case 16:
		goto loc_82C94218;
	case 17:
		goto loc_82C94538;
	case 18:
		goto loc_82C9411C;
	case 19:
		goto loc_82C94538;
	case 20:
		goto loc_82C94538;
	case 21:
		goto loc_82C94538;
	case 22:
		goto loc_82C94538;
	case 23:
		goto loc_82C94268;
	case 24:
		goto loc_82C940E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17744(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17744);
	// lwz r22,17768(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17768);
	// lwz r22,17792(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17792);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16920(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16920);
	// lwz r22,16920(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16920);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17016(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17016);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16920(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16920);
	// lwz r22,17720(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,16668(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16668);
	// lwz r22,17720(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17720(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17720(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17720(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16616(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16616);
loc_82C940E8:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r7,r29,1536
	ctx.r7.s64 = r29.s64 + 1536;
	// rlwinm r9,r8,27,5,31
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r8,27
	ctx.r6.u64 = ctx.r8.u32 & 0x1F;
	// slw r4,r27,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (r27.u32 << (ctx.r6.u8 & 0x3F));
	// lbzx r3,r11,r7
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + ctx.r7.u32);
	// rotlwi r11,r3,3
	r11.u64 = rotl32(ctx.r3.u32, 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// and r7,r8,r4
	ctx.r7.u64 = ctx.r8.u64 & ctx.r4.u64;
	// b 0x82c94530
	goto loc_82C94530;
loc_82C9411C:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x82c94268
	if (!cr6.eq) goto loc_82C94268;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r28,r27
	r28.u64 = r27.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94544
	if (cr6.eq) goto loc_82C94544;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c94150
	if (!cr6.eq) goto loc_82C94150;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c9415c
	goto loc_82C9415C;
loc_82C94150:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C9415C:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c94268
	if (cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,16768
	r12.s64 = r12.s64 + 16768;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C94550;
	case 1:
		goto loc_82C94568;
	case 2:
		goto loc_82C94580;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94268;
	case 5:
		goto loc_82C94268;
	case 6:
		goto loc_82C94268;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94268;
	case 9:
		goto loc_82C94268;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94268;
	case 13:
		goto loc_82C94268;
	case 14:
		goto loc_82C94268;
	case 15:
		goto loc_82C94268;
	case 16:
		goto loc_82C94268;
	case 17:
		goto loc_82C94538;
	case 18:
		goto loc_82C94268;
	case 19:
		goto loc_82C94538;
	case 20:
		goto loc_82C94268;
	case 21:
		goto loc_82C94268;
	case 22:
		goto loc_82C94268;
	case 23:
		goto loc_82C94268;
	case 24:
		goto loc_82C941E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17744(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17744);
	// lwz r22,17768(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17768);
	// lwz r22,17792(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17792);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17720(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17720(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16868(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16868);
loc_82C941E4:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r7,r29,1280
	ctx.r7.s64 = r29.s64 + 1280;
	// rlwinm r9,r8,27,5,31
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r8,27
	ctx.r6.u64 = ctx.r8.u32 & 0x1F;
	// slw r4,r27,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (r27.u32 << (ctx.r6.u8 & 0x3F));
	// lbzx r3,r11,r7
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + ctx.r7.u32);
	// rotlwi r11,r3,3
	r11.u64 = rotl32(ctx.r3.u32, 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// and r7,r8,r4
	ctx.r7.u64 = ctx.r8.u64 & ctx.r4.u64;
	// b 0x82c94530
	goto loc_82C94530;
loc_82C94218:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94544
	if (cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c94240
	if (!cr6.eq) goto loc_82C94240;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c94248
	goto loc_82C94248;
loc_82C94240:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C94248:
	// cmpwi cr6,r3,14
	cr6.compare<int32_t>(ctx.r3.s32, 14, xer);
	// beq cr6,0x82c94278
	if (cr6.eq) goto loc_82C94278;
	// cmpwi cr6,r3,9
	cr6.compare<int32_t>(ctx.r3.s32, 9, xer);
	// blt cr6,0x82c94268
	if (cr6.lt) goto loc_82C94268;
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// ble cr6,0x82c94218
	if (!cr6.gt) goto loc_82C94218;
	// cmpwi cr6,r3,21
	cr6.compare<int32_t>(ctx.r3.s32, 21, xer);
	// beq cr6,0x82c94218
	if (cr6.eq) goto loc_82C94218;
loc_82C94268:
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C94278:
	// li r28,0
	r28.s64 = 0;
loc_82C9427C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94544
	if (cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c942a4
	if (!cr6.eq) goto loc_82C942A4;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r31,76(r11)
	r31.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c942b0
	goto loc_82C942B0;
loc_82C942A4:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_82C942B0:
	// cmpwi cr6,r31,12
	cr6.compare<int32_t>(r31.s32, 12, xer);
	// beq cr6,0x82c942e8
	if (cr6.eq) goto loc_82C942E8;
	// cmpwi cr6,r31,13
	cr6.compare<int32_t>(r31.s32, 13, xer);
	// beq cr6,0x82c942e8
	if (cr6.eq) goto loc_82C942E8;
	// cmpwi cr6,r31,9
	cr6.compare<int32_t>(r31.s32, 9, xer);
	// blt cr6,0x82c94268
	if (cr6.lt) goto loc_82C94268;
	// cmpwi cr6,r31,10
	cr6.compare<int32_t>(r31.s32, 10, xer);
	// ble cr6,0x82c9427c
	if (!cr6.gt) goto loc_82C9427C;
	// cmpwi cr6,r31,21
	cr6.compare<int32_t>(r31.s32, 21, xer);
	// beq cr6,0x82c9427c
	if (cr6.eq) goto loc_82C9427C;
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C942E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C942EC:
	// stw r10,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r10.u32);
loc_82C942F0:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94544
	if (cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c94314
	if (!cr6.eq) goto loc_82C94314;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c9431c
	goto loc_82C9431C;
loc_82C94314:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C9431C:
	// cmpw cr6,r3,r31
	cr6.compare<int32_t>(ctx.r3.s32, r31.s32, xer);
	// beq cr6,0x82c943c0
	if (cr6.eq) goto loc_82C943C0;
	// cmplwi cr6,r3,8
	cr6.compare<uint32_t>(ctx.r3.u32, 8, xer);
	// bgt cr6,0x82c942e8
	if (cr6.gt) goto loc_82C942E8;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,17220
	r12.s64 = r12.s64 + 17220;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C94268;
	case 1:
		goto loc_82C94268;
	case 2:
		goto loc_82C94268;
	case 3:
		goto loc_82C943A0;
	case 4:
		goto loc_82C942E8;
	case 5:
		goto loc_82C94368;
	case 6:
		goto loc_82C94378;
	case 7:
		goto loc_82C9438C;
	case 8:
		goto loc_82C94268;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17312);
	// lwz r22,17128(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17128);
	// lwz r22,17256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17256);
	// lwz r22,17272(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17272);
	// lwz r22,17292(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17292);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
loc_82C94368:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// blt cr6,0x82c9455c
	if (cr6.lt) goto loc_82C9455C;
	// b 0x82c942e8
	goto loc_82C942E8;
loc_82C94378:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c9455c
	if (cr6.lt) goto loc_82C9455C;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c942ec
	goto loc_82C942EC;
loc_82C9438C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c9455c
	if (cr6.lt) goto loc_82C9455C;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c942ec
	goto loc_82C942EC;
loc_82C943A0:
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c93d60
	sub_82C93D60(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x82c945f4
	if (!cr6.gt) goto loc_82C945F4;
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// b 0x82c942f0
	goto loc_82C942F0;
loc_82C943C0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94544
	if (cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c943e8
	if (!cr6.eq) goto loc_82C943E8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c943f0
	goto loc_82C943F0;
loc_82C943E8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C943F0:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// bgt cr6,0x82c94268
	if (cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,17428
	r12.s64 = r12.s64 + 17428;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C94448;
	case 1:
		goto loc_82C94448;
	case 2:
		goto loc_82C945E0;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94268;
	case 5:
		goto loc_82C94268;
	case 6:
		goto loc_82C94268;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94598;
	case 9:
		goto loc_82C94268;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94448;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17480(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17480(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17888(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17888);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17816(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17816);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17480(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
loc_82C94448:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94544
	if (cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c94470
	if (!cr6.eq) goto loc_82C94470;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c94478
	goto loc_82C94478;
loc_82C94470:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C94478:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c94268
	if (cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,17564
	r12.s64 = r12.s64 + 17564;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C94550;
	case 1:
		goto loc_82C94568;
	case 2:
		goto loc_82C94580;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94448;
	case 5:
		goto loc_82C94448;
	case 6:
		goto loc_82C945E0;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94268;
	case 9:
		goto loc_82C94268;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94598;
	case 13:
		goto loc_82C94268;
	case 14:
		goto loc_82C94268;
	case 15:
		goto loc_82C94268;
	case 16:
		goto loc_82C94448;
	case 17:
		goto loc_82C94538;
	case 18:
		goto loc_82C94268;
	case 19:
		goto loc_82C94538;
	case 20:
		goto loc_82C94268;
	case 21:
		goto loc_82C94268;
	case 22:
		goto loc_82C94268;
	case 23:
		goto loc_82C94268;
	case 24:
		goto loc_82C94500;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17744(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17744);
	// lwz r22,17768(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17768);
	// lwz r22,17792(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17792);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17480(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17480(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17888(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17888);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17816(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17816);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17480(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17720(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17720(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17664(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17664);
loc_82C94500:
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r8,r29,1280
	ctx.r8.s64 = r29.s64 + 1280;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r7,27
	ctx.r6.u64 = ctx.r7.u32 & 0x1F;
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + ctx.r8.u32);
	// slw r3,r27,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (r27.u32 << (ctx.r6.u8 & 0x3F));
	// rotlwi r11,r4,3
	r11.u64 = rotl32(ctx.r4.u32, 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// and r7,r8,r3
	ctx.r7.u64 = ctx.r8.u64 & ctx.r3.u64;
loc_82C94530:
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82c94268
	if (cr6.eq) goto loc_82C94268;
loc_82C94538:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c94038
	if (!cr6.eq) goto loc_82C94038;
loc_82C94544:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82C94548:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C94550:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c94268
	if (!cr6.lt) goto loc_82C94268;
loc_82C9455C:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C94568:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c94268
	if (!cr6.lt) goto loc_82C94268;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C94580:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c94268
	if (!cr6.lt) goto loc_82C94268;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C94598:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94544
	if (cr6.eq) goto loc_82C94544;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c945d0
	if (!cr6.eq) goto loc_82C945D0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c945d0
	if (!cr6.eq) goto loc_82C945D0;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// li r3,3
	ctx.r3.s64 = 3;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C945D0:
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C945E0:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C945F4:
	// bne cr6,0x82c94548
	if (!cr6.eq) goto loc_82C94548;
	// lwz r11,172(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C94008) {
	__imp__sub_82C94008(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C94608) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c94634
	if (!cr6.eq) goto loc_82C94634;
loc_82C9462C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94634:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82c94650
	if (!cr6.eq) goto loc_82C94650;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c9465c
	goto loc_82C9465C;
loc_82C94650:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C9465C:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c94b74
	if (cr6.gt) goto loc_82C94B74;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	r31.s64 = 1;
	// addi r7,r9,-4144
	ctx.r7.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,18060
	r12.s64 = r12.s64 + 18060;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C94B74;
	case 5:
		goto loc_82C94B74;
	case 6:
		goto loc_82C94B74;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B54;
	case 11:
		goto loc_82C94AA0;
	case 12:
		goto loc_82C94B64;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C94B74;
	case 17:
		goto loc_82C94728;
	case 18:
		goto loc_82C94B74;
	case 19:
		goto loc_82C94728;
	case 20:
		goto loc_82C94B74;
	case 21:
		goto loc_82C94B74;
	case 22:
		goto loc_82C94B74;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C946F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19284);
	// lwz r22,19104(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19104);
	// lwz r22,19300(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19300);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18216(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18216);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18216(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18216);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18160(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18160);
loc_82C946F0:
	// clrlwi r3,r8,24
	ctx.r3.u64 = ctx.r8.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r9,r7,1280
	ctx.r9.s64 = ctx.r7.s64 + 1280;
	// rlwinm r11,r4,27,5,31
	r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r8,r4,27
	ctx.r8.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r8
	ctx.r4.u64 = ctx.r8.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r8.u8 & 0x3F));
	// lbzx r3,r3,r9
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r9.u32);
	// rotlwi r9,r3,3
	ctx.r9.u64 = rotl32(ctx.r3.u32, 3);
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// and r4,r8,r4
	ctx.r4.u64 = ctx.r8.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82c94b74
	if (cr6.eq) goto loc_82C94B74;
loc_82C94728:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9462c
	if (cr6.eq) goto loc_82C9462C;
loc_82C94738:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c94754
	if (!cr6.eq) goto loc_82C94754;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c94760
	goto loc_82C94760;
loc_82C94754:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C94760:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c94b74
	if (cr6.gt) goto loc_82C94B74;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,18308
	r12.s64 = r12.s64 + 18308;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C94940;
	case 5:
		goto loc_82C94940;
	case 6:
		goto loc_82C94A54;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B74;
	case 11:
		goto loc_82C94B74;
	case 12:
		goto loc_82C94A64;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C94940;
	case 17:
		goto loc_82C948F0;
	case 18:
		goto loc_82C947F0;
	case 19:
		goto loc_82C948F0;
	case 20:
		goto loc_82C948F0;
	case 21:
		goto loc_82C948F0;
	case 22:
		goto loc_82C948F0;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C947E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18752(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18752);
	// lwz r22,18752(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18752);
	// lwz r22,19028(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19028);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19044(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19044);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18752(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18752);
	// lwz r22,18672(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18416(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18416);
	// lwz r22,18672(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18672(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18672(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18672(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18408(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18408);
loc_82C947E8:
	// addi r3,r7,1536
	ctx.r3.s64 = ctx.r7.s64 + 1536;
	// b 0x82c948bc
	goto loc_82C948BC;
loc_82C947F0:
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x82c94b74
	if (!cr6.eq) goto loc_82C94B74;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9462c
	if (cr6.eq) goto loc_82C9462C;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c94824
	if (!cr6.eq) goto loc_82C94824;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c94830
	goto loc_82C94830;
loc_82C94824:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C94830:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c94b74
	if (cr6.gt) goto loc_82C94B74;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,18516
	r12.s64 = r12.s64 + 18516;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C94B74;
	case 5:
		goto loc_82C94B74;
	case 6:
		goto loc_82C94B74;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B74;
	case 11:
		goto loc_82C94B74;
	case 12:
		goto loc_82C94B74;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C94B74;
	case 17:
		goto loc_82C948F0;
	case 18:
		goto loc_82C94B74;
	case 19:
		goto loc_82C948F0;
	case 20:
		goto loc_82C94B74;
	case 21:
		goto loc_82C94B74;
	case 22:
		goto loc_82C94B74;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C948B8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18672(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18672(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18616(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18616);
loc_82C948B8:
	// addi r3,r7,1280
	ctx.r3.s64 = ctx.r7.s64 + 1280;
loc_82C948BC:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r3,r11,r3
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + ctx.r3.u32);
	// slw r4,r31,r4
	ctx.r4.u64 = ctx.r4.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r4.u8 & 0x3F));
	// rotlwi r11,r3,3
	r11.u64 = rotl32(ctx.r3.u32, 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r9,r7
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// and r11,r3,r4
	r11.u64 = ctx.r3.u64 & ctx.r4.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c94b74
	if (cr6.eq) goto loc_82C94B74;
loc_82C948F0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c94738
	if (!cr6.eq) goto loc_82C94738;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94904:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c94b74
	if (!cr6.lt) goto loc_82C94B74;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94918:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c94b74
	if (!cr6.lt) goto loc_82C94B74;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C9492C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c94b74
	if (!cr6.lt) goto loc_82C94B74;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94940:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9462c
	if (cr6.eq) goto loc_82C9462C;
loc_82C9494C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c94968
	if (!cr6.eq) goto loc_82C94968;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c94970
	goto loc_82C94970;
loc_82C94968:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C94970:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c94b74
	if (cr6.gt) goto loc_82C94B74;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,18836
	r12.s64 = r12.s64 + 18836;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C949F8;
	case 5:
		goto loc_82C949F8;
	case 6:
		goto loc_82C94A54;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B74;
	case 11:
		goto loc_82C94B74;
	case 12:
		goto loc_82C94A64;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C949F8;
	case 17:
		goto loc_82C94A44;
	case 18:
		goto loc_82C94B74;
	case 19:
		goto loc_82C94A44;
	case 20:
		goto loc_82C94B74;
	case 21:
		goto loc_82C94B74;
	case 22:
		goto loc_82C94B74;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C94A0C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18936);
	// lwz r22,18936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18936);
	// lwz r22,19028(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19028);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19044(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19044);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18936);
	// lwz r22,19012(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19012);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19012(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19012);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18956(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18956);
loc_82C949F8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c9494c
	if (!cr6.eq) goto loc_82C9494C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A0C:
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r8,r7,1280
	ctx.r8.s64 = ctx.r7.s64 + 1280;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r3,r4,27
	ctx.r3.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r11,r11,r8
	r11.u64 = PPC_LOAD_U8(r11.u32 + ctx.r8.u32);
	// slw r8,r31,r3
	ctx.r8.u64 = ctx.r3.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r3.u8 & 0x3F));
	// rotlwi r11,r11,3
	r11.u64 = rotl32(r11.u32, 3);
	// add r4,r11,r9
	ctx.r4.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r3,r4,2,0,29
	ctx.r3.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r3,r7
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r7.u32);
	// and r9,r11,r8
	ctx.r9.u64 = r11.u64 & ctx.r8.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c94b74
	if (cr6.eq) goto loc_82C94B74;
loc_82C94A44:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c94008
	sub_82C94008(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A54:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A64:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9462c
	if (cr6.eq) goto loc_82C9462C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c94a98
	if (!cr6.eq) goto loc_82C94A98;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c94a98
	if (!cr6.eq) goto loc_82C94A98;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// li r3,4
	ctx.r3.s64 = 4;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A98:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c94b78
	goto loc_82C94B78;
loc_82C94AA0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9462c
	if (cr6.eq) goto loc_82C9462C;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c94ac8
	if (!cr6.eq) goto loc_82C94AC8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c94ad0
	goto loc_82C94AD0;
loc_82C94AC8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C94AD0:
	// cmpwi cr6,r3,20
	cr6.compare<int32_t>(ctx.r3.s32, 20, xer);
	// beq cr6,0x82c94af0
	if (cr6.eq) goto loc_82C94AF0;
	// cmpwi cr6,r3,27
	cr6.compare<int32_t>(ctx.r3.s32, 27, xer);
	// bne cr6,0x82c94b74
	if (!cr6.eq) goto loc_82C94B74;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c92ba0
	sub_82C92BA0(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94AF0:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// subf r10,r11,r5
	ctx.r10.s64 = ctx.r5.s64 - r11.s64;
	// cmpwi cr6,r10,12
	cr6.compare<int32_t>(ctx.r10.s32, 12, xer);
	// blt cr6,0x82c9462c
	if (cr6.lt) goto loc_82C9462C;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r9,-4144
	ctx.r9.s64 = ctx.r9.s64 + -4144;
loc_82C94B0C:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82c94b48
	if (!cr6.eq) goto loc_82C94B48;
	// addi r8,r9,5488
	ctx.r8.s64 = ctx.r9.s64 + 5488;
	// lbz r7,1(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// lbzx r5,r10,r8
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r8.u32);
	// cmplw cr6,r7,r5
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c94b48
	if (!cr6.eq) goto loc_82C94B48;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// blt cr6,0x82c94b0c
	if (cr6.lt) goto loc_82C94B0C;
	// li r3,8
	ctx.r3.s64 = 8;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B48:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B54:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c930e8
	sub_82C930E8(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B64:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82c93830
	sub_82C93830(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B74:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C94B78:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C94B7C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C94608) {
	__imp__sub_82C94608(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C94B98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c94bd0
	if (!cr6.eq) goto loc_82C94BD0;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94BD0:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c94c08
	if (cr6.eq) goto loc_82C94C08;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c94c04
	if (!cr6.eq) goto loc_82C94C04;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94C04:
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
loc_82C94C08:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c94c24
	if (!cr6.eq) goto loc_82C94C24;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c94c2c
	goto loc_82C94C2C;
loc_82C94C24:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C94C2C:
	// cmplwi cr6,r3,10
	cr6.compare<uint32_t>(ctx.r3.u32, 10, xer);
	// bgt cr6,0x82c94e0c
	if (cr6.gt) goto loc_82C94E0C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,19532
	r12.s64 = r12.s64 + 19532;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C94E04;
	case 1:
		goto loc_82C94E04;
	case 2:
		goto loc_82C94C78;
	case 3:
		goto loc_82C94C98;
	case 4:
		goto loc_82C94D34;
	case 5:
		goto loc_82C94DB8;
	case 6:
		goto loc_82C94DDC;
	case 7:
		goto loc_82C94DF0;
	case 8:
		goto loc_82C94E04;
	case 9:
		goto loc_82C94CB8;
	case 10:
		goto loc_82C94D14;
	default:
		__builtin_unreachable();
	}
	// lwz r22,19972(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19972);
	// lwz r22,19972(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19972);
	// lwz r22,19576(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19576);
	// lwz r22,19608(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19608);
	// lwz r22,19764(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19764);
	// lwz r22,19896(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19896);
	// lwz r22,19932(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19932);
	// lwz r22,19952(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19952);
	// lwz r22,19972(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19972);
	// lwz r22,19640(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19640);
	// lwz r22,19732(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19732);
loc_82C94C78:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c94608
	sub_82C94608(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94C98:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c93d60
	sub_82C93D60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94CB8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c94cdc
	if (!cr6.eq) goto loc_82C94CDC;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94CDC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c94cf8
	if (!cr6.eq) goto loc_82C94CF8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c94d00
	goto loc_82C94D00;
loc_82C94CF8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C94D00:
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bne cr6,0x82c94d0c
	if (!cr6.eq) goto loc_82C94D0C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C94D0C:
	// li r3,7
	ctx.r3.s64 = 7;
	// b 0x82c94ea0
	goto loc_82C94EA0;
loc_82C94D14:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94D34:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c94d58
	if (!cr6.eq) goto loc_82C94D58;
loc_82C94D40:
	// li r3,-5
	ctx.r3.s64 = -5;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94D58:
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c94e10
	if (!cr6.eq) goto loc_82C94E10;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c94e10
	if (!cr6.eq) goto loc_82C94E10;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94d40
	if (cr6.eq) goto loc_82C94D40;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c94db0
	if (!cr6.eq) goto loc_82C94DB0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c94db0
	if (!cr6.eq) goto loc_82C94DB0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94DB0:
	// addi r10,r11,-2
	ctx.r10.s64 = r11.s64 + -2;
	// b 0x82c94e10
	goto loc_82C94E10;
loc_82C94DB8:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c94e0c
	if (!cr6.lt) goto loc_82C94E0C;
loc_82C94DC4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94DDC:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82c94dc4
	if (cr6.lt) goto loc_82C94DC4;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c94e10
	goto loc_82C94E10;
loc_82C94DF0:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// blt cr6,0x82c94dc4
	if (cr6.lt) goto loc_82C94DC4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c94e10
	goto loc_82C94E10;
loc_82C94E04:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c94ea0
	goto loc_82C94EA0;
loc_82C94E0C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C94E10:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94e9c
	if (cr6.eq) goto loc_82C94E9C;
	// addi r7,r10,4
	ctx.r7.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C94E24:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c94e40
	if (!cr6.eq) goto loc_82C94E40;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c94e48
	goto loc_82C94E48;
loc_82C94E40:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C94E48:
	// cmplwi cr6,r3,10
	cr6.compare<uint32_t>(ctx.r3.u32, 10, xer);
	// bgt cr6,0x82c94f30
	if (cr6.gt) goto loc_82C94F30;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,20072
	r12.s64 = r12.s64 + 20072;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C94E9C;
	case 1:
		goto loc_82C94E9C;
	case 2:
		goto loc_82C94E9C;
	case 3:
		goto loc_82C94E9C;
	case 4:
		goto loc_82C94EF0;
	case 5:
		goto loc_82C94E94;
	case 6:
		goto loc_82C94EB8;
	case 7:
		goto loc_82C94ED4;
	case 8:
		goto loc_82C94E9C;
	case 9:
		goto loc_82C94E9C;
	case 10:
		goto loc_82C94E9C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,20124(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20208(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20208);
	// lwz r22,20116(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20116);
	// lwz r22,20152(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20152);
	// lwz r22,20180(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20180);
	// lwz r22,20124(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
loc_82C94E94:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bge cr6,0x82c94f30
	if (!cr6.lt) goto loc_82C94F30;
loc_82C94E9C:
	// li r3,6
	ctx.r3.s64 = 6;
loc_82C94EA0:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94EB8:
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// blt cr6,0x82c94e9c
	if (cr6.lt) goto loc_82C94E9C;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// addi r8,r8,3
	ctx.r8.s64 = ctx.r8.s64 + 3;
	// addi r7,r7,3
	ctx.r7.s64 = ctx.r7.s64 + 3;
	// b 0x82c94f40
	goto loc_82C94F40;
loc_82C94ED4:
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c94e9c
	if (cr6.lt) goto loc_82C94E9C;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// b 0x82c94f40
	goto loc_82C94F40;
loc_82C94EF0:
	// cmplw cr6,r8,r5
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94e9c
	if (cr6.eq) goto loc_82C94E9C;
	// lbz r11,0(r8)
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c94f30
	if (!cr6.eq) goto loc_82C94F30;
	// lbz r11,3(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c94f30
	if (!cr6.eq) goto loc_82C94F30;
	// cmplw cr6,r7,r5
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c94e9c
	if (cr6.eq) goto loc_82C94E9C;
	// lbz r11,0(r7)
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c94f30
	if (!cr6.eq) goto loc_82C94F30;
	// lbz r11,5(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 5);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// beq cr6,0x82c94f4c
	if (cr6.eq) goto loc_82C94F4C;
loc_82C94F30:
	// addi r7,r7,2
	ctx.r7.s64 = ctx.r7.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C94F40:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c94e24
	if (!cr6.eq) goto loc_82C94E24;
	// b 0x82c94e9c
	goto loc_82C94E9C;
loc_82C94F4C:
	// addi r11,r10,4
	r11.s64 = ctx.r10.s64 + 4;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C94B98) {
	__imp__sub_82C94B98(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C94F70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c94f9c
	if (!cr6.eq) goto loc_82C94F9C;
	// li r3,-22
	ctx.r3.s64 = -22;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C94F9C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82c94fb8
	if (!cr6.eq) goto loc_82C94FB8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c94fc4
	goto loc_82C94FC4;
loc_82C94FB8:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C94FC4:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,25
	cr6.compare<uint32_t>(r11.u32, 25, xer);
	// bgt cr6,0x82c951f0
	if (cr6.gt) goto loc_82C951F0;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,20468
	r12.s64 = r12.s64 + 20468;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C9519C;
	case 1:
		goto loc_82C951B0;
	case 2:
		goto loc_82C951C4;
	case 3:
		goto loc_82C951F0;
	case 4:
		goto loc_82C951E8;
	case 5:
		goto loc_82C951E8;
	case 6:
		goto loc_82C951F0;
	case 7:
		goto loc_82C951F0;
	case 8:
		goto loc_82C951F0;
	case 9:
		goto loc_82C951F0;
	case 10:
		goto loc_82C951F0;
	case 11:
		goto loc_82C951F0;
	case 12:
		goto loc_82C951F0;
	case 13:
		goto loc_82C951F0;
	case 14:
		goto loc_82C951F0;
	case 15:
		goto loc_82C951F0;
	case 16:
		goto loc_82C951E8;
	case 17:
		goto loc_82C95094;
	case 18:
		goto loc_82C951F0;
	case 19:
		goto loc_82C95094;
	case 20:
		goto loc_82C951F0;
	case 21:
		goto loc_82C951F0;
	case 22:
		goto loc_82C951F0;
	case 23:
		goto loc_82C951F0;
	case 24:
		goto loc_82C9505C;
	case 25:
		goto loc_82C951E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,20892(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20892);
	// lwz r22,20912(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20912);
	// lwz r22,20932(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20932);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
	// lwz r22,20968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
	// lwz r22,20628(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20628);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20628(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20628);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20572(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20572);
	// lwz r22,20968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
loc_82C9505C:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + r11.u32);
	// rotlwi r11,r3,3
	r11.u64 = rotl32(ctx.r3.u32, 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82c951f0
	if (cr6.eq) goto loc_82C951F0;
loc_82C95094:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c95194
	if (cr6.eq) goto loc_82C95194;
loc_82C950A0:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c950bc
	if (!cr6.eq) goto loc_82C950BC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c950c8
	goto loc_82C950C8;
loc_82C950BC:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C950C8:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c951f0
	if (cr6.gt) goto loc_82C951F0;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,20716
	r12.s64 = r12.s64 + 20716;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C9519C;
	case 1:
		goto loc_82C951B0;
	case 2:
		goto loc_82C951C4;
	case 3:
		goto loc_82C951F0;
	case 4:
		goto loc_82C951F0;
	case 5:
		goto loc_82C951F0;
	case 6:
		goto loc_82C951F0;
	case 7:
		goto loc_82C951F0;
	case 8:
		goto loc_82C951F0;
	case 9:
		goto loc_82C951F0;
	case 10:
		goto loc_82C951F0;
	case 11:
		goto loc_82C951F0;
	case 12:
		goto loc_82C951F0;
	case 13:
		goto loc_82C951D8;
	case 14:
		goto loc_82C951F0;
	case 15:
		goto loc_82C951F0;
	case 16:
		goto loc_82C951F0;
	case 17:
		goto loc_82C95188;
	case 18:
		goto loc_82C951F0;
	case 19:
		goto loc_82C95188;
	case 20:
		goto loc_82C95188;
	case 21:
		goto loc_82C95188;
	case 22:
		goto loc_82C95188;
	case 23:
		goto loc_82C951F0;
	case 24:
		goto loc_82C95150;
	default:
		__builtin_unreachable();
	}
	// lwz r22,20892(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20892);
	// lwz r22,20912(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20912);
	// lwz r22,20932(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20932);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20952(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20952);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20872(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20872(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20872(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20872(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20872(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20976(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20816(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20816);
loc_82C95150:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	r11.u64 = rotl32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82c951f0
	if (cr6.eq) goto loc_82C951F0;
loc_82C95188:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c950a0
	if (!cr6.eq) goto loc_82C950A0;
loc_82C95194:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C9519C:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c951f0
	if (!cr6.lt) goto loc_82C951F0;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951B0:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c951f0
	if (!cr6.lt) goto loc_82C951F0;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951C4:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c951f0
	if (!cr6.lt) goto loc_82C951F0;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951D8:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,28
	ctx.r3.s64 = 28;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951E8:
	// li r3,22
	ctx.r3.s64 = 22;
	// b 0x82c951f4
	goto loc_82C951F4;
loc_82C951F0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C951F4:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C951F8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C94F70) {
	__imp__sub_82C94F70(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C95210) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c9523c
	if (!cr6.eq) goto loc_82C9523C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C9523C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82c95258
	if (!cr6.eq) goto loc_82C95258;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c95264
	goto loc_82C95264;
loc_82C95258:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C95264:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c95498
	if (cr6.gt) goto loc_82C95498;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,21140
	r12.s64 = r12.s64 + 21140;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C95454;
	case 1:
		goto loc_82C95468;
	case 2:
		goto loc_82C95484;
	case 3:
		goto loc_82C95498;
	case 4:
		goto loc_82C95498;
	case 5:
		goto loc_82C95498;
	case 6:
		goto loc_82C95498;
	case 7:
		goto loc_82C95498;
	case 8:
		goto loc_82C95498;
	case 9:
		goto loc_82C95498;
	case 10:
		goto loc_82C95498;
	case 11:
		goto loc_82C95498;
	case 12:
		goto loc_82C95498;
	case 13:
		goto loc_82C95498;
	case 14:
		goto loc_82C95498;
	case 15:
		goto loc_82C95498;
	case 16:
		goto loc_82C95498;
	case 17:
		goto loc_82C95330;
	case 18:
		goto loc_82C95498;
	case 19:
		goto loc_82C95330;
	case 20:
		goto loc_82C95498;
	case 21:
		goto loc_82C95498;
	case 22:
		goto loc_82C95498;
	case 23:
		goto loc_82C95498;
	case 24:
		goto loc_82C952F8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,21588(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21588);
	// lwz r22,21608(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21608);
	// lwz r22,21636(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21636);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21296(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21296);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21296(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21296);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21240(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21240);
loc_82C952F8:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + r11.u32);
	// rotlwi r11,r3,3
	r11.u64 = rotl32(ctx.r3.u32, 3);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82c95498
	if (cr6.eq) goto loc_82C95498;
loc_82C95330:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c9544c
	if (cr6.eq) goto loc_82C9544C;
loc_82C9533C:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c95358
	if (!cr6.eq) goto loc_82C95358;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c95364
	goto loc_82C95364;
loc_82C95358:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C95364:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	cr6.compare<uint32_t>(r11.u32, 31, xer);
	// bgt cr6,0x82c95498
	if (cr6.gt) goto loc_82C95498;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,21384
	r12.s64 = r12.s64 + 21384;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C95454;
	case 1:
		goto loc_82C95468;
	case 2:
		goto loc_82C95484;
	case 3:
		goto loc_82C95498;
	case 4:
		goto loc_82C9547C;
	case 5:
		goto loc_82C9547C;
	case 6:
		goto loc_82C9547C;
	case 7:
		goto loc_82C95498;
	case 8:
		goto loc_82C95498;
	case 9:
		goto loc_82C95498;
	case 10:
		goto loc_82C95498;
	case 11:
		goto loc_82C95498;
	case 12:
		goto loc_82C95498;
	case 13:
		goto loc_82C95498;
	case 14:
		goto loc_82C95498;
	case 15:
		goto loc_82C95498;
	case 16:
		goto loc_82C9547C;
	case 17:
		goto loc_82C95440;
	case 18:
		goto loc_82C95498;
	case 19:
		goto loc_82C95440;
	case 20:
		goto loc_82C95440;
	case 21:
		goto loc_82C95440;
	case 22:
		goto loc_82C95440;
	case 23:
		goto loc_82C95498;
	case 24:
		goto loc_82C95408;
	case 25:
		goto loc_82C9547C;
	case 26:
		goto loc_82C95498;
	case 27:
		goto loc_82C9547C;
	case 28:
		goto loc_82C95498;
	case 29:
		goto loc_82C95498;
	case 30:
		goto loc_82C95498;
	case 31:
		goto loc_82C9547C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,21588(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21588);
	// lwz r22,21608(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21608);
	// lwz r22,21636(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21636);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21628(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21628(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21568(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21568(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21568(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21568(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21568(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21512(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21512);
	// lwz r22,21628(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
loc_82C95408:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	r11.u64 = rotl32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82c95498
	if (cr6.eq) goto loc_82C95498;
loc_82C95440:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c9533c
	if (!cr6.eq) goto loc_82C9533C;
loc_82C9544C:
	// li r3,-20
	ctx.r3.s64 = -20;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C95454:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c95498
	if (!cr6.lt) goto loc_82C95498;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C95468:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c95498
	if (!cr6.lt) goto loc_82C95498;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C9547C:
	// li r3,20
	ctx.r3.s64 = 20;
	// b 0x82c9549c
	goto loc_82C9549C;
loc_82C95484:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c95498
	if (!cr6.lt) goto loc_82C95498;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C95498:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C9549C:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C954A0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C95210) {
	__imp__sub_82C95210(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C954B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// beq cr6,0x82c9556c
	if (cr6.eq) goto loc_82C9556C;
	// subf r10,r5,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r5.s64;
loc_82C954D8:
	// lbz r3,0(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c954f4
	if (!cr6.eq) goto loc_82C954F4;
	// lbz r11,1(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c954fc
	goto loc_82C954FC;
loc_82C954F4:
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C954FC:
	// cmplwi cr6,r3,13
	cr6.compare<uint32_t>(ctx.r3.u32, 13, xer);
	// bgt cr6,0x82c9555c
	if (cr6.gt) goto loc_82C9555C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,21788
	r12.s64 = r12.s64 + 21788;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C955E8;
	case 1:
		goto loc_82C955E8;
	case 2:
		goto loc_82C9555C;
	case 3:
		goto loc_82C9555C;
	case 4:
		goto loc_82C9555C;
	case 5:
		goto loc_82C95554;
	case 6:
		goto loc_82C95580;
	case 7:
		goto loc_82C95594;
	case 8:
		goto loc_82C955E8;
	case 9:
		goto loc_82C9555C;
	case 10:
		goto loc_82C9555C;
	case 11:
		goto loc_82C9555C;
	case 12:
		goto loc_82C955A8;
	case 13:
		goto loc_82C955A8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,21992(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21992);
	// lwz r22,21992(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21992);
	// lwz r22,21852(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21844(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21844);
	// lwz r22,21888(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21888);
	// lwz r22,21908(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21908);
	// lwz r22,21992(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21992);
	// lwz r22,21852(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21928(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21928);
	// lwz r22,21928(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21928);
loc_82C95554:
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// blt cr6,0x82c955d4
	if (cr6.lt) goto loc_82C955D4;
loc_82C9555C:
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
loc_82C95564:
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// bne cr6,0x82c954d8
	if (!cr6.eq) goto loc_82C954D8;
loc_82C9556C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C95580:
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// blt cr6,0x82c955d4
	if (cr6.lt) goto loc_82C955D4;
	// addi r5,r5,3
	ctx.r5.s64 = ctx.r5.s64 + 3;
	// addi r10,r10,-3
	ctx.r10.s64 = ctx.r10.s64 + -3;
	// b 0x82c95564
	goto loc_82C95564;
loc_82C95594:
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// blt cr6,0x82c955d4
	if (cr6.lt) goto loc_82C955D4;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// b 0x82c95564
	goto loc_82C95564;
loc_82C955A8:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// cmpw cr6,r3,r9
	cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, xer);
	// bne cr6,0x82c95564
	if (!cr6.eq) goto loc_82C95564;
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// bne cr6,0x82c95600
	if (!cr6.eq) goto loc_82C95600;
	// li r3,-27
	ctx.r3.s64 = -27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C955D4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C955E8:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
loc_82C955EC:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C95600:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
	// lbz r3,0(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c95620
	if (!cr6.eq) goto loc_82C95620;
	// lbz r11,1(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c95628
	goto loc_82C95628;
loc_82C95620:
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C95628:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// bgt cr6,0x82c955ec
	if (cr6.gt) goto loc_82C955EC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,22092
	r12.s64 = r12.s64 + 22092;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C956A4;
	case 1:
		goto loc_82C956A4;
	case 2:
		goto loc_82C956A4;
	case 3:
		goto loc_82C955EC;
	case 4:
		goto loc_82C955EC;
	case 5:
		goto loc_82C955EC;
	case 6:
		goto loc_82C955EC;
	case 7:
		goto loc_82C955EC;
	case 8:
		goto loc_82C955EC;
	case 9:
		goto loc_82C955EC;
	case 10:
		goto loc_82C955EC;
	case 11:
		goto loc_82C956A4;
	case 12:
		goto loc_82C956A4;
	case 13:
		goto loc_82C955EC;
	case 14:
		goto loc_82C955EC;
	case 15:
		goto loc_82C955EC;
	case 16:
		goto loc_82C955EC;
	case 17:
		goto loc_82C955EC;
	case 18:
		goto loc_82C955EC;
	case 19:
		goto loc_82C955EC;
	case 20:
		goto loc_82C955EC;
	case 21:
		goto loc_82C956A4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,22180(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,22180(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,22180(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,22180(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,22180(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,22180(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
loc_82C956A4:
	// li r3,27
	ctx.r3.s64 = 27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C954B8) {
	__imp__sub_82C954B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C956B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c956e0
	if (!cr6.eq) goto loc_82C956E0;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C956E0:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c9570c
	if (cr6.eq) goto loc_82C9570C;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c95708
	if (!cr6.eq) goto loc_82C95708;
loc_82C956FC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95708:
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
loc_82C9570C:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82c95728
	if (!cr6.eq) goto loc_82C95728;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c95734
	goto loc_82C95734;
loc_82C95728:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C95734:
	// addi r9,r3,-2
	ctx.r9.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r9,34
	cr6.compare<uint32_t>(ctx.r9.u32, 34, xer);
	// bgt cr6,0x82c95ef8
	if (cr6.gt) goto loc_82C95EF8;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// li r30,1
	r30.s64 = 1;
	// addi r31,r11,-4144
	r31.s64 = r11.s64 + -4144;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,22372
	r12.s64 = r12.s64 + 22372;
	// rlwinm r0,r9,2,0,29
	r0.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82C95830;
	case 1:
		goto loc_82C95EF8;
	case 2:
		goto loc_82C959F0;
	case 3:
		goto loc_82C95BD4;
	case 4:
		goto loc_82C95BEC;
	case 5:
		goto loc_82C95C04;
	case 6:
		goto loc_82C95EF8;
	case 7:
		goto loc_82C95924;
	case 8:
		goto loc_82C95940;
	case 9:
		goto loc_82C95BAC;
	case 10:
		goto loc_82C957F0;
	case 11:
		goto loc_82C95810;
	case 12:
		goto loc_82C95EF8;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95EF8;
	case 16:
		goto loc_82C95EF8;
	case 17:
		goto loc_82C95BC0;
	case 18:
		goto loc_82C959DC;
	case 19:
		goto loc_82C95940;
	case 20:
		goto loc_82C95C54;
	case 21:
		goto loc_82C95C90;
	case 22:
		goto loc_82C95C54;
	case 23:
		goto loc_82C95C90;
	case 24:
		goto loc_82C95C90;
	case 25:
		goto loc_82C95C90;
	case 26:
		goto loc_82C95EF8;
	case 27:
		goto loc_82C95C1C;
	case 28:
		goto loc_82C959B4;
	case 29:
		goto loc_82C95A68;
	case 30:
		goto loc_82C95A7C;
	case 31:
		goto loc_82C95EF8;
	case 32:
		goto loc_82C95EF8;
	case 33:
		goto loc_82C959C8;
	case 34:
		goto loc_82C95B98;
	default:
		__builtin_unreachable();
	}
	// lwz r22,22576(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22576);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23024(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23024);
	// lwz r22,23508(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23508);
	// lwz r22,23532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23532);
	// lwz r22,23556(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23556);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22820(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22820);
	// lwz r22,22848(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22848);
	// lwz r22,23468(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23468);
	// lwz r22,22512(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22512);
	// lwz r22,22544(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22544);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23488(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23488);
	// lwz r22,23004(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23004);
	// lwz r22,22848(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22848);
	// lwz r22,23636(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23636);
	// lwz r22,23696(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,23636(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23636);
	// lwz r22,23696(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,23696(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,23696(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23580(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23580);
	// lwz r22,22964(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22964);
	// lwz r22,23144(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23144);
	// lwz r22,23164(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23164);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22984(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22984);
	// lwz r22,23448(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23448);
loc_82C957F0:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x82c954b8
	sub_82C954B8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95810:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r3,13
	ctx.r3.s64 = 13;
	// bl 0x82c954b8
	sub_82C954B8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95830:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c956fc
	if (cr6.eq) goto loc_82C956FC;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c95858
	if (!cr6.eq) goto loc_82C95858;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c95860
	goto loc_82C95860;
loc_82C95858:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C95860:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c95ef8
	if (cr6.gt) goto loc_82C95EF8;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,22660
	r12.s64 = r12.s64 + 22660;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C95910;
	case 1:
		goto loc_82C95910;
	case 2:
		goto loc_82C95910;
	case 3:
		goto loc_82C95EF8;
	case 4:
		goto loc_82C95EF8;
	case 5:
		goto loc_82C95EF8;
	case 6:
		goto loc_82C95EF8;
	case 7:
		goto loc_82C95EF8;
	case 8:
		goto loc_82C95EF8;
	case 9:
		goto loc_82C95EF8;
	case 10:
		goto loc_82C958FC;
	case 11:
		goto loc_82C958E8;
	case 12:
		goto loc_82C95EF8;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95EF8;
	case 16:
		goto loc_82C95EF8;
	case 17:
		goto loc_82C95910;
	case 18:
		goto loc_82C95EF8;
	case 19:
		goto loc_82C95910;
	case 20:
		goto loc_82C95EF8;
	case 21:
		goto loc_82C95EF8;
	case 22:
		goto loc_82C95EF8;
	case 23:
		goto loc_82C95EF8;
	case 24:
		goto loc_82C95910;
	default:
		__builtin_unreachable();
	}
	// lwz r22,22800(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,22800(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,22800(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22780(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22780);
	// lwz r22,22760(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22760);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22800(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22800(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22800(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
loc_82C958E8:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c92db0
	sub_82C92DB0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C958FC:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c930e8
	sub_82C930E8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95910:
	// addi r11,r10,-2
	r11.s64 = ctx.r10.s64 + -2;
	// li r3,29
	ctx.r3.s64 = 29;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95924:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c95940
	if (!cr6.eq) goto loc_82C95940;
	// stw r5,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r5.u32);
	// li r3,-15
	ctx.r3.s64 = -15;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95940:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c959a4
	if (cr6.eq) goto loc_82C959A4;
loc_82C9594C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c95968
	if (!cr6.eq) goto loc_82C95968;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c95970
	goto loc_82C95970;
loc_82C95968:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C95970:
	// cmpwi cr6,r3,9
	cr6.compare<int32_t>(ctx.r3.s32, 9, xer);
	// beq cr6,0x82c9598c
	if (cr6.eq) goto loc_82C9598C;
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// beq cr6,0x82c95998
	if (cr6.eq) goto loc_82C95998;
	// cmpwi cr6,r3,21
	cr6.compare<int32_t>(ctx.r3.s32, 21, xer);
	// bne cr6,0x82c959a4
	if (!cr6.eq) goto loc_82C959A4;
	// b 0x82c95998
	goto loc_82C95998;
loc_82C9598C:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c959a4
	if (cr6.eq) goto loc_82C959A4;
loc_82C95998:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c9594c
	if (!cr6.eq) goto loc_82C9594C;
loc_82C959A4:
	// li r3,15
	ctx.r3.s64 = 15;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C959B4:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c94f70
	sub_82C94F70(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C959C8:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,38
	ctx.r3.s64 = 38;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C959DC:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,25
	ctx.r3.s64 = 25;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C959F0:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c95a08
	if (!cr6.eq) goto loc_82C95A08;
	// li r3,-26
	ctx.r3.s64 = -26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95A08:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c95a58
	if (!cr6.eq) goto loc_82C95A58;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,93
	cr6.compare<uint32_t>(ctx.r10.u32, 93, xer);
	// bne cr6,0x82c95a58
	if (!cr6.eq) goto loc_82C95A58;
	// addi r10,r11,2
	ctx.r10.s64 = r11.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c956fc
	if (cr6.eq) goto loc_82C956FC;
	// lbz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c95a58
	if (!cr6.eq) goto loc_82C95A58;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r10,62
	cr6.compare<uint32_t>(ctx.r10.u32, 62, xer);
	// bne cr6,0x82c95a58
	if (!cr6.eq) goto loc_82C95A58;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// li r3,34
	ctx.r3.s64 = 34;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95A58:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// li r3,26
	ctx.r3.s64 = 26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95A68:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,23
	ctx.r3.s64 = 23;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95A7C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c95a94
	if (!cr6.eq) goto loc_82C95A94;
	// li r3,-24
	ctx.r3.s64 = -24;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95A94:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c95ab0
	if (!cr6.eq) goto loc_82C95AB0;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c95ab8
	goto loc_82C95AB8;
loc_82C95AB0:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C95AB8:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,27
	cr6.compare<uint32_t>(r11.u32, 27, xer);
	// bgt cr6,0x82c95ef8
	if (cr6.gt) goto loc_82C95EF8;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,23260
	r12.s64 = r12.s64 + 23260;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C95B88;
	case 1:
		goto loc_82C95B88;
	case 2:
		goto loc_82C95B88;
	case 3:
		goto loc_82C95EF8;
	case 4:
		goto loc_82C95EF8;
	case 5:
		goto loc_82C95EF8;
	case 6:
		goto loc_82C95B60;
	case 7:
		goto loc_82C95EF8;
	case 8:
		goto loc_82C95EF8;
	case 9:
		goto loc_82C95EF8;
	case 10:
		goto loc_82C95EF8;
	case 11:
		goto loc_82C95EF8;
	case 12:
		goto loc_82C95B88;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95EF8;
	case 16:
		goto loc_82C95EF8;
	case 17:
		goto loc_82C95EF8;
	case 18:
		goto loc_82C95EF8;
	case 19:
		goto loc_82C95EF8;
	case 20:
		goto loc_82C95EF8;
	case 21:
		goto loc_82C95EF8;
	case 22:
		goto loc_82C95EF8;
	case 23:
		goto loc_82C95B88;
	case 24:
		goto loc_82C95B4C;
	case 25:
		goto loc_82C95B74;
	case 26:
		goto loc_82C95B88;
	case 27:
		goto loc_82C95B88;
	default:
		__builtin_unreachable();
	}
	// lwz r22,23432(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23432(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23432(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23392(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23392);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23432(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23432(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23372(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23372);
	// lwz r22,23412(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23412);
	// lwz r22,23432(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23432(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
loc_82C95B4C:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,36
	ctx.r3.s64 = 36;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95B60:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,35
	ctx.r3.s64 = 35;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95B74:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,37
	ctx.r3.s64 = 37;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95B88:
	// li r3,24
	ctx.r3.s64 = 24;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95B98:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,21
	ctx.r3.s64 = 21;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95BAC:
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,17
	ctx.r3.s64 = 17;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95BC0:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82c95210
	sub_82C95210(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95BD4:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bge cr6,0x82c95ef8
	if (!cr6.lt) goto loc_82C95EF8;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95BEC:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82c95ef8
	if (!cr6.lt) goto loc_82C95EF8;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95C04:
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bge cr6,0x82c95ef8
	if (!cr6.lt) goto loc_82C95EF8;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95C1C:
	// clrlwi r11,r8,24
	r11.u64 = ctx.r8.u32 & 0xFF;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r7,r31,1280
	ctx.r7.s64 = r31.s64 + 1280;
	// clrlwi r4,r9,27
	ctx.r4.u64 = ctx.r9.u32 & 0x1F;
	// rlwinm r8,r9,27,5,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x7FFFFFF;
	// slw r3,r30,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r9,r11,r7
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + ctx.r7.u32);
	// rotlwi r9,r9,3
	ctx.r9.u64 = rotl32(ctx.r9.u32, 3);
	// add r8,r9,r8
	ctx.r8.u64 = ctx.r9.u64 + ctx.r8.u64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r31
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + r31.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c95c5c
	if (cr6.eq) goto loc_82C95C5C;
loc_82C95C54:
	// li r8,18
	ctx.r8.s64 = 18;
	// b 0x82c95c94
	goto loc_82C95C94;
loc_82C95C5C:
	// addi r8,r31,1536
	ctx.r8.s64 = r31.s64 + 1536;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r4,r7,27
	ctx.r4.u64 = ctx.r7.u32 & 0x1F;
	// lbzx r3,r11,r8
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + ctx.r8.u32);
	// slw r8,r30,r4
	ctx.r8.u64 = ctx.r4.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r4.u8 & 0x3F));
	// rotlwi r11,r3,3
	r11.u64 = rotl32(ctx.r3.u32, 3);
	// add r7,r11,r9
	ctx.r7.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r4,r7,2,0,29
	ctx.r4.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r4,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + r31.u32);
	// and r11,r3,r8
	r11.u64 = ctx.r3.u64 & ctx.r8.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c95ef8
	if (cr6.eq) goto loc_82C95EF8;
loc_82C95C90:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C95C94:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c95d8c
	if (cr6.eq) goto loc_82C95D8C;
loc_82C95CA0:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c95cbc
	if (!cr6.eq) goto loc_82C95CBC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c95cc8
	goto loc_82C95CC8;
loc_82C95CBC:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C95CC8:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	cr6.compare<uint32_t>(r11.u32, 31, xer);
	// bgt cr6,0x82c95ef8
	if (cr6.gt) goto loc_82C95EF8;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,23788
	r12.s64 = r12.s64 + 23788;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C95BD4;
	case 1:
		goto loc_82C95BEC;
	case 2:
		goto loc_82C95C04;
	case 3:
		goto loc_82C95EF8;
	case 4:
		goto loc_82C95E94;
	case 5:
		goto loc_82C95E94;
	case 6:
		goto loc_82C95E94;
	case 7:
		goto loc_82C95EF8;
	case 8:
		goto loc_82C95EF8;
	case 9:
		goto loc_82C95EF8;
	case 10:
		goto loc_82C95EDC;
	case 11:
		goto loc_82C95EF8;
	case 12:
		goto loc_82C95EF8;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95E94;
	case 16:
		goto loc_82C95E94;
	case 17:
		goto loc_82C95E8C;
	case 18:
		goto loc_82C95D6C;
	case 19:
		goto loc_82C95E8C;
	case 20:
		goto loc_82C95E8C;
	case 21:
		goto loc_82C95E8C;
	case 22:
		goto loc_82C95E8C;
	case 23:
		goto loc_82C95EF8;
	case 24:
		goto loc_82C95E54;
	case 25:
		goto loc_82C95E94;
	case 26:
		goto loc_82C95EF8;
	case 27:
		goto loc_82C95E94;
	case 28:
		goto loc_82C95EC0;
	case 29:
		goto loc_82C95EA4;
	case 30:
		goto loc_82C95E94;
	case 31:
		goto loc_82C95E94;
	default:
		__builtin_unreachable();
	}
	// lwz r22,23508(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23508);
	// lwz r22,23532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23532);
	// lwz r22,23556(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23556);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24212(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24284);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24212(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24204(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,23916(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23916);
	// lwz r22,24204(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24148);
	// lwz r22,24212(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24312(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24212(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24256(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24256);
	// lwz r22,24228(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24228);
	// lwz r22,24212(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
loc_82C95D6C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmpwi cr6,r8,18
	cr6.compare<int32_t>(ctx.r8.s32, 18, xer);
	// beq cr6,0x82c95d98
	if (cr6.eq) goto loc_82C95D98;
	// cmpwi cr6,r8,41
	cr6.compare<int32_t>(ctx.r8.s32, 41, xer);
	// bne cr6,0x82c95d84
	if (!cr6.eq) goto loc_82C95D84;
loc_82C95D80:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C95D84:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c95ca0
	if (!cr6.eq) goto loc_82C95CA0;
loc_82C95D8C:
	// neg r3,r8
	ctx.r3.s64 = -ctx.r8.s64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95D98:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c956fc
	if (cr6.eq) goto loc_82C956FC;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// li r8,41
	ctx.r8.s64 = 41;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82c95dc0
	if (!cr6.eq) goto loc_82C95DC0;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c95dcc
	goto loc_82C95DCC;
loc_82C95DC0:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C95DCC:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c95d80
	if (cr6.gt) goto loc_82C95D80;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,24048
	r12.s64 = r12.s64 + 24048;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C95BD4;
	case 1:
		goto loc_82C95BEC;
	case 2:
		goto loc_82C95C04;
	case 3:
		goto loc_82C95D80;
	case 4:
		goto loc_82C95D80;
	case 5:
		goto loc_82C95D80;
	case 6:
		goto loc_82C95D80;
	case 7:
		goto loc_82C95D80;
	case 8:
		goto loc_82C95D80;
	case 9:
		goto loc_82C95D80;
	case 10:
		goto loc_82C95D80;
	case 11:
		goto loc_82C95D80;
	case 12:
		goto loc_82C95D80;
	case 13:
		goto loc_82C95D80;
	case 14:
		goto loc_82C95D80;
	case 15:
		goto loc_82C95D80;
	case 16:
		goto loc_82C95D80;
	case 17:
		goto loc_82C95E8C;
	case 18:
		goto loc_82C95D80;
	case 19:
		goto loc_82C95E8C;
	case 20:
		goto loc_82C95E8C;
	case 21:
		goto loc_82C95E8C;
	case 22:
		goto loc_82C95E8C;
	case 23:
		goto loc_82C95D80;
	case 24:
		goto loc_82C95E54;
	default:
		__builtin_unreachable();
	}
	// lwz r22,23508(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23508);
	// lwz r22,23532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23532);
	// lwz r22,23556(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23556);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,24204(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,24204(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,23936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,24148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24148);
loc_82C95E54:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r31,1536
	ctx.r4.s64 = r31.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r30,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (r30.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	r11.u64 = rotl32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r31
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82c95ef8
	if (cr6.eq) goto loc_82C95EF8;
loc_82C95E8C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c95d84
	goto loc_82C95D84;
loc_82C95E94:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95EA4:
	// cmpwi cr6,r8,19
	cr6.compare<int32_t>(ctx.r8.s32, 19, xer);
	// beq cr6,0x82c95ef8
	if (cr6.eq) goto loc_82C95EF8;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,32
	ctx.r3.s64 = 32;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95EC0:
	// cmpwi cr6,r8,19
	cr6.compare<int32_t>(ctx.r8.s32, 19, xer);
	// beq cr6,0x82c95ef8
	if (cr6.eq) goto loc_82C95EF8;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,31
	ctx.r3.s64 = 31;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95EDC:
	// cmpwi cr6,r8,19
	cr6.compare<int32_t>(ctx.r8.s32, 19, xer);
	// beq cr6,0x82c95ef8
	if (cr6.eq) goto loc_82C95EF8;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,30
	ctx.r3.s64 = 30;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C95EF8:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C956B8) {
	__imp__sub_82C956B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C95F08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c95f38
	if (!cr6.eq) goto loc_82C95F38;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C95F38:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C95F3C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c95f58
	if (!cr6.eq) goto loc_82C95F58;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c95f60
	goto loc_82C95F60;
loc_82C95F58:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C95F60:
	// addi r11,r3,-2
	r11.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r11,19
	cr6.compare<uint32_t>(r11.u32, 19, xer);
	// bgt cr6,0x82c95fe4
	if (cr6.gt) goto loc_82C95FE4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,24452
	r12.s64 = r12.s64 + 24452;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C9602C;
	case 1:
		goto loc_82C96008;
	case 2:
		goto loc_82C95FE4;
	case 3:
		goto loc_82C95FE4;
	case 4:
		goto loc_82C95FD4;
	case 5:
		goto loc_82C95FDC;
	case 6:
		goto loc_82C95FE4;
	case 7:
		goto loc_82C96068;
	case 8:
		goto loc_82C96044;
	case 9:
		goto loc_82C95FE4;
	case 10:
		goto loc_82C95FE4;
	case 11:
		goto loc_82C95FE4;
	case 12:
		goto loc_82C95FE4;
	case 13:
		goto loc_82C95FE4;
	case 14:
		goto loc_82C95FE4;
	case 15:
		goto loc_82C95FE4;
	case 16:
		goto loc_82C95FE4;
	case 17:
		goto loc_82C95FE4;
	case 18:
		goto loc_82C95FE4;
	case 19:
		goto loc_82C960D8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,24620(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24620);
	// lwz r22,24584(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24584);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24532(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24532);
	// lwz r22,24540(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24540);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24680(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24680);
	// lwz r22,24644(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24644);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24792(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24792);
loc_82C95FD4:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c95fe8
	goto loc_82C95FE8;
loc_82C95FDC:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c95fe8
	goto loc_82C95FE8;
loc_82C95FE4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C95FE8:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c95f3c
	if (!cr6.eq) goto loc_82C95F3C;
loc_82C95FF0:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96008:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c95ff0
	if (!cr6.eq) goto loc_82C95FF0;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c93d60
	sub_82C93D60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C9602C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96044:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c95ff0
	if (!cr6.eq) goto loc_82C95FF0;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96068:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c95ff0
	if (!cr6.eq) goto loc_82C95FF0;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c96090
	if (!cr6.eq) goto loc_82C96090;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96090:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c960ac
	if (!cr6.eq) goto loc_82C960AC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c960b4
	goto loc_82C960B4;
loc_82C960AC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C960B4:
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bne cr6,0x82c960c0
	if (!cr6.eq) goto loc_82C960C0;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C960C0:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C960D8:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c95ff0
	if (!cr6.eq) goto loc_82C95FF0;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,39
	ctx.r3.s64 = 39;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C95F08) {
	__imp__sub_82C95F08(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C96100) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c96130
	if (!cr6.eq) goto loc_82C96130;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96130:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C96134:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c96150
	if (!cr6.eq) goto loc_82C96150;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c96158
	goto loc_82C96158;
loc_82C96150:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C96158:
	// addi r11,r3,-3
	r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,27
	cr6.compare<uint32_t>(r11.u32, 27, xer);
	// bgt cr6,0x82c961fc
	if (cr6.gt) goto loc_82C961FC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,24956
	r12.s64 = r12.s64 + 24956;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C96220;
	case 1:
		goto loc_82C961FC;
	case 2:
		goto loc_82C961FC;
	case 3:
		goto loc_82C961EC;
	case 4:
		goto loc_82C961F4;
	case 5:
		goto loc_82C961FC;
	case 6:
		goto loc_82C96298;
	case 7:
		goto loc_82C96274;
	case 8:
		goto loc_82C961FC;
	case 9:
		goto loc_82C961FC;
	case 10:
		goto loc_82C961FC;
	case 11:
		goto loc_82C961FC;
	case 12:
		goto loc_82C961FC;
	case 13:
		goto loc_82C961FC;
	case 14:
		goto loc_82C961FC;
	case 15:
		goto loc_82C961FC;
	case 16:
		goto loc_82C961FC;
	case 17:
		goto loc_82C961FC;
	case 18:
		goto loc_82C961FC;
	case 19:
		goto loc_82C961FC;
	case 20:
		goto loc_82C961FC;
	case 21:
		goto loc_82C961FC;
	case 22:
		goto loc_82C961FC;
	case 23:
		goto loc_82C961FC;
	case 24:
		goto loc_82C961FC;
	case 25:
		goto loc_82C961FC;
	case 26:
		goto loc_82C961FC;
	case 27:
		goto loc_82C96244;
	default:
		__builtin_unreachable();
	}
	// lwz r22,25120(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25120);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25068(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25068);
	// lwz r22,25076(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25076);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25240(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25240);
	// lwz r22,25204(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25204);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25156(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25156);
loc_82C961EC:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c96200
	goto loc_82C96200;
loc_82C961F4:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c96200
	goto loc_82C96200;
loc_82C961FC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C96200:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c96134
	if (!cr6.eq) goto loc_82C96134;
loc_82C96208:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C96210:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96220:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c96208
	if (!cr6.eq) goto loc_82C96208;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c93d60
	sub_82C93D60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96244:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c96208
	if (!cr6.eq) goto loc_82C96208;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c94f70
	sub_82C94F70(ctx, base);
	// cmpwi cr6,r3,22
	cr6.compare<int32_t>(ctx.r3.s32, 22, xer);
	// bne cr6,0x82c96210
	if (!cr6.eq) goto loc_82C96210;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96274:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c96208
	if (!cr6.eq) goto loc_82C96208;
	// addi r11,r10,2
	r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96298:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c96208
	if (!cr6.eq) goto loc_82C96208;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c962c0
	if (!cr6.eq) goto loc_82C962C0;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C962C0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c962dc
	if (!cr6.eq) goto loc_82C962DC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c962e4
	goto loc_82C962E4;
loc_82C962DC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C962E4:
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bne cr6,0x82c962f0
	if (!cr6.eq) goto loc_82C962F0;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C962F0:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C96100) {
	__imp__sub_82C96100(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C96308) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// subf r11,r10,r5
	r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// li r8,0
	ctx.r8.s64 = 0;
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82c96338
	if (cr6.eq) goto loc_82C96338;
	// rlwinm r11,r11,0,0,30
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
loc_82C96338:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c963c4
	if (cr6.eq) goto loc_82C963C4;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C96344:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c96360
	if (!cr6.eq) goto loc_82C96360;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r7
	r11.u64 = r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c96368
	goto loc_82C96368;
loc_82C96360:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C96368:
	// cmplwi cr6,r3,8
	cr6.compare<uint32_t>(ctx.r3.u32, 8, xer);
	// bgt cr6,0x82c963b4
	if (cr6.gt) goto loc_82C963B4;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,25480
	r12.s64 = r12.s64 + 25480;
	// rlwinm r0,r3,2,0,29
	r0.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C964D4;
	case 1:
		goto loc_82C964D4;
	case 2:
		goto loc_82C96400;
	case 3:
		goto loc_82C963B4;
	case 4:
		goto loc_82C96458;
	case 5:
		goto loc_82C963AC;
	case 6:
		goto loc_82C963D8;
	case 7:
		goto loc_82C963EC;
	case 8:
		goto loc_82C964D4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,25812(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25812);
	// lwz r22,25812(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25812);
	// lwz r22,25600(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25600);
	// lwz r22,25524(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25524);
	// lwz r22,25688(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25688);
	// lwz r22,25516(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25516);
	// lwz r22,25560(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25560);
	// lwz r22,25580(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25580);
	// lwz r22,25812(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25812);
loc_82C963AC:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// blt cr6,0x82c964c0
	if (cr6.lt) goto loc_82C964C0;
loc_82C963B4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
loc_82C963BC:
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c96344
	if (!cr6.eq) goto loc_82C96344;
loc_82C963C4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C963D8:
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// blt cr6,0x82c964c0
	if (cr6.lt) goto loc_82C964C0;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c963bc
	goto loc_82C963BC;
loc_82C963EC:
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x82c964c0
	if (cr6.lt) goto loc_82C964C0;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c963bc
	goto loc_82C963BC;
loc_82C96400:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c963c4
	if (cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c963bc
	if (!cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,33
	cr6.compare<uint32_t>(r11.u32, 33, xer);
	// bne cr6,0x82c963bc
	if (!cr6.eq) goto loc_82C963BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c963c4
	if (cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c963bc
	if (!cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,91
	cr6.compare<uint32_t>(r11.u32, 91, xer);
	// bne cr6,0x82c963bc
	if (!cr6.eq) goto loc_82C963BC;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// b 0x82c963b4
	goto loc_82C963B4;
loc_82C96458:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c963c4
	if (cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c963bc
	if (!cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,93
	cr6.compare<uint32_t>(r11.u32, 93, xer);
	// bne cr6,0x82c963bc
	if (!cr6.eq) goto loc_82C963BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c963c4
	if (cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c963bc
	if (!cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,62
	cr6.compare<uint32_t>(r11.u32, 62, xer);
	// bne cr6,0x82c963bc
	if (!cr6.eq) goto loc_82C963BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82c964ec
	if (cr6.eq) goto loc_82C964EC;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// b 0x82c963bc
	goto loc_82C963BC;
loc_82C964C0:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C964D4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C964EC:
	// li r3,42
	ctx.r3.s64 = 42;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C96308) {
	__imp__sub_82C96308(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C96508) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// addi r7,r5,-2
	ctx.r7.s64 = ctx.r5.s64 + -2;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// beq cr6,0x82c9664c
	if (cr6.eq) goto loc_82C9664C;
loc_82C96528:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// extsb r9,r3
	ctx.r9.s64 = ctx.r3.s8;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c96548
	if (!cr6.eq) goto loc_82C96548;
	// add r11,r4,r8
	r11.u64 = ctx.r4.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c9654c
	goto loc_82C9654C;
loc_82C96548:
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C9654C:
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,26
	cr6.compare<uint32_t>(r11.u32, 26, xer);
	// bgt cr6,0x82c96624
	if (cr6.gt) goto loc_82C96624;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,25968
	r12.s64 = r12.s64 + 25968;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C96640;
	case 1:
		goto loc_82C96640;
	case 2:
		goto loc_82C96624;
	case 3:
		goto loc_82C96624;
	case 4:
		goto loc_82C96640;
	case 5:
		goto loc_82C96640;
	case 6:
		goto loc_82C96640;
	case 7:
		goto loc_82C96640;
	case 8:
		goto loc_82C96640;
	case 9:
		goto loc_82C96640;
	case 10:
		goto loc_82C96640;
	case 11:
		goto loc_82C96624;
	case 12:
		goto loc_82C965DC;
	case 13:
		goto loc_82C96608;
	case 14:
		goto loc_82C96640;
	case 15:
		goto loc_82C96640;
	case 16:
		goto loc_82C96640;
	case 17:
		goto loc_82C96608;
	case 18:
		goto loc_82C96640;
	case 19:
		goto loc_82C96624;
	case 20:
		goto loc_82C96624;
	case 21:
		goto loc_82C96640;
	case 22:
		goto loc_82C96640;
	case 23:
		goto loc_82C96640;
	case 24:
		goto loc_82C96640;
	case 25:
		goto loc_82C96640;
	case 26:
		goto loc_82C96640;
	default:
		__builtin_unreachable();
	}
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26076(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26076);
	// lwz r22,26120(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26120);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26120(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26120);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26148(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
loc_82C965DC:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c96640
	if (!cr6.eq) goto loc_82C96640;
	// extsb r11,r4
	r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82c96640
	if (!cr6.eq) goto loc_82C96640;
loc_82C965F0:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96608:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// extsb r11,r4
	r11.s64 = ctx.r4.s8;
	// beq cr6,0x82c96618
	if (cr6.eq) goto loc_82C96618;
	// li r11,-1
	r11.s64 = -1;
loc_82C96618:
	// rlwinm r11,r11,0,0,24
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82c96640
	if (cr6.eq) goto loc_82C96640;
loc_82C96624:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c965f0
	if (!cr6.eq) goto loc_82C965F0;
	// extsb r11,r4
	r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,36
	cr6.compare<int32_t>(r11.s32, 36, xer);
	// beq cr6,0x82c96640
	if (cr6.eq) goto loc_82C96640;
	// cmpwi cr6,r11,64
	cr6.compare<int32_t>(r11.s32, 64, xer);
	// bne cr6,0x82c965f0
	if (!cr6.eq) goto loc_82C965F0;
loc_82C96640:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// bne cr6,0x82c96528
	if (!cr6.eq) goto loc_82C96528;
loc_82C9664C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C96508) {
	__imp__sub_82C96508(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C96660) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r27,0
	r27.s64 = 0;
	// addi r8,r4,2
	ctx.r8.s64 = ctx.r4.s64 + 2;
	// li r29,1
	r29.s64 = 1;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// mr r30,r27
	r30.u64 = r27.u64;
	// addi r31,r8,2
	r31.s64 = ctx.r8.s64 + 2;
loc_82C9668C:
	// lbz r3,0(r8)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// lbz r4,1(r8)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// extsb r10,r3
	ctx.r10.s64 = ctx.r3.s8;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x82c966ac
	if (!cr6.eq) goto loc_82C966AC;
	// add r11,r4,r28
	r11.u64 = ctx.r4.u64 + r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c966b0
	goto loc_82C966B0;
loc_82C966AC:
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C966B0:
	// addi r11,r3,-3
	r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,26
	cr6.compare<uint32_t>(r11.u32, 26, xer);
	// bgt cr6,0x82c96958
	if (cr6.gt) goto loc_82C96958;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,26324
	r12.s64 = r12.s64 + 26324;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C96938;
	case 1:
		goto loc_82C96958;
	case 2:
		goto loc_82C96740;
	case 3:
		goto loc_82C96768;
	case 4:
		goto loc_82C96798;
	case 5:
		goto loc_82C96958;
	case 6:
		goto loc_82C96918;
	case 7:
		goto loc_82C96918;
	case 8:
		goto loc_82C96950;
	case 9:
		goto loc_82C967C8;
	case 10:
		goto loc_82C9681C;
	case 11:
		goto loc_82C96958;
	case 12:
		goto loc_82C96958;
	case 13:
		goto loc_82C96958;
	case 14:
		goto loc_82C96950;
	case 15:
		goto loc_82C96958;
	case 16:
		goto loc_82C96958;
	case 17:
		goto loc_82C96958;
	case 18:
		goto loc_82C96870;
	case 19:
		goto loc_82C96740;
	case 20:
		goto loc_82C96958;
	case 21:
		goto loc_82C96740;
	case 22:
		goto loc_82C96958;
	case 23:
		goto loc_82C96958;
	case 24:
		goto loc_82C96958;
	case 25:
		goto loc_82C96958;
	case 26:
		goto loc_82C96740;
	default:
		__builtin_unreachable();
	}
	// lwz r22,26936(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26936);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26432(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
	// lwz r22,26472(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26472);
	// lwz r22,26520(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26520);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26904(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26904);
	// lwz r22,26904(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26904);
	// lwz r22,26960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26960);
	// lwz r22,26568(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26568);
	// lwz r22,26652(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26652);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26960);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26736(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26736);
	// lwz r22,26432(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26432(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26432(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
loc_82C96740:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c96958
	if (!cr6.eq) goto loc_82C96958;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c96758
	if (!cr6.lt) goto loc_82C96758;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r29.u8);
loc_82C96758:
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96768:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c96784
	if (!cr6.eq) goto loc_82C96784;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c96780
	if (!cr6.lt) goto loc_82C96780;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r29.u8);
loc_82C96780:
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_82C96784:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96798:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c967b4
	if (!cr6.eq) goto loc_82C967B4;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c967b0
	if (!cr6.lt) goto loc_82C967B0;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r29.u8);
loc_82C967B0:
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_82C967B4:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C967C8:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// beq cr6,0x82c967f0
	if (cr6.eq) goto loc_82C967F0;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c967dc
	if (!cr6.lt) goto loc_82C967DC;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, r31.u32);
loc_82C967DC:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,12
	r30.s64 = 12;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C967F0:
	// cmpwi cr6,r30,12
	cr6.compare<int32_t>(r30.s32, 12, xer);
	// bne cr6,0x82c96958
	if (!cr6.eq) goto loc_82C96958;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c96808
	if (!cr6.lt) goto loc_82C96808;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
loc_82C96808:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C9681C:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// beq cr6,0x82c96844
	if (cr6.eq) goto loc_82C96844;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c96830
	if (!cr6.lt) goto loc_82C96830;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, r31.u32);
loc_82C96830:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,13
	r30.s64 = 13;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96844:
	// cmpwi cr6,r30,13
	cr6.compare<int32_t>(r30.s32, 13, xer);
	// bne cr6,0x82c96958
	if (!cr6.eq) goto loc_82C96958;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c96808
	if (!cr6.lt) goto loc_82C96808;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96870:
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// bne cr6,0x82c96888
	if (!cr6.eq) goto loc_82C96888;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96888:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bne cr6,0x82c96958
	if (!cr6.eq) goto loc_82C96958;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c96958
	if (!cr6.lt) goto loc_82C96958;
	// lbz r11,12(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c96958
	if (cr6.eq) goto loc_82C96958;
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// beq cr6,0x82c96908
	if (cr6.eq) goto loc_82C96908;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x82c96908
	if (!cr6.eq) goto loc_82C96908;
	// extsb r11,r4
	r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// bne cr6,0x82c96908
	if (!cr6.eq) goto loc_82C96908;
	// lbz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r11,r3
	r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c968f8
	if (!cr6.eq) goto loc_82C968F8;
	// lbz r10,3(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 3);
	// cmplwi cr6,r10,32
	cr6.compare<uint32_t>(ctx.r10.u32, 32, xer);
	// beq cr6,0x82c96908
	if (cr6.eq) goto loc_82C96908;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c968f8
	if (!cr6.eq) goto loc_82C968F8;
	// clrlwi r11,r10,24
	r11.u64 = ctx.r10.u32 & 0xFF;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c96900
	goto loc_82C96900;
loc_82C968F8:
	// lbz r4,3(r8)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + 3);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C96900:
	// cmpw cr6,r3,r30
	cr6.compare<int32_t>(ctx.r3.s32, r30.s32, xer);
	// bne cr6,0x82c96958
	if (!cr6.eq) goto loc_82C96958;
loc_82C96908:
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96918:
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// bne cr6,0x82c96930
	if (!cr6.eq) goto loc_82C96930;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96930:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bne cr6,0x82c96958
	if (!cr6.eq) goto loc_82C96958;
loc_82C96938:
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bge cr6,0x82c96958
	if (!cr6.lt) goto loc_82C96958;
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96950:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bne cr6,0x82c96964
	if (!cr6.eq) goto loc_82C96964;
loc_82C96958:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	r31.s64 = r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96964:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C96660) {
	__imp__sub_82C96660(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C96970) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// subf r11,r4,r5
	r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// srawi r10,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r10.s64 = r11.s32 >> 1;
	// addze r11,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	r11.s64 = temp.s64;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82c96abc
	if (cr6.eq) goto loc_82C96ABC;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x82c96a68
	if (cr6.eq) goto loc_82C96A68;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,97
	cr6.compare<int32_t>(r11.s32, 97, xer);
	// beq cr6,0x82c96a10
	if (cr6.eq) goto loc_82C96A10;
	// cmpwi cr6,r11,113
	cr6.compare<int32_t>(r11.s32, 113, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,117
	cr6.compare<uint32_t>(ctx.r10.u32, 117, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,111
	cr6.compare<uint32_t>(ctx.r10.u32, 111, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r11,116
	cr6.compare<uint32_t>(r11.u32, 116, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// li r3,34
	ctx.r3.s64 = 34;
	// blr 
	return;
loc_82C96A10:
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,112
	cr6.compare<uint32_t>(ctx.r10.u32, 112, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,111
	cr6.compare<uint32_t>(ctx.r10.u32, 111, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r11,115
	cr6.compare<uint32_t>(r11.u32, 115, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// li r3,39
	ctx.r3.s64 = 39;
	// blr 
	return;
loc_82C96A68:
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,97
	cr6.compare<uint32_t>(r11.u32, 97, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// cmplwi cr6,r10,109
	cr6.compare<uint32_t>(ctx.r10.u32, 109, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r11,112
	cr6.compare<uint32_t>(r11.u32, 112, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// li r3,38
	ctx.r3.s64 = 38;
	// blr 
	return;
loc_82C96ABC:
	// lbz r11,2(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// cmplwi cr6,r11,116
	cr6.compare<uint32_t>(r11.u32, 116, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,103
	cr6.compare<int32_t>(r11.s32, 103, xer);
	// beq cr6,0x82c96b00
	if (cr6.eq) goto loc_82C96B00;
	// cmpwi cr6,r11,108
	cr6.compare<int32_t>(r11.s32, 108, xer);
	// bne cr6,0x82c96b08
	if (!cr6.eq) goto loc_82C96B08;
	// li r3,60
	ctx.r3.s64 = 60;
	// blr 
	return;
loc_82C96B00:
	// li r3,62
	ctx.r3.s64 = 62;
	// blr 
	return;
loc_82C96B08:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C96970) {
	__imp__sub_82C96970(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C96B10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C96B24:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r9,r10,1
	ctx.r9.s64 = ctx.r10.s64 + 1;
	// extsb r8,r3
	ctx.r8.s64 = ctx.r3.s8;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x82c96b48
	if (!cr6.eq) goto loc_82C96B48;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r7
	r11.u64 = r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c96b50
	goto loc_82C96B50;
loc_82C96B48:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C96B50:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c96c8c
	if (cr6.gt) goto loc_82C96C8C;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,27508
	r12.s64 = r12.s64 + 27508;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C96C08;
	case 1:
		goto loc_82C96BF0;
	case 2:
		goto loc_82C96BD8;
	case 3:
		goto loc_82C96C8C;
	case 4:
		goto loc_82C96C8C;
	case 5:
		goto loc_82C96C8C;
	case 6:
		goto loc_82C96C8C;
	case 7:
		goto loc_82C96C8C;
	case 8:
		goto loc_82C96C8C;
	case 9:
		goto loc_82C96C8C;
	case 10:
		goto loc_82C96C8C;
	case 11:
		goto loc_82C96C8C;
	case 12:
		goto loc_82C96C8C;
	case 13:
		goto loc_82C96C8C;
	case 14:
		goto loc_82C96C8C;
	case 15:
		goto loc_82C96C8C;
	case 16:
		goto loc_82C96C8C;
	case 17:
		goto loc_82C96C4C;
	case 18:
		goto loc_82C96C4C;
	case 19:
		goto loc_82C96C4C;
	case 20:
		goto loc_82C96C4C;
	case 21:
		goto loc_82C96C4C;
	case 22:
		goto loc_82C96C4C;
	case 23:
		goto loc_82C96C8C;
	case 24:
		goto loc_82C96C4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,27656(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27656);
	// lwz r22,27632(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27632);
	// lwz r22,27608(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27608);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27724(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27788(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27724(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
loc_82C96BD8:
	// lbz r11,0(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// extsb r9,r11
	ctx.r9.s64 = r11.s8;
	// cmpw cr6,r8,r9
	cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, xer);
	// bne cr6,0x82c96c38
	if (!cr6.eq) goto loc_82C96C38;
loc_82C96BF0:
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lbz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x82c96c38
	if (!cr6.eq) goto loc_82C96C38;
loc_82C96C08:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r11,r10,1
	r11.s64 = ctx.r10.s64 + 1;
	// lbz r6,0(r5)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r9,r5,1
	ctx.r9.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// bne cr6,0x82c96c38
	if (!cr6.eq) goto loc_82C96C38;
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// lbz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r5,r9,1
	ctx.r5.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// beq cr6,0x82c96b24
	if (cr6.eq) goto loc_82C96B24;
loc_82C96C38:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96C4C:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r11,r5,1
	r11.s64 = ctx.r5.s64 + 1;
	// extsb r6,r10
	ctx.r6.s64 = ctx.r10.s8;
	// cmpw cr6,r6,r8
	cr6.compare<int32_t>(ctx.r6.s32, ctx.r8.s32, xer);
	// bne cr6,0x82c96c38
	if (!cr6.eq) goto loc_82C96C38;
	// lbz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r10,r9,1
	ctx.r10.s64 = ctx.r9.s64 + 1;
	// lbz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r5,r11,1
	ctx.r5.s64 = r11.s64 + 1;
	// cmplw cr6,r6,r8
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, xer);
	// beq cr6,0x82c96b24
	if (cr6.eq) goto loc_82C96B24;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96C8C:
	// lbz r3,0(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c96ca8
	if (!cr6.eq) goto loc_82C96CA8;
	// lbz r11,1(r5)
	r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r7
	r11.u64 = r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c96cb0
	goto loc_82C96CB0;
loc_82C96CA8:
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C96CB0:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c96d38
	if (cr6.gt) goto loc_82C96D38;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,27860
	r12.s64 = r12.s64 + 27860;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C96C38;
	case 1:
		goto loc_82C96C38;
	case 2:
		goto loc_82C96C38;
	case 3:
		goto loc_82C96D38;
	case 4:
		goto loc_82C96D38;
	case 5:
		goto loc_82C96D38;
	case 6:
		goto loc_82C96D38;
	case 7:
		goto loc_82C96D38;
	case 8:
		goto loc_82C96D38;
	case 9:
		goto loc_82C96D38;
	case 10:
		goto loc_82C96D38;
	case 11:
		goto loc_82C96D38;
	case 12:
		goto loc_82C96D38;
	case 13:
		goto loc_82C96D38;
	case 14:
		goto loc_82C96D38;
	case 15:
		goto loc_82C96D38;
	case 16:
		goto loc_82C96D38;
	case 17:
		goto loc_82C96C38;
	case 18:
		goto loc_82C96C38;
	case 19:
		goto loc_82C96C38;
	case 20:
		goto loc_82C96C38;
	case 21:
		goto loc_82C96C38;
	case 22:
		goto loc_82C96C38;
	case 23:
		goto loc_82C96D38;
	case 24:
		goto loc_82C96C38;
	default:
		__builtin_unreachable();
	}
	// lwz r22,27704(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27704(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27960(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27704(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
loc_82C96D38:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C96B10) {
	__imp__sub_82C96B10(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C96D50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,0(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82c96d9c
	if (cr6.eq) goto loc_82C96D9C;
loc_82C96D60:
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c96dac
	if (cr6.eq) goto loc_82C96DAC;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c96dac
	if (!cr6.eq) goto loc_82C96DAC;
	// lbz r10,1(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// cmpw cr6,r9,r11
	cr6.compare<int32_t>(ctx.r9.s32, r11.s32, xer);
	// bne cr6,0x82c96dac
	if (!cr6.eq) goto loc_82C96DAC;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// lbz r11,0(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c96d60
	if (!cr6.eq) goto loc_82C96D60;
loc_82C96D9C:
	// subf r11,r4,r5
	r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r10,27,31,31
	ctx.r3.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// blr 
	return;
loc_82C96DAC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C96D50) {
	__imp__sub_82C96D50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C96DB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C96DD0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c96dec
	if (!cr6.eq) goto loc_82C96DEC;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c96df4
	goto loc_82C96DF4;
loc_82C96DEC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C96DF4:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bgt cr6,0x82c96e94
	if (cr6.gt) goto loc_82C96E94;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,28184
	r12.s64 = r12.s64 + 28184;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C96E7C;
	case 1:
		goto loc_82C96E84;
	case 2:
		goto loc_82C96E8C;
	case 3:
		goto loc_82C96E94;
	case 4:
		goto loc_82C96E94;
	case 5:
		goto loc_82C96E94;
	case 6:
		goto loc_82C96E94;
	case 7:
		goto loc_82C96E94;
	case 8:
		goto loc_82C96E94;
	case 9:
		goto loc_82C96E94;
	case 10:
		goto loc_82C96E94;
	case 11:
		goto loc_82C96E94;
	case 12:
		goto loc_82C96E94;
	case 13:
		goto loc_82C96E94;
	case 14:
		goto loc_82C96E94;
	case 15:
		goto loc_82C96E94;
	case 16:
		goto loc_82C96E94;
	case 17:
		goto loc_82C96E7C;
	case 18:
		goto loc_82C96E7C;
	case 19:
		goto loc_82C96E7C;
	case 20:
		goto loc_82C96E7C;
	case 21:
		goto loc_82C96E7C;
	case 22:
		goto loc_82C96E7C;
	case 23:
		goto loc_82C96E94;
	case 24:
		goto loc_82C96E7C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,28284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28292(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28292);
	// lwz r22,28300(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28300);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28308(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28284(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
loc_82C96E7C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c96dd0
	goto loc_82C96DD0;
loc_82C96E84:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c96dd0
	goto loc_82C96DD0;
loc_82C96E8C:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c96dd0
	goto loc_82C96DD0;
loc_82C96E94:
	// subf r3,r8,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r8.s64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C96DB8) {
	__imp__sub_82C96DB8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C96EA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C96EBC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c96ed8
	if (!cr6.eq) goto loc_82C96ED8;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c96ee0
	goto loc_82C96EE0;
loc_82C96ED8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C96EE0:
	// cmpwi cr6,r3,9
	cr6.compare<int32_t>(ctx.r3.s32, 9, xer);
	// blt cr6,0x82c96f00
	if (cr6.lt) goto loc_82C96F00;
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// ble cr6,0x82c96ef8
	if (!cr6.gt) goto loc_82C96EF8;
	// cmpwi cr6,r3,21
	cr6.compare<int32_t>(ctx.r3.s32, 21, xer);
	// bne cr6,0x82c96f00
	if (!cr6.eq) goto loc_82C96F00;
loc_82C96EF8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c96ebc
	goto loc_82C96EBC;
loc_82C96F00:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C96EA8) {
	__imp__sub_82C96EA8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C96F18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c96fd0
	if (cr6.eq) goto loc_82C96FD0;
	// li r9,-1
	ctx.r9.s64 = -1;
loc_82C96F38:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c96f54
	if (!cr6.eq) goto loc_82C96F54;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c96f5c
	goto loc_82C96F5C;
loc_82C96F54:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C96F5C:
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// bgt cr6,0x82c96fb8
	if (cr6.gt) goto loc_82C96FB8;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,28544
	r12.s64 = r12.s64 + 28544;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C96FB8;
	case 1:
		goto loc_82C96F98;
	case 2:
		goto loc_82C96FA0;
	case 3:
		goto loc_82C96FB8;
	case 4:
		goto loc_82C96FE0;
	case 5:
		goto loc_82C96FA8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,28600(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28600);
	// lwz r22,28568(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28568);
	// lwz r22,28576(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28576);
	// lwz r22,28600(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28600);
	// lwz r22,28640(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28640);
	// lwz r22,28584(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28584);
loc_82C96F98:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c96fbc
	goto loc_82C96FBC;
loc_82C96FA0:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c96fbc
	goto loc_82C96FBC;
loc_82C96FA8:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
loc_82C96FB8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C96FBC:
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, r11.u32);
	// bne cr6,0x82c96f38
	if (!cr6.eq) goto loc_82C96F38;
loc_82C96FD0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C96FE0:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// beq cr6,0x82c97028
	if (cr6.eq) goto loc_82C97028;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c97014
	if (!cr6.eq) goto loc_82C97014;
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 76);
	// b 0x82c9701c
	goto loc_82C9701C;
loc_82C97014:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	sub_82C8DAE8(ctx, base);
loc_82C9701C:
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bne cr6,0x82c97028
	if (!cr6.eq) goto loc_82C97028;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C97028:
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// b 0x82c96fbc
	goto loc_82C96FBC;
}

PPC_WEAK_FUNC(sub_82C96F18) {
	__imp__sub_82C96F18(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97030) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
loc_82C97030:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// lbz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// extsb r11,r10
	r11.s64 = ctx.r10.s8;
	// cmpwi cr6,r11,97
	cr6.compare<int32_t>(r11.s32, 97, xer);
	// blt cr6,0x82c9705c
	if (cr6.lt) goto loc_82C9705C;
	// cmpwi cr6,r11,122
	cr6.compare<int32_t>(r11.s32, 122, xer);
	// bgt cr6,0x82c9705c
	if (cr6.gt) goto loc_82C9705C;
	// addi r11,r11,-32
	r11.s64 = r11.s64 + -32;
	// extsb r10,r11
	ctx.r10.s64 = r11.s8;
loc_82C9705C:
	// extsb r11,r9
	r11.s64 = ctx.r9.s8;
	// cmpwi cr6,r11,97
	cr6.compare<int32_t>(r11.s32, 97, xer);
	// blt cr6,0x82c97078
	if (cr6.lt) goto loc_82C97078;
	// cmpwi cr6,r11,122
	cr6.compare<int32_t>(r11.s32, 122, xer);
	// bgt cr6,0x82c97078
	if (cr6.gt) goto loc_82C97078;
	// addi r11,r11,-32
	r11.s64 = r11.s64 + -32;
	// extsb r9,r11
	ctx.r9.s64 = r11.s8;
loc_82C97078:
	// extsb r11,r10
	r11.s64 = ctx.r10.s8;
	// extsb r10,r9
	ctx.r10.s64 = ctx.r9.s8;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82c97098
	if (!cr6.eq) goto loc_82C97098;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c97030
	if (!cr6.eq) goto loc_82C97030;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C97098:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C97030) {
	__imp__sub_82C97030(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C970A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r3,r11,-1976
	ctx.r3.s64 = r11.s64 + -1976;
	// b 0x82c8d750
	// ERROR 82C8D750
	return;
}

PPC_WEAK_FUNC(sub_82C970A0) {
	__imp__sub_82C970A0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C970B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// stw r4,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r4.u32);
	// lwz r10,60(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	// addi r7,r1,81
	ctx.r7.s64 = ctx.r1.s64 + 81;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// bne cr6,0x82c97104
	if (!cr6.eq) goto loc_82C97104;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C97104:
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C970B0) {
	__imp__sub_82C970B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97120) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	// addi r11,r3,-9
	r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,23
	cr6.compare<uint32_t>(r11.u32, 23, xer);
	// bgt cr6,0x82c971ac
	if (cr6.gt) goto loc_82C971AC;
	// lis r12,-32055
	r12.s64 = -2100756480;
	// addi r12,r12,28996
	r12.s64 = r12.s64 + 28996;
	// rlwinm r0,r11,2,0,29
	r0.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82C971A4;
	case 1:
		goto loc_82C971A4;
	case 2:
		goto loc_82C971AC;
	case 3:
		goto loc_82C971AC;
	case 4:
		goto loc_82C971A4;
	case 5:
		goto loc_82C971AC;
	case 6:
		goto loc_82C971AC;
	case 7:
		goto loc_82C971AC;
	case 8:
		goto loc_82C971AC;
	case 9:
		goto loc_82C971AC;
	case 10:
		goto loc_82C971AC;
	case 11:
		goto loc_82C971AC;
	case 12:
		goto loc_82C971AC;
	case 13:
		goto loc_82C971AC;
	case 14:
		goto loc_82C971AC;
	case 15:
		goto loc_82C971AC;
	case 16:
		goto loc_82C971AC;
	case 17:
		goto loc_82C971AC;
	case 18:
		goto loc_82C971AC;
	case 19:
		goto loc_82C971AC;
	case 20:
		goto loc_82C971AC;
	case 21:
		goto loc_82C971AC;
	case 22:
		goto loc_82C971AC;
	case 23:
		goto loc_82C971A4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,29092(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29092);
	// lwz r22,29092(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29092);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29092(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29092);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29092(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29092);
loc_82C971A4:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C971AC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C97120) {
	__imp__sub_82C97120(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C971B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bdc
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// mr r26,r8
	r26.u64 = ctx.r8.u64;
	// mr r25,r9
	r25.u64 = ctx.r9.u64;
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// bne cr6,0x82c971fc
	if (!cr6.eq) goto loc_82C971FC;
loc_82C971E8:
	// li r11,0
	r11.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c2c
	return;
loc_82C971FC:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c970b0
	sub_82C970B0(ctx, base);
	// bl 0x82c97120
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c97444
	if (cr6.eq) goto loc_82C97444;
loc_82C97218:
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lwz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// addi r7,r1,81
	ctx.r7.s64 = ctx.r1.s64 + 81;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r30.u32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// cmplw cr6,r7,r8
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, xer);
	// bne cr6,0x82c97264
	if (!cr6.eq) goto loc_82C97264;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c9726c
	goto loc_82C9726C;
loc_82C97264:
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
loc_82C9726C:
	// bl 0x82c97120
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c97218
	if (!cr6.eq) goto loc_82C97218;
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// beq cr6,0x82c971e8
	if (cr6.eq) goto loc_82C971E8;
	// stw r30,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r30.u32);
loc_82C97284:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r30.u32);
	// addi r7,r1,81
	ctx.r7.s64 = ctx.r1.s64 + 81;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x82c97444
	if (cr6.eq) goto loc_82C97444;
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82c97444
	if (cr6.eq) goto loc_82C97444;
	// cmpwi cr6,r3,61
	cr6.compare<int32_t>(ctx.r3.s32, 61, xer);
	// beq cr6,0x82c972f0
	if (cr6.eq) goto loc_82C972F0;
	// bl 0x82c97120
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c972f8
	if (!cr6.eq) goto loc_82C972F8;
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// b 0x82c97284
	goto loc_82C97284;
loc_82C972F0:
	// stw r30,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r30.u32);
	// b 0x82c9732c
	goto loc_82C9732C;
loc_82C972F8:
	// stw r30,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r30.u32);
loc_82C972FC:
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82c970b0
	sub_82C970B0(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// bl 0x82c97120
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c972fc
	if (!cr6.eq) goto loc_82C972FC;
	// cmpwi cr6,r10,61
	cr6.compare<int32_t>(ctx.r10.s32, 61, xer);
	// bne cr6,0x82c97444
	if (!cr6.eq) goto loc_82C97444;
loc_82C9732C:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// beq cr6,0x82c97444
	if (cr6.eq) goto loc_82C97444;
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82c970b0
	sub_82C970B0(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// bl 0x82c97120
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c97388
	if (cr6.eq) goto loc_82C97388;
loc_82C97360:
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82c970b0
	sub_82C970B0(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// bl 0x82c97120
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c97360
	if (!cr6.eq) goto loc_82C97360;
loc_82C97388:
	// cmpwi cr6,r10,34
	cr6.compare<int32_t>(ctx.r10.s32, 34, xer);
	// beq cr6,0x82c97398
	if (cr6.eq) goto loc_82C97398;
	// cmpwi cr6,r10,39
	cr6.compare<int32_t>(ctx.r10.s32, 39, xer);
	// bne cr6,0x82c97444
	if (!cr6.eq) goto loc_82C97444;
loc_82C97398:
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
	// stw r30,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r30.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82c970b0
	sub_82C970B0(ctx, base);
	// extsb r28,r28
	r28.s64 = r28.s8;
	// cmpw cr6,r3,r28
	cr6.compare<int32_t>(ctx.r3.s32, r28.s32, xer);
	// beq cr6,0x82c9742c
	if (cr6.eq) goto loc_82C9742C;
loc_82C973C4:
	// cmpwi cr6,r3,97
	cr6.compare<int32_t>(ctx.r3.s32, 97, xer);
	// blt cr6,0x82c973d4
	if (cr6.lt) goto loc_82C973D4;
	// cmpwi cr6,r3,122
	cr6.compare<int32_t>(ctx.r3.s32, 122, xer);
	// ble cr6,0x82c9740c
	if (!cr6.gt) goto loc_82C9740C;
loc_82C973D4:
	// cmpwi cr6,r3,65
	cr6.compare<int32_t>(ctx.r3.s32, 65, xer);
	// blt cr6,0x82c973e4
	if (cr6.lt) goto loc_82C973E4;
	// cmpwi cr6,r3,90
	cr6.compare<int32_t>(ctx.r3.s32, 90, xer);
	// ble cr6,0x82c9740c
	if (!cr6.gt) goto loc_82C9740C;
loc_82C973E4:
	// cmpwi cr6,r3,48
	cr6.compare<int32_t>(ctx.r3.s32, 48, xer);
	// blt cr6,0x82c973f4
	if (cr6.lt) goto loc_82C973F4;
	// cmpwi cr6,r3,57
	cr6.compare<int32_t>(ctx.r3.s32, 57, xer);
	// ble cr6,0x82c9740c
	if (!cr6.gt) goto loc_82C9740C;
loc_82C973F4:
	// cmpwi cr6,r3,46
	cr6.compare<int32_t>(ctx.r3.s32, 46, xer);
	// beq cr6,0x82c9740c
	if (cr6.eq) goto loc_82C9740C;
	// cmpwi cr6,r3,45
	cr6.compare<int32_t>(ctx.r3.s32, 45, xer);
	// beq cr6,0x82c9740c
	if (cr6.eq) goto loc_82C9740C;
	// cmpwi cr6,r3,95
	cr6.compare<int32_t>(ctx.r3.s32, 95, xer);
	// bne cr6,0x82c97444
	if (!cr6.eq) goto loc_82C97444;
loc_82C9740C:
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82c970b0
	sub_82C970B0(ctx, base);
	// cmpw cr6,r3,r28
	cr6.compare<int32_t>(ctx.r3.s32, r28.s32, xer);
	// bne cr6,0x82c973c4
	if (!cr6.eq) goto loc_82C973C4;
loc_82C9742C:
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// li r3,1
	ctx.r3.s64 = 1;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c2c
	return;
loc_82C97444:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r30.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c2c
	return;
}

PPC_WEAK_FUNC(sub_82C971B8) {
	__imp__sub_82C971B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97458) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd0
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r24,0
	r24.s64 = 0;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// stw r24,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r24.u32);
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
	// mr r22,r8
	r22.u64 = ctx.r8.u64;
	// stw r24,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r24.u32);
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// stw r24,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r24.u32);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// mr r29,r9
	r29.u64 = ctx.r9.u64;
	// addi r9,r1,236
	ctx.r9.s64 = ctx.r1.s64 + 236;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r11,1,0,30
	ctx.r8.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// subf r27,r8,r7
	r27.s64 = ctx.r7.s64 - ctx.r8.s64;
	// add r4,r11,r6
	ctx.r4.u64 = r11.u64 + ctx.r6.u64;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// stw r4,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, ctx.r4.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x82c971b8
	sub_82C971B8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c97778
	if (cr6.eq) goto loc_82C97778;
	// lwz r30,80(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c97778
	if (cr6.eq) goto loc_82C97778;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r26,r11,2860
	r26.s64 = r11.s64 + 2860;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r6,r26,-36
	ctx.r6.s64 = r26.s64 + -36;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c9751c
	if (!cr6.eq) goto loc_82C9751C;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x82c97580
	if (!cr6.eq) goto loc_82C97580;
loc_82C9750C:
	// stw r30,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r30.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	return;
loc_82C9751C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82c9752c
	if (cr6.eq) goto loc_82C9752C;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_82C9752C:
	// lwz r4,236(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82c9753c
	if (cr6.eq) goto loc_82C9753C;
	// stw r4,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r4.u32);
loc_82C9753C:
	// addi r9,r1,236
	ctx.r9.s64 = ctx.r1.s64 + 236;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c971b8
	sub_82C971B8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c97778
	if (cr6.eq) goto loc_82C97778;
	// lwz r30,80(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82c97580
	if (!cr6.eq) goto loc_82C97580;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x82c97778
	if (!cr6.eq) goto loc_82C97778;
loc_82C97574:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	return;
loc_82C97580:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// addi r6,r26,-28
	ctx.r6.s64 = r26.s64 + -28;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c97664
	if (cr6.eq) goto loc_82C97664;
	// lwz r28,88(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82c970b0
	sub_82C970B0(ctx, base);
	// cmpwi cr6,r3,97
	cr6.compare<int32_t>(ctx.r3.s32, 97, xer);
	// blt cr6,0x82c975c8
	if (cr6.lt) goto loc_82C975C8;
	// cmpwi cr6,r3,122
	cr6.compare<int32_t>(ctx.r3.s32, 122, xer);
	// ble cr6,0x82c975d8
	if (!cr6.gt) goto loc_82C975D8;
loc_82C975C8:
	// cmpwi cr6,r3,65
	cr6.compare<int32_t>(ctx.r3.s32, 65, xer);
	// blt cr6,0x82c97654
	if (cr6.lt) goto loc_82C97654;
	// cmpwi cr6,r3,90
	cr6.compare<int32_t>(ctx.r3.s32, 90, xer);
	// bgt cr6,0x82c97654
	if (cr6.gt) goto loc_82C97654;
loc_82C975D8:
	// lwz r11,276(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c975e8
	if (cr6.eq) goto loc_82C975E8;
	// stw r28,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r28.u32);
loc_82C975E8:
	// lwz r29,284(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// lwz r30,236(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82c97614
	if (cr6.eq) goto loc_82C97614;
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// subf r5,r11,r30
	ctx.r5.s64 = r30.s64 - r11.s64;
	// mtctr r25
	ctr.u64 = r25.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r3.u32);
loc_82C97614:
	// addi r9,r1,236
	ctx.r9.s64 = ctx.r1.s64 + 236;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c971b8
	sub_82C971B8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c97778
	if (cr6.eq) goto loc_82C97778;
	// lwz r30,80(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82c97664
	if (!cr6.eq) goto loc_82C97664;
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	return;
loc_82C97654:
	// stw r28,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r28.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	return;
loc_82C97664:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// addi r6,r26,-16
	ctx.r6.s64 = r26.s64 + -16;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c9750c
	if (cr6.eq) goto loc_82C9750C;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x82c9750c
	if (!cr6.eq) goto loc_82C9750C;
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// addi r6,r26,-4
	ctx.r6.s64 = r26.s64 + -4;
	// lwz r30,236(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r29,88(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// subf r5,r11,r30
	ctx.r5.s64 = r30.s64 - r11.s64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c976d8
	if (cr6.eq) goto loc_82C976D8;
	// lwz r11,292(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c97710
	if (cr6.eq) goto loc_82C97710;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x82c97710
	goto loc_82C97710;
loc_82C976D8:
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// subf r5,r11,r30
	ctx.r5.s64 = r30.s64 - r11.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c97768
	if (cr6.eq) goto loc_82C97768;
	// lwz r11,292(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c97710
	if (cr6.eq) goto loc_82C97710;
	// stw r24,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r24.u32);
loc_82C97710:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c970b0
	sub_82C970B0(ctx, base);
	// bl 0x82c97120
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c97750
	if (cr6.eq) goto loc_82C97750;
loc_82C9772C:
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r30,r30,r11
	r30.u64 = r30.u64 + r11.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82c970b0
	sub_82C970B0(ctx, base);
	// bl 0x82c97120
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c9772c
	if (!cr6.eq) goto loc_82C9772C;
loc_82C97750:
	// cmplw cr6,r30,r27
	cr6.compare<uint32_t>(r30.u32, r27.u32, xer);
	// beq cr6,0x82c97574
	if (cr6.eq) goto loc_82C97574;
	// stw r30,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r30.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	return;
loc_82C97768:
	// stw r29,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r29.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	return;
loc_82C97778:
	// lwz r11,236(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r11.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	return;
}

PPC_WEAK_FUNC(sub_82C97458) {
	__imp__sub_82C97458(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97790) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82c97870
	if (cr6.lt) goto loc_82C97870;
	// cmpwi cr6,r3,128
	cr6.compare<int32_t>(ctx.r3.s32, 128, xer);
	// bge cr6,0x82c977b0
	if (!cr6.lt) goto loc_82C977B0;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, r11.u8);
	// blr 
	return;
loc_82C977B0:
	// cmpwi cr6,r3,2048
	cr6.compare<int32_t>(ctx.r3.s32, 2048, xer);
	// bge cr6,0x82c977e4
	if (!cr6.lt) goto loc_82C977E4;
	// lis r11,511
	r11.s64 = 33488896;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// srawi r8,r3,6
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x3F) != 0);
	ctx.r8.s64 = ctx.r3.s32 >> 6;
	// ori r9,r11,65535
	ctx.r9.u64 = r11.u64 | 65535;
	// li r7,-64
	ctx.r7.s64 = -64;
	// rlwimi r10,r9,7,0,25
	ctx.r10.u64 = (rotl32(ctx.r9.u32, 7) & 0xFFFFFFC0) | (ctx.r10.u64 & 0xFFFFFFFF0000003F);
	// or r6,r8,r7
	ctx.r6.u64 = ctx.r8.u64 | ctx.r7.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// stb r10,1(r4)
	PPC_STORE_U8(ctx.r4.u32 + 1, ctx.r10.u8);
	// stb r6,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r6.u8);
	// blr 
	return;
loc_82C977E4:
	// lis r11,1
	r11.s64 = 65536;
	// cmpw cr6,r3,r11
	cr6.compare<int32_t>(ctx.r3.s32, r11.s32, xer);
	// bge cr6,0x82c97824
	if (!cr6.lt) goto loc_82C97824;
	// lis r11,511
	r11.s64 = 33488896;
	// srawi r10,r3,12
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0xFFF) != 0);
	ctx.r10.s64 = ctx.r3.s32 >> 12;
	// ori r11,r11,65535
	r11.u64 = r11.u64 | 65535;
	// srawi r9,r3,6
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x3F) != 0);
	ctx.r9.s64 = ctx.r3.s32 >> 6;
	// li r8,-32
	ctx.r8.s64 = -32;
	// rlwimi r3,r11,7,0,25
	ctx.r3.u64 = (rotl32(r11.u32, 7) & 0xFFFFFFC0) | (ctx.r3.u64 & 0xFFFFFFFF0000003F);
	// rlwimi r9,r11,7,0,25
	ctx.r9.u64 = (rotl32(r11.u32, 7) & 0xFFFFFFC0) | (ctx.r9.u64 & 0xFFFFFFFF0000003F);
	// or r7,r10,r8
	ctx.r7.u64 = ctx.r10.u64 | ctx.r8.u64;
	// stb r3,2(r4)
	PPC_STORE_U8(ctx.r4.u32 + 2, ctx.r3.u8);
	// li r3,3
	ctx.r3.s64 = 3;
	// stb r9,1(r4)
	PPC_STORE_U8(ctx.r4.u32 + 1, ctx.r9.u8);
	// stb r7,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r7.u8);
	// blr 
	return;
loc_82C97824:
	// lis r11,17
	r11.s64 = 1114112;
	// cmpw cr6,r3,r11
	cr6.compare<int32_t>(ctx.r3.s32, r11.s32, xer);
	// bge cr6,0x82c97870
	if (!cr6.lt) goto loc_82C97870;
	// lis r11,511
	r11.s64 = 33488896;
	// srawi r10,r3,18
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x3FFFF) != 0);
	ctx.r10.s64 = ctx.r3.s32 >> 18;
	// srawi r9,r3,12
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0xFFF) != 0);
	ctx.r9.s64 = ctx.r3.s32 >> 12;
	// ori r11,r11,65535
	r11.u64 = r11.u64 | 65535;
	// srawi r8,r3,6
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x3F) != 0);
	ctx.r8.s64 = ctx.r3.s32 >> 6;
	// li r7,-16
	ctx.r7.s64 = -16;
	// rlwimi r3,r11,7,0,25
	ctx.r3.u64 = (rotl32(r11.u32, 7) & 0xFFFFFFC0) | (ctx.r3.u64 & 0xFFFFFFFF0000003F);
	// rlwimi r9,r11,7,0,25
	ctx.r9.u64 = (rotl32(r11.u32, 7) & 0xFFFFFFC0) | (ctx.r9.u64 & 0xFFFFFFFF0000003F);
	// rlwimi r8,r11,7,0,25
	ctx.r8.u64 = (rotl32(r11.u32, 7) & 0xFFFFFFC0) | (ctx.r8.u64 & 0xFFFFFFFF0000003F);
	// stb r3,3(r4)
	PPC_STORE_U8(ctx.r4.u32 + 3, ctx.r3.u8);
	// or r6,r10,r7
	ctx.r6.u64 = ctx.r10.u64 | ctx.r7.u64;
	// stb r9,1(r4)
	PPC_STORE_U8(ctx.r4.u32 + 1, ctx.r9.u8);
	// li r3,4
	ctx.r3.s64 = 4;
	// stb r8,2(r4)
	PPC_STORE_U8(ctx.r4.u32 + 2, ctx.r8.u8);
	// stb r6,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r6.u8);
	// blr 
	return;
loc_82C97870:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C97790) {
	__imp__sub_82C97790(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97878) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r3,372(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 372);
	// lwz r10,368(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 368);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// rlwinm r9,r3,0,0,15
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFF0000;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x82c978b8
	if (cr6.eq) goto loc_82C978B8;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C978B8:
	// lis r11,-32255
	r11.s64 = -2113863680;
	// srawi r9,r3,8
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0xFF) != 0);
	ctx.r9.s64 = ctx.r3.s32 >> 8;
	// addi r11,r11,-4144
	r11.s64 = r11.s64 + -4144;
	// srawi r8,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	ctx.r8.s64 = ctx.r3.s32 >> 5;
	// addi r7,r11,1536
	ctx.r7.s64 = r11.s64 + 1536;
	// clrlwi r10,r8,29
	ctx.r10.u64 = ctx.r8.u32 & 0x7;
	// clrlwi r6,r3,27
	ctx.r6.u64 = ctx.r3.u32 & 0x1F;
	// li r5,1
	ctx.r5.s64 = 1;
	// lbzx r4,r9,r7
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r7.u32);
	// slw r3,r5,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r6.u8 & 0x3F));
	// rotlwi r9,r4,3
	ctx.r9.u64 = rotl32(ctx.r4.u32, 3);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// and r3,r8,r3
	ctx.r3.u64 = ctx.r8.u64 & ctx.r3.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C97878) {
	__imp__sub_82C97878(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97908) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r3,372(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 372);
	// lwz r10,368(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 368);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// rlwinm r9,r3,0,0,15
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFF0000;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x82c97948
	if (cr6.eq) goto loc_82C97948;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C97948:
	// lis r11,-32255
	r11.s64 = -2113863680;
	// srawi r9,r3,8
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0xFF) != 0);
	ctx.r9.s64 = ctx.r3.s32 >> 8;
	// addi r11,r11,-4144
	r11.s64 = r11.s64 + -4144;
	// srawi r8,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	ctx.r8.s64 = ctx.r3.s32 >> 5;
	// addi r7,r11,1280
	ctx.r7.s64 = r11.s64 + 1280;
	// clrlwi r10,r8,29
	ctx.r10.u64 = ctx.r8.u32 & 0x7;
	// clrlwi r6,r3,27
	ctx.r6.u64 = ctx.r3.u32 & 0x1F;
	// li r5,1
	ctx.r5.s64 = 1;
	// lbzx r4,r9,r7
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r7.u32);
	// slw r3,r5,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r6.u8 & 0x3F));
	// rotlwi r9,r4,3
	ctx.r9.u64 = rotl32(ctx.r4.u32, 3);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// and r3,r8,r3
	ctx.r3.u64 = ctx.r8.u64 & ctx.r3.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C97908) {
	__imp__sub_82C97908(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97998) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r3,372(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 372);
	// lwz r10,368(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 368);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// rlwinm r9,r3,0,0,15
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFF0000;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82c97a1c
	if (!cr6.eq) goto loc_82C97A1C;
	// srawi r11,r3,8
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0xFF) != 0);
	r11.s64 = ctx.r3.s32 >> 8;
	// cmpwi cr6,r11,223
	cr6.compare<int32_t>(r11.s32, 223, xer);
	// bgt cr6,0x82c979f8
	if (cr6.gt) goto loc_82C979F8;
	// cmpwi cr6,r11,216
	cr6.compare<int32_t>(r11.s32, 216, xer);
	// bge cr6,0x82c97a1c
	if (!cr6.lt) goto loc_82C97A1C;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c97a10
	if (!cr6.eq) goto loc_82C97A10;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r11,r11,-504
	r11.s64 = r11.s64 + -504;
	// addi r10,r11,76
	ctx.r10.s64 = r11.s64 + 76;
	// lbzx r9,r3,r10
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// b 0x82c97a0c
	goto loc_82C97A0C;
loc_82C979F8:
	// cmpwi cr6,r11,255
	cr6.compare<int32_t>(r11.s32, 255, xer);
	// bne cr6,0x82c97a10
	if (!cr6.eq) goto loc_82C97A10;
	// cmplwi cr6,r3,65534
	cr6.compare<uint32_t>(ctx.r3.u32, 65534, xer);
	// beq cr6,0x82c97a1c
	if (cr6.eq) goto loc_82C97A1C;
	// cmplwi cr6,r3,65535
	cr6.compare<uint32_t>(ctx.r3.u32, 65535, xer);
loc_82C97A0C:
	// beq cr6,0x82c97a1c
	if (cr6.eq) goto loc_82C97A1C;
loc_82C97A10:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// bge cr6,0x82c97a20
	if (!cr6.lt) goto loc_82C97A20;
loc_82C97A1C:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82C97A20:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C97998) {
	__imp__sub_82C97998(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97A30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// beq cr6,0x82c97b1c
	if (cr6.eq) goto loc_82C97B1C;
loc_82C97A5C:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// addi r11,r11,222
	r11.s64 = r11.s64 + 222;
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// extsb r3,r10
	ctx.r3.s64 = ctx.r10.s8;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c97ad4
	if (!cr6.eq) goto loc_82C97AD4;
	// lwz r3,372(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 372);
	// addi r26,r1,80
	r26.s64 = ctx.r1.s64 + 80;
	// lwz r11,368(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 368);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x82c97790
	sub_82C97790(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// subf r9,r10,r28
	ctx.r9.s64 = r28.s64 - ctx.r10.s64;
	// cmpw cr6,r3,r9
	cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, xer);
	// bgt cr6,0x82c97b1c
	if (cr6.gt) goto loc_82C97B1C;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 + r29.u64;
	// lbz r9,76(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 76);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// addi r8,r10,-3
	ctx.r8.s64 = ctx.r10.s64 + -3;
	// stw r8,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r8.u32);
	// b 0x82c97aec
	goto loc_82C97AEC;
loc_82C97AD4:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// subf r9,r10,r28
	ctx.r9.s64 = r28.s64 - ctx.r10.s64;
	// cmpw cr6,r3,r9
	cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, xer);
	// bgt cr6,0x82c97b1c
	if (cr6.gt) goto loc_82C97B1C;
	// addi r10,r4,1
	ctx.r10.s64 = ctx.r4.s64 + 1;
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
loc_82C97AEC:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stb r10,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r10.u8);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stw r8,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r8.u32);
	// bne 0x82c97aec
	if (!cr0.eq) goto loc_82C97AEC;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bne cr6,0x82c97a5c
	if (!cr6.eq) goto loc_82C97A5C;
loc_82C97B1C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C97A30) {
	__imp__sub_82C97A30(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97B28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x82c97bd8
	if (cr6.eq) goto loc_82C97BD8;
loc_82C97B54:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// beq cr6,0x82c97bd8
	if (cr6.eq) goto loc_82C97BD8;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// addi r11,r11,188
	r11.s64 = r11.s64 + 188;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r10,r10,r30
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + r30.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c97bb0
	if (!cr6.eq) goto loc_82C97BB0;
	// lwz r3,372(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 372);
	// lwz r11,368(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 368);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// clrlwi r10,r3,16
	ctx.r10.u64 = ctx.r3.u32 & 0xFFFF;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// add r9,r9,r30
	ctx.r9.u64 = ctx.r9.u64 + r30.u64;
	// lbz r9,76(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 76);
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// addi r8,r11,-3
	ctx.r8.s64 = r11.s64 + -3;
	// stw r8,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r8.u32);
	// b 0x82c97bb8
	goto loc_82C97BB8;
loc_82C97BB0:
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82C97BB8:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// sth r10,0(r11)
	PPC_STORE_U16(r11.u32 + 0, ctx.r10.u16);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// addi r10,r11,2
	ctx.r10.s64 = r11.s64 + 2;
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplw cr6,r9,r28
	cr6.compare<uint32_t>(ctx.r9.u32, r28.u32, xer);
	// bne cr6,0x82c97b54
	if (!cr6.eq) goto loc_82C97B54;
loc_82C97BD8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C97B28) {
	__imp__sub_82C97B28(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97BE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bc0
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r24,r10,-4144
	r24.s64 = ctx.r10.s64 + -4144;
	// mr r18,r6
	r18.u64 = ctx.r6.u64;
	// addi r9,r24,3640
	ctx.r9.s64 = r24.s64 + 3640;
	// mr r11,r28
	r11.u64 = r28.u64;
	// li r10,368
	ctx.r10.s64 = 368;
	// subf r9,r28,r9
	ctx.r9.s64 = ctx.r9.s64 - r28.s64;
loc_82C97C0C:
	// lbzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stb r8,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r8.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne 0x82c97c0c
	if (!cr0.eq) goto loc_82C97C0C;
	// li r23,0
	r23.s64 = 0;
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
	// mr r11,r23
	r11.u64 = r23.u64;
loc_82C97C2C:
	// addi r10,r24,3640
	ctx.r10.s64 = r24.s64 + 3640;
	// addi r10,r10,76
	ctx.r10.s64 = ctx.r10.s64 + 76;
	// lbzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r10,28
	cr6.compare<uint32_t>(ctx.r10.u32, 28, xer);
	// beq cr6,0x82c97c54
	if (cr6.eq) goto loc_82C97C54;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c97c54
	if (cr6.eq) goto loc_82C97C54;
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// bne cr6,0x82c97cb0
	if (!cr6.eq) goto loc_82C97CB0;
loc_82C97C54:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmpwi cr6,r11,128
	cr6.compare<int32_t>(r11.s32, 128, xer);
	// blt cr6,0x82c97c2c
	if (cr6.lt) goto loc_82C97C2C;
	// lis r11,0
	r11.s64 = 0;
	// mr r29,r23
	r29.u64 = r23.u64;
	// mr r22,r4
	r22.u64 = ctx.r4.u64;
	// addi r27,r28,376
	r27.s64 = r28.s64 + 376;
	// addi r30,r28,888
	r30.s64 = r28.s64 + 888;
	// li r26,1
	r26.s64 = 1;
	// ori r25,r11,65535
	r25.u64 = r11.u64 | 65535;
	// li r19,22
	r19.s64 = 22;
	// li r20,26
	r20.s64 = 26;
	// li r21,28
	r21.s64 = 28;
loc_82C97C8C:
	// lwz r31,0(r22)
	r31.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// bne cr6,0x82c97cbc
	if (!cr6.eq) goto loc_82C97CBC;
	// add r11,r29,r28
	r11.u64 = r29.u64 + r28.u64;
	// stb r26,76(r11)
	PPC_STORE_U8(r11.u32 + 76, r26.u8);
	// sth r25,0(r27)
	PPC_STORE_U16(r27.u32 + 0, r25.u16);
	// stb r26,0(r30)
	PPC_STORE_U8(r30.u32 + 0, r26.u8);
	// stb r23,1(r30)
	PPC_STORE_U8(r30.u32 + 1, r23.u8);
	// b 0x82c97e24
	goto loc_82C97E24;
loc_82C97CB0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c10
	return;
loc_82C97CBC:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bge cr6,0x82c97ce4
	if (!cr6.lt) goto loc_82C97CE4;
	// cmpwi cr6,r31,-4
	cr6.compare<int32_t>(r31.s32, -4, xer);
	// blt cr6,0x82c97cb0
	if (cr6.lt) goto loc_82C97CB0;
	// add r10,r29,r28
	ctx.r10.u64 = r29.u64 + r28.u64;
	// subfic r11,r31,3
	xer.ca = r31.u32 <= 3;
	r11.s64 = 3 - r31.s64;
	// stb r11,76(r10)
	PPC_STORE_U8(ctx.r10.u32 + 76, r11.u8);
	// stb r23,0(r30)
	PPC_STORE_U8(r30.u32 + 0, r23.u8);
	// sth r23,0(r27)
	PPC_STORE_U16(r27.u32 + 0, r23.u16);
	// b 0x82c97e24
	goto loc_82C97E24;
loc_82C97CE4:
	// cmpwi cr6,r31,128
	cr6.compare<int32_t>(r31.s32, 128, xer);
	// bge cr6,0x82c97d34
	if (!cr6.lt) goto loc_82C97D34;
	// addi r11,r24,3640
	r11.s64 = r24.s64 + 3640;
	// addi r11,r11,76
	r11.s64 = r11.s64 + 76;
	// lbzx r11,r31,r11
	r11.u64 = PPC_LOAD_U8(r31.u32 + r11.u32);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// cmplwi cr6,r10,28
	cr6.compare<uint32_t>(ctx.r10.u32, 28, xer);
	// beq cr6,0x82c97d14
	if (cr6.eq) goto loc_82C97D14;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c97d14
	if (cr6.eq) goto loc_82C97D14;
	// cmpw cr6,r31,r29
	cr6.compare<int32_t>(r31.s32, r29.s32, xer);
	// bne cr6,0x82c97cb0
	if (!cr6.eq) goto loc_82C97CB0;
loc_82C97D14:
	// add r10,r29,r28
	ctx.r10.u64 = r29.u64 + r28.u64;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// stb r11,76(r10)
	PPC_STORE_U8(ctx.r10.u32 + 76, r11.u8);
	// stb r26,0(r30)
	PPC_STORE_U8(r30.u32 + 0, r26.u8);
	// stb r31,1(r30)
	PPC_STORE_U8(r30.u32 + 1, r31.u8);
	// bne cr6,0x82c97e20
	if (!cr6.eq) goto loc_82C97E20;
	// mr r31,r25
	r31.u64 = r25.u64;
	// b 0x82c97e20
	goto loc_82C97E20;
loc_82C97D34:
	// srawi r8,r31,8
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0xFF) != 0);
	ctx.r8.s64 = r31.s32 >> 8;
	// cmpwi cr6,r8,223
	cr6.compare<int32_t>(ctx.r8.s32, 223, xer);
	// bgt cr6,0x82c97dac
	if (cr6.gt) goto loc_82C97DAC;
	// cmpwi cr6,r8,216
	cr6.compare<int32_t>(ctx.r8.s32, 216, xer);
	// bge cr6,0x82c97dc4
	if (!cr6.lt) goto loc_82C97DC4;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x82c97d64
	if (!cr6.eq) goto loc_82C97D64;
	// addi r11,r24,3640
	r11.s64 = r24.s64 + 3640;
	// addi r11,r11,76
	r11.s64 = r11.s64 + 76;
	// lbzx r10,r31,r11
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c97dc4
	if (cr6.eq) goto loc_82C97DC4;
loc_82C97D64:
	// cmpw cr6,r31,r25
	cr6.compare<int32_t>(r31.s32, r25.s32, xer);
	// bgt cr6,0x82c97cb0
	if (cr6.gt) goto loc_82C97CB0;
	// addi r9,r24,1280
	ctx.r9.s64 = r24.s64 + 1280;
	// srawi r7,r31,5
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x1F) != 0);
	ctx.r7.s64 = r31.s32 >> 5;
	// clrlwi r6,r31,27
	ctx.r6.u64 = r31.u32 & 0x1F;
	// clrlwi r11,r7,29
	r11.u64 = ctx.r7.u32 & 0x7;
	// slw r10,r26,r6
	ctx.r10.u64 = ctx.r6.u8 & 0x20 ? 0 : (r26.u32 << (ctx.r6.u8 & 0x3F));
	// lbzx r4,r8,r9
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r9.u32);
	// rotlwi r9,r4,3
	ctx.r9.u64 = rotl32(ctx.r4.u32, 3);
	// add r3,r9,r11
	ctx.r3.u64 = ctx.r9.u64 + r11.u64;
	// rlwinm r9,r3,2,0,29
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r24
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r24.u32);
	// and r6,r7,r10
	ctx.r6.u64 = ctx.r7.u64 & ctx.r10.u64;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x82c97ddc
	if (cr6.eq) goto loc_82C97DDC;
	// add r11,r29,r28
	r11.u64 = r29.u64 + r28.u64;
	// stb r19,76(r11)
	PPC_STORE_U8(r11.u32 + 76, r19.u8);
	// b 0x82c97e10
	goto loc_82C97E10;
loc_82C97DAC:
	// cmpwi cr6,r8,255
	cr6.compare<int32_t>(ctx.r8.s32, 255, xer);
	// bne cr6,0x82c97d64
	if (!cr6.eq) goto loc_82C97D64;
	// cmplwi cr6,r31,65534
	cr6.compare<uint32_t>(r31.u32, 65534, xer);
	// beq cr6,0x82c97dc4
	if (cr6.eq) goto loc_82C97DC4;
	// cmplwi cr6,r31,65535
	cr6.compare<uint32_t>(r31.u32, 65535, xer);
	// bne cr6,0x82c97d64
	if (!cr6.eq) goto loc_82C97D64;
loc_82C97DC4:
	// add r11,r29,r28
	r11.u64 = r29.u64 + r28.u64;
	// stb r23,76(r11)
	PPC_STORE_U8(r11.u32 + 76, r23.u8);
	// sth r25,0(r27)
	PPC_STORE_U16(r27.u32 + 0, r25.u16);
	// stb r26,0(r30)
	PPC_STORE_U8(r30.u32 + 0, r26.u8);
	// stb r23,1(r30)
	PPC_STORE_U8(r30.u32 + 1, r23.u8);
	// b 0x82c97e24
	goto loc_82C97E24;
loc_82C97DDC:
	// addi r9,r24,1536
	ctx.r9.s64 = r24.s64 + 1536;
	// lbzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r9.u32);
	// rotlwi r9,r8,3
	ctx.r9.u64 = rotl32(ctx.r8.u32, 3);
	// add r7,r9,r11
	ctx.r7.u64 = ctx.r9.u64 + r11.u64;
	// add r11,r29,r28
	r11.u64 = r29.u64 + r28.u64;
	// rlwinm r6,r7,2,0,29
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r6,r24
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + r24.u32);
	// and r3,r4,r10
	ctx.r3.u64 = ctx.r4.u64 & ctx.r10.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c97e0c
	if (cr6.eq) goto loc_82C97E0C;
	// stb r20,76(r11)
	PPC_STORE_U8(r11.u32 + 76, r20.u8);
	// b 0x82c97e10
	goto loc_82C97E10;
loc_82C97E0C:
	// stb r21,76(r11)
	PPC_STORE_U8(r11.u32 + 76, r21.u8);
loc_82C97E10:
	// addi r4,r30,1
	ctx.r4.s64 = r30.s64 + 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c97790
	sub_82C97790(ctx, base);
	// stb r3,0(r30)
	PPC_STORE_U8(r30.u32 + 0, ctx.r3.u8);
loc_82C97E20:
	// sth r31,0(r27)
	PPC_STORE_U16(r27.u32 + 0, r31.u16);
loc_82C97E24:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r27,r27,2
	r27.s64 = r27.s64 + 2;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmpwi cr6,r29,256
	cr6.compare<int32_t>(r29.s32, 256, xer);
	// blt cr6,0x82c97c8c
	if (cr6.lt) goto loc_82C97C8C;
	// stw r18,372(r28)
	PPC_STORE_U32(r28.u32 + 372, r18.u32);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// stw r5,368(r28)
	PPC_STORE_U32(r28.u32 + 368, ctx.r5.u32);
	// beq cr6,0x82c97eb8
	if (cr6.eq) goto loc_82C97EB8;
	// lis r11,-32055
	r11.s64 = -2100756480;
	// lis r10,-32055
	ctx.r10.s64 = -2100756480;
	// lis r9,-32055
	ctx.r9.s64 = -2100756480;
	// lis r8,-32055
	ctx.r8.s64 = -2100756480;
	// lis r7,-32055
	ctx.r7.s64 = -2100756480;
	// lis r6,-32055
	ctx.r6.s64 = -2100756480;
	// lis r5,-32055
	ctx.r5.s64 = -2100756480;
	// lis r4,-32055
	ctx.r4.s64 = -2100756480;
	// lis r3,-32055
	ctx.r3.s64 = -2100756480;
	// addi r11,r11,30840
	r11.s64 = r11.s64 + 30840;
	// addi r10,r10,30840
	ctx.r10.s64 = ctx.r10.s64 + 30840;
	// addi r9,r9,30840
	ctx.r9.s64 = ctx.r9.s64 + 30840;
	// stw r11,332(r28)
	PPC_STORE_U32(r28.u32 + 332, r11.u32);
	// addi r8,r8,30984
	ctx.r8.s64 = ctx.r8.s64 + 30984;
	// stw r10,336(r28)
	PPC_STORE_U32(r28.u32 + 336, ctx.r10.u32);
	// addi r7,r7,30984
	ctx.r7.s64 = ctx.r7.s64 + 30984;
	// stw r9,340(r28)
	PPC_STORE_U32(r28.u32 + 340, ctx.r9.u32);
	// addi r6,r6,30984
	ctx.r6.s64 = ctx.r6.s64 + 30984;
	// stw r8,344(r28)
	PPC_STORE_U32(r28.u32 + 344, ctx.r8.u32);
	// addi r5,r5,31128
	ctx.r5.s64 = ctx.r5.s64 + 31128;
	// stw r7,348(r28)
	PPC_STORE_U32(r28.u32 + 348, ctx.r7.u32);
	// addi r4,r4,31128
	ctx.r4.s64 = ctx.r4.s64 + 31128;
	// stw r6,352(r28)
	PPC_STORE_U32(r28.u32 + 352, ctx.r6.u32);
	// addi r3,r3,31128
	ctx.r3.s64 = ctx.r3.s64 + 31128;
	// stw r5,356(r28)
	PPC_STORE_U32(r28.u32 + 356, ctx.r5.u32);
	// stw r4,360(r28)
	PPC_STORE_U32(r28.u32 + 360, ctx.r4.u32);
	// stw r3,364(r28)
	PPC_STORE_U32(r28.u32 + 364, ctx.r3.u32);
loc_82C97EB8:
	// lis r11,-32055
	r11.s64 = -2100756480;
	// lis r10,-32055
	ctx.r10.s64 = -2100756480;
	// addi r9,r11,31280
	ctx.r9.s64 = r11.s64 + 31280;
	// addi r8,r10,31528
	ctx.r8.s64 = ctx.r10.s64 + 31528;
	// stw r9,60(r28)
	PPC_STORE_U32(r28.u32 + 60, ctx.r9.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r8,64(r28)
	PPC_STORE_U32(r28.u32 + 64, ctx.r8.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c10
	return;
}

PPC_WEAK_FUNC(sub_82C97BE0) {
	__imp__sub_82C97BE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97EE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82c97f0c
	if (!cr6.eq) goto loc_82C97F0C;
	// li r3,6
	ctx.r3.s64 = 6;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C97F0C:
	// lis r11,-31953
	r11.s64 = -2094071808;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-5880
	ctx.r6.s64 = r11.s64 + -5880;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
loc_82C97F1C:
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// lwz r4,0(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// bl 0x82c97030
	sub_82C97030(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c97f58
	if (!cr6.eq) goto loc_82C97F58;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r11,r6,24
	r11.s64 = ctx.r6.s64 + 24;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// cmpw cr6,r8,r11
	cr6.compare<int32_t>(ctx.r8.s32, r11.s32, xer);
	// blt cr6,0x82c97f1c
	if (cr6.lt) goto loc_82C97F1C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_82C97F58:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C97EE0) {
	__imp__sub_82C97EE0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C97F70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r6,r8
	ctx.r6.u64 = ctx.r8.u64;
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c97fa8
	if (!cr6.eq) goto loc_82C97FA8;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C97FA8:
	// addi r11,r4,1
	r11.s64 = ctx.r4.s64 + 1;
	// lwz r7,76(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x82c98020
	if (!cr6.eq) goto loc_82C98020;
	// lbz r11,73(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 73);
	// extsb r10,r11
	ctx.r10.s64 = r11.s8;
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// blt cr6,0x82c97fd0
	if (cr6.lt) goto loc_82C97FD0;
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// ble cr6,0x82c98014
	if (!cr6.gt) goto loc_82C98014;
loc_82C97FD0:
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmpwi cr6,r11,239
	cr6.compare<int32_t>(r11.s32, 239, xer);
	// bgt cr6,0x82c97ff4
	if (cr6.gt) goto loc_82C97FF4;
	// beq cr6,0x82c98004
	if (cr6.eq) goto loc_82C98004;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82c98014
	if (cr6.eq) goto loc_82C98014;
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// beq cr6,0x82c98014
	if (cr6.eq) goto loc_82C98014;
	// b 0x82c981cc
	goto loc_82C981CC;
loc_82C97FF4:
	// cmpwi cr6,r11,254
	cr6.compare<int32_t>(r11.s32, 254, xer);
	// blt cr6,0x82c981cc
	if (cr6.lt) goto loc_82C981CC;
	// cmpwi cr6,r11,255
	cr6.compare<int32_t>(r11.s32, 255, xer);
	// bgt cr6,0x82c981cc
	if (cr6.gt) goto loc_82C981CC;
loc_82C98004:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x82c98014
	if (!cr6.eq) goto loc_82C98014;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x82c981cc
	if (cr6.eq) goto loc_82C981CC;
loc_82C98014:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C98020:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lis r11,0
	r11.s64 = 0;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// ori r29,r11,65279
	r29.u64 = r11.u64 | 65279;
	// rlwimi r8,r10,8,16,23
	ctx.r8.u64 = (rotl32(ctx.r10.u32, 8) & 0xFF00) | (ctx.r8.u64 & 0xFFFFFFFFFFFF00FF);
	// clrlwi r11,r8,16
	r11.u64 = ctx.r8.u32 & 0xFFFF;
	// cmpw cr6,r11,r29
	cr6.compare<int32_t>(r11.s32, r29.s32, xer);
	// bgt cr6,0x82c98134
	if (cr6.gt) goto loc_82C98134;
	// cmplwi cr6,r11,65279
	cr6.compare<uint32_t>(r11.u32, 65279, xer);
	// beq cr6,0x82c98104
	if (cr6.eq) goto loc_82C98104;
	// cmpwi cr6,r11,15360
	cr6.compare<int32_t>(r11.s32, 15360, xer);
	// beq cr6,0x82c980c0
	if (cr6.eq) goto loc_82C980C0;
	// cmplwi cr6,r11,61371
	cr6.compare<uint32_t>(r11.u32, 61371, xer);
	// bne cr6,0x82c9813c
	if (!cr6.eq) goto loc_82C9813C;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x82c9808c
	if (!cr6.eq) goto loc_82C9808C;
	// lbz r11,73(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 73);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82c981cc
	if (cr6.eq) goto loc_82C981CC;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// beq cr6,0x82c981cc
	if (cr6.eq) goto loc_82C981CC;
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// beq cr6,0x82c981cc
	if (cr6.eq) goto loc_82C981CC;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x82c981cc
	if (cr6.eq) goto loc_82C981CC;
loc_82C9808C:
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// beq cr6,0x82c98014
	if (cr6.eq) goto loc_82C98014;
	// lbz r11,0(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r11,191
	cr6.compare<uint32_t>(r11.u32, 191, xer);
	// bne cr6,0x82c981cc
	if (!cr6.eq) goto loc_82C981CC;
	// addi r11,r4,3
	r11.s64 = ctx.r4.s64 + 3;
	// li r3,14
	ctx.r3.s64 = 14;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C980C0:
	// lbz r11,73(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 73);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// beq cr6,0x82c980d8
	if (cr6.eq) goto loc_82C980D8;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x82c980e0
	if (!cr6.eq) goto loc_82C980E0;
loc_82C980D8:
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x82c981cc
	if (cr6.eq) goto loc_82C981CC;
loc_82C980E0:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r11.u32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C98104:
	// lbz r11,73(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 73);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c98118
	if (!cr6.eq) goto loc_82C98118;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x82c981cc
	if (cr6.eq) goto loc_82C981CC;
loc_82C98118:
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// li r3,14
	ctx.r3.s64 = 14;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C98134:
	// cmplwi cr6,r11,65534
	cr6.compare<uint32_t>(r11.u32, 65534, xer);
	// beq cr6,0x82c981b8
	if (cr6.eq) goto loc_82C981B8;
loc_82C9813C:
	// extsb r11,r10
	r11.s64 = ctx.r10.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c98180
	if (!cr6.eq) goto loc_82C98180;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x82c9815c
	if (!cr6.eq) goto loc_82C9815C;
	// lbz r11,73(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 73);
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// beq cr6,0x82c981cc
	if (cr6.eq) goto loc_82C981CC;
loc_82C9815C:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r11.u32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C98180:
	// extsb r11,r9
	r11.s64 = ctx.r9.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c981cc
	if (!cr6.eq) goto loc_82C981CC;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x82c981cc
	if (cr6.eq) goto loc_82C981CC;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r11.u32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C981B8:
	// lbz r11,73(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 73);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c981fc
	if (!cr6.eq) goto loc_82C981FC;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x82c981fc
	if (!cr6.eq) goto loc_82C981FC;
loc_82C981CC:
	// lbz r11,73(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 73);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// extsb r9,r11
	ctx.r9.s64 = r11.s8;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r8,r31
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r31.u32);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r11.u32);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C981FC:
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// li r3,14
	ctx.r3.s64 = 14;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C97F70) {
	__imp__sub_82C97F70(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98218) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,-31953
	ctx.r10.s64 = -2094071808;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// addi r3,r10,-5856
	ctx.r3.s64 = ctx.r10.s64 + -5856;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// b 0x82c97f70
	sub_82C97F70(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C98218) {
	__imp__sub_82C98218(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98240) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,-31953
	ctx.r10.s64 = -2094071808;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// addi r3,r10,-5856
	ctx.r3.s64 = ctx.r10.s64 + -5856;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// b 0x82c97f70
	sub_82C97F70(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C98240) {
	__imp__sub_82C98240(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98268) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82c97ee0
	sub_82C97EE0(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x82c9829c
	if (!cr6.eq) goto loc_82C9829C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c982d0
	goto loc_82C982D0;
loc_82C9829C:
	// lis r11,-32054
	r11.s64 = -2100690944;
	// stb r3,73(r31)
	PPC_STORE_U8(r31.u32 + 73, ctx.r3.u8);
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// stw r30,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r30.u32);
	// lis r9,-32055
	ctx.r9.s64 = -2100756480;
	// addi r7,r11,-32232
	ctx.r7.s64 = r11.s64 + -32232;
	// addi r6,r10,-32192
	ctx.r6.s64 = ctx.r10.s64 + -32192;
	// addi r5,r9,28832
	ctx.r5.s64 = ctx.r9.s64 + 28832;
	// stw r7,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r7.u32);
	// stw r6,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r6.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r5,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r5.u32);
	// stw r31,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r31.u32);
loc_82C982D0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C98268) {
	__imp__sub_82C98268(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C982E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r4,284(r1)
	PPC_STORE_U32(ctx.r1.u32 + 284, ctx.r4.u32);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// addi r7,r1,223
	ctx.r7.s64 = ctx.r1.s64 + 223;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// addi r4,r1,284
	ctx.r4.s64 = ctx.r1.s64 + 284;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r9,284(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// cmplw cr6,r9,r30
	cr6.compare<uint32_t>(ctx.r9.u32, r30.u32, xer);
	// beq cr6,0x82c9833c
	if (cr6.eq) goto loc_82C9833C;
loc_82C98334:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c98394
	goto loc_82C98394;
loc_82C9833C:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r10,0
	ctx.r10.s64 = 0;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// addi r4,r9,2896
	ctx.r4.s64 = ctx.r9.s64 + 2896;
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// bl 0x82c97030
	sub_82C97030(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c98374
	if (cr6.eq) goto loc_82C98374;
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x82c98374
	if (!cr6.eq) goto loc_82C98374;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x82c98394
	goto loc_82C98394;
loc_82C98374:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82c97ee0
	sub_82C97EE0(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82c98334
	if (cr6.eq) goto loc_82C98334;
	// lis r11,-31953
	r11.s64 = -2094071808;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,-5856
	ctx.r9.s64 = r11.s64 + -5856;
	// lwzx r3,r10,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
loc_82C98394:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C982E8) {
	__imp__sub_82C982E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C983B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lwz r31,220(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// lwz r30,212(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// lis r11,-32054
	r11.s64 = -2100690944;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r11,-32024
	ctx.r3.s64 = r11.s64 + -32024;
	// bl 0x82c97458
	sub_82C97458(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C983B0) {
	__imp__sub_82C983B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98420) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,-31953
	ctx.r10.s64 = -2094071808;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// addi r3,r10,-5828
	ctx.r3.s64 = ctx.r10.s64 + -5828;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// b 0x82c97f70
	sub_82C97F70(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C98420) {
	__imp__sub_82C98420(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98448) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,-31953
	ctx.r10.s64 = -2094071808;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// addi r3,r10,-5828
	ctx.r3.s64 = ctx.r10.s64 + -5828;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// b 0x82c97f70
	sub_82C97F70(ctx, base);
	return;
}

PPC_WEAK_FUNC(sub_82C98448) {
	__imp__sub_82C98448(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98470) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82c97ee0
	sub_82C97EE0(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x82c984a4
	if (!cr6.eq) goto loc_82C984A4;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c984d8
	goto loc_82C984D8;
loc_82C984A4:
	// lis r11,-32054
	r11.s64 = -2100690944;
	// stb r3,73(r31)
	PPC_STORE_U8(r31.u32 + 73, ctx.r3.u8);
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// stw r30,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r30.u32);
	// lis r9,-32055
	ctx.r9.s64 = -2100756480;
	// addi r7,r11,-31712
	ctx.r7.s64 = r11.s64 + -31712;
	// addi r6,r10,-31672
	ctx.r6.s64 = ctx.r10.s64 + -31672;
	// addi r5,r9,28832
	ctx.r5.s64 = ctx.r9.s64 + 28832;
	// stw r7,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r7.u32);
	// stw r6,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r6.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r5,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r5.u32);
	// stw r31,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r31.u32);
loc_82C984D8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C98470) {
	__imp__sub_82C98470(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C984F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r4,284(r1)
	PPC_STORE_U32(ctx.r1.u32 + 284, ctx.r4.u32);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// addi r7,r1,223
	ctx.r7.s64 = ctx.r1.s64 + 223;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// addi r4,r1,284
	ctx.r4.s64 = ctx.r1.s64 + 284;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r9,284(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// cmplw cr6,r9,r30
	cr6.compare<uint32_t>(ctx.r9.u32, r30.u32, xer);
	// beq cr6,0x82c98544
	if (cr6.eq) goto loc_82C98544;
loc_82C9853C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c9859c
	goto loc_82C9859C;
loc_82C98544:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r10,0
	ctx.r10.s64 = 0;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// addi r4,r9,2896
	ctx.r4.s64 = ctx.r9.s64 + 2896;
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// bl 0x82c97030
	sub_82C97030(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c9857c
	if (cr6.eq) goto loc_82C9857C;
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x82c9857c
	if (!cr6.eq) goto loc_82C9857C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x82c9859c
	goto loc_82C9859C;
loc_82C9857C:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82c97ee0
	sub_82C97EE0(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82c9853c
	if (cr6.eq) goto loc_82C9853C;
	// lis r11,-31953
	r11.s64 = -2094071808;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,-5828
	ctx.r9.s64 = r11.s64 + -5828;
	// lwzx r3,r10,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
loc_82C9859C:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C984F0) {
	__imp__sub_82C984F0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C985B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lwz r31,220(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// lwz r30,212(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// lis r11,-32054
	r11.s64 = -2100690944;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r11,-31504
	ctx.r3.s64 = r11.s64 + -31504;
	// bl 0x82c97458
	sub_82C97458(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C985B8) {
	__imp__sub_82C985B8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98628) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x82c97be0
	sub_82C97BE0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c98648
	if (cr6.eq) goto loc_82C98648;
	// li r11,23
	r11.s64 = 23;
	// stb r11,134(r3)
	PPC_STORE_U8(ctx.r3.u32 + 134, r11.u8);
loc_82C98648:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C98628) {
	__imp__sub_82C98628(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98658) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r31
	r30.u64 = r31.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c986a8
	if (cr6.eq) goto loc_82C986A8;
loc_82C98678:
	// lwz r31,4(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r30,r31
	r30.u64 = r31.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82c98678
	if (!cr6.eq) goto loc_82C98678;
loc_82C986A8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C98658) {
	__imp__sub_82C98658(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C986B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bnelr cr6
	if (!cr6.eq) return;
	// stw r4,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r4.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C986B0) {
	__imp__sub_82C986B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C986D0) {
	PPC_FUNC_PROLOGUE();
	// stw r4,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, ctx.r4.u32);
	// stw r5,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, ctx.r5.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C986D0) {
	__imp__sub_82C986D0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C986E0) {
	PPC_FUNC_PROLOGUE();
	// stw r4,60(r3)
	PPC_STORE_U32(ctx.r3.u32 + 60, ctx.r4.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C986E0) {
	__imp__sub_82C986E0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C986E8) {
	PPC_FUNC_PROLOGUE();
	// stw r4,72(r3)
	PPC_STORE_U32(ctx.r3.u32 + 72, ctx.r4.u32);
	// stw r5,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, ctx.r5.u32);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C986E8) {
	__imp__sub_82C986E8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C986F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bec
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,480(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 480);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x82c98898
	if (cr6.eq) goto loc_82C98898;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x82c98884
	if (cr6.eq) goto loc_82C98884;
	// lwz r6,32(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// subf r10,r11,r6
	ctx.r10.s64 = ctx.r6.s64 - r11.s64;
	// cmpw cr6,r4,r10
	cr6.compare<int32_t>(ctx.r4.s32, ctx.r10.s32, xer);
	// ble cr6,0x82c98878
	if (!cr6.gt) goto loc_82C98878;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// subf r8,r9,r11
	ctx.r8.s64 = r11.s64 - ctx.r9.s64;
	// subf r10,r3,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r3.s64;
	// add r7,r8,r4
	ctx.r7.u64 = ctx.r8.u64 + ctx.r4.u64;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,1024
	cr6.compare<int32_t>(ctx.r10.s32, 1024, xer);
	// ble cr6,0x82c98754
	if (!cr6.gt) goto loc_82C98754;
	// li r11,1024
	r11.s64 = 1024;
loc_82C98754:
	// add r7,r11,r7
	ctx.r7.u64 = r11.u64 + ctx.r7.u64;
	// subf r5,r3,r6
	ctx.r5.s64 = ctx.r6.s64 - ctx.r3.s64;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// bgt cr6,0x82c987a0
	if (cr6.gt) goto loc_82C987A0;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bge cr6,0x82c98878
	if (!cr6.lt) goto loc_82C98878;
	// subf r30,r11,r10
	r30.s64 = ctx.r10.s64 - r11.s64;
	// add r5,r8,r11
	ctx.r5.u64 = ctx.r8.u64 + r11.u64;
	// add r4,r3,r30
	ctx.r4.u64 = ctx.r3.u64 + r30.u64;
	// bl 0x82caa2e0
	sub_82CAA2E0(ctx, base);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// subf r9,r30,r11
	ctx.r9.s64 = r11.s64 - r30.s64;
	// subf r8,r30,r10
	ctx.r8.s64 = ctx.r10.s64 - r30.s64;
	// stw r9,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r9.u32);
	// rotlwi r3,r9,0
	ctx.r3.u64 = rotl32(ctx.r9.u32, 0);
	// stw r8,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r8.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C987A0:
	// subf. r29,r9,r6
	r29.s64 = ctx.r6.s64 - ctx.r9.s64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bne 0x82c987ac
	if (!cr0.eq) goto loc_82C987AC;
	// li r29,1024
	r29.s64 = 1024;
loc_82C987AC:
	// rlwinm r29,r29,1,0,30
	r29.u64 = rotl64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpw cr6,r29,r7
	cr6.compare<int32_t>(r29.s32, ctx.r7.s32, xer);
	// blt cr6,0x82c987ac
	if (cr6.lt) goto loc_82C987AC;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82c987e4
	if (!cr6.eq) goto loc_82C987E4;
	// li r11,1
	r11.s64 = 1;
	// stw r11,284(r31)
	PPC_STORE_U32(r31.u32 + 284, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C987E4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r10,r30,r29
	ctx.r10.u64 = r30.u64 + r29.u64;
	// stw r10,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r10.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c98864
	if (cr6.eq) goto loc_82C98864;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// subf r29,r10,r11
	r29.s64 = r11.s64 - ctx.r10.s64;
	// cmpwi cr6,r29,1024
	cr6.compare<int32_t>(r29.s32, 1024, xer);
	// ble cr6,0x82c9880c
	if (!cr6.gt) goto loc_82C9880C;
	// li r29,1024
	r29.s64 = 1024;
loc_82C9880C:
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// subf r4,r29,r11
	ctx.r4.s64 = r11.s64 - r29.s64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// add r5,r11,r29
	ctx.r5.u64 = r11.u64 + r29.u64;
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r7,28(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r8,r29,r30
	ctx.r8.u64 = r29.u64 + r30.u64;
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// subf r11,r6,r7
	r11.s64 = ctx.r7.s64 - ctx.r6.s64;
	// stw r8,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r8.u32);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// add r5,r11,r30
	ctx.r5.u64 = r11.u64 + r30.u64;
	// stw r5,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r5.u32);
	// rotlwi r3,r5,0
	ctx.r3.u64 = rotl32(ctx.r5.u32, 0);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C98864:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// stw r30,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r30.u32);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
loc_82C98878:
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C98884:
	// li r11,33
	r11.s64 = 33;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,284(r31)
	PPC_STORE_U32(r31.u32 + 284, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
loc_82C98898:
	// li r11,36
	r11.s64 = 36;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,284(r31)
	PPC_STORE_U32(r31.u32 + 284, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	return;
}

PPC_WEAK_FUNC(sub_82C986F8) {
	__imp__sub_82C986F8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C988B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,288(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 288);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c988d0
	if (cr6.eq) goto loc_82C988D0;
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// lwz r9,40(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + r11.u64;
	// blr 
	return;
loc_82C988D0:
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C988B0) {
	__imp__sub_82C988B0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C988D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r5,288(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 288);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x82c98924
	if (cr6.eq) goto loc_82C98924;
	// lwz r4,296(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 296);
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// blt cr6,0x82c98924
	if (cr6.lt) goto loc_82C98924;
	// lwz r11,144(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 144);
	// addi r6,r31,408
	ctx.r6.s64 = r31.s64 + 408;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r9,288(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 288);
	// stw r9,296(r31)
	PPC_STORE_U32(r31.u32 + 296, ctx.r9.u32);
loc_82C98924:
	// lwz r11,408(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 408);
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C988D8) {
	__imp__sub_82C988D8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98940) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x82c98964
	if (!cr6.gt) goto loc_82C98964;
	// cmplwi cr6,r3,38
	cr6.compare<uint32_t>(ctx.r3.u32, 38, xer);
	// bge cr6,0x82c98964
	if (!cr6.lt) goto loc_82C98964;
	// lis r11,-31953
	r11.s64 = -2094071808;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,-5800
	ctx.r9.s64 = r11.s64 + -5800;
	// lwzx r3,r10,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// blr 
	return;
loc_82C98964:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C98940) {
	__imp__sub_82C98940(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98970) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r31,364(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 364);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c98a34
	if (cr6.eq) goto loc_82C98A34;
loc_82C9898C:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r3,36(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// addi r28,r11,1
	r28.s64 = r11.s64 + 1;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// add r30,r3,r28
	r30.u64 = ctx.r3.u64 + r28.u64;
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// beq cr6,0x82c98a34
	if (cr6.eq) goto loc_82C98A34;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// add r29,r28,r11
	r29.u64 = r28.u64 + r11.u64;
	// subf r9,r3,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r3.s64;
	// cmpw cr6,r29,r9
	cr6.compare<int32_t>(r29.s32, ctx.r9.s32, xer);
	// ble cr6,0x82c98a14
	if (!cr6.gt) goto loc_82C98A14;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c98a40
	if (cr6.eq) goto loc_82C98A40;
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82c989ec
	if (!cr6.eq) goto loc_82C989EC;
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
loc_82C989EC:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c98a04
	if (cr6.eq) goto loc_82C98A04;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
loc_82C98A04:
	// add r11,r3,r29
	r11.u64 = ctx.r3.u64 + r29.u64;
	// stw r3,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r3.u32);
	// add r30,r3,r28
	r30.u64 = ctx.r3.u64 + r28.u64;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
loc_82C98A14:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// lwz r31,0(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82c9898c
	if (!cr6.eq) goto loc_82C9898C;
loc_82C98A34:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C98A40:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C98970) {
	__imp__sub_82C98970(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98A50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// lbz r11,484(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 484);
	// lwz r5,144(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 144);
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// bl 0x82c9eac0
	sub_82C9EAC0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x82c98ab0
	if (!cr6.eq) goto loc_82C98AB0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c98970
	sub_82C98970(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// li r3,1
	ctx.r3.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c98ab4
	if (cr6.eq) goto loc_82C98AB4;
loc_82C98AB0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_82C98AB4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C98A50) {
	__imp__sub_82C98A50(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98AD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2bd8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// mr r24,r7
	r24.u64 = ctx.r7.u64;
	// lbz r11,0(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c98b18
	if (!cr6.eq) goto loc_82C98B18;
	// lwz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c98b18
	if (cr6.eq) goto loc_82C98B18;
	// li r3,28
	ctx.r3.s64 = 28;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
loc_82C98B18:
	// li r30,0
	r30.s64 = 0;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82c98b34
	if (cr6.eq) goto loc_82C98B34;
loc_82C98B24:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// lbzx r11,r30,r27
	r11.u64 = PPC_LOAD_U8(r30.u32 + r27.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c98b24
	if (!cr6.eq) goto loc_82C98B24;
loc_82C98B34:
	// lbz r11,472(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 472);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c98b44
	if (cr6.eq) goto loc_82C98B44;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_82C98B44:
	// lwz r31,376(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 376);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c98b90
	if (cr6.eq) goto loc_82C98B90;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// ble cr6,0x82c98b84
	if (!cr6.gt) goto loc_82C98B84;
	// addi r29,r30,24
	r29.s64 = r30.s64 + 24;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c98bdc
	if (cr6.eq) goto loc_82C98BDC;
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// stw r29,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r29.u32);
loc_82C98B84:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// stw r11,376(r28)
	PPC_STORE_U32(r28.u32 + 376, r11.u32);
	// b 0x82c98bec
	goto loc_82C98BEC;
loc_82C98B90:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// li r3,28
	ctx.r3.s64 = 28;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82c98bdc
	if (cr6.eq) goto loc_82C98BDC;
	// addi r29,r30,24
	r29.s64 = r30.s64 + 24;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c98be8
	if (!cr6.eq) goto loc_82C98BE8;
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82C98BDC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
loc_82C98BE8:
	// stw r29,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r29.u32);
loc_82C98BEC:
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x82ca2c60
	sub_82CA2C60(ctx, base);
	// lbz r11,472(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 472);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c98c18
	if (cr6.eq) goto loc_82C98C18;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// add r10,r30,r10
	ctx.r10.u64 = r30.u64 + ctx.r10.u64;
	// stb r11,-1(r10)
	PPC_STORE_U8(ctx.r10.u32 + -1, r11.u8);
loc_82C98C18:
	// stw r26,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r26.u32);
	// stw r25,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r25.u32);
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lbz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U8(r27.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c98c50
	if (!cr6.eq) goto loc_82C98C50;
	// lwz r11,356(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 356);
	// addi r11,r11,152
	r11.s64 = r11.s64 + 152;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// bne cr6,0x82c98c50
	if (!cr6.eq) goto loc_82C98C50;
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r11.u32);
	// b 0x82c98c54
	goto loc_82C98C54;
loc_82C98C50:
	// stw r31,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r31.u32);
loc_82C98C54:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r31,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r31.u32);
	// beq cr6,0x82c98c98
	if (cr6.eq) goto loc_82C98C98;
	// lwz r11,100(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 100);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c98c98
	if (cr6.eq) goto loc_82C98C98;
	// lwz r10,4(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c98c88
	if (!cr6.eq) goto loc_82C98C88;
	// li r5,0
	ctx.r5.s64 = 0;
loc_82C98C88:
	// lwz r4,0(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// lwz r3,4(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82C98C98:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	return;
}

PPC_WEAK_FUNC(sub_82C98AD0) {
	__imp__sub_82C98AD0(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98CA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-1136(r1)
	ea = -1136 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r8,124(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 124);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82c98ddc
	if (cr6.eq) goto loc_82C98DDC;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// li r10,-1
	ctx.r10.s64 = -1;
	// li r9,256
	ctx.r9.s64 = 256;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_82C98CD8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82c98cd8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82C98CD8;
	// li r11,0
	r11.s64 = 0;
	// lwz r3,248(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 248);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r11,1108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1108, r11.u32);
	// stw r11,1104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1104, r11.u32);
	// stw r11,1112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1112, r11.u32);
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82c98dc4
	if (cr6.eq) goto loc_82C98DC4;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r3,1912
	ctx.r3.s64 = 1912;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,240(r31)
	PPC_STORE_U32(r31.u32 + 240, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c98d58
	if (!cr6.eq) goto loc_82C98D58;
	// lwz r11,1112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c98d40
	if (cr6.eq) goto loc_82C98D40;
	// lwz r3,1104(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82C98D40:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,1136
	ctx.r1.s64 = ctx.r1.s64 + 1136;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C98D58:
	// lbz r11,236(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 236);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c98d70
	if (cr6.eq) goto loc_82C98D70;
	// lis r11,-32054
	r11.s64 = -2100690944;
	// addi r11,r11,-31192
	r11.s64 = r11.s64 + -31192;
	// b 0x82c98d78
	goto loc_82C98D78;
loc_82C98D70:
	// lis r11,-32055
	r11.s64 = -2100756480;
	// addi r11,r11,31712
	r11.s64 = r11.s64 + 31712;
loc_82C98D78:
	// lwz r6,1104(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r5,1108(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c98dc4
	if (cr6.eq) goto loc_82C98DC4;
	// lwz r10,1104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r9,1112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	// stw r11,144(r31)
	PPC_STORE_U32(r31.u32 + 144, r11.u32);
	// stw r10,244(r31)
	PPC_STORE_U32(r31.u32 + 244, ctx.r10.u32);
	// stw r9,252(r31)
	PPC_STORE_U32(r31.u32 + 252, ctx.r9.u32);
	// addi r1,r1,1136
	ctx.r1.s64 = ctx.r1.s64 + 1136;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C98DC4:
	// lwz r11,1112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c98ddc
	if (cr6.eq) goto loc_82C98DDC;
	// lwz r3,1104(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82C98DDC:
	// li r3,18
	ctx.r3.s64 = 18;
	// addi r1,r1,1136
	ctx.r1.s64 = ctx.r1.s64 + 1136;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C98CA8) {
	__imp__sub_82C98CA8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98DF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// lwz r30,304(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 304);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82c98eb4
	if (cr6.eq) goto loc_82C98EB4;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,304(r31)
	PPC_STORE_U32(r31.u32 + 304, r11.u32);
loc_82C98E24:
	// li r26,0
	r26.s64 = 0;
	// li r11,1
	r11.s64 = 1;
	// stw r26,12(r29)
	PPC_STORE_U32(r29.u32 + 12, r26.u32);
	// stb r11,32(r29)
	PPC_STORE_U8(r29.u32 + 32, r11.u8);
	// lwz r10,300(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 300);
	// stw r10,8(r30)
	PPC_STORE_U32(r30.u32 + 8, ctx.r10.u32);
	// stw r30,300(r31)
	PPC_STORE_U32(r31.u32 + 300, r30.u32);
	// stw r29,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r29.u32);
	// lwz r9,312(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 312);
	// stw r9,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r9.u32);
	// stb r28,20(r30)
	PPC_STORE_U8(r30.u32 + 20, r28.u8);
	// stw r26,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r26.u32);
	// stw r26,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r26.u32);
	// lwz r28,4(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lbz r8,33(r29)
	ctx.r8.u64 = PPC_LOAD_U8(r29.u32 + 33);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// add r27,r11,r28
	r27.u64 = r11.u64 + r28.u64;
	// beq cr6,0x82c98edc
	if (cr6.eq) goto loc_82C98EDC;
	// lwz r3,228(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r4,228(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c9fb58
	sub_82C9FB58(ctx, base);
	// b 0x82c98efc
	goto loc_82C98EFC;
loc_82C98EB4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r3,24
	ctx.r3.s64 = 24;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82c98e24
	if (!cr6.eq) goto loc_82C98E24;
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C98EDC:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r5,228(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lwz r4,312(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 312);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82c9eac0
	sub_82C9EAC0(ctx, base);
loc_82C98EFC:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82c98f50
	if (!cr6.eq) goto loc_82C98F50;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// beq cr6,0x82c98f38
	if (cr6.eq) goto loc_82C98F38;
	// lwz r10,480(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 480);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x82c98f38
	if (!cr6.eq) goto loc_82C98F38;
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// subf r9,r28,r11
	ctx.r9.s64 = r11.s64 - r28.s64;
	// addi r8,r10,6088
	ctx.r8.s64 = ctx.r10.s64 + 6088;
	// stw r9,12(r29)
	PPC_STORE_U32(r29.u32 + 12, ctx.r9.u32);
	// stw r8,280(r31)
	PPC_STORE_U32(r31.u32 + 280, ctx.r8.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
loc_82C98F38:
	// stb r26,32(r29)
	PPC_STORE_U8(r29.u32 + 32, r26.u8);
	// lwz r11,304(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 304);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r10,300(r31)
	PPC_STORE_U32(r31.u32 + 300, ctx.r10.u32);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// stw r30,304(r31)
	PPC_STORE_U32(r31.u32 + 304, r30.u32);
loc_82C98F50:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	return;
}

PPC_WEAK_FUNC(sub_82C98DF8) {
	__imp__sub_82C98DF8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98F58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
loc_82C98F68:
	// cmpwi cr6,r11,13
	cr6.compare<int32_t>(r11.s32, 13, xer);
	// beq cr6,0x82c98f88
	if (cr6.eq) goto loc_82C98F88;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c98f68
	if (!cr6.eq) goto loc_82C98F68;
	// blr 
	return;
loc_82C98F88:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r9,10
	ctx.r9.s64 = 10;
loc_82C98F90:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,13
	cr6.compare<uint32_t>(ctx.r10.u32, 13, xer);
	// bne cr6,0x82c98fbc
	if (!cr6.eq) goto loc_82C98FBC;
	// stb r9,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r9.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r10,10
	cr6.compare<uint32_t>(ctx.r10.u32, 10, xer);
	// bne cr6,0x82c98fc4
	if (!cr6.eq) goto loc_82C98FC4;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// b 0x82c98fc4
	goto loc_82C98FC4;
loc_82C98FBC:
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_82C98FC4:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c98f90
	if (!cr6.eq) goto loc_82C98F90;
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C98F58) {
	__imp__sub_82C98F58(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C98FD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r4,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r4.u32);
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// lbz r11,72(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 72);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c9908c
	if (!cr6.eq) goto loc_82C9908C;
	// lwz r11,144(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 144);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bne cr6,0x82c9901c
	if (!cr6.eq) goto loc_82C9901C;
	// addi r29,r31,288
	r29.s64 = r31.s64 + 288;
	// addi r27,r31,292
	r27.s64 = r31.s64 + 292;
	// b 0x82c99024
	goto loc_82C99024;
loc_82C9901C:
	// lwz r29,300(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 300);
	// addi r27,r29,4
	r27.s64 = r29.s64 + 4;
loc_82C99024:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r7,48(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r10,60(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// addi r4,r1,180
	ctx.r4.s64 = ctx.r1.s64 + 180;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r9,180(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r9,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r9.u32);
	// lwz r4,44(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// subf r5,r4,r8
	ctx.r5.s64 = ctx.r8.s64 - ctx.r4.s64;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r7,80(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// mtctr r7
	ctr.u64 = ctx.r7.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// stw r6,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r6.u32);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplw cr6,r5,r28
	cr6.compare<uint32_t>(ctx.r5.u32, r28.u32, xer);
	// bne cr6,0x82c99024
	if (!cr6.eq) goto loc_82C99024;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
loc_82C9908C:
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// subf r5,r4,r28
	ctx.r5.s64 = r28.s64 - ctx.r4.s64;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C98FD8) {
	__imp__sub_82C98FD8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C990A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x82ca2be4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x82c990d8
	if (!cr6.eq) goto loc_82C990D8;
	// clrlwi r11,r6,24
	r11.u64 = ctx.r6.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c99134
	if (cr6.eq) goto loc_82C99134;
loc_82C990D8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x82c9910c
	if (!cr6.gt) goto loc_82C9910C;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
loc_82C990EC:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r29,r9
	cr6.compare<uint32_t>(r29.u32, ctx.r9.u32, xer);
	// beq cr6,0x82c991f0
	if (cr6.eq) goto loc_82C991F0;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// blt cr6,0x82c990ec
	if (cr6.lt) goto loc_82C990EC;
loc_82C9910C:
	// clrlwi r11,r6,24
	r11.u64 = ctx.r6.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82c99134
	if (cr6.eq) goto loc_82C99134;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c99134
	if (!cr6.eq) goto loc_82C99134;
	// lbz r11,9(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 9);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82c99134
	if (!cr6.eq) goto loc_82C99134;
	// stw r29,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r29.u32);
loc_82C99134:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// bne cr6,0x82c991ac
	if (!cr6.eq) goto loc_82C991AC;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82c9917c
	if (!cr6.eq) goto loc_82C9917C;
	// li r11,8
	r11.s64 = 8;
	// li r3,96
	ctx.r3.s64 = 96;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82c991ac
	if (!cr6.eq) goto loc_82C991AC;
loc_82C99170:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
loc_82C9917C:
	// rlwinm r30,r11,1,0,30
	r30.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r10,16(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = rotl64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// add r9,r30,r11
	ctx.r9.u64 = r30.u64 + r11.u64;
	// rlwinm r4,r9,2,0,29
	ctx.r4.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82c99170
	if (cr6.eq) goto loc_82C99170;
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
loc_82C991AC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// clrlwi r8,r28,24
	ctx.r8.u64 = r28.u32 & 0xFF;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = rotl64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// add r7,r11,r9
	ctx.r7.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r7,2,0,29
	r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// stw r27,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r27.u32);
	// stb r28,4(r11)
	PPC_STORE_U8(r11.u32 + 4, r28.u8);
	// bne cr6,0x82c991e4
	if (!cr6.eq) goto loc_82C991E4;
	// li r11,1
	r11.s64 = 1;
	// stb r11,8(r29)
	PPC_STORE_U8(r29.u32 + 8, r11.u8);
loc_82C991E4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_82C991F0:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	return;
}

PPC_WEAK_FUNC(sub_82C990A8) {
	__imp__sub_82C990A8(ctx, base);
}

PPC_FUNC_IMPL(__imp__sub_82C99200) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82c9928c
	if (cr6.eq) goto loc_82C9928C;
	// li r7,32
	ctx.r7.s64 = 32;
loc_82C99218:
	// lbz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// extsb r10,r9
	ctx.r10.s64 = ctx.r9.s8;
	// cmpwi cr6,r10,10
	cr6.compare<int32_t>(ctx.r10.s32, 10, xer);
	// beq cr6,0x82c99240
	if (cr6.eq) goto loc_82C99240;
	// cmpwi cr6,r10,13
	cr6.compare<int32_t>(ctx.r10.s32, 13, xer);
	// beq cr6,0x82c99240
	if (cr6.eq) goto loc_82C99240;
	// cmpwi cr6,r10,32
	cr6.compare<int32_t>(ctx.r10.s32, 32, xer);
	// beq cr6,0x82c99240
	if (cr6.eq) goto loc_82C99240;
	// stb r9,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r9.u8);
	// b 0x82c99258
	goto loc_82C99258;
loc_82C99240:
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// beq cr6,0x82c9925c
	if (cr6.eq) goto loc_82C9925C;
	// lbz r10,-1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + -1);
	// cmplwi cr6,r10,32
	cr6.compare<uint32_t>(ctx.r10.u32, 32, xer);
	// beq cr6,0x82c9925c
	if (cr6.eq) goto loc_82C9925C;
	// stb r7,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r7.u8);
loc_82C99258:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_82C9925C:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lbz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82c99218
	if (!cr6.eq) goto loc_82C99218;
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// beq cr6,0x82c9928c
	if (cr6.eq) goto loc_82C9928C;
	// lbz r10,-1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + -1);
	// cmplwi cr6,r10,32
	cr6.compare<uint32_t>(ctx.r10.u32, 32, xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// bne cr6,0x82c99290
	if (!cr6.eq) goto loc_82C99290;
	// stb r10,-1(r11)
	PPC_STORE_U8(r11.u32 + -1, ctx.r10.u8);
	// blr 
	return;
loc_82C9928C:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82C99290:
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// blr 
	return;
}

PPC_WEAK_FUNC(sub_82C99200) {
	__imp__sub_82C99200(ctx, base);
}

