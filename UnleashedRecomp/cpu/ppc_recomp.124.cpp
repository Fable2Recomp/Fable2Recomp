#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_82C84188"))) PPC_WEAK_FUNC(sub_82C84188);
PPC_FUNC_IMPL(__imp__sub_82C84188) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c841e0
	if (ctx.cr6.eq) goto loc_82C841E0;
	// li r11,-1
	ctx.r11.s64 = -1;
	// twllei r31,0
	// divwu r10,r11,r31
	ctx.r10.u32 = ctx.r11.u32 / ctx.r31.u32;
	// cmplwi cr6,r10,64
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 64, ctx.xer);
	// bge cr6,0x82c841e0
	if (!ctx.cr6.lt) goto loc_82C841E0;
	// lis r11,-32246
	ctx.r11.s64 = -2113273856;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r11,5684
	ctx.r9.s64 = ctx.r11.s64 + 5684;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// bl 0x822f1f00
	ctx.lr = 0x82C841D4;
	sub_822F1F00(ctx, base);
	// lis r8,-32246
	ctx.r8.s64 = -2113273856;
	// addi r7,r8,5672
	ctx.r7.s64 = ctx.r8.s64 + 5672;
	// stw r7,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r7.u32);
loc_82C841E0:
	// rlwinm r3,r31,6,0,25
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 6) & 0xFFFFFFC0;
	// bl 0x8221f388
	ctx.lr = 0x82C841E8;
	sub_8221F388(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C84200"))) PPC_WEAK_FUNC(sub_82C84200);
PPC_FUNC_IMPL(__imp__sub_82C84200) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,5(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 5);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r5,2
	ctx.r5.s64 = 2;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r8,r9,1
	ctx.r8.u64 = ctx.r9.u64 ^ 1;
	// clrlwi r7,r8,24
	ctx.r7.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c8428c
	if (ctx.cr6.eq) goto loc_82C8428C;
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r31.u32);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C84258;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lbz r8,1(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 1);
	// lbz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cntlzw r6,r3
	ctx.r6.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r3,r6,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 27) & 0x1;
	// stb r8,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r8.u8);
	// stb r7,81(r1)
	PPC_STORE_U8(ctx.r1.u32 + 81, ctx.r7.u8);
	// lhz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r1.u32 + 80);
	// sth r5,0(r31)
	PPC_STORE_U16(ctx.r31.u32 + 0, ctx.r5.u16);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C8428C:
	// stw r31,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r31.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C842A8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cntlzw r8,r3
	ctx.r8.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r3,r8,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C842C8"))) PPC_WEAK_FUNC(sub_82C842C8);
PPC_FUNC_IMPL(__imp__sub_82C842C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,5(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 5);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r5,4
	ctx.r5.s64 = 4;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r8,r9,1
	ctx.r8.u64 = ctx.r9.u64 ^ 1;
	// clrlwi r7,r8,24
	ctx.r7.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c84364
	if (ctx.cr6.eq) goto loc_82C84364;
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r31.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C84320;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lbz r8,3(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 3);
	// lbz r7,2(r31)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r31.u32 + 2);
	// cntlzw r6,r3
	ctx.r6.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// lbz r5,1(r31)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r31.u32 + 1);
	// lbz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// rlwinm r3,r6,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 27) & 0x1;
	// stb r8,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r8.u8);
	// stb r7,81(r1)
	PPC_STORE_U8(ctx.r1.u32 + 81, ctx.r7.u8);
	// stb r5,82(r1)
	PPC_STORE_U8(ctx.r1.u32 + 82, ctx.r5.u8);
	// stb r4,83(r1)
	PPC_STORE_U8(ctx.r1.u32 + 83, ctx.r4.u8);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C84364:
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r31.u32);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C84380;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cntlzw r8,r3
	ctx.r8.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r3,r8,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C843A0"))) PPC_WEAK_FUNC(sub_82C843A0);
PPC_FUNC_IMPL(__imp__sub_82C843A0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,44(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bnelr cr6
	if (!ctx.cr6.eq) return;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// lwz r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi cr6,r9,16
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 16, ctx.xer);
	// blt cr6,0x82c843cc
	if (ctx.cr6.lt) goto loc_82C843CC;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// b 0x82c843d0
	goto loc_82C843D0;
loc_82C843CC:
	// addi r4,r11,4
	ctx.r4.s64 = ctx.r11.s64 + 4;
loc_82C843D0:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// b 0x82c825a0
	sub_82C825A0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C843D8"))) PPC_WEAK_FUNC(sub_82C843D8);
PPC_FUNC_IMPL(__imp__sub_82C843D8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C843E0"))) PPC_WEAK_FUNC(sub_82C843E0);
PPC_FUNC_IMPL(__imp__sub_82C843E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,15
	ctx.r9.s64 = 15;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// stw r9,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
	// stb r10,84(r1)
	PPC_STORE_U8(ctx.r1.u32 + 84, ctx.r10.u8);
loc_82C8440C:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c8440c
	if (!ctx.cr6.eq) goto loc_82C8440C;
	// subf r11,r4,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r4.s64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r5,r11,0
	ctx.r5.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// bl 0x821a8f68
	ctx.lr = 0x82C84430;
	sub_821A8F68(ctx, base);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r10,16
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 16, ctx.xer);
	// bge cr6,0x82c84444
	if (!ctx.cr6.lt) goto loc_82C84444;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
loc_82C84444:
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r7,100(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// bl 0x8217cbe8
	ctx.lr = 0x82C84458;
	sub_8217CBE8(ctx, base);
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// cntlzw r10,r3
	ctx.r10.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// rlwinm r31,r10,27,31,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// blt cr6,0x82c84474
	if (ctx.cr6.lt) goto loc_82C84474;
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x824fe010
	ctx.lr = 0x82C84474;
	sub_824FE010(ctx, base);
loc_82C84474:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C84490"))) PPC_WEAK_FUNC(sub_82C84490);
PPC_FUNC_IMPL(__imp__sub_82C84490) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,15
	ctx.r9.s64 = 15;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// stw r9,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
	// stb r10,84(r1)
	PPC_STORE_U8(ctx.r1.u32 + 84, ctx.r10.u8);
loc_82C844BC:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c844bc
	if (!ctx.cr6.eq) goto loc_82C844BC;
	// subf r11,r4,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r4.s64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r5,r11,0
	ctx.r5.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// bl 0x821a8f68
	ctx.lr = 0x82C844E0;
	sub_821A8F68(ctx, base);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r10,16
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 16, ctx.xer);
	// bge cr6,0x82c844f4
	if (!ctx.cr6.lt) goto loc_82C844F4;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
loc_82C844F4:
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r7,100(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// bl 0x8217cbe8
	ctx.lr = 0x82C84508;
	sub_8217CBE8(ctx, base);
	// cntlzw r11,r3
	ctx.r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// rlwinm r9,r11,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// cmplwi cr6,r10,16
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 16, ctx.xer);
	// xori r31,r9,1
	ctx.r31.u64 = ctx.r9.u64 ^ 1;
	// blt cr6,0x82c84528
	if (ctx.cr6.lt) goto loc_82C84528;
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x824fe010
	ctx.lr = 0x82C84528;
	sub_824FE010(ctx, base);
loc_82C84528:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C84540"))) PPC_WEAK_FUNC(sub_82C84540);
PPC_FUNC_IMPL(__imp__sub_82C84540) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C84548;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c84604
	if (ctx.cr6.eq) goto loc_82C84604;
	// lwz r30,48(r29)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c84604
	if (ctx.cr6.eq) goto loc_82C84604;
	// lwz r31,4(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmplw cr6,r31,r9
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x82c84580
	if (!ctx.cr6.gt) goto loc_82C84580;
	// twi 31,r0,22
loc_82C84580:
	// lwz r11,48(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82c84598
	if (!ctx.cr6.gt) goto loc_82C84598;
	// twi 31,r0,22
loc_82C84598:
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82c845a4
	if (ctx.cr6.eq) goto loc_82C845A4;
	// twi 31,r0,22
loc_82C845A4:
	// cmplw cr6,r31,r10
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82c84604
	if (ctx.cr6.eq) goto loc_82C84604;
	// cmplw cr6,r31,r9
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82c845b8
	if (ctx.cr6.lt) goto loc_82C845B8;
	// twi 31,r0,22
loc_82C845B8:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c843e0
	ctx.lr = 0x82C845C4;
	sub_82C843E0(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c845e8
	if (!ctx.cr6.eq) goto loc_82C845E8;
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmplw cr6,r31,r9
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82c845e0
	if (ctx.cr6.lt) goto loc_82C845E0;
	// twi 31,r0,22
loc_82C845E0:
	// addi r31,r31,64
	ctx.r31.s64 = ctx.r31.s64 + 64;
	// b 0x82c84580
	goto loc_82C84580;
loc_82C845E8:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82c845f8
	if (ctx.cr6.lt) goto loc_82C845F8;
	// twi 31,r0,22
loc_82C845F8:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C84604:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C84610"))) PPC_WEAK_FUNC(sub_82C84610);
PPC_FUNC_IMPL(__imp__sub_82C84610) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// bl 0x82c84540
	ctx.lr = 0x82C84628;
	sub_82C84540(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c84648
	if (!ctx.cr6.eq) goto loc_82C84648;
loc_82C84630:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C84648:
	// lwz r11,28(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bne cr6,0x82c84630
	if (!ctx.cr6.eq) goto loc_82C84630;
	// lwz r11,60(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C84678"))) PPC_WEAK_FUNC(sub_82C84678);
PPC_FUNC_IMPL(__imp__sub_82C84678) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// bl 0x82c84540
	ctx.lr = 0x82C84690;
	sub_82C84540(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c846b0
	if (!ctx.cr6.eq) goto loc_82C846B0;
loc_82C84698:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C846B0:
	// lwz r11,28(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82c84698
	if (!ctx.cr6.eq) goto loc_82C84698;
	// lwz r11,60(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C846E0"))) PPC_WEAK_FUNC(sub_82C846E0);
PPC_FUNC_IMPL(__imp__sub_82C846E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// bl 0x82c84540
	ctx.lr = 0x82C846F8;
	sub_82C84540(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c84718
	if (!ctx.cr6.eq) goto loc_82C84718;
loc_82C84700:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C84718:
	// lwz r11,28(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// cmpwi cr6,r11,5
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 5, ctx.xer);
	// bne cr6,0x82c84700
	if (!ctx.cr6.eq) goto loc_82C84700;
	// lbz r11,60(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 60);
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C84748"))) PPC_WEAK_FUNC(sub_82C84748);
PPC_FUNC_IMPL(__imp__sub_82C84748) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// bl 0x82c84540
	ctx.lr = 0x82C84760;
	sub_82C84540(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c84780
	if (!ctx.cr6.eq) goto loc_82C84780;
loc_82C84768:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C84780:
	// lwz r11,28(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82c84768
	if (!ctx.cr6.eq) goto loc_82C84768;
	// lfs f0,60(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	ctx.f0.f64 = double(temp.f32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C847B0"))) PPC_WEAK_FUNC(sub_82C847B0);
PPC_FUNC_IMPL(__imp__sub_82C847B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// bl 0x82c84540
	ctx.lr = 0x82C847C8;
	sub_82C84540(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c847e8
	if (!ctx.cr6.eq) goto loc_82C847E8;
loc_82C847D0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C847E8:
	// lwz r10,28(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// addi r11,r3,28
	ctx.r11.s64 = ctx.r3.s64 + 28;
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82c847d0
	if (!ctx.cr6.eq) goto loc_82C847D0;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi cr6,r10,16
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 16, ctx.xer);
	// blt cr6,0x82c84810
	if (ctx.cr6.lt) goto loc_82C84810;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// b 0x82c84814
	goto loc_82C84814;
loc_82C84810:
	// addi r4,r11,4
	ctx.r4.s64 = ctx.r11.s64 + 4;
loc_82C84814:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c825a0
	ctx.lr = 0x82C8481C;
	sub_82C825A0(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C84838"))) PPC_WEAK_FUNC(sub_82C84838);
PPC_FUNC_IMPL(__imp__sub_82C84838) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r10,4
	ctx.r10.s64 = 4;
	// lbz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 4);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c84880
	if (ctx.cr6.eq) goto loc_82C84880;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82372268
	ctx.lr = 0x82C84874;
	sub_82372268(ctx, base);
	// lbz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// stb r3,4(r30)
	PPC_STORE_U8(ctx.r30.u32 + 4, ctx.r3.u8);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
loc_82C84880:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C848A0"))) PPC_WEAK_FUNC(sub_82C848A0);
PPC_FUNC_IMPL(__imp__sub_82C848A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C848A8;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// cmplw cr6,r29,r27
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c84918
	if (ctx.cr6.eq) goto loc_82C84918;
	// addi r31,r29,36
	ctx.r31.s64 = ctx.r29.s64 + 36;
	// li r28,15
	ctx.r28.s64 = 15;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82C848C8:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// blt cr6,0x82c848dc
	if (ctx.cr6.lt) goto loc_82C848DC;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x824fe010
	ctx.lr = 0x82C848DC;
	sub_824FE010(ctx, base);
loc_82C848DC:
	// stw r28,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r28.u32);
	// stw r30,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r30.u32);
	// stb r30,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r30.u8);
	// lwz r11,-12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -12);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// blt cr6,0x82c848fc
	if (ctx.cr6.lt) goto loc_82C848FC;
	// lwz r3,-32(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -32);
	// bl 0x824fe010
	ctx.lr = 0x82C848FC;
	sub_824FE010(ctx, base);
loc_82C848FC:
	// addi r29,r29,64
	ctx.r29.s64 = ctx.r29.s64 + 64;
	// stw r28,-12(r31)
	PPC_STORE_U32(ctx.r31.u32 + -12, ctx.r28.u32);
	// stw r30,-16(r31)
	PPC_STORE_U32(ctx.r31.u32 + -16, ctx.r30.u32);
	// stb r30,-32(r31)
	PPC_STORE_U8(ctx.r31.u32 + -32, ctx.r30.u8);
	// addi r31,r31,64
	ctx.r31.s64 = ctx.r31.s64 + 64;
	// cmplw cr6,r29,r27
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c848c8
	if (!ctx.cr6.eq) goto loc_82C848C8;
loc_82C84918:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C84920"))) PPC_WEAK_FUNC(sub_82C84920);
PPC_FUNC_IMPL(__imp__sub_82C84920) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bd8
	ctx.lr = 0x82C84928;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r24,r4
	ctx.r24.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// cmplw cr6,r29,r24
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r24.u32, ctx.xer);
	// beq cr6,0x82c849dc
	if (ctx.cr6.eq) goto loc_82C849DC;
	// addi r30,r29,60
	ctx.r30.s64 = ctx.r29.s64 + 60;
	// addi r31,r27,36
	ctx.r31.s64 = ctx.r27.s64 + 36;
	// li r25,15
	ctx.r25.s64 = 15;
	// li r28,0
	ctx.r28.s64 = 0;
	// li r26,-1
	ctx.r26.s64 = -1;
loc_82C84954:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82c849c4
	if (ctx.cr6.eq) goto loc_82C849C4;
	// stw r25,-12(r31)
	PPC_STORE_U32(ctx.r31.u32 + -12, ctx.r25.u32);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// stw r28,-16(r31)
	PPC_STORE_U32(ctx.r31.u32 + -16, ctx.r28.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stb r28,-32(r31)
	PPC_STORE_U8(ctx.r31.u32 + -32, ctx.r28.u8);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8218ea38
	ctx.lr = 0x82C8497C;
	sub_8218EA38(ctx, base);
	// lwz r11,-32(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + -32);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r30,-28
	ctx.r4.s64 = ctx.r30.s64 + -28;
	// addi r3,r31,-4
	ctx.r3.s64 = ctx.r31.s64 + -4;
	// stw r11,-8(r31)
	PPC_STORE_U32(ctx.r31.u32 + -8, ctx.r11.u32);
	// stw r25,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r25.u32);
	// stw r28,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r28.u32);
	// stb r28,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r28.u8);
	// bl 0x8218ea38
	ctx.lr = 0x82C849A4;
	sub_8218EA38(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// stw r10,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r10.u32);
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// stw r9,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r9.u32);
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,24(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 24, temp.u32);
	// lbz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// stb r8,24(r31)
	PPC_STORE_U8(ctx.r31.u32 + 24, ctx.r8.u8);
loc_82C849C4:
	// addi r29,r29,64
	ctx.r29.s64 = ctx.r29.s64 + 64;
	// addi r27,r27,64
	ctx.r27.s64 = ctx.r27.s64 + 64;
	// addi r31,r31,64
	ctx.r31.s64 = ctx.r31.s64 + 64;
	// addi r30,r30,64
	ctx.r30.s64 = ctx.r30.s64 + 64;
	// cmplw cr6,r29,r24
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r24.u32, ctx.xer);
	// bne cr6,0x82c84954
	if (!ctx.cr6.eq) goto loc_82C84954;
loc_82C849DC:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C849E8"))) PPC_WEAK_FUNC(sub_82C849E8);
PPC_FUNC_IMPL(__imp__sub_82C849E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bdc
	ctx.lr = 0x82C849F0;
	__savegprlr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r4
	ctx.r25.u64 = ctx.r4.u64;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82c84a9c
	if (ctx.cr6.eq) goto loc_82C84A9C;
	// addi r31,r28,36
	ctx.r31.s64 = ctx.r28.s64 + 36;
	// li r26,15
	ctx.r26.s64 = 15;
	// li r29,0
	ctx.r29.s64 = 0;
	// li r27,-1
	ctx.r27.s64 = -1;
loc_82C84A18:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82c84a8c
	if (ctx.cr6.eq) goto loc_82C84A8C;
	// stw r26,-12(r31)
	PPC_STORE_U32(ctx.r31.u32 + -12, ctx.r26.u32);
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// stw r29,-16(r31)
	PPC_STORE_U32(ctx.r31.u32 + -16, ctx.r29.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stb r29,-32(r31)
	PPC_STORE_U8(ctx.r31.u32 + -32, ctx.r29.u8);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8218ea38
	ctx.lr = 0x82C84A40;
	sub_8218EA38(ctx, base);
	// addi r11,r30,28
	ctx.r11.s64 = ctx.r30.s64 + 28;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// addi r4,r11,4
	ctx.r4.s64 = ctx.r11.s64 + 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,-4
	ctx.r3.s64 = ctx.r31.s64 + -4;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// stw r11,-8(r31)
	PPC_STORE_U32(ctx.r31.u32 + -8, ctx.r11.u32);
	// stw r26,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r26.u32);
	// stw r29,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r29.u32);
	// stb r29,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r29.u8);
	// bl 0x8218ea38
	ctx.lr = 0x82C84A6C;
	sub_8218EA38(ctx, base);
	// lwz r10,60(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	// stw r10,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r10.u32);
	// lwz r9,60(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	// stw r9,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r9.u32);
	// lfs f0,60(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,24(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 24, temp.u32);
	// lbz r8,60(r30)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r30.u32 + 60);
	// stb r8,24(r31)
	PPC_STORE_U8(ctx.r31.u32 + 24, ctx.r8.u8);
loc_82C84A8C:
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// addi r28,r28,64
	ctx.r28.s64 = ctx.r28.s64 + 64;
	// addi r31,r31,64
	ctx.r31.s64 = ctx.r31.s64 + 64;
	// bne 0x82c84a18
	if (!ctx.cr0.eq) goto loc_82C84A18;
loc_82C84A9C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C84AA8"))) PPC_WEAK_FUNC(sub_82C84AA8);
PPC_FUNC_IMPL(__imp__sub_82C84AA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C84AB0;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// cmplw cr6,r29,r26
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r26.u32, ctx.xer);
	// beq cr6,0x82c84b3c
	if (ctx.cr6.eq) goto loc_82C84B3C;
	// addi r31,r28,60
	ctx.r31.s64 = ctx.r28.s64 + 60;
	// addi r30,r29,60
	ctx.r30.s64 = ctx.r29.s64 + 60;
	// li r27,-1
	ctx.r27.s64 = -1;
loc_82C84AD4:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8218ea38
	ctx.lr = 0x82C84AE8;
	sub_8218EA38(ctx, base);
	// lwz r11,-32(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + -32);
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r30,-28
	ctx.r4.s64 = ctx.r30.s64 + -28;
	// addi r3,r31,-28
	ctx.r3.s64 = ctx.r31.s64 + -28;
	// stw r11,-32(r31)
	PPC_STORE_U32(ctx.r31.u32 + -32, ctx.r11.u32);
	// bl 0x8218ea38
	ctx.lr = 0x82C84B04;
	sub_8218EA38(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r29,r29,64
	ctx.r29.s64 = ctx.r29.s64 + 64;
	// addi r28,r28,64
	ctx.r28.s64 = ctx.r28.s64 + 64;
	// cmplw cr6,r29,r26
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r26.u32, ctx.xer);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// lbz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// stb r8,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r8.u8);
	// addi r31,r31,64
	ctx.r31.s64 = ctx.r31.s64 + 64;
	// addi r30,r30,64
	ctx.r30.s64 = ctx.r30.s64 + 64;
	// bne cr6,0x82c84ad4
	if (!ctx.cr6.eq) goto loc_82C84AD4;
loc_82C84B3C:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C84B48"))) PPC_WEAK_FUNC(sub_82C84B48);
PPC_FUNC_IMPL(__imp__sub_82C84B48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C84B50;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// cmplw cr6,r26,r29
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82c84bdc
	if (ctx.cr6.eq) goto loc_82C84BDC;
	// addi r30,r28,60
	ctx.r30.s64 = ctx.r28.s64 + 60;
	// addi r31,r29,60
	ctx.r31.s64 = ctx.r29.s64 + 60;
	// li r27,-1
	ctx.r27.s64 = -1;
loc_82C84B74:
	// addi r29,r29,-64
	ctx.r29.s64 = ctx.r29.s64 + -64;
	// addi r28,r28,-64
	ctx.r28.s64 = ctx.r28.s64 + -64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r31,r31,-64
	ctx.r31.s64 = ctx.r31.s64 + -64;
	// addi r30,r30,-64
	ctx.r30.s64 = ctx.r30.s64 + -64;
	// bl 0x8218ea38
	ctx.lr = 0x82C84B98;
	sub_8218EA38(ctx, base);
	// lwz r11,-32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -32);
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r31,-28
	ctx.r4.s64 = ctx.r31.s64 + -28;
	// addi r3,r30,-28
	ctx.r3.s64 = ctx.r30.s64 + -28;
	// stw r11,-32(r30)
	PPC_STORE_U32(ctx.r30.u32 + -32, ctx.r11.u32);
	// bl 0x8218ea38
	ctx.lr = 0x82C84BB4;
	sub_8218EA38(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r29,r26
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r26.u32, ctx.xer);
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r9,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r9.u32);
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// lbz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// stb r8,0(r30)
	PPC_STORE_U8(ctx.r30.u32 + 0, ctx.r8.u8);
	// bne cr6,0x82c84b74
	if (!ctx.cr6.eq) goto loc_82C84B74;
loc_82C84BDC:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C84BE8"))) PPC_WEAK_FUNC(sub_82C84BE8);
PPC_FUNC_IMPL(__imp__sub_82C84BE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bdc
	ctx.lr = 0x82C84BF0;
	__savegprlr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r25,r4
	ctx.r25.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// cmplw cr6,r29,r25
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r25.u32, ctx.xer);
	// beq cr6,0x82c84c78
	if (ctx.cr6.eq) goto loc_82C84C78;
	// addi r30,r27,28
	ctx.r30.s64 = ctx.r27.s64 + 28;
	// addi r31,r29,60
	ctx.r31.s64 = ctx.r29.s64 + 60;
	// addi r26,r30,4
	ctx.r26.s64 = ctx.r30.s64 + 4;
	// li r28,-1
	ctx.r28.s64 = -1;
loc_82C84C18:
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8218ea38
	ctx.lr = 0x82C84C2C;
	sub_8218EA38(ctx, base);
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// addi r3,r31,-28
	ctx.r3.s64 = ctx.r31.s64 + -28;
	// stw r11,-32(r31)
	PPC_STORE_U32(ctx.r31.u32 + -32, ctx.r11.u32);
	// bl 0x8218ea38
	ctx.lr = 0x82C84C48;
	sub_8218EA38(ctx, base);
	// lwz r10,32(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// addi r29,r29,64
	ctx.r29.s64 = ctx.r29.s64 + 64;
	// cmplw cr6,r29,r25
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r25.u32, ctx.xer);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// lwz r9,32(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// lfs f0,32(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// lbz r8,32(r30)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r30.u32 + 32);
	// stb r8,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r8.u8);
	// addi r31,r31,64
	ctx.r31.s64 = ctx.r31.s64 + 64;
	// bne cr6,0x82c84c18
	if (!ctx.cr6.eq) goto loc_82C84C18;
loc_82C84C78:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C84C80"))) PPC_WEAK_FUNC(sub_82C84C80);
PPC_FUNC_IMPL(__imp__sub_82C84C80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lbz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lbz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// bl 0x82c849e8
	ctx.lr = 0x82C84CC4;
	sub_82C849E8(ctx, base);
	// rlwinm r11,r30,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 6) & 0xFFFFFFC0;
	// add r3,r11,r31
	ctx.r3.u64 = ctx.r11.u64 + ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C84CE8"))) PPC_WEAK_FUNC(sub_82C84CE8);
PPC_FUNC_IMPL(__imp__sub_82C84CE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C84CF0;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// std r27,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, ctx.r27.u64);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r11,176(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// std r6,184(r1)
	PPC_STORE_U64(ctx.r1.u32 + 184, ctx.r6.u64);
	// beq cr6,0x82c84d20
	if (ctx.cr6.eq) goto loc_82C84D20;
	// lwz r10,184(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82c84d24
	if (ctx.cr6.eq) goto loc_82C84D24;
loc_82C84D20:
	// twi 31,r0,22
loc_82C84D24:
	// lwz r30,180(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r28,188(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// cmplw cr6,r30,r28
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c84d90
	if (ctx.cr6.eq) goto loc_82C84D90;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lbz r6,81(r1)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r1.u32 + 81);
	// addi r9,r1,81
	ctx.r9.s64 = ctx.r1.s64 + 81;
	// lwz r26,8(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r11.u8);
	// stb r11,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r11.u8);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lbz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// lbz r7,81(r1)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r1.u32 + 81);
	// bl 0x82c84aa8
	ctx.lr = 0x82C84D68;
	sub_82C84AA8(ctx, base);
	// subf r8,r28,r26
	ctx.r8.s64 = ctx.r26.s64 - ctx.r28.s64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lbz r6,81(r1)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r1.u32 + 81);
	// srawi r7,r8,6
	ctx.xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x3F) != 0);
	ctx.r7.s64 = ctx.r8.s32 >> 6;
	// rlwinm r11,r7,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c848a0
	ctx.lr = 0x82C84D8C;
	sub_82C848A0(ctx, base);
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
loc_82C84D90:
	// std r27,0(r29)
	PPC_STORE_U64(ctx.r29.u32 + 0, ctx.r27.u64);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C84DA0"))) PPC_WEAK_FUNC(sub_82C84DA0);
PPC_FUNC_IMPL(__imp__sub_82C84DA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C84DA8;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lbz r6,81(r1)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r1.u32 + 81);
	// addi r9,r1,81
	ctx.r9.s64 = ctx.r1.s64 + 81;
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r11.u8);
	// stb r11,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r11.u8);
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// lbz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// lbz r7,81(r1)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r1.u32 + 81);
	// bl 0x82c84b48
	ctx.lr = 0x82C84DDC;
	sub_82C84B48(ctx, base);
	// subf r8,r31,r30
	ctx.r8.s64 = ctx.r30.s64 - ctx.r31.s64;
	// srawi r7,r8,6
	ctx.xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x3F) != 0);
	ctx.r7.s64 = ctx.r8.s32 >> 6;
	// rlwinm r6,r7,6,0,25
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// subf r3,r6,r29
	ctx.r3.s64 = ctx.r29.s64 - ctx.r6.s64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C84DF8"))) PPC_WEAK_FUNC(sub_82C84DF8);
PPC_FUNC_IMPL(__imp__sub_82C84DF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C84E00;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r30,r29,144
	ctx.r30.s64 = ctx.r29.s64 + 144;
	// addi r10,r11,-5920
	ctx.r10.s64 = ctx.r11.s64 + -5920;
	// stw r10,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r10.u32);
	// lwz r3,148(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 148);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c84e3c
	if (ctx.cr6.eq) goto loc_82C84E3C;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lbz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// bl 0x82c848a0
	ctx.lr = 0x82C84E34;
	sub_82C848A0(ctx, base);
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x824fe010
	ctx.lr = 0x82C84E3C;
	sub_824FE010(ctx, base);
loc_82C84E3C:
	// li r31,0
	ctx.r31.s64 = 0;
	// addi r27,r29,112
	ctx.r27.s64 = ctx.r29.s64 + 112;
	// stw r31,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r31.u32);
	// stw r31,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r31.u32);
	// stw r31,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r31.u32);
	// lwz r11,136(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 136);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// blt cr6,0x82c84e64
	if (ctx.cr6.lt) goto loc_82C84E64;
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// bl 0x824fe010
	ctx.lr = 0x82C84E64;
	sub_824FE010(ctx, base);
loc_82C84E64:
	// li r26,15
	ctx.r26.s64 = 15;
	// stw r31,20(r27)
	PPC_STORE_U32(ctx.r27.u32 + 20, ctx.r31.u32);
	// addi r28,r29,80
	ctx.r28.s64 = ctx.r29.s64 + 80;
	// stw r26,24(r27)
	PPC_STORE_U32(ctx.r27.u32 + 24, ctx.r26.u32);
	// stb r31,4(r27)
	PPC_STORE_U8(ctx.r27.u32 + 4, ctx.r31.u8);
	// lwz r11,104(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 104);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// blt cr6,0x82c84e8c
	if (ctx.cr6.lt) goto loc_82C84E8C;
	// lwz r3,4(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// bl 0x824fe010
	ctx.lr = 0x82C84E8C;
	sub_824FE010(ctx, base);
loc_82C84E8C:
	// stw r26,24(r28)
	PPC_STORE_U32(ctx.r28.u32 + 24, ctx.r26.u32);
	// addi r30,r29,52
	ctx.r30.s64 = ctx.r29.s64 + 52;
	// stw r31,20(r28)
	PPC_STORE_U32(ctx.r28.u32 + 20, ctx.r31.u32);
	// stb r31,4(r28)
	PPC_STORE_U8(ctx.r28.u32 + 4, ctx.r31.u8);
	// lwz r11,76(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 76);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// blt cr6,0x82c84eb0
	if (ctx.cr6.lt) goto loc_82C84EB0;
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x824fe010
	ctx.lr = 0x82C84EB0;
	sub_824FE010(ctx, base);
loc_82C84EB0:
	// stw r26,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r26.u32);
	// addi r11,r29,12
	ctx.r11.s64 = ctx.r29.s64 + 12;
	// stw r31,20(r30)
	PPC_STORE_U32(ctx.r30.u32 + 20, ctx.r31.u32);
	// stb r31,4(r30)
	PPC_STORE_U8(ctx.r30.u32 + 4, ctx.r31.u8);
	// addi r3,r11,8
	ctx.r3.s64 = ctx.r11.s64 + 8;
	// bl 0x8235e680
	ctx.lr = 0x82C84EC8;
	sub_8235E680(ctx, base);
	// lwz r3,12(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c84ee4
	if (ctx.cr6.eq) goto loc_82C84EE4;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C84EE4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C84EE4:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c81bf8
	ctx.lr = 0x82C84EEC;
	sub_82C81BF8(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C84EF8"))) PPC_WEAK_FUNC(sub_82C84EF8);
PPC_FUNC_IMPL(__imp__sub_82C84EF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r11,8(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82c84f1c
	if (!ctx.cr6.gt) goto loc_82C84F1C;
	// twi 31,r0,22
loc_82C84F1C:
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// ble cr6,0x82c84f30
	if (!ctx.cr6.gt) goto loc_82C84F30;
	// twi 31,r0,22
loc_82C84F30:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// stw r4,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r4.u32);
	// ld r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// ld r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// bl 0x82c84ce8
	ctx.lr = 0x82C84F48;
	sub_82C84CE8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C84F58"))) PPC_WEAK_FUNC(sub_82C84F58);
PPC_FUNC_IMPL(__imp__sub_82C84F58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bdc
	ctx.lr = 0x82C84F60;
	__savegprlr_25(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r26,0
	ctx.r26.s64 = 0;
	// std r4,248(r1)
	PPC_STORE_U64(ctx.r1.u32 + 248, ctx.r4.u64);
	// li r25,15
	ctx.r25.s64 = 15;
	// stw r26,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r26.u32);
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// stw r25,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r25.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stb r26,100(r1)
	PPC_STORE_U8(ctx.r1.u32 + 100, ctx.r26.u8);
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// li r6,-1
	ctx.r6.s64 = -1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8218ea38
	ctx.lr = 0x82C84F9C;
	sub_8218EA38(ctx, base);
	// addi r4,r30,28
	ctx.r4.s64 = ctx.r30.s64 + 28;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// bl 0x82c82968
	ctx.lr = 0x82C84FA8;
	sub_82C82968(ctx, base);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c84fbc
	if (!ctx.cr6.eq) goto loc_82C84FBC;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// b 0x82c84fc8
	goto loc_82C84FC8;
loc_82C84FBC:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// subf r9,r10,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r10.s64;
	// srawi r8,r9,6
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3F) != 0);
	ctx.r8.s64 = ctx.r9.s32 >> 6;
loc_82C84FC8:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82c85210
	if (ctx.cr6.eq) goto loc_82C85210;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c84fe0
	if (!ctx.cr6.eq) goto loc_82C84FE0;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// b 0x82c84fec
	goto loc_82C84FEC;
loc_82C84FE0:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// subf r9,r10,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r10.s64;
	// srawi r11,r9,6
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3F) != 0);
	ctx.r11.s64 = ctx.r9.s32 >> 6;
loc_82C84FEC:
	// lis r9,1023
	ctx.r9.s64 = 67043328;
	// ori r9,r9,65535
	ctx.r9.u64 = ctx.r9.u64 | 65535;
	// subf r7,r11,r9
	ctx.r7.s64 = ctx.r9.s64 - ctx.r11.s64;
	// cmplw cr6,r7,r27
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r27.u32, ctx.xer);
	// bge cr6,0x82c85008
	if (!ctx.cr6.lt) goto loc_82C85008;
	// bl 0x82bf8e78
	ctx.lr = 0x82C85004;
	sub_82BF8E78(ctx, base);
	// b 0x82c85210
	goto loc_82C85210;
loc_82C85008:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c85018
	if (!ctx.cr6.eq) goto loc_82C85018;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// b 0x82c85024
	goto loc_82C85024;
loc_82C85018:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// subf r7,r10,r11
	ctx.r7.s64 = ctx.r11.s64 - ctx.r10.s64;
	// srawi r11,r7,6
	ctx.xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x3F) != 0);
	ctx.r11.s64 = ctx.r7.s32 >> 6;
loc_82C85024:
	// add r11,r11,r27
	ctx.r11.u64 = ctx.r11.u64 + ctx.r27.u64;
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82c85168
	if (!ctx.cr6.lt) goto loc_82C85168;
	// rlwinm r11,r8,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 31) & 0x7FFFFFFF;
	// mr r28,r26
	ctx.r28.u64 = ctx.r26.u64;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r11.s64;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// blt cr6,0x82c85048
	if (ctx.cr6.lt) goto loc_82C85048;
	// add r28,r11,r8
	ctx.r28.u64 = ctx.r11.u64 + ctx.r8.u64;
loc_82C85048:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c85058
	if (!ctx.cr6.eq) goto loc_82C85058;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// b 0x82c85064
	goto loc_82C85064;
loc_82C85058:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// subf r9,r10,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r10.s64;
	// srawi r11,r9,6
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3F) != 0);
	ctx.r11.s64 = ctx.r9.s32 >> 6;
loc_82C85064:
	// add r11,r11,r27
	ctx.r11.u64 = ctx.r11.u64 + ctx.r27.u64;
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82c85090
	if (!ctx.cr6.lt) goto loc_82C85090;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c85080
	if (!ctx.cr6.eq) goto loc_82C85080;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// b 0x82c8508c
	goto loc_82C8508C;
loc_82C85080:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// subf r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	// srawi r11,r10,6
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3F) != 0);
	ctx.r11.s64 = ctx.r10.s32 >> 6;
loc_82C8508C:
	// add r28,r11,r27
	ctx.r28.u64 = ctx.r11.u64 + ctx.r27.u64;
loc_82C85090:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82c84188
	ctx.lr = 0x82C8509C;
	sub_82C84188(ctx, base);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lbz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// lwz r29,252(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// stb r26,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r26.u8);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lbz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// bl 0x82c84920
	ctx.lr = 0x82C850CC;
	sub_82C84920(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c84c80
	ctx.lr = 0x82C850E0;
	sub_82C84C80(ctx, base);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lbz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stb r26,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r26.u8);
	// lbz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// bl 0x82c84920
	ctx.lr = 0x82C85104;
	sub_82C84920(ctx, base);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c85118
	if (!ctx.cr6.eq) goto loc_82C85118;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// b 0x82c85124
	goto loc_82C85124;
loc_82C85118:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// subf r10,r3,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r3.s64;
	// srawi r11,r10,6
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3F) != 0);
	ctx.r11.s64 = ctx.r10.s32 >> 6;
loc_82C85124:
	// add r29,r11,r27
	ctx.r29.u64 = ctx.r11.u64 + ctx.r27.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c85148
	if (ctx.cr6.eq) goto loc_82C85148;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lbz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x82c848a0
	ctx.lr = 0x82C85140;
	sub_82C848A0(ctx, base);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x824fe010
	ctx.lr = 0x82C85148;
	sub_824FE010(ctx, base);
loc_82C85148:
	// rlwinm r11,r28,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 6) & 0xFFFFFFC0;
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
	// rlwinm r10,r29,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 6) & 0xFFFFFFC0;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// add r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 + ctx.r30.u64;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
	// b 0x82c85210
	goto loc_82C85210;
loc_82C85168:
	// lwz r29,8(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// rlwinm r28,r27,6,0,25
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 6) & 0xFFFFFFC0;
	// lwz r30,252(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// lbz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// subf r11,r30,r29
	ctx.r11.s64 = ctx.r29.s64 - ctx.r30.s64;
	// srawi r10,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 6;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// cmplw cr6,r10,r27
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r27.u32, ctx.xer);
	// stb r26,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r26.u8);
	// bge cr6,0x82c851d8
	if (!ctx.cr6.lt) goto loc_82C851D8;
	// add r5,r28,r30
	ctx.r5.u64 = ctx.r28.u64 + ctx.r30.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lbz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// bl 0x82c84920
	ctx.lr = 0x82C851A8;
	sub_82C84920(ctx, base);
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// subf r10,r30,r4
	ctx.r10.s64 = ctx.r4.s64 - ctx.r30.s64;
	// srawi r9,r10,6
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3F) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 6;
	// subf r5,r9,r27
	ctx.r5.s64 = ctx.r27.s64 - ctx.r9.s64;
	// bl 0x82c84c80
	ctx.lr = 0x82C851C4;
	sub_82C84C80(ctx, base);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// add r11,r28,r11
	ctx.r11.u64 = ctx.r28.u64 + ctx.r11.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// subf r4,r28,r11
	ctx.r4.s64 = ctx.r11.s64 - ctx.r28.s64;
	// b 0x82c85204
	goto loc_82C85204;
loc_82C851D8:
	// subf r27,r28,r29
	ctx.r27.s64 = ctx.r29.s64 - ctx.r28.s64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lbz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// bl 0x82c84920
	ctx.lr = 0x82C851EC;
	sub_82C84920(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c84da0
	ctx.lr = 0x82C85200;
	sub_82C84DA0(ctx, base);
	// add r4,r28,r30
	ctx.r4.u64 = ctx.r28.u64 + ctx.r30.u64;
loc_82C85204:
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c84be8
	ctx.lr = 0x82C85210;
	sub_82C84BE8(ctx, base);
loc_82C85210:
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// blt cr6,0x82c85224
	if (ctx.cr6.lt) goto loc_82C85224;
	// lwz r3,132(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// bl 0x824fe010
	ctx.lr = 0x82C85224;
	sub_824FE010(ctx, base);
loc_82C85224:
	// lwz r11,120(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// stw r25,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r25.u32);
	// stw r26,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r26.u32);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// stb r26,132(r1)
	PPC_STORE_U8(ctx.r1.u32 + 132, ctx.r26.u8);
	// blt cr6,0x82c85244
	if (ctx.cr6.lt) goto loc_82C85244;
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// bl 0x824fe010
	ctx.lr = 0x82C85244;
	sub_824FE010(ctx, base);
loc_82C85244:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C85250"))) PPC_WEAK_FUNC(sub_82C85250);
PPC_FUNC_IMPL(__imp__sub_82C85250) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C85258;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r3,r30,8
	ctx.r3.s64 = ctx.r30.s64 + 8;
	// bl 0x82c83238
	ctx.lr = 0x82C8526C;
	sub_82C83238(ctx, base);
	// lbz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 4);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c8528c
	if (ctx.cr6.eq) goto loc_82C8528C;
	// addi r4,r1,82
	ctx.r4.s64 = ctx.r1.s64 + 82;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c84200
	ctx.lr = 0x82C85288;
	sub_82C84200(ctx, base);
	// stb r3,4(r30)
	PPC_STORE_U8(ctx.r30.u32 + 4, ctx.r3.u8);
loc_82C8528C:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r9,28
	ctx.r9.s64 = 28;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c852a8
	if (ctx.cr6.eq) goto loc_82C852A8;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// subf r8,r11,r10
	ctx.r8.s64 = ctx.r10.s64 - ctx.r11.s64;
	// divw r11,r8,r9
	ctx.r11.s32 = ctx.r8.s32 / ctx.r9.s32;
loc_82C852A8:
	// lhz r10,82(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82c85300
	if (!ctx.cr6.lt) goto loc_82C85300;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c852d4
	if (ctx.cr6.eq) goto loc_82C852D4;
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// subf r7,r11,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r11.s64;
	// divw r6,r7,r9
	ctx.r6.s32 = ctx.r7.s32 / ctx.r9.s32;
	// cmplw cr6,r10,r6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82c852d8
	if (ctx.cr6.lt) goto loc_82C852D8;
loc_82C852D4:
	// twi 31,r0,22
loc_82C852D8:
	// mulli r10,r10,28
	ctx.r10.s64 = ctx.r10.s64 * 28;
	// add. r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq 0x82c85300
	if (ctx.cr0.eq) goto loc_82C85300;
	// li r6,-1
	ctx.r6.s64 = -1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8218ea38
	ctx.lr = 0x82C852F4;
	sub_8218EA38(ctx, base);
	// lbz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 4);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C85300:
	// lbz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c85320
	if (ctx.cr6.eq) goto loc_82C85320;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c669c0
	ctx.lr = 0x82C8531C;
	sub_82C669C0(ctx, base);
	// stb r3,4(r30)
	PPC_STORE_U8(ctx.r30.u32 + 4, ctx.r3.u8);
loc_82C85320:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c83378
	ctx.lr = 0x82C8532C;
	sub_82C83378(ctx, base);
	// lbz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 4);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C85338"))) PPC_WEAK_FUNC(sub_82C85338);
PPC_FUNC_IMPL(__imp__sub_82C85338) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82c84df8
	ctx.lr = 0x82C85358;
	sub_82C84DF8(ctx, base);
	// clrlwi r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c85370
	if (ctx.cr6.eq) goto loc_82C85370;
	// bl 0x824fe010
	ctx.lr = 0x82C8536C;
	sub_824FE010(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82C85370:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C85388"))) PPC_WEAK_FUNC(sub_82C85388);
PPC_FUNC_IMPL(__imp__sub_82C85388) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C85390;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// std r4,160(r1)
	PPC_STORE_U64(ctx.r1.u32 + 160, ctx.r4.u64);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c853c0
	if (ctx.cr6.eq) goto loc_82C853C0;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// srawi. r9,r9,6
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3F) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 6;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne 0x82c853c8
	if (!ctx.cr0.eq) goto loc_82C853C8;
loc_82C853C0:
	// li r30,0
	ctx.r30.s64 = 0;
	// b 0x82c853f8
	goto loc_82C853F8;
loc_82C853C8:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82c853d4
	if (!ctx.cr6.gt) goto loc_82C853D4;
	// twi 31,r0,22
loc_82C853D4:
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c853e8
	if (ctx.cr6.eq) goto loc_82C853E8;
	// cmplw cr6,r10,r31
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x82c853ec
	if (ctx.cr6.eq) goto loc_82C853EC;
loc_82C853E8:
	// twi 31,r0,22
loc_82C853EC:
	// lwz r10,164(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// srawi r30,r9,6
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3F) != 0);
	ctx.r30.s64 = ctx.r9.s32 >> 6;
loc_82C853F8:
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c84f58
	ctx.lr = 0x82C85404;
	sub_82C84F58(ctx, base);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82c85418
	if (!ctx.cr6.gt) goto loc_82C85418;
	// twi 31,r0,22
loc_82C85418:
	// rlwinm r10,r30,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 6) & 0xFFFFFFC0;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r31.u32);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// ld r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// bgt cr6,0x82c85448
	if (ctx.cr6.gt) goto loc_82C85448;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82c8544c
	if (!ctx.cr6.lt) goto loc_82C8544C;
loc_82C85448:
	// twi 31,r0,22
loc_82C8544C:
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// ld r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,0(r29)
	PPC_STORE_U64(ctx.r29.u32 + 0, ctx.r11.u64);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C85468"))) PPC_WEAK_FUNC(sub_82C85468);
PPC_FUNC_IMPL(__imp__sub_82C85468) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c85498
	if (!ctx.cr6.eq) goto loc_82C85498;
	// li r9,0
	ctx.r9.s64 = 0;
	// b 0x82c854a4
	goto loc_82C854A4;
loc_82C85498:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// srawi r9,r9,6
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3F) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 6;
loc_82C854A4:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c854f4
	if (ctx.cr6.eq) goto loc_82C854F4;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// subf r8,r11,r10
	ctx.r8.s64 = ctx.r10.s64 - ctx.r11.s64;
	// srawi r10,r8,6
	ctx.xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x3F) != 0);
	ctx.r10.s64 = ctx.r8.s32 >> 6;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82c854f4
	if (!ctx.cr6.lt) goto loc_82C854F4;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lbz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r30,8(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// lbz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// bl 0x82c849e8
	ctx.lr = 0x82C854E8;
	sub_82C849E8(ctx, base);
	// addi r9,r30,64
	ctx.r9.s64 = ctx.r30.s64 + 64;
	// stw r9,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r9.u32);
	// b 0x82c85520
	goto loc_82C85520;
loc_82C854F4:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82c85504
	if (!ctx.cr6.gt) goto loc_82C85504;
	// twi 31,r0,22
loc_82C85504:
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r31.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// ld r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// bl 0x82c85388
	ctx.lr = 0x82C85520;
	sub_82C85388(ctx, base);
loc_82C85520:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C85538"))) PPC_WEAK_FUNC(sub_82C85538);
PPC_FUNC_IMPL(__imp__sub_82C85538) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lbz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c85570
	if (ctx.cr6.eq) goto loc_82C85570;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82372268
	ctx.lr = 0x82C8556C;
	sub_82372268(ctx, base);
	// stb r3,4(r31)
	PPC_STORE_U8(ctx.r31.u32 + 4, ctx.r3.u8);
loc_82C85570:
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// bgt cr6,0x82c8563c
	if (ctx.cr6.gt) goto loc_82C8563C;
	// lis r12,-32056
	ctx.r12.s64 = -2100822016;
	// addi r12,r12,21916
	ctx.r12.s64 = ctx.r12.s64 + 21916;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C855B0;
	case 1:
		goto loc_82C855CC;
	case 2:
		goto loc_82C855E8;
	case 3:
		goto loc_82C85604;
	case 4:
		goto loc_82C85620;
	default:
		__builtin_unreachable();
	}
	// lwz r22,21936(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + 21936);
	// lwz r22,21964(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + 21964);
	// lwz r22,21992(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + 21992);
	// lwz r22,22020(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + 22020);
	// lwz r22,22048(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + 22048);
loc_82C855B0:
	// lbz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c8563c
	if (ctx.cr6.eq) goto loc_82C8563C;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r30,4
	ctx.r3.s64 = ctx.r30.s64 + 4;
	// bl 0x82c85250
	ctx.lr = 0x82C855C8;
	sub_82C85250(ctx, base);
	// b 0x82c85638
	goto loc_82C85638;
loc_82C855CC:
	// lbz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c8563c
	if (ctx.cr6.eq) goto loc_82C8563C;
	// addi r4,r30,32
	ctx.r4.s64 = ctx.r30.s64 + 32;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c842c8
	ctx.lr = 0x82C855E4;
	sub_82C842C8(ctx, base);
	// b 0x82c85638
	goto loc_82C85638;
loc_82C855E8:
	// lbz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c8563c
	if (ctx.cr6.eq) goto loc_82C8563C;
	// addi r4,r30,32
	ctx.r4.s64 = ctx.r30.s64 + 32;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c842c8
	ctx.lr = 0x82C85600;
	sub_82C842C8(ctx, base);
	// b 0x82c85638
	goto loc_82C85638;
loc_82C85604:
	// lbz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c8563c
	if (ctx.cr6.eq) goto loc_82C8563C;
	// addi r4,r30,32
	ctx.r4.s64 = ctx.r30.s64 + 32;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c842c8
	ctx.lr = 0x82C8561C;
	sub_82C842C8(ctx, base);
	// b 0x82c85638
	goto loc_82C85638;
loc_82C85620:
	// lbz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c8563c
	if (ctx.cr6.eq) goto loc_82C8563C;
	// addi r4,r30,32
	ctx.r4.s64 = ctx.r30.s64 + 32;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82372268
	ctx.lr = 0x82C85638;
	sub_82372268(ctx, base);
loc_82C85638:
	// stb r3,4(r31)
	PPC_STORE_U8(ctx.r31.u32 + 4, ctx.r3.u8);
loc_82C8563C:
	// lbz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r31.u32 + 4);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C85658"))) PPC_WEAK_FUNC(sub_82C85658);
PPC_FUNC_IMPL(__imp__sub_82C85658) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,32(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82c856bc
	if (!ctx.cr6.eq) goto loc_82C856BC;
	// lbz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 16);
	// addi r31,r30,12
	ctx.r31.s64 = ctx.r30.s64 + 12;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c8569c
	if (ctx.cr6.eq) goto loc_82C8569C;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r30,108
	ctx.r3.s64 = ctx.r30.s64 + 108;
	// bl 0x82c85538
	ctx.lr = 0x82C85698;
	sub_82C85538(ctx, base);
	// stb r3,4(r31)
	PPC_STORE_U8(ctx.r31.u32 + 4, ctx.r3.u8);
loc_82C8569C:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c84838
	ctx.lr = 0x82C856A8;
	sub_82C84838(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// addi r3,r30,108
	ctx.r3.s64 = ctx.r30.s64 + 108;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r10.u32);
	// b 0x82c856c0
	goto loc_82C856C0;
loc_82C856BC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C856C0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C856D8"))) PPC_WEAK_FUNC(sub_82C856D8);
PPC_FUNC_IMPL(__imp__sub_82C856D8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,32(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c85704
	if (ctx.cr6.eq) goto loc_82C85704;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c85740
	goto loc_82C85740;
loc_82C85704:
	// lbz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 16);
	// addi r31,r30,12
	ctx.r31.s64 = ctx.r30.s64 + 12;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c85724
	if (ctx.cr6.eq) goto loc_82C85724;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r30,80
	ctx.r3.s64 = ctx.r30.s64 + 80;
	// bl 0x82c85250
	ctx.lr = 0x82C85720;
	sub_82C85250(ctx, base);
	// stb r3,4(r31)
	PPC_STORE_U8(ctx.r31.u32 + 4, ctx.r3.u8);
loc_82C85724:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c84838
	ctx.lr = 0x82C85730;
	sub_82C84838(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// addi r3,r30,80
	ctx.r3.s64 = ctx.r30.s64 + 80;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r10.u32);
loc_82C85740:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C85758"))) PPC_WEAK_FUNC(sub_82C85758);
PPC_FUNC_IMPL(__imp__sub_82C85758) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C85760;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// bl 0x82c81ba8
	ctx.lr = 0x82C85770;
	sub_82C81BA8(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r30,0
	ctx.r30.s64 = 0;
	// addi r10,r11,-5920
	ctx.r10.s64 = ctx.r11.s64 + -5920;
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
	// addi r29,r31,12
	ctx.r29.s64 = ctx.r31.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// stw r28,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r28.u32);
	// beq cr6,0x82c857a8
	if (ctx.cr6.eq) goto loc_82C857A8;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C857A8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C857A8:
	// li r11,1
	ctx.r11.s64 = 1;
	// addi r3,r29,8
	ctx.r3.s64 = ctx.r29.s64 + 8;
	// stb r11,4(r29)
	PPC_STORE_U8(ctx.r29.u32 + 4, ctx.r11.u8);
	// bl 0x823445b0
	ctx.lr = 0x82C857B8;
	sub_823445B0(ctx, base);
	// li r10,4
	ctx.r10.s64 = 4;
	// stb r30,5(r29)
	PPC_STORE_U8(ctx.r29.u32 + 5, ctx.r30.u8);
	// li r11,15
	ctx.r11.s64 = 15;
	// stw r10,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r10.u32);
	// addi r10,r31,52
	ctx.r10.s64 = ctx.r31.s64 + 52;
	// stw r30,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r30.u32);
	// addi r10,r31,80
	ctx.r10.s64 = ctx.r31.s64 + 80;
	// stw r30,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r30.u32);
	// stw r30,44(r31)
	PPC_STORE_U32(ctx.r31.u32 + 44, ctx.r30.u32);
	// stw r30,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r30.u32);
	// stw r11,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r11.u32);
	// stw r30,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r30.u32);
	// stb r30,56(r31)
	PPC_STORE_U8(ctx.r31.u32 + 56, ctx.r30.u8);
	// stw r11,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r11.u32);
	// stw r30,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r30.u32);
	// stb r30,84(r31)
	PPC_STORE_U8(ctx.r31.u32 + 84, ctx.r30.u8);
	// stw r11,136(r31)
	PPC_STORE_U32(ctx.r31.u32 + 136, ctx.r11.u32);
	// addi r11,r31,108
	ctx.r11.s64 = ctx.r31.s64 + 108;
	// stw r30,132(r31)
	PPC_STORE_U32(ctx.r31.u32 + 132, ctx.r30.u32);
	// stb r30,116(r31)
	PPC_STORE_U8(ctx.r31.u32 + 116, ctx.r30.u8);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r30,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r30.u32);
	// li r11,4
	ctx.r11.s64 = 4;
	// stw r30,148(r31)
	PPC_STORE_U32(ctx.r31.u32 + 148, ctx.r30.u32);
	// stw r30,152(r31)
	PPC_STORE_U32(ctx.r31.u32 + 152, ctx.r30.u32);
	// stw r30,156(r31)
	PPC_STORE_U32(ctx.r31.u32 + 156, ctx.r30.u32);
	// lbz r9,4(r29)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r29.u32 + 4);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c85840
	if (ctx.cr6.eq) goto loc_82C85840;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82372268
	ctx.lr = 0x82C85838;
	sub_82372268(ctx, base);
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// stb r3,4(r29)
	PPC_STORE_U8(ctx.r29.u32 + 4, ctx.r3.u8);
loc_82C85840:
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c856d8
	ctx.lr = 0x82C8584C;
	sub_82C856D8(ctx, base);
	// stw r3,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r3.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C85860"))) PPC_WEAK_FUNC(sub_82C85860);
PPC_FUNC_IMPL(__imp__sub_82C85860) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C85868;
	__savegprlr_27(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r11,32(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 32);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c85888
	if (ctx.cr6.eq) goto loc_82C85888;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C85888:
	// addi r27,r28,144
	ctx.r27.s64 = ctx.r28.s64 + 144;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82c84ef8
	ctx.lr = 0x82C85894;
	sub_82C84EF8(ctx, base);
	// addi r30,r28,12
	ctx.r30.s64 = ctx.r28.s64 + 12;
	// li r29,15
	ctx.r29.s64 = 15;
	// li r31,0
	ctx.r31.s64 = 0;
loc_82C858A0:
	// lbz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 4);
	// stw r29,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r29.u32);
	// stw r31,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r31.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stb r31,116(r1)
	PPC_STORE_U8(ctx.r1.u32 + 116, ctx.r31.u8);
	// stw r29,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r29.u32);
	// stw r31,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r31.u32);
	// stb r31,148(r1)
	PPC_STORE_U8(ctx.r1.u32 + 148, ctx.r31.u8);
	// stw r31,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r31.u32);
	// beq cr6,0x82c85900
	if (ctx.cr6.eq) goto loc_82C85900;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c858e4
	if (ctx.cr6.eq) goto loc_82C858E4;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82c85250
	ctx.lr = 0x82C858E0;
	sub_82C85250(ctx, base);
	// stb r3,4(r30)
	PPC_STORE_U8(ctx.r30.u32 + 4, ctx.r3.u8);
loc_82C858E4:
	// lbz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c85900
	if (ctx.cr6.eq) goto loc_82C85900;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r1,140
	ctx.r3.s64 = ctx.r1.s64 + 140;
	// bl 0x82c85538
	ctx.lr = 0x82C858FC;
	sub_82C85538(ctx, base);
	// stb r3,4(r30)
	PPC_STORE_U8(ctx.r30.u32 + 4, ctx.r3.u8);
loc_82C85900:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82c85468
	ctx.lr = 0x82C8590C;
	sub_82C85468(ctx, base);
	// lbz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 4);
	// li r11,4
	ctx.r11.s64 = 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c85984
	if (ctx.cr6.eq) goto loc_82C85984;
	// lbz r11,5(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 5);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r8,r9,1
	ctx.r8.u64 = ctx.r9.u64 ^ 1;
	// clrlwi r7,r8,24
	ctx.r7.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c85954
	if (ctx.cr6.eq) goto loc_82C85954;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// b 0x82c85960
	goto loc_82C85960;
loc_82C85954:
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
loc_82C85960:
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C85970;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cntlzw r8,r3
	ctx.r8.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// lbz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// rlwinm r11,r8,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// stb r11,4(r30)
	PPC_STORE_U8(ctx.r30.u32 + 4, ctx.r11.u8);
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82C85984:
	// lwz r10,168(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// stw r11,32(r28)
	PPC_STORE_U32(ctx.r28.u32 + 32, ctx.r11.u32);
	// cmplwi cr6,r10,16
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 16, ctx.xer);
	// blt cr6,0x82c8599c
	if (ctx.cr6.lt) goto loc_82C8599C;
	// lwz r3,148(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// bl 0x824fe010
	ctx.lr = 0x82C8599C;
	sub_824FE010(ctx, base);
loc_82C8599C:
	// lwz r11,136(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stw r29,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r29.u32);
	// stw r31,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r31.u32);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// stb r31,148(r1)
	PPC_STORE_U8(ctx.r1.u32 + 148, ctx.r31.u8);
	// blt cr6,0x82c859bc
	if (ctx.cr6.lt) goto loc_82C859BC;
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// bl 0x824fe010
	ctx.lr = 0x82C859BC;
	sub_824FE010(ctx, base);
loc_82C859BC:
	// lwz r11,32(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 32);
	// stw r29,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r29.u32);
	// stw r31,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r31.u32);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// stb r31,116(r1)
	PPC_STORE_U8(ctx.r1.u32 + 116, ctx.r31.u8);
	// beq cr6,0x82c858a0
	if (ctx.cr6.eq) goto loc_82C858A0;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C859E0"))) PPC_WEAK_FUNC(sub_82C859E0);
PPC_FUNC_IMPL(__imp__sub_82C859E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,36(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c85a0c
	if (!ctx.cr6.eq) goto loc_82C85A0C;
loc_82C85A04:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c85a84
	goto loc_82C85A84;
loc_82C85A0C:
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c85a24
	if (ctx.cr6.eq) goto loc_82C85A24;
	// bl 0x82c84490
	ctx.lr = 0x82C85A18;
	sub_82C84490(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c85a04
	if (!ctx.cr6.eq) goto loc_82C85A04;
loc_82C85A24:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r4,36(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bne cr6,0x82c85a44
	if (!ctx.cr6.eq) goto loc_82C85A44;
	// li r30,0
	ctx.r30.s64 = 0;
	// b 0x82c85a58
	goto loc_82C85A58;
loc_82C85A44:
	// addi r30,r31,52
	ctx.r30.s64 = ctx.r31.s64 + 52;
	// li r6,-1
	ctx.r6.s64 = -1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x8218ea38
	ctx.lr = 0x82C85A58;
	sub_8218EA38(ctx, base);
loc_82C85A58:
	// stw r30,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r30.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c85860
	ctx.lr = 0x82C85A64;
	sub_82C85860(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c85658
	ctx.lr = 0x82C85A70;
	sub_82C85658(ctx, base);
	// stw r3,44(r31)
	PPC_STORE_U32(ctx.r31.u32 + 44, ctx.r3.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c856d8
	ctx.lr = 0x82C85A7C;
	sub_82C856D8(ctx, base);
	// stw r3,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r3.u32);
	// li r3,1
	ctx.r3.s64 = 1;
loc_82C85A84:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C85AA0"))) PPC_WEAK_FUNC(sub_82C85AA0);
PPC_FUNC_IMPL(__imp__sub_82C85AA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c85b70
	if (ctx.cr6.eq) goto loc_82C85B70;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r11.u32);
	// bl 0x82c85860
	ctx.lr = 0x82C85ACC;
	sub_82C85860(ctx, base);
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c85658
	ctx.lr = 0x82C85AD8;
	sub_82C85658(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r3,44(r31)
	PPC_STORE_U32(ctx.r31.u32 + 44, ctx.r3.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C85AF4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// clrlwi r8,r3,24
	ctx.r8.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82c85b38
	if (ctx.cr6.eq) goto loc_82C85B38;
loc_82C85B00:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C85B14;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r8,8(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82C85B2C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// clrlwi r7,r3,24
	ctx.r7.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c85b00
	if (!ctx.cr6.eq) goto loc_82C85B00;
loc_82C85B38:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// addi r4,r31,12
	ctx.r4.s64 = ctx.r31.s64 + 12;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bl 0x82c84838
	ctx.lr = 0x82C85B50;
	sub_82C84838(ctx, base);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// stw r10,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r10.u32);
	// beq cr6,0x82c85b70
	if (ctx.cr6.eq) goto loc_82C85B70;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c856d8
	ctx.lr = 0x82C85B6C;
	sub_82C856D8(ctx, base);
	// stw r3,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r3.u32);
loc_82C85B70:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C85B88"))) PPC_WEAK_FUNC(sub_82C85B88);
PPC_FUNC_IMPL(__imp__sub_82C85B88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,48
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 48, ctx.xer);
	// bne cr6,0x82c85bfc
	if (!ctx.cr6.eq) goto loc_82C85BFC;
	// lbz r11,1(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 1);
	// cmplwi cr6,r11,120
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 120, ctx.xer);
	// bne cr6,0x82c85bfc
	if (!ctx.cr6.eq) goto loc_82C85BFC;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// addi r3,r31,2
	ctx.r3.s64 = ctx.r31.s64 + 2;
	// bl 0x82c81c90
	ctx.lr = 0x82C85BCC;
	sub_82C81C90(ctx, base);
	// clrlwi r10,r3,24
	ctx.r10.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c85bf4
	if (!ctx.cr6.eq) goto loc_82C85BF4;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r30,r11,-5856
	ctx.r30.s64 = ctx.r11.s64 + -5856;
	// bl 0x82240578
	ctx.lr = 0x82C85BE4;
	sub_82240578(ctx, base);
	// addi r3,r3,64
	ctx.r3.s64 = ctx.r3.s64 + 64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// bl 0x82ca7120
	ctx.lr = 0x82C85BF4;
	sub_82CA7120(ctx, base);
loc_82C85BF4:
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// b 0x82c85c08
	goto loc_82C85C08;
loc_82C85BFC:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82ca3b40
	ctx.lr = 0x82C85C04;
	sub_82CA3B40(ctx, base);
	// rotlwi r3,r3,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
loc_82C85C08:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C85C20"))) PPC_WEAK_FUNC(sub_82C85C20);
PPC_FUNC_IMPL(__imp__sub_82C85C20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,32
	ctx.r4.s64 = 32;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82caaf10
	ctx.lr = 0x82C85C3C;
	sub_82CAAF10(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c85c74
	if (ctx.cr6.eq) goto loc_82C85C74;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,-5824
	ctx.r4.s64 = ctx.r11.s64 + -5824;
	// bl 0x82ca7408
	ctx.lr = 0x82C85C54;
	sub_82CA7408(ctx, base);
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// bne cr6,0x82c85c74
	if (!ctx.cr6.eq) goto loc_82C85C74;
	// lfs f1,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C85C74:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82ca5860
	ctx.lr = 0x82C85C7C;
	sub_82CA5860(ctx, base);
	// frsp f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C85C98"))) PPC_WEAK_FUNC(sub_82C85C98);
PPC_FUNC_IMPL(__imp__sub_82C85C98) {
	PPC_FUNC_PROLOGUE();
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82C85CA0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c85ca0
	if (!ctx.cr6.eq) goto loc_82C85CA0;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r8,r11,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82C85CCC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// cmpwi cr6,r9,32
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 32, ctx.xer);
	// beq cr6,0x82c85cf8
	if (ctx.cr6.eq) goto loc_82C85CF8;
	// cmpwi cr6,r9,9
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 9, ctx.xer);
	// beq cr6,0x82c85cf8
	if (ctx.cr6.eq) goto loc_82C85CF8;
	// cmpwi cr6,r9,10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 10, ctx.xer);
	// beq cr6,0x82c85cf8
	if (ctx.cr6.eq) goto loc_82C85CF8;
	// cmpwi cr6,r9,13
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 13, ctx.xer);
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
	// bne cr6,0x82c85cfc
	if (!ctx.cr6.eq) goto loc_82C85CFC;
loc_82C85CF8:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C85CFC:
	// clrlwi r9,r9,24
	ctx.r9.u64 = ctx.r9.u32 & 0xFF;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c85d10
	if (ctx.cr6.eq) goto loc_82C85D10;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x82c85ccc
	goto loc_82C85CCC;
loc_82C85D10:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,34
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 34, ctx.xer);
	// bne cr6,0x82c85d20
	if (!ctx.cr6.eq) goto loc_82C85D20;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82C85D20:
	// add r9,r8,r10
	ctx.r9.u64 = ctx.r8.u64 + ctx.r10.u64;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82c85d78
	if (!ctx.cr6.gt) goto loc_82C85D78;
loc_82C85D30:
	// lbz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// extsb r8,r8
	ctx.r8.s64 = ctx.r8.s8;
	// cmpwi cr6,r8,32
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 32, ctx.xer);
	// beq cr6,0x82c85d5c
	if (ctx.cr6.eq) goto loc_82C85D5C;
	// cmpwi cr6,r8,9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 9, ctx.xer);
	// beq cr6,0x82c85d5c
	if (ctx.cr6.eq) goto loc_82C85D5C;
	// cmpwi cr6,r8,10
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 10, ctx.xer);
	// beq cr6,0x82c85d5c
	if (ctx.cr6.eq) goto loc_82C85D5C;
	// cmpwi cr6,r8,13
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 13, ctx.xer);
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
	// bne cr6,0x82c85d60
	if (!ctx.cr6.eq) goto loc_82C85D60;
loc_82C85D5C:
	// li r8,1
	ctx.r8.s64 = 1;
loc_82C85D60:
	// clrlwi r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82c85d78
	if (ctx.cr6.eq) goto loc_82C85D78;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// bgt cr6,0x82c85d30
	if (ctx.cr6.gt) goto loc_82C85D30;
loc_82C85D78:
	// lbz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmplwi cr6,r8,34
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 34, ctx.xer);
	// bne cr6,0x82c85d88
	if (!ctx.cr6.eq) goto loc_82C85D88;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
loc_82C85D88:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82c85db8
	if (ctx.cr6.eq) goto loc_82C85DB8;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bgt cr6,0x82c85db0
	if (ctx.cr6.gt) goto loc_82C85DB0;
loc_82C85D98:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// stb r8,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r8.u8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// ble cr6,0x82c85d98
	if (!ctx.cr6.gt) goto loc_82C85D98;
loc_82C85DB0:
	// stb r7,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r7.u8);
	// blr 
	return;
loc_82C85DB8:
	// stb r7,1(r9)
	PPC_STORE_U8(ctx.r9.u32 + 1, ctx.r7.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C85DC0"))) PPC_WEAK_FUNC(sub_82C85DC0);
PPC_FUNC_IMPL(__imp__sub_82C85DC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C85DC8;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,3224
	ctx.r4.s64 = ctx.r11.s64 + 3224;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82c823d8
	ctx.lr = 0x82C85DE8;
	sub_82C823D8(ctx, base);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r10,-9784
	ctx.r4.s64 = ctx.r10.s64 + -9784;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r8,40(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 40);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82C85E08;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c81e58
	ctx.lr = 0x82C85E10;
	sub_82C81E58(ctx, base);
	// bl 0x82c892e0
	ctx.lr = 0x82C85E14;
	sub_82C892E0(ctx, base);
	// stw r3,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r3.u32);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r3,r11,12
	ctx.r3.s64 = ctx.r11.s64 + 12;
	// bl 0x82c81e58
	ctx.lr = 0x82C85E24;
	sub_82C81E58(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82C85E28:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c85e28
	if (!ctx.cr6.eq) goto loc_82C85E28;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// addi r4,r11,1
	ctx.r4.s64 = ctx.r11.s64 + 1;
	// bl 0x82c87b08
	ctx.lr = 0x82C85E50;
	sub_82C87B08(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c87a40
	ctx.lr = 0x82C85E58;
	sub_82C87A40(ctx, base);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r3,r11,12
	ctx.r3.s64 = ctx.r11.s64 + 12;
	// bl 0x82c81e58
	ctx.lr = 0x82C85E68;
	sub_82C81E58(ctx, base);
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82C85E6C:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// bne cr6,0x82c85e6c
	if (!ctx.cr6.eq) goto loc_82C85E6C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c85c98
	ctx.lr = 0x82C85E8C;
	sub_82C85C98(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C85E98"))) PPC_WEAK_FUNC(sub_82C85E98);
PPC_FUNC_IMPL(__imp__sub_82C85E98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C85EA0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r31,8(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c85ec8
	if (ctx.cr6.eq) goto loc_82C85EC8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c88a58
	ctx.lr = 0x82C85EC0;
	sub_82C88A58(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82ca29e8
	ctx.lr = 0x82C85EC8;
	sub_82CA29E8(ctx, base);
loc_82C85EC8:
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x82c88628
	ctx.lr = 0x82C85ED0;
	sub_82C88628(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c85ee0
	if (ctx.cr6.eq) goto loc_82C85EE0;
	// bl 0x82c88678
	ctx.lr = 0x82C85EDC;
	sub_82C88678(ctx, base);
	// b 0x82c85ee4
	goto loc_82C85EE4;
loc_82C85EE0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C85EE4:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r5,4(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x82c88b38
	ctx.lr = 0x82C85EF4;
	sub_82C88B38(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C85F00"))) PPC_WEAK_FUNC(sub_82C85F00);
PPC_FUNC_IMPL(__imp__sub_82C85F00) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C85F08;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r31,8(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c85f30
	if (ctx.cr6.eq) goto loc_82C85F30;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c88a58
	ctx.lr = 0x82C85F28;
	sub_82C88A58(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82ca29e8
	ctx.lr = 0x82C85F30;
	sub_82CA29E8(ctx, base);
loc_82C85F30:
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x82c88628
	ctx.lr = 0x82C85F38;
	sub_82C88628(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c85f48
	if (ctx.cr6.eq) goto loc_82C85F48;
	// bl 0x82c88678
	ctx.lr = 0x82C85F44;
	sub_82C88678(ctx, base);
	// b 0x82c85f4c
	goto loc_82C85F4C;
loc_82C85F48:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C85F4C:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r5,4(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x82c88bc8
	ctx.lr = 0x82C85F5C;
	sub_82C88BC8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C85F68"))) PPC_WEAK_FUNC(sub_82C85F68);
PPC_FUNC_IMPL(__imp__sub_82C85F68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C85F70;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// lwz r31,8(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c85f9c
	if (ctx.cr6.eq) goto loc_82C85F9C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c88a58
	ctx.lr = 0x82C85F94;
	sub_82C88A58(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82ca29e8
	ctx.lr = 0x82C85F9C;
	sub_82CA29E8(ctx, base);
loc_82C85F9C:
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x82c88628
	ctx.lr = 0x82C85FA4;
	sub_82C88628(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c85fb4
	if (ctx.cr6.eq) goto loc_82C85FB4;
	// bl 0x82c88678
	ctx.lr = 0x82C85FB0;
	sub_82C88678(ctx, base);
	// b 0x82c85fb8
	goto loc_82C85FB8;
loc_82C85FB4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C85FB8:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82c88c58
	ctx.lr = 0x82C85FC8;
	sub_82C88C58(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C85FD0"))) PPC_WEAK_FUNC(sub_82C85FD0);
PPC_FUNC_IMPL(__imp__sub_82C85FD0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82c879b0
	ctx.lr = 0x82C85FFC;
	sub_82C879B0(ctx, base);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c85dc0
	ctx.lr = 0x82C8600C;
	sub_82C85DC0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C86014;
	sub_82C87A40(ctx, base);
	// bl 0x82ca3b30
	ctx.lr = 0x82C86018;
	sub_82CA3B30(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86024;
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86040"))) PPC_WEAK_FUNC(sub_82C86040);
PPC_FUNC_IMPL(__imp__sub_82C86040) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82c879b0
	ctx.lr = 0x82C8606C;
	sub_82C879B0(ctx, base);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c85dc0
	ctx.lr = 0x82C8607C;
	sub_82C85DC0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C86084;
	sub_82C87A40(ctx, base);
	// bl 0x82c85b88
	ctx.lr = 0x82C86088;
	sub_82C85B88(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86094;
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C860B0"))) PPC_WEAK_FUNC(sub_82C860B0);
PPC_FUNC_IMPL(__imp__sub_82C860B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82c879b0
	ctx.lr = 0x82C860DC;
	sub_82C879B0(ctx, base);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c85dc0
	ctx.lr = 0x82C860EC;
	sub_82C85DC0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C860F4;
	sub_82C87A40(ctx, base);
	// bl 0x82c85c20
	ctx.lr = 0x82C860F8;
	sub_82C85C20(ctx, base);
	// stfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86104;
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86120"))) PPC_WEAK_FUNC(sub_82C86120);
PPC_FUNC_IMPL(__imp__sub_82C86120) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82c879b0
	ctx.lr = 0x82C8614C;
	sub_82C879B0(ctx, base);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c85dc0
	ctx.lr = 0x82C8615C;
	sub_82C85DC0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C86164;
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c825a0
	ctx.lr = 0x82C86170;
	sub_82C825A0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86178;
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86190"))) PPC_WEAK_FUNC(sub_82C86190);
PPC_FUNC_IMPL(__imp__sub_82C86190) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82c879b0
	ctx.lr = 0x82C861BC;
	sub_82C879B0(ctx, base);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c85dc0
	ctx.lr = 0x82C861CC;
	sub_82C85DC0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C861D4;
	sub_82C87A40(ctx, base);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r4,r10,3900
	ctx.r4.s64 = ctx.r10.s64 + 3900;
	// bl 0x82caaf80
	ctx.lr = 0x82C861E0;
	sub_82CAAF80(ctx, base);
	// cntlzw r9,r3
	ctx.r9.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// stb r8,0(r30)
	PPC_STORE_U8(ctx.r30.u32 + 0, ctx.r8.u8);
	// bl 0x82c87a10
	ctx.lr = 0x82C861F4;
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86210"))) PPC_WEAK_FUNC(sub_82C86210);
PPC_FUNC_IMPL(__imp__sub_82C86210) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,76(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C86234;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r8,68(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 68);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82C86248;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86260"))) PPC_WEAK_FUNC(sub_82C86260);
PPC_FUNC_IMPL(__imp__sub_82C86260) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86274
	if (ctx.cr6.eq) goto loc_82C86274;
	// addi r3,r11,8
	ctx.r3.s64 = ctx.r11.s64 + 8;
	// b 0x82c81e58
	sub_82C81E58(ctx, base);
	return;
loc_82C86274:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86280"))) PPC_WEAK_FUNC(sub_82C86280);
PPC_FUNC_IMPL(__imp__sub_82C86280) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,12(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r3,r11,12
	ctx.r3.s64 = ctx.r11.s64 + 12;
	// bl 0x82c81e58
	ctx.lr = 0x82C862A4;
	sub_82C81E58(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	ctx.lr = 0x82C862B0;
	sub_82C879B0(ctx, base);
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82C862B4:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c862b4
	if (!ctx.cr6.eq) goto loc_82C862B4;
	// subf r11,r31,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r31.s64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// addi r4,r11,1
	ctx.r4.s64 = ctx.r11.s64 + 1;
	// bl 0x82c87b08
	ctx.lr = 0x82C862DC;
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C862E4;
	sub_82C87A40(ctx, base);
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// subf r10,r31,r3
	ctx.r10.s64 = ctx.r3.s64 - ctx.r31.s64;
loc_82C862EC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// stbx r9,r10,r11
	PPC_STORE_U8(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// bne cr6,0x82c862ec
	if (!ctx.cr6.eq) goto loc_82C862EC;
	// bl 0x82c85c98
	ctx.lr = 0x82C86304;
	sub_82C85C98(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c823d8
	ctx.lr = 0x82C86310;
	sub_82C823D8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86318;
	sub_82C87A10(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86338"))) PPC_WEAK_FUNC(sub_82C86338);
PPC_FUNC_IMPL(__imp__sub_82C86338) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82c81ba8
	ctx.lr = 0x82C86350;
	sub_82C81BA8(ctx, base);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r9,r10,-5816
	ctx.r9.s64 = ctx.r10.s64 + -5816;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// stb r11,20(r31)
	PPC_STORE_U8(ctx.r31.u32 + 20, ctx.r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86388"))) PPC_WEAK_FUNC(sub_82C86388);
PPC_FUNC_IMPL(__imp__sub_82C86388) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r10,r11,-5816
	ctx.r10.s64 = ctx.r11.s64 + -5816;
	// lwz r30,8(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c863c8
	if (ctx.cr6.eq) goto loc_82C863C8;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c88a58
	ctx.lr = 0x82C863C0;
	sub_82C88A58(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82ca29e8
	ctx.lr = 0x82C863C8;
	sub_82CA29E8(ctx, base);
loc_82C863C8:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c81bf8
	ctx.lr = 0x82C863D0;
	sub_82C81BF8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C863E8"))) PPC_WEAK_FUNC(sub_82C863E8);
PPC_FUNC_IMPL(__imp__sub_82C863E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C863F0;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86490
	if (ctx.cr6.eq) goto loc_82C86490;
	// clrlwi r27,r6,24
	ctx.r27.u64 = ctx.r6.u32 & 0xFF;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82c86424
	if (ctx.cr6.eq) goto loc_82C86424;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82c8642c
	if (!ctx.cr6.eq) goto loc_82C8642C;
	// lwz r29,20(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
loc_82C86424:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82c8646c
	if (ctx.cr6.eq) goto loc_82C8646C;
loc_82C8642C:
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
loc_82C86430:
	// addi r3,r31,8
	ctx.r3.s64 = ctx.r31.s64 + 8;
	// bl 0x82c81e58
	ctx.lr = 0x82C86438;
	sub_82C81E58(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82caaf08
	ctx.lr = 0x82C86440;
	sub_82CAAF08(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c86478
	if (ctx.cr6.eq) goto loc_82C86478;
	// lwz r31,4(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82c86464
	if (!ctx.cr6.eq) goto loc_82C86464;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82c8646c
	if (ctx.cr6.eq) goto loc_82C8646C;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r31,20(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
loc_82C86464:
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// bne cr6,0x82c86430
	if (!ctx.cr6.eq) goto loc_82C86430;
loc_82C8646C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C86478:
	// stw r31,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r31.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// stw r11,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C86490:
	// clrlwi r11,r6,24
	ctx.r11.u64 = ctx.r6.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c864a8
	if (!ctx.cr6.eq) goto loc_82C864A8;
	// lbz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8646c
	if (!ctx.cr6.eq) goto loc_82C8646C;
loc_82C864A8:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r31,0(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c8646c
	if (ctx.cr6.eq) goto loc_82C8646C;
	// addi r3,r31,8
	ctx.r3.s64 = ctx.r31.s64 + 8;
	// bl 0x82c81e58
	ctx.lr = 0x82C864C0;
	sub_82C81E58(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82caaf08
	ctx.lr = 0x82C864C8;
	sub_82CAAF08(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8646c
	if (!ctx.cr6.eq) goto loc_82C8646C;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r31,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r31.u32);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r10,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r10.u32);
	// stb r11,20(r30)
	PPC_STORE_U8(ctx.r30.u32 + 20, ctx.r11.u8);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C864F0"))) PPC_WEAK_FUNC(sub_82C864F0);
PPC_FUNC_IMPL(__imp__sub_82C864F0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r10.u32);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86508"))) PPC_WEAK_FUNC(sub_82C86508);
PPC_FUNC_IMPL(__imp__sub_82C86508) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c86558
	if (ctx.cr6.eq) goto loc_82C86558;
	// bl 0x82c88ee8
	ctx.lr = 0x82C8652C;
	sub_82C88EE8(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c86558
	if (ctx.cr6.eq) goto loc_82C86558;
	// bl 0x82ca3b30
	ctx.lr = 0x82C86538;
	sub_82CA3B30(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C86558:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86570"))) PPC_WEAK_FUNC(sub_82C86570);
PPC_FUNC_IMPL(__imp__sub_82C86570) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c865c0
	if (ctx.cr6.eq) goto loc_82C865C0;
	// bl 0x82c88ee8
	ctx.lr = 0x82C86594;
	sub_82C88EE8(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c865c0
	if (ctx.cr6.eq) goto loc_82C865C0;
	// bl 0x82c85b88
	ctx.lr = 0x82C865A0;
	sub_82C85B88(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C865C0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C865D8"))) PPC_WEAK_FUNC(sub_82C865D8);
PPC_FUNC_IMPL(__imp__sub_82C865D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c86624
	if (ctx.cr6.eq) goto loc_82C86624;
	// bl 0x82c88ee8
	ctx.lr = 0x82C865FC;
	sub_82C88EE8(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c86624
	if (ctx.cr6.eq) goto loc_82C86624;
	// bl 0x82c85c20
	ctx.lr = 0x82C86608;
	sub_82C85C20(ctx, base);
	// stfs f1,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C86624:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86640"))) PPC_WEAK_FUNC(sub_82C86640);
PPC_FUNC_IMPL(__imp__sub_82C86640) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c8669c
	if (ctx.cr6.eq) goto loc_82C8669C;
	// bl 0x82c88ee8
	ctx.lr = 0x82C86664;
	sub_82C88EE8(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c8669c
	if (ctx.cr6.eq) goto loc_82C8669C;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// addi r4,r11,3900
	ctx.r4.s64 = ctx.r11.s64 + 3900;
	// bl 0x82caaf80
	ctx.lr = 0x82C86678;
	sub_82CAAF80(ctx, base);
	// cntlzw r10,r3
	ctx.r10.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// stb r9,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r9.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C8669C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C866B8"))) PPC_WEAK_FUNC(sub_82C866B8);
PPC_FUNC_IMPL(__imp__sub_82C866B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c86710
	if (ctx.cr6.eq) goto loc_82C86710;
	// bl 0x82c88ee8
	ctx.lr = 0x82C866DC;
	sub_82C88EE8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c86710
	if (ctx.cr6.eq) goto loc_82C86710;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c823d8
	ctx.lr = 0x82C866F0;
	sub_82C823D8(ctx, base);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C86710:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86728"))) PPC_WEAK_FUNC(sub_82C86728);
PPC_FUNC_IMPL(__imp__sub_82C86728) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c8676c
	if (ctx.cr6.eq) goto loc_82C8676C;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c8674c
	if (ctx.cr6.eq) goto loc_82C8674C;
	// stw r10,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
	// b 0x82c86798
	goto loc_82C86798;
loc_82C8674C:
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c867b4
	if (ctx.cr6.eq) goto loc_82C867B4;
	// lwz r10,20(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c867b4
	if (ctx.cr6.eq) goto loc_82C867B4;
	// stw r10,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
	// b 0x82c86798
	goto loc_82C86798;
loc_82C8676C:
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c86784
	if (!ctx.cr6.eq) goto loc_82C86784;
	// lbz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 20);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c86798
	if (!ctx.cr6.eq) goto loc_82C86798;
loc_82C86784:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stb r9,20(r11)
	PPC_STORE_U8(ctx.r11.u32 + 20, ctx.r9.u8);
	// stw r8,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r8.u32);
loc_82C86798:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c867b4
	if (ctx.cr6.eq) goto loc_82C867B4;
	// lwz r9,20(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// addi r3,r10,8
	ctx.r3.s64 = ctx.r10.s64 + 8;
	// stw r9,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r9.u32);
	// b 0x82c81e58
	sub_82C81E58(ctx, base);
	return;
loc_82C867B4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C867C0"))) PPC_WEAK_FUNC(sub_82C867C0);
PPC_FUNC_IMPL(__imp__sub_82C867C0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c867d4
	if (ctx.cr6.eq) goto loc_82C867D4;
	// lwz r5,20(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// b 0x82c867d8
	goto loc_82C867D8;
loc_82C867D4:
	// li r5,0
	ctx.r5.s64 = 0;
loc_82C867D8:
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82c863e8
	sub_82C863E8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C867E0"))) PPC_WEAK_FUNC(sub_82C867E0);
PPC_FUNC_IMPL(__imp__sub_82C867E0) {
	PPC_FUNC_PROLOGUE();
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x82c86728
	sub_82C86728(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C867E8"))) PPC_WEAK_FUNC(sub_82C867E8);
PPC_FUNC_IMPL(__imp__sub_82C867E8) {
	PPC_FUNC_PROLOGUE();
	// lwz r5,16(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82c863e8
	sub_82C863E8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C867F8"))) PPC_WEAK_FUNC(sub_82C867F8);
PPC_FUNC_IMPL(__imp__sub_82C867F8) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// xori r3,r8,1
	ctx.r3.u64 = ctx.r8.u64 ^ 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86810"))) PPC_WEAK_FUNC(sub_82C86810);
PPC_FUNC_IMPL(__imp__sub_82C86810) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86828"))) PPC_WEAK_FUNC(sub_82C86828);
PPC_FUNC_IMPL(__imp__sub_82C86828) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C86830;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// addi r10,r11,-5816
	ctx.r10.s64 = ctx.r11.s64 + -5816;
	// lwz r30,8(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c86864
	if (ctx.cr6.eq) goto loc_82C86864;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c88a58
	ctx.lr = 0x82C8685C;
	sub_82C88A58(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82ca29e8
	ctx.lr = 0x82C86864;
	sub_82CA29E8(ctx, base);
loc_82C86864:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c81bf8
	ctx.lr = 0x82C8686C;
	sub_82C81BF8(ctx, base);
	// clrlwi r11,r29,31
	ctx.r11.u64 = ctx.r29.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86884
	if (ctx.cr6.eq) goto loc_82C86884;
	// bl 0x824fe010
	ctx.lr = 0x82C86880;
	sub_824FE010(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82C86884:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86890"))) PPC_WEAK_FUNC(sub_82C86890);
PPC_FUNC_IMPL(__imp__sub_82C86890) {
	PPC_FUNC_PROLOGUE();
	// lwz r5,16(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// li r6,1
	ctx.r6.s64 = 1;
	// b 0x82c863e8
	sub_82C863E8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C868A0"))) PPC_WEAK_FUNC(sub_82C868A0);
PPC_FUNC_IMPL(__imp__sub_82C868A0) {
	PPC_FUNC_PROLOGUE();
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x82c86728
	sub_82C86728(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C868A8"))) PPC_WEAK_FUNC(sub_82C868A8);
PPC_FUNC_IMPL(__imp__sub_82C868A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// li r4,128
	ctx.r4.s64 = 128;
	// stfs f31,132(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c87b08
	ctx.lr = 0x82C868D4;
	sub_82C87B08(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r31,r11,-5728
	ctx.r31.s64 = ctx.r11.s64 + -5728;
	// bl 0x82c87a40
	ctx.lr = 0x82C868E4;
	sub_82C87A40(ctx, base);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// stfd f1,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.f1.u64);
	// ld r6,40(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 40);
	// li r4,128
	ctx.r4.s64 = 128;
	// lwz r7,132(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// bl 0x82ca3eb8
	ctx.lr = 0x82C86900;
	sub_82CA3EB8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86918"))) PPC_WEAK_FUNC(sub_82C86918);
PPC_FUNC_IMPL(__imp__sub_82C86918) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82c87b08
	ctx.lr = 0x82C86940;
	sub_82C87B08(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c87a40
	ctx.lr = 0x82C86948;
	sub_82C87A40(ctx, base);
	// clrlwi r11,r31,24
	ctx.r11.u64 = ctx.r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86960
	if (ctx.cr6.eq) goto loc_82C86960;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r5,r11,-22980
	ctx.r5.s64 = ctx.r11.s64 + -22980;
	// b 0x82c86968
	goto loc_82C86968;
loc_82C86960:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r5,r11,-22988
	ctx.r5.s64 = ctx.r11.s64 + -22988;
loc_82C86968:
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82ca3eb8
	ctx.lr = 0x82C86970;
	sub_82CA3EB8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86988"))) PPC_WEAK_FUNC(sub_82C86988);
PPC_FUNC_IMPL(__imp__sub_82C86988) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c869d0
	if (!ctx.cr6.eq) goto loc_82C869D0;
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x82c88628
	ctx.lr = 0x82C869B8;
	sub_82C88628(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c869c8
	if (ctx.cr6.eq) goto loc_82C869C8;
	// bl 0x82c88678
	ctx.lr = 0x82C869C4;
	sub_82C88678(ctx, base);
	// b 0x82c869cc
	goto loc_82C869CC;
loc_82C869C8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C869CC:
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
loc_82C869D0:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82c89270
	ctx.lr = 0x82C869E0;
	sub_82C89270(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// beq cr6,0x82c869fc
	if (ctx.cr6.eq) goto loc_82C869FC;
	// bl 0x82c88d78
	ctx.lr = 0x82C869F8;
	sub_82C88D78(ctx, base);
	// b 0x82c86a04
	goto loc_82C86A04;
loc_82C869FC:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x82c88630
	ctx.lr = 0x82C86A04;
	sub_82C88630(ctx, base);
loc_82C86A04:
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r30,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r30.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86A30"))) PPC_WEAK_FUNC(sub_82C86A30);
PPC_FUNC_IMPL(__imp__sub_82C86A30) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86A40"))) PPC_WEAK_FUNC(sub_82C86A40);
PPC_FUNC_IMPL(__imp__sub_82C86A40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C86A48;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82c892c8
	ctx.lr = 0x82C86A60;
	sub_82C892C8(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c892c8
	ctx.lr = 0x82C86A68;
	sub_82C892C8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c823d8
	ctx.lr = 0x82C86A74;
	sub_82C823D8(ctx, base);
	// lbz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86aa0
	if (ctx.cr6.eq) goto loc_82C86AA0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r10,-9784
	ctx.r4.s64 = ctx.r10.s64 + -9784;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r9,40(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C86AA0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C86AA0:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// bl 0x82c88cf0
	ctx.lr = 0x82C86AAC;
	sub_82C88CF0(ctx, base);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86AC0"))) PPC_WEAK_FUNC(sub_82C86AC0);
PPC_FUNC_IMPL(__imp__sub_82C86AC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C86AC8;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86b48
	if (ctx.cr6.eq) goto loc_82C86B48;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	ctx.lr = 0x82C86AEC;
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82c87b08
	ctx.lr = 0x82C86AFC;
	sub_82C87B08(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r28,r11,2864
	ctx.r28.s64 = ctx.r11.s64 + 2864;
	// bl 0x82c87a40
	ctx.lr = 0x82C86B0C;
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// bl 0x82ca3eb8
	ctx.lr = 0x82C86B1C;
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c87a40
	ctx.lr = 0x82C86B28;
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r10,88(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C86B40;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86B48;
	sub_82C87A10(ctx, base);
loc_82C86B48:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86B50"))) PPC_WEAK_FUNC(sub_82C86B50);
PPC_FUNC_IMPL(__imp__sub_82C86B50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C86B58;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86bd8
	if (ctx.cr6.eq) goto loc_82C86BD8;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	ctx.lr = 0x82C86B7C;
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82c87b08
	ctx.lr = 0x82C86B8C;
	sub_82C87B08(ctx, base);
	// lis r11,-32246
	ctx.r11.s64 = -2113273856;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r28,r11,30568
	ctx.r28.s64 = ctx.r11.s64 + 30568;
	// bl 0x82c87a40
	ctx.lr = 0x82C86B9C;
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// bl 0x82ca3eb8
	ctx.lr = 0x82C86BAC;
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c87a40
	ctx.lr = 0x82C86BB8;
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r10,88(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C86BD0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86BD8;
	sub_82C87A10(ctx, base);
loc_82C86BD8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86BE0"))) PPC_WEAK_FUNC(sub_82C86BE0);
PPC_FUNC_IMPL(__imp__sub_82C86BE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C86BE8;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86c44
	if (ctx.cr6.eq) goto loc_82C86C44;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	ctx.lr = 0x82C86C0C;
	sub_82C879B0(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82c868a8
	ctx.lr = 0x82C86C18;
	sub_82C868A8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c87a40
	ctx.lr = 0x82C86C24;
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C86C3C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86C44;
	sub_82C87A10(ctx, base);
loc_82C86C44:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86C50"))) PPC_WEAK_FUNC(sub_82C86C50);
PPC_FUNC_IMPL(__imp__sub_82C86C50) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r3,12(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// b 0x82c88e68
	sub_82C88E68(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86C6C"))) PPC_WEAK_FUNC(sub_82C86C6C);
PPC_FUNC_IMPL(__imp__sub_82C86C6C) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86C70"))) PPC_WEAK_FUNC(sub_82C86C70);
PPC_FUNC_IMPL(__imp__sub_82C86C70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C86C78;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r31,0(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82c81e58
	ctx.lr = 0x82C86C90;
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C86CA8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86CB0"))) PPC_WEAK_FUNC(sub_82C86CB0);
PPC_FUNC_IMPL(__imp__sub_82C86CB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C86CB8;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86d14
	if (ctx.cr6.eq) goto loc_82C86D14;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	ctx.lr = 0x82C86CDC;
	sub_82C879B0(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// bl 0x82c86918
	ctx.lr = 0x82C86CE8;
	sub_82C86918(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c87a40
	ctx.lr = 0x82C86CF4;
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C86D0C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86D14;
	sub_82C87A10(ctx, base);
loc_82C86D14:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86D20"))) PPC_WEAK_FUNC(sub_82C86D20);
PPC_FUNC_IMPL(__imp__sub_82C86D20) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C86D28;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86da8
	if (ctx.cr6.eq) goto loc_82C86DA8;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	ctx.lr = 0x82C86D4C;
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82c87b08
	ctx.lr = 0x82C86D5C;
	sub_82C87B08(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r28,r11,2864
	ctx.r28.s64 = ctx.r11.s64 + 2864;
	// bl 0x82c87a40
	ctx.lr = 0x82C86D6C;
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// bl 0x82ca3eb8
	ctx.lr = 0x82C86D7C;
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c87a40
	ctx.lr = 0x82C86D88;
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r10,88(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C86DA0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86DA8;
	sub_82C87A10(ctx, base);
loc_82C86DA8:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86DB8"))) PPC_WEAK_FUNC(sub_82C86DB8);
PPC_FUNC_IMPL(__imp__sub_82C86DB8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C86DC0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86e40
	if (ctx.cr6.eq) goto loc_82C86E40;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	ctx.lr = 0x82C86DE4;
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82c87b08
	ctx.lr = 0x82C86DF4;
	sub_82C87B08(ctx, base);
	// lis r11,-32246
	ctx.r11.s64 = -2113273856;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r28,r11,30568
	ctx.r28.s64 = ctx.r11.s64 + 30568;
	// bl 0x82c87a40
	ctx.lr = 0x82C86E04;
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// bl 0x82ca3eb8
	ctx.lr = 0x82C86E14;
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c87a40
	ctx.lr = 0x82C86E20;
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r10,88(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C86E38;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86E40;
	sub_82C87A10(ctx, base);
loc_82C86E40:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86E50"))) PPC_WEAK_FUNC(sub_82C86E50);
PPC_FUNC_IMPL(__imp__sub_82C86E50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C86E58;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86eb4
	if (ctx.cr6.eq) goto loc_82C86EB4;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	ctx.lr = 0x82C86E7C;
	sub_82C879B0(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82c868a8
	ctx.lr = 0x82C86E88;
	sub_82C868A8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c87a40
	ctx.lr = 0x82C86E94;
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C86EAC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86EB4;
	sub_82C87A10(ctx, base);
loc_82C86EB4:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86EC0"))) PPC_WEAK_FUNC(sub_82C86EC0);
PPC_FUNC_IMPL(__imp__sub_82C86EC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C86EC8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r31,0(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82c81e58
	ctx.lr = 0x82C86EE0;
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C86EF8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86F08"))) PPC_WEAK_FUNC(sub_82C86F08);
PPC_FUNC_IMPL(__imp__sub_82C86F08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C86F10;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c86f6c
	if (ctx.cr6.eq) goto loc_82C86F6C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c879b0
	ctx.lr = 0x82C86F34;
	sub_82C879B0(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// bl 0x82c86918
	ctx.lr = 0x82C86F40;
	sub_82C86918(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c87a40
	ctx.lr = 0x82C86F4C;
	sub_82C87A40(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r11,88(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C86F64;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C86F6C;
	sub_82C87A10(ctx, base);
loc_82C86F6C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86F78"))) PPC_WEAK_FUNC(sub_82C86F78);
PPC_FUNC_IMPL(__imp__sub_82C86F78) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// b 0x82c88cf8
	sub_82C88CF8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86F80"))) PPC_WEAK_FUNC(sub_82C86F80);
PPC_FUNC_IMPL(__imp__sub_82C86F80) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,8(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// b 0x82c886f0
	sub_82C886F0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C86F88"))) PPC_WEAK_FUNC(sub_82C86F88);
PPC_FUNC_IMPL(__imp__sub_82C86F88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r8,84(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82C86FB4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C86FC8"))) PPC_WEAK_FUNC(sub_82C86FC8);
PPC_FUNC_IMPL(__imp__sub_82C86FC8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r8,80(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82C86FF4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87008"))) PPC_WEAK_FUNC(sub_82C87008);
PPC_FUNC_IMPL(__imp__sub_82C87008) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r10,76(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C87030;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87040"))) PPC_WEAK_FUNC(sub_82C87040);
PPC_FUNC_IMPL(__imp__sub_82C87040) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x82c81e58
	ctx.lr = 0x82C8705C;
	sub_82C81E58(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C87074;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87088"))) PPC_WEAK_FUNC(sub_82C87088);
PPC_FUNC_IMPL(__imp__sub_82C87088) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lwz r8,64(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// stb r9,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r9.u8);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82C870B4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C870C8"))) PPC_WEAK_FUNC(sub_82C870C8);
PPC_FUNC_IMPL(__imp__sub_82C870C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C870D0;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	ctx.lr = 0x82C870E4;
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82c87b08
	ctx.lr = 0x82C870F4;
	sub_82C87B08(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r29,r11,2864
	ctx.r29.s64 = ctx.r11.s64 + 2864;
	// bl 0x82c87a40
	ctx.lr = 0x82C87104;
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// bl 0x82ca3eb8
	ctx.lr = 0x82C87114;
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C8711C;
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82c86a40
	ctx.lr = 0x82C8712C;
	sub_82C86A40(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C87134;
	sub_82C87A10(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C87140"))) PPC_WEAK_FUNC(sub_82C87140);
PPC_FUNC_IMPL(__imp__sub_82C87140) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C87148;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	ctx.lr = 0x82C8715C;
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r30,0(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82c87b08
	ctx.lr = 0x82C8716C;
	sub_82C87B08(ctx, base);
	// lis r11,-32246
	ctx.r11.s64 = -2113273856;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r29,r11,30568
	ctx.r29.s64 = ctx.r11.s64 + 30568;
	// bl 0x82c87a40
	ctx.lr = 0x82C8717C;
	sub_82C87A40(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// bl 0x82ca3eb8
	ctx.lr = 0x82C8718C;
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C87194;
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// bl 0x82c86a40
	ctx.lr = 0x82C871A4;
	sub_82C86A40(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C871AC;
	sub_82C87A10(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C871B8"))) PPC_WEAK_FUNC(sub_82C871B8);
PPC_FUNC_IMPL(__imp__sub_82C871B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, ctx.f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	ctx.lr = 0x82C871E0;
	sub_82C879B0(ctx, base);
	// li r4,128
	ctx.r4.s64 = 128;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f31,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// stfs f31,84(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x82c87b08
	ctx.lr = 0x82C871F4;
	sub_82C87B08(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r30,r11,-5728
	ctx.r30.s64 = ctx.r11.s64 + -5728;
	// bl 0x82c87a40
	ctx.lr = 0x82C87204;
	sub_82C87A40(ctx, base);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// stfd f1,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.f1.u64);
	// ld r6,40(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 40);
	// li r4,128
	ctx.r4.s64 = 128;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82ca3eb8
	ctx.lr = 0x82C87220;
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C87228;
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// bl 0x82c86a40
	ctx.lr = 0x82C87238;
	sub_82C86A40(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C87240;
	sub_82C87A10(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87260"))) PPC_WEAK_FUNC(sub_82C87260);
PPC_FUNC_IMPL(__imp__sub_82C87260) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r31,0(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82c81e58
	ctx.lr = 0x82C87284;
	sub_82C81E58(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C87298;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C872B0"))) PPC_WEAK_FUNC(sub_82C872B0);
PPC_FUNC_IMPL(__imp__sub_82C872B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	ctx.lr = 0x82C872D4;
	sub_82C879B0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lbz r30,0(r30)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// bl 0x82c87b08
	ctx.lr = 0x82C872E4;
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C872EC;
	sub_82C87A40(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c87300
	if (ctx.cr6.eq) goto loc_82C87300;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r5,r11,-22980
	ctx.r5.s64 = ctx.r11.s64 + -22980;
	// b 0x82c87308
	goto loc_82C87308;
loc_82C87300:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r5,r11,-22988
	ctx.r5.s64 = ctx.r11.s64 + -22988;
loc_82C87308:
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82ca3eb8
	ctx.lr = 0x82C87310;
	sub_82CA3EB8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C87318;
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// li r5,5
	ctx.r5.s64 = 5;
	// bl 0x82c86a40
	ctx.lr = 0x82C87328;
	sub_82C86A40(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C87330;
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87348"))) PPC_WEAK_FUNC(sub_82C87348);
PPC_FUNC_IMPL(__imp__sub_82C87348) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bd4
	ctx.lr = 0x82C87350;
	__savegprlr_23(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r24,r4
	ctx.r24.u64 = ctx.r4.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,3224
	ctx.r4.s64 = ctx.r11.s64 + 3224;
	// bl 0x82c823d8
	ctx.lr = 0x82C8736C;
	sub_82C823D8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c81e58
	ctx.lr = 0x82C87374;
	sub_82C81E58(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82C87378:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c87378
	if (!ctx.cr6.eq) goto loc_82C87378;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r27,r11,0
	ctx.r27.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// bl 0x82c81e58
	ctx.lr = 0x82C8739C;
	sub_82C81E58(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82c8747c
	if (ctx.cr6.eq) goto loc_82C8747C;
	// lis r11,-31953
	ctx.r11.s64 = -2094071808;
	// li r25,0
	ctx.r25.s64 = 0;
	// addi r26,r11,-5996
	ctx.r26.s64 = ctx.r11.s64 + -5996;
loc_82C873B4:
	// li r31,5
	ctx.r31.s64 = 5;
	// mr r28,r29
	ctx.r28.u64 = ctx.r29.u64;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82c87410
	if (ctx.cr6.eq) goto loc_82C87410;
loc_82C873C4:
	// cmplwi cr6,r31,5
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 5, ctx.xer);
	// bne cr6,0x82c87418
	if (!ctx.cr6.eq) goto loc_82C87418;
	// lbz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 0);
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// mr r31,r25
	ctx.r31.u64 = ctx.r25.u64;
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
loc_82C873DC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r8,r9
	ctx.r8.s64 = ctx.r9.s8;
	// cmpw cr6,r10,r8
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r8.s32, ctx.xer);
	// beq cr6,0x82c873fc
	if (ctx.cr6.eq) goto loc_82C873FC;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// cmplwi cr6,r31,5
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 5, ctx.xer);
	// blt cr6,0x82c873dc
	if (ctx.cr6.lt) goto loc_82C873DC;
loc_82C873FC:
	// addic. r27,r27,-1
	ctx.xer.ca = ctx.r27.u32 > 0;
	ctx.r27.s64 = ctx.r27.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// bne 0x82c873c4
	if (!ctx.cr0.eq) goto loc_82C873C4;
	// cmplwi cr6,r31,5
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 5, ctx.xer);
	// bne cr6,0x82c87418
	if (!ctx.cr6.eq) goto loc_82C87418;
loc_82C87410:
	// subf r30,r28,r29
	ctx.r30.s64 = ctx.r29.s64 - ctx.r28.s64;
	// b 0x82c87420
	goto loc_82C87420;
loc_82C87418:
	// subf r11,r28,r29
	ctx.r11.s64 = ctx.r29.s64 - ctx.r28.s64;
	// addi r30,r11,-1
	ctx.r30.s64 = ctx.r11.s64 + -1;
loc_82C87420:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82c87458
	if (!ctx.cr6.gt) goto loc_82C87458;
	// addi r3,r30,1
	ctx.r3.s64 = ctx.r30.s64 + 1;
	// bl 0x82c87a50
	ctx.lr = 0x82C87430;
	sub_82C87A50(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	ctx.lr = 0x82C87440;
	sub_82CA2C60(ctx, base);
	// stbx r25,r23,r30
	PPC_STORE_U8(ctx.r23.u32 + ctx.r30.u32, ctx.r25.u8);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c824d8
	ctx.lr = 0x82C87450;
	sub_82C824D8(ctx, base);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82c87a68
	ctx.lr = 0x82C87458;
	sub_82C87A68(ctx, base);
loc_82C87458:
	// cmplwi cr6,r31,5
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 5, ctx.xer);
	// beq cr6,0x82c87474
	if (ctx.cr6.eq) goto loc_82C87474;
	// rlwinm r11,r31,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r26,4
	ctx.r10.s64 = ctx.r26.s64 + 4;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// bl 0x82c824d8
	ctx.lr = 0x82C87474;
	sub_82C824D8(ctx, base);
loc_82C87474:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x82c873b4
	if (!ctx.cr6.eq) goto loc_82C873B4;
loc_82C8747C:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c81e58
	ctx.lr = 0x82C87484;
	sub_82C81E58(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82C87488:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c87488
	if (!ctx.cr6.eq) goto loc_82C87488;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// addi r31,r11,1
	ctx.r31.s64 = ctx.r11.s64 + 1;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82c87b08
	ctx.lr = 0x82C874B4;
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c81e58
	ctx.lr = 0x82C874BC;
	sub_82C81E58(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c87a40
	ctx.lr = 0x82C874C8;
	sub_82C87A40(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82ca3eb8
	ctx.lr = 0x82C874D4;
	sub_82CA3EB8(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C874E0"))) PPC_WEAK_FUNC(sub_82C874E0);
PPC_FUNC_IMPL(__imp__sub_82C874E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82c81ba8
	ctx.lr = 0x82C874F8;
	sub_82C81BA8(ctx, base);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r9,r10,-5720
	ctx.r9.s64 = ctx.r10.s64 + -5720;
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// stb r8,20(r31)
	PPC_STORE_U8(ctx.r31.u32 + 20, ctx.r8.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87538"))) PPC_WEAK_FUNC(sub_82C87538);
PPC_FUNC_IMPL(__imp__sub_82C87538) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r10,r11,-5720
	ctx.r10.s64 = ctx.r11.s64 + -5720;
	// lwz r30,8(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c87578
	if (ctx.cr6.eq) goto loc_82C87578;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c88a58
	ctx.lr = 0x82C87570;
	sub_82C88A58(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82ca29e8
	ctx.lr = 0x82C87578;
	sub_82CA29E8(ctx, base);
loc_82C87578:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c81bf8
	ctx.lr = 0x82C87580;
	sub_82C81BF8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87598"))) PPC_WEAK_FUNC(sub_82C87598);
PPC_FUNC_IMPL(__imp__sub_82C87598) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	ctx.lr = 0x82C875BC;
	sub_82C879B0(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82c823d8
	ctx.lr = 0x82C875C8;
	sub_82C823D8(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82c87348
	ctx.lr = 0x82C875D4;
	sub_82C87348(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C875DC;
	sub_82C87A40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// bl 0x82c86a40
	ctx.lr = 0x82C875EC;
	sub_82C86A40(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C875F4;
	sub_82C87A10(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87610"))) PPC_WEAK_FUNC(sub_82C87610);
PPC_FUNC_IMPL(__imp__sub_82C87610) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C87618;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// addi r10,r11,-5720
	ctx.r10.s64 = ctx.r11.s64 + -5720;
	// lwz r30,8(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c8764c
	if (ctx.cr6.eq) goto loc_82C8764C;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c88a58
	ctx.lr = 0x82C87644;
	sub_82C88A58(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82ca29e8
	ctx.lr = 0x82C8764C;
	sub_82CA29E8(ctx, base);
loc_82C8764C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c81bf8
	ctx.lr = 0x82C87654;
	sub_82C81BF8(ctx, base);
	// clrlwi r11,r29,31
	ctx.r11.u64 = ctx.r29.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c8766c
	if (ctx.cr6.eq) goto loc_82C8766C;
	// bl 0x824fe010
	ctx.lr = 0x82C87668;
	sub_824FE010(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82C8766C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C87678"))) PPC_WEAK_FUNC(sub_82C87678);
PPC_FUNC_IMPL(__imp__sub_82C87678) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87688"))) PPC_WEAK_FUNC(sub_82C87688);
PPC_FUNC_IMPL(__imp__sub_82C87688) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r3,r11,-1
	ctx.r3.s64 = ctx.r11.s64 + -1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87698"))) PPC_WEAK_FUNC(sub_82C87698);
PPC_FUNC_IMPL(__imp__sub_82C87698) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C876A0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// li r31,0
	ctx.r31.s64 = 0;
	// li r3,4096
	ctx.r3.s64 = 4096;
	// stw r31,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r31.u32);
	// stw r31,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r31.u32);
	// stw r31,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r31.u32);
	// bl 0x82c87a50
	ctx.lr = 0x82C876C0;
	sub_82C87A50(ctx, base);
	// lwz r5,8(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	ctx.lr = 0x82C876D0;
	sub_82CA2C60(ctx, base);
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// bl 0x82c87a68
	ctx.lr = 0x82C876D8;
	sub_82C87A68(ctx, base);
	// li r11,4096
	ctx.r11.s64 = 4096;
	// stw r30,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r30.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r11,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r11.u32);
	// lwz r30,8(r29)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// addi r4,r30,1
	ctx.r4.s64 = ctx.r30.s64 + 1;
	// bl 0x82c81ed0
	ctx.lr = 0x82C876F4;
	sub_82C81ED0(ctx, base);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stbx r31,r10,r30
	PPC_STORE_U8(ctx.r10.u32 + ctx.r30.u32, ctx.r31.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C87708"))) PPC_WEAK_FUNC(sub_82C87708);
PPC_FUNC_IMPL(__imp__sub_82C87708) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r3,12
	ctx.r3.s64 = 12;
	// addi r10,r11,-5608
	ctx.r10.s64 = ctx.r11.s64 + -5608;
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// bl 0x82c87a50
	ctx.lr = 0x82C87730;
	sub_82C87A50(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c87744
	if (ctx.cr6.eq) goto loc_82C87744;
	// bl 0x82c87698
	ctx.lr = 0x82C8773C;
	sub_82C87698(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// b 0x82c87748
	goto loc_82C87748;
loc_82C87744:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82C87748:
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87768"))) PPC_WEAK_FUNC(sub_82C87768);
PPC_FUNC_IMPL(__imp__sub_82C87768) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C87770;
	__savegprlr_26(ctx, base);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// bl 0x82c879b0
	ctx.lr = 0x82C8779C;
	sub_82C879B0(ctx, base);
	// li r4,1024
	ctx.r4.s64 = 1024;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// li r30,1024
	ctx.r30.s64 = 1024;
	// bl 0x82c87b08
	ctx.lr = 0x82C877AC;
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C877B4;
	sub_82C87A40(ctx, base);
	// addi r11,r1,84
	ctx.r11.s64 = ctx.r1.s64 + 84;
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// li r27,-1
	ctx.r27.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r28,84(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82C877C8:
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82ca46e8
	ctx.lr = 0x82C877E0;
	sub_82CA46E8(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// bne cr6,0x82c87804
	if (!ctx.cr6.eq) goto loc_82C87804;
	// rlwinm r30,r30,1,0,30
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c87b08
	ctx.lr = 0x82C877F8;
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C87800;
	sub_82C87A40(ctx, base);
	// b 0x82c877c8
	goto loc_82C877C8;
loc_82C87804:
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82C87808:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c87808
	if (!ctx.cr6.eq) goto loc_82C87808;
	// subf r11,r31,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r31.s64;
	// lwz r28,4(r26)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// rotlwi r29,r11,0
	ctx.r29.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// lwz r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// addi r30,r11,-1
	ctx.r30.s64 = ctx.r11.s64 + -1;
	// add r4,r29,r30
	ctx.r4.u64 = ctx.r29.u64 + ctx.r30.u64;
	// bl 0x82c81ed0
	ctx.lr = 0x82C8783C;
	sub_82C81ED0(ctx, base);
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// add r3,r30,r11
	ctx.r3.u64 = ctx.r30.u64 + ctx.r11.u64;
	// bl 0x82ca2c60
	ctx.lr = 0x82C87850;
	sub_82CA2C60(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r31,8(r28)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// bl 0x82c81ed0
	ctx.lr = 0x82C87860;
	sub_82C81ED0(ctx, base);
	// lwz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stbx r10,r31,r9
	PPC_STORE_U8(ctx.r31.u32 + ctx.r9.u32, ctx.r10.u8);
	// bl 0x82c87a10
	ctx.lr = 0x82C87874;
	sub_82C87A10(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C87880"))) PPC_WEAK_FUNC(sub_82C87880);
PPC_FUNC_IMPL(__imp__sub_82C87880) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C87888;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r28,4(r3)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// addi r31,r11,-1
	ctx.r31.s64 = ctx.r11.s64 + -1;
	// add r4,r31,r30
	ctx.r4.u64 = ctx.r31.u64 + ctx.r30.u64;
	// bl 0x82c81ed0
	ctx.lr = 0x82C878AC;
	sub_82C81ED0(ctx, base);
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// add r3,r11,r31
	ctx.r3.u64 = ctx.r11.u64 + ctx.r31.u64;
	// bl 0x82ca2c60
	ctx.lr = 0x82C878C0;
	sub_82CA2C60(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r31,8(r28)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// bl 0x82c81ed0
	ctx.lr = 0x82C878D0;
	sub_82C81ED0(ctx, base);
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r11,0
	ctx.r11.s64 = 0;
	// stbx r11,r10,r31
	PPC_STORE_U8(ctx.r10.u32 + ctx.r31.u32, ctx.r11.u8);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C878E8"))) PPC_WEAK_FUNC(sub_82C878E8);
PPC_FUNC_IMPL(__imp__sub_82C878E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r10,r11,-5608
	ctx.r10.s64 = ctx.r11.s64 + -5608;
	// lwz r31,4(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c87938
	if (ctx.cr6.eq) goto loc_82C87938;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c87a68
	ctx.lr = 0x82C87920;
	sub_82C87A68(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bl 0x82c87a68
	ctx.lr = 0x82C87938;
	sub_82C87A68(ctx, base);
loc_82C87938:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r10,r11,-12180
	ctx.r10.s64 = ctx.r11.s64 + -12180;
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87960"))) PPC_WEAK_FUNC(sub_82C87960);
PPC_FUNC_IMPL(__imp__sub_82C87960) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82c878e8
	ctx.lr = 0x82C87980;
	sub_82C878E8(ctx, base);
	// clrlwi r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c87998
	if (ctx.cr6.eq) goto loc_82C87998;
	// bl 0x824fe010
	ctx.lr = 0x82C87994;
	sub_824FE010(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82C87998:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C879B0"))) PPC_WEAK_FUNC(sub_82C879B0);
PPC_FUNC_IMPL(__imp__sub_82C879B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31949
	ctx.r11.s64 = -2093809664;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r31,r11,22648
	ctx.r31.s64 = ctx.r11.s64 + 22648;
	// lbz r11,37(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 37);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c879ec
	if (!ctx.cr6.eq) goto loc_82C879EC;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x832b258c
	ctx.lr = 0x82C879E4;
	__imp__RtlInitializeCriticalSection(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,37(r31)
	PPC_STORE_U8(ctx.r31.u32 + 37, ctx.r11.u8);
loc_82C879EC:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x832b227c
	ctx.lr = 0x82C879F4;
	__imp__RtlEnterCriticalSection(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87A10"))) PPC_WEAK_FUNC(sub_82C87A10);
PPC_FUNC_IMPL(__imp__sub_82C87A10) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r10,22648
	ctx.r3.s64 = ctx.r10.s64 + 22648;
	// stb r11,36(r3)
	PPC_STORE_U8(ctx.r3.u32 + 36, ctx.r11.u8);
	// b 0x832b226c
	__imp__RtlLeaveCriticalSection(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C87A28"))) PPC_WEAK_FUNC(sub_82C87A28);
PPC_FUNC_IMPL(__imp__sub_82C87A28) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// lwz r11,22688(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 22688);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,22688(r10)
	PPC_STORE_U32(ctx.r10.u32 + 22688, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87A40"))) PPC_WEAK_FUNC(sub_82C87A40);
PPC_FUNC_IMPL(__imp__sub_82C87A40) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-31949
	ctx.r11.s64 = -2093809664;
	// lwz r3,22676(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 22676);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87A50"))) PPC_WEAK_FUNC(sub_82C87A50);
PPC_FUNC_IMPL(__imp__sub_82C87A50) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// lwz r11,22692(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 22692);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,22692(r10)
	PPC_STORE_U32(ctx.r10.u32 + 22692, ctx.r11.u32);
	// b 0x8221f388
	sub_8221F388(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C87A68"))) PPC_WEAK_FUNC(sub_82C87A68);
PPC_FUNC_IMPL(__imp__sub_82C87A68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c87a90
	if (ctx.cr6.eq) goto loc_82C87A90;
	// bl 0x824fe010
	ctx.lr = 0x82C87A80;
	sub_824FE010(ctx, base);
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// lwz r11,22692(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 22692);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,22692(r10)
	PPC_STORE_U32(ctx.r10.u32 + 22692, ctx.r11.u32);
loc_82C87A90:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87AA0"))) PPC_WEAK_FUNC(sub_82C87AA0);
PPC_FUNC_IMPL(__imp__sub_82C87AA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31949
	ctx.r11.s64 = -2093809664;
	// addi r31,r11,22692
	ctx.r31.s64 = ctx.r11.s64 + 22692;
	// lwz r11,-4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,-4(r31)
	PPC_STORE_U32(ctx.r31.u32 + -4, ctx.r11.u32);
	// bne 0x82c87af4
	if (!ctx.cr0.eq) goto loc_82C87AF4;
	// lwz r3,-16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -16);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c87ae4
	if (ctx.cr6.eq) goto loc_82C87AE4;
	// bl 0x824fe010
	ctx.lr = 0x82C87AD8;
	sub_824FE010(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
loc_82C87AE4:
	// li r11,0
	ctx.r11.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,-16(r31)
	PPC_STORE_U32(ctx.r31.u32 + -16, ctx.r11.u32);
	// stw r10,-12(r31)
	PPC_STORE_U32(ctx.r31.u32 + -12, ctx.r10.u32);
loc_82C87AF4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87B08"))) PPC_WEAK_FUNC(sub_82C87B08);
PPC_FUNC_IMPL(__imp__sub_82C87B08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31949
	ctx.r11.s64 = -2093809664;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r31,r11,22692
	ctx.r31.s64 = ctx.r11.s64 + 22692;
	// lwz r3,-16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -16);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c87b50
	if (ctx.cr6.eq) goto loc_82C87B50;
	// lwz r11,-12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -12);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// bge cr6,0x82c87b6c
	if (!ctx.cr6.lt) goto loc_82C87B6C;
	// bl 0x824fe010
	ctx.lr = 0x82C87B44;
	sub_824FE010(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// b 0x82c87b54
	goto loc_82C87B54;
loc_82C87B50:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
loc_82C87B54:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// bl 0x8221f388
	ctx.lr = 0x82C87B64;
	sub_8221F388(ctx, base);
	// stw r30,-12(r31)
	PPC_STORE_U32(ctx.r31.u32 + -12, ctx.r30.u32);
	// stw r3,-16(r31)
	PPC_STORE_U32(ctx.r31.u32 + -16, ctx.r3.u32);
loc_82C87B6C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87B88"))) PPC_WEAK_FUNC(sub_82C87B88);
PPC_FUNC_IMPL(__imp__sub_82C87B88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82240578
	ctx.lr = 0x82C87BA0;
	sub_82240578(ctx, base);
	// addi r3,r3,64
	ctx.r3.s64 = ctx.r3.s64 + 64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82ca7120
	ctx.lr = 0x82C87BAC;
	sub_82CA7120(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87BC0"))) PPC_WEAK_FUNC(sub_82C87BC0);
PPC_FUNC_IMPL(__imp__sub_82C87BC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r9,r11,-5580
	ctx.r9.s64 = ctx.r11.s64 + -5580;
	// addi r30,r10,3224
	ctx.r30.s64 = ctx.r10.s64 + 3224;
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// addi r3,r31,8
	ctx.r3.s64 = ctx.r31.s64 + 8;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c823d8
	ctx.lr = 0x82C87BF8;
	sub_82C823D8(ctx, base);
	// addi r3,r31,12
	ctx.r3.s64 = ctx.r31.s64 + 12;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c823d8
	ctx.lr = 0x82C87C04;
	sub_82C823D8(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stb r11,16(r31)
	PPC_STORE_U8(ctx.r31.u32 + 16, ctx.r11.u8);
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87C30"))) PPC_WEAK_FUNC(sub_82C87C30);
PPC_FUNC_IMPL(__imp__sub_82C87C30) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C87C38;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r3,r31,12
	ctx.r3.s64 = ctx.r31.s64 + 12;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82c81e58
	ctx.lr = 0x82C87C50;
	sub_82C81E58(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82C87C54:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c87c54
	if (!ctx.cr6.eq) goto loc_82C87C54;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r10,r11,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c87c94
	if (!ctx.cr6.eq) goto loc_82C87C94;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C87C94;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C87C94:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C87CA0"))) PPC_WEAK_FUNC(sub_82C87CA0);
PPC_FUNC_IMPL(__imp__sub_82C87CA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C87CA8;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c81e58
	ctx.lr = 0x82C87CC0;
	sub_82C81E58(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82C87CC4:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c87cc4
	if (!ctx.cr6.eq) goto loc_82C87CC4;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r10,r11,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c87d1c
	if (ctx.cr6.eq) goto loc_82C87D1C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c823d8
	ctx.lr = 0x82C87CF4;
	sub_82C823D8(ctx, base);
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c87d30
	if (!ctx.cr6.eq) goto loc_82C87D30;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r4,r11,3224
	ctx.r4.s64 = ctx.r11.s64 + 3224;
	// bl 0x82c825a0
	ctx.lr = 0x82C87D14;
	sub_82C825A0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C87D1C:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C87D30;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C87D30:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C87D38"))) PPC_WEAK_FUNC(sub_82C87D38);
PPC_FUNC_IMPL(__imp__sub_82C87D38) {
	PPC_FUNC_PROLOGUE();
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,16(r3)
	PPC_STORE_U8(ctx.r3.u32 + 16, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87D48"))) PPC_WEAK_FUNC(sub_82C87D48);
PPC_FUNC_IMPL(__imp__sub_82C87D48) {
	PPC_FUNC_PROLOGUE();
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// ble cr6,0x82c87da0
	if (!ctx.cr6.gt) goto loc_82C87DA0;
loc_82C87D54:
	// lbz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,32
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 32, ctx.xer);
	// beq cr6,0x82c87d80
	if (ctx.cr6.eq) goto loc_82C87D80;
	// cmpwi cr6,r11,10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 10, ctx.xer);
	// beq cr6,0x82c87d80
	if (ctx.cr6.eq) goto loc_82C87D80;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82c87d80
	if (ctx.cr6.eq) goto loc_82C87D80;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// li r11,0
	ctx.r11.s64 = 0;
	// bne cr6,0x82c87d84
	if (!ctx.cr6.eq) goto loc_82C87D84;
loc_82C87D80:
	// li r11,1
	ctx.r11.s64 = 1;
loc_82C87D84:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c87da8
	if (ctx.cr6.eq) goto loc_82C87DA8;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmpw cr6,r10,r4
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r4.s32, ctx.xer);
	// blt cr6,0x82c87d54
	if (ctx.cr6.lt) goto loc_82C87D54;
loc_82C87DA0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C87DA8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87DB0"))) PPC_WEAK_FUNC(sub_82C87DB0);
PPC_FUNC_IMPL(__imp__sub_82C87DB0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-31953
	ctx.r11.s64 = -2094071808;
	// stw r3,-5940(r11)
	PPC_STORE_U32(ctx.r11.u32 + -5940, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C87DC0"))) PPC_WEAK_FUNC(sub_82C87DC0);
PPC_FUNC_IMPL(__imp__sub_82C87DC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C87DC8;
	__savegprlr_28(ctx, base);
	// std r4,24(r1)
	PPC_STORE_U64(ctx.r1.u32 + 24, ctx.r4.u64);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,152
	ctx.r10.s64 = ctx.r1.s64 + 152;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82ca6e88
	ctx.lr = 0x82C87E04;
	sub_82CA6E88(ctx, base);
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// lis r11,-31949
	ctx.r11.s64 = -2093809664;
	// addi r30,r3,1
	ctx.r30.s64 = ctx.r3.s64 + 1;
	// addi r31,r11,22696
	ctx.r31.s64 = ctx.r11.s64 + 22696;
	// lwz r11,22704(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 22704);
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c87e44
	if (!ctx.cr6.eq) goto loc_82C87E44;
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r11,22704(r10)
	PPC_STORE_U32(ctx.r10.u32 + 22704, ctx.r11.u32);
	// lis r11,-31957
	ctx.r11.s64 = -2094333952;
	// stw r8,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r8.u32);
	// addi r3,r11,1792
	ctx.r3.s64 = ctx.r11.s64 + 1792;
	// bl 0x82ca3700
	ctx.lr = 0x82C87E44;
	sub_82CA3700(ctx, base);
loc_82C87E44:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82c87e68
	if (!ctx.cr6.gt) goto loc_82C87E68;
	// bl 0x824fe010
	ctx.lr = 0x82C87E58;
	sub_824FE010(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8221f388
	ctx.lr = 0x82C87E60;
	sub_8221F388(ctx, base);
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
loc_82C87E68:
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82ca4578
	ctx.lr = 0x82C87E78;
	sub_82CA4578(ctx, base);
	// lis r11,-31953
	ctx.r11.s64 = -2094071808;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,-5940(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -5940);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C87E8C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C87E98"))) PPC_WEAK_FUNC(sub_82C87E98);
PPC_FUNC_IMPL(__imp__sub_82C87E98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C87EA0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r3,r31,12
	ctx.r3.s64 = ctx.r31.s64 + 12;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82c81e58
	ctx.lr = 0x82C87EB8;
	sub_82C81E58(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82C87EBC:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c87ebc
	if (!ctx.cr6.eq) goto loc_82C87EBC;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r10,r11,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c87f28
	if (!ctx.cr6.eq) goto loc_82C87F28;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c87f28
	if (ctx.cr6.eq) goto loc_82C87F28;
	// lbz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c87f0c
	if (!ctx.cr6.eq) goto loc_82C87F0C;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c87d48
	ctx.lr = 0x82C87F00;
	sub_82C87D48(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c87f28
	if (!ctx.cr6.eq) goto loc_82C87F28;
loc_82C87F0C:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C87F28;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C87F28:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C87F30"))) PPC_WEAK_FUNC(sub_82C87F30);
PPC_FUNC_IMPL(__imp__sub_82C87F30) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C87F38;
	__savegprlr_27(ctx, base);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// addi r10,r1,208
	ctx.r10.s64 = ctx.r1.s64 + 208;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r27,112(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82ca6e88
	ctx.lr = 0x82C87F78;
	sub_82CA6E88(ctx, base);
	// lis r10,-31949
	ctx.r10.s64 = -2093809664;
	// lis r11,-31949
	ctx.r11.s64 = -2093809664;
	// addi r29,r3,1
	ctx.r29.s64 = ctx.r3.s64 + 1;
	// addi r31,r11,22708
	ctx.r31.s64 = ctx.r11.s64 + 22708;
	// lwz r11,22716(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 22716);
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c87fb8
	if (!ctx.cr6.eq) goto loc_82C87FB8;
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r11,22716(r10)
	PPC_STORE_U32(ctx.r10.u32 + 22716, ctx.r11.u32);
	// lis r11,-31957
	ctx.r11.s64 = -2094333952;
	// stw r8,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r8.u32);
	// addi r3,r11,1808
	ctx.r3.s64 = ctx.r11.s64 + 1808;
	// bl 0x82ca3700
	ctx.lr = 0x82C87FB8;
	sub_82CA3700(ctx, base);
loc_82C87FB8:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82c87fdc
	if (!ctx.cr6.gt) goto loc_82C87FDC;
	// bl 0x824fe010
	ctx.lr = 0x82C87FCC;
	sub_824FE010(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8221f388
	ctx.lr = 0x82C87FD4;
	sub_8221F388(ctx, base);
	// stw r29,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r29.u32);
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
loc_82C87FDC:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82ca4578
	ctx.lr = 0x82C87FEC;
	sub_82CA4578(ctx, base);
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x82c988d8
	ctx.lr = 0x82C87FF4;
	sub_82C988D8(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r3,r30,8
	ctx.r3.s64 = ctx.r30.s64 + 8;
	// lwz r31,0(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c81e58
	ctx.lr = 0x82C88004;
	sub_82C81E58(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r11,-5568
	ctx.r3.s64 = ctx.r11.s64 + -5568;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// bl 0x82c87dc0
	ctx.lr = 0x82C8801C;
	sub_82C87DC0(ctx, base);
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,20(r30)
	PPC_STORE_U32(ctx.r30.u32 + 20, ctx.r10.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88030"))) PPC_WEAK_FUNC(sub_82C88030);
PPC_FUNC_IMPL(__imp__sub_82C88030) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31953
	ctx.r11.s64 = -2094071808;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r11,-5952
	ctx.r4.s64 = ctx.r11.s64 + -5952;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82ca2968
	ctx.lr = 0x82C88058;
	sub_82CA2968(ctx, base);
	// stw r3,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r3.u32);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82c986b0
	ctx.lr = 0x82C88064;
	sub_82C986B0(ctx, base);
	// lis r10,-32056
	ctx.r10.s64 = -2100822016;
	// lis r9,-32056
	ctx.r9.s64 = -2100822016;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// addi r5,r10,31904
	ctx.r5.s64 = ctx.r10.s64 + 31904;
	// addi r4,r9,31792
	ctx.r4.s64 = ctx.r9.s64 + 31792;
	// bl 0x82c986d0
	ctx.lr = 0x82C8807C;
	sub_82C986D0(ctx, base);
	// lis r8,-32056
	ctx.r8.s64 = -2100822016;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// addi r4,r8,32408
	ctx.r4.s64 = ctx.r8.s64 + 32408;
	// bl 0x82c986e0
	ctx.lr = 0x82C8808C;
	sub_82C986E0(ctx, base);
	// lis r7,-32024
	ctx.r7.s64 = -2098724864;
	// lis r6,-32056
	ctx.r6.s64 = -2100822016;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// addi r5,r7,22088
	ctx.r5.s64 = ctx.r7.s64 + 22088;
	// addi r4,r6,32056
	ctx.r4.s64 = ctx.r6.s64 + 32056;
	// bl 0x82c986e8
	ctx.lr = 0x82C880A4;
	sub_82C986E8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C880B8"))) PPC_WEAK_FUNC(sub_82C880B8);
PPC_FUNC_IMPL(__imp__sub_82C880B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C880C0;
	__savegprlr_27(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// clrlwi r6,r6,24
	ctx.r6.u64 = ctx.r6.u32 & 0xFF;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// bl 0x82c9b8f8
	ctx.lr = 0x82C880DC;
	sub_82C9B8F8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8824c
	if (!ctx.cr6.eq) goto loc_82C8824C;
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// bl 0x8233d248
	ctx.lr = 0x82C880EC;
	sub_8233D248(ctx, base);
	// bl 0x82c98940
	ctx.lr = 0x82C880F0;
	sub_82C98940(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r3,r27,8
	ctx.r3.s64 = ctx.r27.s64 + 8;
	// bl 0x82c81e58
	ctx.lr = 0x82C880FC;
	sub_82C81E58(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// bl 0x82c87f30
	ctx.lr = 0x82C8810C;
	sub_82C87F30(ctx, base);
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// bl 0x82c988b0
	ctx.lr = 0x82C88114;
	sub_82C988B0(ctx, base);
	// cmplw cr6,r3,r30
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r30.u32, ctx.xer);
	// bge cr6,0x82c88240
	if (!ctx.cr6.lt) goto loc_82C88240;
	// add r11,r3,r31
	ctx.r11.u64 = ctx.r3.u64 + ctx.r31.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// beq cr6,0x82c88158
	if (ctx.cr6.eq) goto loc_82C88158;
loc_82C88130:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,10
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 10, ctx.xer);
	// beq cr6,0x82c88158
	if (ctx.cr6.eq) goto loc_82C88158;
	// cmpwi cr6,r10,13
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 13, ctx.xer);
	// beq cr6,0x82c88158
	if (ctx.cr6.eq) goto loc_82C88158;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82c88130
	if (!ctx.cr6.eq) goto loc_82C88130;
loc_82C88158:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c88168
	if (ctx.cr6.eq) goto loc_82C88168;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82C88168:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lis r7,-31949
	ctx.r7.s64 = -2093809664;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// addi r31,r7,22720
	ctx.r31.s64 = ctx.r7.s64 + 22720;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82c881bc
	if (ctx.cr6.eq) goto loc_82C881BC;
	// subf r7,r11,r31
	ctx.r7.s64 = ctx.r31.s64 - ctx.r11.s64;
loc_82C88188:
	// cmpwi cr6,r9,10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 10, ctx.xer);
	// beq cr6,0x82c881bc
	if (ctx.cr6.eq) goto loc_82C881BC;
	// cmpwi cr6,r9,13
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 13, ctx.xer);
	// beq cr6,0x82c881bc
	if (ctx.cr6.eq) goto loc_82C881BC;
	// cmpwi cr6,r8,4096
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 4096, ctx.xer);
	// bge cr6,0x82c881bc
	if (!ctx.cr6.lt) goto loc_82C881BC;
	// stbx r10,r7,r11
	PPC_STORE_U8(ctx.r7.u32 + ctx.r11.u32, ctx.r10.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c88188
	if (!ctx.cr6.eq) goto loc_82C88188;
loc_82C881BC:
	// stbx r28,r8,r31
	PPC_STORE_U8(ctx.r8.u32 + ctx.r31.u32, ctx.r28.u8);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r30,r11,-21148
	ctx.r30.s64 = ctx.r11.s64 + -21148;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c87dc0
	ctx.lr = 0x82C881D4;
	sub_82C87DC0(ctx, base);
	// cmpwi cr6,r29,4094
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 4094, ctx.xer);
	// ble cr6,0x82c881e0
	if (!ctx.cr6.gt) goto loc_82C881E0;
	// li r29,4094
	ctx.r29.s64 = 4094;
loc_82C881E0:
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// ble cr6,0x82c88224
	if (!ctx.cr6.gt) goto loc_82C88224;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// li r8,32
	ctx.r8.s64 = 32;
loc_82C881FC:
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r7,9
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 9, ctx.xer);
	// beq cr6,0x82c8820c
	if (ctx.cr6.eq) goto loc_82C8820C;
	// stb r8,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r8.u8);
loc_82C8820C:
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// bne 0x82c881fc
	if (!ctx.cr0.eq) goto loc_82C881FC;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82c88224
	if (ctx.cr6.eq) goto loc_82C88224;
	// addi r9,r29,-1
	ctx.r9.s64 = ctx.r29.s64 + -1;
loc_82C88224:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r10,94
	ctx.r10.s64 = 94;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// stbx r10,r9,r31
	PPC_STORE_U8(ctx.r9.u32 + ctx.r31.u32, ctx.r10.u8);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stbx r28,r9,r11
	PPC_STORE_U8(ctx.r9.u32 + ctx.r11.u32, ctx.r28.u8);
	// bl 0x82c87dc0
	ctx.lr = 0x82C88240;
	sub_82C87DC0(ctx, base);
loc_82C88240:
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,20(r27)
	PPC_STORE_U32(ctx.r27.u32 + 20, ctx.r11.u32);
loc_82C8824C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88258"))) PPC_WEAK_FUNC(sub_82C88258);
PPC_FUNC_IMPL(__imp__sub_82C88258) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C88260;
	__savegprlr_26(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// addi r3,r29,8
	ctx.r3.s64 = ctx.r29.s64 + 8;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// bl 0x82c825a0
	ctx.lr = 0x82C88278;
	sub_82C825A0(ctx, base);
	// lis r11,-32246
	ctx.r11.s64 = -2113273856;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,11936
	ctx.r4.s64 = ctx.r11.s64 + 11936;
	// bl 0x82ca4890
	ctx.lr = 0x82C88288;
	sub_82CA4890(ctx, base);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// bne cr6,0x82c882b8
	if (!ctx.cr6.eq) goto loc_82C882B8;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r11,-5504
	ctx.r3.s64 = ctx.r11.s64 + -5504;
	// bl 0x82c87dc0
	ctx.lr = 0x82C882A4;
	sub_82C87DC0(ctx, base);
	// lwz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,20(r29)
	PPC_STORE_U32(ctx.r29.u32 + 20, ctx.r10.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C882B8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82ca5338
	ctx.lr = 0x82C882C8;
	sub_82CA5338(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82ca5670
	ctx.lr = 0x82C882D0;
	sub_82CA5670(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82ca5338
	ctx.lr = 0x82C882E4;
	sub_82CA5338(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c87a50
	ctx.lr = 0x82C882EC;
	sub_82C87A50(ctx, base);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c88030
	ctx.lr = 0x82C882F8;
	sub_82C88030(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c88350
	if (ctx.cr6.eq) goto loc_82C88350;
loc_82C88300:
	// cmplw cr6,r31,r26
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r26.u32, ctx.xer);
	// mr r30,r31
	ctx.r30.u64 = ctx.r31.u64;
	// blt cr6,0x82c88310
	if (ctx.cr6.lt) goto loc_82C88310;
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
loc_82C88310:
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82cab340
	ctx.lr = 0x82C88324;
	sub_82CAB340(ctx, base);
	// cmpw cr6,r3,r30
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r30.s32, ctx.xer);
	// bne cr6,0x82c88370
	if (!ctx.cr6.eq) goto loc_82C88370;
	// subf r31,r30,r31
	ctx.r31.s64 = ctx.r31.s64 - ctx.r30.s64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// cntlzw r11,r31
	ctx.r11.u64 = ctx.r31.u32 == 0 ? 32 : __builtin_clz(ctx.r31.u32);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// rlwinm r6,r11,27,31,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c880b8
	ctx.lr = 0x82C88348;
	sub_82C880B8(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82c88300
	if (!ctx.cr6.eq) goto loc_82C88300;
loc_82C88350:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82ca49d8
	ctx.lr = 0x82C88358;
	sub_82CA49D8(ctx, base);
	// lwz r3,4(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// bl 0x82c9b770
	ctx.lr = 0x82C88360;
	sub_82C9B770(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82c87a68
	ctx.lr = 0x82C88368;
	sub_82C87A68(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C88370:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r11,-5544
	ctx.r3.s64 = ctx.r11.s64 + -5544;
	// bl 0x82c87dc0
	ctx.lr = 0x82C8837C;
	sub_82C87DC0(ctx, base);
	// lwz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,20(r29)
	PPC_STORE_U32(ctx.r29.u32 + 20, ctx.r10.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88390"))) PPC_WEAK_FUNC(sub_82C88390);
PPC_FUNC_IMPL(__imp__sub_82C88390) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bd8
	ctx.lr = 0x82C88398;
	__savegprlr_24(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// bne cr6,0x82c883d0
	if (!ctx.cr6.eq) goto loc_82C883D0;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r11,-5464
	ctx.r3.s64 = ctx.r11.s64 + -5464;
	// bl 0x82c87dc0
	ctx.lr = 0x82C883BC;
	sub_82C87DC0(ctx, base);
	// lwz r11,20(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,20(r26)
	PPC_STORE_U32(ctx.r26.u32 + 20, ctx.r10.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	__restgprlr_24(ctx, base);
	return;
loc_82C883D0:
	// lis r11,-32246
	ctx.r11.s64 = -2113273856;
	// addi r3,r26,8
	ctx.r3.s64 = ctx.r26.s64 + 8;
	// addi r4,r11,5792
	ctx.r4.s64 = ctx.r11.s64 + 5792;
	// bl 0x82c825a0
	ctx.lr = 0x82C883E0;
	sub_82C825A0(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c88030
	ctx.lr = 0x82C883E8;
	sub_82C88030(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82c87a50
	ctx.lr = 0x82C883F0;
	sub_82C87A50(ctx, base);
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r9,24(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C88408;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// rotlwi r31,r3,0
	ctx.r31.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// li r24,0
	ctx.r24.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// mr r29,r24
	ctx.r29.u64 = ctx.r24.u64;
	// beq cr6,0x82c88488
	if (ctx.cr6.eq) goto loc_82C88488;
loc_82C8841C:
	// cmplw cr6,r31,r25
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r25.u32, ctx.xer);
	// mr r30,r31
	ctx.r30.u64 = ctx.r31.u64;
	// blt cr6,0x82c8842c
	if (ctx.cr6.lt) goto loc_82C8842C;
	// mr r30,r25
	ctx.r30.u64 = ctx.r25.u64;
loc_82C8842C:
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r27,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r27.u32);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// stw r24,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r24.u32);
	// clrldi r5,r29,32
	ctx.r5.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C88458;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c884a0
	if (!ctx.cr6.eq) goto loc_82C884A0;
	// subf r31,r30,r31
	ctx.r31.s64 = ctx.r31.s64 - ctx.r30.s64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// cntlzw r11,r31
	ctx.r11.u64 = ctx.r31.u32 == 0 ? 32 : __builtin_clz(ctx.r31.u32);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// rlwinm r6,r11,27,31,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// add r29,r30,r29
	ctx.r29.u64 = ctx.r30.u64 + ctx.r29.u64;
	// bl 0x82c880b8
	ctx.lr = 0x82C88480;
	sub_82C880B8(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82c8841c
	if (!ctx.cr6.eq) goto loc_82C8841C;
loc_82C88488:
	// lwz r3,4(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// bl 0x82c9b770
	ctx.lr = 0x82C88490;
	sub_82C9B770(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82c87a68
	ctx.lr = 0x82C88498;
	sub_82C87A68(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	__restgprlr_24(ctx, base);
	return;
loc_82C884A0:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r11,-5544
	ctx.r3.s64 = ctx.r11.s64 + -5544;
	// bl 0x82c87dc0
	ctx.lr = 0x82C884AC;
	sub_82C87DC0(ctx, base);
	// lwz r11,20(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,20(r26)
	PPC_STORE_U32(ctx.r26.u32 + 20, ctx.r10.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c28
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C884C0"))) PPC_WEAK_FUNC(sub_82C884C0);
PPC_FUNC_IMPL(__imp__sub_82C884C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C884C8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne cr6,0x82c884e8
	if (!ctx.cr6.eq) goto loc_82C884E8;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r6,r11,-5600
	ctx.r6.s64 = ctx.r11.s64 + -5600;
loc_82C884E8:
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// addi r3,r31,8
	ctx.r3.s64 = ctx.r31.s64 + 8;
	// bl 0x82c825a0
	ctx.lr = 0x82C884F4;
	sub_82C825A0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c88030
	ctx.lr = 0x82C884FC;
	sub_82C88030(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c880b8
	ctx.lr = 0x82C88510;
	sub_82C880B8(ctx, base);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82c9b770
	ctx.lr = 0x82C88518;
	sub_82C9B770(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88520"))) PPC_WEAK_FUNC(sub_82C88520);
PPC_FUNC_IMPL(__imp__sub_82C88520) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C88528;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,28(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// addi r30,r3,28
	ctx.r30.s64 = ctx.r3.s64 + 28;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C88548;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c8859c
	if (ctx.cr6.eq) goto loc_82C8859C;
loc_82C88554:
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c8859c
	if (ctx.cr6.eq) goto loc_82C8859C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c823d8
	ctx.lr = 0x82C88570;
	sub_82C823D8(ctx, base);
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C88590;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c88554
	if (!ctx.cr6.eq) goto loc_82C88554;
loc_82C8859C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C885A8"))) PPC_WEAK_FUNC(sub_82C885A8);
PPC_FUNC_IMPL(__imp__sub_82C885A8) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,28(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// addi r3,r3,28
	ctx.r3.s64 = ctx.r3.s64 + 28;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
}

__attribute__((alias("__imp__sub_82C885C0"))) PPC_WEAK_FUNC(sub_82C885C0);
PPC_FUNC_IMPL(__imp__sub_82C885C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C885C8;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// bl 0x82c879b0
	ctx.lr = 0x82C885E0;
	sub_82C879B0(ctx, base);
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87b08
	ctx.lr = 0x82C885EC;
	sub_82C87B08(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a40
	ctx.lr = 0x82C885F4;
	sub_82C87A40(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// bl 0x82cab3c8
	ctx.lr = 0x82C88604;
	sub_82CAB3C8(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r3,r30,28
	ctx.r3.s64 = ctx.r30.s64 + 28;
	// stbx r11,r28,r31
	PPC_STORE_U8(ctx.r28.u32 + ctx.r31.u32, ctx.r11.u8);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82c86f78
	ctx.lr = 0x82C88618;
	sub_82C86F78(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c87a10
	ctx.lr = 0x82C88620;
	sub_82C87A10(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88628"))) PPC_WEAK_FUNC(sub_82C88628);
PPC_FUNC_IMPL(__imp__sub_82C88628) {
	PPC_FUNC_PROLOGUE();
	// b 0x82c87a50
	sub_82C87A50(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88630"))) PPC_WEAK_FUNC(sub_82C88630);
PPC_FUNC_IMPL(__imp__sub_82C88630) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c89208
	ctx.lr = 0x82C88658;
	sub_82C89208(ctx, base);
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C88678"))) PPC_WEAK_FUNC(sub_82C88678);
PPC_FUNC_IMPL(__imp__sub_82C88678) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r31,0
	ctx.r31.s64 = 0;
	// li r3,4096
	ctx.r3.s64 = 4096;
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
	// bl 0x82c87a50
	ctx.lr = 0x82C886A0;
	sub_82C87A50(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c886d0
	if (ctx.cr6.eq) goto loc_82C886D0;
	// li r10,4096
	ctx.r10.s64 = 4096;
	// stw r31,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r31.u32);
	// li r9,-1
	ctx.r9.s64 = -1;
	// stw r31,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r31.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// stw r31,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r31.u32);
	// stw r31,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r31.u32);
	// stw r31,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r31.u32);
loc_82C886D0:
	// stw r11,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r11.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C886F0"))) PPC_WEAK_FUNC(sub_82C886F0);
PPC_FUNC_IMPL(__imp__sub_82C886F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bb0
	ctx.lr = 0x82C886F8;
	__savegprlr_14(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r4
	ctx.r24.u64 = ctx.r4.u64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r4,r11,-5392
	ctx.r4.s64 = ctx.r11.s64 + -5392;
	// bl 0x82c87768
	ctx.lr = 0x82C88714;
	sub_82C87768(ctx, base);
	// li r22,0
	ctx.r22.s64 = 0;
	// li r23,0
	ctx.r23.s64 = 0;
	// li r25,0
	ctx.r25.s64 = 0;
	// lwz r26,0(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82c88934
	if (ctx.cr6.eq) goto loc_82C88934;
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// lis r8,-32255
	ctx.r8.s64 = -2113863680;
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lis r6,-32245
	ctx.r6.s64 = -2113208320;
	// lis r5,-32245
	ctx.r5.s64 = -2113208320;
	// lis r4,-32244
	ctx.r4.s64 = -2113142784;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r21,r9,-27472
	ctx.r21.s64 = ctx.r9.s64 + -27472;
	// addi r20,r8,-5400
	ctx.r20.s64 = ctx.r8.s64 + -5400;
	// addi r15,r7,-5404
	ctx.r15.s64 = ctx.r7.s64 + -5404;
	// addi r14,r6,-17152
	ctx.r14.s64 = ctx.r6.s64 + -17152;
	// addi r16,r5,-6332
	ctx.r16.s64 = ctx.r5.s64 + -6332;
	// addi r17,r4,22552
	ctx.r17.s64 = ctx.r4.s64 + 22552;
	// addi r19,r10,-5416
	ctx.r19.s64 = ctx.r10.s64 + -5416;
	// addi r18,r11,-5420
	ctx.r18.s64 = ctx.r11.s64 + -5420;
loc_82C8876C:
	// addi r27,r26,8
	ctx.r27.s64 = ctx.r26.s64 + 8;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82c81e58
	ctx.lr = 0x82C88778;
	sub_82C81E58(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,0
	ctx.cr6.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// ble cr6,0x82c8879c
	if (!ctx.cr6.gt) goto loc_82C8879C;
	// mr r31,r25
	ctx.r31.u64 = ctx.r25.u64;
loc_82C88788:
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c87768
	ctx.lr = 0x82C88794;
	sub_82C87768(ctx, base);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bne 0x82c88788
	if (!ctx.cr0.eq) goto loc_82C88788;
loc_82C8879C:
	// mr r4,r18
	ctx.r4.u64 = ctx.r18.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c87768
	ctx.lr = 0x82C887AC;
	sub_82C87768(ctx, base);
	// lwz r29,40(r26)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r26.u32 + 40);
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82c88804
	if (ctx.cr6.eq) goto loc_82C88804;
	// li r31,0
	ctx.r31.s64 = 0;
	// ble cr6,0x82c88804
	if (!ctx.cr6.gt) goto loc_82C88804;
loc_82C887C0:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c88f58
	ctx.lr = 0x82C887CC;
	sub_82C88F58(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r3,r30,12
	ctx.r3.s64 = ctx.r30.s64 + 12;
	// bl 0x82c81e58
	ctx.lr = 0x82C887D8;
	sub_82C81E58(ctx, base);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r3,r30,8
	ctx.r3.s64 = ctx.r30.s64 + 8;
	// bl 0x82c81e58
	ctx.lr = 0x82C887E4;
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// bl 0x82c87768
	ctx.lr = 0x82C887F8;
	sub_82C87768(ctx, base);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmpw cr6,r31,r29
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r29.s32, ctx.xer);
	// blt cr6,0x82c887c0
	if (ctx.cr6.lt) goto loc_82C887C0;
loc_82C88804:
	// addi r31,r26,12
	ctx.r31.s64 = ctx.r26.s64 + 12;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c81e58
	ctx.lr = 0x82C88810;
	sub_82C81E58(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82baa130
	ctx.lr = 0x82C8881C;
	sub_82BAA130(ctx, base);
	// cntlzw r11,r3
	ctx.r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// rlwinm r10,r11,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r29,r10,1
	ctx.r29.u64 = ctx.r10.u64 ^ 1;
	// bne cr6,0x82c88844
	if (!ctx.cr6.eq) goto loc_82C88844;
	// clrlwi r30,r29,24
	ctx.r30.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82c88844
	if (!ctx.cr6.eq) goto loc_82C88844;
	// mr r4,r15
	ctx.r4.u64 = ctx.r15.u64;
	// b 0x82c888a8
	goto loc_82C888A8;
loc_82C88844:
	// mr r4,r17
	ctx.r4.u64 = ctx.r17.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c87768
	ctx.lr = 0x82C88850;
	sub_82C87768(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c81e58
	ctx.lr = 0x82C88858;
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82c88898
	if (ctx.cr6.eq) goto loc_82C88898;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
loc_82C88868:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c88868
	if (!ctx.cr6.eq) goto loc_82C88868;
	// subf r11,r5,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r5.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r10,r11,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c88898
	if (ctx.cr6.eq) goto loc_82C88898;
	// mr r4,r16
	ctx.r4.u64 = ctx.r16.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c87768
	ctx.lr = 0x82C88898;
	sub_82C87768(ctx, base);
loc_82C88898:
	// clrlwi r30,r29,24
	ctx.r30.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c888b0
	if (ctx.cr6.eq) goto loc_82C888B0;
	// mr r4,r14
	ctx.r4.u64 = ctx.r14.u64;
loc_82C888A8:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c87768
	ctx.lr = 0x82C888B0;
	sub_82C87768(ctx, base);
loc_82C888B0:
	// lwz r28,20(r26)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82c88944
	if (ctx.cr6.eq) goto loc_82C88944;
	// addi r29,r25,1
	ctx.r29.s64 = ctx.r25.s64 + 1;
	// mr r31,r23
	ctx.r31.u64 = ctx.r23.u64;
	// cmplw cr6,r23,r29
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, ctx.r29.u32, ctx.xer);
	// bge cr6,0x82c8891c
	if (!ctx.cr6.lt) goto loc_82C8891C;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// bne cr6,0x82c888d8
	if (!ctx.cr6.eq) goto loc_82C888D8;
	// li r31,1
	ctx.r31.s64 = 1;
loc_82C888D8:
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// bge cr6,0x82c888ec
	if (!ctx.cr6.lt) goto loc_82C888EC;
loc_82C888E0:
	// rlwinm r31,r31,1,0,30
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// blt cr6,0x82c888e0
	if (ctx.cr6.lt) goto loc_82C888E0;
loc_82C888EC:
	// cmplw cr6,r31,r23
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r23.u32, ctx.xer);
	// ble cr6,0x82c8891c
	if (!ctx.cr6.gt) goto loc_82C8891C;
	// rlwinm r3,r31,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82c87a50
	ctx.lr = 0x82C888FC;
	sub_82C87A50(ctx, base);
	// rlwinm r5,r25,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	ctx.lr = 0x82C8890C;
	sub_82CA2C60(ctx, base);
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82c87a68
	ctx.lr = 0x82C88914;
	sub_82C87A68(ctx, base);
	// mr r22,r30
	ctx.r22.u64 = ctx.r30.u64;
	// mr r23,r31
	ctx.r23.u64 = ctx.r31.u64;
loc_82C8891C:
	// rlwinm r11,r25,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r25,r29
	ctx.r25.u64 = ctx.r29.u64;
	// stwx r26,r11,r22
	PPC_STORE_U32(ctx.r11.u32 + ctx.r22.u32, ctx.r26.u32);
	// mr r26,r28
	ctx.r26.u64 = ctx.r28.u64;
loc_82C8892C:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// bne cr6,0x82c8876c
	if (!ctx.cr6.eq) goto loc_82C8876C;
loc_82C88934:
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82c87a68
	ctx.lr = 0x82C8893C;
	sub_82C87A68(ctx, base);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82ca2c00
	__restgprlr_14(ctx, base);
	return;
loc_82C88944:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c88968
	if (ctx.cr6.eq) goto loc_82C88968;
	// addic. r31,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r31.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// ble 0x82c88968
	if (!ctx.cr0.gt) goto loc_82C88968;
loc_82C88954:
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c87768
	ctx.lr = 0x82C88960;
	sub_82C87768(ctx, base);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bne 0x82c88954
	if (!ctx.cr0.eq) goto loc_82C88954;
loc_82C88968:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82c81e58
	ctx.lr = 0x82C88970;
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r20
	ctx.r4.u64 = ctx.r20.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c87768
	ctx.lr = 0x82C88980;
	sub_82C87768(ctx, base);
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c88994
	if (ctx.cr6.eq) goto loc_82C88994;
	// mr r26,r11
	ctx.r26.u64 = ctx.r11.u64;
	// b 0x82c8892c
	goto loc_82C8892C;
loc_82C88994:
	// li r26,0
	ctx.r26.s64 = 0;
loc_82C88998:
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82c8892c
	if (ctx.cr6.eq) goto loc_82C8892C;
	// rlwinm r28,r25,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r25,-1
	ctx.r30.s64 = ctx.r25.s64 + -1;
	// add r11,r28,r22
	ctx.r11.u64 = ctx.r28.u64 + ctx.r22.u64;
	// mr r31,r23
	ctx.r31.u64 = ctx.r23.u64;
	// cmplw cr6,r23,r30
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, ctx.r30.u32, ctx.xer);
	// lwz r27,-4(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// bge cr6,0x82c88a0c
	if (!ctx.cr6.lt) goto loc_82C88A0C;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// bne cr6,0x82c889c8
	if (!ctx.cr6.eq) goto loc_82C889C8;
	// li r31,1
	ctx.r31.s64 = 1;
loc_82C889C8:
	// cmplw cr6,r31,r30
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r30.u32, ctx.xer);
	// bge cr6,0x82c889dc
	if (!ctx.cr6.lt) goto loc_82C889DC;
loc_82C889D0:
	// rlwinm r31,r31,1,0,30
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r31,r30
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r30.u32, ctx.xer);
	// blt cr6,0x82c889d0
	if (ctx.cr6.lt) goto loc_82C889D0;
loc_82C889DC:
	// cmplw cr6,r31,r23
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r23.u32, ctx.xer);
	// ble cr6,0x82c88a0c
	if (!ctx.cr6.gt) goto loc_82C88A0C;
	// rlwinm r3,r31,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82c87a50
	ctx.lr = 0x82C889EC;
	sub_82C87A50(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// bl 0x82ca2c60
	ctx.lr = 0x82C889FC;
	sub_82CA2C60(ctx, base);
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82c87a68
	ctx.lr = 0x82C88A04;
	sub_82C87A68(ctx, base);
	// mr r22,r29
	ctx.r22.u64 = ctx.r29.u64;
	// mr r23,r31
	ctx.r23.u64 = ctx.r31.u64;
loc_82C88A0C:
	// lwz r26,4(r27)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// mr r25,r30
	ctx.r25.u64 = ctx.r30.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82c88a34
	if (!ctx.cr6.gt) goto loc_82C88A34;
	// mr r31,r30
	ctx.r31.u64 = ctx.r30.u64;
loc_82C88A20:
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c87768
	ctx.lr = 0x82C88A2C;
	sub_82C87768(ctx, base);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bne 0x82c88a20
	if (!ctx.cr0.eq) goto loc_82C88A20;
loc_82C88A34:
	// addi r3,r27,8
	ctx.r3.s64 = ctx.r27.s64 + 8;
	// bl 0x82c81e58
	ctx.lr = 0x82C88A3C;
	sub_82C81E58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r20
	ctx.r4.u64 = ctx.r20.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c87768
	ctx.lr = 0x82C88A4C;
	sub_82C87768(ctx, base);
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82c88998
	if (ctx.cr6.eq) goto loc_82C88998;
	// b 0x82c8876c
	goto loc_82C8876C;
}

__attribute__((alias("__imp__sub_82C88A58"))) PPC_WEAK_FUNC(sub_82C88A58);
PPC_FUNC_IMPL(__imp__sub_82C88A58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c89208
	ctx.lr = 0x82C88A78;
	sub_82C89208(ctx, base);
	// lwz r31,4(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c88aac
	if (ctx.cr6.eq) goto loc_82C88AAC;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c82038
	ctx.lr = 0x82C88A8C;
	sub_82C82038(ctx, base);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// bl 0x82c87a68
	ctx.lr = 0x82C88A94;
	sub_82C87A68(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// bl 0x82c87a68
	ctx.lr = 0x82C88AAC;
	sub_82C87A68(ctx, base);
loc_82C88AAC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C88AC0"))) PPC_WEAK_FUNC(sub_82C88AC0);
PPC_FUNC_IMPL(__imp__sub_82C88AC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C88AC8;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82c89208
	ctx.lr = 0x82C88AE0;
	sub_82C89208(ctx, base);
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r28,0
	ctx.r28.s64 = 0;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// stw r28,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r28.u32);
	// lwz r30,4(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c88b20
	if (ctx.cr6.eq) goto loc_82C88B20;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c82038
	ctx.lr = 0x82C88B04;
	sub_82C82038(ctx, base);
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// bl 0x82c87a68
	ctx.lr = 0x82C88B0C;
	sub_82C87A68(ctx, base);
	// stw r28,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r28.u32);
	// stw r28,20(r30)
	PPC_STORE_U32(ctx.r30.u32 + 20, ctx.r28.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r28,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r28.u32);
	// bl 0x82c87a68
	ctx.lr = 0x82C88B20;
	sub_82C87A68(ctx, base);
loc_82C88B20:
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// stw r28,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r28.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88B38"))) PPC_WEAK_FUNC(sub_82C88B38);
PPC_FUNC_IMPL(__imp__sub_82C88B38) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C88B40;
	__savegprlr_29(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82c87bc0
	ctx.lr = 0x82C88B58;
	sub_82C87BC0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// addi r10,r11,-5432
	ctx.r10.s64 = ctx.r11.s64 + -5432;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x82c874e0
	ctx.lr = 0x82C88B6C;
	sub_82C874E0(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c88258
	ctx.lr = 0x82C88B7C;
	sub_82C88258(ctx, base);
	// lwz r9,100(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c88bb0
	if (!ctx.cr6.eq) goto loc_82C88BB0;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x830418a8
	ctx.lr = 0x82C88B90;
	sub_830418A8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82c88ac0
	ctx.lr = 0x82C88B98;
	sub_82C88AC0(ctx, base);
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,1
	ctx.r31.s64 = 1;
	// bl 0x82c87538
	ctx.lr = 0x82C88BA4;
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C88BB0:
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,0
	ctx.r31.s64 = 0;
	// bl 0x82c87538
	ctx.lr = 0x82C88BBC;
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88BC8"))) PPC_WEAK_FUNC(sub_82C88BC8);
PPC_FUNC_IMPL(__imp__sub_82C88BC8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C88BD0;
	__savegprlr_29(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82c87bc0
	ctx.lr = 0x82C88BE8;
	sub_82C87BC0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// addi r10,r11,-5432
	ctx.r10.s64 = ctx.r11.s64 + -5432;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x82c874e0
	ctx.lr = 0x82C88BFC;
	sub_82C874E0(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c88390
	ctx.lr = 0x82C88C0C;
	sub_82C88390(ctx, base);
	// lwz r9,100(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c88c40
	if (!ctx.cr6.eq) goto loc_82C88C40;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x830418a8
	ctx.lr = 0x82C88C20;
	sub_830418A8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82c88ac0
	ctx.lr = 0x82C88C28;
	sub_82C88AC0(ctx, base);
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,1
	ctx.r31.s64 = 1;
	// bl 0x82c87538
	ctx.lr = 0x82C88C34;
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C88C40:
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,0
	ctx.r31.s64 = 0;
	// bl 0x82c87538
	ctx.lr = 0x82C88C4C;
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88C58"))) PPC_WEAK_FUNC(sub_82C88C58);
PPC_FUNC_IMPL(__imp__sub_82C88C58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C88C60;
	__savegprlr_29(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82c87bc0
	ctx.lr = 0x82C88C78;
	sub_82C87BC0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// addi r10,r11,-5432
	ctx.r10.s64 = ctx.r11.s64 + -5432;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x82c874e0
	ctx.lr = 0x82C88C8C;
	sub_82C874E0(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82c884c0
	ctx.lr = 0x82C88CA0;
	sub_82C884C0(ctx, base);
	// lwz r9,100(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c88cd4
	if (!ctx.cr6.eq) goto loc_82C88CD4;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x830418a8
	ctx.lr = 0x82C88CB4;
	sub_830418A8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82c88ac0
	ctx.lr = 0x82C88CBC;
	sub_82C88AC0(ctx, base);
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,1
	ctx.r31.s64 = 1;
	// bl 0x82c87538
	ctx.lr = 0x82C88CC8;
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C88CD4:
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// li r31,0
	ctx.r31.s64 = 0;
	// bl 0x82c87538
	ctx.lr = 0x82C88CE0;
	sub_82C87538(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88CF0"))) PPC_WEAK_FUNC(sub_82C88CF0);
PPC_FUNC_IMPL(__imp__sub_82C88CF0) {
	PPC_FUNC_PROLOGUE();
	// addi r3,r3,12
	ctx.r3.s64 = ctx.r3.s64 + 12;
	// b 0x82c825a0
	sub_82C825A0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88CF8"))) PPC_WEAK_FUNC(sub_82C88CF8);
PPC_FUNC_IMPL(__imp__sub_82C88CF8) {
	PPC_FUNC_PROLOGUE();
	// addi r3,r3,12
	ctx.r3.s64 = ctx.r3.s64 + 12;
	// b 0x82c824d8
	sub_82C824D8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88D00"))) PPC_WEAK_FUNC(sub_82C88D00);
PPC_FUNC_IMPL(__imp__sub_82C88D00) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// addi r3,r31,8
	ctx.r3.s64 = ctx.r31.s64 + 8;
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
	// bl 0x82c823d8
	ctx.lr = 0x82C88D2C;
	sub_82C823D8(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// addi r3,r31,12
	ctx.r3.s64 = ctx.r31.s64 + 12;
	// addi r4,r11,3224
	ctx.r4.s64 = ctx.r11.s64 + 3224;
	// bl 0x82c823d8
	ctx.lr = 0x82C88D3C;
	sub_82C823D8(ctx, base);
	// stw r30,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r30.u32);
	// stw r30,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r30.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r30,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r30.u32);
	// stw r30,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r30.u32);
	// stw r30,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r30.u32);
	// stw r30,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r30.u32);
	// stw r30,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C88D78"))) PPC_WEAK_FUNC(sub_82C88D78);
PPC_FUNC_IMPL(__imp__sub_82C88D78) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// addi r11,r3,20
	ctx.r11.s64 = ctx.r3.s64 + 20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c88db4
	if (ctx.cr6.eq) goto loc_82C88DB4;
	// stw r4,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r4.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r8,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r8.u32);
	// stw r9,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r9.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r4,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r4.u32);
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// stw r3,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r3.u32);
	// blr 
	return;
loc_82C88DB4:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r4,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r4.u32);
	// stw r4,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r4.u32);
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// stw r10,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// stw r3,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C88DE0"))) PPC_WEAK_FUNC(sub_82C88DE0);
PPC_FUNC_IMPL(__imp__sub_82C88DE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// bl 0x82ca2a08
	ctx.lr = 0x82C88E04;
	sub_82CA2A08(ctx, base);
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// addi r11,r31,32
	ctx.r11.s64 = ctx.r31.s64 + 32;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c88e30
	if (ctx.cr6.eq) goto loc_82C88E30;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r3,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r3.u32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r3,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r3.u32);
	// b 0x82c88e44
	goto loc_82C88E44;
loc_82C88E30:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r3,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r3.u32);
	// stw r3,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r3.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
loc_82C88E44:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C88E68"))) PPC_WEAK_FUNC(sub_82C88E68);
PPC_FUNC_IMPL(__imp__sub_82C88E68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C88E70;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// lwz r31,32(r29)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + 32);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c88eb4
	if (ctx.cr6.eq) goto loc_82C88EB4;
loc_82C88E90:
	// addi r3,r31,8
	ctx.r3.s64 = ctx.r31.s64 + 8;
	// bl 0x82c81e58
	ctx.lr = 0x82C88E98;
	sub_82C81E58(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82caaf08
	ctx.lr = 0x82C88EA0;
	sub_82CAAF08(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c88ed0
	if (ctx.cr6.eq) goto loc_82C88ED0;
	// lwz r31,4(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82c88e90
	if (!ctx.cr6.eq) goto loc_82C88E90;
loc_82C88EB4:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c88de0
	ctx.lr = 0x82C88EC8;
	sub_82C88DE0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C88ED0:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// addi r3,r31,12
	ctx.r3.s64 = ctx.r31.s64 + 12;
	// bl 0x82c825a0
	ctx.lr = 0x82C88EDC;
	sub_82C825A0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C88EE8"))) PPC_WEAK_FUNC(sub_82C88EE8);
PPC_FUNC_IMPL(__imp__sub_82C88EE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,32(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c88f30
	if (ctx.cr6.eq) goto loc_82C88F30;
loc_82C88F0C:
	// addi r3,r31,8
	ctx.r3.s64 = ctx.r31.s64 + 8;
	// bl 0x82c81e58
	ctx.lr = 0x82C88F14;
	sub_82C81E58(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82caaf08
	ctx.lr = 0x82C88F1C;
	sub_82CAAF08(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c88f4c
	if (ctx.cr6.eq) goto loc_82C88F4C;
	// lwz r31,4(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82c88f0c
	if (!ctx.cr6.eq) goto loc_82C88F0C;
loc_82C88F30:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C88F34:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C88F4C:
	// addi r3,r31,12
	ctx.r3.s64 = ctx.r31.s64 + 12;
	// bl 0x82c81e58
	ctx.lr = 0x82C88F54;
	sub_82C81E58(ctx, base);
	// b 0x82c88f34
	goto loc_82C88F34;
}

__attribute__((alias("__imp__sub_82C88F58"))) PPC_WEAK_FUNC(sub_82C88F58);
PPC_FUNC_IMPL(__imp__sub_82C88F58) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,32(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82C88F68:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r3,4(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r11,r4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r4.u32, ctx.xer);
	// blt cr6,0x82c88f68
	if (ctx.cr6.lt) goto loc_82C88F68;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C88F88"))) PPC_WEAK_FUNC(sub_82C88F88);
PPC_FUNC_IMPL(__imp__sub_82C88F88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C88F90;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r31,r3,32
	ctx.r31.s64 = ctx.r3.s64 + 32;
	// lwz r3,32(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c8901c
	if (ctx.cr6.eq) goto loc_82C8901C;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82C88FAC:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c88fc4
	if (!ctx.cr6.eq) goto loc_82C88FC4;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// b 0x82c88fd0
	goto loc_82C88FD0;
loc_82C88FC4:
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_82C88FD0:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c88fe8
	if (!ctx.cr6.eq) goto loc_82C88FE8;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// b 0x82c88ff4
	goto loc_82C88FF4;
loc_82C88FE8:
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
loc_82C88FF4:
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bl 0x82ca29f0
	ctx.lr = 0x82C89010;
	sub_82CA29F0(ctx, base);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c88fac
	if (!ctx.cr6.eq) goto loc_82C88FAC;
loc_82C8901C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C89028"))) PPC_WEAK_FUNC(sub_82C89028);
PPC_FUNC_IMPL(__imp__sub_82C89028) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C89030;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lwz r31,0(r29)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c89064
	if (ctx.cr6.eq) goto loc_82C89064;
loc_82C89044:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r30,4(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x829ce870
	ctx.lr = 0x82C89050;
	sub_829CE870(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82ca29e8
	ctx.lr = 0x82C89058;
	sub_82CA29E8(ctx, base);
	// mr r31,r30
	ctx.r31.u64 = ctx.r30.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82c89044
	if (!ctx.cr6.eq) goto loc_82C89044;
loc_82C89064:
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r11.u32);
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C89080"))) PPC_WEAK_FUNC(sub_82C89080);
PPC_FUNC_IMPL(__imp__sub_82C89080) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C89088;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r31,0(r26)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c890f8
	if (ctx.cr6.eq) goto loc_82C890F8;
loc_82C890A0:
	// lwz r30,32(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// lwz r28,4(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c890d0
	if (ctx.cr6.eq) goto loc_82C890D0;
loc_82C890B0:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r29,4(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x829ce870
	ctx.lr = 0x82C890BC;
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82ca29e8
	ctx.lr = 0x82C890C4;
	sub_82CA29E8(ctx, base);
	// mr r30,r29
	ctx.r30.u64 = ctx.r29.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82c890b0
	if (!ctx.cr6.eq) goto loc_82C890B0;
loc_82C890D0:
	// stw r27,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r27.u32);
	// addi r3,r31,20
	ctx.r3.s64 = ctx.r31.s64 + 20;
	// stw r27,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r27.u32);
	// stw r27,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r27.u32);
	// bl 0x82c89080
	ctx.lr = 0x82C890E4;
	sub_82C89080(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c87a68
	ctx.lr = 0x82C890EC;
	sub_82C87A68(ctx, base);
	// mr r31,r28
	ctx.r31.u64 = ctx.r28.u64;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// bne cr6,0x82c890a0
	if (!ctx.cr6.eq) goto loc_82C890A0;
loc_82C890F8:
	// stw r27,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r27.u32);
	// stw r27,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r27.u32);
	// stw r27,8(r26)
	PPC_STORE_U32(ctx.r26.u32 + 8, ctx.r27.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C89110"))) PPC_WEAK_FUNC(sub_82C89110);
PPC_FUNC_IMPL(__imp__sub_82C89110) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C89118;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,20(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// addi r29,r3,20
	ctx.r29.s64 = ctx.r3.s64 + 20;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c89200
	if (ctx.cr6.eq) goto loc_82C89200;
	// li r27,0
	ctx.r27.s64 = 0;
loc_82C89134:
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c89110
	ctx.lr = 0x82C89140;
	sub_82C89110(ctx, base);
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c89158
	if (!ctx.cr6.eq) goto loc_82C89158;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
	// b 0x82c89164
	goto loc_82C89164;
loc_82C89158:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_82C89164:
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c8917c
	if (!ctx.cr6.eq) goto loc_82C8917C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r11,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r11.u32);
	// b 0x82c89188
	goto loc_82C89188;
loc_82C8917C:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
loc_82C89188:
	// stw r27,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r27.u32);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// stw r27,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r27.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// bl 0x82c88f88
	ctx.lr = 0x82C891A8;
	sub_82C88F88(ctx, base);
	// lwz r30,32(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c891d4
	if (ctx.cr6.eq) goto loc_82C891D4;
loc_82C891B4:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r28,4(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x829ce870
	ctx.lr = 0x82C891C0;
	sub_829CE870(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82ca29e8
	ctx.lr = 0x82C891C8;
	sub_82CA29E8(ctx, base);
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// bne cr6,0x82c891b4
	if (!ctx.cr6.eq) goto loc_82C891B4;
loc_82C891D4:
	// stw r27,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r27.u32);
	// addi r3,r31,20
	ctx.r3.s64 = ctx.r31.s64 + 20;
	// stw r27,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r27.u32);
	// stw r27,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r27.u32);
	// bl 0x82c89080
	ctx.lr = 0x82C891E8;
	sub_82C89080(ctx, base);
	// lwz r11,12(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,12(r26)
	PPC_STORE_U32(ctx.r26.u32 + 12, ctx.r11.u32);
	// lwz r31,0(r29)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82c89134
	if (!ctx.cr6.eq) goto loc_82C89134;
loc_82C89200:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C89208"))) PPC_WEAK_FUNC(sub_82C89208);
PPC_FUNC_IMPL(__imp__sub_82C89208) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c89258
	if (ctx.cr6.eq) goto loc_82C89258;
	// bl 0x82c89110
	ctx.lr = 0x82C89230;
	sub_82C89110(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c88f88
	ctx.lr = 0x82C8923C;
	sub_82C88F88(ctx, base);
	// addi r3,r31,32
	ctx.r3.s64 = ctx.r31.s64 + 32;
	// bl 0x82c89028
	ctx.lr = 0x82C89244;
	sub_82C89028(ctx, base);
	// addi r3,r31,20
	ctx.r3.s64 = ctx.r31.s64 + 20;
	// bl 0x82c89080
	ctx.lr = 0x82C8924C;
	sub_82C89080(ctx, base);
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r11.u32);
loc_82C89258:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C89270"))) PPC_WEAK_FUNC(sub_82C89270);
PPC_FUNC_IMPL(__imp__sub_82C89270) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// li r4,44
	ctx.r4.s64 = 44;
	// bl 0x82c82220
	ctx.lr = 0x82C89294;
	sub_82C82220(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c892ac
	if (ctx.cr6.eq) goto loc_82C892AC;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c88d00
	ctx.lr = 0x82C892A8;
	sub_82C88D00(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82C892AC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C892C8"))) PPC_WEAK_FUNC(sub_82C892C8);
PPC_FUNC_IMPL(__imp__sub_82C892C8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,-5348
	ctx.r9.s64 = ctx.r11.s64 + -5348;
	// lwzx r3,r10,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C892E0"))) PPC_WEAK_FUNC(sub_82C892E0);
PPC_FUNC_IMPL(__imp__sub_82C892E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C892E8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// addi r31,r11,-5348
	ctx.r31.s64 = ctx.r11.s64 + -5348;
loc_82C892FC:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82caaf80
	ctx.lr = 0x82C89308;
	sub_82CAAF80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8932c
	if (ctx.cr6.eq) goto loc_82C8932C;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r30,7
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 7, ctx.xer);
	// blt cr6,0x82c892fc
	if (ctx.cr6.lt) goto loc_82C892FC;
	// li r3,6
	ctx.r3.s64 = 6;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C8932C:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C89338"))) PPC_WEAK_FUNC(sub_82C89338);
PPC_FUNC_IMPL(__imp__sub_82C89338) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// lbz r9,1(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r11,r11,-4144
	ctx.r11.s64 = ctx.r11.s64 + -4144;
	// rlwinm r6,r10,30,29,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x7;
	// addi r5,r11,1536
	ctx.r5.s64 = ctx.r11.s64 + 1536;
	// clrlwi r4,r9,27
	ctx.r4.u64 = ctx.r9.u32 & 0x1F;
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// slw r7,r7,r4
	ctx.r7.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r3,r6,r5
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r6.u32 + ctx.r5.u32);
	// rotlwi r9,r3,2
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r3.u32, 2);
	// add r6,r9,r10
	ctx.r6.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r10,r6,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// add r5,r10,r8
	ctx.r5.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r4,r5,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r4,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r11.u32);
	// and r3,r3,r7
	ctx.r3.u64 = ctx.r3.u64 & ctx.r7.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C89388"))) PPC_WEAK_FUNC(sub_82C89388);
PPC_FUNC_IMPL(__imp__sub_82C89388) {
	PPC_FUNC_PROLOGUE();
	// lbz r8,1(r4)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lbz r6,0(r4)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r7,-4144
	ctx.r11.s64 = ctx.r7.s64 + -4144;
	// lbz r4,2(r4)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// rlwinm r9,r6,4,24,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xF0;
	// rlwinm r10,r8,30,28,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 30) & 0xF;
	// addi r3,r11,1536
	ctx.r3.s64 = ctx.r11.s64 + 1536;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// clrlwi r8,r8,30
	ctx.r8.u64 = ctx.r8.u32 & 0x3;
	// rlwinm r9,r4,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x1;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r6,r10,r3
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r3.u32);
	// slw r5,r5,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r7.u8 & 0x3F));
	// rotlwi r10,r6,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r6.u32, 2);
	// add r4,r10,r8
	ctx.r4.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r10,r4,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 1) & 0xFFFFFFFE;
	// add r3,r10,r9
	ctx.r3.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// and r3,r9,r5
	ctx.r3.u64 = ctx.r9.u64 & ctx.r5.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C893E8"))) PPC_WEAK_FUNC(sub_82C893E8);
PPC_FUNC_IMPL(__imp__sub_82C893E8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// lbz r9,1(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r11,r11,-4144
	ctx.r11.s64 = ctx.r11.s64 + -4144;
	// rlwinm r6,r10,30,29,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x7;
	// addi r5,r11,1280
	ctx.r5.s64 = ctx.r11.s64 + 1280;
	// clrlwi r4,r9,27
	ctx.r4.u64 = ctx.r9.u32 & 0x1F;
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// slw r7,r7,r4
	ctx.r7.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r3,r6,r5
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r6.u32 + ctx.r5.u32);
	// rotlwi r9,r3,2
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r3.u32, 2);
	// add r6,r9,r10
	ctx.r6.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r10,r6,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// add r5,r10,r8
	ctx.r5.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r4,r5,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r4,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r11.u32);
	// and r3,r3,r7
	ctx.r3.u64 = ctx.r3.u64 & ctx.r7.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C89438"))) PPC_WEAK_FUNC(sub_82C89438);
PPC_FUNC_IMPL(__imp__sub_82C89438) {
	PPC_FUNC_PROLOGUE();
	// lbz r8,1(r4)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lbz r6,0(r4)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r7,-4144
	ctx.r11.s64 = ctx.r7.s64 + -4144;
	// lbz r4,2(r4)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// rlwinm r9,r6,4,24,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xF0;
	// rlwinm r10,r8,30,28,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 30) & 0xF;
	// addi r3,r11,1280
	ctx.r3.s64 = ctx.r11.s64 + 1280;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// clrlwi r8,r8,30
	ctx.r8.u64 = ctx.r8.u32 & 0x3;
	// rlwinm r9,r4,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x1;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r6,r10,r3
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r3.u32);
	// slw r5,r5,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r7.u8 & 0x3F));
	// rotlwi r10,r6,2
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r6.u32, 2);
	// add r4,r10,r8
	ctx.r4.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r10,r4,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 1) & 0xFFFFFFFE;
	// add r3,r10,r9
	ctx.r3.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// and r3,r9,r5
	ctx.r3.u64 = ctx.r9.u64 & ctx.r5.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C89498"))) PPC_WEAK_FUNC(sub_82C89498);
PPC_FUNC_IMPL(__imp__sub_82C89498) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,194
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 194, ctx.xer);
	// blt cr6,0x82c894c4
	if (ctx.cr6.lt) goto loc_82C894C4;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c894c4
	if (ctx.cr6.eq) goto loc_82C894C4;
	// rlwinm r11,r11,0,24,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r11,192
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 192, ctx.xer);
	// bnelr cr6
	if (!ctx.cr6.eq) return;
loc_82C894C4:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C894D0"))) PPC_WEAK_FUNC(sub_82C894D0);
PPC_FUNC_IMPL(__imp__sub_82C894D0) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,2(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c89500
	if (ctx.cr6.eq) goto loc_82C89500;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r10,239
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 239, ctx.xer);
	// bne cr6,0x82c89508
	if (!ctx.cr6.eq) goto loc_82C89508;
	// lbz r9,1(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r9,191
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 191, ctx.xer);
	// bne cr6,0x82c89508
	if (!ctx.cr6.eq) goto loc_82C89508;
	// cmplwi cr6,r11,189
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 189, ctx.xer);
	// ble cr6,0x82c89520
	if (!ctx.cr6.gt) goto loc_82C89520;
loc_82C89500:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C89508:
	// rlwinm r11,r11,0,24,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0;
	// addi r11,r11,-192
	ctx.r11.s64 = ctx.r11.s64 + -192;
	// cntlzw r9,r11
	ctx.r9.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne cr6,0x82c89500
	if (!ctx.cr6.eq) goto loc_82C89500;
loc_82C89520:
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r10,224
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 224, ctx.xer);
	// bne cr6,0x82c89548
	if (!ctx.cr6.eq) goto loc_82C89548;
	// cmplwi cr6,r11,160
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 160, ctx.xer);
	// blt cr6,0x82c89500
	if (ctx.cr6.lt) goto loc_82C89500;
	// rlwinm r11,r11,0,24,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0;
	// cmplwi cr6,r11,192
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 192, ctx.xer);
	// bne cr6,0x82c89584
	if (!ctx.cr6.eq) goto loc_82C89584;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C89548:
	// rlwinm r9,r11,0,0,24
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c89500
	if (ctx.cr6.eq) goto loc_82C89500;
	// cmplwi cr6,r10,237
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 237, ctx.xer);
	// bne cr6,0x82c8956c
	if (!ctx.cr6.eq) goto loc_82C8956C;
	// cmplwi cr6,r11,159
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 159, ctx.xer);
	// bgt cr6,0x82c89500
	if (ctx.cr6.gt) goto loc_82C89500;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8956C:
	// rlwinm r11,r11,0,24,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0;
	// addi r11,r11,-192
	ctx.r11.s64 = ctx.r11.s64 + -192;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c89500
	if (!ctx.cr6.eq) goto loc_82C89500;
loc_82C89584:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C89590"))) PPC_WEAK_FUNC(sub_82C89590);
PPC_FUNC_IMPL(__imp__sub_82C89590) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,3(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c895ec
	if (ctx.cr6.eq) goto loc_82C895EC;
	// rlwinm r11,r11,0,24,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0;
	// cmplwi cr6,r11,192
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 192, ctx.xer);
	// beq cr6,0x82c895ec
	if (ctx.cr6.eq) goto loc_82C895EC;
	// lbz r11,2(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c895ec
	if (ctx.cr6.eq) goto loc_82C895EC;
	// rlwinm r11,r11,0,24,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0;
	// cmplwi cr6,r11,192
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 192, ctx.xer);
	// beq cr6,0x82c895ec
	if (ctx.cr6.eq) goto loc_82C895EC;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r10,240
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 240, ctx.xer);
	// bne cr6,0x82c895f4
	if (!ctx.cr6.eq) goto loc_82C895F4;
	// cmplwi cr6,r11,144
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 144, ctx.xer);
	// blt cr6,0x82c895ec
	if (ctx.cr6.lt) goto loc_82C895EC;
	// rlwinm r11,r11,0,24,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0;
	// cmplwi cr6,r11,192
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 192, ctx.xer);
	// bne cr6,0x82c89630
	if (!ctx.cr6.eq) goto loc_82C89630;
loc_82C895EC:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C895F4:
	// rlwinm r9,r11,0,0,24
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c895ec
	if (ctx.cr6.eq) goto loc_82C895EC;
	// cmplwi cr6,r10,244
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 244, ctx.xer);
	// bne cr6,0x82c89618
	if (!ctx.cr6.eq) goto loc_82C89618;
	// cmplwi cr6,r11,143
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 143, ctx.xer);
	// bgt cr6,0x82c895ec
	if (ctx.cr6.gt) goto loc_82C895EC;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C89618:
	// rlwinm r11,r11,0,24,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0;
	// addi r11,r11,-192
	ctx.r11.s64 = ctx.r11.s64 + -192;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c895ec
	if (!ctx.cr6.eq) goto loc_82C895EC;
loc_82C89630:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C89638"))) PPC_WEAK_FUNC(sub_82C89638);
PPC_FUNC_IMPL(__imp__sub_82C89638) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C89640;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// cmplw cr6,r4,r28
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c89804
	if (ctx.cr6.eq) goto loc_82C89804;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,45
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 45, ctx.xer);
	// beq cr6,0x82c89674
	if (ctx.cr6.eq) goto loc_82C89674;
	// stw r4,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C89674:
	// addi r31,r4,1
	ctx.r31.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c89804
	if (ctx.cr6.eq) goto loc_82C89804;
	// subf r30,r31,r28
	ctx.r30.s64 = ctx.r28.s64 - ctx.r31.s64;
loc_82C89684:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmplwi cr6,r11,27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 27, ctx.xer);
	// bgt cr6,0x82c897f4
	if (ctx.cr6.gt) goto loc_82C897F4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-26960
	ctx.r12.s64 = ctx.r12.s64 + -26960;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8981C;
	case 1:
		goto loc_82C8981C;
	case 2:
		goto loc_82C897F4;
	case 3:
		goto loc_82C897F4;
	case 4:
		goto loc_82C897F4;
	case 5:
		goto loc_82C89720;
	case 6:
		goto loc_82C89750;
	case 7:
		goto loc_82C89780;
	case 8:
		goto loc_82C8981C;
	case 9:
		goto loc_82C897F4;
	case 10:
		goto loc_82C897F4;
	case 11:
		goto loc_82C897F4;
	case 12:
		goto loc_82C897F4;
	case 13:
		goto loc_82C897F4;
	case 14:
		goto loc_82C897F4;
	case 15:
		goto loc_82C897F4;
	case 16:
		goto loc_82C897F4;
	case 17:
		goto loc_82C897F4;
	case 18:
		goto loc_82C897F4;
	case 19:
		goto loc_82C897F4;
	case 20:
		goto loc_82C897F4;
	case 21:
		goto loc_82C897F4;
	case 22:
		goto loc_82C897F4;
	case 23:
		goto loc_82C897F4;
	case 24:
		goto loc_82C897F4;
	case 25:
		goto loc_82C897F4;
	case 26:
		goto loc_82C897F4;
	case 27:
		goto loc_82C897B0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-26596(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26596);
	// lwz r22,-26596(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26596);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26848(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26848);
	// lwz r22,-26800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26800);
	// lwz r22,-26752(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26752);
	// lwz r22,-26596(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26596);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26636(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26636);
	// lwz r22,-26704(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26704);
loc_82C89720:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c89810
	if (ctx.cr6.lt) goto loc_82C89810;
	// lwz r11,356(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8973C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8981c
	if (!ctx.cr6.eq) goto loc_82C8981C;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c897fc
	goto loc_82C897FC;
loc_82C89750:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c89810
	if (ctx.cr6.lt) goto loc_82C89810;
	// lwz r11,360(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8976C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8981c
	if (!ctx.cr6.eq) goto loc_82C8981C;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c897fc
	goto loc_82C897FC;
loc_82C89780:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c89810
	if (ctx.cr6.lt) goto loc_82C89810;
	// lwz r11,364(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8979C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8981c
	if (!ctx.cr6.eq) goto loc_82C8981C;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// b 0x82c897fc
	goto loc_82C897FC;
loc_82C897B0:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c89804
	if (ctx.cr6.eq) goto loc_82C89804;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,45
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 45, ctx.xer);
	// bne cr6,0x82c897fc
	if (!ctx.cr6.eq) goto loc_82C897FC;
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c89804
	if (ctx.cr6.eq) goto loc_82C89804;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// beq cr6,0x82c8982c
	if (ctx.cr6.eq) goto loc_82C8982C;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C897F4:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
loc_82C897FC:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c89684
	if (!ctx.cr6.eq) goto loc_82C89684;
loc_82C89804:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C89810:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8981C:
	// stw r31,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8982C:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r3,13
	ctx.r3.s64 = 13;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C89840"))) PPC_WEAK_FUNC(sub_82C89840);
PPC_FUNC_IMPL(__imp__sub_82C89840) {
	PPC_FUNC_PROLOGUE();
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c89850
	if (!ctx.cr6.eq) goto loc_82C89850;
loc_82C89848:
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
loc_82C89850:
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-20
	ctx.r11.s64 = ctx.r11.s64 + -20;
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// bgt cr6,0x82c89a0c
	if (ctx.cr6.gt) goto loc_82C89A0C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-26496
	ctx.r12.s64 = ctx.r12.s64 + -26496;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C898A8;
	case 1:
		goto loc_82C89A0C;
	case 2:
		goto loc_82C898B8;
	case 3:
		goto loc_82C89A0C;
	case 4:
		goto loc_82C898B8;
	case 5:
		goto loc_82C89A0C;
	case 6:
		goto loc_82C89A0C;
	case 7:
		goto loc_82C898A0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-26456(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26456);
	// lwz r22,-26100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26100);
	// lwz r22,-26440(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26440);
	// lwz r22,-26100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26100);
	// lwz r22,-26440(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26440);
	// lwz r22,-26100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26100);
	// lwz r22,-26100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26100);
	// lwz r22,-26464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26464);
loc_82C898A0:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c89638
	sub_82C89638(ctx, base);
	return;
loc_82C898A8:
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// li r3,33
	ctx.r3.s64 = 33;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// blr 
	return;
loc_82C898B8:
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c89848
	if (ctx.cr6.eq) goto loc_82C89848;
loc_82C898C4:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-9
	ctx.r10.s64 = ctx.r10.s64 + -9;
	// cmplwi cr6,r10,21
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 21, ctx.xer);
	// bgt cr6,0x82c899f4
	if (ctx.cr6.gt) goto loc_82C899F4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-26380
	ctx.r12.s64 = ctx.r12.s64 + -26380;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C89A00;
	case 1:
		goto loc_82C89A00;
	case 2:
		goto loc_82C899F4;
	case 3:
		goto loc_82C899F4;
	case 4:
		goto loc_82C899F4;
	case 5:
		goto loc_82C899F4;
	case 6:
		goto loc_82C899F4;
	case 7:
		goto loc_82C899F4;
	case 8:
		goto loc_82C899F4;
	case 9:
		goto loc_82C899F4;
	case 10:
		goto loc_82C899F4;
	case 11:
		goto loc_82C899F4;
	case 12:
		goto loc_82C89A00;
	case 13:
		goto loc_82C8994C;
	case 14:
		goto loc_82C899F4;
	case 15:
		goto loc_82C8994C;
	case 16:
		goto loc_82C899F4;
	case 17:
		goto loc_82C899F4;
	case 18:
		goto loc_82C899F4;
	case 19:
		goto loc_82C899F4;
	case 20:
		goto loc_82C899F4;
	case 21:
		goto loc_82C89960;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26292(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26292);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26292(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26292);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26272);
loc_82C8994C:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c898c4
	if (!ctx.cr6.eq) goto loc_82C898C4;
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
loc_82C89960:
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c89848
	if (ctx.cr6.eq) goto loc_82C89848;
	// lbz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-9
	ctx.r10.s64 = ctx.r10.s64 + -9;
	// cmplwi cr6,r10,21
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 21, ctx.xer);
	// bgt cr6,0x82c89a00
	if (ctx.cr6.gt) goto loc_82C89A00;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-26212
	ctx.r12.s64 = ctx.r12.s64 + -26212;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C899F4;
	case 1:
		goto loc_82C899F4;
	case 2:
		goto loc_82C89A00;
	case 3:
		goto loc_82C89A00;
	case 4:
		goto loc_82C89A00;
	case 5:
		goto loc_82C89A00;
	case 6:
		goto loc_82C89A00;
	case 7:
		goto loc_82C89A00;
	case 8:
		goto loc_82C89A00;
	case 9:
		goto loc_82C89A00;
	case 10:
		goto loc_82C89A00;
	case 11:
		goto loc_82C89A00;
	case 12:
		goto loc_82C899F4;
	case 13:
		goto loc_82C89A00;
	case 14:
		goto loc_82C89A00;
	case 15:
		goto loc_82C89A00;
	case 16:
		goto loc_82C89A00;
	case 17:
		goto loc_82C89A00;
	case 18:
		goto loc_82C89A00;
	case 19:
		goto loc_82C89A00;
	case 20:
		goto loc_82C89A00;
	case 21:
		goto loc_82C899F4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26112(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26112);
	// lwz r22,-26124(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26124);
loc_82C899F4:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C89A00:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,16
	ctx.r3.s64 = 16;
	// blr 
	return;
loc_82C89A0C:
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C89A18"))) PPC_WEAK_FUNC(sub_82C89A18);
PPC_FUNC_IMPL(__imp__sub_82C89A18) {
	PPC_FUNC_PROLOGUE();
	// li r11,11
	ctx.r11.s64 = 11;
	// subf r9,r4,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r4.s64;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// bne cr6,0x82c89aa8
	if (!ctx.cr6.eq) goto loc_82C89AA8;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,88
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 88, ctx.xer);
	// beq cr6,0x82c89a50
	if (ctx.cr6.eq) goto loc_82C89A50;
	// cmpwi cr6,r11,120
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 120, ctx.xer);
	// beq cr6,0x82c89a54
	if (ctx.cr6.eq) goto loc_82C89A54;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C89A50:
	// li r10,1
	ctx.r10.s64 = 1;
loc_82C89A54:
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,77
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 77, ctx.xer);
	// beq cr6,0x82c89a74
	if (ctx.cr6.eq) goto loc_82C89A74;
	// cmpwi cr6,r11,109
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 109, ctx.xer);
	// beq cr6,0x82c89a78
	if (ctx.cr6.eq) goto loc_82C89A78;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C89A74:
	// li r10,1
	ctx.r10.s64 = 1;
loc_82C89A78:
	// lbz r11,2(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,76
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 76, ctx.xer);
	// beq cr6,0x82c89a98
	if (ctx.cr6.eq) goto loc_82C89A98;
	// cmpwi cr6,r11,108
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 108, ctx.xer);
	// bne cr6,0x82c89aa8
	if (!ctx.cr6.eq) goto loc_82C89AA8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82c89aa0
	if (ctx.cr6.eq) goto loc_82C89AA0;
loc_82C89A98:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C89AA0:
	// li r11,12
	ctx.r11.s64 = 12;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C89AA8:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C89AB0"))) PPC_WEAK_FUNC(sub_82C89AB0);
PPC_FUNC_IMPL(__imp__sub_82C89AB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C89AB8;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// mr r28,r31
	ctx.r28.u64 = ctx.r31.u64;
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c89ae4
	if (!ctx.cr6.eq) goto loc_82C89AE4;
loc_82C89AD8:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C89AE4:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c89f0c
	if (ctx.cr6.gt) goto loc_82C89F0C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-25836
	ctx.r12.s64 = ctx.r12.s64 + -25836;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C89B80;
	case 1:
		goto loc_82C89BBC;
	case 2:
		goto loc_82C89BEC;
	case 3:
		goto loc_82C89F0C;
	case 4:
		goto loc_82C89F0C;
	case 5:
		goto loc_82C89F0C;
	case 6:
		goto loc_82C89F0C;
	case 7:
		goto loc_82C89F0C;
	case 8:
		goto loc_82C89F0C;
	case 9:
		goto loc_82C89F0C;
	case 10:
		goto loc_82C89F0C;
	case 11:
		goto loc_82C89F0C;
	case 12:
		goto loc_82C89F0C;
	case 13:
		goto loc_82C89F0C;
	case 14:
		goto loc_82C89F0C;
	case 15:
		goto loc_82C89F0C;
	case 16:
		goto loc_82C89F0C;
	case 17:
		goto loc_82C89B78;
	case 18:
		goto loc_82C89F0C;
	case 19:
		goto loc_82C89B78;
	case 20:
		goto loc_82C89F0C;
	case 21:
		goto loc_82C89F0C;
	case 22:
		goto loc_82C89F0C;
	case 23:
		goto loc_82C89F0C;
	case 24:
		goto loc_82C89F0C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-25728(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25728);
	// lwz r22,-25668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25668);
	// lwz r22,-25620(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25620);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-25736(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25736);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-25736(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25736);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
loc_82C89B78:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82c89c18
	goto loc_82C89C18;
loc_82C89B80:
	// subf r11,r31,r27
	ctx.r11.s64 = ctx.r27.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c89b98
	if (!ctx.cr6.lt) goto loc_82C89B98;
loc_82C89B8C:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C89B98:
	// lwz r11,344(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C89BAC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c89f0c
	if (ctx.cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c89c18
	goto loc_82C89C18;
loc_82C89BBC:
	// subf r11,r31,r27
	ctx.r11.s64 = ctx.r27.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c89b8c
	if (ctx.cr6.lt) goto loc_82C89B8C;
	// lwz r11,348(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C89BDC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c89f0c
	if (ctx.cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c89c18
	goto loc_82C89C18;
loc_82C89BEC:
	// subf r11,r31,r27
	ctx.r11.s64 = ctx.r27.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c89b8c
	if (ctx.cr6.lt) goto loc_82C89B8C;
	// lwz r11,352(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C89C0C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c89f0c
	if (ctx.cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
loc_82C89C18:
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c89ad8
	if (ctx.cr6.eq) goto loc_82C89AD8;
	// subf r30,r31,r27
	ctx.r30.s64 = ctx.r27.s64 - ctx.r31.s64;
loc_82C89C24:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c89f0c
	if (ctx.cr6.gt) goto loc_82C89F0C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-25516
	ctx.r12.s64 = ctx.r12.s64 + -25516;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C89CC4;
	case 1:
		goto loc_82C89CF4;
	case 2:
		goto loc_82C89D24;
	case 3:
		goto loc_82C89F0C;
	case 4:
		goto loc_82C89D64;
	case 5:
		goto loc_82C89D64;
	case 6:
		goto loc_82C89F0C;
	case 7:
		goto loc_82C89F0C;
	case 8:
		goto loc_82C89F0C;
	case 9:
		goto loc_82C89F0C;
	case 10:
		goto loc_82C89ED8;
	case 11:
		goto loc_82C89F0C;
	case 12:
		goto loc_82C89F0C;
	case 13:
		goto loc_82C89F0C;
	case 14:
		goto loc_82C89F0C;
	case 15:
		goto loc_82C89F0C;
	case 16:
		goto loc_82C89D64;
	case 17:
		goto loc_82C89CB8;
	case 18:
		goto loc_82C89F0C;
	case 19:
		goto loc_82C89CB8;
	case 20:
		goto loc_82C89CB8;
	case 21:
		goto loc_82C89CB8;
	case 22:
		goto loc_82C89CB8;
	case 23:
		goto loc_82C89F0C;
	case 24:
		goto loc_82C89F0C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-25404(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25404);
	// lwz r22,-25356(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25356);
	// lwz r22,-25308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25308);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-25244(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25244);
	// lwz r22,-25244(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25244);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24872(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24872);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-25244(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25244);
	// lwz r22,-25416(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25416);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-25416(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25416);
	// lwz r22,-25416(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25416);
	// lwz r22,-25416(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25416);
	// lwz r22,-25416(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25416);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
loc_82C89CB8:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// b 0x82c89d50
	goto loc_82C89D50;
loc_82C89CC4:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c89b8c
	if (ctx.cr6.lt) goto loc_82C89B8C;
	// lwz r11,332(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C89CE0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c89f0c
	if (ctx.cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c89d50
	goto loc_82C89D50;
loc_82C89CF4:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c89b8c
	if (ctx.cr6.lt) goto loc_82C89B8C;
	// lwz r11,336(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C89D10;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c89f0c
	if (ctx.cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c89d50
	goto loc_82C89D50;
loc_82C89D24:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c89b8c
	if (ctx.cr6.lt) goto loc_82C89B8C;
	// lwz r11,340(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C89D40;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c89f0c
	if (ctx.cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
loc_82C89D50:
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c89c24
	if (!ctx.cr6.eq) goto loc_82C89C24;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C89D64:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c89a18
	ctx.lr = 0x82C89D78;
	sub_82C89A18(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c89f0c
	if (ctx.cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c89ad8
	if (ctx.cr6.eq) goto loc_82C89AD8;
	// subf r30,r31,r27
	ctx.r30.s64 = ctx.r27.s64 - ctx.r31.s64;
loc_82C89D90:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmplwi cr6,r11,15
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 15, ctx.xer);
	// bgt cr6,0x82c89ebc
	if (ctx.cr6.gt) goto loc_82C89EBC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-25156
	ctx.r12.s64 = ctx.r12.s64 + -25156;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C89F0C;
	case 1:
		goto loc_82C89F0C;
	case 2:
		goto loc_82C89EBC;
	case 3:
		goto loc_82C89EBC;
	case 4:
		goto loc_82C89EBC;
	case 5:
		goto loc_82C89DFC;
	case 6:
		goto loc_82C89E2C;
	case 7:
		goto loc_82C89E5C;
	case 8:
		goto loc_82C89F0C;
	case 9:
		goto loc_82C89EBC;
	case 10:
		goto loc_82C89EBC;
	case 11:
		goto loc_82C89EBC;
	case 12:
		goto loc_82C89EBC;
	case 13:
		goto loc_82C89EBC;
	case 14:
		goto loc_82C89EBC;
	case 15:
		goto loc_82C89E8C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24900(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-25092(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25092);
	// lwz r22,-25044(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -25044);
	// lwz r22,-24996(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24996);
	// lwz r22,-24820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24820);
	// lwz r22,-24900(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24900(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24900);
	// lwz r22,-24948(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24948);
loc_82C89DFC:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c89b8c
	if (ctx.cr6.lt) goto loc_82C89B8C;
	// lwz r11,356(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C89E18;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c89f0c
	if (!ctx.cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c89ec4
	goto loc_82C89EC4;
loc_82C89E2C:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c89b8c
	if (ctx.cr6.lt) goto loc_82C89B8C;
	// lwz r11,360(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C89E48;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c89f0c
	if (!ctx.cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c89ec4
	goto loc_82C89EC4;
loc_82C89E5C:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c89b8c
	if (ctx.cr6.lt) goto loc_82C89B8C;
	// lwz r11,364(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C89E78;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c89f0c
	if (!ctx.cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// b 0x82c89ec4
	goto loc_82C89EC4;
loc_82C89E8C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c89ad8
	if (ctx.cr6.eq) goto loc_82C89AD8;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c89ec4
	if (!ctx.cr6.eq) goto loc_82C89EC4;
loc_82C89EA8:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C89EBC:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
loc_82C89EC4:
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c89d90
	if (!ctx.cr6.eq) goto loc_82C89D90;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C89ED8:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c89a18
	ctx.lr = 0x82C89EEC;
	sub_82C89A18(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c89f0c
	if (ctx.cr6.eq) goto loc_82C89F0C;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c89ad8
	if (ctx.cr6.eq) goto loc_82C89AD8;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// beq cr6,0x82c89ea8
	if (ctx.cr6.eq) goto loc_82C89EA8;
loc_82C89F0C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r31.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C89F20"))) PPC_WEAK_FUNC(sub_82C89F20);
PPC_FUNC_IMPL(__imp__sub_82C89F20) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C89F28;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c89f50
	if (!ctx.cr6.eq) goto loc_82C89F50;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C89F50:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82c8a0f4
	if (ctx.cr6.gt) goto loc_82C8A0F4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-24708
	ctx.r12.s64 = ctx.r12.s64 + -24708;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8A07C;
	case 1:
		goto loc_82C8A07C;
	case 2:
		goto loc_82C8A0F4;
	case 3:
		goto loc_82C8A0F4;
	case 4:
		goto loc_82C89FA8;
	case 5:
		goto loc_82C8A048;
	case 6:
		goto loc_82C8A094;
	case 7:
		goto loc_82C8A0C4;
	case 8:
		goto loc_82C8A07C;
	case 9:
		goto loc_82C8A000;
	case 10:
		goto loc_82C8A034;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-24452(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24452);
	// lwz r22,-24452(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24452);
	// lwz r22,-24332(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24332);
	// lwz r22,-24332(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24332);
	// lwz r22,-24664(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24664);
	// lwz r22,-24504(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24504);
	// lwz r22,-24428(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24428);
	// lwz r22,-24380(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24380);
	// lwz r22,-24452(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24452);
	// lwz r22,-24576(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24576);
	// lwz r22,-24524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24524);
loc_82C89FA8:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c89fc0
	if (!ctx.cr6.eq) goto loc_82C89FC0;
loc_82C89FB4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C89FC0:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c8a0f8
	if (!ctx.cr6.eq) goto loc_82C8A0F8;
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c89fb4
	if (ctx.cr6.eq) goto loc_82C89FB4;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// beq cr6,0x82c89fec
	if (ctx.cr6.eq) goto loc_82C89FEC;
	// addi r31,r11,-1
	ctx.r31.s64 = ctx.r11.s64 + -1;
	// b 0x82c8a0f8
	goto loc_82C8A0F8;
loc_82C89FEC:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r3,40
	ctx.r3.s64 = 40;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A000:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c89fb4
	if (ctx.cr6.eq) goto loc_82C89FB4;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + ctx.r29.u64;
	// lbz r9,76(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmplwi cr6,r9,10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 10, ctx.xer);
	// bne cr6,0x82c8a024
	if (!ctx.cr6.eq) goto loc_82C8A024;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82C8A024:
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// li r3,7
	ctx.r3.s64 = 7;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A034:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A048:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8a060
	if (!ctx.cr6.lt) goto loc_82C8A060;
loc_82C8A054:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A060:
	// lwz r11,356(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A074;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a08c
	if (ctx.cr6.eq) goto loc_82C8A08C;
loc_82C8A07C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A08C:
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c8a0f8
	goto loc_82C8A0F8;
loc_82C8A094:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8a054
	if (ctx.cr6.lt) goto loc_82C8A054;
	// lwz r11,360(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A0B4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8a07c
	if (!ctx.cr6.eq) goto loc_82C8A07C;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c8a0f8
	goto loc_82C8A0F8;
loc_82C8A0C4:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8a054
	if (ctx.cr6.lt) goto loc_82C8A054;
	// lwz r11,364(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A0E4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8a07c
	if (!ctx.cr6.eq) goto loc_82C8A07C;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// b 0x82c8a0f8
	goto loc_82C8A0F8;
loc_82C8A0F4:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
loc_82C8A0F8:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8a1fc
	if (ctx.cr6.eq) goto loc_82C8A1FC;
	// subf r30,r31,r28
	ctx.r30.s64 = ctx.r28.s64 - ctx.r31.s64;
loc_82C8A104:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82c8a1ec
	if (ctx.cr6.gt) goto loc_82C8A1EC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-24272
	ctx.r12.s64 = ctx.r12.s64 + -24272;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8A1FC;
	case 1:
		goto loc_82C8A1FC;
	case 2:
		goto loc_82C8A1EC;
	case 3:
		goto loc_82C8A1EC;
	case 4:
		goto loc_82C8A1FC;
	case 5:
		goto loc_82C8A15C;
	case 6:
		goto loc_82C8A18C;
	case 7:
		goto loc_82C8A1BC;
	case 8:
		goto loc_82C8A1FC;
	case 9:
		goto loc_82C8A1FC;
	case 10:
		goto loc_82C8A1FC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-24068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
	// lwz r22,-24068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
	// lwz r22,-24084(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24084);
	// lwz r22,-24084(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24084);
	// lwz r22,-24068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
	// lwz r22,-24228(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24228);
	// lwz r22,-24180(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24180);
	// lwz r22,-24132(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24132);
	// lwz r22,-24068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
	// lwz r22,-24068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
	// lwz r22,-24068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -24068);
loc_82C8A15C:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c8a1fc
	if (ctx.cr6.lt) goto loc_82C8A1FC;
	// lwz r11,356(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A178;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8a1fc
	if (!ctx.cr6.eq) goto loc_82C8A1FC;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c8a1f4
	goto loc_82C8A1F4;
loc_82C8A18C:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c8a1fc
	if (ctx.cr6.lt) goto loc_82C8A1FC;
	// lwz r11,360(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A1A8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8a1fc
	if (!ctx.cr6.eq) goto loc_82C8A1FC;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c8a1f4
	goto loc_82C8A1F4;
loc_82C8A1BC:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c8a1fc
	if (ctx.cr6.lt) goto loc_82C8A1FC;
	// lwz r11,364(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A1D8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8a1fc
	if (!ctx.cr6.eq) goto loc_82C8A1FC;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// b 0x82c8a1f4
	goto loc_82C8A1F4;
loc_82C8A1EC:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
loc_82C8A1F4:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8a104
	if (!ctx.cr6.eq) goto loc_82C8A104;
loc_82C8A1FC:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r31,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8A210"))) PPC_WEAK_FUNC(sub_82C8A210);
PPC_FUNC_IMPL(__imp__sub_82C8A210) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C8A218;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8a240
	if (!ctx.cr6.eq) goto loc_82C8A240;
loc_82C8A234:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A240:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8a580
	if (ctx.cr6.gt) goto loc_82C8A580;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-23952
	ctx.r12.s64 = ctx.r12.s64 + -23952;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8A2DC;
	case 1:
		goto loc_82C8A318;
	case 2:
		goto loc_82C8A348;
	case 3:
		goto loc_82C8A580;
	case 4:
		goto loc_82C8A580;
	case 5:
		goto loc_82C8A580;
	case 6:
		goto loc_82C8A580;
	case 7:
		goto loc_82C8A580;
	case 8:
		goto loc_82C8A580;
	case 9:
		goto loc_82C8A580;
	case 10:
		goto loc_82C8A580;
	case 11:
		goto loc_82C8A580;
	case 12:
		goto loc_82C8A580;
	case 13:
		goto loc_82C8A580;
	case 14:
		goto loc_82C8A580;
	case 15:
		goto loc_82C8A580;
	case 16:
		goto loc_82C8A580;
	case 17:
		goto loc_82C8A2D4;
	case 18:
		goto loc_82C8A580;
	case 19:
		goto loc_82C8A2D4;
	case 20:
		goto loc_82C8A580;
	case 21:
		goto loc_82C8A580;
	case 22:
		goto loc_82C8A580;
	case 23:
		goto loc_82C8A580;
	case 24:
		goto loc_82C8A580;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-23844(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23844);
	// lwz r22,-23784(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23784);
	// lwz r22,-23736(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23736);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23852(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23852);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23852(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23852);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
loc_82C8A2D4:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82c8a374
	goto loc_82C8A374;
loc_82C8A2DC:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8a2f4
	if (!ctx.cr6.lt) goto loc_82C8A2F4;
loc_82C8A2E8:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A2F4:
	// lwz r11,344(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A308;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a580
	if (ctx.cr6.eq) goto loc_82C8A580;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c8a374
	goto loc_82C8A374;
loc_82C8A318:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8a2e8
	if (ctx.cr6.lt) goto loc_82C8A2E8;
	// lwz r11,348(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A338;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a580
	if (ctx.cr6.eq) goto loc_82C8A580;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c8a374
	goto loc_82C8A374;
loc_82C8A348:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8a2e8
	if (ctx.cr6.lt) goto loc_82C8A2E8;
	// lwz r11,352(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A368;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a580
	if (ctx.cr6.eq) goto loc_82C8A580;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
loc_82C8A374:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8a234
	if (ctx.cr6.eq) goto loc_82C8A234;
	// subf r30,r31,r28
	ctx.r30.s64 = ctx.r28.s64 - ctx.r31.s64;
loc_82C8A380:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8a580
	if (ctx.cr6.gt) goto loc_82C8A580;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-23632
	ctx.r12.s64 = ctx.r12.s64 + -23632;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8A414;
	case 1:
		goto loc_82C8A444;
	case 2:
		goto loc_82C8A474;
	case 3:
		goto loc_82C8A580;
	case 4:
		goto loc_82C8A4C0;
	case 5:
		goto loc_82C8A4C0;
	case 6:
		goto loc_82C8A56C;
	case 7:
		goto loc_82C8A580;
	case 8:
		goto loc_82C8A580;
	case 9:
		goto loc_82C8A580;
	case 10:
		goto loc_82C8A580;
	case 11:
		goto loc_82C8A580;
	case 12:
		goto loc_82C8A580;
	case 13:
		goto loc_82C8A580;
	case 14:
		goto loc_82C8A580;
	case 15:
		goto loc_82C8A580;
	case 16:
		goto loc_82C8A4C0;
	case 17:
		goto loc_82C8A4A4;
	case 18:
		goto loc_82C8A4A4;
	case 19:
		goto loc_82C8A4A4;
	case 20:
		goto loc_82C8A4A4;
	case 21:
		goto loc_82C8A4A4;
	case 22:
		goto loc_82C8A4A4;
	case 23:
		goto loc_82C8A580;
	case 24:
		goto loc_82C8A580;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-23532(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23532);
	// lwz r22,-23484(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23484);
	// lwz r22,-23436(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23436);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23360(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23360);
	// lwz r22,-23360(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23360);
	// lwz r22,-23188(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23188);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23360(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23360);
	// lwz r22,-23388(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23388(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23388(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23388(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23388(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23388(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23388);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
	// lwz r22,-23168(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23168);
loc_82C8A414:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c8a2e8
	if (ctx.cr6.lt) goto loc_82C8A2E8;
	// lwz r11,332(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A430;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a580
	if (ctx.cr6.eq) goto loc_82C8A580;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c8a4ac
	goto loc_82C8A4AC;
loc_82C8A444:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c8a2e8
	if (ctx.cr6.lt) goto loc_82C8A2E8;
	// lwz r11,336(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A460;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a580
	if (ctx.cr6.eq) goto loc_82C8A580;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c8a4ac
	goto loc_82C8A4AC;
loc_82C8A474:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c8a2e8
	if (ctx.cr6.lt) goto loc_82C8A2E8;
	// lwz r11,340(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A490;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a580
	if (ctx.cr6.eq) goto loc_82C8A580;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// b 0x82c8a4ac
	goto loc_82C8A4AC;
loc_82C8A4A4:
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
loc_82C8A4AC:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8a380
	if (!ctx.cr6.eq) goto loc_82C8A380;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A4C0:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8a234
	if (ctx.cr6.eq) goto loc_82C8A234;
loc_82C8A4CC:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + ctx.r29.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-9
	ctx.r10.s64 = ctx.r10.s64 + -9;
	// cmplwi cr6,r10,12
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 12, ctx.xer);
	// bgt cr6,0x82c8a55c
	if (ctx.cr6.gt) goto loc_82C8A55C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-23300
	ctx.r12.s64 = ctx.r12.s64 + -23300;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C8A530;
	case 1:
		goto loc_82C8A530;
	case 2:
		goto loc_82C8A548;
	case 3:
		goto loc_82C8A55C;
	case 4:
		goto loc_82C8A55C;
	case 5:
		goto loc_82C8A55C;
	case 6:
		goto loc_82C8A55C;
	case 7:
		goto loc_82C8A55C;
	case 8:
		goto loc_82C8A55C;
	case 9:
		goto loc_82C8A55C;
	case 10:
		goto loc_82C8A55C;
	case 11:
		goto loc_82C8A55C;
	case 12:
		goto loc_82C8A530;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-23248(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23248);
	// lwz r22,-23248(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23248);
	// lwz r22,-23224(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23224);
	// lwz r22,-23204(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23204(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23204);
	// lwz r22,-23248(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -23248);
loc_82C8A530:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8a4cc
	if (!ctx.cr6.eq) goto loc_82C8A4CC;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A548:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r3,5
	ctx.r3.s64 = 5;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A55C:
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A56C:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,5
	ctx.r3.s64 = 5;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A580:
	// stw r31,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8A590"))) PPC_WEAK_FUNC(sub_82C8A590);
PPC_FUNC_IMPL(__imp__sub_82C8A590) {
	PPC_FUNC_PROLOGUE();
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8a608
	if (ctx.cr6.eq) goto loc_82C8A608;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,120
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 120, ctx.xer);
	// bne cr6,0x82c8a61c
	if (!ctx.cr6.eq) goto loc_82C8A61C;
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8a608
	if (ctx.cr6.eq) goto loc_82C8A608;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmpwi cr6,r10,24
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 24, ctx.xer);
	// blt cr6,0x82c8a610
	if (ctx.cr6.lt) goto loc_82C8A610;
	// cmpwi cr6,r10,25
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 25, ctx.xer);
	// bgt cr6,0x82c8a610
	if (ctx.cr6.gt) goto loc_82C8A610;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8a608
	if (ctx.cr6.eq) goto loc_82C8A608;
loc_82C8A5D8:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmpwi cr6,r10,18
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 18, ctx.xer);
	// beq cr6,0x82c8a684
	if (ctx.cr6.eq) goto loc_82C8A684;
	// cmpwi cr6,r10,23
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 23, ctx.xer);
	// ble cr6,0x82c8a678
	if (!ctx.cr6.gt) goto loc_82C8A678;
	// cmpwi cr6,r10,25
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 25, ctx.xer);
	// bgt cr6,0x82c8a678
	if (ctx.cr6.gt) goto loc_82C8A678;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8a5d8
	if (!ctx.cr6.eq) goto loc_82C8A5D8;
loc_82C8A608:
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
loc_82C8A610:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// blr 
	return;
loc_82C8A61C:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r10,76(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmplwi cr6,r10,25
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 25, ctx.xer);
	// beq cr6,0x82c8a63c
	if (ctx.cr6.eq) goto loc_82C8A63C;
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8A63C:
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8a608
	if (ctx.cr6.eq) goto loc_82C8A608;
loc_82C8A648:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmpwi cr6,r10,18
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 18, ctx.xer);
	// beq cr6,0x82c8a684
	if (ctx.cr6.eq) goto loc_82C8A684;
	// cmpwi cr6,r10,25
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 25, ctx.xer);
	// bne cr6,0x82c8a678
	if (!ctx.cr6.eq) goto loc_82C8A678;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8a648
	if (!ctx.cr6.eq) goto loc_82C8A648;
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
loc_82C8A678:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8A684:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8A698"))) PPC_WEAK_FUNC(sub_82C8A698);
PPC_FUNC_IMPL(__imp__sub_82C8A698) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C8A6A0;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8a6c8
	if (!ctx.cr6.eq) goto loc_82C8A6C8;
loc_82C8A6BC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A6C8:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8a978
	if (ctx.cr6.gt) goto loc_82C8A978;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-22792
	ctx.r12.s64 = ctx.r12.s64 + -22792;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8A764;
	case 1:
		goto loc_82C8A7A0;
	case 2:
		goto loc_82C8A7D0;
	case 3:
		goto loc_82C8A978;
	case 4:
		goto loc_82C8A978;
	case 5:
		goto loc_82C8A978;
	case 6:
		goto loc_82C8A978;
	case 7:
		goto loc_82C8A978;
	case 8:
		goto loc_82C8A978;
	case 9:
		goto loc_82C8A978;
	case 10:
		goto loc_82C8A978;
	case 11:
		goto loc_82C8A978;
	case 12:
		goto loc_82C8A978;
	case 13:
		goto loc_82C8A978;
	case 14:
		goto loc_82C8A95C;
	case 15:
		goto loc_82C8A978;
	case 16:
		goto loc_82C8A978;
	case 17:
		goto loc_82C8A75C;
	case 18:
		goto loc_82C8A978;
	case 19:
		goto loc_82C8A75C;
	case 20:
		goto loc_82C8A978;
	case 21:
		goto loc_82C8A978;
	case 22:
		goto loc_82C8A978;
	case 23:
		goto loc_82C8A978;
	case 24:
		goto loc_82C8A978;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-22684(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22684);
	// lwz r22,-22624(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22624);
	// lwz r22,-22576(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22576);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22180(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22180);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22692(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22692);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22692(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22692);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
loc_82C8A75C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82c8a7fc
	goto loc_82C8A7FC;
loc_82C8A764:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8a77c
	if (!ctx.cr6.lt) goto loc_82C8A77C;
loc_82C8A770:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A77C:
	// lwz r11,344(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A790;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a978
	if (ctx.cr6.eq) goto loc_82C8A978;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c8a7fc
	goto loc_82C8A7FC;
loc_82C8A7A0:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8a770
	if (ctx.cr6.lt) goto loc_82C8A770;
	// lwz r11,348(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A7C0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a978
	if (ctx.cr6.eq) goto loc_82C8A978;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c8a7fc
	goto loc_82C8A7FC;
loc_82C8A7D0:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8a770
	if (ctx.cr6.lt) goto loc_82C8A770;
	// lwz r11,352(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A7F0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a978
	if (ctx.cr6.eq) goto loc_82C8A978;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
loc_82C8A7FC:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8a6bc
	if (ctx.cr6.eq) goto loc_82C8A6BC;
	// subf r30,r31,r28
	ctx.r30.s64 = ctx.r28.s64 - ctx.r31.s64;
loc_82C8A808:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8a978
	if (ctx.cr6.gt) goto loc_82C8A978;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-22472
	ctx.r12.s64 = ctx.r12.s64 + -22472;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8A8A8;
	case 1:
		goto loc_82C8A8D8;
	case 2:
		goto loc_82C8A908;
	case 3:
		goto loc_82C8A978;
	case 4:
		goto loc_82C8A978;
	case 5:
		goto loc_82C8A978;
	case 6:
		goto loc_82C8A978;
	case 7:
		goto loc_82C8A978;
	case 8:
		goto loc_82C8A978;
	case 9:
		goto loc_82C8A978;
	case 10:
		goto loc_82C8A978;
	case 11:
		goto loc_82C8A978;
	case 12:
		goto loc_82C8A978;
	case 13:
		goto loc_82C8A948;
	case 14:
		goto loc_82C8A978;
	case 15:
		goto loc_82C8A978;
	case 16:
		goto loc_82C8A978;
	case 17:
		goto loc_82C8A89C;
	case 18:
		goto loc_82C8A978;
	case 19:
		goto loc_82C8A89C;
	case 20:
		goto loc_82C8A89C;
	case 21:
		goto loc_82C8A89C;
	case 22:
		goto loc_82C8A89C;
	case 23:
		goto loc_82C8A978;
	case 24:
		goto loc_82C8A978;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-22360(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22360);
	// lwz r22,-22312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22312);
	// lwz r22,-22264(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22264);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22200(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22200);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22372(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22372);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22372(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22372);
	// lwz r22,-22372(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22372);
	// lwz r22,-22372(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22372);
	// lwz r22,-22372(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22372);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
	// lwz r22,-22152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -22152);
loc_82C8A89C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// b 0x82c8a934
	goto loc_82C8A934;
loc_82C8A8A8:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c8a770
	if (ctx.cr6.lt) goto loc_82C8A770;
	// lwz r11,332(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A8C4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a978
	if (ctx.cr6.eq) goto loc_82C8A978;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c8a934
	goto loc_82C8A934;
loc_82C8A8D8:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c8a770
	if (ctx.cr6.lt) goto loc_82C8A770;
	// lwz r11,336(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A8F4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a978
	if (ctx.cr6.eq) goto loc_82C8A978;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c8a934
	goto loc_82C8A934;
loc_82C8A908:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c8a770
	if (ctx.cr6.lt) goto loc_82C8A770;
	// lwz r11,340(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8A924;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8a978
	if (ctx.cr6.eq) goto loc_82C8A978;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
loc_82C8A934:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8a808
	if (!ctx.cr6.eq) goto loc_82C8A808;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A948:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,9
	ctx.r3.s64 = 9;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A95C:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8a590
	ctx.lr = 0x82C8A970;
	sub_82C8A590(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8A978:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8A988"))) PPC_WEAK_FUNC(sub_82C8A988);
PPC_FUNC_IMPL(__imp__sub_82C8A988) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C8A990;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// li r27,0
	ctx.r27.s64 = 0;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8aec8
	if (ctx.cr6.eq) goto loc_82C8AEC8;
loc_82C8A9B0:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8ab9c
	if (ctx.cr6.gt) goto loc_82C8AB9C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-22048
	ctx.r12.s64 = ctx.r12.s64 + -22048;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8AA44;
	case 1:
		goto loc_82C8AA74;
	case 2:
		goto loc_82C8AAA4;
	case 3:
		goto loc_82C8AB9C;
	case 4:
		goto loc_82C8AB64;
	case 5:
		goto loc_82C8AB64;
	case 6:
		goto loc_82C8AB9C;
	case 7:
		goto loc_82C8AB9C;
	case 8:
		goto loc_82C8AB9C;
	case 9:
		goto loc_82C8ABAC;
	case 10:
		goto loc_82C8AB9C;
	case 11:
		goto loc_82C8AB9C;
	case 12:
		goto loc_82C8AB9C;
	case 13:
		goto loc_82C8AB9C;
	case 14:
		goto loc_82C8AB9C;
	case 15:
		goto loc_82C8AB9C;
	case 16:
		goto loc_82C8AB64;
	case 17:
		goto loc_82C8AE2C;
	case 18:
		goto loc_82C8AAB8;
	case 19:
		goto loc_82C8AE2C;
	case 20:
		goto loc_82C8AE2C;
	case 21:
		goto loc_82C8AE2C;
	case 22:
		goto loc_82C8AE2C;
	case 23:
		goto loc_82C8AB9C;
	case 24:
		goto loc_82C8AB9C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-21948(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21948);
	// lwz r22,-21900(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21900);
	// lwz r22,-21852(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21852);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21660(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21660);
	// lwz r22,-21660(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21660);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21588(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21588);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21660(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21660);
	// lwz r22,-20948(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21832(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21832);
	// lwz r22,-20948(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-20948(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-20948(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-20948(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
loc_82C8AA44:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// blt cr6,0x82c8aed4
	if (ctx.cr6.lt) goto loc_82C8AED4;
	// lwz r11,332(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8AA64;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8ab9c
	if (ctx.cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c8aec0
	goto loc_82C8AEC0;
loc_82C8AA74:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8aed4
	if (ctx.cr6.lt) goto loc_82C8AED4;
	// lwz r11,336(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8AA94;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8ab9c
	if (ctx.cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c8aec0
	goto loc_82C8AEC0;
loc_82C8AAA4:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8aed4
	if (ctx.cr6.lt) goto loc_82C8AED4;
	// lwz r11,340(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 340);
	// b 0x82c8aea4
	goto loc_82C8AEA4;
loc_82C8AAB8:
	// cmpwi cr6,r27,0
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// bne cr6,0x82c8ab9c
	if (!ctx.cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// li r27,1
	ctx.r27.s64 = 1;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8aec8
	if (ctx.cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8ab9c
	if (ctx.cr6.gt) goto loc_82C8AB9C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-21760
	ctx.r12.s64 = ctx.r12.s64 + -21760;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8AE34;
	case 1:
		goto loc_82C8AE64;
	case 2:
		goto loc_82C8AE94;
	case 3:
		goto loc_82C8AB9C;
	case 4:
		goto loc_82C8AB9C;
	case 5:
		goto loc_82C8AB9C;
	case 6:
		goto loc_82C8AB9C;
	case 7:
		goto loc_82C8AB9C;
	case 8:
		goto loc_82C8AB9C;
	case 9:
		goto loc_82C8AB9C;
	case 10:
		goto loc_82C8AB9C;
	case 11:
		goto loc_82C8AB9C;
	case 12:
		goto loc_82C8AB9C;
	case 13:
		goto loc_82C8AB9C;
	case 14:
		goto loc_82C8AB9C;
	case 15:
		goto loc_82C8AB9C;
	case 16:
		goto loc_82C8AB9C;
	case 17:
		goto loc_82C8AE2C;
	case 18:
		goto loc_82C8AB9C;
	case 19:
		goto loc_82C8AE2C;
	case 20:
		goto loc_82C8AB9C;
	case 21:
		goto loc_82C8AB9C;
	case 22:
		goto loc_82C8AB9C;
	case 23:
		goto loc_82C8AB9C;
	case 24:
		goto loc_82C8AB9C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-20940(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20940);
	// lwz r22,-20892(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20892);
	// lwz r22,-20844(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20844);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-20948(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-20948(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
loc_82C8AB64:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8aec8
	if (ctx.cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmpwi cr6,r11,14
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 14, ctx.xer);
	// beq cr6,0x82c8abac
	if (ctx.cr6.eq) goto loc_82C8ABAC;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// blt cr6,0x82c8ab9c
	if (ctx.cr6.lt) goto loc_82C8AB9C;
	// cmpwi cr6,r11,10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 10, ctx.xer);
	// ble cr6,0x82c8ab64
	if (!ctx.cr6.gt) goto loc_82C8AB64;
	// cmpwi cr6,r11,21
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 21, ctx.xer);
	// beq cr6,0x82c8ab64
	if (ctx.cr6.eq) goto loc_82C8AB64;
loc_82C8AB9C:
	// stw r31,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8ABAC:
	// li r27,0
	ctx.r27.s64 = 0;
loc_82C8ABB0:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8aec8
	if (ctx.cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r29,76(r11)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmpwi cr6,r29,12
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 12, ctx.xer);
	// beq cr6,0x82c8ac00
	if (ctx.cr6.eq) goto loc_82C8AC00;
	// cmpwi cr6,r29,13
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 13, ctx.xer);
	// beq cr6,0x82c8ac00
	if (ctx.cr6.eq) goto loc_82C8AC00;
	// cmpwi cr6,r29,9
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 9, ctx.xer);
	// blt cr6,0x82c8ab9c
	if (ctx.cr6.lt) goto loc_82C8AB9C;
	// cmpwi cr6,r29,10
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 10, ctx.xer);
	// ble cr6,0x82c8abb0
	if (!ctx.cr6.gt) goto loc_82C8ABB0;
	// cmpwi cr6,r29,21
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 21, ctx.xer);
	// beq cr6,0x82c8abb0
	if (ctx.cr6.eq) goto loc_82C8ABB0;
	// stw r31,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8AC00:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
loc_82C8AC04:
	// stw r31,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r31.u32);
loc_82C8AC08:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8aec8
	if (ctx.cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmpw cr6,r11,r29
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r29.s32, ctx.xer);
	// beq cr6,0x82c8ad1c
	if (ctx.cr6.eq) goto loc_82C8AD1C;
	// cmplwi cr6,r11,8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8, ctx.xer);
	// bgt cr6,0x82c8ac00
	if (ctx.cr6.gt) goto loc_82C8AC00;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-21436
	ctx.r12.s64 = ctx.r12.s64 + -21436;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8AB9C;
	case 1:
		goto loc_82C8AB9C;
	case 2:
		goto loc_82C8AB9C;
	case 3:
		goto loc_82C8ACF8;
	case 4:
		goto loc_82C8AC00;
	case 5:
		goto loc_82C8AC68;
	case 6:
		goto loc_82C8AC98;
	case 7:
		goto loc_82C8ACC8;
	case 8:
		goto loc_82C8AB9C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21256);
	// lwz r22,-21504(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21504);
	// lwz r22,-21400(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21400);
	// lwz r22,-21352(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21352);
	// lwz r22,-21304(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21304);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
loc_82C8AC68:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// blt cr6,0x82c8aed4
	if (ctx.cr6.lt) goto loc_82C8AED4;
	// lwz r11,356(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8AC88;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8ab9c
	if (!ctx.cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c8ac04
	goto loc_82C8AC04;
loc_82C8AC98:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8aed4
	if (ctx.cr6.lt) goto loc_82C8AED4;
	// lwz r11,360(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8ACB8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8ab9c
	if (!ctx.cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c8ac04
	goto loc_82C8AC04;
loc_82C8ACC8:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8aed4
	if (ctx.cr6.lt) goto loc_82C8AED4;
	// lwz r11,364(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8ACE8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8ab9c
	if (!ctx.cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// b 0x82c8ac04
	goto loc_82C8AC04;
loc_82C8ACF8:
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8a698
	ctx.lr = 0x82C8AD0C;
	sub_82C8A698(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// ble cr6,0x82c8af30
	if (!ctx.cr6.gt) goto loc_82C8AF30;
	// lwz r31,172(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// b 0x82c8ac08
	goto loc_82C8AC08;
loc_82C8AD1C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8aec8
	if (ctx.cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-9
	ctx.r11.s64 = ctx.r11.s64 + -9;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bgt cr6,0x82c8ab9c
	if (ctx.cr6.gt) goto loc_82C8AB9C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-21160
	ctx.r12.s64 = ctx.r12.s64 + -21160;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8AD8C;
	case 1:
		goto loc_82C8AD8C;
	case 2:
		goto loc_82C8AF1C;
	case 3:
		goto loc_82C8AB9C;
	case 4:
		goto loc_82C8AB9C;
	case 5:
		goto loc_82C8AB9C;
	case 6:
		goto loc_82C8AB9C;
	case 7:
		goto loc_82C8AB9C;
	case 8:
		goto loc_82C8AEE0;
	case 9:
		goto loc_82C8AB9C;
	case 10:
		goto loc_82C8AB9C;
	case 11:
		goto loc_82C8AB9C;
	case 12:
		goto loc_82C8AD8C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-21108(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
	// lwz r22,-21108(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
	// lwz r22,-20708(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20708);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-20768(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20768);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21108(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
loc_82C8AD8C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8aec8
	if (ctx.cr6.eq) goto loc_82C8AEC8;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8ab9c
	if (ctx.cr6.gt) goto loc_82C8AB9C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-21048
	ctx.r12.s64 = ctx.r12.s64 + -21048;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8AE34;
	case 1:
		goto loc_82C8AE64;
	case 2:
		goto loc_82C8AE94;
	case 3:
		goto loc_82C8AB9C;
	case 4:
		goto loc_82C8AD8C;
	case 5:
		goto loc_82C8AD8C;
	case 6:
		goto loc_82C8AF1C;
	case 7:
		goto loc_82C8AB9C;
	case 8:
		goto loc_82C8AB9C;
	case 9:
		goto loc_82C8AB9C;
	case 10:
		goto loc_82C8AB9C;
	case 11:
		goto loc_82C8AB9C;
	case 12:
		goto loc_82C8AEE0;
	case 13:
		goto loc_82C8AB9C;
	case 14:
		goto loc_82C8AB9C;
	case 15:
		goto loc_82C8AB9C;
	case 16:
		goto loc_82C8AD8C;
	case 17:
		goto loc_82C8AE2C;
	case 18:
		goto loc_82C8AB9C;
	case 19:
		goto loc_82C8AE2C;
	case 20:
		goto loc_82C8AB9C;
	case 21:
		goto loc_82C8AB9C;
	case 22:
		goto loc_82C8AB9C;
	case 23:
		goto loc_82C8AB9C;
	case 24:
		goto loc_82C8AB9C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-20940(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20940);
	// lwz r22,-20892(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20892);
	// lwz r22,-20844(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20844);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21108(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
	// lwz r22,-21108(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
	// lwz r22,-20708(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20708);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-20768(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20768);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21108(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21108);
	// lwz r22,-20948(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-20948(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20948);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
	// lwz r22,-21604(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -21604);
loc_82C8AE2C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82c8aec0
	goto loc_82C8AEC0;
loc_82C8AE34:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// blt cr6,0x82c8aed4
	if (ctx.cr6.lt) goto loc_82C8AED4;
	// lwz r11,344(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 344);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8AE54;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8ab9c
	if (ctx.cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c8aec0
	goto loc_82C8AEC0;
loc_82C8AE64:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8aed4
	if (ctx.cr6.lt) goto loc_82C8AED4;
	// lwz r11,348(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 348);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8AE84;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8ab9c
	if (ctx.cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c8aec0
	goto loc_82C8AEC0;
loc_82C8AE94:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8aed4
	if (ctx.cr6.lt) goto loc_82C8AED4;
	// lwz r11,352(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 352);
loc_82C8AEA4:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8AEB4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8ab9c
	if (ctx.cr6.eq) goto loc_82C8AB9C;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
loc_82C8AEC0:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8a9b0
	if (!ctx.cr6.eq) goto loc_82C8A9B0;
loc_82C8AEC8:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82C8AECC:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8AED4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8AEE0:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8aec8
	if (ctx.cr6.eq) goto loc_82C8AEC8;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// beq cr6,0x82c8af08
	if (ctx.cr6.eq) goto loc_82C8AF08;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8AF08:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r3,3
	ctx.r3.s64 = 3;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8AF1C:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8AF30:
	// bne cr6,0x82c8aecc
	if (!ctx.cr6.eq) goto loc_82C8AECC;
	// lwz r11,172(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8AF48"))) PPC_WEAK_FUNC(sub_82C8AF48);
PPC_FUNC_IMPL(__imp__sub_82C8AF48) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C8AF50;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8af78
	if (!ctx.cr6.eq) goto loc_82C8AF78;
loc_82C8AF6C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8AF78:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8b5e4
	if (ctx.cr6.gt) goto loc_82C8B5E4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-20568
	ctx.r12.s64 = ctx.r12.s64 + -20568;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8B014;
	case 1:
		goto loc_82C8B050;
	case 2:
		goto loc_82C8B080;
	case 3:
		goto loc_82C8B5E4;
	case 4:
		goto loc_82C8B5E4;
	case 5:
		goto loc_82C8B5E4;
	case 6:
		goto loc_82C8B5E4;
	case 7:
		goto loc_82C8B5E4;
	case 8:
		goto loc_82C8B5E4;
	case 9:
		goto loc_82C8B5E4;
	case 10:
		goto loc_82C8B5AC;
	case 11:
		goto loc_82C8B50C;
	case 12:
		goto loc_82C8B5C8;
	case 13:
		goto loc_82C8B5E4;
	case 14:
		goto loc_82C8B5E4;
	case 15:
		goto loc_82C8B5E4;
	case 16:
		goto loc_82C8B5E4;
	case 17:
		goto loc_82C8B00C;
	case 18:
		goto loc_82C8B5E4;
	case 19:
		goto loc_82C8B00C;
	case 20:
		goto loc_82C8B5E4;
	case 21:
		goto loc_82C8B5E4;
	case 22:
		goto loc_82C8B5E4;
	case 23:
		goto loc_82C8B5E4;
	case 24:
		goto loc_82C8B5E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-20460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20460);
	// lwz r22,-20400(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20400);
	// lwz r22,-20352(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20352);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19028(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19028);
	// lwz r22,-19188(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19188);
	// lwz r22,-19000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19000);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-20468(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20468);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-20468(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20468);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
loc_82C8B00C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82c8b0ac
	goto loc_82C8B0AC;
loc_82C8B014:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8b02c
	if (!ctx.cr6.lt) goto loc_82C8B02C;
loc_82C8B020:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B02C:
	// lwz r11,344(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B040;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b5e4
	if (ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c8b0ac
	goto loc_82C8B0AC;
loc_82C8B050:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8b020
	if (ctx.cr6.lt) goto loc_82C8B020;
	// lwz r11,348(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B070;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b5e4
	if (ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c8b0ac
	goto loc_82C8B0AC;
loc_82C8B080:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8b020
	if (ctx.cr6.lt) goto loc_82C8B020;
	// lwz r11,352(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B0A0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b5e4
	if (ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
loc_82C8B0AC:
	// li r27,0
	ctx.r27.s64 = 0;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8af6c
	if (ctx.cr6.eq) goto loc_82C8AF6C;
	// subf r30,r31,r28
	ctx.r30.s64 = ctx.r28.s64 - ctx.r31.s64;
loc_82C8B0BC:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8b5e4
	if (ctx.cr6.gt) goto loc_82C8B5E4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-20244
	ctx.r12.s64 = ctx.r12.s64 + -20244;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8B150;
	case 1:
		goto loc_82C8B180;
	case 2:
		goto loc_82C8B1B0;
	case 3:
		goto loc_82C8B5E4;
	case 4:
		goto loc_82C8B31C;
	case 5:
		goto loc_82C8B31C;
	case 6:
		goto loc_82C8B4BC;
	case 7:
		goto loc_82C8B5E4;
	case 8:
		goto loc_82C8B5E4;
	case 9:
		goto loc_82C8B5E4;
	case 10:
		goto loc_82C8B5E4;
	case 11:
		goto loc_82C8B5E4;
	case 12:
		goto loc_82C8B4D0;
	case 13:
		goto loc_82C8B5E4;
	case 14:
		goto loc_82C8B5E4;
	case 15:
		goto loc_82C8B5E4;
	case 16:
		goto loc_82C8B31C;
	case 17:
		goto loc_82C8B270;
	case 18:
		goto loc_82C8B1C0;
	case 19:
		goto loc_82C8B270;
	case 20:
		goto loc_82C8B270;
	case 21:
		goto loc_82C8B270;
	case 22:
		goto loc_82C8B270;
	case 23:
		goto loc_82C8B5E4;
	case 24:
		goto loc_82C8B5E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-20144(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20144);
	// lwz r22,-20096(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20096);
	// lwz r22,-20048(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20048);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19684(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19684);
	// lwz r22,-19684(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19684);
	// lwz r22,-19268(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19268);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19248(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19248);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19684(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19684);
	// lwz r22,-19856(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-20032(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -20032);
	// lwz r22,-19856(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-19856(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-19856(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-19856(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
loc_82C8B150:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c8b020
	if (ctx.cr6.lt) goto loc_82C8B020;
	// lwz r11,332(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B16C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b5e4
	if (ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c8b308
	goto loc_82C8B308;
loc_82C8B180:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c8b020
	if (ctx.cr6.lt) goto loc_82C8B020;
	// lwz r11,336(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B19C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b5e4
	if (ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c8b308
	goto loc_82C8B308;
loc_82C8B1B0:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c8b020
	if (ctx.cr6.lt) goto loc_82C8B020;
	// lwz r11,340(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 340);
	// b 0x82c8b2e8
	goto loc_82C8B2E8;
loc_82C8B1C0:
	// cmpwi cr6,r27,0
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// bne cr6,0x82c8b5e4
	if (!ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// li r27,1
	ctx.r27.s64 = 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8af6c
	if (ctx.cr6.eq) goto loc_82C8AF6C;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8b5e4
	if (ctx.cr6.gt) goto loc_82C8B5E4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-19956
	ctx.r12.s64 = ctx.r12.s64 + -19956;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8B27C;
	case 1:
		goto loc_82C8B2AC;
	case 2:
		goto loc_82C8B2DC;
	case 3:
		goto loc_82C8B5E4;
	case 4:
		goto loc_82C8B5E4;
	case 5:
		goto loc_82C8B5E4;
	case 6:
		goto loc_82C8B5E4;
	case 7:
		goto loc_82C8B5E4;
	case 8:
		goto loc_82C8B5E4;
	case 9:
		goto loc_82C8B5E4;
	case 10:
		goto loc_82C8B5E4;
	case 11:
		goto loc_82C8B5E4;
	case 12:
		goto loc_82C8B5E4;
	case 13:
		goto loc_82C8B5E4;
	case 14:
		goto loc_82C8B5E4;
	case 15:
		goto loc_82C8B5E4;
	case 16:
		goto loc_82C8B5E4;
	case 17:
		goto loc_82C8B270;
	case 18:
		goto loc_82C8B5E4;
	case 19:
		goto loc_82C8B270;
	case 20:
		goto loc_82C8B5E4;
	case 21:
		goto loc_82C8B5E4;
	case 22:
		goto loc_82C8B5E4;
	case 23:
		goto loc_82C8B5E4;
	case 24:
		goto loc_82C8B5E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-19844(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19844);
	// lwz r22,-19796(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19796);
	// lwz r22,-19748(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19748);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19856(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19856(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19856);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
loc_82C8B270:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// b 0x82c8b308
	goto loc_82C8B308;
loc_82C8B27C:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c8b020
	if (ctx.cr6.lt) goto loc_82C8B020;
	// lwz r11,344(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B298;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b5e4
	if (ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c8b308
	goto loc_82C8B308;
loc_82C8B2AC:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c8b020
	if (ctx.cr6.lt) goto loc_82C8B020;
	// lwz r11,348(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B2C8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b5e4
	if (ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c8b308
	goto loc_82C8B308;
loc_82C8B2DC:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c8b020
	if (ctx.cr6.lt) goto loc_82C8B020;
	// lwz r11,352(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 352);
loc_82C8B2E8:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B2F8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b5e4
	if (ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
loc_82C8B308:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8b0bc
	if (!ctx.cr6.eq) goto loc_82C8B0BC;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B31C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8af6c
	if (ctx.cr6.eq) goto loc_82C8AF6C;
loc_82C8B328:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8b5e4
	if (ctx.cr6.gt) goto loc_82C8B5E4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-19624
	ctx.r12.s64 = ctx.r12.s64 + -19624;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8B3F0;
	case 1:
		goto loc_82C8B434;
	case 2:
		goto loc_82C8B478;
	case 3:
		goto loc_82C8B5E4;
	case 4:
		goto loc_82C8B3BC;
	case 5:
		goto loc_82C8B3BC;
	case 6:
		goto loc_82C8B4BC;
	case 7:
		goto loc_82C8B5E4;
	case 8:
		goto loc_82C8B5E4;
	case 9:
		goto loc_82C8B5E4;
	case 10:
		goto loc_82C8B5E4;
	case 11:
		goto loc_82C8B5E4;
	case 12:
		goto loc_82C8B4D0;
	case 13:
		goto loc_82C8B5E4;
	case 14:
		goto loc_82C8B5E4;
	case 15:
		goto loc_82C8B5E4;
	case 16:
		goto loc_82C8B3BC;
	case 17:
		goto loc_82C8B3D4;
	case 18:
		goto loc_82C8B5E4;
	case 19:
		goto loc_82C8B3D4;
	case 20:
		goto loc_82C8B5E4;
	case 21:
		goto loc_82C8B5E4;
	case 22:
		goto loc_82C8B5E4;
	case 23:
		goto loc_82C8B5E4;
	case 24:
		goto loc_82C8B5E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-19472(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19472);
	// lwz r22,-19404(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19404);
	// lwz r22,-19336(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19336);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19524);
	// lwz r22,-19524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19524);
	// lwz r22,-19268(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19268);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19248(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19248);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19524);
	// lwz r22,-19500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19500);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-19500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -19500);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
	// lwz r22,-18972(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18972);
loc_82C8B3BC:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8b328
	if (!ctx.cr6.eq) goto loc_82C8B328;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B3D4:
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8a988
	ctx.lr = 0x82C8B3E8;
	sub_82C8A988(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B3F0:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// blt cr6,0x82c8b020
	if (ctx.cr6.lt) goto loc_82C8B020;
	// lwz r11,344(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B410;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b5e4
	if (ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r4,r31,2
	ctx.r4.s64 = ctx.r31.s64 + 2;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8a988
	ctx.lr = 0x82C8B42C;
	sub_82C8A988(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B434:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8b020
	if (ctx.cr6.lt) goto loc_82C8B020;
	// lwz r11,348(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B454;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b5e4
	if (ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r4,r31,3
	ctx.r4.s64 = ctx.r31.s64 + 3;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8a988
	ctx.lr = 0x82C8B470;
	sub_82C8A988(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B478:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8b020
	if (ctx.cr6.lt) goto loc_82C8B020;
	// lwz r11,352(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B498;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b5e4
	if (ctx.cr6.eq) goto loc_82C8B5E4;
	// addi r4,r31,4
	ctx.r4.s64 = ctx.r31.s64 + 4;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8a988
	ctx.lr = 0x82C8B4B4;
	sub_82C8A988(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B4BC:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B4D0:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8af6c
	if (ctx.cr6.eq) goto loc_82C8AF6C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// beq cr6,0x82c8b4f8
	if (ctx.cr6.eq) goto loc_82C8B4F8;
loc_82C8B4E8:
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B4F8:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r3,4
	ctx.r3.s64 = 4;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B50C:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8af6c
	if (ctx.cr6.eq) goto loc_82C8AF6C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + ctx.r29.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmpwi cr6,r10,20
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 20, ctx.xer);
	// beq cr6,0x82c8b550
	if (ctx.cr6.eq) goto loc_82C8B550;
	// cmpwi cr6,r10,27
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 27, ctx.xer);
	// bne cr6,0x82c8b4e8
	if (!ctx.cr6.eq) goto loc_82C8B4E8;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r4,r11,1
	ctx.r4.s64 = ctx.r11.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c89638
	ctx.lr = 0x82C8B548;
	sub_82C89638(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B550:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// subf r10,r11,r28
	ctx.r10.s64 = ctx.r28.s64 - ctx.r11.s64;
	// cmpwi cr6,r10,6
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 6, ctx.xer);
	// blt cr6,0x82c8af6c
	if (ctx.cr6.lt) goto loc_82C8AF6C;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r9,-2352
	ctx.r9.s64 = ctx.r9.s64 + -2352;
loc_82C8B56C:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbzx r7,r10,r9
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r9.u32);
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// bne cr6,0x82c8b59c
	if (!ctx.cr6.eq) goto loc_82C8B59C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpwi cr6,r10,6
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 6, ctx.xer);
	// blt cr6,0x82c8b56c
	if (ctx.cr6.lt) goto loc_82C8B56C;
	// li r3,8
	ctx.r3.s64 = 8;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B59C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B5AC:
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c89ab0
	ctx.lr = 0x82C8B5C0;
	sub_82C89AB0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B5C8:
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8a210
	ctx.lr = 0x82C8B5DC;
	sub_82C8A210(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8B5E4:
	// stw r31,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8B5F8"))) PPC_WEAK_FUNC(sub_82C8B5F8);
PPC_FUNC_IMPL(__imp__sub_82C8B5F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bdc
	ctx.lr = 0x82C8B600;
	__savegprlr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r25,r6
	ctx.r25.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r26
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r26.u32, ctx.xer);
	// bne cr6,0x82c8b628
	if (!ctx.cr6.eq) goto loc_82C8B628;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
loc_82C8B628:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r27
	ctx.r11.u64 = ctx.r11.u64 + ctx.r27.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82c8b80c
	if (ctx.cr6.gt) goto loc_82C8B80C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-18860
	ctx.r12.s64 = ctx.r12.s64 + -18860;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8B794;
	case 1:
		goto loc_82C8B794;
	case 2:
		goto loc_82C8B680;
	case 3:
		goto loc_82C8B69C;
	case 4:
		goto loc_82C8B70C;
	case 5:
		goto loc_82C8B760;
	case 6:
		goto loc_82C8B7AC;
	case 7:
		goto loc_82C8B7DC;
	case 8:
		goto loc_82C8B794;
	case 9:
		goto loc_82C8B6B8;
	case 10:
		goto loc_82C8B6F8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-18540(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18540);
	// lwz r22,-18540(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18540);
	// lwz r22,-18816(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18816);
	// lwz r22,-18788(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18788);
	// lwz r22,-18676(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18676);
	// lwz r22,-18592(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18592);
	// lwz r22,-18516(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18516);
	// lwz r22,-18468(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18468);
	// lwz r22,-18540(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18540);
	// lwz r22,-18760(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18760);
	// lwz r22,-18696(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18696);
loc_82C8B680:
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82c8af48
	ctx.lr = 0x82C8B694;
	sub_82C8AF48(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
loc_82C8B69C:
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82c8a698
	ctx.lr = 0x82C8B6B0;
	sub_82C8A698(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
loc_82C8B6B8:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// bne cr6,0x82c8b6d0
	if (!ctx.cr6.eq) goto loc_82C8B6D0;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
loc_82C8B6D0:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r27
	ctx.r10.u64 = ctx.r10.u64 + ctx.r27.u64;
	// lbz r9,76(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmplwi cr6,r9,10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 10, ctx.xer);
	// bne cr6,0x82c8b6e8
	if (!ctx.cr6.eq) goto loc_82C8B6E8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82C8B6E8:
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
	// li r3,7
	ctx.r3.s64 = 7;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
loc_82C8B6F8:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
loc_82C8B70C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r26
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r26.u32, ctx.xer);
	// bne cr6,0x82c8b724
	if (!ctx.cr6.eq) goto loc_82C8B724;
loc_82C8B718:
	// li r3,-5
	ctx.r3.s64 = -5;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
loc_82C8B724:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c8b810
	if (!ctx.cr6.eq) goto loc_82C8B810;
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// beq cr6,0x82c8b718
	if (ctx.cr6.eq) goto loc_82C8B718;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// beq cr6,0x82c8b750
	if (ctx.cr6.eq) goto loc_82C8B750;
	// addi r31,r11,-1
	ctx.r31.s64 = ctx.r11.s64 + -1;
	// b 0x82c8b810
	goto loc_82C8B810;
loc_82C8B750:
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
loc_82C8B760:
	// subf r11,r31,r26
	ctx.r11.s64 = ctx.r26.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8b778
	if (!ctx.cr6.lt) goto loc_82C8B778;
loc_82C8B76C:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
loc_82C8B778:
	// lwz r11,356(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B78C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8b7a4
	if (ctx.cr6.eq) goto loc_82C8B7A4;
loc_82C8B794:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r31.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
loc_82C8B7A4:
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c8b810
	goto loc_82C8B810;
loc_82C8B7AC:
	// subf r11,r31,r26
	ctx.r11.s64 = ctx.r26.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8b76c
	if (ctx.cr6.lt) goto loc_82C8B76C;
	// lwz r11,360(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B7CC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8b794
	if (!ctx.cr6.eq) goto loc_82C8B794;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c8b810
	goto loc_82C8B810;
loc_82C8B7DC:
	// subf r11,r31,r26
	ctx.r11.s64 = ctx.r26.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8b76c
	if (ctx.cr6.lt) goto loc_82C8B76C;
	// lwz r11,364(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B7FC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8b794
	if (!ctx.cr6.eq) goto loc_82C8B794;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// b 0x82c8b810
	goto loc_82C8B810;
loc_82C8B80C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
loc_82C8B810:
	// cmplw cr6,r31,r26
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r26.u32, ctx.xer);
	// beq cr6,0x82c8b964
	if (ctx.cr6.eq) goto loc_82C8B964;
	// addi r28,r31,2
	ctx.r28.s64 = ctx.r31.s64 + 2;
	// addi r29,r31,1
	ctx.r29.s64 = ctx.r31.s64 + 1;
	// subf r30,r31,r26
	ctx.r30.s64 = ctx.r26.s64 - ctx.r31.s64;
loc_82C8B824:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r27
	ctx.r11.u64 = ctx.r11.u64 + ctx.r27.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bgt cr6,0x82c8b94c
	if (ctx.cr6.gt) goto loc_82C8B94C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-18352
	ctx.r12.s64 = ctx.r12.s64 + -18352;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8B964;
	case 1:
		goto loc_82C8B964;
	case 2:
		goto loc_82C8B964;
	case 3:
		goto loc_82C8B964;
	case 4:
		goto loc_82C8B924;
	case 5:
		goto loc_82C8B87C;
	case 6:
		goto loc_82C8B8B4;
	case 7:
		goto loc_82C8B8EC;
	case 8:
		goto loc_82C8B964;
	case 9:
		goto loc_82C8B964;
	case 10:
		goto loc_82C8B964;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-18076(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18076(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18076(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18076(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18140(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18140);
	// lwz r22,-18308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18308);
	// lwz r22,-18252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18252);
	// lwz r22,-18196(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18196);
	// lwz r22,-18076(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18076(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
	// lwz r22,-18076(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18076);
loc_82C8B87C:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c8b964
	if (ctx.cr6.lt) goto loc_82C8B964;
	// lwz r11,356(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B898;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8b964
	if (!ctx.cr6.eq) goto loc_82C8B964;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// addi r29,r29,2
	ctx.r29.s64 = ctx.r29.s64 + 2;
	// addi r28,r28,2
	ctx.r28.s64 = ctx.r28.s64 + 2;
	// b 0x82c8b95c
	goto loc_82C8B95C;
loc_82C8B8B4:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c8b964
	if (ctx.cr6.lt) goto loc_82C8B964;
	// lwz r11,360(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B8D0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8b964
	if (!ctx.cr6.eq) goto loc_82C8B964;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// addi r29,r29,3
	ctx.r29.s64 = ctx.r29.s64 + 3;
	// addi r28,r28,3
	ctx.r28.s64 = ctx.r28.s64 + 3;
	// b 0x82c8b95c
	goto loc_82C8B95C;
loc_82C8B8EC:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c8b964
	if (ctx.cr6.lt) goto loc_82C8B964;
	// lwz r11,364(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8B908;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8b964
	if (!ctx.cr6.eq) goto loc_82C8B964;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// addi r28,r28,4
	ctx.r28.s64 = ctx.r28.s64 + 4;
	// b 0x82c8b95c
	goto loc_82C8B95C;
loc_82C8B924:
	// cmplw cr6,r29,r26
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r26.u32, ctx.xer);
	// beq cr6,0x82c8b964
	if (ctx.cr6.eq) goto loc_82C8B964;
	// lbz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c8b94c
	if (!ctx.cr6.eq) goto loc_82C8B94C;
	// cmplw cr6,r28,r26
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r26.u32, ctx.xer);
	// beq cr6,0x82c8b964
	if (ctx.cr6.eq) goto loc_82C8B964;
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// beq cr6,0x82c8b974
	if (ctx.cr6.eq) goto loc_82C8B974;
loc_82C8B94C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
loc_82C8B95C:
	// cmplw cr6,r31,r26
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r26.u32, ctx.xer);
	// bne cr6,0x82c8b824
	if (!ctx.cr6.eq) goto loc_82C8B824;
loc_82C8B964:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r31,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r31.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
loc_82C8B974:
	// addi r11,r31,2
	ctx.r11.s64 = ctx.r31.s64 + 2;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8B988"))) PPC_WEAK_FUNC(sub_82C8B988);
PPC_FUNC_IMPL(__imp__sub_82C8B988) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C8B990;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8b9b8
	if (!ctx.cr6.eq) goto loc_82C8B9B8;
	// li r3,-22
	ctx.r3.s64 = -22;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8B9B8:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,25
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 25, ctx.xer);
	// bgt cr6,0x82c8bc60
	if (ctx.cr6.gt) goto loc_82C8BC60;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-17944
	ctx.r12.s64 = ctx.r12.s64 + -17944;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8BA58;
	case 1:
		goto loc_82C8BA94;
	case 2:
		goto loc_82C8BAC4;
	case 3:
		goto loc_82C8BC60;
	case 4:
		goto loc_82C8BC50;
	case 5:
		goto loc_82C8BC50;
	case 6:
		goto loc_82C8BC60;
	case 7:
		goto loc_82C8BC60;
	case 8:
		goto loc_82C8BC60;
	case 9:
		goto loc_82C8BC60;
	case 10:
		goto loc_82C8BC60;
	case 11:
		goto loc_82C8BC60;
	case 12:
		goto loc_82C8BC60;
	case 13:
		goto loc_82C8BC60;
	case 14:
		goto loc_82C8BC60;
	case 15:
		goto loc_82C8BC60;
	case 16:
		goto loc_82C8BC50;
	case 17:
		goto loc_82C8BA50;
	case 18:
		goto loc_82C8BC60;
	case 19:
		goto loc_82C8BA50;
	case 20:
		goto loc_82C8BC60;
	case 21:
		goto loc_82C8BC60;
	case 22:
		goto loc_82C8BC60;
	case 23:
		goto loc_82C8BC60;
	case 24:
		goto loc_82C8BC60;
	case 25:
		goto loc_82C8BC50;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-17832(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17832);
	// lwz r22,-17772(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17772);
	// lwz r22,-17724(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17724);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17328);
	// lwz r22,-17328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17328);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17328);
	// lwz r22,-17840(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17840);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17840(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17840);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17328);
loc_82C8BA50:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82c8baf0
	goto loc_82C8BAF0;
loc_82C8BA58:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8ba70
	if (!ctx.cr6.lt) goto loc_82C8BA70;
loc_82C8BA64:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8BA70:
	// lwz r11,344(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BA84;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bc60
	if (ctx.cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c8baf0
	goto loc_82C8BAF0;
loc_82C8BA94:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8ba64
	if (ctx.cr6.lt) goto loc_82C8BA64;
	// lwz r11,348(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BAB4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bc60
	if (ctx.cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c8baf0
	goto loc_82C8BAF0;
loc_82C8BAC4:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8ba64
	if (ctx.cr6.lt) goto loc_82C8BA64;
	// lwz r11,352(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BAE4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bc60
	if (ctx.cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
loc_82C8BAF0:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8bc30
	if (ctx.cr6.eq) goto loc_82C8BC30;
	// subf r30,r31,r28
	ctx.r30.s64 = ctx.r28.s64 - ctx.r31.s64;
loc_82C8BAFC:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8bc60
	if (ctx.cr6.gt) goto loc_82C8BC60;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-17620
	ctx.r12.s64 = ctx.r12.s64 + -17620;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8BB9C;
	case 1:
		goto loc_82C8BBCC;
	case 2:
		goto loc_82C8BBFC;
	case 3:
		goto loc_82C8BC60;
	case 4:
		goto loc_82C8BC60;
	case 5:
		goto loc_82C8BC60;
	case 6:
		goto loc_82C8BC60;
	case 7:
		goto loc_82C8BC60;
	case 8:
		goto loc_82C8BC60;
	case 9:
		goto loc_82C8BC60;
	case 10:
		goto loc_82C8BC60;
	case 11:
		goto loc_82C8BC60;
	case 12:
		goto loc_82C8BC60;
	case 13:
		goto loc_82C8BC3C;
	case 14:
		goto loc_82C8BC60;
	case 15:
		goto loc_82C8BC60;
	case 16:
		goto loc_82C8BC60;
	case 17:
		goto loc_82C8BB90;
	case 18:
		goto loc_82C8BC60;
	case 19:
		goto loc_82C8BB90;
	case 20:
		goto loc_82C8BB90;
	case 21:
		goto loc_82C8BB90;
	case 22:
		goto loc_82C8BB90;
	case 23:
		goto loc_82C8BC60;
	case 24:
		goto loc_82C8BC60;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-17508(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17508);
	// lwz r22,-17460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17460);
	// lwz r22,-17412(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17412);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17348(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17348);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17520(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17520);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17520(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17520);
	// lwz r22,-17520(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17520);
	// lwz r22,-17520(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17520);
	// lwz r22,-17520(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17520);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
	// lwz r22,-17312(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17312);
loc_82C8BB90:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// b 0x82c8bc28
	goto loc_82C8BC28;
loc_82C8BB9C:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c8ba64
	if (ctx.cr6.lt) goto loc_82C8BA64;
	// lwz r11,332(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BBB8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bc60
	if (ctx.cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c8bc28
	goto loc_82C8BC28;
loc_82C8BBCC:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c8ba64
	if (ctx.cr6.lt) goto loc_82C8BA64;
	// lwz r11,336(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BBE8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bc60
	if (ctx.cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c8bc28
	goto loc_82C8BC28;
loc_82C8BBFC:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c8ba64
	if (ctx.cr6.lt) goto loc_82C8BA64;
	// lwz r11,340(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BC18;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bc60
	if (ctx.cr6.eq) goto loc_82C8BC60;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
loc_82C8BC28:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8bafc
	if (!ctx.cr6.eq) goto loc_82C8BAFC;
loc_82C8BC30:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8BC3C:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,28
	ctx.r3.s64 = 28;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8BC50:
	// li r3,22
	ctx.r3.s64 = 22;
	// stw r31,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8BC60:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8BC70"))) PPC_WEAK_FUNC(sub_82C8BC70);
PPC_FUNC_IMPL(__imp__sub_82C8BC70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C8BC78;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8bca0
	if (!ctx.cr6.eq) goto loc_82C8BCA0;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8BCA0:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8bf4c
	if (ctx.cr6.gt) goto loc_82C8BF4C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-17200
	ctx.r12.s64 = ctx.r12.s64 + -17200;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8BD3C;
	case 1:
		goto loc_82C8BD78;
	case 2:
		goto loc_82C8BDA8;
	case 3:
		goto loc_82C8BF4C;
	case 4:
		goto loc_82C8BF4C;
	case 5:
		goto loc_82C8BF4C;
	case 6:
		goto loc_82C8BF4C;
	case 7:
		goto loc_82C8BF4C;
	case 8:
		goto loc_82C8BF4C;
	case 9:
		goto loc_82C8BF4C;
	case 10:
		goto loc_82C8BF4C;
	case 11:
		goto loc_82C8BF4C;
	case 12:
		goto loc_82C8BF4C;
	case 13:
		goto loc_82C8BF4C;
	case 14:
		goto loc_82C8BF4C;
	case 15:
		goto loc_82C8BF4C;
	case 16:
		goto loc_82C8BF4C;
	case 17:
		goto loc_82C8BD34;
	case 18:
		goto loc_82C8BF4C;
	case 19:
		goto loc_82C8BD34;
	case 20:
		goto loc_82C8BF4C;
	case 21:
		goto loc_82C8BF4C;
	case 22:
		goto loc_82C8BF4C;
	case 23:
		goto loc_82C8BF4C;
	case 24:
		goto loc_82C8BF4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-17092(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17092);
	// lwz r22,-17032(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17032);
	// lwz r22,-16984(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16984);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-17100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17100);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-17100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -17100);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
loc_82C8BD34:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82c8bdd4
	goto loc_82C8BDD4;
loc_82C8BD3C:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8bd54
	if (!ctx.cr6.lt) goto loc_82C8BD54;
loc_82C8BD48:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8BD54:
	// lwz r11,344(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BD68;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bf4c
	if (ctx.cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c8bdd4
	goto loc_82C8BDD4;
loc_82C8BD78:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8bd48
	if (ctx.cr6.lt) goto loc_82C8BD48;
	// lwz r11,348(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BD98;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bf4c
	if (ctx.cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c8bdd4
	goto loc_82C8BDD4;
loc_82C8BDA8:
	// subf r11,r31,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8bd48
	if (ctx.cr6.lt) goto loc_82C8BD48;
	// lwz r11,352(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BDC8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bf4c
	if (ctx.cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
loc_82C8BDD4:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8bf30
	if (ctx.cr6.eq) goto loc_82C8BF30;
	// subf r30,r31,r28
	ctx.r30.s64 = ctx.r28.s64 - ctx.r31.s64;
loc_82C8BDE0:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 31, ctx.xer);
	// bgt cr6,0x82c8bf4c
	if (ctx.cr6.gt) goto loc_82C8BF4C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-16880
	ctx.r12.s64 = ctx.r12.s64 + -16880;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8BE9C;
	case 1:
		goto loc_82C8BECC;
	case 2:
		goto loc_82C8BEFC;
	case 3:
		goto loc_82C8BF4C;
	case 4:
		goto loc_82C8BF3C;
	case 5:
		goto loc_82C8BF3C;
	case 6:
		goto loc_82C8BF3C;
	case 7:
		goto loc_82C8BF4C;
	case 8:
		goto loc_82C8BF4C;
	case 9:
		goto loc_82C8BF4C;
	case 10:
		goto loc_82C8BF4C;
	case 11:
		goto loc_82C8BF4C;
	case 12:
		goto loc_82C8BF4C;
	case 13:
		goto loc_82C8BF4C;
	case 14:
		goto loc_82C8BF4C;
	case 15:
		goto loc_82C8BF4C;
	case 16:
		goto loc_82C8BF3C;
	case 17:
		goto loc_82C8BE90;
	case 18:
		goto loc_82C8BF4C;
	case 19:
		goto loc_82C8BE90;
	case 20:
		goto loc_82C8BE90;
	case 21:
		goto loc_82C8BE90;
	case 22:
		goto loc_82C8BE90;
	case 23:
		goto loc_82C8BF4C;
	case 24:
		goto loc_82C8BF4C;
	case 25:
		goto loc_82C8BF3C;
	case 26:
		goto loc_82C8BF4C;
	case 27:
		goto loc_82C8BF3C;
	case 28:
		goto loc_82C8BF4C;
	case 29:
		goto loc_82C8BF4C;
	case 30:
		goto loc_82C8BF4C;
	case 31:
		goto loc_82C8BF3C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-16740(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16740);
	// lwz r22,-16692(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16692);
	// lwz r22,-16644(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16644);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16580(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16580(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16580(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16580(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16752(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16752);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16752(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16752);
	// lwz r22,-16752(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16752);
	// lwz r22,-16752(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16752);
	// lwz r22,-16752(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16752);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16580(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16580(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16564);
	// lwz r22,-16580(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16580);
loc_82C8BE90:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// b 0x82c8bf28
	goto loc_82C8BF28;
loc_82C8BE9C:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c8bd48
	if (ctx.cr6.lt) goto loc_82C8BD48;
	// lwz r11,332(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BEB8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bf4c
	if (ctx.cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c8bf28
	goto loc_82C8BF28;
loc_82C8BECC:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c8bd48
	if (ctx.cr6.lt) goto loc_82C8BD48;
	// lwz r11,336(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BEE8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bf4c
	if (ctx.cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c8bf28
	goto loc_82C8BF28;
loc_82C8BEFC:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c8bd48
	if (ctx.cr6.lt) goto loc_82C8BD48;
	// lwz r11,340(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8BF18;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8bf4c
	if (ctx.cr6.eq) goto loc_82C8BF4C;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
loc_82C8BF28:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8bde0
	if (!ctx.cr6.eq) goto loc_82C8BDE0;
loc_82C8BF30:
	// li r3,-20
	ctx.r3.s64 = -20;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8BF3C:
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r31,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
loc_82C8BF4C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8BF60"))) PPC_WEAK_FUNC(sub_82C8BF60);
PPC_FUNC_IMPL(__imp__sub_82C8BF60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C8BF68;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r26,r7
	ctx.r26.u64 = ctx.r7.u64;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c8c0b4
	if (ctx.cr6.eq) goto loc_82C8C0B4;
	// subf r30,r31,r28
	ctx.r30.s64 = ctx.r28.s64 - ctx.r31.s64;
loc_82C8BF8C:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmplwi cr6,r11,13
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 13, ctx.xer);
	// bgt cr6,0x82c8c0a4
	if (ctx.cr6.gt) goto loc_82C8C0A4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-16456
	ctx.r12.s64 = ctx.r12.s64 + -16456;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8C0CC;
	case 1:
		goto loc_82C8C0CC;
	case 2:
		goto loc_82C8C0A4;
	case 3:
		goto loc_82C8C0A4;
	case 4:
		goto loc_82C8C0A4;
	case 5:
		goto loc_82C8BFF0;
	case 6:
		goto loc_82C8C020;
	case 7:
		goto loc_82C8C050;
	case 8:
		goto loc_82C8C0CC;
	case 9:
		goto loc_82C8C0A4;
	case 10:
		goto loc_82C8C0A4;
	case 11:
		goto loc_82C8C0A4;
	case 12:
		goto loc_82C8C080;
	case 13:
		goto loc_82C8C080;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-16180(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16180);
	// lwz r22,-16180(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16180);
	// lwz r22,-16220(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16220(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16220(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16400(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16400);
	// lwz r22,-16352(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16352);
	// lwz r22,-16304(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16304);
	// lwz r22,-16180(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16180);
	// lwz r22,-16220(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16220(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16220(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16220);
	// lwz r22,-16256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16256);
	// lwz r22,-16256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16256);
loc_82C8BFF0:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c8c0c0
	if (ctx.cr6.lt) goto loc_82C8C0C0;
	// lwz r11,356(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C00C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8c0cc
	if (!ctx.cr6.eq) goto loc_82C8C0CC;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c8c0ac
	goto loc_82C8C0AC;
loc_82C8C020:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c8c0c0
	if (ctx.cr6.lt) goto loc_82C8C0C0;
	// lwz r11,360(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C03C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8c0cc
	if (!ctx.cr6.eq) goto loc_82C8C0CC;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c8c0ac
	goto loc_82C8C0AC;
loc_82C8C050:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c8c0c0
	if (ctx.cr6.lt) goto loc_82C8C0C0;
	// lwz r11,364(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C06C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8c0cc
	if (!ctx.cr6.eq) goto loc_82C8C0CC;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// b 0x82c8c0ac
	goto loc_82C8C0AC;
loc_82C8C080:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmpw cr6,r11,r27
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r27.s32, ctx.xer);
	// bne cr6,0x82c8c0ac
	if (!ctx.cr6.eq) goto loc_82C8C0AC;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8c0dc
	if (!ctx.cr6.eq) goto loc_82C8C0DC;
	// li r3,-27
	ctx.r3.s64 = -27;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C0A4:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
loc_82C8C0AC:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c8bf8c
	if (!ctx.cr6.eq) goto loc_82C8BF8C;
loc_82C8C0B4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C0C0:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C0CC:
	// stw r31,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r31.u32);
loc_82C8C0D0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C0DC:
	// stw r31,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r31.u32);
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-9
	ctx.r11.s64 = ctx.r11.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c8c0d0
	if (ctx.cr6.gt) goto loc_82C8C0D0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-16112
	ctx.r12.s64 = ctx.r12.s64 + -16112;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8C168;
	case 1:
		goto loc_82C8C168;
	case 2:
		goto loc_82C8C168;
	case 3:
		goto loc_82C8C0D0;
	case 4:
		goto loc_82C8C0D0;
	case 5:
		goto loc_82C8C0D0;
	case 6:
		goto loc_82C8C0D0;
	case 7:
		goto loc_82C8C0D0;
	case 8:
		goto loc_82C8C0D0;
	case 9:
		goto loc_82C8C0D0;
	case 10:
		goto loc_82C8C0D0;
	case 11:
		goto loc_82C8C168;
	case 12:
		goto loc_82C8C168;
	case 13:
		goto loc_82C8C0D0;
	case 14:
		goto loc_82C8C0D0;
	case 15:
		goto loc_82C8C0D0;
	case 16:
		goto loc_82C8C0D0;
	case 17:
		goto loc_82C8C0D0;
	case 18:
		goto loc_82C8C0D0;
	case 19:
		goto loc_82C8C0D0;
	case 20:
		goto loc_82C8C0D0;
	case 21:
		goto loc_82C8C168;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-16024(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
	// lwz r22,-16024(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
	// lwz r22,-16024(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16024(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
	// lwz r22,-16024(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16176);
	// lwz r22,-16024(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -16024);
loc_82C8C168:
	// li r3,27
	ctx.r3.s64 = 27;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8C178"))) PPC_WEAK_FUNC(sub_82C8C178);
PPC_FUNC_IMPL(__imp__sub_82C8C178) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C8C180;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c8c1a8
	if (!ctx.cr6.eq) goto loc_82C8C1A8;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C1A8:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-2
	ctx.r11.s64 = ctx.r11.s64 + -2;
	// cmplwi cr6,r11,34
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 34, ctx.xer);
	// bgt cr6,0x82c8c9dc
	if (ctx.cr6.gt) goto loc_82C8C9DC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-15912
	ctx.r12.s64 = ctx.r12.s64 + -15912;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8C2A4;
	case 1:
		goto loc_82C8C9DC;
	case 2:
		goto loc_82C8C46C;
	case 3:
		goto loc_82C8C628;
	case 4:
		goto loc_82C8C68C;
	case 5:
		goto loc_82C8C6E4;
	case 6:
		goto loc_82C8C9DC;
	case 7:
		goto loc_82C8C3AC;
	case 8:
		goto loc_82C8C3C8;
	case 9:
		goto loc_82C8C5F8;
	case 10:
		goto loc_82C8C264;
	case 11:
		goto loc_82C8C284;
	case 12:
		goto loc_82C8C9DC;
	case 13:
		goto loc_82C8C9DC;
	case 14:
		goto loc_82C8C9DC;
	case 15:
		goto loc_82C8C9DC;
	case 16:
		goto loc_82C8C9DC;
	case 17:
		goto loc_82C8C60C;
	case 18:
		goto loc_82C8C458;
	case 19:
		goto loc_82C8C3C8;
	case 20:
		goto loc_82C8C73C;
	case 21:
		goto loc_82C8C748;
	case 22:
		goto loc_82C8C73C;
	case 23:
		goto loc_82C8C748;
	case 24:
		goto loc_82C8C748;
	case 25:
		goto loc_82C8C748;
	case 26:
		goto loc_82C8C9DC;
	case 27:
		goto loc_82C8C9DC;
	case 28:
		goto loc_82C8C428;
	case 29:
		goto loc_82C8C4CC;
	case 30:
		goto loc_82C8C4E0;
	case 31:
		goto loc_82C8C9DC;
	case 32:
		goto loc_82C8C9DC;
	case 33:
		goto loc_82C8C444;
	case 34:
		goto loc_82C8C5E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-15708(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15708);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-15252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15252);
	// lwz r22,-14808(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14808);
	// lwz r22,-14708(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14708);
	// lwz r22,-14620(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14620);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-15444(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15444);
	// lwz r22,-15416(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15416);
	// lwz r22,-14856(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14856);
	// lwz r22,-15772(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15772);
	// lwz r22,-15740(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15740);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-14836(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14836);
	// lwz r22,-15272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15272);
	// lwz r22,-15416(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15416);
	// lwz r22,-14532(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14532);
	// lwz r22,-14520(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14520);
	// lwz r22,-14532(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14532);
	// lwz r22,-14520(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14520);
	// lwz r22,-14520(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14520);
	// lwz r22,-14520(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14520);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-15320(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15320);
	// lwz r22,-15156(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15156);
	// lwz r22,-15136(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15136);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-15292(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15292);
	// lwz r22,-14876(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14876);
loc_82C8C264:
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// addi r5,r31,1
	ctx.r5.s64 = ctx.r31.s64 + 1;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x82c8bf60
	ctx.lr = 0x82C8C27C;
	sub_82C8BF60(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C284:
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// addi r5,r31,1
	ctx.r5.s64 = ctx.r31.s64 + 1;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,13
	ctx.r3.s64 = 13;
	// bl 0x82c8bf60
	ctx.lr = 0x82C8C29C;
	sub_82C8BF60(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C2A4:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c8c2bc
	if (!ctx.cr6.eq) goto loc_82C8C2BC;
loc_82C8C2B0:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C2BC:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + ctx.r29.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-5
	ctx.r10.s64 = ctx.r10.s64 + -5;
	// cmplwi cr6,r10,24
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 24, ctx.xer);
	// bgt cr6,0x82c8c39c
	if (ctx.cr6.gt) goto loc_82C8C39C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-15636
	ctx.r12.s64 = ctx.r12.s64 + -15636;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C8C388;
	case 1:
		goto loc_82C8C388;
	case 2:
		goto loc_82C8C388;
	case 3:
		goto loc_82C8C39C;
	case 4:
		goto loc_82C8C39C;
	case 5:
		goto loc_82C8C39C;
	case 6:
		goto loc_82C8C39C;
	case 7:
		goto loc_82C8C39C;
	case 8:
		goto loc_82C8C39C;
	case 9:
		goto loc_82C8C39C;
	case 10:
		goto loc_82C8C36C;
	case 11:
		goto loc_82C8C350;
	case 12:
		goto loc_82C8C39C;
	case 13:
		goto loc_82C8C39C;
	case 14:
		goto loc_82C8C39C;
	case 15:
		goto loc_82C8C39C;
	case 16:
		goto loc_82C8C39C;
	case 17:
		goto loc_82C8C388;
	case 18:
		goto loc_82C8C39C;
	case 19:
		goto loc_82C8C388;
	case 20:
		goto loc_82C8C39C;
	case 21:
		goto loc_82C8C39C;
	case 22:
		goto loc_82C8C39C;
	case 23:
		goto loc_82C8C39C;
	case 24:
		goto loc_82C8C388;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-15480(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
	// lwz r22,-15480(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
	// lwz r22,-15480(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15508(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15508);
	// lwz r22,-15536(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15536);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15480(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15480(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15480(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15480);
loc_82C8C350:
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// addi r4,r11,1
	ctx.r4.s64 = ctx.r11.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c89840
	ctx.lr = 0x82C8C364;
	sub_82C89840(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C36C:
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// addi r4,r11,1
	ctx.r4.s64 = ctx.r11.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c89ab0
	ctx.lr = 0x82C8C380;
	sub_82C89AB0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C388:
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// li r3,29
	ctx.r3.s64 = 29;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C39C:
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C3AC:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c8c3c8
	if (!ctx.cr6.eq) goto loc_82C8C3C8;
	// stw r27,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r27.u32);
	// li r3,-15
	ctx.r3.s64 = -15;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C3C8:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c8c418
	if (ctx.cr6.eq) goto loc_82C8C418;
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
loc_82C8C3D8:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + ctx.r29.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmpwi cr6,r10,9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 9, ctx.xer);
	// beq cr6,0x82c8c400
	if (ctx.cr6.eq) goto loc_82C8C400;
	// cmpwi cr6,r10,10
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 10, ctx.xer);
	// beq cr6,0x82c8c408
	if (ctx.cr6.eq) goto loc_82C8C408;
	// cmpwi cr6,r10,21
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 21, ctx.xer);
	// bne cr6,0x82c8c418
	if (!ctx.cr6.eq) goto loc_82C8C418;
	// b 0x82c8c408
	goto loc_82C8C408;
loc_82C8C400:
	// cmplw cr6,r9,r27
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c8c418
	if (ctx.cr6.eq) goto loc_82C8C418;
loc_82C8C408:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c8c3d8
	if (!ctx.cr6.eq) goto loc_82C8C3D8;
loc_82C8C418:
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// li r3,15
	ctx.r3.s64 = 15;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C428:
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8b988
	ctx.lr = 0x82C8C43C;
	sub_82C8B988(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C444:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,38
	ctx.r3.s64 = 38;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C458:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,25
	ctx.r3.s64 = 25;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C46C:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c8c484
	if (!ctx.cr6.eq) goto loc_82C8C484;
	// li r3,-26
	ctx.r3.s64 = -26;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C484:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,93
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 93, ctx.xer);
	// bne cr6,0x82c8c4bc
	if (!ctx.cr6.eq) goto loc_82C8C4BC;
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r10,r27
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c8c2b0
	if (ctx.cr6.eq) goto loc_82C8C2B0;
	// lbz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c8c4bc
	if (!ctx.cr6.eq) goto loc_82C8C4BC;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,34
	ctx.r3.s64 = 34;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C4BC:
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// li r3,26
	ctx.r3.s64 = 26;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C4CC:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,23
	ctx.r3.s64 = 23;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C4E0:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c8c4f8
	if (!ctx.cr6.eq) goto loc_82C8C4F8;
	// li r3,-24
	ctx.r3.s64 = -24;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C4F8:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + ctx.r29.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-9
	ctx.r10.s64 = ctx.r10.s64 + -9;
	// cmplwi cr6,r10,27
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 27, ctx.xer);
	// bgt cr6,0x82c8c39c
	if (ctx.cr6.gt) goto loc_82C8C39C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-15064
	ctx.r12.s64 = ctx.r12.s64 + -15064;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C8C5D4;
	case 1:
		goto loc_82C8C5D4;
	case 2:
		goto loc_82C8C5D4;
	case 3:
		goto loc_82C8C39C;
	case 4:
		goto loc_82C8C39C;
	case 5:
		goto loc_82C8C39C;
	case 6:
		goto loc_82C8C5AC;
	case 7:
		goto loc_82C8C39C;
	case 8:
		goto loc_82C8C39C;
	case 9:
		goto loc_82C8C39C;
	case 10:
		goto loc_82C8C39C;
	case 11:
		goto loc_82C8C39C;
	case 12:
		goto loc_82C8C5D4;
	case 13:
		goto loc_82C8C39C;
	case 14:
		goto loc_82C8C39C;
	case 15:
		goto loc_82C8C39C;
	case 16:
		goto loc_82C8C39C;
	case 17:
		goto loc_82C8C39C;
	case 18:
		goto loc_82C8C39C;
	case 19:
		goto loc_82C8C39C;
	case 20:
		goto loc_82C8C39C;
	case 21:
		goto loc_82C8C39C;
	case 22:
		goto loc_82C8C39C;
	case 23:
		goto loc_82C8C5D4;
	case 24:
		goto loc_82C8C598;
	case 25:
		goto loc_82C8C5C0;
	case 26:
		goto loc_82C8C5D4;
	case 27:
		goto loc_82C8C5D4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-14892(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-14892(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-14892(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-14932(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14932);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-14892(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-15460(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -15460);
	// lwz r22,-14892(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-14952(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14952);
	// lwz r22,-14912(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14912);
	// lwz r22,-14892(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
	// lwz r22,-14892(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14892);
loc_82C8C598:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r3,36
	ctx.r3.s64 = 36;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C5AC:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r3,35
	ctx.r3.s64 = 35;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C5C0:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r3,37
	ctx.r3.s64 = 37;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C5D4:
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// li r3,24
	ctx.r3.s64 = 24;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C5E4:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,21
	ctx.r3.s64 = 21;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C5F8:
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,17
	ctx.r3.s64 = 17;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C60C:
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8bc70
	ctx.lr = 0x82C8C620;
	sub_82C8BC70(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C628:
	// subf r11,r31,r27
	ctx.r11.s64 = ctx.r27.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8c640
	if (!ctx.cr6.lt) goto loc_82C8C640;
loc_82C8C634:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C640:
	// lwz r11,344(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 344);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C654;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8c668
	if (ctx.cr6.eq) goto loc_82C8C668;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// li r28,18
	ctx.r28.s64 = 18;
	// b 0x82c8c750
	goto loc_82C8C750;
loc_82C8C668:
	// lwz r11,332(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C67C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8c9dc
	if (ctx.cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c8c74c
	goto loc_82C8C74C;
loc_82C8C68C:
	// subf r11,r31,r27
	ctx.r11.s64 = ctx.r27.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8c634
	if (ctx.cr6.lt) goto loc_82C8C634;
	// lwz r11,348(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 348);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C6AC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8c6c0
	if (ctx.cr6.eq) goto loc_82C8C6C0;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// li r28,18
	ctx.r28.s64 = 18;
	// b 0x82c8c750
	goto loc_82C8C750;
loc_82C8C6C0:
	// lwz r11,336(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C6D4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8c9dc
	if (ctx.cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// b 0x82c8c74c
	goto loc_82C8C74C;
loc_82C8C6E4:
	// subf r11,r31,r27
	ctx.r11.s64 = ctx.r27.s64 - ctx.r31.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8c634
	if (ctx.cr6.lt) goto loc_82C8C634;
	// lwz r11,352(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 352);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C704;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8c718
	if (ctx.cr6.eq) goto loc_82C8C718;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// li r28,18
	ctx.r28.s64 = 18;
	// b 0x82c8c750
	goto loc_82C8C750;
loc_82C8C718:
	// lwz r11,340(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C72C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8c9dc
	if (ctx.cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// b 0x82c8c74c
	goto loc_82C8C74C;
loc_82C8C73C:
	// li r28,18
	ctx.r28.s64 = 18;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82c8c750
	goto loc_82C8C750;
loc_82C8C748:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
loc_82C8C74C:
	// li r28,19
	ctx.r28.s64 = 19;
loc_82C8C750:
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c8c860
	if (ctx.cr6.eq) goto loc_82C8C860;
	// subf r30,r31,r27
	ctx.r30.s64 = ctx.r27.s64 - ctx.r31.s64;
loc_82C8C75C:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 31, ctx.xer);
	// bgt cr6,0x82c8c9dc
	if (ctx.cr6.gt) goto loc_82C8C9DC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-14452
	ctx.r12.s64 = ctx.r12.s64 + -14452;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8C80C;
	case 1:
		goto loc_82C8C918;
	case 2:
		goto loc_82C8C948;
	case 3:
		goto loc_82C8C9DC;
	case 4:
		goto loc_82C8C978;
	case 5:
		goto loc_82C8C978;
	case 6:
		goto loc_82C8C978;
	case 7:
		goto loc_82C8C9DC;
	case 8:
		goto loc_82C8C9DC;
	case 9:
		goto loc_82C8C9DC;
	case 10:
		goto loc_82C8C9C0;
	case 11:
		goto loc_82C8C9DC;
	case 12:
		goto loc_82C8C9DC;
	case 13:
		goto loc_82C8C9DC;
	case 14:
		goto loc_82C8C9DC;
	case 15:
		goto loc_82C8C978;
	case 16:
		goto loc_82C8C978;
	case 17:
		goto loc_82C8C90C;
	case 18:
		goto loc_82C8C83C;
	case 19:
		goto loc_82C8C90C;
	case 20:
		goto loc_82C8C90C;
	case 21:
		goto loc_82C8C90C;
	case 22:
		goto loc_82C8C90C;
	case 23:
		goto loc_82C8C9DC;
	case 24:
		goto loc_82C8C9DC;
	case 25:
		goto loc_82C8C978;
	case 26:
		goto loc_82C8C9DC;
	case 27:
		goto loc_82C8C978;
	case 28:
		goto loc_82C8C9A4;
	case 29:
		goto loc_82C8C988;
	case 30:
		goto loc_82C8C978;
	case 31:
		goto loc_82C8C978;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-14324(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14324);
	// lwz r22,-14056(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14056);
	// lwz r22,-14008(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14008);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13960(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13960(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13960(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13888(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13888);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13960(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13960(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-14068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14276);
	// lwz r22,-14068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13960(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
	// lwz r22,-13960(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13916(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13916);
	// lwz r22,-13944(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13944);
	// lwz r22,-13960(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
	// lwz r22,-13960(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13960);
loc_82C8C80C:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c8c634
	if (ctx.cr6.lt) goto loc_82C8C634;
	// lwz r11,332(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 332);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C828;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8c9dc
	if (ctx.cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c8c858
	goto loc_82C8C858;
loc_82C8C83C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmpwi cr6,r28,18
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 18, ctx.xer);
	// beq cr6,0x82c8c86c
	if (ctx.cr6.eq) goto loc_82C8C86C;
	// cmpwi cr6,r28,41
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 41, ctx.xer);
	// bne cr6,0x82c8c858
	if (!ctx.cr6.eq) goto loc_82C8C858;
loc_82C8C854:
	// li r28,19
	ctx.r28.s64 = 19;
loc_82C8C858:
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c8c75c
	if (!ctx.cr6.eq) goto loc_82C8C75C;
loc_82C8C860:
	// neg r3,r28
	ctx.r3.s64 = -ctx.r28.s64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C86C:
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c8c2b0
	if (ctx.cr6.eq) goto loc_82C8C2B0;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// li r28,41
	ctx.r28.s64 = 41;
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8c854
	if (ctx.cr6.gt) goto loc_82C8C854;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-14168
	ctx.r12.s64 = ctx.r12.s64 + -14168;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8C80C;
	case 1:
		goto loc_82C8C918;
	case 2:
		goto loc_82C8C948;
	case 3:
		goto loc_82C8C854;
	case 4:
		goto loc_82C8C854;
	case 5:
		goto loc_82C8C854;
	case 6:
		goto loc_82C8C854;
	case 7:
		goto loc_82C8C854;
	case 8:
		goto loc_82C8C854;
	case 9:
		goto loc_82C8C854;
	case 10:
		goto loc_82C8C854;
	case 11:
		goto loc_82C8C854;
	case 12:
		goto loc_82C8C854;
	case 13:
		goto loc_82C8C854;
	case 14:
		goto loc_82C8C854;
	case 15:
		goto loc_82C8C854;
	case 16:
		goto loc_82C8C854;
	case 17:
		goto loc_82C8C90C;
	case 18:
		goto loc_82C8C854;
	case 19:
		goto loc_82C8C90C;
	case 20:
		goto loc_82C8C90C;
	case 21:
		goto loc_82C8C90C;
	case 22:
		goto loc_82C8C90C;
	case 23:
		goto loc_82C8C854;
	case 24:
		goto loc_82C8C9DC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-14324(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14324);
	// lwz r22,-14056(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14056);
	// lwz r22,-14008(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14008);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-14068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14068(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14068);
	// lwz r22,-14252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -14252);
	// lwz r22,-13860(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13860);
loc_82C8C90C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// b 0x82c8c858
	goto loc_82C8C858;
loc_82C8C918:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c8c634
	if (ctx.cr6.lt) goto loc_82C8C634;
	// lwz r11,336(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 336);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C934;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8c9dc
	if (ctx.cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c8c858
	goto loc_82C8C858;
loc_82C8C948:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c8c634
	if (ctx.cr6.lt) goto loc_82C8C634;
	// lwz r11,340(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 340);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8C964;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8c9dc
	if (ctx.cr6.eq) goto loc_82C8C9DC;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// b 0x82c8c858
	goto loc_82C8C858;
loc_82C8C978:
	// stw r31,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r31.u32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C988:
	// cmpwi cr6,r28,19
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 19, ctx.xer);
	// beq cr6,0x82c8c9dc
	if (ctx.cr6.eq) goto loc_82C8C9DC;
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,32
	ctx.r3.s64 = 32;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C9A4:
	// cmpwi cr6,r28,19
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 19, ctx.xer);
	// beq cr6,0x82c8c9dc
	if (ctx.cr6.eq) goto loc_82C8C9DC;
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,31
	ctx.r3.s64 = 31;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C9C0:
	// cmpwi cr6,r28,19
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 19, ctx.xer);
	// beq cr6,0x82c8c9dc
	if (ctx.cr6.eq) goto loc_82C8C9DC;
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
	// li r3,30
	ctx.r3.s64 = 30;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8C9DC:
	// stw r31,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8C9F0"))) PPC_WEAK_FUNC(sub_82C8C9F0);
PPC_FUNC_IMPL(__imp__sub_82C8C9F0) {
	PPC_FUNC_PROLOGUE();
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8ca00
	if (!ctx.cr6.eq) goto loc_82C8CA00;
	// li r3,-4
	ctx.r3.s64 = -4;
	// blr 
	return;
loc_82C8CA00:
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C8CA04:
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-2
	ctx.r11.s64 = ctx.r11.s64 + -2;
	// cmplwi cr6,r11,19
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 19, ctx.xer);
	// bgt cr6,0x82c8ca9c
	if (ctx.cr6.gt) goto loc_82C8CA9C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-13772
	ctx.r12.s64 = ctx.r12.s64 + -13772;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8CAC4;
	case 1:
		goto loc_82C8CAB4;
	case 2:
		goto loc_82C8CA9C;
	case 3:
		goto loc_82C8CA84;
	case 4:
		goto loc_82C8CA8C;
	case 5:
		goto loc_82C8CA94;
	case 6:
		goto loc_82C8CA9C;
	case 7:
		goto loc_82C8CAE8;
	case 8:
		goto loc_82C8CAD0;
	case 9:
		goto loc_82C8CA9C;
	case 10:
		goto loc_82C8CA9C;
	case 11:
		goto loc_82C8CA9C;
	case 12:
		goto loc_82C8CA9C;
	case 13:
		goto loc_82C8CA9C;
	case 14:
		goto loc_82C8CA9C;
	case 15:
		goto loc_82C8CA9C;
	case 16:
		goto loc_82C8CA9C;
	case 17:
		goto loc_82C8CA9C;
	case 18:
		goto loc_82C8CA9C;
	case 19:
		goto loc_82C8CB28;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-13628(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13628);
	// lwz r22,-13644(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13644);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13692(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13692);
	// lwz r22,-13684(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13684);
	// lwz r22,-13676(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13676);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13592(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13592);
	// lwz r22,-13616(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13616);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13668(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13668);
	// lwz r22,-13528(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13528);
loc_82C8CA84:
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// b 0x82c8caa0
	goto loc_82C8CAA0;
loc_82C8CA8C:
	// addi r4,r4,3
	ctx.r4.s64 = ctx.r4.s64 + 3;
	// b 0x82c8caa0
	goto loc_82C8CAA0;
loc_82C8CA94:
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// b 0x82c8caa0
	goto loc_82C8CAA0;
loc_82C8CA9C:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_82C8CAA0:
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8ca04
	if (!ctx.cr6.eq) goto loc_82C8CA04;
loc_82C8CAA8:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// blr 
	return;
loc_82C8CAB4:
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c8caa8
	if (!ctx.cr6.eq) goto loc_82C8CAA8;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8a698
	sub_82C8A698(ctx, base);
	return;
loc_82C8CAC4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// blr 
	return;
loc_82C8CAD0:
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c8caa8
	if (!ctx.cr6.eq) goto loc_82C8CAA8;
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// blr 
	return;
loc_82C8CAE8:
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c8caa8
	if (!ctx.cr6.eq) goto loc_82C8CAA8;
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8cb04
	if (!ctx.cr6.eq) goto loc_82C8CB04;
	// li r3,-3
	ctx.r3.s64 = -3;
	// blr 
	return;
loc_82C8CB04:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r9,76(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmplwi cr6,r9,10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 10, ctx.xer);
	// bne cr6,0x82c8cb1c
	if (!ctx.cr6.eq) goto loc_82C8CB1C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82C8CB1C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,7
	ctx.r3.s64 = 7;
	// blr 
	return;
loc_82C8CB28:
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c8caa8
	if (!ctx.cr6.eq) goto loc_82C8CAA8;
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// li r3,39
	ctx.r3.s64 = 39;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8CB40"))) PPC_WEAK_FUNC(sub_82C8CB40);
PPC_FUNC_IMPL(__imp__sub_82C8CB40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8cb68
	if (!ctx.cr6.eq) goto loc_82C8CB68;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8CB68:
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C8CB6C:
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-3
	ctx.r11.s64 = ctx.r11.s64 + -3;
	// cmplwi cr6,r11,27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 27, ctx.xer);
	// bgt cr6,0x82c8cc24
	if (ctx.cr6.gt) goto loc_82C8CC24;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-13412
	ctx.r12.s64 = ctx.r12.s64 + -13412;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8CC48;
	case 1:
		goto loc_82C8CC24;
	case 2:
		goto loc_82C8CC0C;
	case 3:
		goto loc_82C8CC14;
	case 4:
		goto loc_82C8CC1C;
	case 5:
		goto loc_82C8CC24;
	case 6:
		goto loc_82C8CCB8;
	case 7:
		goto loc_82C8CC94;
	case 8:
		goto loc_82C8CC24;
	case 9:
		goto loc_82C8CC24;
	case 10:
		goto loc_82C8CC24;
	case 11:
		goto loc_82C8CC24;
	case 12:
		goto loc_82C8CC24;
	case 13:
		goto loc_82C8CC24;
	case 14:
		goto loc_82C8CC24;
	case 15:
		goto loc_82C8CC24;
	case 16:
		goto loc_82C8CC24;
	case 17:
		goto loc_82C8CC24;
	case 18:
		goto loc_82C8CC24;
	case 19:
		goto loc_82C8CC24;
	case 20:
		goto loc_82C8CC24;
	case 21:
		goto loc_82C8CC24;
	case 22:
		goto loc_82C8CC24;
	case 23:
		goto loc_82C8CC24;
	case 24:
		goto loc_82C8CC24;
	case 25:
		goto loc_82C8CC24;
	case 26:
		goto loc_82C8CC24;
	case 27:
		goto loc_82C8CC68;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-13240(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13240);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13300(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13300);
	// lwz r22,-13292(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13292);
	// lwz r22,-13284(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13284);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13128);
	// lwz r22,-13164(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13164);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13276);
	// lwz r22,-13208(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -13208);
loc_82C8CC0C:
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// b 0x82c8cc28
	goto loc_82C8CC28;
loc_82C8CC14:
	// addi r4,r4,3
	ctx.r4.s64 = ctx.r4.s64 + 3;
	// b 0x82c8cc28
	goto loc_82C8CC28;
loc_82C8CC1C:
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// b 0x82c8cc28
	goto loc_82C8CC28;
loc_82C8CC24:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_82C8CC28:
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8cb6c
	if (!ctx.cr6.eq) goto loc_82C8CB6C;
loc_82C8CC30:
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,6
	ctx.r3.s64 = 6;
loc_82C8CC38:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8CC48:
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c8cc30
	if (!ctx.cr6.eq) goto loc_82C8CC30;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// bl 0x82c8a698
	ctx.lr = 0x82C8CC58;
	sub_82C8A698(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8CC68:
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c8cc30
	if (!ctx.cr6.eq) goto loc_82C8CC30;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// bl 0x82c8b988
	ctx.lr = 0x82C8CC78;
	sub_82C8B988(ctx, base);
	// cmpwi cr6,r3,22
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 22, ctx.xer);
	// bne cr6,0x82c8cc38
	if (!ctx.cr6.eq) goto loc_82C8CC38;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8CC94:
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c8cc30
	if (!ctx.cr6.eq) goto loc_82C8CC30;
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8CCB8:
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c8cc30
	if (!ctx.cr6.eq) goto loc_82C8CC30;
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8cce0
	if (!ctx.cr6.eq) goto loc_82C8CCE0;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8CCE0:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r9,76(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// cmplwi cr6,r9,10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 10, ctx.xer);
	// bne cr6,0x82c8ccf8
	if (!ctx.cr6.eq) goto loc_82C8CCF8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82C8CCF8:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,7
	ctx.r3.s64 = 7;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8CD10"))) PPC_WEAK_FUNC(sub_82C8CD10);
PPC_FUNC_IMPL(__imp__sub_82C8CD10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C8CD18;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// li r27,0
	ctx.r27.s64 = 0;
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82c8ce68
	if (ctx.cr6.eq) goto loc_82C8CE68;
	// subf r30,r31,r29
	ctx.r30.s64 = ctx.r29.s64 - ctx.r31.s64;
loc_82C8CD3C:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmplwi cr6,r11,8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8, ctx.xer);
	// bgt cr6,0x82c8ce58
	if (ctx.cr6.gt) goto loc_82C8CE58;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-12952
	ctx.r12.s64 = ctx.r12.s64 + -12952;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8CEE0;
	case 1:
		goto loc_82C8CEE0;
	case 2:
		goto loc_82C8CE1C;
	case 3:
		goto loc_82C8CE58;
	case 4:
		goto loc_82C8CE74;
	case 5:
		goto loc_82C8CD8C;
	case 6:
		goto loc_82C8CDBC;
	case 7:
		goto loc_82C8CDEC;
	case 8:
		goto loc_82C8CEE0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-12576(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12576);
	// lwz r22,-12576(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12576);
	// lwz r22,-12772(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12772);
	// lwz r22,-12712(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12712);
	// lwz r22,-12684(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12684);
	// lwz r22,-12916(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12916);
	// lwz r22,-12868(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12868);
	// lwz r22,-12820(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12820);
	// lwz r22,-12576(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12576);
loc_82C8CD8C:
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// blt cr6,0x82c8cec4
	if (ctx.cr6.lt) goto loc_82C8CEC4;
	// lwz r11,356(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 356);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8CDA8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8ced0
	if (!ctx.cr6.eq) goto loc_82C8CED0;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r30,r30,-2
	ctx.r30.s64 = ctx.r30.s64 + -2;
	// b 0x82c8ce60
	goto loc_82C8CE60;
loc_82C8CDBC:
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// blt cr6,0x82c8cec4
	if (ctx.cr6.lt) goto loc_82C8CEC4;
	// lwz r11,360(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 360);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8CDD8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8ced0
	if (!ctx.cr6.eq) goto loc_82C8CED0;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r30,r30,-3
	ctx.r30.s64 = ctx.r30.s64 + -3;
	// b 0x82c8ce60
	goto loc_82C8CE60;
loc_82C8CDEC:
	// cmpwi cr6,r30,4
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 4, ctx.xer);
	// blt cr6,0x82c8cec4
	if (ctx.cr6.lt) goto loc_82C8CEC4;
	// lwz r11,364(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 364);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C8CE08;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c8ced0
	if (!ctx.cr6.eq) goto loc_82C8CED0;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// b 0x82c8ce60
	goto loc_82C8CE60;
loc_82C8CE1C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82c8ce68
	if (ctx.cr6.eq) goto loc_82C8CE68;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,33
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 33, ctx.xer);
	// bne cr6,0x82c8ce60
	if (!ctx.cr6.eq) goto loc_82C8CE60;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82c8ce68
	if (ctx.cr6.eq) goto loc_82C8CE68;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,91
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 91, ctx.xer);
	// bne cr6,0x82c8ce60
	if (!ctx.cr6.eq) goto loc_82C8CE60;
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
loc_82C8CE58:
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
loc_82C8CE60:
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// bne cr6,0x82c8cd3c
	if (!ctx.cr6.eq) goto loc_82C8CD3C;
loc_82C8CE68:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8CE74:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82c8ce68
	if (ctx.cr6.eq) goto loc_82C8CE68;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c8ce60
	if (!ctx.cr6.eq) goto loc_82C8CE60;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82c8ce68
	if (ctx.cr6.eq) goto loc_82C8CE68;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c8ce60
	if (!ctx.cr6.eq) goto loc_82C8CE60;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmpwi cr6,r27,0
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// beq cr6,0x82c8cef0
	if (ctx.cr6.eq) goto loc_82C8CEF0;
	// addi r27,r27,-1
	ctx.r27.s64 = ctx.r27.s64 + -1;
	// b 0x82c8ce60
	goto loc_82C8CE60;
loc_82C8CEC4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8CED0:
	// stw r31,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8CEE0:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r31.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8CEF0:
	// li r3,42
	ctx.r3.s64 = 42;
	// stw r31,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r31.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8CF00"))) PPC_WEAK_FUNC(sub_82C8CF00);
PPC_FUNC_IMPL(__imp__sub_82C8CF00) {
	PPC_FUNC_PROLOGUE();
	// addi r10,r4,1
	ctx.r10.s64 = ctx.r4.s64 + 1;
	// addi r8,r5,-1
	ctx.r8.s64 = ctx.r5.s64 + -1;
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x82c8cff8
	if (ctx.cr6.eq) goto loc_82C8CFF8;
loc_82C8CF10:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r9,r11,r3
	ctx.r9.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r9,76(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 76);
	// addi r9,r9,-9
	ctx.r9.s64 = ctx.r9.s64 + -9;
	// cmplwi cr6,r9,26
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 26, ctx.xer);
	// bgt cr6,0x82c8cfd8
	if (ctx.cr6.gt) goto loc_82C8CFD8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-12480
	ctx.r12.s64 = ctx.r12.s64 + -12480;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82C8CFEC;
	case 1:
		goto loc_82C8CFEC;
	case 2:
		goto loc_82C8CFD8;
	case 3:
		goto loc_82C8CFD8;
	case 4:
		goto loc_82C8CFEC;
	case 5:
		goto loc_82C8CFEC;
	case 6:
		goto loc_82C8CFEC;
	case 7:
		goto loc_82C8CFEC;
	case 8:
		goto loc_82C8CFEC;
	case 9:
		goto loc_82C8CFEC;
	case 10:
		goto loc_82C8CFEC;
	case 11:
		goto loc_82C8CFD8;
	case 12:
		goto loc_82C8CFAC;
	case 13:
		goto loc_82C8CFC4;
	case 14:
		goto loc_82C8CFEC;
	case 15:
		goto loc_82C8CFEC;
	case 16:
		goto loc_82C8CFEC;
	case 17:
		goto loc_82C8CFC4;
	case 18:
		goto loc_82C8CFEC;
	case 19:
		goto loc_82C8CFD8;
	case 20:
		goto loc_82C8CFD8;
	case 21:
		goto loc_82C8CFEC;
	case 22:
		goto loc_82C8CFEC;
	case 23:
		goto loc_82C8CFEC;
	case 24:
		goto loc_82C8CFEC;
	case 25:
		goto loc_82C8CFEC;
	case 26:
		goto loc_82C8CFEC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12328);
	// lwz r22,-12328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12328);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12328);
	// lwz r22,-12372(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12372);
	// lwz r22,-12348(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12348);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12348(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12348);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12328);
	// lwz r22,-12328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12328);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
	// lwz r22,-12308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12308);
loc_82C8CFAC:
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82c8cfec
	if (!ctx.cr6.eq) goto loc_82C8CFEC;
loc_82C8CFB8:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8CFC4:
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// rlwinm r7,r9,0,0,24
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFF80;
	// extsb r4,r7
	ctx.r4.s64 = ctx.r7.s8;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82c8cfec
	if (ctx.cr6.eq) goto loc_82C8CFEC;
loc_82C8CFD8:
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,36
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 36, ctx.xer);
	// beq cr6,0x82c8cfec
	if (ctx.cr6.eq) goto loc_82C8CFEC;
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// bne cr6,0x82c8cfb8
	if (!ctx.cr6.eq) goto loc_82C8CFB8;
loc_82C8CFEC:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c8cf10
	if (!ctx.cr6.eq) goto loc_82C8CF10;
loc_82C8CFF8:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8D000"))) PPC_WEAK_FUNC(sub_82C8D000);
PPC_FUNC_IMPL(__imp__sub_82C8D000) {
	PPC_FUNC_PROLOGUE();
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C8D008;
	__savegprlr_29(ctx, base);
	// li r29,0
	ctx.r29.s64 = 0;
	// addi r8,r4,1
	ctx.r8.s64 = ctx.r4.s64 + 1;
	// li r30,1
	ctx.r30.s64 = 1;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
	// addi r4,r8,1
	ctx.r4.s64 = ctx.r8.s64 + 1;
loc_82C8D024:
	// lbz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// add r11,r10,r3
	ctx.r11.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-3
	ctx.r11.s64 = ctx.r11.s64 + -3;
	// cmplwi cr6,r11,26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 26, ctx.xer);
	// bgt cr6,0x82c8d2dc
	if (ctx.cr6.gt) goto loc_82C8D2DC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-12204
	ctx.r12.s64 = ctx.r12.s64 + -12204;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8D2BC;
	case 1:
		goto loc_82C8D2DC;
	case 2:
		goto loc_82C8D0C0;
	case 3:
		goto loc_82C8D0F0;
	case 4:
		goto loc_82C8D120;
	case 5:
		goto loc_82C8D2DC;
	case 6:
		goto loc_82C8D29C;
	case 7:
		goto loc_82C8D29C;
	case 8:
		goto loc_82C8D2D4;
	case 9:
		goto loc_82C8D178;
	case 10:
		goto loc_82C8D1CC;
	case 11:
		goto loc_82C8D2DC;
	case 12:
		goto loc_82C8D2DC;
	case 13:
		goto loc_82C8D2DC;
	case 14:
		goto loc_82C8D2D4;
	case 15:
		goto loc_82C8D2DC;
	case 16:
		goto loc_82C8D2DC;
	case 17:
		goto loc_82C8D2DC;
	case 18:
		goto loc_82C8D220;
	case 19:
		goto loc_82C8D150;
	case 20:
		goto loc_82C8D2DC;
	case 21:
		goto loc_82C8D150;
	case 22:
		goto loc_82C8D2DC;
	case 23:
		goto loc_82C8D2DC;
	case 24:
		goto loc_82C8D2DC;
	case 25:
		goto loc_82C8D2DC;
	case 26:
		goto loc_82C8D150;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-11588(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11588);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-12096(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12096);
	// lwz r22,-12048(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12048);
	// lwz r22,-12000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -12000);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11620(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11620);
	// lwz r22,-11620(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11620);
	// lwz r22,-11564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11564);
	// lwz r22,-11912(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11912);
	// lwz r22,-11828(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11828);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11564(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11564);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11744(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11744);
	// lwz r22,-11952(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11952);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11952(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11952);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11556(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11556);
	// lwz r22,-11952(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11952);
loc_82C8D0C0:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c8d0dc
	if (!ctx.cr6.eq) goto loc_82C8D0DC;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c8d0d8
	if (!ctx.cr6.lt) goto loc_82C8D0D8;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r30,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r30.u8);
loc_82C8D0D8:
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
loc_82C8D0DC:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D0F0:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c8d10c
	if (!ctx.cr6.eq) goto loc_82C8D10C;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c8d108
	if (!ctx.cr6.lt) goto loc_82C8D108;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r30,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r30.u8);
loc_82C8D108:
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
loc_82C8D10C:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D120:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c8d13c
	if (!ctx.cr6.eq) goto loc_82C8D13C;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c8d138
	if (!ctx.cr6.lt) goto loc_82C8D138;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r30,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r30.u8);
loc_82C8D138:
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
loc_82C8D13C:
	// addi r8,r8,3
	ctx.r8.s64 = ctx.r8.s64 + 3;
	// addi r4,r4,3
	ctx.r4.s64 = ctx.r4.s64 + 3;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D150:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c8d2dc
	if (!ctx.cr6.eq) goto loc_82C8D2DC;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c8d168
	if (!ctx.cr6.lt) goto loc_82C8D168;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r30,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r30.u8);
loc_82C8D168:
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D178:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// beq cr6,0x82c8d1a0
	if (ctx.cr6.eq) goto loc_82C8D1A0;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c8d18c
	if (!ctx.cr6.lt) goto loc_82C8D18C;
	// stw r4,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r4.u32);
loc_82C8D18C:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r31,12
	ctx.r31.s64 = 12;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D1A0:
	// cmpwi cr6,r31,12
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 12, ctx.xer);
	// bne cr6,0x82c8d2dc
	if (!ctx.cr6.eq) goto loc_82C8D2DC;
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c8d1b8
	if (!ctx.cr6.lt) goto loc_82C8D1B8;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
loc_82C8D1B8:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D1CC:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// beq cr6,0x82c8d1f4
	if (ctx.cr6.eq) goto loc_82C8D1F4;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c8d1e0
	if (!ctx.cr6.lt) goto loc_82C8D1E0;
	// stw r4,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r4.u32);
loc_82C8D1E0:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r31,13
	ctx.r31.s64 = 13;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D1F4:
	// cmpwi cr6,r31,13
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 13, ctx.xer);
	// bne cr6,0x82c8d2dc
	if (!ctx.cr6.eq) goto loc_82C8D2DC;
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c8d1b8
	if (!ctx.cr6.lt) goto loc_82C8D1B8;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D220:
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82c8d238
	if (!ctx.cr6.eq) goto loc_82C8D238;
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D238:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c8d2dc
	if (!ctx.cr6.eq) goto loc_82C8D2DC;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c8d2dc
	if (!ctx.cr6.lt) goto loc_82C8D2DC;
	// lbz r11,12(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c8d2dc
	if (ctx.cr6.eq) goto loc_82C8D2DC;
	// lwz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82c8d28c
	if (ctx.cr6.eq) goto loc_82C8D28C;
	// extsb r11,r10
	ctx.r11.s64 = ctx.r10.s8;
	// cmpwi cr6,r11,32
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 32, ctx.xer);
	// bne cr6,0x82c8d28c
	if (!ctx.cr6.eq) goto loc_82C8D28C;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,32
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 32, ctx.xer);
	// beq cr6,0x82c8d28c
	if (ctx.cr6.eq) goto loc_82C8D28C;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r10,76(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmpw cr6,r10,r31
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r31.s32, ctx.xer);
	// bne cr6,0x82c8d2dc
	if (!ctx.cr6.eq) goto loc_82C8D2DC;
loc_82C8D28C:
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D29C:
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82c8d2b4
	if (!ctx.cr6.eq) goto loc_82C8D2B4;
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D2B4:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c8d2dc
	if (!ctx.cr6.eq) goto loc_82C8D2DC;
loc_82C8D2BC:
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c8d2dc
	if (!ctx.cr6.lt) goto loc_82C8D2DC;
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D2D4:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c8d2e8
	if (!ctx.cr6.eq) goto loc_82C8D2E8;
loc_82C8D2DC:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// b 0x82c8d024
	goto loc_82C8D024;
loc_82C8D2E8:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8D2F0"))) PPC_WEAK_FUNC(sub_82C8D2F0);
PPC_FUNC_IMPL(__imp__sub_82C8D2F0) {
	PPC_FUNC_PROLOGUE();
	// subf r11,r4,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82c8d3b0
	if (ctx.cr6.eq) goto loc_82C8D3B0;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c8d384
	if (ctx.cr6.eq) goto loc_82C8D384;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,97
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 97, ctx.xer);
	// beq cr6,0x82c8d354
	if (ctx.cr6.eq) goto loc_82C8D354;
	// cmpwi cr6,r11,113
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 113, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// lbz r10,1(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// cmplwi cr6,r10,117
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 117, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,111
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 111, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// lbz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r11,116
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 116, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// li r3,34
	ctx.r3.s64 = 34;
	// blr 
	return;
loc_82C8D354:
	// lbz r10,1(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// cmplwi cr6,r10,112
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 112, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,111
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 111, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// lbz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r11,115
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 115, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// li r3,39
	ctx.r3.s64 = 39;
	// blr 
	return;
loc_82C8D384:
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,97
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 97, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,109
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 109, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// lbz r11,2(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// cmplwi cr6,r11,112
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 112, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// li r3,38
	ctx.r3.s64 = 38;
	// blr 
	return;
loc_82C8D3B0:
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,116
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 116, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,103
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 103, ctx.xer);
	// beq cr6,0x82c8d3dc
	if (ctx.cr6.eq) goto loc_82C8D3DC;
	// cmpwi cr6,r11,108
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 108, ctx.xer);
	// bne cr6,0x82c8d3e4
	if (!ctx.cr6.eq) goto loc_82C8D3E4;
	// li r3,60
	ctx.r3.s64 = 60;
	// blr 
	return;
loc_82C8D3DC:
	// li r3,62
	ctx.r3.s64 = 62;
	// blr 
	return;
loc_82C8D3E4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8D3F0"))) PPC_WEAK_FUNC(sub_82C8D3F0);
PPC_FUNC_IMPL(__imp__sub_82C8D3F0) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r10,r11,r3
	ctx.r10.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-5
	ctx.r10.s64 = ctx.r10.s64 + -5;
	// cmplwi cr6,r10,24
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 24, ctx.xer);
	// bgt cr6,0x82c8d51c
	if (ctx.cr6.gt) goto loc_82C8D51C;
loc_82C8D408:
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-11232
	ctx.r12.s64 = ctx.r12.s64 + -11232;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82C8D4B8;
	case 1:
		goto loc_82C8D4A0;
	case 2:
		goto loc_82C8D484;
	case 3:
		goto loc_82C8D51C;
	case 4:
		goto loc_82C8D51C;
	case 5:
		goto loc_82C8D51C;
	case 6:
		goto loc_82C8D51C;
	case 7:
		goto loc_82C8D51C;
	case 8:
		goto loc_82C8D51C;
	case 9:
		goto loc_82C8D51C;
	case 10:
		goto loc_82C8D51C;
	case 11:
		goto loc_82C8D51C;
	case 12:
		goto loc_82C8D51C;
	case 13:
		goto loc_82C8D51C;
	case 14:
		goto loc_82C8D51C;
	case 15:
		goto loc_82C8D51C;
	case 16:
		goto loc_82C8D51C;
	case 17:
		goto loc_82C8D4E8;
	case 18:
		goto loc_82C8D4E8;
	case 19:
		goto loc_82C8D4E8;
	case 20:
		goto loc_82C8D4E8;
	case 21:
		goto loc_82C8D4E8;
	case 22:
		goto loc_82C8D4E8;
	case 23:
		goto loc_82C8D51C;
	case 24:
		goto loc_82C8D4E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-11080(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11080);
	// lwz r22,-11104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11104);
	// lwz r22,-11132(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11132);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-11032(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-11032(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-11032(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-11032(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-11032(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-11032(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
	// lwz r22,-10980(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10980);
	// lwz r22,-11032(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -11032);
loc_82C8D484:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// extsb r8,r10
	ctx.r8.s64 = ctx.r10.s8;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// cmpw cr6,r9,r8
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x82c8d5c8
	if (!ctx.cr6.eq) goto loc_82C8D5C8;
loc_82C8D4A0:
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c8d5c8
	if (!ctx.cr6.eq) goto loc_82C8D5C8;
loc_82C8D4B8:
	// lbz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// lbz r8,0(r5)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r10,r5,1
	ctx.r10.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c8d5c8
	if (!ctx.cr6.eq) goto loc_82C8D5C8;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r4,r11,1
	ctx.r4.s64 = ctx.r11.s64 + 1;
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r5,r10,1
	ctx.r5.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// b 0x82c8d500
	goto loc_82C8D500;
loc_82C8D4E8:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// extsb r8,r10
	ctx.r8.s64 = ctx.r10.s8;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
loc_82C8D500:
	// bne cr6,0x82c8d5c8
	if (!ctx.cr6.eq) goto loc_82C8D5C8;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r10,r11,r3
	ctx.r10.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r10,76(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 76);
	// addi r10,r10,-5
	ctx.r10.s64 = ctx.r10.s64 + -5;
	// cmplwi cr6,r10,24
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 24, ctx.xer);
	// ble cr6,0x82c8d408
	if (!ctx.cr6.gt) goto loc_82C8D408;
loc_82C8D51C:
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// extsb r8,r10
	ctx.r8.s64 = ctx.r10.s8;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// beq cr6,0x82c8d5d0
	if (ctx.cr6.eq) goto loc_82C8D5D0;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8d5d0
	if (ctx.cr6.gt) goto loc_82C8D5D0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-10908
	ctx.r12.s64 = ctx.r12.s64 + -10908;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8D5C8;
	case 1:
		goto loc_82C8D5C8;
	case 2:
		goto loc_82C8D5C8;
	case 3:
		goto loc_82C8D5D0;
	case 4:
		goto loc_82C8D5D0;
	case 5:
		goto loc_82C8D5D0;
	case 6:
		goto loc_82C8D5D0;
	case 7:
		goto loc_82C8D5D0;
	case 8:
		goto loc_82C8D5D0;
	case 9:
		goto loc_82C8D5D0;
	case 10:
		goto loc_82C8D5D0;
	case 11:
		goto loc_82C8D5D0;
	case 12:
		goto loc_82C8D5D0;
	case 13:
		goto loc_82C8D5D0;
	case 14:
		goto loc_82C8D5D0;
	case 15:
		goto loc_82C8D5D0;
	case 16:
		goto loc_82C8D5D0;
	case 17:
		goto loc_82C8D5C8;
	case 18:
		goto loc_82C8D5C8;
	case 19:
		goto loc_82C8D5C8;
	case 20:
		goto loc_82C8D5C8;
	case 21:
		goto loc_82C8D5C8;
	case 22:
		goto loc_82C8D5C8;
	case 23:
		goto loc_82C8D5D0;
	case 24:
		goto loc_82C8D5C8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-10808(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10808(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10808(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
	// lwz r22,-10800(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10800);
	// lwz r22,-10808(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10808);
loc_82C8D5C8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8D5D0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
	// lbz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c8d618
	if (ctx.cr6.eq) goto loc_82C8D618;
loc_82C8D5E8:
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8d628
	if (ctx.cr6.eq) goto loc_82C8D628;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82c8d628
	if (!ctx.cr6.eq) goto loc_82C8D628;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// lbz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c8d5e8
	if (!ctx.cr6.eq) goto loc_82C8D5E8;
loc_82C8D618:
	// subf r11,r4,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r3,r10,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// blr 
	return;
loc_82C8D628:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8d6fc
	if (ctx.cr6.gt) goto loc_82C8D6FC;
loc_82C8D64C:
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-10652
	ctx.r12.s64 = ctx.r12.s64 + -10652;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8D6C8;
	case 1:
		goto loc_82C8D6D0;
	case 2:
		goto loc_82C8D6D8;
	case 3:
		goto loc_82C8D6FC;
	case 4:
		goto loc_82C8D6FC;
	case 5:
		goto loc_82C8D6FC;
	case 6:
		goto loc_82C8D6FC;
	case 7:
		goto loc_82C8D6FC;
	case 8:
		goto loc_82C8D6FC;
	case 9:
		goto loc_82C8D6FC;
	case 10:
		goto loc_82C8D6FC;
	case 11:
		goto loc_82C8D6FC;
	case 12:
		goto loc_82C8D6FC;
	case 13:
		goto loc_82C8D6FC;
	case 14:
		goto loc_82C8D6FC;
	case 15:
		goto loc_82C8D6FC;
	case 16:
		goto loc_82C8D6FC;
	case 17:
		goto loc_82C8D6E0;
	case 18:
		goto loc_82C8D6E0;
	case 19:
		goto loc_82C8D6E0;
	case 20:
		goto loc_82C8D6E0;
	case 21:
		goto loc_82C8D6E0;
	case 22:
		goto loc_82C8D6E0;
	case 23:
		goto loc_82C8D6FC;
	case 24:
		goto loc_82C8D6E0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-10552(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10552);
	// lwz r22,-10544(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10544);
	// lwz r22,-10536(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10536);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10528(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10528(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10528(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10528(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10528(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10528(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
	// lwz r22,-10500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10500);
	// lwz r22,-10528(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10528);
loc_82C8D6C8:
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// b 0x82c8d6e4
	goto loc_82C8D6E4;
loc_82C8D6D0:
	// addi r4,r4,3
	ctx.r4.s64 = ctx.r4.s64 + 3;
	// b 0x82c8d6e4
	goto loc_82C8D6E4;
loc_82C8D6D8:
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// b 0x82c8d6e4
	goto loc_82C8D6E4;
loc_82C8D6E0:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_82C8D6E4:
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// ble cr6,0x82c8d64c
	if (!ctx.cr6.gt) goto loc_82C8D64C;
loc_82C8D6FC:
	// subf r3,r10,r4
	ctx.r3.s64 = ctx.r4.s64 - ctx.r10.s64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8D708"))) PPC_WEAK_FUNC(sub_82C8D708);
PPC_FUNC_IMPL(__imp__sub_82C8D708) {
	PPC_FUNC_PROLOGUE();
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lbz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bltlr cr6
	if (ctx.cr6.lt) return;
loc_82C8D724:
	// cmpwi cr6,r11,10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 10, ctx.xer);
	// ble cr6,0x82c8d734
	if (!ctx.cr6.gt) goto loc_82C8D734;
	// cmpwi cr6,r11,21
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 21, ctx.xer);
	// bnelr cr6
	if (!ctx.cr6.eq) return;
loc_82C8D734:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// lbz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bge cr6,0x82c8d724
	if (!ctx.cr6.lt) goto loc_82C8D724;
	// blr 
	return;
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// li r10,-1
	ctx.r10.s64 = -1;
loc_82C8D75C:
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// bgt cr6,0x82c8d7cc
	if (ctx.cr6.gt) goto loc_82C8D7CC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-10356
	ctx.r12.s64 = ctx.r12.s64 + -10356;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8D7A4;
	case 1:
		goto loc_82C8D7AC;
	case 2:
		goto loc_82C8D7B4;
	case 3:
		goto loc_82C8D7CC;
	case 4:
		goto loc_82C8D7E8;
	case 5:
		goto loc_82C8D7BC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-10332(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10332);
	// lwz r22,-10324(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10324);
	// lwz r22,-10316(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10316);
	// lwz r22,-10292(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10292);
	// lwz r22,-10264(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10264);
	// lwz r22,-10308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -10308);
loc_82C8D7A4:
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// b 0x82c8d7d0
	goto loc_82C8D7D0;
loc_82C8D7AC:
	// addi r4,r4,3
	ctx.r4.s64 = ctx.r4.s64 + 3;
	// b 0x82c8d7d0
	goto loc_82C8D7D0;
loc_82C8D7B4:
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// b 0x82c8d7d0
	goto loc_82C8D7D0;
loc_82C8D7BC:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// stw r10,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C8D7CC:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_82C8D7D0:
	// lwz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r11.u32);
	// bne cr6,0x82c8d75c
	if (!ctx.cr6.eq) goto loc_82C8D75C;
	// blr 
	return;
loc_82C8D7E8:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// beq cr6,0x82c8d818
	if (ctx.cr6.eq) goto loc_82C8D818;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lbz r9,76(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// cmplwi cr6,r9,10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 10, ctx.xer);
	// bne cr6,0x82c8d818
	if (!ctx.cr6.eq) goto loc_82C8D818;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_82C8D818:
	// stw r10,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r10.u32);
	// b 0x82c8d7d0
	goto loc_82C8D7D0;
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// subf r9,r10,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r10.s64;
	// subf r8,r11,r5
	ctx.r8.s64 = ctx.r5.s64 - ctx.r11.s64;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// ble cr6,0x82c8d86c
	if (!ctx.cr6.gt) goto loc_82C8D86C;
	// subf r9,r10,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r10.s64;
	// add r5,r9,r7
	ctx.r5.u64 = ctx.r9.u64 + ctx.r7.u64;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bge cr6,0x82c8d870
	if (!ctx.cr6.lt) goto loc_82C8D870;
loc_82C8D848:
	// lbz r8,-1(r5)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r5.u32 + -1);
	// addi r9,r5,-1
	ctx.r9.s64 = ctx.r5.s64 + -1;
	// rlwinm r7,r8,0,0,25
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFC0;
	// cmplwi cr6,r7,128
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 128, ctx.xer);
	// bne cr6,0x82c8d86c
	if (!ctx.cr6.eq) goto loc_82C8D86C;
	// lwz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// bgt cr6,0x82c8d848
	if (ctx.cr6.gt) goto loc_82C8D848;
loc_82C8D86C:
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
loc_82C8D870:
	// beq cr6,0x82c8d88c
	if (ctx.cr6.eq) goto loc_82C8D88C;
loc_82C8D874:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// stb r9,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r9.u8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// bne cr6,0x82c8d874
	if (!ctx.cr6.eq) goto loc_82C8D874;
loc_82C8D88C:
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8D898"))) PPC_WEAK_FUNC(sub_82C8D898);
PPC_FUNC_IMPL(__imp__sub_82C8D898) {
	PPC_FUNC_PROLOGUE();
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C8D8A0;
	__savegprlr_29(ctx, base);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8d98c
	if (ctx.cr6.eq) goto loc_82C8D98C;
	// addi r9,r10,2
	ctx.r9.s64 = ctx.r10.s64 + 2;
	// lis r30,1
	ctx.r30.s64 = 65536;
loc_82C8D8B8:
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82c8d98c
	if (ctx.cr6.eq) goto loc_82C8D98C;
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r31,r8,r3
	ctx.r31.u64 = ctx.r8.u64 + ctx.r3.u64;
	// lbz r31,76(r31)
	ctx.r31.u64 = PPC_LOAD_U8(ctx.r31.u32 + 76);
	// cmpwi cr6,r31,5
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 5, ctx.xer);
	// beq cr6,0x82c8d964
	if (ctx.cr6.eq) goto loc_82C8D964;
	// cmpwi cr6,r31,6
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 6, ctx.xer);
	// beq cr6,0x82c8d944
	if (ctx.cr6.eq) goto loc_82C8D944;
	// cmpwi cr6,r31,7
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 7, ctx.xer);
	// beq cr6,0x82c8d8f0
	if (ctx.cr6.eq) goto loc_82C8D8F0;
	// extsb r8,r8
	ctx.r8.s64 = ctx.r8.s8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x82c8d978
	goto loc_82C8D978;
loc_82C8D8F0:
	// cmplw cr6,r9,r7
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82c8d98c
	if (ctx.cr6.eq) goto loc_82C8D98C;
	// lbz r31,1(r11)
	ctx.r31.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// extsb r8,r8
	ctx.r8.s64 = ctx.r8.s8;
	// lbz r29,2(r11)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// rlwimi r31,r8,6,23,25
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r8.u32, 6) & 0x1C0) | (ctx.r31.u64 & 0xFFFFFFFFFFFFFE3F);
	// lbz r8,3(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// clrlwi r31,r31,23
	ctx.r31.u64 = ctx.r31.u32 & 0x1FF;
	// rlwimi r29,r31,6,0,25
	ctx.r29.u64 = (__builtin_rotateleft32(ctx.r31.u32, 6) & 0xFFFFFFC0) | (ctx.r29.u64 & 0xFFFFFFFF0000003F);
	// rlwimi r8,r29,6,0,25
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r29.u32, 6) & 0xFFFFFFC0) | (ctx.r8.u64 & 0xFFFFFFFF0000003F);
	// subf r8,r30,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r30.s64;
	// rlwinm r31,r8,22,16,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 22) & 0xFFFF;
	// clrlwi r8,r8,22
	ctx.r8.u64 = ctx.r8.u32 & 0x3FF;
	// ori r31,r31,55296
	ctx.r31.u64 = ctx.r31.u64 | 55296;
	// ori r8,r8,56320
	ctx.r8.u64 = ctx.r8.u64 | 56320;
	// sth r31,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r31.u16);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// sth r8,0(r9)
	PPC_STORE_U16(ctx.r9.u32 + 0, ctx.r8.u16);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// b 0x82c8d984
	goto loc_82C8D984;
loc_82C8D944:
	// lbz r31,1(r11)
	ctx.r31.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// extsb r8,r8
	ctx.r8.s64 = ctx.r8.s8;
	// lbz r29,2(r11)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// rlwimi r31,r8,6,0,25
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r8.u32, 6) & 0xFFFFFFC0) | (ctx.r31.u64 & 0xFFFFFFFF0000003F);
	// rlwimi r29,r31,6,0,25
	ctx.r29.u64 = (__builtin_rotateleft32(ctx.r31.u32, 6) & 0xFFFFFFC0) | (ctx.r29.u64 & 0xFFFFFFFF0000003F);
	// sth r29,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r29.u16);
	// b 0x82c8d97c
	goto loc_82C8D97C;
loc_82C8D964:
	// lbz r31,1(r11)
	ctx.r31.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// extsb r8,r8
	ctx.r8.s64 = ctx.r8.s8;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// rlwimi r31,r8,6,21,25
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r8.u32, 6) & 0x7C0) | (ctx.r31.u64 & 0xFFFFFFFFFFFFF83F);
	// clrlwi r8,r31,21
	ctx.r8.u64 = ctx.r31.u32 & 0x7FF;
loc_82C8D978:
	// sth r8,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r8.u16);
loc_82C8D97C:
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8D984:
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8d8b8
	if (!ctx.cr6.eq) goto loc_82C8D8B8;
loc_82C8D98C:
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8D998"))) PPC_WEAK_FUNC(sub_82C8D998);
PPC_FUNC_IMPL(__imp__sub_82C8D998) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lis r11,511
	ctx.r11.s64 = 33488896;
	// ori r9,r11,65535
	ctx.r9.u64 = ctx.r11.u64 | 65535;
loc_82C8D9AC:
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// rlwinm r10,r11,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// beq cr6,0x82c8da10
	if (ctx.cr6.eq) goto loc_82C8DA10;
	// subf r8,r10,r7
	ctx.r8.s64 = ctx.r7.s64 - ctx.r10.s64;
	// cmpwi cr6,r8,2
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 2, ctx.xer);
	// bltlr cr6
	if (ctx.cr6.lt) return;
	// li r8,-64
	ctx.r8.s64 = -64;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// rlwimi r8,r11,26,30,31
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r11.u32, 26) & 0x3) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFFC);
	// rlwimi r3,r9,7,0,25
	ctx.r3.u64 = (__builtin_rotateleft32(ctx.r9.u32, 7) & 0xFFFFFFC0) | (ctx.r3.u64 & 0xFFFFFFFF0000003F);
	// stb r8,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r8.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// stb r3,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// b 0x82c8da34
	goto loc_82C8DA34;
loc_82C8DA10:
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r11.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
loc_82C8DA34:
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8d9ac
	if (!ctx.cr6.eq) goto loc_82C8D9AC;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8DA48"))) PPC_WEAK_FUNC(sub_82C8DA48);
PPC_FUNC_IMPL(__imp__sub_82C8DA48) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82C8DA54:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r7.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// sth r9,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r9.u16);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r8,r11,2
	ctx.r8.s64 = ctx.r11.s64 + 2;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// rotlwi r11,r3,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8da54
	if (!ctx.cr6.eq) goto loc_82C8DA54;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8DA98"))) PPC_WEAK_FUNC(sub_82C8DA98);
PPC_FUNC_IMPL(__imp__sub_82C8DA98) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82C8DAA4:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r7.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// stb r9,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// rotlwi r11,r3,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8daa4
	if (!ctx.cr6.eq) goto loc_82C8DAA4;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8DAE8"))) PPC_WEAK_FUNC(sub_82C8DAE8);
PPC_FUNC_IMPL(__imp__sub_82C8DAE8) {
	PPC_FUNC_PROLOGUE();
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// addi r11,r11,-216
	ctx.r11.s64 = ctx.r11.s64 + -216;
	// cmplwi cr6,r11,39
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 39, ctx.xer);
	// bgt cr6,0x82c8dbd8
	if (ctx.cr6.gt) goto loc_82C8DBD8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-9456
	ctx.r12.s64 = ctx.r12.s64 + -9456;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8DBB0;
	case 1:
		goto loc_82C8DBB0;
	case 2:
		goto loc_82C8DBB0;
	case 3:
		goto loc_82C8DBB0;
	case 4:
		goto loc_82C8DBB8;
	case 5:
		goto loc_82C8DBB8;
	case 6:
		goto loc_82C8DBB8;
	case 7:
		goto loc_82C8DBB8;
	case 8:
		goto loc_82C8DBD8;
	case 9:
		goto loc_82C8DBD8;
	case 10:
		goto loc_82C8DBD8;
	case 11:
		goto loc_82C8DBD8;
	case 12:
		goto loc_82C8DBD8;
	case 13:
		goto loc_82C8DBD8;
	case 14:
		goto loc_82C8DBD8;
	case 15:
		goto loc_82C8DBD8;
	case 16:
		goto loc_82C8DBD8;
	case 17:
		goto loc_82C8DBD8;
	case 18:
		goto loc_82C8DBD8;
	case 19:
		goto loc_82C8DBD8;
	case 20:
		goto loc_82C8DBD8;
	case 21:
		goto loc_82C8DBD8;
	case 22:
		goto loc_82C8DBD8;
	case 23:
		goto loc_82C8DBD8;
	case 24:
		goto loc_82C8DBD8;
	case 25:
		goto loc_82C8DBD8;
	case 26:
		goto loc_82C8DBD8;
	case 27:
		goto loc_82C8DBD8;
	case 28:
		goto loc_82C8DBD8;
	case 29:
		goto loc_82C8DBD8;
	case 30:
		goto loc_82C8DBD8;
	case 31:
		goto loc_82C8DBD8;
	case 32:
		goto loc_82C8DBD8;
	case 33:
		goto loc_82C8DBD8;
	case 34:
		goto loc_82C8DBD8;
	case 35:
		goto loc_82C8DBD8;
	case 36:
		goto loc_82C8DBD8;
	case 37:
		goto loc_82C8DBD8;
	case 38:
		goto loc_82C8DBD8;
	case 39:
		goto loc_82C8DBC0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-9296(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9296);
	// lwz r22,-9296(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9296);
	// lwz r22,-9296(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9296);
	// lwz r22,-9296(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9296);
	// lwz r22,-9288(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9288);
	// lwz r22,-9288(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9288);
	// lwz r22,-9288(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9288);
	// lwz r22,-9288(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9288);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9256);
	// lwz r22,-9280(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -9280);
loc_82C8DBB0:
	// li r3,7
	ctx.r3.s64 = 7;
	// blr 
	return;
loc_82C8DBB8:
	// li r3,8
	ctx.r3.s64 = 8;
	// blr 
	return;
loc_82C8DBC0:
	// clrlwi r11,r4,24
	ctx.r11.u64 = ctx.r4.u32 & 0xFF;
	// cmpwi cr6,r11,254
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 254, ctx.xer);
	// blt cr6,0x82c8dbd8
	if (ctx.cr6.lt) goto loc_82C8DBD8;
	// cmpwi cr6,r11,255
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 255, ctx.xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// blelr cr6
	if (!ctx.cr6.gt) return;
loc_82C8DBD8:
	// li r3,29
	ctx.r3.s64 = 29;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8DBE0"))) PPC_WEAK_FUNC(sub_82C8DBE0);
PPC_FUNC_IMPL(__imp__sub_82C8DBE0) {
	PPC_FUNC_PROLOGUE();
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C8DBE8;
	__savegprlr_27(ctx, base);
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e130
	if (ctx.cr6.eq) goto loc_82C8E130;
	// lis r11,511
	ctx.r11.s64 = 33488896;
	// li r30,-16
	ctx.r30.s64 = -16;
	// ori r8,r11,65535
	ctx.r8.u64 = ctx.r11.u64 | 65535;
loc_82C8DC00:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// mr r31,r9
	ctx.r31.u64 = ctx.r9.u64;
	// cmplwi cr6,r31,219
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 219, ctx.xer);
	// bgt cr6,0x82c8e0c0
	if (ctx.cr6.gt) goto loc_82C8E0C0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-9172
	ctx.r12.s64 = ctx.r12.s64 + -9172;
	// rlwinm r0,r31,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r31.u64) {
	case 0:
		goto loc_82C8DF9C;
	case 1:
		goto loc_82C8DFBC;
	case 2:
		goto loc_82C8DFBC;
	case 3:
		goto loc_82C8DFBC;
	case 4:
		goto loc_82C8DFBC;
	case 5:
		goto loc_82C8DFBC;
	case 6:
		goto loc_82C8DFBC;
	case 7:
		goto loc_82C8DFBC;
	case 8:
		goto loc_82C8E0C0;
	case 9:
		goto loc_82C8E0C0;
	case 10:
		goto loc_82C8E0C0;
	case 11:
		goto loc_82C8E0C0;
	case 12:
		goto loc_82C8E0C0;
	case 13:
		goto loc_82C8E0C0;
	case 14:
		goto loc_82C8E0C0;
	case 15:
		goto loc_82C8E0C0;
	case 16:
		goto loc_82C8E0C0;
	case 17:
		goto loc_82C8E0C0;
	case 18:
		goto loc_82C8E0C0;
	case 19:
		goto loc_82C8E0C0;
	case 20:
		goto loc_82C8E0C0;
	case 21:
		goto loc_82C8E0C0;
	case 22:
		goto loc_82C8E0C0;
	case 23:
		goto loc_82C8E0C0;
	case 24:
		goto loc_82C8E0C0;
	case 25:
		goto loc_82C8E0C0;
	case 26:
		goto loc_82C8E0C0;
	case 27:
		goto loc_82C8E0C0;
	case 28:
		goto loc_82C8E0C0;
	case 29:
		goto loc_82C8E0C0;
	case 30:
		goto loc_82C8E0C0;
	case 31:
		goto loc_82C8E0C0;
	case 32:
		goto loc_82C8E0C0;
	case 33:
		goto loc_82C8E0C0;
	case 34:
		goto loc_82C8E0C0;
	case 35:
		goto loc_82C8E0C0;
	case 36:
		goto loc_82C8E0C0;
	case 37:
		goto loc_82C8E0C0;
	case 38:
		goto loc_82C8E0C0;
	case 39:
		goto loc_82C8E0C0;
	case 40:
		goto loc_82C8E0C0;
	case 41:
		goto loc_82C8E0C0;
	case 42:
		goto loc_82C8E0C0;
	case 43:
		goto loc_82C8E0C0;
	case 44:
		goto loc_82C8E0C0;
	case 45:
		goto loc_82C8E0C0;
	case 46:
		goto loc_82C8E0C0;
	case 47:
		goto loc_82C8E0C0;
	case 48:
		goto loc_82C8E0C0;
	case 49:
		goto loc_82C8E0C0;
	case 50:
		goto loc_82C8E0C0;
	case 51:
		goto loc_82C8E0C0;
	case 52:
		goto loc_82C8E0C0;
	case 53:
		goto loc_82C8E0C0;
	case 54:
		goto loc_82C8E0C0;
	case 55:
		goto loc_82C8E0C0;
	case 56:
		goto loc_82C8E0C0;
	case 57:
		goto loc_82C8E0C0;
	case 58:
		goto loc_82C8E0C0;
	case 59:
		goto loc_82C8E0C0;
	case 60:
		goto loc_82C8E0C0;
	case 61:
		goto loc_82C8E0C0;
	case 62:
		goto loc_82C8E0C0;
	case 63:
		goto loc_82C8E0C0;
	case 64:
		goto loc_82C8E0C0;
	case 65:
		goto loc_82C8E0C0;
	case 66:
		goto loc_82C8E0C0;
	case 67:
		goto loc_82C8E0C0;
	case 68:
		goto loc_82C8E0C0;
	case 69:
		goto loc_82C8E0C0;
	case 70:
		goto loc_82C8E0C0;
	case 71:
		goto loc_82C8E0C0;
	case 72:
		goto loc_82C8E0C0;
	case 73:
		goto loc_82C8E0C0;
	case 74:
		goto loc_82C8E0C0;
	case 75:
		goto loc_82C8E0C0;
	case 76:
		goto loc_82C8E0C0;
	case 77:
		goto loc_82C8E0C0;
	case 78:
		goto loc_82C8E0C0;
	case 79:
		goto loc_82C8E0C0;
	case 80:
		goto loc_82C8E0C0;
	case 81:
		goto loc_82C8E0C0;
	case 82:
		goto loc_82C8E0C0;
	case 83:
		goto loc_82C8E0C0;
	case 84:
		goto loc_82C8E0C0;
	case 85:
		goto loc_82C8E0C0;
	case 86:
		goto loc_82C8E0C0;
	case 87:
		goto loc_82C8E0C0;
	case 88:
		goto loc_82C8E0C0;
	case 89:
		goto loc_82C8E0C0;
	case 90:
		goto loc_82C8E0C0;
	case 91:
		goto loc_82C8E0C0;
	case 92:
		goto loc_82C8E0C0;
	case 93:
		goto loc_82C8E0C0;
	case 94:
		goto loc_82C8E0C0;
	case 95:
		goto loc_82C8E0C0;
	case 96:
		goto loc_82C8E0C0;
	case 97:
		goto loc_82C8E0C0;
	case 98:
		goto loc_82C8E0C0;
	case 99:
		goto loc_82C8E0C0;
	case 100:
		goto loc_82C8E0C0;
	case 101:
		goto loc_82C8E0C0;
	case 102:
		goto loc_82C8E0C0;
	case 103:
		goto loc_82C8E0C0;
	case 104:
		goto loc_82C8E0C0;
	case 105:
		goto loc_82C8E0C0;
	case 106:
		goto loc_82C8E0C0;
	case 107:
		goto loc_82C8E0C0;
	case 108:
		goto loc_82C8E0C0;
	case 109:
		goto loc_82C8E0C0;
	case 110:
		goto loc_82C8E0C0;
	case 111:
		goto loc_82C8E0C0;
	case 112:
		goto loc_82C8E0C0;
	case 113:
		goto loc_82C8E0C0;
	case 114:
		goto loc_82C8E0C0;
	case 115:
		goto loc_82C8E0C0;
	case 116:
		goto loc_82C8E0C0;
	case 117:
		goto loc_82C8E0C0;
	case 118:
		goto loc_82C8E0C0;
	case 119:
		goto loc_82C8E0C0;
	case 120:
		goto loc_82C8E0C0;
	case 121:
		goto loc_82C8E0C0;
	case 122:
		goto loc_82C8E0C0;
	case 123:
		goto loc_82C8E0C0;
	case 124:
		goto loc_82C8E0C0;
	case 125:
		goto loc_82C8E0C0;
	case 126:
		goto loc_82C8E0C0;
	case 127:
		goto loc_82C8E0C0;
	case 128:
		goto loc_82C8E0C0;
	case 129:
		goto loc_82C8E0C0;
	case 130:
		goto loc_82C8E0C0;
	case 131:
		goto loc_82C8E0C0;
	case 132:
		goto loc_82C8E0C0;
	case 133:
		goto loc_82C8E0C0;
	case 134:
		goto loc_82C8E0C0;
	case 135:
		goto loc_82C8E0C0;
	case 136:
		goto loc_82C8E0C0;
	case 137:
		goto loc_82C8E0C0;
	case 138:
		goto loc_82C8E0C0;
	case 139:
		goto loc_82C8E0C0;
	case 140:
		goto loc_82C8E0C0;
	case 141:
		goto loc_82C8E0C0;
	case 142:
		goto loc_82C8E0C0;
	case 143:
		goto loc_82C8E0C0;
	case 144:
		goto loc_82C8E0C0;
	case 145:
		goto loc_82C8E0C0;
	case 146:
		goto loc_82C8E0C0;
	case 147:
		goto loc_82C8E0C0;
	case 148:
		goto loc_82C8E0C0;
	case 149:
		goto loc_82C8E0C0;
	case 150:
		goto loc_82C8E0C0;
	case 151:
		goto loc_82C8E0C0;
	case 152:
		goto loc_82C8E0C0;
	case 153:
		goto loc_82C8E0C0;
	case 154:
		goto loc_82C8E0C0;
	case 155:
		goto loc_82C8E0C0;
	case 156:
		goto loc_82C8E0C0;
	case 157:
		goto loc_82C8E0C0;
	case 158:
		goto loc_82C8E0C0;
	case 159:
		goto loc_82C8E0C0;
	case 160:
		goto loc_82C8E0C0;
	case 161:
		goto loc_82C8E0C0;
	case 162:
		goto loc_82C8E0C0;
	case 163:
		goto loc_82C8E0C0;
	case 164:
		goto loc_82C8E0C0;
	case 165:
		goto loc_82C8E0C0;
	case 166:
		goto loc_82C8E0C0;
	case 167:
		goto loc_82C8E0C0;
	case 168:
		goto loc_82C8E0C0;
	case 169:
		goto loc_82C8E0C0;
	case 170:
		goto loc_82C8E0C0;
	case 171:
		goto loc_82C8E0C0;
	case 172:
		goto loc_82C8E0C0;
	case 173:
		goto loc_82C8E0C0;
	case 174:
		goto loc_82C8E0C0;
	case 175:
		goto loc_82C8E0C0;
	case 176:
		goto loc_82C8E0C0;
	case 177:
		goto loc_82C8E0C0;
	case 178:
		goto loc_82C8E0C0;
	case 179:
		goto loc_82C8E0C0;
	case 180:
		goto loc_82C8E0C0;
	case 181:
		goto loc_82C8E0C0;
	case 182:
		goto loc_82C8E0C0;
	case 183:
		goto loc_82C8E0C0;
	case 184:
		goto loc_82C8E0C0;
	case 185:
		goto loc_82C8E0C0;
	case 186:
		goto loc_82C8E0C0;
	case 187:
		goto loc_82C8E0C0;
	case 188:
		goto loc_82C8E0C0;
	case 189:
		goto loc_82C8E0C0;
	case 190:
		goto loc_82C8E0C0;
	case 191:
		goto loc_82C8E0C0;
	case 192:
		goto loc_82C8E0C0;
	case 193:
		goto loc_82C8E0C0;
	case 194:
		goto loc_82C8E0C0;
	case 195:
		goto loc_82C8E0C0;
	case 196:
		goto loc_82C8E0C0;
	case 197:
		goto loc_82C8E0C0;
	case 198:
		goto loc_82C8E0C0;
	case 199:
		goto loc_82C8E0C0;
	case 200:
		goto loc_82C8E0C0;
	case 201:
		goto loc_82C8E0C0;
	case 202:
		goto loc_82C8E0C0;
	case 203:
		goto loc_82C8E0C0;
	case 204:
		goto loc_82C8E0C0;
	case 205:
		goto loc_82C8E0C0;
	case 206:
		goto loc_82C8E0C0;
	case 207:
		goto loc_82C8E0C0;
	case 208:
		goto loc_82C8E0C0;
	case 209:
		goto loc_82C8E0C0;
	case 210:
		goto loc_82C8E0C0;
	case 211:
		goto loc_82C8E0C0;
	case 212:
		goto loc_82C8E0C0;
	case 213:
		goto loc_82C8E0C0;
	case 214:
		goto loc_82C8E0C0;
	case 215:
		goto loc_82C8E0C0;
	case 216:
		goto loc_82C8E010;
	case 217:
		goto loc_82C8E010;
	case 218:
		goto loc_82C8E010;
	case 219:
		goto loc_82C8E010;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-8292(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8292);
	// lwz r22,-8260(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8260(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8260);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8000(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8000);
	// lwz r22,-8176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8176);
	// lwz r22,-8176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8176);
	// lwz r22,-8176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8176);
	// lwz r22,-8176(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8176);
loc_82C8DF9C:
	// clrlwi r3,r11,24
	ctx.r3.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r3,128
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 128, ctx.xer);
	// bge cr6,0x82c8dfbc
	if (!ctx.cr6.lt) goto loc_82C8DFBC;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r9,r7
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82c8e130
	if (ctx.cr6.eq) goto loc_82C8E130;
	// stb r11,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r11.u8);
	// b 0x82c8e118
	goto loc_82C8E118;
loc_82C8DFBC:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r31,r3,r7
	ctx.r31.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r31,2
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 2, ctx.xer);
	// blt cr6,0x82c8e130
	if (ctx.cr6.lt) goto loc_82C8E130;
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// li r31,-64
	ctx.r31.s64 = -64;
	// rlwinm r29,r11,26,30,31
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3;
	// rlwimi r31,r9,2,26,29
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r9.u32, 2) & 0x3C) | (ctx.r31.u64 & 0xFFFFFFFFFFFFFFC3);
	// rlwimi r11,r8,7,0,25
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (ctx.r11.u64 & 0xFFFFFFFF0000003F);
	// extsb r9,r31
	ctx.r9.s64 = ctx.r31.s8;
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// or r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 | ctx.r29.u64;
	// stb r9,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// stb r31,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r31.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// stw r3,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r3.u32);
	// b 0x82c8e124
	goto loc_82C8E124;
loc_82C8E010:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r9,r3,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c8e130
	if (ctx.cr6.lt) goto loc_82C8E130;
	// rlwinm r9,r11,26,30,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3;
	// rlwinm r31,r31,2,28,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xC;
	// li r29,-128
	ctx.r29.s64 = -128;
	// or r9,r9,r31
	ctx.r9.u64 = ctx.r9.u64 | ctx.r31.u64;
	// rlwinm r31,r11,30,28,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0xF;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// li r28,-32
	ctx.r28.s64 = -32;
	// srawi r27,r9,2
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r27.s64 = ctx.r9.s32 >> 2;
	// rlwimi r29,r9,4,26,27
	ctx.r29.u64 = (__builtin_rotateleft32(ctx.r9.u32, 4) & 0x30) | (ctx.r29.u64 & 0xFFFFFFFFFFFFFFCF);
	// or r9,r27,r30
	ctx.r9.u64 = ctx.r27.u64 | ctx.r30.u64;
	// extsb r29,r29
	ctx.r29.s64 = ctx.r29.s8;
	// stb r9,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r9.u8);
	// rlwimi r28,r11,2,28,29
	ctx.r28.u64 = (__builtin_rotateleft32(ctx.r11.u32, 2) & 0xC) | (ctx.r28.u64 & 0xFFFFFFFFFFFFFFF3);
	// or r3,r31,r29
	ctx.r3.u64 = ctx.r31.u64 | ctx.r29.u64;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r9.u32);
	// stb r3,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// clrlwi r3,r3,30
	ctx.r3.u64 = ctx.r3.u32 & 0x3;
	// or r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 | ctx.r3.u64;
	// rlwinm r31,r9,26,6,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwimi r9,r8,7,0,25
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (ctx.r9.u64 & 0xFFFFFFFF0000003F);
	// extsb r3,r3
	ctx.r3.s64 = ctx.r3.s8;
	// or r3,r3,r31
	ctx.r3.u64 = ctx.r3.u64 | ctx.r31.u64;
	// stb r3,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// stb r9,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// stw r3,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r3.u32);
	// b 0x82c8e124
	goto loc_82C8E124;
loc_82C8E0C0:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r31,r3,r7
	ctx.r31.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r31,3
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 3, ctx.xer);
	// blt cr6,0x82c8e130
	if (ctx.cr6.lt) goto loc_82C8E130;
	// li r31,-32
	ctx.r31.s64 = -32;
	// li r29,-128
	ctx.r29.s64 = -128;
	// rlwimi r31,r9,28,28,31
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r9.u32, 28) & 0xF) | (ctx.r31.u64 & 0xFFFFFFFFFFFFFFF0);
	// rlwimi r29,r9,2,26,29
	ctx.r29.u64 = (__builtin_rotateleft32(ctx.r9.u32, 2) & 0x3C) | (ctx.r29.u64 & 0xFFFFFFFFFFFFFFC3);
	// stb r31,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r31.u8);
	// rlwinm r3,r11,26,30,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// addi r11,r9,1
	ctx.r11.s64 = ctx.r9.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// extsb r11,r29
	ctx.r11.s64 = ctx.r29.s8;
	// rlwimi r31,r8,7,0,25
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (ctx.r31.u64 & 0xFFFFFFFF0000003F);
	// or r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 | ctx.r3.u64;
	// stb r3,1(r9)
	PPC_STORE_U8(ctx.r9.u32 + 1, ctx.r3.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// stb r31,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r31.u8);
loc_82C8E118:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C8E124:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8dc00
	if (!ctx.cr6.eq) goto loc_82C8DC00;
loc_82C8E130:
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8E138"))) PPC_WEAK_FUNC(sub_82C8E138);
PPC_FUNC_IMPL(__imp__sub_82C8E138) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// subf r9,r10,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r10.s64;
	// subf r8,r11,r5
	ctx.r8.s64 = ctx.r5.s64 - ctx.r11.s64;
	// rlwinm r3,r9,0,0,30
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// cmpw cr6,r8,r3
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r3.s32, ctx.xer);
	// ble cr6,0x82c8e168
	if (!ctx.cr6.gt) goto loc_82C8E168;
	// lbz r10,-1(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + -1);
	// rlwinm r9,r10,0,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF8;
	// cmplwi cr6,r9,216
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 216, ctx.xer);
	// bne cr6,0x82c8e168
	if (!ctx.cr6.eq) goto loc_82C8E168;
	// addi r5,r5,-2
	ctx.r5.s64 = ctx.r5.s64 + -2;
loc_82C8E168:
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82C8E170:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r7.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// rotlwi r3,r9,8
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r10,r3,r8
	ctx.r10.u64 = ctx.r3.u64 | ctx.r8.u64;
	// sth r10,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r8,r11,2
	ctx.r8.s64 = ctx.r11.s64 + 2;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// rotlwi r11,r3,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8e170
	if (!ctx.cr6.eq) goto loc_82C8E170;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8E1C0"))) PPC_WEAK_FUNC(sub_82C8E1C0);
PPC_FUNC_IMPL(__imp__sub_82C8E1C0) {
	PPC_FUNC_PROLOGUE();
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C8E1C8;
	__savegprlr_27(ctx, base);
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e710
	if (ctx.cr6.eq) goto loc_82C8E710;
	// lis r11,511
	ctx.r11.s64 = 33488896;
	// li r30,-16
	ctx.r30.s64 = -16;
	// ori r8,r11,65535
	ctx.r8.u64 = ctx.r11.u64 | 65535;
loc_82C8E1E0:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// mr r31,r9
	ctx.r31.u64 = ctx.r9.u64;
	// cmplwi cr6,r31,219
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 219, ctx.xer);
	// bgt cr6,0x82c8e6a0
	if (ctx.cr6.gt) goto loc_82C8E6A0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-7668
	ctx.r12.s64 = ctx.r12.s64 + -7668;
	// rlwinm r0,r31,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r31.u64) {
	case 0:
		goto loc_82C8E57C;
	case 1:
		goto loc_82C8E59C;
	case 2:
		goto loc_82C8E59C;
	case 3:
		goto loc_82C8E59C;
	case 4:
		goto loc_82C8E59C;
	case 5:
		goto loc_82C8E59C;
	case 6:
		goto loc_82C8E59C;
	case 7:
		goto loc_82C8E59C;
	case 8:
		goto loc_82C8E6A0;
	case 9:
		goto loc_82C8E6A0;
	case 10:
		goto loc_82C8E6A0;
	case 11:
		goto loc_82C8E6A0;
	case 12:
		goto loc_82C8E6A0;
	case 13:
		goto loc_82C8E6A0;
	case 14:
		goto loc_82C8E6A0;
	case 15:
		goto loc_82C8E6A0;
	case 16:
		goto loc_82C8E6A0;
	case 17:
		goto loc_82C8E6A0;
	case 18:
		goto loc_82C8E6A0;
	case 19:
		goto loc_82C8E6A0;
	case 20:
		goto loc_82C8E6A0;
	case 21:
		goto loc_82C8E6A0;
	case 22:
		goto loc_82C8E6A0;
	case 23:
		goto loc_82C8E6A0;
	case 24:
		goto loc_82C8E6A0;
	case 25:
		goto loc_82C8E6A0;
	case 26:
		goto loc_82C8E6A0;
	case 27:
		goto loc_82C8E6A0;
	case 28:
		goto loc_82C8E6A0;
	case 29:
		goto loc_82C8E6A0;
	case 30:
		goto loc_82C8E6A0;
	case 31:
		goto loc_82C8E6A0;
	case 32:
		goto loc_82C8E6A0;
	case 33:
		goto loc_82C8E6A0;
	case 34:
		goto loc_82C8E6A0;
	case 35:
		goto loc_82C8E6A0;
	case 36:
		goto loc_82C8E6A0;
	case 37:
		goto loc_82C8E6A0;
	case 38:
		goto loc_82C8E6A0;
	case 39:
		goto loc_82C8E6A0;
	case 40:
		goto loc_82C8E6A0;
	case 41:
		goto loc_82C8E6A0;
	case 42:
		goto loc_82C8E6A0;
	case 43:
		goto loc_82C8E6A0;
	case 44:
		goto loc_82C8E6A0;
	case 45:
		goto loc_82C8E6A0;
	case 46:
		goto loc_82C8E6A0;
	case 47:
		goto loc_82C8E6A0;
	case 48:
		goto loc_82C8E6A0;
	case 49:
		goto loc_82C8E6A0;
	case 50:
		goto loc_82C8E6A0;
	case 51:
		goto loc_82C8E6A0;
	case 52:
		goto loc_82C8E6A0;
	case 53:
		goto loc_82C8E6A0;
	case 54:
		goto loc_82C8E6A0;
	case 55:
		goto loc_82C8E6A0;
	case 56:
		goto loc_82C8E6A0;
	case 57:
		goto loc_82C8E6A0;
	case 58:
		goto loc_82C8E6A0;
	case 59:
		goto loc_82C8E6A0;
	case 60:
		goto loc_82C8E6A0;
	case 61:
		goto loc_82C8E6A0;
	case 62:
		goto loc_82C8E6A0;
	case 63:
		goto loc_82C8E6A0;
	case 64:
		goto loc_82C8E6A0;
	case 65:
		goto loc_82C8E6A0;
	case 66:
		goto loc_82C8E6A0;
	case 67:
		goto loc_82C8E6A0;
	case 68:
		goto loc_82C8E6A0;
	case 69:
		goto loc_82C8E6A0;
	case 70:
		goto loc_82C8E6A0;
	case 71:
		goto loc_82C8E6A0;
	case 72:
		goto loc_82C8E6A0;
	case 73:
		goto loc_82C8E6A0;
	case 74:
		goto loc_82C8E6A0;
	case 75:
		goto loc_82C8E6A0;
	case 76:
		goto loc_82C8E6A0;
	case 77:
		goto loc_82C8E6A0;
	case 78:
		goto loc_82C8E6A0;
	case 79:
		goto loc_82C8E6A0;
	case 80:
		goto loc_82C8E6A0;
	case 81:
		goto loc_82C8E6A0;
	case 82:
		goto loc_82C8E6A0;
	case 83:
		goto loc_82C8E6A0;
	case 84:
		goto loc_82C8E6A0;
	case 85:
		goto loc_82C8E6A0;
	case 86:
		goto loc_82C8E6A0;
	case 87:
		goto loc_82C8E6A0;
	case 88:
		goto loc_82C8E6A0;
	case 89:
		goto loc_82C8E6A0;
	case 90:
		goto loc_82C8E6A0;
	case 91:
		goto loc_82C8E6A0;
	case 92:
		goto loc_82C8E6A0;
	case 93:
		goto loc_82C8E6A0;
	case 94:
		goto loc_82C8E6A0;
	case 95:
		goto loc_82C8E6A0;
	case 96:
		goto loc_82C8E6A0;
	case 97:
		goto loc_82C8E6A0;
	case 98:
		goto loc_82C8E6A0;
	case 99:
		goto loc_82C8E6A0;
	case 100:
		goto loc_82C8E6A0;
	case 101:
		goto loc_82C8E6A0;
	case 102:
		goto loc_82C8E6A0;
	case 103:
		goto loc_82C8E6A0;
	case 104:
		goto loc_82C8E6A0;
	case 105:
		goto loc_82C8E6A0;
	case 106:
		goto loc_82C8E6A0;
	case 107:
		goto loc_82C8E6A0;
	case 108:
		goto loc_82C8E6A0;
	case 109:
		goto loc_82C8E6A0;
	case 110:
		goto loc_82C8E6A0;
	case 111:
		goto loc_82C8E6A0;
	case 112:
		goto loc_82C8E6A0;
	case 113:
		goto loc_82C8E6A0;
	case 114:
		goto loc_82C8E6A0;
	case 115:
		goto loc_82C8E6A0;
	case 116:
		goto loc_82C8E6A0;
	case 117:
		goto loc_82C8E6A0;
	case 118:
		goto loc_82C8E6A0;
	case 119:
		goto loc_82C8E6A0;
	case 120:
		goto loc_82C8E6A0;
	case 121:
		goto loc_82C8E6A0;
	case 122:
		goto loc_82C8E6A0;
	case 123:
		goto loc_82C8E6A0;
	case 124:
		goto loc_82C8E6A0;
	case 125:
		goto loc_82C8E6A0;
	case 126:
		goto loc_82C8E6A0;
	case 127:
		goto loc_82C8E6A0;
	case 128:
		goto loc_82C8E6A0;
	case 129:
		goto loc_82C8E6A0;
	case 130:
		goto loc_82C8E6A0;
	case 131:
		goto loc_82C8E6A0;
	case 132:
		goto loc_82C8E6A0;
	case 133:
		goto loc_82C8E6A0;
	case 134:
		goto loc_82C8E6A0;
	case 135:
		goto loc_82C8E6A0;
	case 136:
		goto loc_82C8E6A0;
	case 137:
		goto loc_82C8E6A0;
	case 138:
		goto loc_82C8E6A0;
	case 139:
		goto loc_82C8E6A0;
	case 140:
		goto loc_82C8E6A0;
	case 141:
		goto loc_82C8E6A0;
	case 142:
		goto loc_82C8E6A0;
	case 143:
		goto loc_82C8E6A0;
	case 144:
		goto loc_82C8E6A0;
	case 145:
		goto loc_82C8E6A0;
	case 146:
		goto loc_82C8E6A0;
	case 147:
		goto loc_82C8E6A0;
	case 148:
		goto loc_82C8E6A0;
	case 149:
		goto loc_82C8E6A0;
	case 150:
		goto loc_82C8E6A0;
	case 151:
		goto loc_82C8E6A0;
	case 152:
		goto loc_82C8E6A0;
	case 153:
		goto loc_82C8E6A0;
	case 154:
		goto loc_82C8E6A0;
	case 155:
		goto loc_82C8E6A0;
	case 156:
		goto loc_82C8E6A0;
	case 157:
		goto loc_82C8E6A0;
	case 158:
		goto loc_82C8E6A0;
	case 159:
		goto loc_82C8E6A0;
	case 160:
		goto loc_82C8E6A0;
	case 161:
		goto loc_82C8E6A0;
	case 162:
		goto loc_82C8E6A0;
	case 163:
		goto loc_82C8E6A0;
	case 164:
		goto loc_82C8E6A0;
	case 165:
		goto loc_82C8E6A0;
	case 166:
		goto loc_82C8E6A0;
	case 167:
		goto loc_82C8E6A0;
	case 168:
		goto loc_82C8E6A0;
	case 169:
		goto loc_82C8E6A0;
	case 170:
		goto loc_82C8E6A0;
	case 171:
		goto loc_82C8E6A0;
	case 172:
		goto loc_82C8E6A0;
	case 173:
		goto loc_82C8E6A0;
	case 174:
		goto loc_82C8E6A0;
	case 175:
		goto loc_82C8E6A0;
	case 176:
		goto loc_82C8E6A0;
	case 177:
		goto loc_82C8E6A0;
	case 178:
		goto loc_82C8E6A0;
	case 179:
		goto loc_82C8E6A0;
	case 180:
		goto loc_82C8E6A0;
	case 181:
		goto loc_82C8E6A0;
	case 182:
		goto loc_82C8E6A0;
	case 183:
		goto loc_82C8E6A0;
	case 184:
		goto loc_82C8E6A0;
	case 185:
		goto loc_82C8E6A0;
	case 186:
		goto loc_82C8E6A0;
	case 187:
		goto loc_82C8E6A0;
	case 188:
		goto loc_82C8E6A0;
	case 189:
		goto loc_82C8E6A0;
	case 190:
		goto loc_82C8E6A0;
	case 191:
		goto loc_82C8E6A0;
	case 192:
		goto loc_82C8E6A0;
	case 193:
		goto loc_82C8E6A0;
	case 194:
		goto loc_82C8E6A0;
	case 195:
		goto loc_82C8E6A0;
	case 196:
		goto loc_82C8E6A0;
	case 197:
		goto loc_82C8E6A0;
	case 198:
		goto loc_82C8E6A0;
	case 199:
		goto loc_82C8E6A0;
	case 200:
		goto loc_82C8E6A0;
	case 201:
		goto loc_82C8E6A0;
	case 202:
		goto loc_82C8E6A0;
	case 203:
		goto loc_82C8E6A0;
	case 204:
		goto loc_82C8E6A0;
	case 205:
		goto loc_82C8E6A0;
	case 206:
		goto loc_82C8E6A0;
	case 207:
		goto loc_82C8E6A0;
	case 208:
		goto loc_82C8E6A0;
	case 209:
		goto loc_82C8E6A0;
	case 210:
		goto loc_82C8E6A0;
	case 211:
		goto loc_82C8E6A0;
	case 212:
		goto loc_82C8E6A0;
	case 213:
		goto loc_82C8E6A0;
	case 214:
		goto loc_82C8E6A0;
	case 215:
		goto loc_82C8E6A0;
	case 216:
		goto loc_82C8E5F0;
	case 217:
		goto loc_82C8E5F0;
	case 218:
		goto loc_82C8E5F0;
	case 219:
		goto loc_82C8E5F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-6788(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6788);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6672(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
	// lwz r22,-6672(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
	// lwz r22,-6672(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
	// lwz r22,-6672(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
loc_82C8E57C:
	// clrlwi r3,r11,24
	ctx.r3.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r3,128
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 128, ctx.xer);
	// bge cr6,0x82c8e59c
	if (!ctx.cr6.lt) goto loc_82C8E59C;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r9,r7
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82c8e710
	if (ctx.cr6.eq) goto loc_82C8E710;
	// stb r11,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r11.u8);
	// b 0x82c8e6f8
	goto loc_82C8E6F8;
loc_82C8E59C:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r31,r3,r7
	ctx.r31.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r31,2
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 2, ctx.xer);
	// blt cr6,0x82c8e710
	if (ctx.cr6.lt) goto loc_82C8E710;
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// li r31,-64
	ctx.r31.s64 = -64;
	// rlwinm r29,r11,26,30,31
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3;
	// rlwimi r31,r9,2,26,29
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r9.u32, 2) & 0x3C) | (ctx.r31.u64 & 0xFFFFFFFFFFFFFFC3);
	// rlwimi r11,r8,7,0,25
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (ctx.r11.u64 & 0xFFFFFFFF0000003F);
	// extsb r9,r31
	ctx.r9.s64 = ctx.r31.s8;
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// or r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 | ctx.r29.u64;
	// stb r9,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// stb r31,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r31.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// stw r3,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r3.u32);
	// b 0x82c8e704
	goto loc_82C8E704;
loc_82C8E5F0:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r9,r3,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c8e710
	if (ctx.cr6.lt) goto loc_82C8E710;
	// rlwinm r9,r11,26,30,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3;
	// rlwinm r31,r31,2,28,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xC;
	// li r29,-128
	ctx.r29.s64 = -128;
	// or r9,r9,r31
	ctx.r9.u64 = ctx.r9.u64 | ctx.r31.u64;
	// rlwinm r31,r11,30,28,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0xF;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// li r28,-32
	ctx.r28.s64 = -32;
	// srawi r27,r9,2
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r27.s64 = ctx.r9.s32 >> 2;
	// rlwimi r29,r9,4,26,27
	ctx.r29.u64 = (__builtin_rotateleft32(ctx.r9.u32, 4) & 0x30) | (ctx.r29.u64 & 0xFFFFFFFFFFFFFFCF);
	// or r9,r27,r30
	ctx.r9.u64 = ctx.r27.u64 | ctx.r30.u64;
	// extsb r29,r29
	ctx.r29.s64 = ctx.r29.s8;
	// stb r9,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r9.u8);
	// rlwimi r28,r11,2,28,29
	ctx.r28.u64 = (__builtin_rotateleft32(ctx.r11.u32, 2) & 0xC) | (ctx.r28.u64 & 0xFFFFFFFFFFFFFFF3);
	// or r3,r31,r29
	ctx.r3.u64 = ctx.r31.u64 | ctx.r29.u64;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r9.u32);
	// stb r3,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// clrlwi r3,r3,30
	ctx.r3.u64 = ctx.r3.u32 & 0x3;
	// or r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 | ctx.r3.u64;
	// rlwinm r31,r9,26,6,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwimi r9,r8,7,0,25
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (ctx.r9.u64 & 0xFFFFFFFF0000003F);
	// extsb r3,r3
	ctx.r3.s64 = ctx.r3.s8;
	// or r3,r3,r31
	ctx.r3.u64 = ctx.r3.u64 | ctx.r31.u64;
	// stb r3,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// stb r9,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// stw r3,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r3.u32);
	// b 0x82c8e704
	goto loc_82C8E704;
loc_82C8E6A0:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r31,r3,r7
	ctx.r31.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r31,3
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 3, ctx.xer);
	// blt cr6,0x82c8e710
	if (ctx.cr6.lt) goto loc_82C8E710;
	// li r31,-32
	ctx.r31.s64 = -32;
	// li r29,-128
	ctx.r29.s64 = -128;
	// rlwimi r31,r9,28,28,31
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r9.u32, 28) & 0xF) | (ctx.r31.u64 & 0xFFFFFFFFFFFFFFF0);
	// rlwimi r29,r9,2,26,29
	ctx.r29.u64 = (__builtin_rotateleft32(ctx.r9.u32, 2) & 0x3C) | (ctx.r29.u64 & 0xFFFFFFFFFFFFFFC3);
	// stb r31,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r31.u8);
	// rlwinm r3,r11,26,30,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// addi r11,r9,1
	ctx.r11.s64 = ctx.r9.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// extsb r11,r29
	ctx.r11.s64 = ctx.r29.s8;
	// rlwimi r31,r8,7,0,25
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (ctx.r31.u64 & 0xFFFFFFFF0000003F);
	// or r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 | ctx.r3.u64;
	// stb r3,1(r9)
	PPC_STORE_U8(ctx.r9.u32 + 1, ctx.r3.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// stb r31,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r31.u8);
loc_82C8E6F8:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C8E704:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8e1e0
	if (!ctx.cr6.eq) goto loc_82C8E1E0;
loc_82C8E710:
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8E718"))) PPC_WEAK_FUNC(sub_82C8E718);
PPC_FUNC_IMPL(__imp__sub_82C8E718) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// subf r9,r10,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r10.s64;
	// subf r8,r11,r5
	ctx.r8.s64 = ctx.r5.s64 - ctx.r11.s64;
	// rlwinm r3,r9,0,0,30
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// cmpw cr6,r8,r3
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r3.s32, ctx.xer);
	// ble cr6,0x82c8e748
	if (!ctx.cr6.gt) goto loc_82C8E748;
	// lbz r10,-2(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + -2);
	// rlwinm r9,r10,0,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF8;
	// cmplwi cr6,r9,216
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 216, ctx.xer);
	// bne cr6,0x82c8e748
	if (!ctx.cr6.eq) goto loc_82C8E748;
	// addi r5,r5,-2
	ctx.r5.s64 = ctx.r5.s64 + -2;
loc_82C8E748:
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82C8E750:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r7.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rotlwi r3,r9,8
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r10,r3,r8
	ctx.r10.u64 = ctx.r3.u64 | ctx.r8.u64;
	// sth r10,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r8,r11,2
	ctx.r8.s64 = ctx.r11.s64 + 2;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// rotlwi r11,r3,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8e750
	if (!ctx.cr6.eq) goto loc_82C8E750;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8E7A0"))) PPC_WEAK_FUNC(sub_82C8E7A0);
PPC_FUNC_IMPL(__imp__sub_82C8E7A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e8ac
	if (ctx.cr6.eq) goto loc_82C8E8AC;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8e994
	if (!ctx.cr6.eq) goto loc_82C8E994;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,45
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 45, ctx.xer);
	// bne cr6,0x82c8e994
	if (!ctx.cr6.eq) goto loc_82C8E994;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e8ac
	if (ctx.cr6.eq) goto loc_82C8E8AC;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C8E7E0:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8e7fc
	if (!ctx.cr6.eq) goto loc_82C8E7FC;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8e804
	goto loc_82C8E804;
loc_82C8E7FC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8E804;
	sub_82C8DAE8(ctx, base);
loc_82C8E804:
	// cmplwi cr6,r3,27
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 27, ctx.xer);
	// bgt cr6,0x82c8e89c
	if (ctx.cr6.gt) goto loc_82C8E89C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-6108
	ctx.r12.s64 = ctx.r12.s64 + -6108;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8E964;
	case 1:
		goto loc_82C8E964;
	case 2:
		goto loc_82C8E89C;
	case 3:
		goto loc_82C8E89C;
	case 4:
		goto loc_82C8E89C;
	case 5:
		goto loc_82C8E894;
	case 6:
		goto loc_82C8E8C0;
	case 7:
		goto loc_82C8E8D4;
	case 8:
		goto loc_82C8E964;
	case 9:
		goto loc_82C8E89C;
	case 10:
		goto loc_82C8E89C;
	case 11:
		goto loc_82C8E89C;
	case 12:
		goto loc_82C8E89C;
	case 13:
		goto loc_82C8E89C;
	case 14:
		goto loc_82C8E89C;
	case 15:
		goto loc_82C8E89C;
	case 16:
		goto loc_82C8E89C;
	case 17:
		goto loc_82C8E89C;
	case 18:
		goto loc_82C8E89C;
	case 19:
		goto loc_82C8E89C;
	case 20:
		goto loc_82C8E89C;
	case 21:
		goto loc_82C8E89C;
	case 22:
		goto loc_82C8E89C;
	case 23:
		goto loc_82C8E89C;
	case 24:
		goto loc_82C8E89C;
	case 25:
		goto loc_82C8E89C;
	case 26:
		goto loc_82C8E89C;
	case 27:
		goto loc_82C8E8E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5788(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5788);
	// lwz r22,-5788(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5788);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5996(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5996);
	// lwz r22,-5952(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5952);
	// lwz r22,-5932(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5932);
	// lwz r22,-5788(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5788);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5912(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5912);
loc_82C8E894:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c8e950
	if (ctx.cr6.lt) goto loc_82C8E950;
loc_82C8E89C:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8E8A4:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8e7e0
	if (!ctx.cr6.eq) goto loc_82C8E7E0;
loc_82C8E8AC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E8C0:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c8e950
	if (ctx.cr6.lt) goto loc_82C8E950;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c8e8a4
	goto loc_82C8E8A4;
loc_82C8E8D4:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c8e950
	if (ctx.cr6.lt) goto loc_82C8E950;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c8e8a4
	goto loc_82C8E8A4;
loc_82C8E8E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e8ac
	if (ctx.cr6.eq) goto loc_82C8E8AC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8e8a4
	if (!ctx.cr6.eq) goto loc_82C8E8A4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,45
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 45, ctx.xer);
	// bne cr6,0x82c8e8a4
	if (!ctx.cr6.eq) goto loc_82C8E8A4;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e8ac
	if (ctx.cr6.eq) goto loc_82C8E8AC;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c8e97c
	if (!ctx.cr6.eq) goto loc_82C8E97C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c8e97c
	if (!ctx.cr6.eq) goto loc_82C8E97C;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,13
	ctx.r3.s64 = 13;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E950:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E964:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E97C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E994:
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8E9B0"))) PPC_WEAK_FUNC(sub_82C8E9B0);
PPC_FUNC_IMPL(__imp__sub_82C8E9B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8e9e0
	if (!ctx.cr6.eq) goto loc_82C8E9E0;
loc_82C8E9CC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E9E0:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8e9fc
	if (!ctx.cr6.eq) goto loc_82C8E9FC;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8ea04
	goto loc_82C8EA04;
loc_82C8E9FC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8EA04;
	sub_82C8DAE8(ctx, base);
loc_82C8EA04:
	// addi r11,r3,-20
	ctx.r11.s64 = ctx.r3.s64 + -20;
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// bgt cr6,0x82c8ec10
	if (ctx.cr6.gt) goto loc_82C8EC10;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-5592
	ctx.r12.s64 = ctx.r12.s64 + -5592;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8EA64;
	case 1:
		goto loc_82C8EC10;
	case 2:
		goto loc_82C8EA80;
	case 3:
		goto loc_82C8EC10;
	case 4:
		goto loc_82C8EA80;
	case 5:
		goto loc_82C8EC10;
	case 6:
		goto loc_82C8EC10;
	case 7:
		goto loc_82C8EA48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5532(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5532);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5504(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5504);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5504(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5504);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5560(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5560);
loc_82C8EA48:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8e7a0
	ctx.lr = 0x82C8EA54;
	sub_82C8E7A0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8EA64:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,33
	ctx.r3.s64 = 33;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8EA80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e9cc
	if (ctx.cr6.eq) goto loc_82C8E9CC;
loc_82C8EA8C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8eaa8
	if (!ctx.cr6.eq) goto loc_82C8EAA8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8eab0
	goto loc_82C8EAB0;
loc_82C8EAA8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8EAB0;
	sub_82C8DAE8(ctx, base);
loc_82C8EAB0:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c8ec10
	if (ctx.cr6.gt) goto loc_82C8EC10;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-5420
	ctx.r12.s64 = ctx.r12.s64 + -5420;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8EBF8;
	case 1:
		goto loc_82C8EBF8;
	case 2:
		goto loc_82C8EC10;
	case 3:
		goto loc_82C8EC10;
	case 4:
		goto loc_82C8EC10;
	case 5:
		goto loc_82C8EC10;
	case 6:
		goto loc_82C8EC10;
	case 7:
		goto loc_82C8EC10;
	case 8:
		goto loc_82C8EC10;
	case 9:
		goto loc_82C8EC10;
	case 10:
		goto loc_82C8EC10;
	case 11:
		goto loc_82C8EC10;
	case 12:
		goto loc_82C8EBF8;
	case 13:
		goto loc_82C8EB2C;
	case 14:
		goto loc_82C8EC10;
	case 15:
		goto loc_82C8EB2C;
	case 16:
		goto loc_82C8EC10;
	case 17:
		goto loc_82C8EC10;
	case 18:
		goto loc_82C8EC10;
	case 19:
		goto loc_82C8EC10;
	case 20:
		goto loc_82C8EC10;
	case 21:
		goto loc_82C8EB4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5332(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5332);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5332(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5332);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5300(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5300);
loc_82C8EB2C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8ea8c
	if (!ctx.cr6.eq) goto loc_82C8EA8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8EB4C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e9cc
	if (ctx.cr6.eq) goto loc_82C8E9CC;
	// lbz r3,3(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8eb74
	if (!ctx.cr6.eq) goto loc_82C8EB74;
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8eb7c
	goto loc_82C8EB7C;
loc_82C8EB74:
	// lbz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8EB7C;
	sub_82C8DAE8(ctx, base);
loc_82C8EB7C:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c8ebf8
	if (ctx.cr6.gt) goto loc_82C8EBF8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-5216
	ctx.r12.s64 = ctx.r12.s64 + -5216;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8EC10;
	case 1:
		goto loc_82C8EC10;
	case 2:
		goto loc_82C8EBF8;
	case 3:
		goto loc_82C8EBF8;
	case 4:
		goto loc_82C8EBF8;
	case 5:
		goto loc_82C8EBF8;
	case 6:
		goto loc_82C8EBF8;
	case 7:
		goto loc_82C8EBF8;
	case 8:
		goto loc_82C8EBF8;
	case 9:
		goto loc_82C8EBF8;
	case 10:
		goto loc_82C8EBF8;
	case 11:
		goto loc_82C8EBF8;
	case 12:
		goto loc_82C8EC10;
	case 13:
		goto loc_82C8EBF8;
	case 14:
		goto loc_82C8EBF8;
	case 15:
		goto loc_82C8EBF8;
	case 16:
		goto loc_82C8EBF8;
	case 17:
		goto loc_82C8EBF8;
	case 18:
		goto loc_82C8EBF8;
	case 19:
		goto loc_82C8EBF8;
	case 20:
		goto loc_82C8EBF8;
	case 21:
		goto loc_82C8EC10;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
loc_82C8EBF8:
	// li r3,16
	ctx.r3.s64 = 16;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8EC10:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8EC28"))) PPC_WEAK_FUNC(sub_82C8EC28);
PPC_FUNC_IMPL(__imp__sub_82C8EC28) {
	PPC_FUNC_PROLOGUE();
	// li r11,11
	ctx.r11.s64 = 11;
	// subf r10,r4,r5
	ctx.r10.s64 = ctx.r5.s64 - ctx.r4.s64;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// cmpwi cr6,r10,6
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 6, ctx.xer);
	// bne cr6,0x82c8ece0
	if (!ctx.cr6.eq) goto loc_82C8ECE0;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8ece0
	if (!ctx.cr6.eq) goto loc_82C8ECE0;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,88
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 88, ctx.xer);
	// beq cr6,0x82c8ec6c
	if (ctx.cr6.eq) goto loc_82C8EC6C;
	// cmpwi cr6,r11,120
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 120, ctx.xer);
	// beq cr6,0x82c8ec70
	if (ctx.cr6.eq) goto loc_82C8EC70;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C8EC6C:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C8EC70:
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c8ece0
	if (!ctx.cr6.eq) goto loc_82C8ECE0;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,77
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 77, ctx.xer);
	// beq cr6,0x82c8eca0
	if (ctx.cr6.eq) goto loc_82C8ECA0;
	// cmpwi cr6,r10,109
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 109, ctx.xer);
	// beq cr6,0x82c8eca4
	if (ctx.cr6.eq) goto loc_82C8ECA4;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C8ECA0:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C8ECA4:
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c8ece0
	if (!ctx.cr6.eq) goto loc_82C8ECE0;
	// lbz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,76
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 76, ctx.xer);
	// beq cr6,0x82c8ecd0
	if (ctx.cr6.eq) goto loc_82C8ECD0;
	// cmpwi cr6,r11,108
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 108, ctx.xer);
	// bne cr6,0x82c8ece0
	if (!ctx.cr6.eq) goto loc_82C8ECE0;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82c8ecd8
	if (ctx.cr6.eq) goto loc_82C8ECD8;
loc_82C8ECD0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8ECD8:
	// li r11,12
	ctx.r11.s64 = 12;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C8ECE0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8ECE8"))) PPC_WEAK_FUNC(sub_82C8ECE8);
PPC_FUNC_IMPL(__imp__sub_82C8ECE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C8ECF0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r31,r10
	ctx.r31.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c8ed1c
	if (!ctx.cr6.eq) goto loc_82C8ED1C;
loc_82C8ED10:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C8ED1C:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c8ed38
	if (!ctx.cr6.eq) goto loc_82C8ED38;
	// add r11,r4,r29
	ctx.r11.u64 = ctx.r4.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8ed40
	goto loc_82C8ED40;
loc_82C8ED38:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8ED40;
	sub_82C8DAE8(ctx, base);
loc_82C8ED40:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8f124
	if (ctx.cr6.gt) goto loc_82C8F124;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-4752
	ctx.r12.s64 = ctx.r12.s64 + -4752;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8F0E8;
	case 1:
		goto loc_82C8F100;
	case 2:
		goto loc_82C8F118;
	case 3:
		goto loc_82C8F124;
	case 4:
		goto loc_82C8F124;
	case 5:
		goto loc_82C8F124;
	case 6:
		goto loc_82C8F124;
	case 7:
		goto loc_82C8F124;
	case 8:
		goto loc_82C8F124;
	case 9:
		goto loc_82C8F124;
	case 10:
		goto loc_82C8F124;
	case 11:
		goto loc_82C8F124;
	case 12:
		goto loc_82C8F124;
	case 13:
		goto loc_82C8F124;
	case 14:
		goto loc_82C8F124;
	case 15:
		goto loc_82C8F124;
	case 16:
		goto loc_82C8F124;
	case 17:
		goto loc_82C8EE08;
	case 18:
		goto loc_82C8F124;
	case 19:
		goto loc_82C8EE08;
	case 20:
		goto loc_82C8F124;
	case 21:
		goto loc_82C8F124;
	case 22:
		goto loc_82C8F124;
	case 23:
		goto loc_82C8F124;
	case 24:
		goto loc_82C8EDD4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3864(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3864);
	// lwz r22,-3840(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3840);
	// lwz r22,-3816(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3816);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4600(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4600);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4600(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4600);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4652(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4652);
loc_82C8EDD4:
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r5,r4,27
	ctx.r5.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r6,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r5.u8 & 0x3F));
	// lbzx r3,r7,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r11.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r5,r7,r4
	ctx.r5.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82c8f124
	if (ctx.cr6.eq) goto loc_82C8F124;
loc_82C8EE08:
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c8ed10
	if (ctx.cr6.eq) goto loc_82C8ED10;
loc_82C8EE14:
	// lbz r10,1(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c8ee30
	if (!ctx.cr6.eq) goto loc_82C8EE30;
	// add r11,r4,r29
	ctx.r11.u64 = ctx.r4.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8ee38
	goto loc_82C8EE38;
loc_82C8EE30:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8EE38;
	sub_82C8DAE8(ctx, base);
loc_82C8EE38:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8ef0c
	if (ctx.cr6.gt) goto loc_82C8EF0C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-4516
	ctx.r12.s64 = ctx.r12.s64 + -4516;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8EF1C;
	case 1:
		goto loc_82C8EF34;
	case 2:
		goto loc_82C8EF4C;
	case 3:
		goto loc_82C8EF0C;
	case 4:
		goto loc_82C8EF64;
	case 5:
		goto loc_82C8EF64;
	case 6:
		goto loc_82C8EF0C;
	case 7:
		goto loc_82C8EF0C;
	case 8:
		goto loc_82C8EF0C;
	case 9:
		goto loc_82C8EF0C;
	case 10:
		goto loc_82C8F098;
	case 11:
		goto loc_82C8EF0C;
	case 12:
		goto loc_82C8EF0C;
	case 13:
		goto loc_82C8EF0C;
	case 14:
		goto loc_82C8EF0C;
	case 15:
		goto loc_82C8EF0C;
	case 16:
		goto loc_82C8EF64;
	case 17:
		goto loc_82C8EEF4;
	case 18:
		goto loc_82C8EF0C;
	case 19:
		goto loc_82C8EEF4;
	case 20:
		goto loc_82C8EEF4;
	case 21:
		goto loc_82C8EEF4;
	case 22:
		goto loc_82C8EEF4;
	case 23:
		goto loc_82C8EF0C;
	case 24:
		goto loc_82C8EEC0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-4324(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4324);
	// lwz r22,-4300(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4300);
	// lwz r22,-4276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4276);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4252);
	// lwz r22,-4252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4252);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-3944(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3944);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4252);
	// lwz r22,-4364(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4364(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4364(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4364(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4364(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4416(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4416);
loc_82C8EEC0:
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// addi r9,r8,1536
	ctx.r9.s64 = ctx.r8.s64 + 1536;
	// rlwinm r10,r4,27,29,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r6,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r11,r9
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r9.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// and r7,r9,r4
	ctx.r7.u64 = ctx.r9.u64 & ctx.r4.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c8ef0c
	if (ctx.cr6.eq) goto loc_82C8EF0C;
loc_82C8EEF4:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c8ee14
	if (!ctx.cr6.eq) goto loc_82C8EE14;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C8EF0C:
	// stw r5,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r5.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C8EF1C:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8ef0c
	if (!ctx.cr6.lt) goto loc_82C8EF0C;
loc_82C8EF28:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C8EF34:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c8ef0c
	if (!ctx.cr6.lt) goto loc_82C8EF0C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C8EF4C:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c8ef0c
	if (!ctx.cr6.lt) goto loc_82C8EF0C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C8EF64:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8ec28
	ctx.lr = 0x82C8EF74;
	sub_82C8EC28(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8ef0c
	if (ctx.cr6.eq) goto loc_82C8EF0C;
	// addi r10,r5,2
	ctx.r10.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c8ed10
	if (ctx.cr6.eq) goto loc_82C8ED10;
	// subf r9,r10,r30
	ctx.r9.s64 = ctx.r30.s64 - ctx.r10.s64;
loc_82C8EF8C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8efa8
	if (!ctx.cr6.eq) goto loc_82C8EFA8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8efb0
	goto loc_82C8EFB0;
loc_82C8EFA8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8EFB0;
	sub_82C8DAE8(ctx, base);
loc_82C8EFB0:
	// cmplwi cr6,r3,15
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 15, ctx.xer);
	// bgt cr6,0x82c8f018
	if (ctx.cr6.gt) goto loc_82C8F018;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-4144
	ctx.r12.s64 = ctx.r12.s64 + -4144;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8F124;
	case 1:
		goto loc_82C8F124;
	case 2:
		goto loc_82C8F018;
	case 3:
		goto loc_82C8F018;
	case 4:
		goto loc_82C8F018;
	case 5:
		goto loc_82C8F010;
	case 6:
		goto loc_82C8F034;
	case 7:
		goto loc_82C8F048;
	case 8:
		goto loc_82C8F124;
	case 9:
		goto loc_82C8F018;
	case 10:
		goto loc_82C8F018;
	case 11:
		goto loc_82C8F018;
	case 12:
		goto loc_82C8F018;
	case 13:
		goto loc_82C8F018;
	case 14:
		goto loc_82C8F018;
	case 15:
		goto loc_82C8F05C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4080(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4080);
	// lwz r22,-4044(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4044);
	// lwz r22,-4024(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4024);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4004(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4004);
loc_82C8F010:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c8ef28
	if (ctx.cr6.lt) goto loc_82C8EF28;
loc_82C8F018:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F020:
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c8ef8c
	if (!ctx.cr6.eq) goto loc_82C8EF8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C8F034:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c8ef28
	if (ctx.cr6.lt) goto loc_82C8EF28;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c8f020
	goto loc_82C8F020;
loc_82C8F048:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c8ef28
	if (ctx.cr6.lt) goto loc_82C8EF28;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c8f020
	goto loc_82C8F020;
loc_82C8F05C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c8ed10
	if (ctx.cr6.eq) goto loc_82C8ED10;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8f020
	if (!ctx.cr6.eq) goto loc_82C8F020;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c8f020
	if (!ctx.cr6.eq) goto loc_82C8F020;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C8F098:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8ec28
	ctx.lr = 0x82C8F0A8;
	sub_82C8EC28(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8ef0c
	if (ctx.cr6.eq) goto loc_82C8EF0C;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c8ed10
	if (ctx.cr6.eq) goto loc_82C8ED10;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8ef0c
	if (!ctx.cr6.eq) goto loc_82C8EF0C;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c8ef0c
	if (!ctx.cr6.eq) goto loc_82C8EF0C;
	// addi r11,r5,2
	ctx.r11.s64 = ctx.r5.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C8F0E8:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8f124
	if (!ctx.cr6.lt) goto loc_82C8F124;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C8F100:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c8f124
	if (!ctx.cr6.lt) goto loc_82C8F124;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C8F118:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8ef28
	if (ctx.cr6.lt) goto loc_82C8EF28;
loc_82C8F124:
	// stw r10,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C8F138"))) PPC_WEAK_FUNC(sub_82C8F138);
PPC_FUNC_IMPL(__imp__sub_82C8F138) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f168
	if (!ctx.cr6.eq) goto loc_82C8F168;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F168:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c8f19c
	if (ctx.cr6.eq) goto loc_82C8F19C;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8f198
	if (!ctx.cr6.eq) goto loc_82C8F198;
loc_82C8F184:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F198:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C8F19C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f1b8
	if (!ctx.cr6.eq) goto loc_82C8F1B8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f1c0
	goto loc_82C8F1C0;
loc_82C8F1B8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F1C0;
	sub_82C8DAE8(ctx, base);
loc_82C8F1C0:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c8f348
	if (ctx.cr6.gt) goto loc_82C8F348;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-3616
	ctx.r12.s64 = ctx.r12.s64 + -3616;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8F330;
	case 1:
		goto loc_82C8F330;
	case 2:
		goto loc_82C8F348;
	case 3:
		goto loc_82C8F348;
	case 4:
		goto loc_82C8F20C;
	case 5:
		goto loc_82C8F2E8;
	case 6:
		goto loc_82C8F308;
	case 7:
		goto loc_82C8F31C;
	case 8:
		goto loc_82C8F330;
	case 9:
		goto loc_82C8F278;
	case 10:
		goto loc_82C8F2CC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3280(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3280);
	// lwz r22,-3280(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3280);
	// lwz r22,-3256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3256);
	// lwz r22,-3256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3256);
	// lwz r22,-3572(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3572);
	// lwz r22,-3352(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3352);
	// lwz r22,-3320(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3320);
	// lwz r22,-3300(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3300);
	// lwz r22,-3280(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3280);
	// lwz r22,-3464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3464);
	// lwz r22,-3380(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3380);
loc_82C8F20C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f184
	if (ctx.cr6.eq) goto loc_82C8F184;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8f34c
	if (!ctx.cr6.eq) goto loc_82C8F34C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c8f34c
	if (!ctx.cr6.eq) goto loc_82C8F34C;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f184
	if (ctx.cr6.eq) goto loc_82C8F184;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c8f270
	if (!ctx.cr6.eq) goto loc_82C8F270;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c8f270
	if (!ctx.cr6.eq) goto loc_82C8F270;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,40
	ctx.r3.s64 = 40;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F270:
	// addi r10,r11,-2
	ctx.r10.s64 = ctx.r11.s64 + -2;
	// b 0x82c8f34c
	goto loc_82C8F34C;
loc_82C8F278:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f184
	if (ctx.cr6.eq) goto loc_82C8F184;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f2a0
	if (!ctx.cr6.eq) goto loc_82C8F2A0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f2a8
	goto loc_82C8F2A8;
loc_82C8F2A0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F2A8;
	sub_82C8DAE8(ctx, base);
loc_82C8F2A8:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c8f2b4
	if (!ctx.cr6.eq) goto loc_82C8F2B4;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F2B4:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F2CC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F2E8:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8f348
	if (!ctx.cr6.lt) goto loc_82C8F348;
loc_82C8F2F4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F308:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8f2f4
	if (ctx.cr6.lt) goto loc_82C8F2F4;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c8f34c
	goto loc_82C8F34C;
loc_82C8F31C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8f2f4
	if (ctx.cr6.lt) goto loc_82C8F2F4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c8f34c
	goto loc_82C8F34C;
loc_82C8F330:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F348:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F34C:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f3e0
	if (ctx.cr6.eq) goto loc_82C8F3E0;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C8F358:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f374
	if (!ctx.cr6.eq) goto loc_82C8F374;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f37c
	goto loc_82C8F37C;
loc_82C8F374:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F37C;
	sub_82C8DAE8(ctx, base);
loc_82C8F37C:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c8f3d0
	if (ctx.cr6.gt) goto loc_82C8F3D0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-3172
	ctx.r12.s64 = ctx.r12.s64 + -3172;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8F3E0;
	case 1:
		goto loc_82C8F3E0;
	case 2:
		goto loc_82C8F3D0;
	case 3:
		goto loc_82C8F3D0;
	case 4:
		goto loc_82C8F3E0;
	case 5:
		goto loc_82C8F3C8;
	case 6:
		goto loc_82C8F3F8;
	case 7:
		goto loc_82C8F40C;
	case 8:
		goto loc_82C8F3E0;
	case 9:
		goto loc_82C8F3E0;
	case 10:
		goto loc_82C8F3E0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3120(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3120);
	// lwz r22,-3120(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3120);
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3128);
	// lwz r22,-3080(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3080);
	// lwz r22,-3060(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3060);
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
loc_82C8F3C8:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c8f3e0
	if (ctx.cr6.lt) goto loc_82C8F3E0;
loc_82C8F3D0:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F3D8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f358
	if (!ctx.cr6.eq) goto loc_82C8F358;
loc_82C8F3E0:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F3F8:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c8f3e0
	if (ctx.cr6.lt) goto loc_82C8F3E0;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c8f3d8
	goto loc_82C8F3D8;
loc_82C8F40C:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c8f3e0
	if (ctx.cr6.lt) goto loc_82C8F3E0;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c8f3d8
	goto loc_82C8F3D8;
}

__attribute__((alias("__imp__sub_82C8F420"))) PPC_WEAK_FUNC(sub_82C8F420);
PPC_FUNC_IMPL(__imp__sub_82C8F420) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f44c
	if (!ctx.cr6.eq) goto loc_82C8F44C;
loc_82C8F444:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F44C:
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c8f468
	if (!ctx.cr6.eq) goto loc_82C8F468;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f470
	goto loc_82C8F470;
loc_82C8F468:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F470;
	sub_82C8DAE8(ctx, base);
loc_82C8F470:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8f720
	if (ctx.cr6.gt) goto loc_82C8F720;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r7,r9,-4144
	ctx.r7.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-2912
	ctx.r12.s64 = ctx.r12.s64 + -2912;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8F638;
	case 1:
		goto loc_82C8F64C;
	case 2:
		goto loc_82C8F70C;
	case 3:
		goto loc_82C8F720;
	case 4:
		goto loc_82C8F720;
	case 5:
		goto loc_82C8F720;
	case 6:
		goto loc_82C8F720;
	case 7:
		goto loc_82C8F720;
	case 8:
		goto loc_82C8F720;
	case 9:
		goto loc_82C8F720;
	case 10:
		goto loc_82C8F720;
	case 11:
		goto loc_82C8F720;
	case 12:
		goto loc_82C8F720;
	case 13:
		goto loc_82C8F720;
	case 14:
		goto loc_82C8F720;
	case 15:
		goto loc_82C8F720;
	case 16:
		goto loc_82C8F720;
	case 17:
		goto loc_82C8F538;
	case 18:
		goto loc_82C8F720;
	case 19:
		goto loc_82C8F538;
	case 20:
		goto loc_82C8F720;
	case 21:
		goto loc_82C8F720;
	case 22:
		goto loc_82C8F720;
	case 23:
		goto loc_82C8F720;
	case 24:
		goto loc_82C8F504;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-2504(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2504);
	// lwz r22,-2484(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2484);
	// lwz r22,-2292(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2292);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2760(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2760);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2760(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2760);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2812(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2812);
loc_82C8F504:
	// clrlwi r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	// addi r11,r7,1280
	ctx.r11.s64 = ctx.r7.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r8,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r11.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r8,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c8f720
	if (ctx.cr6.eq) goto loc_82C8F720;
loc_82C8F538:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f444
	if (ctx.cr6.eq) goto loc_82C8F444;
loc_82C8F544:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c8f560
	if (!ctx.cr6.eq) goto loc_82C8F560;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f568
	goto loc_82C8F568;
loc_82C8F560:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F568;
	sub_82C8DAE8(ctx, base);
loc_82C8F568:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8f720
	if (ctx.cr6.gt) goto loc_82C8F720;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-2676
	ctx.r12.s64 = ctx.r12.s64 + -2676;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8F638;
	case 1:
		goto loc_82C8F64C;
	case 2:
		goto loc_82C8F70C;
	case 3:
		goto loc_82C8F720;
	case 4:
		goto loc_82C8F660;
	case 5:
		goto loc_82C8F660;
	case 6:
		goto loc_82C8F6FC;
	case 7:
		goto loc_82C8F720;
	case 8:
		goto loc_82C8F720;
	case 9:
		goto loc_82C8F720;
	case 10:
		goto loc_82C8F720;
	case 11:
		goto loc_82C8F720;
	case 12:
		goto loc_82C8F720;
	case 13:
		goto loc_82C8F720;
	case 14:
		goto loc_82C8F720;
	case 15:
		goto loc_82C8F720;
	case 16:
		goto loc_82C8F660;
	case 17:
		goto loc_82C8F624;
	case 18:
		goto loc_82C8F624;
	case 19:
		goto loc_82C8F624;
	case 20:
		goto loc_82C8F624;
	case 21:
		goto loc_82C8F624;
	case 22:
		goto loc_82C8F624;
	case 23:
		goto loc_82C8F720;
	case 24:
		goto loc_82C8F5F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-2504(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2504);
	// lwz r22,-2484(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2484);
	// lwz r22,-2292(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2292);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2464);
	// lwz r22,-2464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2464);
	// lwz r22,-2308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2308);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2464);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2576(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2576);
loc_82C8F5F0:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r8,r7,1536
	ctx.r8.s64 = ctx.r7.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r8
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r8,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c8f720
	if (ctx.cr6.eq) goto loc_82C8F720;
loc_82C8F624:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f544
	if (!ctx.cr6.eq) goto loc_82C8F544;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F638:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8f720
	if (!ctx.cr6.lt) goto loc_82C8F720;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F64C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c8f720
	if (!ctx.cr6.lt) goto loc_82C8F720;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F660:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f444
	if (ctx.cr6.eq) goto loc_82C8F444;
loc_82C8F66C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f688
	if (!ctx.cr6.eq) goto loc_82C8F688;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f690
	goto loc_82C8F690;
loc_82C8F688:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F690;
	sub_82C8DAE8(ctx, base);
loc_82C8F690:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bgt cr6,0x82c8f720
	if (ctx.cr6.gt) goto loc_82C8F720;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-2380
	ctx.r12.s64 = ctx.r12.s64 + -2380;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8F6E8;
	case 1:
		goto loc_82C8F6E8;
	case 2:
		goto loc_82C8F6FC;
	case 3:
		goto loc_82C8F720;
	case 4:
		goto loc_82C8F720;
	case 5:
		goto loc_82C8F720;
	case 6:
		goto loc_82C8F720;
	case 7:
		goto loc_82C8F720;
	case 8:
		goto loc_82C8F720;
	case 9:
		goto loc_82C8F720;
	case 10:
		goto loc_82C8F720;
	case 11:
		goto loc_82C8F720;
	case 12:
		goto loc_82C8F6E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-2328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2328);
	// lwz r22,-2328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2328);
	// lwz r22,-2308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2308);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2328);
loc_82C8F6E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f66c
	if (!ctx.cr6.eq) goto loc_82C8F66C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F6FC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,5
	ctx.r3.s64 = 5;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F70C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c8f720
	if (!ctx.cr6.lt) goto loc_82C8F720;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F720:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C8F728:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8F740"))) PPC_WEAK_FUNC(sub_82C8F740);
PPC_FUNC_IMPL(__imp__sub_82C8F740) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f7e4
	if (ctx.cr6.eq) goto loc_82C8F7E4;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f778
	if (!ctx.cr6.eq) goto loc_82C8F778;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f780
	goto loc_82C8F780;
loc_82C8F778:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F780;
	sub_82C8DAE8(ctx, base);
loc_82C8F780:
	// cmpwi cr6,r3,24
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 24, ctx.xer);
	// blt cr6,0x82c8f814
	if (ctx.cr6.lt) goto loc_82C8F814;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bgt cr6,0x82c8f814
	if (ctx.cr6.gt) goto loc_82C8F814;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f7e4
	if (ctx.cr6.eq) goto loc_82C8F7E4;
loc_82C8F79C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f7b8
	if (!ctx.cr6.eq) goto loc_82C8F7B8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f7c0
	goto loc_82C8F7C0;
loc_82C8F7B8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F7C0;
	sub_82C8DAE8(ctx, base);
loc_82C8F7C0:
	// cmpwi cr6,r3,18
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 18, ctx.xer);
	// beq cr6,0x82c8f7f8
	if (ctx.cr6.eq) goto loc_82C8F7F8;
	// cmpwi cr6,r3,23
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 23, ctx.xer);
	// ble cr6,0x82c8f814
	if (!ctx.cr6.gt) goto loc_82C8F814;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bgt cr6,0x82c8f814
	if (ctx.cr6.gt) goto loc_82C8F814;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f79c
	if (!ctx.cr6.eq) goto loc_82C8F79C;
loc_82C8F7E4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F7F8:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F814:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8F830"))) PPC_WEAK_FUNC(sub_82C8F830);
PPC_FUNC_IMPL(__imp__sub_82C8F830) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f910
	if (ctx.cr6.eq) goto loc_82C8F910;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// extsb r11,r3
	ctx.r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c8f89c
	if (!ctx.cr6.eq) goto loc_82C8F89C;
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,120
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 120, ctx.xer);
	// bne cr6,0x82c8f884
	if (!ctx.cr6.eq) goto loc_82C8F884;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8f740
	ctx.lr = 0x82C8F874;
	sub_82C8F740(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F884:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c8f89c
	if (!ctx.cr6.eq) goto loc_82C8F89C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f8a4
	goto loc_82C8F8A4;
loc_82C8F89C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F8A4;
	sub_82C8DAE8(ctx, base);
loc_82C8F8A4:
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// beq cr6,0x82c8f8c4
	if (ctx.cr6.eq) goto loc_82C8F8C4;
loc_82C8F8AC:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F8C4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f910
	if (ctx.cr6.eq) goto loc_82C8F910;
loc_82C8F8D0:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f8ec
	if (!ctx.cr6.eq) goto loc_82C8F8EC;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f8f4
	goto loc_82C8F8F4;
loc_82C8F8EC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F8F4;
	sub_82C8DAE8(ctx, base);
loc_82C8F8F4:
	// cmpwi cr6,r3,18
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 18, ctx.xer);
	// beq cr6,0x82c8f924
	if (ctx.cr6.eq) goto loc_82C8F924;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bne cr6,0x82c8f8ac
	if (!ctx.cr6.eq) goto loc_82C8F8AC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f8d0
	if (!ctx.cr6.eq) goto loc_82C8F8D0;
loc_82C8F910:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F924:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8F940"))) PPC_WEAK_FUNC(sub_82C8F940);
PPC_FUNC_IMPL(__imp__sub_82C8F940) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f96c
	if (!ctx.cr6.eq) goto loc_82C8F96C;
loc_82C8F964:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8F96C:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c8f988
	if (!ctx.cr6.eq) goto loc_82C8F988;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f990
	goto loc_82C8F990;
loc_82C8F988:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F990;
	sub_82C8DAE8(ctx, base);
loc_82C8F990:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8fbb4
	if (ctx.cr6.gt) goto loc_82C8FBB4;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-1600
	ctx.r12.s64 = ctx.r12.s64 + -1600;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8FB58;
	case 1:
		goto loc_82C8FB6C;
	case 2:
		goto loc_82C8FB80;
	case 3:
		goto loc_82C8FBB4;
	case 4:
		goto loc_82C8FBB4;
	case 5:
		goto loc_82C8FBB4;
	case 6:
		goto loc_82C8FBB4;
	case 7:
		goto loc_82C8FBB4;
	case 8:
		goto loc_82C8FBB4;
	case 9:
		goto loc_82C8FBB4;
	case 10:
		goto loc_82C8FBB4;
	case 11:
		goto loc_82C8FBB4;
	case 12:
		goto loc_82C8FBB4;
	case 13:
		goto loc_82C8FBB4;
	case 14:
		goto loc_82C8FBA4;
	case 15:
		goto loc_82C8FBB4;
	case 16:
		goto loc_82C8FBB4;
	case 17:
		goto loc_82C8FA58;
	case 18:
		goto loc_82C8FBB4;
	case 19:
		goto loc_82C8FA58;
	case 20:
		goto loc_82C8FBB4;
	case 21:
		goto loc_82C8FBB4;
	case 22:
		goto loc_82C8FBB4;
	case 23:
		goto loc_82C8FBB4;
	case 24:
		goto loc_82C8FA24;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-1192(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1192);
	// lwz r22,-1172(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1172);
	// lwz r22,-1152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1152);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1116(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1116);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1448(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1448);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1448(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1448);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1500);
loc_82C8FA24:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r7,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r11.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c8fbb4
	if (ctx.cr6.eq) goto loc_82C8FBB4;
loc_82C8FA58:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f964
	if (ctx.cr6.eq) goto loc_82C8F964;
loc_82C8FA64:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c8fa80
	if (!ctx.cr6.eq) goto loc_82C8FA80;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fa88
	goto loc_82C8FA88;
loc_82C8FA80:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FA88;
	sub_82C8DAE8(ctx, base);
loc_82C8FA88:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8fbb4
	if (ctx.cr6.gt) goto loc_82C8FBB4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-1364
	ctx.r12.s64 = ctx.r12.s64 + -1364;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8FB58;
	case 1:
		goto loc_82C8FB6C;
	case 2:
		goto loc_82C8FB80;
	case 3:
		goto loc_82C8FBB4;
	case 4:
		goto loc_82C8FBB4;
	case 5:
		goto loc_82C8FBB4;
	case 6:
		goto loc_82C8FBB4;
	case 7:
		goto loc_82C8FBB4;
	case 8:
		goto loc_82C8FBB4;
	case 9:
		goto loc_82C8FBB4;
	case 10:
		goto loc_82C8FBB4;
	case 11:
		goto loc_82C8FBB4;
	case 12:
		goto loc_82C8FBB4;
	case 13:
		goto loc_82C8FB94;
	case 14:
		goto loc_82C8FBB4;
	case 15:
		goto loc_82C8FBB4;
	case 16:
		goto loc_82C8FBB4;
	case 17:
		goto loc_82C8FB44;
	case 18:
		goto loc_82C8FBB4;
	case 19:
		goto loc_82C8FB44;
	case 20:
		goto loc_82C8FB44;
	case 21:
		goto loc_82C8FB44;
	case 22:
		goto loc_82C8FB44;
	case 23:
		goto loc_82C8FBB4;
	case 24:
		goto loc_82C8FB10;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-1192(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1192);
	// lwz r22,-1172(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1172);
	// lwz r22,-1152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1152);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1132(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1132);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1212(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1212(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1212(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1212(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1212(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1264(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1264);
loc_82C8FB10:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c8fbb4
	if (ctx.cr6.eq) goto loc_82C8FBB4;
loc_82C8FB44:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8fa64
	if (!ctx.cr6.eq) goto loc_82C8FA64;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB58:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8fbb4
	if (!ctx.cr6.lt) goto loc_82C8FBB4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB6C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c8fbb4
	if (!ctx.cr6.lt) goto loc_82C8FBB4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB80:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c8fbb4
	if (!ctx.cr6.lt) goto loc_82C8FBB4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB94:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,9
	ctx.r3.s64 = 9;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FBA4:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8f830
	ctx.lr = 0x82C8FBB0;
	sub_82C8F830(ctx, base);
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FBB4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C8FBBC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8FBD8"))) PPC_WEAK_FUNC(sub_82C8FBD8);
PPC_FUNC_IMPL(__imp__sub_82C8FBD8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C8FBE0;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r27,1
	ctx.r27.s64 = 1;
	// addi r29,r11,-4144
	ctx.r29.s64 = ctx.r11.s64 + -4144;
loc_82C8FC08:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c8fc24
	if (!ctx.cr6.eq) goto loc_82C8FC24;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fc2c
	goto loc_82C8FC2C;
loc_82C8FC24:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FC2C;
	sub_82C8DAE8(ctx, base);
loc_82C8FC2C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8fe30
	if (ctx.cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-944
	ctx.r12.s64 = ctx.r12.s64 + -944;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90118;
	case 1:
		goto loc_82C90130;
	case 2:
		goto loc_82C90148;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C8FDE0;
	case 5:
		goto loc_82C8FDE0;
	case 6:
		goto loc_82C8FE30;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C8FE30;
	case 9:
		goto loc_82C8FE40;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C8FE30;
	case 13:
		goto loc_82C8FE30;
	case 14:
		goto loc_82C8FE30;
	case 15:
		goto loc_82C8FE30;
	case 16:
		goto loc_82C8FDE0;
	case 17:
		goto loc_82C90100;
	case 18:
		goto loc_82C8FCE8;
	case 19:
		goto loc_82C90100;
	case 20:
		goto loc_82C90100;
	case 21:
		goto loc_82C90100;
	case 22:
		goto loc_82C90100;
	case 23:
		goto loc_82C8FE30;
	case 24:
		goto loc_82C8FCB4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 280);
	// lwz r22,304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 304);
	// lwz r22,328(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-544(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -544);
	// lwz r22,-544(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -544);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-448(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -448);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-544(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -544);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-792(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -792);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-844(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -844);
loc_82C8FCB4:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r8,r29,1536
	ctx.r8.s64 = ctx.r29.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r6,r27,r7
	ctx.r6.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r29
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// and r8,r9,r6
	ctx.r8.u64 = ctx.r9.u64 & ctx.r6.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// b 0x82c900fc
	goto loc_82C900FC;
loc_82C8FCE8:
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne cr6,0x82c8fe30
	if (!ctx.cr6.eq) goto loc_82C8FE30;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r28,r27
	ctx.r28.u64 = ctx.r27.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c8fd1c
	if (!ctx.cr6.eq) goto loc_82C8FD1C;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fd24
	goto loc_82C8FD24;
loc_82C8FD1C:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FD24;
	sub_82C8DAE8(ctx, base);
loc_82C8FD24:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8fe30
	if (ctx.cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-696
	ctx.r12.s64 = ctx.r12.s64 + -696;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90118;
	case 1:
		goto loc_82C90130;
	case 2:
		goto loc_82C90148;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C8FE30;
	case 5:
		goto loc_82C8FE30;
	case 6:
		goto loc_82C8FE30;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C8FE30;
	case 9:
		goto loc_82C8FE30;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C8FE30;
	case 13:
		goto loc_82C8FE30;
	case 14:
		goto loc_82C8FE30;
	case 15:
		goto loc_82C8FE30;
	case 16:
		goto loc_82C8FE30;
	case 17:
		goto loc_82C90100;
	case 18:
		goto loc_82C8FE30;
	case 19:
		goto loc_82C90100;
	case 20:
		goto loc_82C8FE30;
	case 21:
		goto loc_82C8FE30;
	case 22:
		goto loc_82C8FE30;
	case 23:
		goto loc_82C8FE30;
	case 24:
		goto loc_82C8FDAC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 280);
	// lwz r22,304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 304);
	// lwz r22,328(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-596(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -596);
loc_82C8FDAC:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r8,r29,1280
	ctx.r8.s64 = ctx.r29.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r6,r27,r7
	ctx.r6.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r29
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// and r8,r9,r6
	ctx.r8.u64 = ctx.r9.u64 & ctx.r6.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// b 0x82c900fc
	goto loc_82C900FC;
loc_82C8FDE0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8fe08
	if (!ctx.cr6.eq) goto loc_82C8FE08;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fe10
	goto loc_82C8FE10;
loc_82C8FE08:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FE10;
	sub_82C8DAE8(ctx, base);
loc_82C8FE10:
	// cmpwi cr6,r3,14
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 14, ctx.xer);
	// beq cr6,0x82c8fe40
	if (ctx.cr6.eq) goto loc_82C8FE40;
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// blt cr6,0x82c8fe30
	if (ctx.cr6.lt) goto loc_82C8FE30;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// ble cr6,0x82c8fde0
	if (!ctx.cr6.gt) goto loc_82C8FDE0;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// beq cr6,0x82c8fde0
	if (ctx.cr6.eq) goto loc_82C8FDE0;
loc_82C8FE30:
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8FE40:
	// li r28,0
	ctx.r28.s64 = 0;
loc_82C8FE44:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8fe6c
	if (!ctx.cr6.eq) goto loc_82C8FE6C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r31,76(r11)
	ctx.r31.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fe78
	goto loc_82C8FE78;
loc_82C8FE6C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FE74;
	sub_82C8DAE8(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
loc_82C8FE78:
	// cmpwi cr6,r31,12
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 12, ctx.xer);
	// beq cr6,0x82c8feb0
	if (ctx.cr6.eq) goto loc_82C8FEB0;
	// cmpwi cr6,r31,13
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 13, ctx.xer);
	// beq cr6,0x82c8feb0
	if (ctx.cr6.eq) goto loc_82C8FEB0;
	// cmpwi cr6,r31,9
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 9, ctx.xer);
	// blt cr6,0x82c8fe30
	if (ctx.cr6.lt) goto loc_82C8FE30;
	// cmpwi cr6,r31,10
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 10, ctx.xer);
	// ble cr6,0x82c8fe44
	if (!ctx.cr6.gt) goto loc_82C8FE44;
	// cmpwi cr6,r31,21
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 21, ctx.xer);
	// beq cr6,0x82c8fe44
	if (ctx.cr6.eq) goto loc_82C8FE44;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C8FEB0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8FEB4:
	// stw r10,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r10.u32);
loc_82C8FEB8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8fedc
	if (!ctx.cr6.eq) goto loc_82C8FEDC;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fee4
	goto loc_82C8FEE4;
loc_82C8FEDC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FEE4;
	sub_82C8DAE8(ctx, base);
loc_82C8FEE4:
	// cmpw cr6,r3,r31
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r31.s32, ctx.xer);
	// beq cr6,0x82c8ff88
	if (ctx.cr6.eq) goto loc_82C8FF88;
	// cmplwi cr6,r3,8
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 8, ctx.xer);
	// bgt cr6,0x82c8feb0
	if (ctx.cr6.gt) goto loc_82C8FEB0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-244
	ctx.r12.s64 = ctx.r12.s64 + -244;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8FE30;
	case 1:
		goto loc_82C8FE30;
	case 2:
		goto loc_82C8FE30;
	case 3:
		goto loc_82C8FF68;
	case 4:
		goto loc_82C8FEB0;
	case 5:
		goto loc_82C8FF30;
	case 6:
		goto loc_82C8FF40;
	case 7:
		goto loc_82C8FF54;
	case 8:
		goto loc_82C8FE30;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -152);
	// lwz r22,-336(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -336);
	// lwz r22,-208(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -208);
	// lwz r22,-192(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -192);
	// lwz r22,-172(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -172);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
loc_82C8FF30:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// blt cr6,0x82c90124
	if (ctx.cr6.lt) goto loc_82C90124;
	// b 0x82c8feb0
	goto loc_82C8FEB0;
loc_82C8FF40:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c90124
	if (ctx.cr6.lt) goto loc_82C90124;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c8feb4
	goto loc_82C8FEB4;
loc_82C8FF54:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c90124
	if (ctx.cr6.lt) goto loc_82C90124;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c8feb4
	goto loc_82C8FEB4;
loc_82C8FF68:
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8f940
	ctx.lr = 0x82C8FF78;
	sub_82C8F940(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// ble cr6,0x82c901bc
	if (!ctx.cr6.gt) goto loc_82C901BC;
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// b 0x82c8feb8
	goto loc_82C8FEB8;
loc_82C8FF88:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8ffb0
	if (!ctx.cr6.eq) goto loc_82C8FFB0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8ffb8
	goto loc_82C8FFB8;
loc_82C8FFB0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FFB8;
	sub_82C8DAE8(ctx, base);
loc_82C8FFB8:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bgt cr6,0x82c8fe30
	if (ctx.cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-36
	ctx.r12.s64 = ctx.r12.s64 + -36;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90010;
	case 1:
		goto loc_82C90010;
	case 2:
		goto loc_82C901A8;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C8FE30;
	case 5:
		goto loc_82C8FE30;
	case 6:
		goto loc_82C8FE30;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C90160;
	case 9:
		goto loc_82C8FE30;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C90010;
	default:
		__builtin_unreachable();
	}
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,424(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 424);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 352);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_82C90010:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c90038
	if (!ctx.cr6.eq) goto loc_82C90038;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90040
	goto loc_82C90040;
loc_82C90038:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C90040;
	sub_82C8DAE8(ctx, base);
loc_82C90040:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8fe30
	if (ctx.cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,100
	ctx.r12.s64 = ctx.r12.s64 + 100;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90118;
	case 1:
		goto loc_82C90130;
	case 2:
		goto loc_82C90148;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C90010;
	case 5:
		goto loc_82C90010;
	case 6:
		goto loc_82C901A8;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C8FE30;
	case 9:
		goto loc_82C8FE30;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C90160;
	case 13:
		goto loc_82C8FE30;
	case 14:
		goto loc_82C8FE30;
	case 15:
		goto loc_82C8FE30;
	case 16:
		goto loc_82C90010;
	case 17:
		goto loc_82C90100;
	case 18:
		goto loc_82C8FE30;
	case 19:
		goto loc_82C90100;
	case 20:
		goto loc_82C8FE30;
	case 21:
		goto loc_82C8FE30;
	case 22:
		goto loc_82C8FE30;
	case 23:
		goto loc_82C8FE30;
	case 24:
		goto loc_82C900C8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 280);
	// lwz r22,304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 304);
	// lwz r22,328(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,424(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 424);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 352);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,200(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 200);
loc_82C900C8:
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r8,r29,1280
	ctx.r8.s64 = ctx.r29.s64 + 1280;
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r7,27
	ctx.r6.u64 = ctx.r7.u32 & 0x1F;
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// slw r3,r27,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r6.u8 & 0x3F));
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r29.u32);
	// and r7,r8,r3
	ctx.r7.u64 = ctx.r8.u64 & ctx.r3.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
loc_82C900FC:
	// beq cr6,0x82c8fe30
	if (ctx.cr6.eq) goto loc_82C8FE30;
loc_82C90100:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8fc08
	if (!ctx.cr6.eq) goto loc_82C8FC08;
loc_82C9010C:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82C90110:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C90118:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8fe30
	if (!ctx.cr6.lt) goto loc_82C8FE30;
loc_82C90124:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C90130:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c8fe30
	if (!ctx.cr6.lt) goto loc_82C8FE30;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C90148:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c8fe30
	if (!ctx.cr6.lt) goto loc_82C8FE30;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C90160:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c90198
	if (!ctx.cr6.eq) goto loc_82C90198;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c90198
	if (!ctx.cr6.eq) goto loc_82C90198;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,3
	ctx.r3.s64 = 3;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C90198:
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C901A8:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C901BC:
	// bne cr6,0x82c90110
	if (!ctx.cr6.eq) goto loc_82C90110;
	// lwz r11,172(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C901D0"))) PPC_WEAK_FUNC(sub_82C901D0);
PPC_FUNC_IMPL(__imp__sub_82C901D0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c901fc
	if (!ctx.cr6.eq) goto loc_82C901FC;
loc_82C901F4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C901FC:
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c90218
	if (!ctx.cr6.eq) goto loc_82C90218;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90220
	goto loc_82C90220;
loc_82C90218:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C90220;
	sub_82C8DAE8(ctx, base);
loc_82C90220:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c90728
	if (ctx.cr6.gt) goto loc_82C90728;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r7,r9,-4144
	ctx.r7.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,592
	ctx.r12.s64 = ctx.r12.s64 + 592;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C90728;
	case 5:
		goto loc_82C90728;
	case 6:
		goto loc_82C90728;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90708;
	case 11:
		goto loc_82C90654;
	case 12:
		goto loc_82C90718;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C90728;
	case 17:
		goto loc_82C902E8;
	case 18:
		goto loc_82C90728;
	case 19:
		goto loc_82C902E8;
	case 20:
		goto loc_82C90728;
	case 21:
		goto loc_82C90728;
	case 22:
		goto loc_82C90728;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C902B4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1800);
	// lwz r22,1620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1620);
	// lwz r22,1816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1816);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 744);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 744);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 692);
loc_82C902B4:
	// clrlwi r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	// addi r11,r7,1280
	ctx.r11.s64 = ctx.r7.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r8,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r11.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r8,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c90728
	if (ctx.cr6.eq) goto loc_82C90728;
loc_82C902E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c901f4
	if (ctx.cr6.eq) goto loc_82C901F4;
loc_82C902F8:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c90314
	if (!ctx.cr6.eq) goto loc_82C90314;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9031c
	goto loc_82C9031C;
loc_82C90314:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C9031C;
	sub_82C8DAE8(ctx, base);
loc_82C9031C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c90728
	if (ctx.cr6.gt) goto loc_82C90728;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,832
	ctx.r12.s64 = ctx.r12.s64 + 832;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C904F4;
	case 5:
		goto loc_82C904F4;
	case 6:
		goto loc_82C90608;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90728;
	case 11:
		goto loc_82C90728;
	case 12:
		goto loc_82C90618;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C904F4;
	case 17:
		goto loc_82C904A4;
	case 18:
		goto loc_82C903AC;
	case 19:
		goto loc_82C904A4;
	case 20:
		goto loc_82C904A4;
	case 21:
		goto loc_82C904A4;
	case 22:
		goto loc_82C904A4;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C903A4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1268(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1268);
	// lwz r22,1268(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1268);
	// lwz r22,1544(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1544);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1560(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1560);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1268(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1268);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,940(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 940);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,932(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 932);
loc_82C903A4:
	// addi r3,r7,1536
	ctx.r3.s64 = ctx.r7.s64 + 1536;
	// b 0x82c90474
	goto loc_82C90474;
loc_82C903AC:
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne cr6,0x82c90728
	if (!ctx.cr6.eq) goto loc_82C90728;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r8,r31
	ctx.r8.u64 = ctx.r31.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c901f4
	if (ctx.cr6.eq) goto loc_82C901F4;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c903e0
	if (!ctx.cr6.eq) goto loc_82C903E0;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c903e8
	goto loc_82C903E8;
loc_82C903E0:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C903E8;
	sub_82C8DAE8(ctx, base);
loc_82C903E8:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c90728
	if (ctx.cr6.gt) goto loc_82C90728;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,1036
	ctx.r12.s64 = ctx.r12.s64 + 1036;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C90728;
	case 5:
		goto loc_82C90728;
	case 6:
		goto loc_82C90728;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90728;
	case 11:
		goto loc_82C90728;
	case 12:
		goto loc_82C90728;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C90728;
	case 17:
		goto loc_82C904A4;
	case 18:
		goto loc_82C90728;
	case 19:
		goto loc_82C904A4;
	case 20:
		goto loc_82C90728;
	case 21:
		goto loc_82C90728;
	case 22:
		goto loc_82C90728;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C90470;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1136);
loc_82C90470:
	// addi r3,r7,1280
	ctx.r3.s64 = ctx.r7.s64 + 1280;
loc_82C90474:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r4
	ctx.r4.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r3,r11,r3
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r3.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r9,r7
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// and r11,r3,r4
	ctx.r11.u64 = ctx.r3.u64 & ctx.r4.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c90728
	if (ctx.cr6.eq) goto loc_82C90728;
loc_82C904A4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c902f8
	if (!ctx.cr6.eq) goto loc_82C902F8;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904B8:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c90728
	if (!ctx.cr6.lt) goto loc_82C90728;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904CC:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c90728
	if (!ctx.cr6.lt) goto loc_82C90728;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904E0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c90728
	if (!ctx.cr6.lt) goto loc_82C90728;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904F4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c901f4
	if (ctx.cr6.eq) goto loc_82C901F4;
loc_82C90500:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9051c
	if (!ctx.cr6.eq) goto loc_82C9051C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90524
	goto loc_82C90524;
loc_82C9051C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C90524;
	sub_82C8DAE8(ctx, base);
loc_82C90524:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c90728
	if (ctx.cr6.gt) goto loc_82C90728;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,1352
	ctx.r12.s64 = ctx.r12.s64 + 1352;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C905AC;
	case 5:
		goto loc_82C905AC;
	case 6:
		goto loc_82C90608;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90728;
	case 11:
		goto loc_82C90728;
	case 12:
		goto loc_82C90618;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C905AC;
	case 17:
		goto loc_82C905F8;
	case 18:
		goto loc_82C90728;
	case 19:
		goto loc_82C905F8;
	case 20:
		goto loc_82C90728;
	case 21:
		goto loc_82C90728;
	case 22:
		goto loc_82C90728;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C905C0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1452(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1452);
	// lwz r22,1452(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1452);
	// lwz r22,1544(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1544);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1560(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1560);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1452(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1452);
	// lwz r22,1528(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1528);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1528(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1528);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1472);
loc_82C905AC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90500
	if (!ctx.cr6.eq) goto loc_82C90500;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C905C0:
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r8,r7,1280
	ctx.r8.s64 = ctx.r7.s64 + 1280;
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r3,r4,27
	ctx.r3.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r11,r11,r8
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// slw r8,r31,r3
	ctx.r8.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r4,r11,r9
	ctx.r4.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r3,r4,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r3,r7
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r7.u32);
	// and r9,r11,r8
	ctx.r9.u64 = ctx.r11.u64 & ctx.r8.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c90728
	if (ctx.cr6.eq) goto loc_82C90728;
loc_82C905F8:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8fbd8
	ctx.lr = 0x82C90604;
	sub_82C8FBD8(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90608:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90618:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c901f4
	if (ctx.cr6.eq) goto loc_82C901F4;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c9064c
	if (!ctx.cr6.eq) goto loc_82C9064C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c9064c
	if (!ctx.cr6.eq) goto loc_82C9064C;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,4
	ctx.r3.s64 = 4;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C9064C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c9072c
	goto loc_82C9072C;
loc_82C90654:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c901f4
	if (ctx.cr6.eq) goto loc_82C901F4;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9067c
	if (!ctx.cr6.eq) goto loc_82C9067C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90684
	goto loc_82C90684;
loc_82C9067C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C90684;
	sub_82C8DAE8(ctx, base);
loc_82C90684:
	// cmpwi cr6,r3,20
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 20, ctx.xer);
	// beq cr6,0x82c906a4
	if (ctx.cr6.eq) goto loc_82C906A4;
	// cmpwi cr6,r3,27
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 27, ctx.xer);
	// bne cr6,0x82c90728
	if (!ctx.cr6.eq) goto loc_82C90728;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8e7a0
	ctx.lr = 0x82C906A0;
	sub_82C8E7A0(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C906A4:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// subf r10,r11,r5
	ctx.r10.s64 = ctx.r5.s64 - ctx.r11.s64;
	// cmpwi cr6,r10,12
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 12, ctx.xer);
	// blt cr6,0x82c901f4
	if (ctx.cr6.lt) goto loc_82C901F4;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r9,-4144
	ctx.r9.s64 = ctx.r9.s64 + -4144;
loc_82C906C0:
	// lbz r8,1(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c906fc
	if (!ctx.cr6.eq) goto loc_82C906FC;
	// addi r8,r9,4744
	ctx.r8.s64 = ctx.r9.s64 + 4744;
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbzx r5,r10,r8
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r8.u32);
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c906fc
	if (!ctx.cr6.eq) goto loc_82C906FC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// cmpwi cr6,r10,6
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 6, ctx.xer);
	// blt cr6,0x82c906c0
	if (ctx.cr6.lt) goto loc_82C906C0;
	// li r3,8
	ctx.r3.s64 = 8;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C906FC:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90708:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8ece8
	ctx.lr = 0x82C90714;
	sub_82C8ECE8(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90718:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8f420
	ctx.lr = 0x82C90724;
	sub_82C8F420(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90728:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C9072C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C90730:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C90748"))) PPC_WEAK_FUNC(sub_82C90748);
PPC_FUNC_IMPL(__imp__sub_82C90748) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90780
	if (!ctx.cr6.eq) goto loc_82C90780;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90780:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c907b8
	if (ctx.cr6.eq) goto loc_82C907B8;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c907b4
	if (!ctx.cr6.eq) goto loc_82C907B4;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C907B4:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C907B8:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c907d4
	if (!ctx.cr6.eq) goto loc_82C907D4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c907dc
	goto loc_82C907DC;
loc_82C907D4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C907DC;
	sub_82C8DAE8(ctx, base);
loc_82C907DC:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c909bc
	if (ctx.cr6.gt) goto loc_82C909BC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,2044
	ctx.r12.s64 = ctx.r12.s64 + 2044;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C909B4;
	case 1:
		goto loc_82C909B4;
	case 2:
		goto loc_82C90828;
	case 3:
		goto loc_82C90848;
	case 4:
		goto loc_82C908E4;
	case 5:
		goto loc_82C90968;
	case 6:
		goto loc_82C9098C;
	case 7:
		goto loc_82C909A0;
	case 8:
		goto loc_82C909B4;
	case 9:
		goto loc_82C90868;
	case 10:
		goto loc_82C908C4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,2484(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2484);
	// lwz r22,2484(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2484);
	// lwz r22,2088(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2088);
	// lwz r22,2120(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2120);
	// lwz r22,2276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2276);
	// lwz r22,2408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2408);
	// lwz r22,2444(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2444);
	// lwz r22,2464(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2464);
	// lwz r22,2484(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2484);
	// lwz r22,2152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2152);
	// lwz r22,2244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2244);
loc_82C90828:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c901d0
	ctx.lr = 0x82C90834;
	sub_82C901D0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90848:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c8f940
	ctx.lr = 0x82C90854;
	sub_82C8F940(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90868:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9088c
	if (!ctx.cr6.eq) goto loc_82C9088C;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9088C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c908a8
	if (!ctx.cr6.eq) goto loc_82C908A8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c908b0
	goto loc_82C908B0;
loc_82C908A8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C908B0;
	sub_82C8DAE8(ctx, base);
loc_82C908B0:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c908bc
	if (!ctx.cr6.eq) goto loc_82C908BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C908BC:
	// li r3,7
	ctx.r3.s64 = 7;
	// b 0x82c90a50
	goto loc_82C90A50;
loc_82C908C4:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C908E4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90908
	if (!ctx.cr6.eq) goto loc_82C90908;
loc_82C908F0:
	// li r3,-5
	ctx.r3.s64 = -5;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90908:
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c909c0
	if (!ctx.cr6.eq) goto loc_82C909C0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c909c0
	if (!ctx.cr6.eq) goto loc_82C909C0;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c908f0
	if (ctx.cr6.eq) goto loc_82C908F0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c90960
	if (!ctx.cr6.eq) goto loc_82C90960;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c90960
	if (!ctx.cr6.eq) goto loc_82C90960;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90960:
	// addi r10,r11,-2
	ctx.r10.s64 = ctx.r11.s64 + -2;
	// b 0x82c909c0
	goto loc_82C909C0;
loc_82C90968:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c909bc
	if (!ctx.cr6.lt) goto loc_82C909BC;
loc_82C90974:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9098C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c90974
	if (ctx.cr6.lt) goto loc_82C90974;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c909c0
	goto loc_82C909C0;
loc_82C909A0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c90974
	if (ctx.cr6.lt) goto loc_82C90974;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c909c0
	goto loc_82C909C0;
loc_82C909B4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c90a50
	goto loc_82C90A50;
loc_82C909BC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C909C0:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c90a4c
	if (ctx.cr6.eq) goto loc_82C90A4C;
	// addi r7,r10,4
	ctx.r7.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C909D4:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c909f0
	if (!ctx.cr6.eq) goto loc_82C909F0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c909f8
	goto loc_82C909F8;
loc_82C909F0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C909F8;
	sub_82C8DAE8(ctx, base);
loc_82C909F8:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c90ae0
	if (ctx.cr6.gt) goto loc_82C90AE0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,2584
	ctx.r12.s64 = ctx.r12.s64 + 2584;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C90A4C;
	case 1:
		goto loc_82C90A4C;
	case 2:
		goto loc_82C90A4C;
	case 3:
		goto loc_82C90A4C;
	case 4:
		goto loc_82C90AA0;
	case 5:
		goto loc_82C90A44;
	case 6:
		goto loc_82C90A68;
	case 7:
		goto loc_82C90A84;
	case 8:
		goto loc_82C90A4C;
	case 9:
		goto loc_82C90A4C;
	case 10:
		goto loc_82C90A4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2720);
	// lwz r22,2628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2628);
	// lwz r22,2664(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2664);
	// lwz r22,2692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2692);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
loc_82C90A44:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bge cr6,0x82c90ae0
	if (!ctx.cr6.lt) goto loc_82C90AE0;
loc_82C90A4C:
	// li r3,6
	ctx.r3.s64 = 6;
loc_82C90A50:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90A68:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c90a4c
	if (ctx.cr6.lt) goto loc_82C90A4C;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// addi r8,r8,3
	ctx.r8.s64 = ctx.r8.s64 + 3;
	// addi r7,r7,3
	ctx.r7.s64 = ctx.r7.s64 + 3;
	// b 0x82c90af0
	goto loc_82C90AF0;
loc_82C90A84:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c90a4c
	if (ctx.cr6.lt) goto loc_82C90A4C;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// b 0x82c90af0
	goto loc_82C90AF0;
loc_82C90AA0:
	// cmplw cr6,r8,r5
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c90a4c
	if (ctx.cr6.eq) goto loc_82C90A4C;
	// lbz r11,3(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c90ae0
	if (!ctx.cr6.eq) goto loc_82C90AE0;
	// lbz r11,0(r8)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c90ae0
	if (!ctx.cr6.eq) goto loc_82C90AE0;
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c90a4c
	if (ctx.cr6.eq) goto loc_82C90A4C;
	// lbz r11,5(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 5);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c90ae0
	if (!ctx.cr6.eq) goto loc_82C90AE0;
	// lbz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// beq cr6,0x82c90afc
	if (ctx.cr6.eq) goto loc_82C90AFC;
loc_82C90AE0:
	// addi r7,r7,2
	ctx.r7.s64 = ctx.r7.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C90AF0:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c909d4
	if (!ctx.cr6.eq) goto loc_82C909D4;
	// b 0x82c90a4c
	goto loc_82C90A4C;
loc_82C90AFC:
	// addi r11,r10,4
	ctx.r11.s64 = ctx.r10.s64 + 4;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C90B20"))) PPC_WEAK_FUNC(sub_82C90B20);
PPC_FUNC_IMPL(__imp__sub_82C90B20) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90b4c
	if (!ctx.cr6.eq) goto loc_82C90B4C;
	// li r3,-22
	ctx.r3.s64 = -22;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90B4C:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c90b68
	if (!ctx.cr6.eq) goto loc_82C90B68;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90b70
	goto loc_82C90B70;
loc_82C90B68:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C90B70;
	sub_82C8DAE8(ctx, base);
loc_82C90B70:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,25
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 25, ctx.xer);
	// bgt cr6,0x82c90d90
	if (ctx.cr6.gt) goto loc_82C90D90;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,2976
	ctx.r12.s64 = ctx.r12.s64 + 2976;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90D3C;
	case 1:
		goto loc_82C90D50;
	case 2:
		goto loc_82C90D64;
	case 3:
		goto loc_82C90D90;
	case 4:
		goto loc_82C90D88;
	case 5:
		goto loc_82C90D88;
	case 6:
		goto loc_82C90D90;
	case 7:
		goto loc_82C90D90;
	case 8:
		goto loc_82C90D90;
	case 9:
		goto loc_82C90D90;
	case 10:
		goto loc_82C90D90;
	case 11:
		goto loc_82C90D90;
	case 12:
		goto loc_82C90D90;
	case 13:
		goto loc_82C90D90;
	case 14:
		goto loc_82C90D90;
	case 15:
		goto loc_82C90D90;
	case 16:
		goto loc_82C90D88;
	case 17:
		goto loc_82C90C3C;
	case 18:
		goto loc_82C90D90;
	case 19:
		goto loc_82C90C3C;
	case 20:
		goto loc_82C90D90;
	case 21:
		goto loc_82C90D90;
	case 22:
		goto loc_82C90D90;
	case 23:
		goto loc_82C90D90;
	case 24:
		goto loc_82C90C08;
	case 25:
		goto loc_82C90D88;
	default:
		__builtin_unreachable();
	}
	// lwz r22,3388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3388);
	// lwz r22,3408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3408);
	// lwz r22,3428(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3428);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3464(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
	// lwz r22,3464(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3464(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
	// lwz r22,3132(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3132);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3132(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3132);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3080(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3080);
	// lwz r22,3464(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
loc_82C90C08:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r7,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r11.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c90d90
	if (ctx.cr6.eq) goto loc_82C90D90;
loc_82C90C3C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c90d34
	if (ctx.cr6.eq) goto loc_82C90D34;
loc_82C90C48:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c90c64
	if (!ctx.cr6.eq) goto loc_82C90C64;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90c6c
	goto loc_82C90C6C;
loc_82C90C64:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C90C6C;
	sub_82C8DAE8(ctx, base);
loc_82C90C6C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c90d90
	if (ctx.cr6.gt) goto loc_82C90D90;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,3216
	ctx.r12.s64 = ctx.r12.s64 + 3216;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90D3C;
	case 1:
		goto loc_82C90D50;
	case 2:
		goto loc_82C90D64;
	case 3:
		goto loc_82C90D90;
	case 4:
		goto loc_82C90D90;
	case 5:
		goto loc_82C90D90;
	case 6:
		goto loc_82C90D90;
	case 7:
		goto loc_82C90D90;
	case 8:
		goto loc_82C90D90;
	case 9:
		goto loc_82C90D90;
	case 10:
		goto loc_82C90D90;
	case 11:
		goto loc_82C90D90;
	case 12:
		goto loc_82C90D90;
	case 13:
		goto loc_82C90D78;
	case 14:
		goto loc_82C90D90;
	case 15:
		goto loc_82C90D90;
	case 16:
		goto loc_82C90D90;
	case 17:
		goto loc_82C90D28;
	case 18:
		goto loc_82C90D90;
	case 19:
		goto loc_82C90D28;
	case 20:
		goto loc_82C90D28;
	case 21:
		goto loc_82C90D28;
	case 22:
		goto loc_82C90D28;
	case 23:
		goto loc_82C90D90;
	case 24:
		goto loc_82C90CF4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,3388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3388);
	// lwz r22,3408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3408);
	// lwz r22,3428(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3428);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3448(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3448);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3316);
loc_82C90CF4:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c90d90
	if (ctx.cr6.eq) goto loc_82C90D90;
loc_82C90D28:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90c48
	if (!ctx.cr6.eq) goto loc_82C90C48;
loc_82C90D34:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D3C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c90d90
	if (!ctx.cr6.lt) goto loc_82C90D90;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D50:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c90d90
	if (!ctx.cr6.lt) goto loc_82C90D90;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D64:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c90d90
	if (!ctx.cr6.lt) goto loc_82C90D90;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D78:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,28
	ctx.r3.s64 = 28;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D88:
	// li r3,22
	ctx.r3.s64 = 22;
	// b 0x82c90d94
	goto loc_82C90D94;
loc_82C90D90:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C90D94:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C90D98:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C90DB0"))) PPC_WEAK_FUNC(sub_82C90DB0);
PPC_FUNC_IMPL(__imp__sub_82C90DB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90ddc
	if (!ctx.cr6.eq) goto loc_82C90DDC;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C90DDC:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c90df8
	if (!ctx.cr6.eq) goto loc_82C90DF8;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90e00
	goto loc_82C90E00;
loc_82C90DF8:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C90E00;
	sub_82C8DAE8(ctx, base);
loc_82C90E00:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c91028
	if (ctx.cr6.gt) goto loc_82C91028;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,3632
	ctx.r12.s64 = ctx.r12.s64 + 3632;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90FE4;
	case 1:
		goto loc_82C90FF8;
	case 2:
		goto loc_82C91014;
	case 3:
		goto loc_82C91028;
	case 4:
		goto loc_82C91028;
	case 5:
		goto loc_82C91028;
	case 6:
		goto loc_82C91028;
	case 7:
		goto loc_82C91028;
	case 8:
		goto loc_82C91028;
	case 9:
		goto loc_82C91028;
	case 10:
		goto loc_82C91028;
	case 11:
		goto loc_82C91028;
	case 12:
		goto loc_82C91028;
	case 13:
		goto loc_82C91028;
	case 14:
		goto loc_82C91028;
	case 15:
		goto loc_82C91028;
	case 16:
		goto loc_82C91028;
	case 17:
		goto loc_82C90EC8;
	case 18:
		goto loc_82C91028;
	case 19:
		goto loc_82C90EC8;
	case 20:
		goto loc_82C91028;
	case 21:
		goto loc_82C91028;
	case 22:
		goto loc_82C91028;
	case 23:
		goto loc_82C91028;
	case 24:
		goto loc_82C90E94;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4068(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4068);
	// lwz r22,4088(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4088);
	// lwz r22,4116(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4116);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3784(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3784);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3784(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3784);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3732);
loc_82C90E94:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r7,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r11.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c91028
	if (ctx.cr6.eq) goto loc_82C91028;
loc_82C90EC8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c90fdc
	if (ctx.cr6.eq) goto loc_82C90FDC;
loc_82C90ED4:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c90ef0
	if (!ctx.cr6.eq) goto loc_82C90EF0;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90ef8
	goto loc_82C90EF8;
loc_82C90EF0:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C90EF8;
	sub_82C8DAE8(ctx, base);
loc_82C90EF8:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 31, ctx.xer);
	// bgt cr6,0x82c91028
	if (ctx.cr6.gt) goto loc_82C91028;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,3868
	ctx.r12.s64 = ctx.r12.s64 + 3868;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90FE4;
	case 1:
		goto loc_82C90FF8;
	case 2:
		goto loc_82C91014;
	case 3:
		goto loc_82C91028;
	case 4:
		goto loc_82C9100C;
	case 5:
		goto loc_82C9100C;
	case 6:
		goto loc_82C9100C;
	case 7:
		goto loc_82C91028;
	case 8:
		goto loc_82C91028;
	case 9:
		goto loc_82C91028;
	case 10:
		goto loc_82C91028;
	case 11:
		goto loc_82C91028;
	case 12:
		goto loc_82C91028;
	case 13:
		goto loc_82C91028;
	case 14:
		goto loc_82C91028;
	case 15:
		goto loc_82C91028;
	case 16:
		goto loc_82C9100C;
	case 17:
		goto loc_82C90FD0;
	case 18:
		goto loc_82C91028;
	case 19:
		goto loc_82C90FD0;
	case 20:
		goto loc_82C90FD0;
	case 21:
		goto loc_82C90FD0;
	case 22:
		goto loc_82C90FD0;
	case 23:
		goto loc_82C91028;
	case 24:
		goto loc_82C90F9C;
	case 25:
		goto loc_82C9100C;
	case 26:
		goto loc_82C91028;
	case 27:
		goto loc_82C9100C;
	case 28:
		goto loc_82C91028;
	case 29:
		goto loc_82C91028;
	case 30:
		goto loc_82C91028;
	case 31:
		goto loc_82C9100C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4068(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4068);
	// lwz r22,4088(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4088);
	// lwz r22,4116(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4116);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3996);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
loc_82C90F9C:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c91028
	if (ctx.cr6.eq) goto loc_82C91028;
loc_82C90FD0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90ed4
	if (!ctx.cr6.eq) goto loc_82C90ED4;
loc_82C90FDC:
	// li r3,-20
	ctx.r3.s64 = -20;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C90FE4:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c91028
	if (!ctx.cr6.lt) goto loc_82C91028;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C90FF8:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c91028
	if (!ctx.cr6.lt) goto loc_82C91028;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C9100C:
	// li r3,20
	ctx.r3.s64 = 20;
	// b 0x82c9102c
	goto loc_82C9102C;
loc_82C91014:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c91028
	if (!ctx.cr6.lt) goto loc_82C91028;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C91028:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C9102C:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C91030:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C91048"))) PPC_WEAK_FUNC(sub_82C91048);
PPC_FUNC_IMPL(__imp__sub_82C91048) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// beq cr6,0x82c910fc
	if (ctx.cr6.eq) goto loc_82C910FC;
	// subf r10,r5,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r5.s64;
loc_82C91068:
	// lbz r3,1(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91084
	if (!ctx.cr6.eq) goto loc_82C91084;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9108c
	goto loc_82C9108C;
loc_82C91084:
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9108C;
	sub_82C8DAE8(ctx, base);
loc_82C9108C:
	// cmplwi cr6,r3,13
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 13, ctx.xer);
	// bgt cr6,0x82c910ec
	if (ctx.cr6.gt) goto loc_82C910EC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,4268
	ctx.r12.s64 = ctx.r12.s64 + 4268;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C91178;
	case 1:
		goto loc_82C91178;
	case 2:
		goto loc_82C910EC;
	case 3:
		goto loc_82C910EC;
	case 4:
		goto loc_82C910EC;
	case 5:
		goto loc_82C910E4;
	case 6:
		goto loc_82C91110;
	case 7:
		goto loc_82C91124;
	case 8:
		goto loc_82C91178;
	case 9:
		goto loc_82C910EC;
	case 10:
		goto loc_82C910EC;
	case 11:
		goto loc_82C910EC;
	case 12:
		goto loc_82C91138;
	case 13:
		goto loc_82C91138;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4472);
	// lwz r22,4472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4472);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4324(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4324);
	// lwz r22,4368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4368);
	// lwz r22,4388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4388);
	// lwz r22,4472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4472);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4408);
	// lwz r22,4408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4408);
loc_82C910E4:
	// cmpwi cr6,r10,2
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 2, ctx.xer);
	// blt cr6,0x82c91164
	if (ctx.cr6.lt) goto loc_82C91164;
loc_82C910EC:
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
loc_82C910F4:
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c91068
	if (!ctx.cr6.eq) goto loc_82C91068;
loc_82C910FC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91110:
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// blt cr6,0x82c91164
	if (ctx.cr6.lt) goto loc_82C91164;
	// addi r5,r5,3
	ctx.r5.s64 = ctx.r5.s64 + 3;
	// addi r10,r10,-3
	ctx.r10.s64 = ctx.r10.s64 + -3;
	// b 0x82c910f4
	goto loc_82C910F4;
loc_82C91124:
	// cmpwi cr6,r10,4
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 4, ctx.xer);
	// blt cr6,0x82c91164
	if (ctx.cr6.lt) goto loc_82C91164;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// b 0x82c910f4
	goto loc_82C910F4;
loc_82C91138:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// cmpw cr6,r3,r9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82c910f4
	if (!ctx.cr6.eq) goto loc_82C910F4;
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c91190
	if (!ctx.cr6.eq) goto loc_82C91190;
	// li r3,-27
	ctx.r3.s64 = -27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91164:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91178:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
loc_82C9117C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91190:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
	// lbz r3,1(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c911b0
	if (!ctx.cr6.eq) goto loc_82C911B0;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c911b8
	goto loc_82C911B8;
loc_82C911B0:
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C911B8;
	sub_82C8DAE8(ctx, base);
loc_82C911B8:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c9117c
	if (ctx.cr6.gt) goto loc_82C9117C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,4572
	ctx.r12.s64 = ctx.r12.s64 + 4572;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91234;
	case 1:
		goto loc_82C91234;
	case 2:
		goto loc_82C91234;
	case 3:
		goto loc_82C9117C;
	case 4:
		goto loc_82C9117C;
	case 5:
		goto loc_82C9117C;
	case 6:
		goto loc_82C9117C;
	case 7:
		goto loc_82C9117C;
	case 8:
		goto loc_82C9117C;
	case 9:
		goto loc_82C9117C;
	case 10:
		goto loc_82C9117C;
	case 11:
		goto loc_82C91234;
	case 12:
		goto loc_82C91234;
	case 13:
		goto loc_82C9117C;
	case 14:
		goto loc_82C9117C;
	case 15:
		goto loc_82C9117C;
	case 16:
		goto loc_82C9117C;
	case 17:
		goto loc_82C9117C;
	case 18:
		goto loc_82C9117C;
	case 19:
		goto loc_82C9117C;
	case 20:
		goto loc_82C9117C;
	case 21:
		goto loc_82C91234;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
loc_82C91234:
	// li r3,27
	ctx.r3.s64 = 27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C91248"))) PPC_WEAK_FUNC(sub_82C91248);
PPC_FUNC_IMPL(__imp__sub_82C91248) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C91250;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91270
	if (!ctx.cr6.eq) goto loc_82C91270;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91270:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c9129c
	if (ctx.cr6.eq) goto loc_82C9129C;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c91298
	if (!ctx.cr6.eq) goto loc_82C91298;
loc_82C9128C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91298:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C9129C:
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c912b8
	if (!ctx.cr6.eq) goto loc_82C912B8;
	// add r11,r4,r29
	ctx.r11.u64 = ctx.r4.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c912c0
	goto loc_82C912C0;
loc_82C912B8:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C912C0;
	sub_82C8DAE8(ctx, base);
loc_82C912C0:
	// addi r9,r3,-2
	ctx.r9.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r9,34
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 34, ctx.xer);
	// bgt cr6,0x82c91a64
	if (ctx.cr6.gt) goto loc_82C91A64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r30,1
	ctx.r30.s64 = 1;
	// addi r31,r11,-4144
	ctx.r31.s64 = ctx.r11.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,4848
	ctx.r12.s64 = ctx.r12.s64 + 4848;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82C913BC;
	case 1:
		goto loc_82C91A64;
	case 2:
		goto loc_82C9157C;
	case 3:
		goto loc_82C91760;
	case 4:
		goto loc_82C91778;
	case 5:
		goto loc_82C91790;
	case 6:
		goto loc_82C91A64;
	case 7:
		goto loc_82C914B0;
	case 8:
		goto loc_82C914CC;
	case 9:
		goto loc_82C91738;
	case 10:
		goto loc_82C9137C;
	case 11:
		goto loc_82C9139C;
	case 12:
		goto loc_82C91A64;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A64;
	case 16:
		goto loc_82C91A64;
	case 17:
		goto loc_82C9174C;
	case 18:
		goto loc_82C91568;
	case 19:
		goto loc_82C914CC;
	case 20:
		goto loc_82C917DC;
	case 21:
		goto loc_82C91808;
	case 22:
		goto loc_82C917DC;
	case 23:
		goto loc_82C91808;
	case 24:
		goto loc_82C91808;
	case 25:
		goto loc_82C91808;
	case 26:
		goto loc_82C91A64;
	case 27:
		goto loc_82C917A8;
	case 28:
		goto loc_82C91540;
	case 29:
		goto loc_82C915F4;
	case 30:
		goto loc_82C91608;
	case 31:
		goto loc_82C91A64;
	case 32:
		goto loc_82C91A64;
	case 33:
		goto loc_82C91554;
	case 34:
		goto loc_82C91724;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5052(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5052);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5500(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5500);
	// lwz r22,5984(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5984);
	// lwz r22,6008(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6008);
	// lwz r22,6032(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6032);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5296(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5296);
	// lwz r22,5324(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5324);
	// lwz r22,5944(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5944);
	// lwz r22,4988(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4988);
	// lwz r22,5020(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5020);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5964(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5964);
	// lwz r22,5480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5480);
	// lwz r22,5324(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5324);
	// lwz r22,6108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6108);
	// lwz r22,6152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6108);
	// lwz r22,6152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6056(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6056);
	// lwz r22,5440(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5440);
	// lwz r22,5620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5620);
	// lwz r22,5640(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5640);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5460(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5460);
	// lwz r22,5924(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5924);
loc_82C9137C:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x82c91048
	ctx.lr = 0x82C91394;
	sub_82C91048(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C9139C:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,13
	ctx.r3.s64 = 13;
	// bl 0x82c91048
	ctx.lr = 0x82C913B4;
	sub_82C91048(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C913BC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9128c
	if (ctx.cr6.eq) goto loc_82C9128C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c913e4
	if (!ctx.cr6.eq) goto loc_82C913E4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c913ec
	goto loc_82C913EC;
loc_82C913E4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C913EC;
	sub_82C8DAE8(ctx, base);
loc_82C913EC:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c91a64
	if (ctx.cr6.gt) goto loc_82C91A64;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,5136
	ctx.r12.s64 = ctx.r12.s64 + 5136;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9149C;
	case 1:
		goto loc_82C9149C;
	case 2:
		goto loc_82C9149C;
	case 3:
		goto loc_82C91A64;
	case 4:
		goto loc_82C91A64;
	case 5:
		goto loc_82C91A64;
	case 6:
		goto loc_82C91A64;
	case 7:
		goto loc_82C91A64;
	case 8:
		goto loc_82C91A64;
	case 9:
		goto loc_82C91A64;
	case 10:
		goto loc_82C91488;
	case 11:
		goto loc_82C91474;
	case 12:
		goto loc_82C91A64;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A64;
	case 16:
		goto loc_82C91A64;
	case 17:
		goto loc_82C9149C;
	case 18:
		goto loc_82C91A64;
	case 19:
		goto loc_82C9149C;
	case 20:
		goto loc_82C91A64;
	case 21:
		goto loc_82C91A64;
	case 22:
		goto loc_82C91A64;
	case 23:
		goto loc_82C91A64;
	case 24:
		goto loc_82C9149C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5256);
	// lwz r22,5236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5236);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
loc_82C91474:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8e9b0
	ctx.lr = 0x82C91480;
	sub_82C8E9B0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91488:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8ece8
	ctx.lr = 0x82C91494;
	sub_82C8ECE8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C9149C:
	// addi r11,r10,-2
	ctx.r11.s64 = ctx.r10.s64 + -2;
	// li r3,29
	ctx.r3.s64 = 29;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C914B0:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c914cc
	if (!ctx.cr6.eq) goto loc_82C914CC;
	// stw r5,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r5.u32);
	// li r3,-15
	ctx.r3.s64 = -15;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C914CC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91530
	if (ctx.cr6.eq) goto loc_82C91530;
loc_82C914D8:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c914f4
	if (!ctx.cr6.eq) goto loc_82C914F4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c914fc
	goto loc_82C914FC;
loc_82C914F4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C914FC;
	sub_82C8DAE8(ctx, base);
loc_82C914FC:
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// beq cr6,0x82c91518
	if (ctx.cr6.eq) goto loc_82C91518;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// beq cr6,0x82c91524
	if (ctx.cr6.eq) goto loc_82C91524;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// bne cr6,0x82c91530
	if (!ctx.cr6.eq) goto loc_82C91530;
	// b 0x82c91524
	goto loc_82C91524;
loc_82C91518:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91530
	if (ctx.cr6.eq) goto loc_82C91530;
loc_82C91524:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c914d8
	if (!ctx.cr6.eq) goto loc_82C914D8;
loc_82C91530:
	// li r3,15
	ctx.r3.s64 = 15;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91540:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c90b20
	ctx.lr = 0x82C9154C;
	sub_82C90B20(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91554:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,38
	ctx.r3.s64 = 38;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91568:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,25
	ctx.r3.s64 = 25;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C9157C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91594
	if (!ctx.cr6.eq) goto loc_82C91594;
	// li r3,-26
	ctx.r3.s64 = -26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91594:
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c915e4
	if (!ctx.cr6.eq) goto loc_82C915E4;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,93
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 93, ctx.xer);
	// bne cr6,0x82c915e4
	if (!ctx.cr6.eq) goto loc_82C915E4;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9128c
	if (ctx.cr6.eq) goto loc_82C9128C;
	// lbz r9,3(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c915e4
	if (!ctx.cr6.eq) goto loc_82C915E4;
	// lbz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c915e4
	if (!ctx.cr6.eq) goto loc_82C915E4;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// li r3,34
	ctx.r3.s64 = 34;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C915E4:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,26
	ctx.r3.s64 = 26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C915F4:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,23
	ctx.r3.s64 = 23;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91608:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91620
	if (!ctx.cr6.eq) goto loc_82C91620;
	// li r3,-24
	ctx.r3.s64 = -24;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91620:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9163c
	if (!ctx.cr6.eq) goto loc_82C9163C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91644
	goto loc_82C91644;
loc_82C9163C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91644;
	sub_82C8DAE8(ctx, base);
loc_82C91644:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 27, ctx.xer);
	// bgt cr6,0x82c91a64
	if (ctx.cr6.gt) goto loc_82C91A64;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,5736
	ctx.r12.s64 = ctx.r12.s64 + 5736;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91714;
	case 1:
		goto loc_82C91714;
	case 2:
		goto loc_82C91714;
	case 3:
		goto loc_82C91A64;
	case 4:
		goto loc_82C91A64;
	case 5:
		goto loc_82C91A64;
	case 6:
		goto loc_82C916EC;
	case 7:
		goto loc_82C91A64;
	case 8:
		goto loc_82C91A64;
	case 9:
		goto loc_82C91A64;
	case 10:
		goto loc_82C91A64;
	case 11:
		goto loc_82C91A64;
	case 12:
		goto loc_82C91714;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A64;
	case 16:
		goto loc_82C91A64;
	case 17:
		goto loc_82C91A64;
	case 18:
		goto loc_82C91A64;
	case 19:
		goto loc_82C91A64;
	case 20:
		goto loc_82C91A64;
	case 21:
		goto loc_82C91A64;
	case 22:
		goto loc_82C91A64;
	case 23:
		goto loc_82C91714;
	case 24:
		goto loc_82C916D8;
	case 25:
		goto loc_82C91700;
	case 26:
		goto loc_82C91714;
	case 27:
		goto loc_82C91714;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5868(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5868);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5848(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5848);
	// lwz r22,5888(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5888);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
loc_82C916D8:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,36
	ctx.r3.s64 = 36;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C916EC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,35
	ctx.r3.s64 = 35;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91700:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,37
	ctx.r3.s64 = 37;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91714:
	// li r3,24
	ctx.r3.s64 = 24;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91724:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,21
	ctx.r3.s64 = 21;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91738:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,17
	ctx.r3.s64 = 17;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C9174C:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c90db0
	ctx.lr = 0x82C91758;
	sub_82C90DB0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91760:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c91a64
	if (!ctx.cr6.lt) goto loc_82C91A64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91778:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c91a64
	if (!ctx.cr6.lt) goto loc_82C91A64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91790:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c91a64
	if (!ctx.cr6.lt) goto loc_82C91A64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C917A8:
	// clrlwi r11,r8,24
	ctx.r11.u64 = ctx.r8.u32 & 0xFF;
	// addi r7,r31,1280
	ctx.r7.s64 = ctx.r31.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r8,r30,r4
	ctx.r8.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r30.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r3,r11,r7
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r4,r3,3
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r7,r4,r9
	ctx.r7.u64 = ctx.r4.u64 + ctx.r9.u64;
	// rlwinm r4,r7,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r4,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r31.u32);
	// and r7,r3,r8
	ctx.r7.u64 = ctx.r3.u64 & ctx.r8.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c917e4
	if (ctx.cr6.eq) goto loc_82C917E4;
loc_82C917DC:
	// li r8,18
	ctx.r8.s64 = 18;
	// b 0x82c9180c
	goto loc_82C9180C;
loc_82C917E4:
	// addi r7,r31,1536
	ctx.r7.s64 = ctx.r31.s64 + 1536;
	// lbzx r4,r11,r7
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r31
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// and r8,r9,r8
	ctx.r8.u64 = ctx.r9.u64 & ctx.r8.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82c91a64
	if (ctx.cr6.eq) goto loc_82C91A64;
loc_82C91808:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C9180C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91900
	if (ctx.cr6.eq) goto loc_82C91900;
loc_82C91818:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c91834
	if (!ctx.cr6.eq) goto loc_82C91834;
	// add r11,r4,r29
	ctx.r11.u64 = ctx.r4.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9183c
	goto loc_82C9183C;
loc_82C91834:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C9183C;
	sub_82C8DAE8(ctx, base);
loc_82C9183C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 31, ctx.xer);
	// bgt cr6,0x82c91a64
	if (ctx.cr6.gt) goto loc_82C91A64;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,6240
	ctx.r12.s64 = ctx.r12.s64 + 6240;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91760;
	case 1:
		goto loc_82C91778;
	case 2:
		goto loc_82C91790;
	case 3:
		goto loc_82C91A64;
	case 4:
		goto loc_82C91A00;
	case 5:
		goto loc_82C91A00;
	case 6:
		goto loc_82C91A00;
	case 7:
		goto loc_82C91A64;
	case 8:
		goto loc_82C91A64;
	case 9:
		goto loc_82C91A64;
	case 10:
		goto loc_82C91A48;
	case 11:
		goto loc_82C91A64;
	case 12:
		goto loc_82C91A64;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A00;
	case 16:
		goto loc_82C91A00;
	case 17:
		goto loc_82C919F8;
	case 18:
		goto loc_82C918E0;
	case 19:
		goto loc_82C919F8;
	case 20:
		goto loc_82C919F8;
	case 21:
		goto loc_82C919F8;
	case 22:
		goto loc_82C919F8;
	case 23:
		goto loc_82C91A64;
	case 24:
		goto loc_82C919C4;
	case 25:
		goto loc_82C91A00;
	case 26:
		goto loc_82C91A64;
	case 27:
		goto loc_82C91A00;
	case 28:
		goto loc_82C91A2C;
	case 29:
		goto loc_82C91A10;
	case 30:
		goto loc_82C91A00;
	case 31:
		goto loc_82C91A00;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5984(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5984);
	// lwz r22,6008(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6008);
	// lwz r22,6032(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6032);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6728(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6728);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6368);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6596);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6700(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6700);
	// lwz r22,6672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6672);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
loc_82C918E0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmpwi cr6,r8,18
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 18, ctx.xer);
	// beq cr6,0x82c9190c
	if (ctx.cr6.eq) goto loc_82C9190C;
	// cmpwi cr6,r8,41
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 41, ctx.xer);
	// bne cr6,0x82c918f8
	if (!ctx.cr6.eq) goto loc_82C918F8;
loc_82C918F4:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C918F8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91818
	if (!ctx.cr6.eq) goto loc_82C91818;
loc_82C91900:
	// neg r3,r8
	ctx.r3.s64 = -ctx.r8.s64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C9190C:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9128c
	if (ctx.cr6.eq) goto loc_82C9128C;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// li r8,41
	ctx.r8.s64 = 41;
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c91934
	if (!ctx.cr6.eq) goto loc_82C91934;
	// add r11,r4,r29
	ctx.r11.u64 = ctx.r4.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9193c
	goto loc_82C9193C;
loc_82C91934:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C9193C;
	sub_82C8DAE8(ctx, base);
loc_82C9193C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c918f4
	if (ctx.cr6.gt) goto loc_82C918F4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,6496
	ctx.r12.s64 = ctx.r12.s64 + 6496;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91760;
	case 1:
		goto loc_82C91778;
	case 2:
		goto loc_82C91790;
	case 3:
		goto loc_82C918F4;
	case 4:
		goto loc_82C918F4;
	case 5:
		goto loc_82C918F4;
	case 6:
		goto loc_82C918F4;
	case 7:
		goto loc_82C918F4;
	case 8:
		goto loc_82C918F4;
	case 9:
		goto loc_82C918F4;
	case 10:
		goto loc_82C918F4;
	case 11:
		goto loc_82C918F4;
	case 12:
		goto loc_82C918F4;
	case 13:
		goto loc_82C918F4;
	case 14:
		goto loc_82C918F4;
	case 15:
		goto loc_82C918F4;
	case 16:
		goto loc_82C918F4;
	case 17:
		goto loc_82C919F8;
	case 18:
		goto loc_82C918F4;
	case 19:
		goto loc_82C919F8;
	case 20:
		goto loc_82C919F8;
	case 21:
		goto loc_82C919F8;
	case 22:
		goto loc_82C919F8;
	case 23:
		goto loc_82C918F4;
	case 24:
		goto loc_82C919C4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5984(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5984);
	// lwz r22,6008(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6008);
	// lwz r22,6032(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6032);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6596);
loc_82C919C4:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r31,1536
	ctx.r7.s64 = ctx.r31.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r30,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r30.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r31
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r31.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c91a64
	if (ctx.cr6.eq) goto loc_82C91A64;
loc_82C919F8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c918f8
	goto loc_82C918F8;
loc_82C91A00:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91A10:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c91a64
	if (ctx.cr6.eq) goto loc_82C91A64;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,32
	ctx.r3.s64 = 32;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91A2C:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c91a64
	if (ctx.cr6.eq) goto loc_82C91A64;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,31
	ctx.r3.s64 = 31;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91A48:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c91a64
	if (ctx.cr6.eq) goto loc_82C91A64;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,30
	ctx.r3.s64 = 30;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C91A64:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C91A78"))) PPC_WEAK_FUNC(sub_82C91A78);
PPC_FUNC_IMPL(__imp__sub_82C91A78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91aa8
	if (!ctx.cr6.eq) goto loc_82C91AA8;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91AA8:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C91AAC:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91ac8
	if (!ctx.cr6.eq) goto loc_82C91AC8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91ad0
	goto loc_82C91AD0;
loc_82C91AC8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91AD0;
	sub_82C8DAE8(ctx, base);
loc_82C91AD0:
	// addi r11,r3,-2
	ctx.r11.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r11,19
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 19, ctx.xer);
	// bgt cr6,0x82c91b54
	if (ctx.cr6.gt) goto loc_82C91B54;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,6900
	ctx.r12.s64 = ctx.r12.s64 + 6900;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91B9C;
	case 1:
		goto loc_82C91B78;
	case 2:
		goto loc_82C91B54;
	case 3:
		goto loc_82C91B54;
	case 4:
		goto loc_82C91B44;
	case 5:
		goto loc_82C91B4C;
	case 6:
		goto loc_82C91B54;
	case 7:
		goto loc_82C91BD8;
	case 8:
		goto loc_82C91BB4;
	case 9:
		goto loc_82C91B54;
	case 10:
		goto loc_82C91B54;
	case 11:
		goto loc_82C91B54;
	case 12:
		goto loc_82C91B54;
	case 13:
		goto loc_82C91B54;
	case 14:
		goto loc_82C91B54;
	case 15:
		goto loc_82C91B54;
	case 16:
		goto loc_82C91B54;
	case 17:
		goto loc_82C91B54;
	case 18:
		goto loc_82C91B54;
	case 19:
		goto loc_82C91C48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,7068(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7068);
	// lwz r22,7032(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7032);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6980(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6980);
	// lwz r22,6988(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6988);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,7128(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7128);
	// lwz r22,7092(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7092);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,7240(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7240);
loc_82C91B44:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c91b58
	goto loc_82C91B58;
loc_82C91B4C:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c91b58
	goto loc_82C91B58;
loc_82C91B54:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91B58:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91aac
	if (!ctx.cr6.eq) goto loc_82C91AAC;
loc_82C91B60:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91B78:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91b60
	if (!ctx.cr6.eq) goto loc_82C91B60;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8f940
	ctx.lr = 0x82C91B8C;
	sub_82C8F940(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91B9C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91BB4:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91b60
	if (!ctx.cr6.eq) goto loc_82C91B60;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91BD8:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91b60
	if (!ctx.cr6.eq) goto loc_82C91B60;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91c00
	if (!ctx.cr6.eq) goto loc_82C91C00;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91C00:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91c1c
	if (!ctx.cr6.eq) goto loc_82C91C1C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91c24
	goto loc_82C91C24;
loc_82C91C1C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91C24;
	sub_82C8DAE8(ctx, base);
loc_82C91C24:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c91c30
	if (!ctx.cr6.eq) goto loc_82C91C30;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91C30:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91C48:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91b60
	if (!ctx.cr6.eq) goto loc_82C91B60;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,39
	ctx.r3.s64 = 39;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C91C70"))) PPC_WEAK_FUNC(sub_82C91C70);
PPC_FUNC_IMPL(__imp__sub_82C91C70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91ca0
	if (!ctx.cr6.eq) goto loc_82C91CA0;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91CA0:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C91CA4:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91cc0
	if (!ctx.cr6.eq) goto loc_82C91CC0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91cc8
	goto loc_82C91CC8;
loc_82C91CC0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91CC8;
	sub_82C8DAE8(ctx, base);
loc_82C91CC8:
	// addi r11,r3,-3
	ctx.r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 27, ctx.xer);
	// bgt cr6,0x82c91d6c
	if (ctx.cr6.gt) goto loc_82C91D6C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,7404
	ctx.r12.s64 = ctx.r12.s64 + 7404;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91D90;
	case 1:
		goto loc_82C91D6C;
	case 2:
		goto loc_82C91D6C;
	case 3:
		goto loc_82C91D5C;
	case 4:
		goto loc_82C91D64;
	case 5:
		goto loc_82C91D6C;
	case 6:
		goto loc_82C91E08;
	case 7:
		goto loc_82C91DE4;
	case 8:
		goto loc_82C91D6C;
	case 9:
		goto loc_82C91D6C;
	case 10:
		goto loc_82C91D6C;
	case 11:
		goto loc_82C91D6C;
	case 12:
		goto loc_82C91D6C;
	case 13:
		goto loc_82C91D6C;
	case 14:
		goto loc_82C91D6C;
	case 15:
		goto loc_82C91D6C;
	case 16:
		goto loc_82C91D6C;
	case 17:
		goto loc_82C91D6C;
	case 18:
		goto loc_82C91D6C;
	case 19:
		goto loc_82C91D6C;
	case 20:
		goto loc_82C91D6C;
	case 21:
		goto loc_82C91D6C;
	case 22:
		goto loc_82C91D6C;
	case 23:
		goto loc_82C91D6C;
	case 24:
		goto loc_82C91D6C;
	case 25:
		goto loc_82C91D6C;
	case 26:
		goto loc_82C91D6C;
	case 27:
		goto loc_82C91DB4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,7568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7568);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7516(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7516);
	// lwz r22,7524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7524);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7688(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7688);
	// lwz r22,7652(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7652);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7604);
loc_82C91D5C:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c91d70
	goto loc_82C91D70;
loc_82C91D64:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c91d70
	goto loc_82C91D70;
loc_82C91D6C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91D70:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91ca4
	if (!ctx.cr6.eq) goto loc_82C91CA4;
loc_82C91D78:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C91D80:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91D90:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91d78
	if (!ctx.cr6.eq) goto loc_82C91D78;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8f940
	ctx.lr = 0x82C91DA4;
	sub_82C8F940(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91DB4:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91d78
	if (!ctx.cr6.eq) goto loc_82C91D78;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c90b20
	ctx.lr = 0x82C91DC8;
	sub_82C90B20(ctx, base);
	// cmpwi cr6,r3,22
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 22, ctx.xer);
	// bne cr6,0x82c91d80
	if (!ctx.cr6.eq) goto loc_82C91D80;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91DE4:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91d78
	if (!ctx.cr6.eq) goto loc_82C91D78;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91E08:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91d78
	if (!ctx.cr6.eq) goto loc_82C91D78;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91e30
	if (!ctx.cr6.eq) goto loc_82C91E30;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91E30:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91e4c
	if (!ctx.cr6.eq) goto loc_82C91E4C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91e54
	goto loc_82C91E54;
loc_82C91E4C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91E54;
	sub_82C8DAE8(ctx, base);
loc_82C91E54:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c91e60
	if (!ctx.cr6.eq) goto loc_82C91E60;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91E60:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C91E78"))) PPC_WEAK_FUNC(sub_82C91E78);
PPC_FUNC_IMPL(__imp__sub_82C91E78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// li r8,0
	ctx.r8.s64 = 0;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c91ea8
	if (ctx.cr6.eq) goto loc_82C91EA8;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C91EA8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91f34
	if (ctx.cr6.eq) goto loc_82C91F34;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C91EB4:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91ed0
	if (!ctx.cr6.eq) goto loc_82C91ED0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91ed8
	goto loc_82C91ED8;
loc_82C91ED0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91ED8;
	sub_82C8DAE8(ctx, base);
loc_82C91ED8:
	// cmplwi cr6,r3,8
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 8, ctx.xer);
	// bgt cr6,0x82c91f24
	if (ctx.cr6.gt) goto loc_82C91F24;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,7928
	ctx.r12.s64 = ctx.r12.s64 + 7928;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C92044;
	case 1:
		goto loc_82C92044;
	case 2:
		goto loc_82C91F70;
	case 3:
		goto loc_82C91F24;
	case 4:
		goto loc_82C91FC8;
	case 5:
		goto loc_82C91F1C;
	case 6:
		goto loc_82C91F48;
	case 7:
		goto loc_82C91F5C;
	case 8:
		goto loc_82C92044;
	default:
		__builtin_unreachable();
	}
	// lwz r22,8260(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8260);
	// lwz r22,8260(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8260);
	// lwz r22,8048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8048);
	// lwz r22,7972(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7972);
	// lwz r22,8136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8136);
	// lwz r22,7964(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7964);
	// lwz r22,8008(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8008);
	// lwz r22,8028(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8028);
	// lwz r22,8260(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8260);
loc_82C91F1C:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c92030
	if (ctx.cr6.lt) goto loc_82C92030;
loc_82C91F24:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
loc_82C91F2C:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91eb4
	if (!ctx.cr6.eq) goto loc_82C91EB4;
loc_82C91F34:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91F48:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c92030
	if (ctx.cr6.lt) goto loc_82C92030;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c91f2c
	goto loc_82C91F2C;
loc_82C91F5C:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c92030
	if (ctx.cr6.lt) goto loc_82C92030;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c91f2c
	goto loc_82C91F2C;
loc_82C91F70:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91f34
	if (ctx.cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,33
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 33, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91f34
	if (ctx.cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,91
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 91, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// b 0x82c91f24
	goto loc_82C91F24;
loc_82C91FC8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91f34
	if (ctx.cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91f34
	if (ctx.cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82c9205c
	if (ctx.cr6.eq) goto loc_82C9205C;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// b 0x82c91f2c
	goto loc_82C91F2C;
loc_82C92030:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92044:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C9205C:
	// li r3,42
	ctx.r3.s64 = 42;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92078"))) PPC_WEAK_FUNC(sub_82C92078);
PPC_FUNC_IMPL(__imp__sub_82C92078) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// addi r7,r5,-2
	ctx.r7.s64 = ctx.r5.s64 + -2;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82c921bc
	if (ctx.cr6.eq) goto loc_82C921BC;
loc_82C92098:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// extsb r9,r3
	ctx.r9.s64 = ctx.r3.s8;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c920b8
	if (!ctx.cr6.eq) goto loc_82C920B8;
	// add r11,r4,r8
	ctx.r11.u64 = ctx.r4.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c920bc
	goto loc_82C920BC;
loc_82C920B8:
	// bl 0x82c8dae8
	ctx.lr = 0x82C920BC;
	sub_82C8DAE8(ctx, base);
loc_82C920BC:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 26, ctx.xer);
	// bgt cr6,0x82c92194
	if (ctx.cr6.gt) goto loc_82C92194;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,8416
	ctx.r12.s64 = ctx.r12.s64 + 8416;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C921B0;
	case 1:
		goto loc_82C921B0;
	case 2:
		goto loc_82C92194;
	case 3:
		goto loc_82C92194;
	case 4:
		goto loc_82C921B0;
	case 5:
		goto loc_82C921B0;
	case 6:
		goto loc_82C921B0;
	case 7:
		goto loc_82C921B0;
	case 8:
		goto loc_82C921B0;
	case 9:
		goto loc_82C921B0;
	case 10:
		goto loc_82C921B0;
	case 11:
		goto loc_82C92194;
	case 12:
		goto loc_82C9214C;
	case 13:
		goto loc_82C92178;
	case 14:
		goto loc_82C921B0;
	case 15:
		goto loc_82C921B0;
	case 16:
		goto loc_82C921B0;
	case 17:
		goto loc_82C92178;
	case 18:
		goto loc_82C921B0;
	case 19:
		goto loc_82C92194;
	case 20:
		goto loc_82C92194;
	case 21:
		goto loc_82C921B0;
	case 22:
		goto loc_82C921B0;
	case 23:
		goto loc_82C921B0;
	case 24:
		goto loc_82C921B0;
	case 25:
		goto loc_82C921B0;
	case 26:
		goto loc_82C921B0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8524);
	// lwz r22,8568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8568);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8568);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
loc_82C9214C:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c921b0
	if (!ctx.cr6.eq) goto loc_82C921B0;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82c921b0
	if (!ctx.cr6.eq) goto loc_82C921B0;
loc_82C92160:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92178:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// beq cr6,0x82c92188
	if (ctx.cr6.eq) goto loc_82C92188;
	// li r11,-1
	ctx.r11.s64 = -1;
loc_82C92188:
	// rlwinm r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c921b0
	if (ctx.cr6.eq) goto loc_82C921B0;
loc_82C92194:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c92160
	if (!ctx.cr6.eq) goto loc_82C92160;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,36
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 36, ctx.xer);
	// beq cr6,0x82c921b0
	if (ctx.cr6.eq) goto loc_82C921B0;
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// bne cr6,0x82c92160
	if (!ctx.cr6.eq) goto loc_82C92160;
loc_82C921B0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// bne cr6,0x82c92098
	if (!ctx.cr6.eq) goto loc_82C92098;
loc_82C921BC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C921D0"))) PPC_WEAK_FUNC(sub_82C921D0);
PPC_FUNC_IMPL(__imp__sub_82C921D0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C921D8;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r27,0
	ctx.r27.s64 = 0;
	// addi r8,r4,2
	ctx.r8.s64 = ctx.r4.s64 + 2;
	// li r29,1
	ctx.r29.s64 = 1;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// mr r30,r27
	ctx.r30.u64 = ctx.r27.u64;
	// addi r31,r8,2
	ctx.r31.s64 = ctx.r8.s64 + 2;
loc_82C921FC:
	// lbz r3,1(r8)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// lbz r4,0(r8)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// extsb r10,r3
	ctx.r10.s64 = ctx.r3.s8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9221c
	if (!ctx.cr6.eq) goto loc_82C9221C;
	// add r11,r4,r28
	ctx.r11.u64 = ctx.r4.u64 + ctx.r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92220
	goto loc_82C92220;
loc_82C9221C:
	// bl 0x82c8dae8
	ctx.lr = 0x82C92220;
	sub_82C8DAE8(ctx, base);
loc_82C92220:
	// addi r11,r3,-3
	ctx.r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 26, ctx.xer);
	// bgt cr6,0x82c924c8
	if (ctx.cr6.gt) goto loc_82C924C8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,8772
	ctx.r12.s64 = ctx.r12.s64 + 8772;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C924A8;
	case 1:
		goto loc_82C924C8;
	case 2:
		goto loc_82C922B0;
	case 3:
		goto loc_82C922D8;
	case 4:
		goto loc_82C92308;
	case 5:
		goto loc_82C924C8;
	case 6:
		goto loc_82C92488;
	case 7:
		goto loc_82C92488;
	case 8:
		goto loc_82C924C0;
	case 9:
		goto loc_82C92338;
	case 10:
		goto loc_82C9238C;
	case 11:
		goto loc_82C924C8;
	case 12:
		goto loc_82C924C8;
	case 13:
		goto loc_82C924C8;
	case 14:
		goto loc_82C924C0;
	case 15:
		goto loc_82C924C8;
	case 16:
		goto loc_82C924C8;
	case 17:
		goto loc_82C924C8;
	case 18:
		goto loc_82C923E0;
	case 19:
		goto loc_82C922B0;
	case 20:
		goto loc_82C924C8;
	case 21:
		goto loc_82C922B0;
	case 22:
		goto loc_82C924C8;
	case 23:
		goto loc_82C924C8;
	case 24:
		goto loc_82C924C8;
	case 25:
		goto loc_82C924C8;
	case 26:
		goto loc_82C922B0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,9384(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9384);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,8880(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
	// lwz r22,8920(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8920);
	// lwz r22,8968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8968);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9352);
	// lwz r22,9352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9352);
	// lwz r22,9408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9408);
	// lwz r22,9016(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9016);
	// lwz r22,9100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9100);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9408);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9184(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9184);
	// lwz r22,8880(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,8880(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,8880(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
loc_82C922B0:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c922c8
	if (!ctx.cr6.lt) goto loc_82C922C8;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C922C8:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C922D8:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c922f4
	if (!ctx.cr6.eq) goto loc_82C922F4;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c922f0
	if (!ctx.cr6.lt) goto loc_82C922F0;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C922F0:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
loc_82C922F4:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92308:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c92324
	if (!ctx.cr6.eq) goto loc_82C92324;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c92320
	if (!ctx.cr6.lt) goto loc_82C92320;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C92320:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
loc_82C92324:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92338:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// beq cr6,0x82c92360
	if (ctx.cr6.eq) goto loc_82C92360;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c9234c
	if (!ctx.cr6.lt) goto loc_82C9234C;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r31.u32);
loc_82C9234C:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,12
	ctx.r30.s64 = 12;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92360:
	// cmpwi cr6,r30,12
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 12, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c92378
	if (!ctx.cr6.lt) goto loc_82C92378;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
loc_82C92378:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C9238C:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// beq cr6,0x82c923b4
	if (ctx.cr6.eq) goto loc_82C923B4;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c923a0
	if (!ctx.cr6.lt) goto loc_82C923A0;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r31.u32);
loc_82C923A0:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,13
	ctx.r30.s64 = 13;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C923B4:
	// cmpwi cr6,r30,13
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 13, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c92378
	if (!ctx.cr6.lt) goto loc_82C92378;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C923E0:
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82c923f8
	if (!ctx.cr6.eq) goto loc_82C923F8;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C923F8:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c924c8
	if (!ctx.cr6.lt) goto loc_82C924C8;
	// lbz r11,12(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c924c8
	if (ctx.cr6.eq) goto loc_82C924C8;
	// lwz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82c92478
	if (ctx.cr6.eq) goto loc_82C92478;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c92478
	if (!ctx.cr6.eq) goto loc_82C92478;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,32
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 32, ctx.xer);
	// bne cr6,0x82c92478
	if (!ctx.cr6.eq) goto loc_82C92478;
	// lbz r3,3(r8)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r8.u32 + 3);
	// extsb r11,r3
	ctx.r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c92468
	if (!ctx.cr6.eq) goto loc_82C92468;
	// lbz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r10,32
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 32, ctx.xer);
	// beq cr6,0x82c92478
	if (ctx.cr6.eq) goto loc_82C92478;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c92468
	if (!ctx.cr6.eq) goto loc_82C92468;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92470
	goto loc_82C92470;
loc_82C92468:
	// lbz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92470;
	sub_82C8DAE8(ctx, base);
loc_82C92470:
	// cmpw cr6,r3,r30
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r30.s32, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
loc_82C92478:
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92488:
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82c924a0
	if (!ctx.cr6.eq) goto loc_82C924A0;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C924A0:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
loc_82C924A8:
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c924c8
	if (!ctx.cr6.lt) goto loc_82C924C8;
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C924C0:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c924d4
	if (!ctx.cr6.eq) goto loc_82C924D4;
loc_82C924C8:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C924D4:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C924E0"))) PPC_WEAK_FUNC(sub_82C924E0);
PPC_FUNC_IMPL(__imp__sub_82C924E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// subf r11,r4,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// srawi r10,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 1;
	// addze r11,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r11.s64 = temp.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82c9262c
	if (ctx.cr6.eq) goto loc_82C9262C;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c925d8
	if (ctx.cr6.eq) goto loc_82C925D8;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,97
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 97, ctx.xer);
	// beq cr6,0x82c92580
	if (ctx.cr6.eq) goto loc_82C92580;
	// cmpwi cr6,r11,113
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 113, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,117
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 117, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,111
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 111, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r11,116
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 116, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// li r3,34
	ctx.r3.s64 = 34;
	// blr 
	return;
loc_82C92580:
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,112
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 112, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,111
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 111, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r11,115
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 115, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// li r3,39
	ctx.r3.s64 = 39;
	// blr 
	return;
loc_82C925D8:
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,97
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 97, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,109
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 109, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r11,112
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 112, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// li r3,38
	ctx.r3.s64 = 38;
	// blr 
	return;
loc_82C9262C:
	// lbz r11,3(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,2(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// cmplwi cr6,r11,116
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 116, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,103
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 103, ctx.xer);
	// beq cr6,0x82c92670
	if (ctx.cr6.eq) goto loc_82C92670;
	// cmpwi cr6,r11,108
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 108, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// li r3,60
	ctx.r3.s64 = 60;
	// blr 
	return;
loc_82C92670:
	// li r3,62
	ctx.r3.s64 = 62;
	// blr 
	return;
loc_82C92678:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92680"))) PPC_WEAK_FUNC(sub_82C92680);
PPC_FUNC_IMPL(__imp__sub_82C92680) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C92694:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r9,r10,1
	ctx.r9.s64 = ctx.r10.s64 + 1;
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c926b4
	if (!ctx.cr6.eq) goto loc_82C926B4;
	// add r11,r4,r8
	ctx.r11.u64 = ctx.r4.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c926b8
	goto loc_82C926B8;
loc_82C926B4:
	// bl 0x82c8dae8
	ctx.lr = 0x82C926B8;
	sub_82C8DAE8(ctx, base);
loc_82C926B8:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c927fc
	if (ctx.cr6.gt) goto loc_82C927FC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,9948
	ctx.r12.s64 = ctx.r12.s64 + 9948;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C92774;
	case 1:
		goto loc_82C9275C;
	case 2:
		goto loc_82C92740;
	case 3:
		goto loc_82C927FC;
	case 4:
		goto loc_82C927FC;
	case 5:
		goto loc_82C927FC;
	case 6:
		goto loc_82C927FC;
	case 7:
		goto loc_82C927FC;
	case 8:
		goto loc_82C927FC;
	case 9:
		goto loc_82C927FC;
	case 10:
		goto loc_82C927FC;
	case 11:
		goto loc_82C927FC;
	case 12:
		goto loc_82C927FC;
	case 13:
		goto loc_82C927FC;
	case 14:
		goto loc_82C927FC;
	case 15:
		goto loc_82C927FC;
	case 16:
		goto loc_82C927FC;
	case 17:
		goto loc_82C927B8;
	case 18:
		goto loc_82C927B8;
	case 19:
		goto loc_82C927B8;
	case 20:
		goto loc_82C927B8;
	case 21:
		goto loc_82C927B8;
	case 22:
		goto loc_82C927B8;
	case 23:
		goto loc_82C927FC;
	case 24:
		goto loc_82C927B8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,10100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10100);
	// lwz r22,10076(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10076);
	// lwz r22,10048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10048);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
loc_82C92740:
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r7,r4
	ctx.r7.s64 = ctx.r4.s8;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// extsb r6,r11
	ctx.r6.s64 = ctx.r11.s8;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// cmpw cr6,r7,r6
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r6.s32, ctx.xer);
	// bne cr6,0x82c927a4
	if (!ctx.cr6.eq) goto loc_82C927A4;
loc_82C9275C:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lbz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82c927a4
	if (!ctx.cr6.eq) goto loc_82C927A4;
loc_82C92774:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
	// lbz r6,0(r5)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r9,r5,1
	ctx.r9.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r7,r6
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c927a4
	if (!ctx.cr6.eq) goto loc_82C927A4;
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// lbz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r5,r9,1
	ctx.r5.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r7,r6
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, ctx.xer);
	// beq cr6,0x82c92694
	if (ctx.cr6.eq) goto loc_82C92694;
loc_82C927A4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C927B8:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r7,r4
	ctx.r7.s64 = ctx.r4.s8;
	// addi r11,r5,1
	ctx.r11.s64 = ctx.r5.s64 + 1;
	// extsb r6,r10
	ctx.r6.s64 = ctx.r10.s8;
	// cmpw cr6,r6,r7
	ctx.cr6.compare<int32_t>(ctx.r6.s32, ctx.r7.s32, ctx.xer);
	// bne cr6,0x82c927a4
	if (!ctx.cr6.eq) goto loc_82C927A4;
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r10,r9,1
	ctx.r10.s64 = ctx.r9.s64 + 1;
	// lbz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r5,r11,1
	ctx.r5.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r6,r7
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82c92694
	if (ctx.cr6.eq) goto loc_82C92694;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C927FC:
	// lbz r3,1(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92818
	if (!ctx.cr6.eq) goto loc_82C92818;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92820
	goto loc_82C92820;
loc_82C92818:
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92820;
	sub_82C8DAE8(ctx, base);
loc_82C92820:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c928a8
	if (ctx.cr6.gt) goto loc_82C928A8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,10308
	ctx.r12.s64 = ctx.r12.s64 + 10308;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C927A4;
	case 1:
		goto loc_82C927A4;
	case 2:
		goto loc_82C927A4;
	case 3:
		goto loc_82C928A8;
	case 4:
		goto loc_82C928A8;
	case 5:
		goto loc_82C928A8;
	case 6:
		goto loc_82C928A8;
	case 7:
		goto loc_82C928A8;
	case 8:
		goto loc_82C928A8;
	case 9:
		goto loc_82C928A8;
	case 10:
		goto loc_82C928A8;
	case 11:
		goto loc_82C928A8;
	case 12:
		goto loc_82C928A8;
	case 13:
		goto loc_82C928A8;
	case 14:
		goto loc_82C928A8;
	case 15:
		goto loc_82C928A8;
	case 16:
		goto loc_82C928A8;
	case 17:
		goto loc_82C927A4;
	case 18:
		goto loc_82C927A4;
	case 19:
		goto loc_82C927A4;
	case 20:
		goto loc_82C927A4;
	case 21:
		goto loc_82C927A4;
	case 22:
		goto loc_82C927A4;
	case 23:
		goto loc_82C928A8;
	case 24:
		goto loc_82C927A4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
loc_82C928A8:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C928C0"))) PPC_WEAK_FUNC(sub_82C928C0);
PPC_FUNC_IMPL(__imp__sub_82C928C0) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9290c
	if (ctx.cr6.eq) goto loc_82C9290C;
loc_82C928D0:
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9291c
	if (ctx.cr6.eq) goto loc_82C9291C;
	// lbz r10,1(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c9291c
	if (!ctx.cr6.eq) goto loc_82C9291C;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82c9291c
	if (!ctx.cr6.eq) goto loc_82C9291C;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// lbz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c928d0
	if (!ctx.cr6.eq) goto loc_82C928D0;
loc_82C9290C:
	// subf r11,r4,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r3,r10,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// blr 
	return;
loc_82C9291C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92928"))) PPC_WEAK_FUNC(sub_82C92928);
PPC_FUNC_IMPL(__imp__sub_82C92928) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C92940:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9295c
	if (!ctx.cr6.eq) goto loc_82C9295C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92964
	goto loc_82C92964;
loc_82C9295C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92964;
	sub_82C8DAE8(ctx, base);
loc_82C92964:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c92a04
	if (ctx.cr6.gt) goto loc_82C92A04;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,10632
	ctx.r12.s64 = ctx.r12.s64 + 10632;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C929EC;
	case 1:
		goto loc_82C929F4;
	case 2:
		goto loc_82C929FC;
	case 3:
		goto loc_82C92A04;
	case 4:
		goto loc_82C92A04;
	case 5:
		goto loc_82C92A04;
	case 6:
		goto loc_82C92A04;
	case 7:
		goto loc_82C92A04;
	case 8:
		goto loc_82C92A04;
	case 9:
		goto loc_82C92A04;
	case 10:
		goto loc_82C92A04;
	case 11:
		goto loc_82C92A04;
	case 12:
		goto loc_82C92A04;
	case 13:
		goto loc_82C92A04;
	case 14:
		goto loc_82C92A04;
	case 15:
		goto loc_82C92A04;
	case 16:
		goto loc_82C92A04;
	case 17:
		goto loc_82C929EC;
	case 18:
		goto loc_82C929EC;
	case 19:
		goto loc_82C929EC;
	case 20:
		goto loc_82C929EC;
	case 21:
		goto loc_82C929EC;
	case 22:
		goto loc_82C929EC;
	case 23:
		goto loc_82C92A04;
	case 24:
		goto loc_82C929EC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10740(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10740);
	// lwz r22,10748(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10748);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
loc_82C929EC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c92940
	goto loc_82C92940;
loc_82C929F4:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c92940
	goto loc_82C92940;
loc_82C929FC:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c92940
	goto loc_82C92940;
loc_82C92A04:
	// subf r3,r8,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r8.s64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92A18"))) PPC_WEAK_FUNC(sub_82C92A18);
PPC_FUNC_IMPL(__imp__sub_82C92A18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C92A2C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92a48
	if (!ctx.cr6.eq) goto loc_82C92A48;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92a50
	goto loc_82C92A50;
loc_82C92A48:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92A50;
	sub_82C8DAE8(ctx, base);
loc_82C92A50:
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// blt cr6,0x82c92a70
	if (ctx.cr6.lt) goto loc_82C92A70;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// ble cr6,0x82c92a68
	if (!ctx.cr6.gt) goto loc_82C92A68;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// bne cr6,0x82c92a70
	if (!ctx.cr6.eq) goto loc_82C92A70;
loc_82C92A68:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c92a2c
	goto loc_82C92A2C;
loc_82C92A70:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92A88"))) PPC_WEAK_FUNC(sub_82C92A88);
PPC_FUNC_IMPL(__imp__sub_82C92A88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92b40
	if (ctx.cr6.eq) goto loc_82C92B40;
	// li r9,-1
	ctx.r9.s64 = -1;
loc_82C92AA8:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92ac4
	if (!ctx.cr6.eq) goto loc_82C92AC4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92acc
	goto loc_82C92ACC;
loc_82C92AC4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92ACC;
	sub_82C8DAE8(ctx, base);
loc_82C92ACC:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// bgt cr6,0x82c92b28
	if (ctx.cr6.gt) goto loc_82C92B28;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,10992
	ctx.r12.s64 = ctx.r12.s64 + 10992;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C92B28;
	case 1:
		goto loc_82C92B08;
	case 2:
		goto loc_82C92B10;
	case 3:
		goto loc_82C92B28;
	case 4:
		goto loc_82C92B50;
	case 5:
		goto loc_82C92B18;
	default:
		__builtin_unreachable();
	}
	// lwz r22,11048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11048);
	// lwz r22,11016(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11016);
	// lwz r22,11024(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11024);
	// lwz r22,11048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11048);
	// lwz r22,11088(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11088);
	// lwz r22,11032(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11032);
loc_82C92B08:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c92b2c
	goto loc_82C92B2C;
loc_82C92B10:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c92b2c
	goto loc_82C92B2C;
loc_82C92B18:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C92B28:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C92B2C:
	// lwz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r11.u32);
	// bne cr6,0x82c92aa8
	if (!ctx.cr6.eq) goto loc_82C92AA8;
loc_82C92B40:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92B50:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// beq cr6,0x82c92b98
	if (ctx.cr6.eq) goto loc_82C92B98;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92b84
	if (!ctx.cr6.eq) goto loc_82C92B84;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92b8c
	goto loc_82C92B8C;
loc_82C92B84:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92B8C;
	sub_82C8DAE8(ctx, base);
loc_82C92B8C:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c92b98
	if (!ctx.cr6.eq) goto loc_82C92B98;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C92B98:
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// b 0x82c92b2c
	goto loc_82C92B2C;
}

__attribute__((alias("__imp__sub_82C92BA0"))) PPC_WEAK_FUNC(sub_82C92BA0);
PPC_FUNC_IMPL(__imp__sub_82C92BA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92cac
	if (ctx.cr6.eq) goto loc_82C92CAC;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92d94
	if (!ctx.cr6.eq) goto loc_82C92D94;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,45
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 45, ctx.xer);
	// bne cr6,0x82c92d94
	if (!ctx.cr6.eq) goto loc_82C92D94;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92cac
	if (ctx.cr6.eq) goto loc_82C92CAC;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C92BE0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92bfc
	if (!ctx.cr6.eq) goto loc_82C92BFC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92c04
	goto loc_82C92C04;
loc_82C92BFC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92C04;
	sub_82C8DAE8(ctx, base);
loc_82C92C04:
	// cmplwi cr6,r3,27
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 27, ctx.xer);
	// bgt cr6,0x82c92c9c
	if (ctx.cr6.gt) goto loc_82C92C9C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,11300
	ctx.r12.s64 = ctx.r12.s64 + 11300;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C92D64;
	case 1:
		goto loc_82C92D64;
	case 2:
		goto loc_82C92C9C;
	case 3:
		goto loc_82C92C9C;
	case 4:
		goto loc_82C92C9C;
	case 5:
		goto loc_82C92C94;
	case 6:
		goto loc_82C92CC0;
	case 7:
		goto loc_82C92CD4;
	case 8:
		goto loc_82C92D64;
	case 9:
		goto loc_82C92C9C;
	case 10:
		goto loc_82C92C9C;
	case 11:
		goto loc_82C92C9C;
	case 12:
		goto loc_82C92C9C;
	case 13:
		goto loc_82C92C9C;
	case 14:
		goto loc_82C92C9C;
	case 15:
		goto loc_82C92C9C;
	case 16:
		goto loc_82C92C9C;
	case 17:
		goto loc_82C92C9C;
	case 18:
		goto loc_82C92C9C;
	case 19:
		goto loc_82C92C9C;
	case 20:
		goto loc_82C92C9C;
	case 21:
		goto loc_82C92C9C;
	case 22:
		goto loc_82C92C9C;
	case 23:
		goto loc_82C92C9C;
	case 24:
		goto loc_82C92C9C;
	case 25:
		goto loc_82C92C9C;
	case 26:
		goto loc_82C92C9C;
	case 27:
		goto loc_82C92CE8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,11620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11620);
	// lwz r22,11620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11620);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11412(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11412);
	// lwz r22,11456(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11456);
	// lwz r22,11476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11476);
	// lwz r22,11620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11620);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11496);
loc_82C92C94:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c92d50
	if (ctx.cr6.lt) goto loc_82C92D50;
loc_82C92C9C:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C92CA4:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c92be0
	if (!ctx.cr6.eq) goto loc_82C92BE0;
loc_82C92CAC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92CC0:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c92d50
	if (ctx.cr6.lt) goto loc_82C92D50;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c92ca4
	goto loc_82C92CA4;
loc_82C92CD4:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c92d50
	if (ctx.cr6.lt) goto loc_82C92D50;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c92ca4
	goto loc_82C92CA4;
loc_82C92CE8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92cac
	if (ctx.cr6.eq) goto loc_82C92CAC;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92ca4
	if (!ctx.cr6.eq) goto loc_82C92CA4;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,45
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 45, ctx.xer);
	// bne cr6,0x82c92ca4
	if (!ctx.cr6.eq) goto loc_82C92CA4;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92cac
	if (ctx.cr6.eq) goto loc_82C92CAC;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92d7c
	if (!ctx.cr6.eq) goto loc_82C92D7C;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c92d7c
	if (!ctx.cr6.eq) goto loc_82C92D7C;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,13
	ctx.r3.s64 = 13;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92D50:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92D64:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92D7C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92D94:
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92DB0"))) PPC_WEAK_FUNC(sub_82C92DB0);
PPC_FUNC_IMPL(__imp__sub_82C92DB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c92de0
	if (!ctx.cr6.eq) goto loc_82C92DE0;
loc_82C92DCC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92DE0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92dfc
	if (!ctx.cr6.eq) goto loc_82C92DFC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92e04
	goto loc_82C92E04;
loc_82C92DFC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92E04;
	sub_82C8DAE8(ctx, base);
loc_82C92E04:
	// addi r11,r3,-20
	ctx.r11.s64 = ctx.r3.s64 + -20;
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// bgt cr6,0x82c93010
	if (ctx.cr6.gt) goto loc_82C93010;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,11816
	ctx.r12.s64 = ctx.r12.s64 + 11816;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C92E64;
	case 1:
		goto loc_82C93010;
	case 2:
		goto loc_82C92E80;
	case 3:
		goto loc_82C93010;
	case 4:
		goto loc_82C92E80;
	case 5:
		goto loc_82C93010;
	case 6:
		goto loc_82C93010;
	case 7:
		goto loc_82C92E48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,11876(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11876);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,11904(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11904);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,11904(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11904);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,11848(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11848);
loc_82C92E48:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c92ba0
	ctx.lr = 0x82C92E54;
	sub_82C92BA0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92E64:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,33
	ctx.r3.s64 = 33;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92E80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92dcc
	if (ctx.cr6.eq) goto loc_82C92DCC;
loc_82C92E8C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92ea8
	if (!ctx.cr6.eq) goto loc_82C92EA8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92eb0
	goto loc_82C92EB0;
loc_82C92EA8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92EB0;
	sub_82C8DAE8(ctx, base);
loc_82C92EB0:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c93010
	if (ctx.cr6.gt) goto loc_82C93010;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,11988
	ctx.r12.s64 = ctx.r12.s64 + 11988;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C92FF8;
	case 1:
		goto loc_82C92FF8;
	case 2:
		goto loc_82C93010;
	case 3:
		goto loc_82C93010;
	case 4:
		goto loc_82C93010;
	case 5:
		goto loc_82C93010;
	case 6:
		goto loc_82C93010;
	case 7:
		goto loc_82C93010;
	case 8:
		goto loc_82C93010;
	case 9:
		goto loc_82C93010;
	case 10:
		goto loc_82C93010;
	case 11:
		goto loc_82C93010;
	case 12:
		goto loc_82C92FF8;
	case 13:
		goto loc_82C92F2C;
	case 14:
		goto loc_82C93010;
	case 15:
		goto loc_82C92F2C;
	case 16:
		goto loc_82C93010;
	case 17:
		goto loc_82C93010;
	case 18:
		goto loc_82C93010;
	case 19:
		goto loc_82C93010;
	case 20:
		goto loc_82C93010;
	case 21:
		goto loc_82C92F4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12076(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12076);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12076(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12076);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12108);
loc_82C92F2C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c92e8c
	if (!ctx.cr6.eq) goto loc_82C92E8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92F4C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92dcc
	if (ctx.cr6.eq) goto loc_82C92DCC;
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92f74
	if (!ctx.cr6.eq) goto loc_82C92F74;
	// lbz r11,3(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92f7c
	goto loc_82C92F7C;
loc_82C92F74:
	// lbz r4,3(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92F7C;
	sub_82C8DAE8(ctx, base);
loc_82C92F7C:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c92ff8
	if (ctx.cr6.gt) goto loc_82C92FF8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,12192
	ctx.r12.s64 = ctx.r12.s64 + 12192;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93010;
	case 1:
		goto loc_82C93010;
	case 2:
		goto loc_82C92FF8;
	case 3:
		goto loc_82C92FF8;
	case 4:
		goto loc_82C92FF8;
	case 5:
		goto loc_82C92FF8;
	case 6:
		goto loc_82C92FF8;
	case 7:
		goto loc_82C92FF8;
	case 8:
		goto loc_82C92FF8;
	case 9:
		goto loc_82C92FF8;
	case 10:
		goto loc_82C92FF8;
	case 11:
		goto loc_82C92FF8;
	case 12:
		goto loc_82C93010;
	case 13:
		goto loc_82C92FF8;
	case 14:
		goto loc_82C92FF8;
	case 15:
		goto loc_82C92FF8;
	case 16:
		goto loc_82C92FF8;
	case 17:
		goto loc_82C92FF8;
	case 18:
		goto loc_82C92FF8;
	case 19:
		goto loc_82C92FF8;
	case 20:
		goto loc_82C92FF8;
	case 21:
		goto loc_82C93010;
	default:
		__builtin_unreachable();
	}
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
loc_82C92FF8:
	// li r3,16
	ctx.r3.s64 = 16;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93010:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C93028"))) PPC_WEAK_FUNC(sub_82C93028);
PPC_FUNC_IMPL(__imp__sub_82C93028) {
	PPC_FUNC_PROLOGUE();
	// li r11,11
	ctx.r11.s64 = 11;
	// subf r10,r4,r5
	ctx.r10.s64 = ctx.r5.s64 - ctx.r4.s64;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// cmpwi cr6,r10,6
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 6, ctx.xer);
	// bne cr6,0x82c930e0
	if (!ctx.cr6.eq) goto loc_82C930E0;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c930e0
	if (!ctx.cr6.eq) goto loc_82C930E0;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,88
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 88, ctx.xer);
	// beq cr6,0x82c9306c
	if (ctx.cr6.eq) goto loc_82C9306C;
	// cmpwi cr6,r11,120
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 120, ctx.xer);
	// beq cr6,0x82c93070
	if (ctx.cr6.eq) goto loc_82C93070;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C9306C:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C93070:
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c930e0
	if (!ctx.cr6.eq) goto loc_82C930E0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,77
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 77, ctx.xer);
	// beq cr6,0x82c930a0
	if (ctx.cr6.eq) goto loc_82C930A0;
	// cmpwi cr6,r10,109
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 109, ctx.xer);
	// beq cr6,0x82c930a4
	if (ctx.cr6.eq) goto loc_82C930A4;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C930A0:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C930A4:
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c930e0
	if (!ctx.cr6.eq) goto loc_82C930E0;
	// lbz r11,3(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,76
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 76, ctx.xer);
	// beq cr6,0x82c930d0
	if (ctx.cr6.eq) goto loc_82C930D0;
	// cmpwi cr6,r11,108
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 108, ctx.xer);
	// bne cr6,0x82c930e0
	if (!ctx.cr6.eq) goto loc_82C930E0;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82c930d8
	if (ctx.cr6.eq) goto loc_82C930D8;
loc_82C930D0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C930D8:
	// li r11,12
	ctx.r11.s64 = 12;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C930E0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C930E8"))) PPC_WEAK_FUNC(sub_82C930E8);
PPC_FUNC_IMPL(__imp__sub_82C930E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C930F0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r31,r10
	ctx.r31.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c9311c
	if (!ctx.cr6.eq) goto loc_82C9311C;
loc_82C93110:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C9311C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c93138
	if (!ctx.cr6.eq) goto loc_82C93138;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93144
	goto loc_82C93144;
loc_82C93138:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93144;
	sub_82C8DAE8(ctx, base);
loc_82C93144:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c93534
	if (ctx.cr6.gt) goto loc_82C93534;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,12660
	ctx.r12.s64 = ctx.r12.s64 + 12660;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C934F8;
	case 1:
		goto loc_82C93510;
	case 2:
		goto loc_82C93528;
	case 3:
		goto loc_82C93534;
	case 4:
		goto loc_82C93534;
	case 5:
		goto loc_82C93534;
	case 6:
		goto loc_82C93534;
	case 7:
		goto loc_82C93534;
	case 8:
		goto loc_82C93534;
	case 9:
		goto loc_82C93534;
	case 10:
		goto loc_82C93534;
	case 11:
		goto loc_82C93534;
	case 12:
		goto loc_82C93534;
	case 13:
		goto loc_82C93534;
	case 14:
		goto loc_82C93534;
	case 15:
		goto loc_82C93534;
	case 16:
		goto loc_82C93534;
	case 17:
		goto loc_82C93210;
	case 18:
		goto loc_82C93534;
	case 19:
		goto loc_82C93210;
	case 20:
		goto loc_82C93534;
	case 21:
		goto loc_82C93534;
	case 22:
		goto loc_82C93534;
	case 23:
		goto loc_82C93534;
	case 24:
		goto loc_82C931D8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,13560(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13560);
	// lwz r22,13584(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13584);
	// lwz r22,13608(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13608);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,12816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12816);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,12816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12816);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,12760(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12760);
loc_82C931D8:
	// clrlwi r4,r7,24
	ctx.r4.u64 = ctx.r7.u32 & 0xFF;
	// lbz r5,1(r10)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r5,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r3,r5,27
	ctx.r3.u64 = ctx.r5.u32 & 0x1F;
	// slw r7,r6,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r5,r4,r11
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r4.u32 + ctx.r11.u32);
	// rotlwi r11,r5,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r5.u32, 3);
	// add r4,r11,r9
	ctx.r4.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r3,r4,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r3,r8
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r8.u32);
	// and r9,r11,r7
	ctx.r9.u64 = ctx.r11.u64 & ctx.r7.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c93534
	if (ctx.cr6.eq) goto loc_82C93534;
loc_82C93210:
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c93110
	if (ctx.cr6.eq) goto loc_82C93110;
loc_82C9321C:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c93238
	if (!ctx.cr6.eq) goto loc_82C93238;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93244
	goto loc_82C93244;
loc_82C93238:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93244;
	sub_82C8DAE8(ctx, base);
loc_82C93244:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c9331c
	if (ctx.cr6.gt) goto loc_82C9331C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,12904
	ctx.r12.s64 = ctx.r12.s64 + 12904;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9332C;
	case 1:
		goto loc_82C93344;
	case 2:
		goto loc_82C9335C;
	case 3:
		goto loc_82C9331C;
	case 4:
		goto loc_82C93374;
	case 5:
		goto loc_82C93374;
	case 6:
		goto loc_82C9331C;
	case 7:
		goto loc_82C9331C;
	case 8:
		goto loc_82C9331C;
	case 9:
		goto loc_82C9331C;
	case 10:
		goto loc_82C934A8;
	case 11:
		goto loc_82C9331C;
	case 12:
		goto loc_82C9331C;
	case 13:
		goto loc_82C9331C;
	case 14:
		goto loc_82C9331C;
	case 15:
		goto loc_82C9331C;
	case 16:
		goto loc_82C93374;
	case 17:
		goto loc_82C93304;
	case 18:
		goto loc_82C9331C;
	case 19:
		goto loc_82C93304;
	case 20:
		goto loc_82C93304;
	case 21:
		goto loc_82C93304;
	case 22:
		goto loc_82C93304;
	case 23:
		goto loc_82C9331C;
	case 24:
		goto loc_82C932CC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,13100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13100);
	// lwz r22,13124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13124);
	// lwz r22,13148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13148);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13172(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13172);
	// lwz r22,13172(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13172);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13480);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13172(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13172);
	// lwz r22,13060(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13060(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13060(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13060(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13060(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13004(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13004);
loc_82C932CC:
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// lbz r9,1(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r10,r9,27,5,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r4,r9,27
	ctx.r4.u64 = ctx.r9.u32 & 0x1F;
	// slw r3,r6,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r3
	ctx.r4.u64 = ctx.r7.u64 & ctx.r3.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c9331c
	if (ctx.cr6.eq) goto loc_82C9331C;
loc_82C93304:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c9321c
	if (!ctx.cr6.eq) goto loc_82C9321C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C9331C:
	// stw r5,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r5.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C9332C:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c9331c
	if (!ctx.cr6.lt) goto loc_82C9331C;
loc_82C93338:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C93344:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c9331c
	if (!ctx.cr6.lt) goto loc_82C9331C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C9335C:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c9331c
	if (!ctx.cr6.lt) goto loc_82C9331C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C93374:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c93028
	ctx.lr = 0x82C93384;
	sub_82C93028(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9331c
	if (ctx.cr6.eq) goto loc_82C9331C;
	// addi r10,r5,2
	ctx.r10.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c93110
	if (ctx.cr6.eq) goto loc_82C93110;
	// subf r9,r10,r30
	ctx.r9.s64 = ctx.r30.s64 - ctx.r10.s64;
loc_82C9339C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c933b8
	if (!ctx.cr6.eq) goto loc_82C933B8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c933c0
	goto loc_82C933C0;
loc_82C933B8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C933C0;
	sub_82C8DAE8(ctx, base);
loc_82C933C0:
	// cmplwi cr6,r3,15
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 15, ctx.xer);
	// bgt cr6,0x82c93428
	if (ctx.cr6.gt) goto loc_82C93428;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,13280
	ctx.r12.s64 = ctx.r12.s64 + 13280;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C93534;
	case 1:
		goto loc_82C93534;
	case 2:
		goto loc_82C93428;
	case 3:
		goto loc_82C93428;
	case 4:
		goto loc_82C93428;
	case 5:
		goto loc_82C93420;
	case 6:
		goto loc_82C93444;
	case 7:
		goto loc_82C93458;
	case 8:
		goto loc_82C93534;
	case 9:
		goto loc_82C93428;
	case 10:
		goto loc_82C93428;
	case 11:
		goto loc_82C93428;
	case 12:
		goto loc_82C93428;
	case 13:
		goto loc_82C93428;
	case 14:
		goto loc_82C93428;
	case 15:
		goto loc_82C9346C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13344(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13344);
	// lwz r22,13380(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13380);
	// lwz r22,13400(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13400);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13420);
loc_82C93420:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c93338
	if (ctx.cr6.lt) goto loc_82C93338;
loc_82C93428:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C93430:
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c9339c
	if (!ctx.cr6.eq) goto loc_82C9339C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C93444:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c93338
	if (ctx.cr6.lt) goto loc_82C93338;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c93430
	goto loc_82C93430;
loc_82C93458:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c93338
	if (ctx.cr6.lt) goto loc_82C93338;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c93430
	goto loc_82C93430;
loc_82C9346C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c93110
	if (ctx.cr6.eq) goto loc_82C93110;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c93430
	if (!ctx.cr6.eq) goto loc_82C93430;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c93430
	if (!ctx.cr6.eq) goto loc_82C93430;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C934A8:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c93028
	ctx.lr = 0x82C934B8;
	sub_82C93028(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9331c
	if (ctx.cr6.eq) goto loc_82C9331C;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c93110
	if (ctx.cr6.eq) goto loc_82C93110;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9331c
	if (!ctx.cr6.eq) goto loc_82C9331C;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c9331c
	if (!ctx.cr6.eq) goto loc_82C9331C;
	// addi r11,r5,2
	ctx.r11.s64 = ctx.r5.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C934F8:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c93534
	if (!ctx.cr6.lt) goto loc_82C93534;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C93510:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c93534
	if (!ctx.cr6.lt) goto loc_82C93534;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
loc_82C93528:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c93338
	if (ctx.cr6.lt) goto loc_82C93338;
loc_82C93534:
	// stw r10,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C93548"))) PPC_WEAK_FUNC(sub_82C93548);
PPC_FUNC_IMPL(__imp__sub_82C93548) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93578
	if (!ctx.cr6.eq) goto loc_82C93578;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93578:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c935ac
	if (ctx.cr6.eq) goto loc_82C935AC;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c935a8
	if (!ctx.cr6.eq) goto loc_82C935A8;
loc_82C93594:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C935A8:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C935AC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c935c8
	if (!ctx.cr6.eq) goto loc_82C935C8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c935d0
	goto loc_82C935D0;
loc_82C935C8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C935D0;
	sub_82C8DAE8(ctx, base);
loc_82C935D0:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c93758
	if (ctx.cr6.gt) goto loc_82C93758;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,13808
	ctx.r12.s64 = ctx.r12.s64 + 13808;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C93740;
	case 1:
		goto loc_82C93740;
	case 2:
		goto loc_82C93758;
	case 3:
		goto loc_82C93758;
	case 4:
		goto loc_82C9361C;
	case 5:
		goto loc_82C936F8;
	case 6:
		goto loc_82C93718;
	case 7:
		goto loc_82C9372C;
	case 8:
		goto loc_82C93740;
	case 9:
		goto loc_82C93688;
	case 10:
		goto loc_82C936DC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14144(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14144);
	// lwz r22,14144(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14144);
	// lwz r22,14168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14168);
	// lwz r22,14168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14168);
	// lwz r22,13852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13852);
	// lwz r22,14072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14072);
	// lwz r22,14104(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14104);
	// lwz r22,14124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14124);
	// lwz r22,14144(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14144);
	// lwz r22,13960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13960);
	// lwz r22,14044(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14044);
loc_82C9361C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93594
	if (ctx.cr6.eq) goto loc_82C93594;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9375c
	if (!ctx.cr6.eq) goto loc_82C9375C;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c9375c
	if (!ctx.cr6.eq) goto loc_82C9375C;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93594
	if (ctx.cr6.eq) goto loc_82C93594;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c93680
	if (!ctx.cr6.eq) goto loc_82C93680;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c93680
	if (!ctx.cr6.eq) goto loc_82C93680;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,40
	ctx.r3.s64 = 40;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93680:
	// addi r10,r11,-2
	ctx.r10.s64 = ctx.r11.s64 + -2;
	// b 0x82c9375c
	goto loc_82C9375C;
loc_82C93688:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93594
	if (ctx.cr6.eq) goto loc_82C93594;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c936b0
	if (!ctx.cr6.eq) goto loc_82C936B0;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c936b8
	goto loc_82C936B8;
loc_82C936B0:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C936B8;
	sub_82C8DAE8(ctx, base);
loc_82C936B8:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c936c4
	if (!ctx.cr6.eq) goto loc_82C936C4;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C936C4:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C936DC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C936F8:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c93758
	if (!ctx.cr6.lt) goto loc_82C93758;
loc_82C93704:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93718:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c93704
	if (ctx.cr6.lt) goto loc_82C93704;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c9375c
	goto loc_82C9375C;
loc_82C9372C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c93704
	if (ctx.cr6.lt) goto loc_82C93704;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c9375c
	goto loc_82C9375C;
loc_82C93740:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93758:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C9375C:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c937f0
	if (ctx.cr6.eq) goto loc_82C937F0;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C93768:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c93784
	if (!ctx.cr6.eq) goto loc_82C93784;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9378c
	goto loc_82C9378C;
loc_82C93784:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9378C;
	sub_82C8DAE8(ctx, base);
loc_82C9378C:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c937e0
	if (ctx.cr6.gt) goto loc_82C937E0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,14252
	ctx.r12.s64 = ctx.r12.s64 + 14252;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C937F0;
	case 1:
		goto loc_82C937F0;
	case 2:
		goto loc_82C937E0;
	case 3:
		goto loc_82C937E0;
	case 4:
		goto loc_82C937F0;
	case 5:
		goto loc_82C937D8;
	case 6:
		goto loc_82C93808;
	case 7:
		goto loc_82C9381C;
	case 8:
		goto loc_82C937F0;
	case 9:
		goto loc_82C937F0;
	case 10:
		goto loc_82C937F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14304);
	// lwz r22,14304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14304);
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14296(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14296);
	// lwz r22,14344(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14344);
	// lwz r22,14364(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14364);
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
loc_82C937D8:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c937f0
	if (ctx.cr6.lt) goto loc_82C937F0;
loc_82C937E0:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C937E8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93768
	if (!ctx.cr6.eq) goto loc_82C93768;
loc_82C937F0:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93808:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c937f0
	if (ctx.cr6.lt) goto loc_82C937F0;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c937e8
	goto loc_82C937E8;
loc_82C9381C:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c937f0
	if (ctx.cr6.lt) goto loc_82C937F0;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c937e8
	goto loc_82C937E8;
}

__attribute__((alias("__imp__sub_82C93830"))) PPC_WEAK_FUNC(sub_82C93830);
PPC_FUNC_IMPL(__imp__sub_82C93830) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9385c
	if (!ctx.cr6.eq) goto loc_82C9385C;
loc_82C93854:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C9385C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c93878
	if (!ctx.cr6.eq) goto loc_82C93878;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93884
	goto loc_82C93884;
loc_82C93878:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93884;
	sub_82C8DAE8(ctx, base);
loc_82C93884:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c93b40
	if (ctx.cr6.gt) goto loc_82C93B40;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,14516
	ctx.r12.s64 = ctx.r12.s64 + 14516;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93A58;
	case 1:
		goto loc_82C93A6C;
	case 2:
		goto loc_82C93B2C;
	case 3:
		goto loc_82C93B40;
	case 4:
		goto loc_82C93B40;
	case 5:
		goto loc_82C93B40;
	case 6:
		goto loc_82C93B40;
	case 7:
		goto loc_82C93B40;
	case 8:
		goto loc_82C93B40;
	case 9:
		goto loc_82C93B40;
	case 10:
		goto loc_82C93B40;
	case 11:
		goto loc_82C93B40;
	case 12:
		goto loc_82C93B40;
	case 13:
		goto loc_82C93B40;
	case 14:
		goto loc_82C93B40;
	case 15:
		goto loc_82C93B40;
	case 16:
		goto loc_82C93B40;
	case 17:
		goto loc_82C93950;
	case 18:
		goto loc_82C93B40;
	case 19:
		goto loc_82C93950;
	case 20:
		goto loc_82C93B40;
	case 21:
		goto loc_82C93B40;
	case 22:
		goto loc_82C93B40;
	case 23:
		goto loc_82C93B40;
	case 24:
		goto loc_82C93918;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14936);
	// lwz r22,14956(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14956);
	// lwz r22,15148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15148);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14672);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14672);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14616(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14616);
loc_82C93918:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r11.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c93b40
	if (ctx.cr6.eq) goto loc_82C93B40;
loc_82C93950:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93854
	if (ctx.cr6.eq) goto loc_82C93854;
loc_82C9395C:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c93978
	if (!ctx.cr6.eq) goto loc_82C93978;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93984
	goto loc_82C93984;
loc_82C93978:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93984;
	sub_82C8DAE8(ctx, base);
loc_82C93984:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c93b40
	if (ctx.cr6.gt) goto loc_82C93B40;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,14760
	ctx.r12.s64 = ctx.r12.s64 + 14760;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93A58;
	case 1:
		goto loc_82C93A6C;
	case 2:
		goto loc_82C93B2C;
	case 3:
		goto loc_82C93B40;
	case 4:
		goto loc_82C93A80;
	case 5:
		goto loc_82C93A80;
	case 6:
		goto loc_82C93B1C;
	case 7:
		goto loc_82C93B40;
	case 8:
		goto loc_82C93B40;
	case 9:
		goto loc_82C93B40;
	case 10:
		goto loc_82C93B40;
	case 11:
		goto loc_82C93B40;
	case 12:
		goto loc_82C93B40;
	case 13:
		goto loc_82C93B40;
	case 14:
		goto loc_82C93B40;
	case 15:
		goto loc_82C93B40;
	case 16:
		goto loc_82C93A80;
	case 17:
		goto loc_82C93A44;
	case 18:
		goto loc_82C93A44;
	case 19:
		goto loc_82C93A44;
	case 20:
		goto loc_82C93A44;
	case 21:
		goto loc_82C93A44;
	case 22:
		goto loc_82C93A44;
	case 23:
		goto loc_82C93B40;
	case 24:
		goto loc_82C93A0C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14936);
	// lwz r22,14956(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14956);
	// lwz r22,15148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15148);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14976);
	// lwz r22,14976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14976);
	// lwz r22,15132(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15132);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14976);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14860(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14860);
loc_82C93A0C:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c93b40
	if (ctx.cr6.eq) goto loc_82C93B40;
loc_82C93A44:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9395c
	if (!ctx.cr6.eq) goto loc_82C9395C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93A58:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c93b40
	if (!ctx.cr6.lt) goto loc_82C93B40;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93A6C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c93b40
	if (!ctx.cr6.lt) goto loc_82C93B40;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93A80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93854
	if (ctx.cr6.eq) goto loc_82C93854;
loc_82C93A8C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c93aa8
	if (!ctx.cr6.eq) goto loc_82C93AA8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93ab0
	goto loc_82C93AB0;
loc_82C93AA8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93AB0;
	sub_82C8DAE8(ctx, base);
loc_82C93AB0:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bgt cr6,0x82c93b40
	if (ctx.cr6.gt) goto loc_82C93B40;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,15060
	ctx.r12.s64 = ctx.r12.s64 + 15060;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93B08;
	case 1:
		goto loc_82C93B08;
	case 2:
		goto loc_82C93B1C;
	case 3:
		goto loc_82C93B40;
	case 4:
		goto loc_82C93B40;
	case 5:
		goto loc_82C93B40;
	case 6:
		goto loc_82C93B40;
	case 7:
		goto loc_82C93B40;
	case 8:
		goto loc_82C93B40;
	case 9:
		goto loc_82C93B40;
	case 10:
		goto loc_82C93B40;
	case 11:
		goto loc_82C93B40;
	case 12:
		goto loc_82C93B08;
	default:
		__builtin_unreachable();
	}
	// lwz r22,15112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15112);
	// lwz r22,15112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15112);
	// lwz r22,15132(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15132);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15112);
loc_82C93B08:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93a8c
	if (!ctx.cr6.eq) goto loc_82C93A8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93B1C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,5
	ctx.r3.s64 = 5;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93B2C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c93b40
	if (!ctx.cr6.lt) goto loc_82C93B40;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93B40:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C93B48:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C93B60"))) PPC_WEAK_FUNC(sub_82C93B60);
PPC_FUNC_IMPL(__imp__sub_82C93B60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93c04
	if (ctx.cr6.eq) goto loc_82C93C04;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c93b98
	if (!ctx.cr6.eq) goto loc_82C93B98;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93ba0
	goto loc_82C93BA0;
loc_82C93B98:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93BA0;
	sub_82C8DAE8(ctx, base);
loc_82C93BA0:
	// cmpwi cr6,r3,24
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 24, ctx.xer);
	// blt cr6,0x82c93c34
	if (ctx.cr6.lt) goto loc_82C93C34;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bgt cr6,0x82c93c34
	if (ctx.cr6.gt) goto loc_82C93C34;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93c04
	if (ctx.cr6.eq) goto loc_82C93C04;
loc_82C93BBC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c93bd8
	if (!ctx.cr6.eq) goto loc_82C93BD8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93be0
	goto loc_82C93BE0;
loc_82C93BD8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93BE0;
	sub_82C8DAE8(ctx, base);
loc_82C93BE0:
	// cmpwi cr6,r3,18
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 18, ctx.xer);
	// beq cr6,0x82c93c18
	if (ctx.cr6.eq) goto loc_82C93C18;
	// cmpwi cr6,r3,23
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 23, ctx.xer);
	// ble cr6,0x82c93c34
	if (!ctx.cr6.gt) goto loc_82C93C34;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bgt cr6,0x82c93c34
	if (ctx.cr6.gt) goto loc_82C93C34;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93bbc
	if (!ctx.cr6.eq) goto loc_82C93BBC;
loc_82C93C04:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93C18:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93C34:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C93C50"))) PPC_WEAK_FUNC(sub_82C93C50);
PPC_FUNC_IMPL(__imp__sub_82C93C50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93d30
	if (ctx.cr6.eq) goto loc_82C93D30;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// extsb r11,r3
	ctx.r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c93cbc
	if (!ctx.cr6.eq) goto loc_82C93CBC;
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r8,120
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 120, ctx.xer);
	// bne cr6,0x82c93ca4
	if (!ctx.cr6.eq) goto loc_82C93CA4;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c93b60
	ctx.lr = 0x82C93C94;
	sub_82C93B60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93CA4:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c93cbc
	if (!ctx.cr6.eq) goto loc_82C93CBC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93cc4
	goto loc_82C93CC4;
loc_82C93CBC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93CC4;
	sub_82C8DAE8(ctx, base);
loc_82C93CC4:
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// beq cr6,0x82c93ce4
	if (ctx.cr6.eq) goto loc_82C93CE4;
loc_82C93CCC:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93CE4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93d30
	if (ctx.cr6.eq) goto loc_82C93D30;
loc_82C93CF0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c93d0c
	if (!ctx.cr6.eq) goto loc_82C93D0C;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93d14
	goto loc_82C93D14;
loc_82C93D0C:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93D14;
	sub_82C8DAE8(ctx, base);
loc_82C93D14:
	// cmpwi cr6,r3,18
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 18, ctx.xer);
	// beq cr6,0x82c93d44
	if (ctx.cr6.eq) goto loc_82C93D44;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bne cr6,0x82c93ccc
	if (!ctx.cr6.eq) goto loc_82C93CCC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93cf0
	if (!ctx.cr6.eq) goto loc_82C93CF0;
loc_82C93D30:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93D44:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C93D60"))) PPC_WEAK_FUNC(sub_82C93D60);
PPC_FUNC_IMPL(__imp__sub_82C93D60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93d8c
	if (!ctx.cr6.eq) goto loc_82C93D8C;
loc_82C93D84:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93D8C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c93da8
	if (!ctx.cr6.eq) goto loc_82C93DA8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93db4
	goto loc_82C93DB4;
loc_82C93DA8:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93DB4;
	sub_82C8DAE8(ctx, base);
loc_82C93DB4:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c93fe4
	if (ctx.cr6.gt) goto loc_82C93FE4;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,15844
	ctx.r12.s64 = ctx.r12.s64 + 15844;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93F88;
	case 1:
		goto loc_82C93F9C;
	case 2:
		goto loc_82C93FB0;
	case 3:
		goto loc_82C93FE4;
	case 4:
		goto loc_82C93FE4;
	case 5:
		goto loc_82C93FE4;
	case 6:
		goto loc_82C93FE4;
	case 7:
		goto loc_82C93FE4;
	case 8:
		goto loc_82C93FE4;
	case 9:
		goto loc_82C93FE4;
	case 10:
		goto loc_82C93FE4;
	case 11:
		goto loc_82C93FE4;
	case 12:
		goto loc_82C93FE4;
	case 13:
		goto loc_82C93FE4;
	case 14:
		goto loc_82C93FD4;
	case 15:
		goto loc_82C93FE4;
	case 16:
		goto loc_82C93FE4;
	case 17:
		goto loc_82C93E80;
	case 18:
		goto loc_82C93FE4;
	case 19:
		goto loc_82C93E80;
	case 20:
		goto loc_82C93FE4;
	case 21:
		goto loc_82C93FE4;
	case 22:
		goto loc_82C93FE4;
	case 23:
		goto loc_82C93FE4;
	case 24:
		goto loc_82C93E48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,16264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16264);
	// lwz r22,16284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16284);
	// lwz r22,16304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16304);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16340(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16340);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16000);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16000);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,15944(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15944);
loc_82C93E48:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r11.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c93fe4
	if (ctx.cr6.eq) goto loc_82C93FE4;
loc_82C93E80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93d84
	if (ctx.cr6.eq) goto loc_82C93D84;
loc_82C93E8C:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c93ea8
	if (!ctx.cr6.eq) goto loc_82C93EA8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93eb4
	goto loc_82C93EB4;
loc_82C93EA8:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93EB4;
	sub_82C8DAE8(ctx, base);
loc_82C93EB4:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c93fe4
	if (ctx.cr6.gt) goto loc_82C93FE4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,16088
	ctx.r12.s64 = ctx.r12.s64 + 16088;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93F88;
	case 1:
		goto loc_82C93F9C;
	case 2:
		goto loc_82C93FB0;
	case 3:
		goto loc_82C93FE4;
	case 4:
		goto loc_82C93FE4;
	case 5:
		goto loc_82C93FE4;
	case 6:
		goto loc_82C93FE4;
	case 7:
		goto loc_82C93FE4;
	case 8:
		goto loc_82C93FE4;
	case 9:
		goto loc_82C93FE4;
	case 10:
		goto loc_82C93FE4;
	case 11:
		goto loc_82C93FE4;
	case 12:
		goto loc_82C93FE4;
	case 13:
		goto loc_82C93FC4;
	case 14:
		goto loc_82C93FE4;
	case 15:
		goto loc_82C93FE4;
	case 16:
		goto loc_82C93FE4;
	case 17:
		goto loc_82C93F74;
	case 18:
		goto loc_82C93FE4;
	case 19:
		goto loc_82C93F74;
	case 20:
		goto loc_82C93F74;
	case 21:
		goto loc_82C93F74;
	case 22:
		goto loc_82C93F74;
	case 23:
		goto loc_82C93FE4;
	case 24:
		goto loc_82C93F3C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,16264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16264);
	// lwz r22,16284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16284);
	// lwz r22,16304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16304);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16324(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16324);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16188);
loc_82C93F3C:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c93fe4
	if (ctx.cr6.eq) goto loc_82C93FE4;
loc_82C93F74:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93e8c
	if (!ctx.cr6.eq) goto loc_82C93E8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93F88:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c93fe4
	if (!ctx.cr6.lt) goto loc_82C93FE4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93F9C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c93fe4
	if (!ctx.cr6.lt) goto loc_82C93FE4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FB0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c93fe4
	if (!ctx.cr6.lt) goto loc_82C93FE4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FC4:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,9
	ctx.r3.s64 = 9;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FD4:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c93c50
	ctx.lr = 0x82C93FE0;
	sub_82C93C50(ctx, base);
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FE4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C93FEC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C94008"))) PPC_WEAK_FUNC(sub_82C94008);
PPC_FUNC_IMPL(__imp__sub_82C94008) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C94010;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r27,1
	ctx.r27.s64 = 1;
	// addi r29,r11,-4144
	ctx.r29.s64 = ctx.r11.s64 + -4144;
loc_82C94038:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c94054
	if (!ctx.cr6.eq) goto loc_82C94054;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94060
	goto loc_82C94060;
loc_82C94054:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94060;
	sub_82C8DAE8(ctx, base);
loc_82C94060:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94268
	if (ctx.cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,16516
	ctx.r12.s64 = ctx.r12.s64 + 16516;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94550;
	case 1:
		goto loc_82C94568;
	case 2:
		goto loc_82C94580;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94218;
	case 5:
		goto loc_82C94218;
	case 6:
		goto loc_82C94268;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94268;
	case 9:
		goto loc_82C94278;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94268;
	case 13:
		goto loc_82C94268;
	case 14:
		goto loc_82C94268;
	case 15:
		goto loc_82C94268;
	case 16:
		goto loc_82C94218;
	case 17:
		goto loc_82C94538;
	case 18:
		goto loc_82C9411C;
	case 19:
		goto loc_82C94538;
	case 20:
		goto loc_82C94538;
	case 21:
		goto loc_82C94538;
	case 22:
		goto loc_82C94538;
	case 23:
		goto loc_82C94268;
	case 24:
		goto loc_82C940E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17744);
	// lwz r22,17768(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17768);
	// lwz r22,17792(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17792);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16920(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16920);
	// lwz r22,16920(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16920);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17016(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17016);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16920(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16920);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,16668(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16668);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16616(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16616);
loc_82C940E8:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r7,r29,1536
	ctx.r7.s64 = ctx.r29.s64 + 1536;
	// rlwinm r9,r8,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r8,27
	ctx.r6.u64 = ctx.r8.u32 & 0x1F;
	// slw r4,r27,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r6.u8 & 0x3F));
	// lbzx r3,r11,r7
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r29.u32);
	// and r7,r8,r4
	ctx.r7.u64 = ctx.r8.u64 & ctx.r4.u64;
	// b 0x82c94530
	goto loc_82C94530;
loc_82C9411C:
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne cr6,0x82c94268
	if (!ctx.cr6.eq) goto loc_82C94268;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r28,r27
	ctx.r28.u64 = ctx.r27.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c94150
	if (!ctx.cr6.eq) goto loc_82C94150;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9415c
	goto loc_82C9415C;
loc_82C94150:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9415C;
	sub_82C8DAE8(ctx, base);
loc_82C9415C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94268
	if (ctx.cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,16768
	ctx.r12.s64 = ctx.r12.s64 + 16768;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94550;
	case 1:
		goto loc_82C94568;
	case 2:
		goto loc_82C94580;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94268;
	case 5:
		goto loc_82C94268;
	case 6:
		goto loc_82C94268;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94268;
	case 9:
		goto loc_82C94268;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94268;
	case 13:
		goto loc_82C94268;
	case 14:
		goto loc_82C94268;
	case 15:
		goto loc_82C94268;
	case 16:
		goto loc_82C94268;
	case 17:
		goto loc_82C94538;
	case 18:
		goto loc_82C94268;
	case 19:
		goto loc_82C94538;
	case 20:
		goto loc_82C94268;
	case 21:
		goto loc_82C94268;
	case 22:
		goto loc_82C94268;
	case 23:
		goto loc_82C94268;
	case 24:
		goto loc_82C941E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17744);
	// lwz r22,17768(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17768);
	// lwz r22,17792(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17792);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16868(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16868);
loc_82C941E4:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r7,r29,1280
	ctx.r7.s64 = ctx.r29.s64 + 1280;
	// rlwinm r9,r8,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r8,27
	ctx.r6.u64 = ctx.r8.u32 & 0x1F;
	// slw r4,r27,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r6.u8 & 0x3F));
	// lbzx r3,r11,r7
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r29.u32);
	// and r7,r8,r4
	ctx.r7.u64 = ctx.r8.u64 & ctx.r4.u64;
	// b 0x82c94530
	goto loc_82C94530;
loc_82C94218:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94240
	if (!ctx.cr6.eq) goto loc_82C94240;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94248
	goto loc_82C94248;
loc_82C94240:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94248;
	sub_82C8DAE8(ctx, base);
loc_82C94248:
	// cmpwi cr6,r3,14
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 14, ctx.xer);
	// beq cr6,0x82c94278
	if (ctx.cr6.eq) goto loc_82C94278;
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// blt cr6,0x82c94268
	if (ctx.cr6.lt) goto loc_82C94268;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// ble cr6,0x82c94218
	if (!ctx.cr6.gt) goto loc_82C94218;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// beq cr6,0x82c94218
	if (ctx.cr6.eq) goto loc_82C94218;
loc_82C94268:
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C94278:
	// li r28,0
	ctx.r28.s64 = 0;
loc_82C9427C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c942a4
	if (!ctx.cr6.eq) goto loc_82C942A4;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r31,76(r11)
	ctx.r31.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c942b0
	goto loc_82C942B0;
loc_82C942A4:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C942AC;
	sub_82C8DAE8(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
loc_82C942B0:
	// cmpwi cr6,r31,12
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 12, ctx.xer);
	// beq cr6,0x82c942e8
	if (ctx.cr6.eq) goto loc_82C942E8;
	// cmpwi cr6,r31,13
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 13, ctx.xer);
	// beq cr6,0x82c942e8
	if (ctx.cr6.eq) goto loc_82C942E8;
	// cmpwi cr6,r31,9
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 9, ctx.xer);
	// blt cr6,0x82c94268
	if (ctx.cr6.lt) goto loc_82C94268;
	// cmpwi cr6,r31,10
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 10, ctx.xer);
	// ble cr6,0x82c9427c
	if (!ctx.cr6.gt) goto loc_82C9427C;
	// cmpwi cr6,r31,21
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 21, ctx.xer);
	// beq cr6,0x82c9427c
	if (ctx.cr6.eq) goto loc_82C9427C;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C942E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C942EC:
	// stw r10,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r10.u32);
loc_82C942F0:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94314
	if (!ctx.cr6.eq) goto loc_82C94314;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9431c
	goto loc_82C9431C;
loc_82C94314:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9431C;
	sub_82C8DAE8(ctx, base);
loc_82C9431C:
	// cmpw cr6,r3,r31
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r31.s32, ctx.xer);
	// beq cr6,0x82c943c0
	if (ctx.cr6.eq) goto loc_82C943C0;
	// cmplwi cr6,r3,8
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 8, ctx.xer);
	// bgt cr6,0x82c942e8
	if (ctx.cr6.gt) goto loc_82C942E8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,17220
	ctx.r12.s64 = ctx.r12.s64 + 17220;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C94268;
	case 1:
		goto loc_82C94268;
	case 2:
		goto loc_82C94268;
	case 3:
		goto loc_82C943A0;
	case 4:
		goto loc_82C942E8;
	case 5:
		goto loc_82C94368;
	case 6:
		goto loc_82C94378;
	case 7:
		goto loc_82C9438C;
	case 8:
		goto loc_82C94268;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17312);
	// lwz r22,17128(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17128);
	// lwz r22,17256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17256);
	// lwz r22,17272(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17272);
	// lwz r22,17292(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17292);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
loc_82C94368:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// blt cr6,0x82c9455c
	if (ctx.cr6.lt) goto loc_82C9455C;
	// b 0x82c942e8
	goto loc_82C942E8;
loc_82C94378:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c9455c
	if (ctx.cr6.lt) goto loc_82C9455C;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c942ec
	goto loc_82C942EC;
loc_82C9438C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c9455c
	if (ctx.cr6.lt) goto loc_82C9455C;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c942ec
	goto loc_82C942EC;
loc_82C943A0:
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c93d60
	ctx.lr = 0x82C943B0;
	sub_82C93D60(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// ble cr6,0x82c945f4
	if (!ctx.cr6.gt) goto loc_82C945F4;
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// b 0x82c942f0
	goto loc_82C942F0;
loc_82C943C0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c943e8
	if (!ctx.cr6.eq) goto loc_82C943E8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c943f0
	goto loc_82C943F0;
loc_82C943E8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C943F0;
	sub_82C8DAE8(ctx, base);
loc_82C943F0:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bgt cr6,0x82c94268
	if (ctx.cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,17428
	ctx.r12.s64 = ctx.r12.s64 + 17428;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94448;
	case 1:
		goto loc_82C94448;
	case 2:
		goto loc_82C945E0;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94268;
	case 5:
		goto loc_82C94268;
	case 6:
		goto loc_82C94268;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94598;
	case 9:
		goto loc_82C94268;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94448;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17888(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17888);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17816);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
loc_82C94448:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94470
	if (!ctx.cr6.eq) goto loc_82C94470;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94478
	goto loc_82C94478;
loc_82C94470:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94478;
	sub_82C8DAE8(ctx, base);
loc_82C94478:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94268
	if (ctx.cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,17564
	ctx.r12.s64 = ctx.r12.s64 + 17564;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94550;
	case 1:
		goto loc_82C94568;
	case 2:
		goto loc_82C94580;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94448;
	case 5:
		goto loc_82C94448;
	case 6:
		goto loc_82C945E0;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94268;
	case 9:
		goto loc_82C94268;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94598;
	case 13:
		goto loc_82C94268;
	case 14:
		goto loc_82C94268;
	case 15:
		goto loc_82C94268;
	case 16:
		goto loc_82C94448;
	case 17:
		goto loc_82C94538;
	case 18:
		goto loc_82C94268;
	case 19:
		goto loc_82C94538;
	case 20:
		goto loc_82C94268;
	case 21:
		goto loc_82C94268;
	case 22:
		goto loc_82C94268;
	case 23:
		goto loc_82C94268;
	case 24:
		goto loc_82C94500;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17744);
	// lwz r22,17768(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17768);
	// lwz r22,17792(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17792);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17888(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17888);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17816);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17664(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17664);
loc_82C94500:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r8,r29,1280
	ctx.r8.s64 = ctx.r29.s64 + 1280;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r7,27
	ctx.r6.u64 = ctx.r7.u32 & 0x1F;
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// slw r3,r27,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r6.u8 & 0x3F));
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r29.u32);
	// and r7,r8,r3
	ctx.r7.u64 = ctx.r8.u64 & ctx.r3.u64;
loc_82C94530:
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c94268
	if (ctx.cr6.eq) goto loc_82C94268;
loc_82C94538:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94038
	if (!ctx.cr6.eq) goto loc_82C94038;
loc_82C94544:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82C94548:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C94550:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c94268
	if (!ctx.cr6.lt) goto loc_82C94268;
loc_82C9455C:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C94568:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c94268
	if (!ctx.cr6.lt) goto loc_82C94268;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C94580:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c94268
	if (!ctx.cr6.lt) goto loc_82C94268;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C94598:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c945d0
	if (!ctx.cr6.eq) goto loc_82C945D0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c945d0
	if (!ctx.cr6.eq) goto loc_82C945D0;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,3
	ctx.r3.s64 = 3;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C945D0:
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C945E0:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
loc_82C945F4:
	// bne cr6,0x82c94548
	if (!ctx.cr6.eq) goto loc_82C94548;
	// lwz r11,172(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C94608"))) PPC_WEAK_FUNC(sub_82C94608);
PPC_FUNC_IMPL(__imp__sub_82C94608) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94634
	if (!ctx.cr6.eq) goto loc_82C94634;
loc_82C9462C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94634:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c94650
	if (!ctx.cr6.eq) goto loc_82C94650;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9465c
	goto loc_82C9465C;
loc_82C94650:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9465C;
	sub_82C8DAE8(ctx, base);
loc_82C9465C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94b74
	if (ctx.cr6.gt) goto loc_82C94B74;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r7,r9,-4144
	ctx.r7.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,18060
	ctx.r12.s64 = ctx.r12.s64 + 18060;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C94B74;
	case 5:
		goto loc_82C94B74;
	case 6:
		goto loc_82C94B74;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B54;
	case 11:
		goto loc_82C94AA0;
	case 12:
		goto loc_82C94B64;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C94B74;
	case 17:
		goto loc_82C94728;
	case 18:
		goto loc_82C94B74;
	case 19:
		goto loc_82C94728;
	case 20:
		goto loc_82C94B74;
	case 21:
		goto loc_82C94B74;
	case 22:
		goto loc_82C94B74;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C946F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19284);
	// lwz r22,19104(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19104);
	// lwz r22,19300(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19300);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18216(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18216);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18216(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18216);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18160(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18160);
loc_82C946F0:
	// clrlwi r3,r8,24
	ctx.r3.u64 = ctx.r8.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r9,r7,1280
	ctx.r9.s64 = ctx.r7.s64 + 1280;
	// rlwinm r11,r4,27,5,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r8,r4,27
	ctx.r8.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r8
	ctx.r4.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r8.u8 & 0x3F));
	// lbzx r3,r3,r9
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r9.u32);
	// rotlwi r9,r3,3
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// and r4,r8,r4
	ctx.r4.u64 = ctx.r8.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c94b74
	if (ctx.cr6.eq) goto loc_82C94B74;
loc_82C94728:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9462c
	if (ctx.cr6.eq) goto loc_82C9462C;
loc_82C94738:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c94754
	if (!ctx.cr6.eq) goto loc_82C94754;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94760
	goto loc_82C94760;
loc_82C94754:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94760;
	sub_82C8DAE8(ctx, base);
loc_82C94760:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94b74
	if (ctx.cr6.gt) goto loc_82C94B74;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,18308
	ctx.r12.s64 = ctx.r12.s64 + 18308;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C94940;
	case 5:
		goto loc_82C94940;
	case 6:
		goto loc_82C94A54;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B74;
	case 11:
		goto loc_82C94B74;
	case 12:
		goto loc_82C94A64;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C94940;
	case 17:
		goto loc_82C948F0;
	case 18:
		goto loc_82C947F0;
	case 19:
		goto loc_82C948F0;
	case 20:
		goto loc_82C948F0;
	case 21:
		goto loc_82C948F0;
	case 22:
		goto loc_82C948F0;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C947E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18752(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18752);
	// lwz r22,18752(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18752);
	// lwz r22,19028(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19028);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19044(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19044);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18752(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18752);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18416);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18408);
loc_82C947E8:
	// addi r3,r7,1536
	ctx.r3.s64 = ctx.r7.s64 + 1536;
	// b 0x82c948bc
	goto loc_82C948BC;
loc_82C947F0:
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne cr6,0x82c94b74
	if (!ctx.cr6.eq) goto loc_82C94B74;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r8,r31
	ctx.r8.u64 = ctx.r31.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9462c
	if (ctx.cr6.eq) goto loc_82C9462C;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c94824
	if (!ctx.cr6.eq) goto loc_82C94824;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94830
	goto loc_82C94830;
loc_82C94824:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94830;
	sub_82C8DAE8(ctx, base);
loc_82C94830:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94b74
	if (ctx.cr6.gt) goto loc_82C94B74;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,18516
	ctx.r12.s64 = ctx.r12.s64 + 18516;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C94B74;
	case 5:
		goto loc_82C94B74;
	case 6:
		goto loc_82C94B74;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B74;
	case 11:
		goto loc_82C94B74;
	case 12:
		goto loc_82C94B74;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C94B74;
	case 17:
		goto loc_82C948F0;
	case 18:
		goto loc_82C94B74;
	case 19:
		goto loc_82C948F0;
	case 20:
		goto loc_82C94B74;
	case 21:
		goto loc_82C94B74;
	case 22:
		goto loc_82C94B74;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C948B8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18616(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18616);
loc_82C948B8:
	// addi r3,r7,1280
	ctx.r3.s64 = ctx.r7.s64 + 1280;
loc_82C948BC:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r3,r11,r3
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r3.u32);
	// slw r4,r31,r4
	ctx.r4.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r9,r7
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// and r11,r3,r4
	ctx.r11.u64 = ctx.r3.u64 & ctx.r4.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c94b74
	if (ctx.cr6.eq) goto loc_82C94B74;
loc_82C948F0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94738
	if (!ctx.cr6.eq) goto loc_82C94738;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94904:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c94b74
	if (!ctx.cr6.lt) goto loc_82C94B74;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94918:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c94b74
	if (!ctx.cr6.lt) goto loc_82C94B74;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C9492C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c94b74
	if (!ctx.cr6.lt) goto loc_82C94B74;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94940:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9462c
	if (ctx.cr6.eq) goto loc_82C9462C;
loc_82C9494C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94968
	if (!ctx.cr6.eq) goto loc_82C94968;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94970
	goto loc_82C94970;
loc_82C94968:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94970;
	sub_82C8DAE8(ctx, base);
loc_82C94970:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94b74
	if (ctx.cr6.gt) goto loc_82C94B74;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,18836
	ctx.r12.s64 = ctx.r12.s64 + 18836;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C949F8;
	case 5:
		goto loc_82C949F8;
	case 6:
		goto loc_82C94A54;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B74;
	case 11:
		goto loc_82C94B74;
	case 12:
		goto loc_82C94A64;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C949F8;
	case 17:
		goto loc_82C94A44;
	case 18:
		goto loc_82C94B74;
	case 19:
		goto loc_82C94A44;
	case 20:
		goto loc_82C94B74;
	case 21:
		goto loc_82C94B74;
	case 22:
		goto loc_82C94B74;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C94A0C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18936);
	// lwz r22,18936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18936);
	// lwz r22,19028(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19028);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19044(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19044);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18936);
	// lwz r22,19012(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19012);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19012(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19012);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18956(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18956);
loc_82C949F8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9494c
	if (!ctx.cr6.eq) goto loc_82C9494C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A0C:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r8,r7,1280
	ctx.r8.s64 = ctx.r7.s64 + 1280;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r3,r4,27
	ctx.r3.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r11,r11,r8
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// slw r8,r31,r3
	ctx.r8.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r4,r11,r9
	ctx.r4.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r3,r4,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r3,r7
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r7.u32);
	// and r9,r11,r8
	ctx.r9.u64 = ctx.r11.u64 & ctx.r8.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c94b74
	if (ctx.cr6.eq) goto loc_82C94B74;
loc_82C94A44:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c94008
	ctx.lr = 0x82C94A50;
	sub_82C94008(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A54:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A64:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9462c
	if (ctx.cr6.eq) goto loc_82C9462C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c94a98
	if (!ctx.cr6.eq) goto loc_82C94A98;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c94a98
	if (!ctx.cr6.eq) goto loc_82C94A98;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,4
	ctx.r3.s64 = 4;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A98:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c94b78
	goto loc_82C94B78;
loc_82C94AA0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9462c
	if (ctx.cr6.eq) goto loc_82C9462C;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94ac8
	if (!ctx.cr6.eq) goto loc_82C94AC8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94ad0
	goto loc_82C94AD0;
loc_82C94AC8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94AD0;
	sub_82C8DAE8(ctx, base);
loc_82C94AD0:
	// cmpwi cr6,r3,20
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 20, ctx.xer);
	// beq cr6,0x82c94af0
	if (ctx.cr6.eq) goto loc_82C94AF0;
	// cmpwi cr6,r3,27
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 27, ctx.xer);
	// bne cr6,0x82c94b74
	if (!ctx.cr6.eq) goto loc_82C94B74;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c92ba0
	ctx.lr = 0x82C94AEC;
	sub_82C92BA0(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94AF0:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// subf r10,r11,r5
	ctx.r10.s64 = ctx.r5.s64 - ctx.r11.s64;
	// cmpwi cr6,r10,12
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 12, ctx.xer);
	// blt cr6,0x82c9462c
	if (ctx.cr6.lt) goto loc_82C9462C;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r9,-4144
	ctx.r9.s64 = ctx.r9.s64 + -4144;
loc_82C94B0C:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c94b48
	if (!ctx.cr6.eq) goto loc_82C94B48;
	// addi r8,r9,5488
	ctx.r8.s64 = ctx.r9.s64 + 5488;
	// lbz r7,1(r11)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// lbzx r5,r10,r8
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r8.u32);
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94b48
	if (!ctx.cr6.eq) goto loc_82C94B48;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// cmpwi cr6,r10,6
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 6, ctx.xer);
	// blt cr6,0x82c94b0c
	if (ctx.cr6.lt) goto loc_82C94B0C;
	// li r3,8
	ctx.r3.s64 = 8;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B48:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B54:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c930e8
	ctx.lr = 0x82C94B60;
	sub_82C930E8(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B64:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c93830
	ctx.lr = 0x82C94B70;
	sub_82C93830(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B74:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C94B78:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C94B7C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C94B98"))) PPC_WEAK_FUNC(sub_82C94B98);
PPC_FUNC_IMPL(__imp__sub_82C94B98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94bd0
	if (!ctx.cr6.eq) goto loc_82C94BD0;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94BD0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c94c08
	if (ctx.cr6.eq) goto loc_82C94C08;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c94c04
	if (!ctx.cr6.eq) goto loc_82C94C04;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94C04:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C94C08:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94c24
	if (!ctx.cr6.eq) goto loc_82C94C24;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94c2c
	goto loc_82C94C2C;
loc_82C94C24:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94C2C;
	sub_82C8DAE8(ctx, base);
loc_82C94C2C:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c94e0c
	if (ctx.cr6.gt) goto loc_82C94E0C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,19532
	ctx.r12.s64 = ctx.r12.s64 + 19532;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C94E04;
	case 1:
		goto loc_82C94E04;
	case 2:
		goto loc_82C94C78;
	case 3:
		goto loc_82C94C98;
	case 4:
		goto loc_82C94D34;
	case 5:
		goto loc_82C94DB8;
	case 6:
		goto loc_82C94DDC;
	case 7:
		goto loc_82C94DF0;
	case 8:
		goto loc_82C94E04;
	case 9:
		goto loc_82C94CB8;
	case 10:
		goto loc_82C94D14;
	default:
		__builtin_unreachable();
	}
	// lwz r22,19972(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19972);
	// lwz r22,19972(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19972);
	// lwz r22,19576(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19576);
	// lwz r22,19608(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19608);
	// lwz r22,19764(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19764);
	// lwz r22,19896(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19896);
	// lwz r22,19932(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19932);
	// lwz r22,19952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19952);
	// lwz r22,19972(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19972);
	// lwz r22,19640(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19640);
	// lwz r22,19732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19732);
loc_82C94C78:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c94608
	ctx.lr = 0x82C94C84;
	sub_82C94608(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94C98:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c93d60
	ctx.lr = 0x82C94CA4;
	sub_82C93D60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94CB8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94cdc
	if (!ctx.cr6.eq) goto loc_82C94CDC;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94CDC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94cf8
	if (!ctx.cr6.eq) goto loc_82C94CF8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94d00
	goto loc_82C94D00;
loc_82C94CF8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94D00;
	sub_82C8DAE8(ctx, base);
loc_82C94D00:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c94d0c
	if (!ctx.cr6.eq) goto loc_82C94D0C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C94D0C:
	// li r3,7
	ctx.r3.s64 = 7;
	// b 0x82c94ea0
	goto loc_82C94EA0;
loc_82C94D14:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94D34:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94d58
	if (!ctx.cr6.eq) goto loc_82C94D58;
loc_82C94D40:
	// li r3,-5
	ctx.r3.s64 = -5;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94D58:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c94e10
	if (!ctx.cr6.eq) goto loc_82C94E10;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c94e10
	if (!ctx.cr6.eq) goto loc_82C94E10;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94d40
	if (ctx.cr6.eq) goto loc_82C94D40;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c94db0
	if (!ctx.cr6.eq) goto loc_82C94DB0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c94db0
	if (!ctx.cr6.eq) goto loc_82C94DB0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94DB0:
	// addi r10,r11,-2
	ctx.r10.s64 = ctx.r11.s64 + -2;
	// b 0x82c94e10
	goto loc_82C94E10;
loc_82C94DB8:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c94e0c
	if (!ctx.cr6.lt) goto loc_82C94E0C;
loc_82C94DC4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94DDC:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c94dc4
	if (ctx.cr6.lt) goto loc_82C94DC4;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c94e10
	goto loc_82C94E10;
loc_82C94DF0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c94dc4
	if (ctx.cr6.lt) goto loc_82C94DC4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c94e10
	goto loc_82C94E10;
loc_82C94E04:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c94ea0
	goto loc_82C94EA0;
loc_82C94E0C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C94E10:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94e9c
	if (ctx.cr6.eq) goto loc_82C94E9C;
	// addi r7,r10,4
	ctx.r7.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C94E24:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94e40
	if (!ctx.cr6.eq) goto loc_82C94E40;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94e48
	goto loc_82C94E48;
loc_82C94E40:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94E48;
	sub_82C8DAE8(ctx, base);
loc_82C94E48:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c94f30
	if (ctx.cr6.gt) goto loc_82C94F30;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,20072
	ctx.r12.s64 = ctx.r12.s64 + 20072;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C94E9C;
	case 1:
		goto loc_82C94E9C;
	case 2:
		goto loc_82C94E9C;
	case 3:
		goto loc_82C94E9C;
	case 4:
		goto loc_82C94EF0;
	case 5:
		goto loc_82C94E94;
	case 6:
		goto loc_82C94EB8;
	case 7:
		goto loc_82C94ED4;
	case 8:
		goto loc_82C94E9C;
	case 9:
		goto loc_82C94E9C;
	case 10:
		goto loc_82C94E9C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20208(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20208);
	// lwz r22,20116(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20116);
	// lwz r22,20152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20152);
	// lwz r22,20180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20180);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
loc_82C94E94:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bge cr6,0x82c94f30
	if (!ctx.cr6.lt) goto loc_82C94F30;
loc_82C94E9C:
	// li r3,6
	ctx.r3.s64 = 6;
loc_82C94EA0:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94EB8:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c94e9c
	if (ctx.cr6.lt) goto loc_82C94E9C;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// addi r8,r8,3
	ctx.r8.s64 = ctx.r8.s64 + 3;
	// addi r7,r7,3
	ctx.r7.s64 = ctx.r7.s64 + 3;
	// b 0x82c94f40
	goto loc_82C94F40;
loc_82C94ED4:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c94e9c
	if (ctx.cr6.lt) goto loc_82C94E9C;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// b 0x82c94f40
	goto loc_82C94F40;
loc_82C94EF0:
	// cmplw cr6,r8,r5
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94e9c
	if (ctx.cr6.eq) goto loc_82C94E9C;
	// lbz r11,0(r8)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c94f30
	if (!ctx.cr6.eq) goto loc_82C94F30;
	// lbz r11,3(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c94f30
	if (!ctx.cr6.eq) goto loc_82C94F30;
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94e9c
	if (ctx.cr6.eq) goto loc_82C94E9C;
	// lbz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c94f30
	if (!ctx.cr6.eq) goto loc_82C94F30;
	// lbz r11,5(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 5);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// beq cr6,0x82c94f4c
	if (ctx.cr6.eq) goto loc_82C94F4C;
loc_82C94F30:
	// addi r7,r7,2
	ctx.r7.s64 = ctx.r7.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C94F40:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94e24
	if (!ctx.cr6.eq) goto loc_82C94E24;
	// b 0x82c94e9c
	goto loc_82C94E9C;
loc_82C94F4C:
	// addi r11,r10,4
	ctx.r11.s64 = ctx.r10.s64 + 4;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C94F70"))) PPC_WEAK_FUNC(sub_82C94F70);
PPC_FUNC_IMPL(__imp__sub_82C94F70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94f9c
	if (!ctx.cr6.eq) goto loc_82C94F9C;
	// li r3,-22
	ctx.r3.s64 = -22;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C94F9C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c94fb8
	if (!ctx.cr6.eq) goto loc_82C94FB8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94fc4
	goto loc_82C94FC4;
loc_82C94FB8:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94FC4;
	sub_82C8DAE8(ctx, base);
loc_82C94FC4:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,25
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 25, ctx.xer);
	// bgt cr6,0x82c951f0
	if (ctx.cr6.gt) goto loc_82C951F0;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,20468
	ctx.r12.s64 = ctx.r12.s64 + 20468;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9519C;
	case 1:
		goto loc_82C951B0;
	case 2:
		goto loc_82C951C4;
	case 3:
		goto loc_82C951F0;
	case 4:
		goto loc_82C951E8;
	case 5:
		goto loc_82C951E8;
	case 6:
		goto loc_82C951F0;
	case 7:
		goto loc_82C951F0;
	case 8:
		goto loc_82C951F0;
	case 9:
		goto loc_82C951F0;
	case 10:
		goto loc_82C951F0;
	case 11:
		goto loc_82C951F0;
	case 12:
		goto loc_82C951F0;
	case 13:
		goto loc_82C951F0;
	case 14:
		goto loc_82C951F0;
	case 15:
		goto loc_82C951F0;
	case 16:
		goto loc_82C951E8;
	case 17:
		goto loc_82C95094;
	case 18:
		goto loc_82C951F0;
	case 19:
		goto loc_82C95094;
	case 20:
		goto loc_82C951F0;
	case 21:
		goto loc_82C951F0;
	case 22:
		goto loc_82C951F0;
	case 23:
		goto loc_82C951F0;
	case 24:
		goto loc_82C9505C;
	case 25:
		goto loc_82C951E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,20892(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20892);
	// lwz r22,20912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20912);
	// lwz r22,20932(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20932);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
	// lwz r22,20968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
	// lwz r22,20628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20628);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20628);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20572(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20572);
	// lwz r22,20968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
loc_82C9505C:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r11.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c951f0
	if (ctx.cr6.eq) goto loc_82C951F0;
loc_82C95094:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c95194
	if (ctx.cr6.eq) goto loc_82C95194;
loc_82C950A0:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c950bc
	if (!ctx.cr6.eq) goto loc_82C950BC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c950c8
	goto loc_82C950C8;
loc_82C950BC:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C950C8;
	sub_82C8DAE8(ctx, base);
loc_82C950C8:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c951f0
	if (ctx.cr6.gt) goto loc_82C951F0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,20716
	ctx.r12.s64 = ctx.r12.s64 + 20716;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9519C;
	case 1:
		goto loc_82C951B0;
	case 2:
		goto loc_82C951C4;
	case 3:
		goto loc_82C951F0;
	case 4:
		goto loc_82C951F0;
	case 5:
		goto loc_82C951F0;
	case 6:
		goto loc_82C951F0;
	case 7:
		goto loc_82C951F0;
	case 8:
		goto loc_82C951F0;
	case 9:
		goto loc_82C951F0;
	case 10:
		goto loc_82C951F0;
	case 11:
		goto loc_82C951F0;
	case 12:
		goto loc_82C951F0;
	case 13:
		goto loc_82C951D8;
	case 14:
		goto loc_82C951F0;
	case 15:
		goto loc_82C951F0;
	case 16:
		goto loc_82C951F0;
	case 17:
		goto loc_82C95188;
	case 18:
		goto loc_82C951F0;
	case 19:
		goto loc_82C95188;
	case 20:
		goto loc_82C95188;
	case 21:
		goto loc_82C95188;
	case 22:
		goto loc_82C95188;
	case 23:
		goto loc_82C951F0;
	case 24:
		goto loc_82C95150;
	default:
		__builtin_unreachable();
	}
	// lwz r22,20892(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20892);
	// lwz r22,20912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20912);
	// lwz r22,20932(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20932);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20952);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20872(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20872(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20872(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20872(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20872(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20816);
loc_82C95150:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c951f0
	if (ctx.cr6.eq) goto loc_82C951F0;
loc_82C95188:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c950a0
	if (!ctx.cr6.eq) goto loc_82C950A0;
loc_82C95194:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C9519C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c951f0
	if (!ctx.cr6.lt) goto loc_82C951F0;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951B0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c951f0
	if (!ctx.cr6.lt) goto loc_82C951F0;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951C4:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c951f0
	if (!ctx.cr6.lt) goto loc_82C951F0;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951D8:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,28
	ctx.r3.s64 = 28;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951E8:
	// li r3,22
	ctx.r3.s64 = 22;
	// b 0x82c951f4
	goto loc_82C951F4;
loc_82C951F0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C951F4:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C951F8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C95210"))) PPC_WEAK_FUNC(sub_82C95210);
PPC_FUNC_IMPL(__imp__sub_82C95210) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9523c
	if (!ctx.cr6.eq) goto loc_82C9523C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C9523C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c95258
	if (!ctx.cr6.eq) goto loc_82C95258;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95264
	goto loc_82C95264;
loc_82C95258:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95264;
	sub_82C8DAE8(ctx, base);
loc_82C95264:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c95498
	if (ctx.cr6.gt) goto loc_82C95498;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,21140
	ctx.r12.s64 = ctx.r12.s64 + 21140;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95454;
	case 1:
		goto loc_82C95468;
	case 2:
		goto loc_82C95484;
	case 3:
		goto loc_82C95498;
	case 4:
		goto loc_82C95498;
	case 5:
		goto loc_82C95498;
	case 6:
		goto loc_82C95498;
	case 7:
		goto loc_82C95498;
	case 8:
		goto loc_82C95498;
	case 9:
		goto loc_82C95498;
	case 10:
		goto loc_82C95498;
	case 11:
		goto loc_82C95498;
	case 12:
		goto loc_82C95498;
	case 13:
		goto loc_82C95498;
	case 14:
		goto loc_82C95498;
	case 15:
		goto loc_82C95498;
	case 16:
		goto loc_82C95498;
	case 17:
		goto loc_82C95330;
	case 18:
		goto loc_82C95498;
	case 19:
		goto loc_82C95330;
	case 20:
		goto loc_82C95498;
	case 21:
		goto loc_82C95498;
	case 22:
		goto loc_82C95498;
	case 23:
		goto loc_82C95498;
	case 24:
		goto loc_82C952F8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,21588(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21588);
	// lwz r22,21608(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21608);
	// lwz r22,21636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21636);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21296(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21296);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21296(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21296);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21240(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21240);
loc_82C952F8:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r11.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c95498
	if (ctx.cr6.eq) goto loc_82C95498;
loc_82C95330:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9544c
	if (ctx.cr6.eq) goto loc_82C9544C;
loc_82C9533C:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c95358
	if (!ctx.cr6.eq) goto loc_82C95358;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95364
	goto loc_82C95364;
loc_82C95358:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95364;
	sub_82C8DAE8(ctx, base);
loc_82C95364:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 31, ctx.xer);
	// bgt cr6,0x82c95498
	if (ctx.cr6.gt) goto loc_82C95498;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,21384
	ctx.r12.s64 = ctx.r12.s64 + 21384;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95454;
	case 1:
		goto loc_82C95468;
	case 2:
		goto loc_82C95484;
	case 3:
		goto loc_82C95498;
	case 4:
		goto loc_82C9547C;
	case 5:
		goto loc_82C9547C;
	case 6:
		goto loc_82C9547C;
	case 7:
		goto loc_82C95498;
	case 8:
		goto loc_82C95498;
	case 9:
		goto loc_82C95498;
	case 10:
		goto loc_82C95498;
	case 11:
		goto loc_82C95498;
	case 12:
		goto loc_82C95498;
	case 13:
		goto loc_82C95498;
	case 14:
		goto loc_82C95498;
	case 15:
		goto loc_82C95498;
	case 16:
		goto loc_82C9547C;
	case 17:
		goto loc_82C95440;
	case 18:
		goto loc_82C95498;
	case 19:
		goto loc_82C95440;
	case 20:
		goto loc_82C95440;
	case 21:
		goto loc_82C95440;
	case 22:
		goto loc_82C95440;
	case 23:
		goto loc_82C95498;
	case 24:
		goto loc_82C95408;
	case 25:
		goto loc_82C9547C;
	case 26:
		goto loc_82C95498;
	case 27:
		goto loc_82C9547C;
	case 28:
		goto loc_82C95498;
	case 29:
		goto loc_82C95498;
	case 30:
		goto loc_82C95498;
	case 31:
		goto loc_82C9547C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,21588(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21588);
	// lwz r22,21608(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21608);
	// lwz r22,21636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21636);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21512(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21512);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
loc_82C95408:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c95498
	if (ctx.cr6.eq) goto loc_82C95498;
loc_82C95440:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9533c
	if (!ctx.cr6.eq) goto loc_82C9533C;
loc_82C9544C:
	// li r3,-20
	ctx.r3.s64 = -20;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C95454:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c95498
	if (!ctx.cr6.lt) goto loc_82C95498;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C95468:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c95498
	if (!ctx.cr6.lt) goto loc_82C95498;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C9547C:
	// li r3,20
	ctx.r3.s64 = 20;
	// b 0x82c9549c
	goto loc_82C9549C;
loc_82C95484:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c95498
	if (!ctx.cr6.lt) goto loc_82C95498;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C95498:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C9549C:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C954A0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C954B8"))) PPC_WEAK_FUNC(sub_82C954B8);
PPC_FUNC_IMPL(__imp__sub_82C954B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// beq cr6,0x82c9556c
	if (ctx.cr6.eq) goto loc_82C9556C;
	// subf r10,r5,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r5.s64;
loc_82C954D8:
	// lbz r3,0(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c954f4
	if (!ctx.cr6.eq) goto loc_82C954F4;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c954fc
	goto loc_82C954FC;
loc_82C954F4:
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C954FC;
	sub_82C8DAE8(ctx, base);
loc_82C954FC:
	// cmplwi cr6,r3,13
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 13, ctx.xer);
	// bgt cr6,0x82c9555c
	if (ctx.cr6.gt) goto loc_82C9555C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,21788
	ctx.r12.s64 = ctx.r12.s64 + 21788;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C955E8;
	case 1:
		goto loc_82C955E8;
	case 2:
		goto loc_82C9555C;
	case 3:
		goto loc_82C9555C;
	case 4:
		goto loc_82C9555C;
	case 5:
		goto loc_82C95554;
	case 6:
		goto loc_82C95580;
	case 7:
		goto loc_82C95594;
	case 8:
		goto loc_82C955E8;
	case 9:
		goto loc_82C9555C;
	case 10:
		goto loc_82C9555C;
	case 11:
		goto loc_82C9555C;
	case 12:
		goto loc_82C955A8;
	case 13:
		goto loc_82C955A8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,21992(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21992);
	// lwz r22,21992(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21992);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21844(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21844);
	// lwz r22,21888(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21888);
	// lwz r22,21908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21908);
	// lwz r22,21992(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21992);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21928(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21928);
	// lwz r22,21928(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21928);
loc_82C95554:
	// cmpwi cr6,r10,2
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 2, ctx.xer);
	// blt cr6,0x82c955d4
	if (ctx.cr6.lt) goto loc_82C955D4;
loc_82C9555C:
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
loc_82C95564:
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c954d8
	if (!ctx.cr6.eq) goto loc_82C954D8;
loc_82C9556C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C95580:
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// blt cr6,0x82c955d4
	if (ctx.cr6.lt) goto loc_82C955D4;
	// addi r5,r5,3
	ctx.r5.s64 = ctx.r5.s64 + 3;
	// addi r10,r10,-3
	ctx.r10.s64 = ctx.r10.s64 + -3;
	// b 0x82c95564
	goto loc_82C95564;
loc_82C95594:
	// cmpwi cr6,r10,4
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 4, ctx.xer);
	// blt cr6,0x82c955d4
	if (ctx.cr6.lt) goto loc_82C955D4;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// b 0x82c95564
	goto loc_82C95564;
loc_82C955A8:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// cmpw cr6,r3,r9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82c95564
	if (!ctx.cr6.eq) goto loc_82C95564;
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c95600
	if (!ctx.cr6.eq) goto loc_82C95600;
	// li r3,-27
	ctx.r3.s64 = -27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C955D4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C955E8:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
loc_82C955EC:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C95600:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
	// lbz r3,0(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c95620
	if (!ctx.cr6.eq) goto loc_82C95620;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95628
	goto loc_82C95628;
loc_82C95620:
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95628;
	sub_82C8DAE8(ctx, base);
loc_82C95628:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c955ec
	if (ctx.cr6.gt) goto loc_82C955EC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,22092
	ctx.r12.s64 = ctx.r12.s64 + 22092;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C956A4;
	case 1:
		goto loc_82C956A4;
	case 2:
		goto loc_82C956A4;
	case 3:
		goto loc_82C955EC;
	case 4:
		goto loc_82C955EC;
	case 5:
		goto loc_82C955EC;
	case 6:
		goto loc_82C955EC;
	case 7:
		goto loc_82C955EC;
	case 8:
		goto loc_82C955EC;
	case 9:
		goto loc_82C955EC;
	case 10:
		goto loc_82C955EC;
	case 11:
		goto loc_82C956A4;
	case 12:
		goto loc_82C956A4;
	case 13:
		goto loc_82C955EC;
	case 14:
		goto loc_82C955EC;
	case 15:
		goto loc_82C955EC;
	case 16:
		goto loc_82C955EC;
	case 17:
		goto loc_82C955EC;
	case 18:
		goto loc_82C955EC;
	case 19:
		goto loc_82C955EC;
	case 20:
		goto loc_82C955EC;
	case 21:
		goto loc_82C956A4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
loc_82C956A4:
	// li r3,27
	ctx.r3.s64 = 27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C956B8"))) PPC_WEAK_FUNC(sub_82C956B8);
PPC_FUNC_IMPL(__imp__sub_82C956B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C956C0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c956e0
	if (!ctx.cr6.eq) goto loc_82C956E0;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C956E0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c9570c
	if (ctx.cr6.eq) goto loc_82C9570C;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c95708
	if (!ctx.cr6.eq) goto loc_82C95708;
loc_82C956FC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95708:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C9570C:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c95728
	if (!ctx.cr6.eq) goto loc_82C95728;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95734
	goto loc_82C95734;
loc_82C95728:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95734;
	sub_82C8DAE8(ctx, base);
loc_82C95734:
	// addi r9,r3,-2
	ctx.r9.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r9,34
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 34, ctx.xer);
	// bgt cr6,0x82c95ef8
	if (ctx.cr6.gt) goto loc_82C95EF8;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r30,1
	ctx.r30.s64 = 1;
	// addi r31,r11,-4144
	ctx.r31.s64 = ctx.r11.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,22372
	ctx.r12.s64 = ctx.r12.s64 + 22372;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82C95830;
	case 1:
		goto loc_82C95EF8;
	case 2:
		goto loc_82C959F0;
	case 3:
		goto loc_82C95BD4;
	case 4:
		goto loc_82C95BEC;
	case 5:
		goto loc_82C95C04;
	case 6:
		goto loc_82C95EF8;
	case 7:
		goto loc_82C95924;
	case 8:
		goto loc_82C95940;
	case 9:
		goto loc_82C95BAC;
	case 10:
		goto loc_82C957F0;
	case 11:
		goto loc_82C95810;
	case 12:
		goto loc_82C95EF8;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95EF8;
	case 16:
		goto loc_82C95EF8;
	case 17:
		goto loc_82C95BC0;
	case 18:
		goto loc_82C959DC;
	case 19:
		goto loc_82C95940;
	case 20:
		goto loc_82C95C54;
	case 21:
		goto loc_82C95C90;
	case 22:
		goto loc_82C95C54;
	case 23:
		goto loc_82C95C90;
	case 24:
		goto loc_82C95C90;
	case 25:
		goto loc_82C95C90;
	case 26:
		goto loc_82C95EF8;
	case 27:
		goto loc_82C95C1C;
	case 28:
		goto loc_82C959B4;
	case 29:
		goto loc_82C95A68;
	case 30:
		goto loc_82C95A7C;
	case 31:
		goto loc_82C95EF8;
	case 32:
		goto loc_82C95EF8;
	case 33:
		goto loc_82C959C8;
	case 34:
		goto loc_82C95B98;
	default:
		__builtin_unreachable();
	}
	// lwz r22,22576(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22576);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23024(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23024);
	// lwz r22,23508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23508);
	// lwz r22,23532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23532);
	// lwz r22,23556(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23556);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22820(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22820);
	// lwz r22,22848(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22848);
	// lwz r22,23468(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23468);
	// lwz r22,22512(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22512);
	// lwz r22,22544(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22544);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23488(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23488);
	// lwz r22,23004(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23004);
	// lwz r22,22848(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22848);
	// lwz r22,23636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23636);
	// lwz r22,23696(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,23636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23636);
	// lwz r22,23696(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,23696(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,23696(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23580(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23580);
	// lwz r22,22964(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22964);
	// lwz r22,23144(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23144);
	// lwz r22,23164(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23164);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22984(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22984);
	// lwz r22,23448(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23448);
loc_82C957F0:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x82c954b8
	ctx.lr = 0x82C95808;
	sub_82C954B8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95810:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,13
	ctx.r3.s64 = 13;
	// bl 0x82c954b8
	ctx.lr = 0x82C95828;
	sub_82C954B8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95830:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c956fc
	if (ctx.cr6.eq) goto loc_82C956FC;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c95858
	if (!ctx.cr6.eq) goto loc_82C95858;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95860
	goto loc_82C95860;
loc_82C95858:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95860;
	sub_82C8DAE8(ctx, base);
loc_82C95860:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c95ef8
	if (ctx.cr6.gt) goto loc_82C95EF8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,22660
	ctx.r12.s64 = ctx.r12.s64 + 22660;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95910;
	case 1:
		goto loc_82C95910;
	case 2:
		goto loc_82C95910;
	case 3:
		goto loc_82C95EF8;
	case 4:
		goto loc_82C95EF8;
	case 5:
		goto loc_82C95EF8;
	case 6:
		goto loc_82C95EF8;
	case 7:
		goto loc_82C95EF8;
	case 8:
		goto loc_82C95EF8;
	case 9:
		goto loc_82C95EF8;
	case 10:
		goto loc_82C958FC;
	case 11:
		goto loc_82C958E8;
	case 12:
		goto loc_82C95EF8;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95EF8;
	case 16:
		goto loc_82C95EF8;
	case 17:
		goto loc_82C95910;
	case 18:
		goto loc_82C95EF8;
	case 19:
		goto loc_82C95910;
	case 20:
		goto loc_82C95EF8;
	case 21:
		goto loc_82C95EF8;
	case 22:
		goto loc_82C95EF8;
	case 23:
		goto loc_82C95EF8;
	case 24:
		goto loc_82C95910;
	default:
		__builtin_unreachable();
	}
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22780(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22780);
	// lwz r22,22760(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22760);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
loc_82C958E8:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c92db0
	ctx.lr = 0x82C958F4;
	sub_82C92DB0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C958FC:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c930e8
	ctx.lr = 0x82C95908;
	sub_82C930E8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95910:
	// addi r11,r10,-2
	ctx.r11.s64 = ctx.r10.s64 + -2;
	// li r3,29
	ctx.r3.s64 = 29;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95924:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95940
	if (!ctx.cr6.eq) goto loc_82C95940;
	// stw r5,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r5.u32);
	// li r3,-15
	ctx.r3.s64 = -15;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95940:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c959a4
	if (ctx.cr6.eq) goto loc_82C959A4;
loc_82C9594C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c95968
	if (!ctx.cr6.eq) goto loc_82C95968;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95970
	goto loc_82C95970;
loc_82C95968:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95970;
	sub_82C8DAE8(ctx, base);
loc_82C95970:
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// beq cr6,0x82c9598c
	if (ctx.cr6.eq) goto loc_82C9598C;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// beq cr6,0x82c95998
	if (ctx.cr6.eq) goto loc_82C95998;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// bne cr6,0x82c959a4
	if (!ctx.cr6.eq) goto loc_82C959A4;
	// b 0x82c95998
	goto loc_82C95998;
loc_82C9598C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c959a4
	if (ctx.cr6.eq) goto loc_82C959A4;
loc_82C95998:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9594c
	if (!ctx.cr6.eq) goto loc_82C9594C;
loc_82C959A4:
	// li r3,15
	ctx.r3.s64 = 15;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C959B4:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c94f70
	ctx.lr = 0x82C959C0;
	sub_82C94F70(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C959C8:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,38
	ctx.r3.s64 = 38;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C959DC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,25
	ctx.r3.s64 = 25;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C959F0:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95a08
	if (!ctx.cr6.eq) goto loc_82C95A08;
	// li r3,-26
	ctx.r3.s64 = -26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95A08:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c95a58
	if (!ctx.cr6.eq) goto loc_82C95A58;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,93
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 93, ctx.xer);
	// bne cr6,0x82c95a58
	if (!ctx.cr6.eq) goto loc_82C95A58;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c956fc
	if (ctx.cr6.eq) goto loc_82C956FC;
	// lbz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c95a58
	if (!ctx.cr6.eq) goto loc_82C95A58;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c95a58
	if (!ctx.cr6.eq) goto loc_82C95A58;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// li r3,34
	ctx.r3.s64 = 34;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95A58:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,26
	ctx.r3.s64 = 26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95A68:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,23
	ctx.r3.s64 = 23;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95A7C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95a94
	if (!ctx.cr6.eq) goto loc_82C95A94;
	// li r3,-24
	ctx.r3.s64 = -24;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95A94:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c95ab0
	if (!ctx.cr6.eq) goto loc_82C95AB0;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95ab8
	goto loc_82C95AB8;
loc_82C95AB0:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95AB8;
	sub_82C8DAE8(ctx, base);
loc_82C95AB8:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 27, ctx.xer);
	// bgt cr6,0x82c95ef8
	if (ctx.cr6.gt) goto loc_82C95EF8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,23260
	ctx.r12.s64 = ctx.r12.s64 + 23260;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95B88;
	case 1:
		goto loc_82C95B88;
	case 2:
		goto loc_82C95B88;
	case 3:
		goto loc_82C95EF8;
	case 4:
		goto loc_82C95EF8;
	case 5:
		goto loc_82C95EF8;
	case 6:
		goto loc_82C95B60;
	case 7:
		goto loc_82C95EF8;
	case 8:
		goto loc_82C95EF8;
	case 9:
		goto loc_82C95EF8;
	case 10:
		goto loc_82C95EF8;
	case 11:
		goto loc_82C95EF8;
	case 12:
		goto loc_82C95B88;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95EF8;
	case 16:
		goto loc_82C95EF8;
	case 17:
		goto loc_82C95EF8;
	case 18:
		goto loc_82C95EF8;
	case 19:
		goto loc_82C95EF8;
	case 20:
		goto loc_82C95EF8;
	case 21:
		goto loc_82C95EF8;
	case 22:
		goto loc_82C95EF8;
	case 23:
		goto loc_82C95B88;
	case 24:
		goto loc_82C95B4C;
	case 25:
		goto loc_82C95B74;
	case 26:
		goto loc_82C95B88;
	case 27:
		goto loc_82C95B88;
	default:
		__builtin_unreachable();
	}
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23392(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23392);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23372(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23372);
	// lwz r22,23412(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23412);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
loc_82C95B4C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,36
	ctx.r3.s64 = 36;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95B60:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,35
	ctx.r3.s64 = 35;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95B74:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,37
	ctx.r3.s64 = 37;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95B88:
	// li r3,24
	ctx.r3.s64 = 24;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95B98:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,21
	ctx.r3.s64 = 21;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95BAC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,17
	ctx.r3.s64 = 17;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95BC0:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c95210
	ctx.lr = 0x82C95BCC;
	sub_82C95210(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95BD4:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c95ef8
	if (!ctx.cr6.lt) goto loc_82C95EF8;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95BEC:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c95ef8
	if (!ctx.cr6.lt) goto loc_82C95EF8;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95C04:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c95ef8
	if (!ctx.cr6.lt) goto loc_82C95EF8;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95C1C:
	// clrlwi r11,r8,24
	ctx.r11.u64 = ctx.r8.u32 & 0xFF;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r7,r31,1280
	ctx.r7.s64 = ctx.r31.s64 + 1280;
	// clrlwi r4,r9,27
	ctx.r4.u64 = ctx.r9.u32 & 0x1F;
	// rlwinm r8,r9,27,5,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x7FFFFFF;
	// slw r3,r30,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r30.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r9,r11,r7
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r9,r9,3
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 3);
	// add r8,r9,r8
	ctx.r8.u64 = ctx.r9.u64 + ctx.r8.u64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r31
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r31.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c95c5c
	if (ctx.cr6.eq) goto loc_82C95C5C;
loc_82C95C54:
	// li r8,18
	ctx.r8.s64 = 18;
	// b 0x82c95c94
	goto loc_82C95C94;
loc_82C95C5C:
	// addi r8,r31,1536
	ctx.r8.s64 = ctx.r31.s64 + 1536;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r4,r7,27
	ctx.r4.u64 = ctx.r7.u32 & 0x1F;
	// lbzx r3,r11,r8
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// slw r8,r30,r4
	ctx.r8.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r30.u32 << (ctx.r4.u8 & 0x3F));
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r7,r11,r9
	ctx.r7.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r4,r7,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r4,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r31.u32);
	// and r11,r3,r8
	ctx.r11.u64 = ctx.r3.u64 & ctx.r8.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c95ef8
	if (ctx.cr6.eq) goto loc_82C95EF8;
loc_82C95C90:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C95C94:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c95d8c
	if (ctx.cr6.eq) goto loc_82C95D8C;
loc_82C95CA0:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c95cbc
	if (!ctx.cr6.eq) goto loc_82C95CBC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95cc8
	goto loc_82C95CC8;
loc_82C95CBC:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95CC8;
	sub_82C8DAE8(ctx, base);
loc_82C95CC8:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 31, ctx.xer);
	// bgt cr6,0x82c95ef8
	if (ctx.cr6.gt) goto loc_82C95EF8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,23788
	ctx.r12.s64 = ctx.r12.s64 + 23788;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95BD4;
	case 1:
		goto loc_82C95BEC;
	case 2:
		goto loc_82C95C04;
	case 3:
		goto loc_82C95EF8;
	case 4:
		goto loc_82C95E94;
	case 5:
		goto loc_82C95E94;
	case 6:
		goto loc_82C95E94;
	case 7:
		goto loc_82C95EF8;
	case 8:
		goto loc_82C95EF8;
	case 9:
		goto loc_82C95EF8;
	case 10:
		goto loc_82C95EDC;
	case 11:
		goto loc_82C95EF8;
	case 12:
		goto loc_82C95EF8;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95E94;
	case 16:
		goto loc_82C95E94;
	case 17:
		goto loc_82C95E8C;
	case 18:
		goto loc_82C95D6C;
	case 19:
		goto loc_82C95E8C;
	case 20:
		goto loc_82C95E8C;
	case 21:
		goto loc_82C95E8C;
	case 22:
		goto loc_82C95E8C;
	case 23:
		goto loc_82C95EF8;
	case 24:
		goto loc_82C95E54;
	case 25:
		goto loc_82C95E94;
	case 26:
		goto loc_82C95EF8;
	case 27:
		goto loc_82C95E94;
	case 28:
		goto loc_82C95EC0;
	case 29:
		goto loc_82C95EA4;
	case 30:
		goto loc_82C95E94;
	case 31:
		goto loc_82C95E94;
	default:
		__builtin_unreachable();
	}
	// lwz r22,23508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23508);
	// lwz r22,23532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23532);
	// lwz r22,23556(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23556);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24284);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,23916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23916);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24148);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24256);
	// lwz r22,24228(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24228);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
loc_82C95D6C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmpwi cr6,r8,18
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 18, ctx.xer);
	// beq cr6,0x82c95d98
	if (ctx.cr6.eq) goto loc_82C95D98;
	// cmpwi cr6,r8,41
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 41, ctx.xer);
	// bne cr6,0x82c95d84
	if (!ctx.cr6.eq) goto loc_82C95D84;
loc_82C95D80:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C95D84:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95ca0
	if (!ctx.cr6.eq) goto loc_82C95CA0;
loc_82C95D8C:
	// neg r3,r8
	ctx.r3.s64 = -ctx.r8.s64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95D98:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c956fc
	if (ctx.cr6.eq) goto loc_82C956FC;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// li r8,41
	ctx.r8.s64 = 41;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c95dc0
	if (!ctx.cr6.eq) goto loc_82C95DC0;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95dcc
	goto loc_82C95DCC;
loc_82C95DC0:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95DCC;
	sub_82C8DAE8(ctx, base);
loc_82C95DCC:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c95d80
	if (ctx.cr6.gt) goto loc_82C95D80;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,24048
	ctx.r12.s64 = ctx.r12.s64 + 24048;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95BD4;
	case 1:
		goto loc_82C95BEC;
	case 2:
		goto loc_82C95C04;
	case 3:
		goto loc_82C95D80;
	case 4:
		goto loc_82C95D80;
	case 5:
		goto loc_82C95D80;
	case 6:
		goto loc_82C95D80;
	case 7:
		goto loc_82C95D80;
	case 8:
		goto loc_82C95D80;
	case 9:
		goto loc_82C95D80;
	case 10:
		goto loc_82C95D80;
	case 11:
		goto loc_82C95D80;
	case 12:
		goto loc_82C95D80;
	case 13:
		goto loc_82C95D80;
	case 14:
		goto loc_82C95D80;
	case 15:
		goto loc_82C95D80;
	case 16:
		goto loc_82C95D80;
	case 17:
		goto loc_82C95E8C;
	case 18:
		goto loc_82C95D80;
	case 19:
		goto loc_82C95E8C;
	case 20:
		goto loc_82C95E8C;
	case 21:
		goto loc_82C95E8C;
	case 22:
		goto loc_82C95E8C;
	case 23:
		goto loc_82C95D80;
	case 24:
		goto loc_82C95E54;
	default:
		__builtin_unreachable();
	}
	// lwz r22,23508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23508);
	// lwz r22,23532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23532);
	// lwz r22,23556(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23556);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,24148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24148);
loc_82C95E54:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r31,1536
	ctx.r4.s64 = ctx.r31.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r30,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r30.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r31
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c95ef8
	if (ctx.cr6.eq) goto loc_82C95EF8;
loc_82C95E8C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c95d84
	goto loc_82C95D84;
loc_82C95E94:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95EA4:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c95ef8
	if (ctx.cr6.eq) goto loc_82C95EF8;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,32
	ctx.r3.s64 = 32;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95EC0:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c95ef8
	if (ctx.cr6.eq) goto loc_82C95EF8;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,31
	ctx.r3.s64 = 31;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95EDC:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c95ef8
	if (ctx.cr6.eq) goto loc_82C95EF8;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,30
	ctx.r3.s64 = 30;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
loc_82C95EF8:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C95F08"))) PPC_WEAK_FUNC(sub_82C95F08);
PPC_FUNC_IMPL(__imp__sub_82C95F08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95f38
	if (!ctx.cr6.eq) goto loc_82C95F38;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C95F38:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C95F3C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c95f58
	if (!ctx.cr6.eq) goto loc_82C95F58;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95f60
	goto loc_82C95F60;
loc_82C95F58:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95F60;
	sub_82C8DAE8(ctx, base);
loc_82C95F60:
	// addi r11,r3,-2
	ctx.r11.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r11,19
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 19, ctx.xer);
	// bgt cr6,0x82c95fe4
	if (ctx.cr6.gt) goto loc_82C95FE4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,24452
	ctx.r12.s64 = ctx.r12.s64 + 24452;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9602C;
	case 1:
		goto loc_82C96008;
	case 2:
		goto loc_82C95FE4;
	case 3:
		goto loc_82C95FE4;
	case 4:
		goto loc_82C95FD4;
	case 5:
		goto loc_82C95FDC;
	case 6:
		goto loc_82C95FE4;
	case 7:
		goto loc_82C96068;
	case 8:
		goto loc_82C96044;
	case 9:
		goto loc_82C95FE4;
	case 10:
		goto loc_82C95FE4;
	case 11:
		goto loc_82C95FE4;
	case 12:
		goto loc_82C95FE4;
	case 13:
		goto loc_82C95FE4;
	case 14:
		goto loc_82C95FE4;
	case 15:
		goto loc_82C95FE4;
	case 16:
		goto loc_82C95FE4;
	case 17:
		goto loc_82C95FE4;
	case 18:
		goto loc_82C95FE4;
	case 19:
		goto loc_82C960D8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,24620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24620);
	// lwz r22,24584(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24584);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24532);
	// lwz r22,24540(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24540);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24680(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24680);
	// lwz r22,24644(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24644);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24792(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24792);
loc_82C95FD4:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c95fe8
	goto loc_82C95FE8;
loc_82C95FDC:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c95fe8
	goto loc_82C95FE8;
loc_82C95FE4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C95FE8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95f3c
	if (!ctx.cr6.eq) goto loc_82C95F3C;
loc_82C95FF0:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96008:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c95ff0
	if (!ctx.cr6.eq) goto loc_82C95FF0;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c93d60
	ctx.lr = 0x82C9601C;
	sub_82C93D60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C9602C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96044:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c95ff0
	if (!ctx.cr6.eq) goto loc_82C95FF0;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96068:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c95ff0
	if (!ctx.cr6.eq) goto loc_82C95FF0;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c96090
	if (!ctx.cr6.eq) goto loc_82C96090;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96090:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c960ac
	if (!ctx.cr6.eq) goto loc_82C960AC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c960b4
	goto loc_82C960B4;
loc_82C960AC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C960B4;
	sub_82C8DAE8(ctx, base);
loc_82C960B4:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c960c0
	if (!ctx.cr6.eq) goto loc_82C960C0;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C960C0:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C960D8:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c95ff0
	if (!ctx.cr6.eq) goto loc_82C95FF0;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,39
	ctx.r3.s64 = 39;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96100"))) PPC_WEAK_FUNC(sub_82C96100);
PPC_FUNC_IMPL(__imp__sub_82C96100) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c96130
	if (!ctx.cr6.eq) goto loc_82C96130;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96130:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C96134:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96150
	if (!ctx.cr6.eq) goto loc_82C96150;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96158
	goto loc_82C96158;
loc_82C96150:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96158;
	sub_82C8DAE8(ctx, base);
loc_82C96158:
	// addi r11,r3,-3
	ctx.r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 27, ctx.xer);
	// bgt cr6,0x82c961fc
	if (ctx.cr6.gt) goto loc_82C961FC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,24956
	ctx.r12.s64 = ctx.r12.s64 + 24956;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96220;
	case 1:
		goto loc_82C961FC;
	case 2:
		goto loc_82C961FC;
	case 3:
		goto loc_82C961EC;
	case 4:
		goto loc_82C961F4;
	case 5:
		goto loc_82C961FC;
	case 6:
		goto loc_82C96298;
	case 7:
		goto loc_82C96274;
	case 8:
		goto loc_82C961FC;
	case 9:
		goto loc_82C961FC;
	case 10:
		goto loc_82C961FC;
	case 11:
		goto loc_82C961FC;
	case 12:
		goto loc_82C961FC;
	case 13:
		goto loc_82C961FC;
	case 14:
		goto loc_82C961FC;
	case 15:
		goto loc_82C961FC;
	case 16:
		goto loc_82C961FC;
	case 17:
		goto loc_82C961FC;
	case 18:
		goto loc_82C961FC;
	case 19:
		goto loc_82C961FC;
	case 20:
		goto loc_82C961FC;
	case 21:
		goto loc_82C961FC;
	case 22:
		goto loc_82C961FC;
	case 23:
		goto loc_82C961FC;
	case 24:
		goto loc_82C961FC;
	case 25:
		goto loc_82C961FC;
	case 26:
		goto loc_82C961FC;
	case 27:
		goto loc_82C96244;
	default:
		__builtin_unreachable();
	}
	// lwz r22,25120(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25120);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25068(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25068);
	// lwz r22,25076(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25076);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25240(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25240);
	// lwz r22,25204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25204);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25156(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25156);
loc_82C961EC:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c96200
	goto loc_82C96200;
loc_82C961F4:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c96200
	goto loc_82C96200;
loc_82C961FC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C96200:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c96134
	if (!ctx.cr6.eq) goto loc_82C96134;
loc_82C96208:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C96210:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96220:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c96208
	if (!ctx.cr6.eq) goto loc_82C96208;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c93d60
	ctx.lr = 0x82C96234;
	sub_82C93D60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96244:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c96208
	if (!ctx.cr6.eq) goto loc_82C96208;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c94f70
	ctx.lr = 0x82C96258;
	sub_82C94F70(ctx, base);
	// cmpwi cr6,r3,22
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 22, ctx.xer);
	// bne cr6,0x82c96210
	if (!ctx.cr6.eq) goto loc_82C96210;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96274:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c96208
	if (!ctx.cr6.eq) goto loc_82C96208;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96298:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c96208
	if (!ctx.cr6.eq) goto loc_82C96208;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c962c0
	if (!ctx.cr6.eq) goto loc_82C962C0;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C962C0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c962dc
	if (!ctx.cr6.eq) goto loc_82C962DC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c962e4
	goto loc_82C962E4;
loc_82C962DC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C962E4;
	sub_82C8DAE8(ctx, base);
loc_82C962E4:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c962f0
	if (!ctx.cr6.eq) goto loc_82C962F0;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C962F0:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96308"))) PPC_WEAK_FUNC(sub_82C96308);
PPC_FUNC_IMPL(__imp__sub_82C96308) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// li r8,0
	ctx.r8.s64 = 0;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c96338
	if (ctx.cr6.eq) goto loc_82C96338;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C96338:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c963c4
	if (ctx.cr6.eq) goto loc_82C963C4;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C96344:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96360
	if (!ctx.cr6.eq) goto loc_82C96360;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96368
	goto loc_82C96368;
loc_82C96360:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96368;
	sub_82C8DAE8(ctx, base);
loc_82C96368:
	// cmplwi cr6,r3,8
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 8, ctx.xer);
	// bgt cr6,0x82c963b4
	if (ctx.cr6.gt) goto loc_82C963B4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,25480
	ctx.r12.s64 = ctx.r12.s64 + 25480;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C964D4;
	case 1:
		goto loc_82C964D4;
	case 2:
		goto loc_82C96400;
	case 3:
		goto loc_82C963B4;
	case 4:
		goto loc_82C96458;
	case 5:
		goto loc_82C963AC;
	case 6:
		goto loc_82C963D8;
	case 7:
		goto loc_82C963EC;
	case 8:
		goto loc_82C964D4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,25812(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25812);
	// lwz r22,25812(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25812);
	// lwz r22,25600(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25600);
	// lwz r22,25524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25524);
	// lwz r22,25688(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25688);
	// lwz r22,25516(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25516);
	// lwz r22,25560(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25560);
	// lwz r22,25580(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25580);
	// lwz r22,25812(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25812);
loc_82C963AC:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c964c0
	if (ctx.cr6.lt) goto loc_82C964C0;
loc_82C963B4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
loc_82C963BC:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c96344
	if (!ctx.cr6.eq) goto loc_82C96344;
loc_82C963C4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C963D8:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c964c0
	if (ctx.cr6.lt) goto loc_82C964C0;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c963bc
	goto loc_82C963BC;
loc_82C963EC:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c964c0
	if (ctx.cr6.lt) goto loc_82C964C0;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c963bc
	goto loc_82C963BC;
loc_82C96400:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c963c4
	if (ctx.cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,33
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 33, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c963c4
	if (ctx.cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,91
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 91, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// b 0x82c963b4
	goto loc_82C963B4;
loc_82C96458:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c963c4
	if (ctx.cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c963c4
	if (ctx.cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82c964ec
	if (ctx.cr6.eq) goto loc_82C964EC;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// b 0x82c963bc
	goto loc_82C963BC;
loc_82C964C0:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C964D4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C964EC:
	// li r3,42
	ctx.r3.s64 = 42;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96508"))) PPC_WEAK_FUNC(sub_82C96508);
PPC_FUNC_IMPL(__imp__sub_82C96508) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// addi r7,r5,-2
	ctx.r7.s64 = ctx.r5.s64 + -2;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82c9664c
	if (ctx.cr6.eq) goto loc_82C9664C;
loc_82C96528:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// extsb r9,r3
	ctx.r9.s64 = ctx.r3.s8;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c96548
	if (!ctx.cr6.eq) goto loc_82C96548;
	// add r11,r4,r8
	ctx.r11.u64 = ctx.r4.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9654c
	goto loc_82C9654C;
loc_82C96548:
	// bl 0x82c8dae8
	ctx.lr = 0x82C9654C;
	sub_82C8DAE8(ctx, base);
loc_82C9654C:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 26, ctx.xer);
	// bgt cr6,0x82c96624
	if (ctx.cr6.gt) goto loc_82C96624;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,25968
	ctx.r12.s64 = ctx.r12.s64 + 25968;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96640;
	case 1:
		goto loc_82C96640;
	case 2:
		goto loc_82C96624;
	case 3:
		goto loc_82C96624;
	case 4:
		goto loc_82C96640;
	case 5:
		goto loc_82C96640;
	case 6:
		goto loc_82C96640;
	case 7:
		goto loc_82C96640;
	case 8:
		goto loc_82C96640;
	case 9:
		goto loc_82C96640;
	case 10:
		goto loc_82C96640;
	case 11:
		goto loc_82C96624;
	case 12:
		goto loc_82C965DC;
	case 13:
		goto loc_82C96608;
	case 14:
		goto loc_82C96640;
	case 15:
		goto loc_82C96640;
	case 16:
		goto loc_82C96640;
	case 17:
		goto loc_82C96608;
	case 18:
		goto loc_82C96640;
	case 19:
		goto loc_82C96624;
	case 20:
		goto loc_82C96624;
	case 21:
		goto loc_82C96640;
	case 22:
		goto loc_82C96640;
	case 23:
		goto loc_82C96640;
	case 24:
		goto loc_82C96640;
	case 25:
		goto loc_82C96640;
	case 26:
		goto loc_82C96640;
	default:
		__builtin_unreachable();
	}
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26076(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26076);
	// lwz r22,26120(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26120);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26120(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26120);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
loc_82C965DC:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c96640
	if (!ctx.cr6.eq) goto loc_82C96640;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82c96640
	if (!ctx.cr6.eq) goto loc_82C96640;
loc_82C965F0:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96608:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// beq cr6,0x82c96618
	if (ctx.cr6.eq) goto loc_82C96618;
	// li r11,-1
	ctx.r11.s64 = -1;
loc_82C96618:
	// rlwinm r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c96640
	if (ctx.cr6.eq) goto loc_82C96640;
loc_82C96624:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c965f0
	if (!ctx.cr6.eq) goto loc_82C965F0;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,36
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 36, ctx.xer);
	// beq cr6,0x82c96640
	if (ctx.cr6.eq) goto loc_82C96640;
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// bne cr6,0x82c965f0
	if (!ctx.cr6.eq) goto loc_82C965F0;
loc_82C96640:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// bne cr6,0x82c96528
	if (!ctx.cr6.eq) goto loc_82C96528;
loc_82C9664C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96660"))) PPC_WEAK_FUNC(sub_82C96660);
PPC_FUNC_IMPL(__imp__sub_82C96660) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C96668;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r27,0
	ctx.r27.s64 = 0;
	// addi r8,r4,2
	ctx.r8.s64 = ctx.r4.s64 + 2;
	// li r29,1
	ctx.r29.s64 = 1;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// mr r30,r27
	ctx.r30.u64 = ctx.r27.u64;
	// addi r31,r8,2
	ctx.r31.s64 = ctx.r8.s64 + 2;
loc_82C9668C:
	// lbz r3,0(r8)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// lbz r4,1(r8)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// extsb r10,r3
	ctx.r10.s64 = ctx.r3.s8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c966ac
	if (!ctx.cr6.eq) goto loc_82C966AC;
	// add r11,r4,r28
	ctx.r11.u64 = ctx.r4.u64 + ctx.r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c966b0
	goto loc_82C966B0;
loc_82C966AC:
	// bl 0x82c8dae8
	ctx.lr = 0x82C966B0;
	sub_82C8DAE8(ctx, base);
loc_82C966B0:
	// addi r11,r3,-3
	ctx.r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 26, ctx.xer);
	// bgt cr6,0x82c96958
	if (ctx.cr6.gt) goto loc_82C96958;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,26324
	ctx.r12.s64 = ctx.r12.s64 + 26324;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96938;
	case 1:
		goto loc_82C96958;
	case 2:
		goto loc_82C96740;
	case 3:
		goto loc_82C96768;
	case 4:
		goto loc_82C96798;
	case 5:
		goto loc_82C96958;
	case 6:
		goto loc_82C96918;
	case 7:
		goto loc_82C96918;
	case 8:
		goto loc_82C96950;
	case 9:
		goto loc_82C967C8;
	case 10:
		goto loc_82C9681C;
	case 11:
		goto loc_82C96958;
	case 12:
		goto loc_82C96958;
	case 13:
		goto loc_82C96958;
	case 14:
		goto loc_82C96950;
	case 15:
		goto loc_82C96958;
	case 16:
		goto loc_82C96958;
	case 17:
		goto loc_82C96958;
	case 18:
		goto loc_82C96870;
	case 19:
		goto loc_82C96740;
	case 20:
		goto loc_82C96958;
	case 21:
		goto loc_82C96740;
	case 22:
		goto loc_82C96958;
	case 23:
		goto loc_82C96958;
	case 24:
		goto loc_82C96958;
	case 25:
		goto loc_82C96958;
	case 26:
		goto loc_82C96740;
	default:
		__builtin_unreachable();
	}
	// lwz r22,26936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26936);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
	// lwz r22,26472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26472);
	// lwz r22,26520(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26520);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26904(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26904);
	// lwz r22,26904(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26904);
	// lwz r22,26960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26960);
	// lwz r22,26568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26568);
	// lwz r22,26652(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26652);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26960);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26736(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26736);
	// lwz r22,26432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
loc_82C96740:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96758
	if (!ctx.cr6.lt) goto loc_82C96758;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C96758:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96768:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c96784
	if (!ctx.cr6.eq) goto loc_82C96784;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96780
	if (!ctx.cr6.lt) goto loc_82C96780;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C96780:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
loc_82C96784:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96798:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c967b4
	if (!ctx.cr6.eq) goto loc_82C967B4;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c967b0
	if (!ctx.cr6.lt) goto loc_82C967B0;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C967B0:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
loc_82C967B4:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C967C8:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// beq cr6,0x82c967f0
	if (ctx.cr6.eq) goto loc_82C967F0;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c967dc
	if (!ctx.cr6.lt) goto loc_82C967DC;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r31.u32);
loc_82C967DC:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,12
	ctx.r30.s64 = 12;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C967F0:
	// cmpwi cr6,r30,12
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 12, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96808
	if (!ctx.cr6.lt) goto loc_82C96808;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
loc_82C96808:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C9681C:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// beq cr6,0x82c96844
	if (ctx.cr6.eq) goto loc_82C96844;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96830
	if (!ctx.cr6.lt) goto loc_82C96830;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r31.u32);
loc_82C96830:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,13
	ctx.r30.s64 = 13;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96844:
	// cmpwi cr6,r30,13
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 13, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96808
	if (!ctx.cr6.lt) goto loc_82C96808;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96870:
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82c96888
	if (!ctx.cr6.eq) goto loc_82C96888;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96888:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96958
	if (!ctx.cr6.lt) goto loc_82C96958;
	// lbz r11,12(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c96958
	if (ctx.cr6.eq) goto loc_82C96958;
	// lwz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82c96908
	if (ctx.cr6.eq) goto loc_82C96908;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c96908
	if (!ctx.cr6.eq) goto loc_82C96908;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,32
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 32, ctx.xer);
	// bne cr6,0x82c96908
	if (!ctx.cr6.eq) goto loc_82C96908;
	// lbz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r11,r3
	ctx.r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c968f8
	if (!ctx.cr6.eq) goto loc_82C968F8;
	// lbz r10,3(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 3);
	// cmplwi cr6,r10,32
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 32, ctx.xer);
	// beq cr6,0x82c96908
	if (ctx.cr6.eq) goto loc_82C96908;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c968f8
	if (!ctx.cr6.eq) goto loc_82C968F8;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96900
	goto loc_82C96900;
loc_82C968F8:
	// lbz r4,3(r8)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + 3);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96900;
	sub_82C8DAE8(ctx, base);
loc_82C96900:
	// cmpw cr6,r3,r30
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r30.s32, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
loc_82C96908:
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96918:
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82c96930
	if (!ctx.cr6.eq) goto loc_82C96930;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96930:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
loc_82C96938:
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96958
	if (!ctx.cr6.lt) goto loc_82C96958;
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96950:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c96964
	if (!ctx.cr6.eq) goto loc_82C96964;
loc_82C96958:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96964:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C96970"))) PPC_WEAK_FUNC(sub_82C96970);
PPC_FUNC_IMPL(__imp__sub_82C96970) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// subf r11,r4,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// srawi r10,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 1;
	// addze r11,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r11.s64 = temp.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82c96abc
	if (ctx.cr6.eq) goto loc_82C96ABC;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c96a68
	if (ctx.cr6.eq) goto loc_82C96A68;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,97
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 97, ctx.xer);
	// beq cr6,0x82c96a10
	if (ctx.cr6.eq) goto loc_82C96A10;
	// cmpwi cr6,r11,113
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 113, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,117
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 117, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,111
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 111, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r11,116
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 116, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// li r3,34
	ctx.r3.s64 = 34;
	// blr 
	return;
loc_82C96A10:
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,112
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 112, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,111
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 111, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r11,115
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 115, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// li r3,39
	ctx.r3.s64 = 39;
	// blr 
	return;
loc_82C96A68:
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,97
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 97, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,109
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 109, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r11,112
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 112, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// li r3,38
	ctx.r3.s64 = 38;
	// blr 
	return;
loc_82C96ABC:
	// lbz r11,2(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// cmplwi cr6,r11,116
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 116, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,103
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 103, ctx.xer);
	// beq cr6,0x82c96b00
	if (ctx.cr6.eq) goto loc_82C96B00;
	// cmpwi cr6,r11,108
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 108, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// li r3,60
	ctx.r3.s64 = 60;
	// blr 
	return;
loc_82C96B00:
	// li r3,62
	ctx.r3.s64 = 62;
	// blr 
	return;
loc_82C96B08:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96B10"))) PPC_WEAK_FUNC(sub_82C96B10);
PPC_FUNC_IMPL(__imp__sub_82C96B10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C96B24:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r9,r10,1
	ctx.r9.s64 = ctx.r10.s64 + 1;
	// extsb r8,r3
	ctx.r8.s64 = ctx.r3.s8;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne cr6,0x82c96b48
	if (!ctx.cr6.eq) goto loc_82C96B48;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96b50
	goto loc_82C96B50;
loc_82C96B48:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96B50;
	sub_82C8DAE8(ctx, base);
loc_82C96B50:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c96c8c
	if (ctx.cr6.gt) goto loc_82C96C8C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,27508
	ctx.r12.s64 = ctx.r12.s64 + 27508;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96C08;
	case 1:
		goto loc_82C96BF0;
	case 2:
		goto loc_82C96BD8;
	case 3:
		goto loc_82C96C8C;
	case 4:
		goto loc_82C96C8C;
	case 5:
		goto loc_82C96C8C;
	case 6:
		goto loc_82C96C8C;
	case 7:
		goto loc_82C96C8C;
	case 8:
		goto loc_82C96C8C;
	case 9:
		goto loc_82C96C8C;
	case 10:
		goto loc_82C96C8C;
	case 11:
		goto loc_82C96C8C;
	case 12:
		goto loc_82C96C8C;
	case 13:
		goto loc_82C96C8C;
	case 14:
		goto loc_82C96C8C;
	case 15:
		goto loc_82C96C8C;
	case 16:
		goto loc_82C96C8C;
	case 17:
		goto loc_82C96C4C;
	case 18:
		goto loc_82C96C4C;
	case 19:
		goto loc_82C96C4C;
	case 20:
		goto loc_82C96C4C;
	case 21:
		goto loc_82C96C4C;
	case 22:
		goto loc_82C96C4C;
	case 23:
		goto loc_82C96C8C;
	case 24:
		goto loc_82C96C4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,27656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27656);
	// lwz r22,27632(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27632);
	// lwz r22,27608(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27608);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
loc_82C96BD8:
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82c96c38
	if (!ctx.cr6.eq) goto loc_82C96C38;
loc_82C96BF0:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lbz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82c96c38
	if (!ctx.cr6.eq) goto loc_82C96C38;
loc_82C96C08:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
	// lbz r6,0(r5)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r9,r5,1
	ctx.r9.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r8,r6
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c96c38
	if (!ctx.cr6.eq) goto loc_82C96C38;
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// lbz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r5,r9,1
	ctx.r5.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r8,r6
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, ctx.xer);
	// beq cr6,0x82c96b24
	if (ctx.cr6.eq) goto loc_82C96B24;
loc_82C96C38:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96C4C:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r11,r5,1
	ctx.r11.s64 = ctx.r5.s64 + 1;
	// extsb r6,r10
	ctx.r6.s64 = ctx.r10.s8;
	// cmpw cr6,r6,r8
	ctx.cr6.compare<int32_t>(ctx.r6.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x82c96c38
	if (!ctx.cr6.eq) goto loc_82C96C38;
	// lbz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r10,r9,1
	ctx.r10.s64 = ctx.r9.s64 + 1;
	// lbz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r5,r11,1
	ctx.r5.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r6,r8
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x82c96b24
	if (ctx.cr6.eq) goto loc_82C96B24;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96C8C:
	// lbz r3,0(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96ca8
	if (!ctx.cr6.eq) goto loc_82C96CA8;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96cb0
	goto loc_82C96CB0;
loc_82C96CA8:
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96CB0;
	sub_82C8DAE8(ctx, base);
loc_82C96CB0:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c96d38
	if (ctx.cr6.gt) goto loc_82C96D38;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,27860
	ctx.r12.s64 = ctx.r12.s64 + 27860;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96C38;
	case 1:
		goto loc_82C96C38;
	case 2:
		goto loc_82C96C38;
	case 3:
		goto loc_82C96D38;
	case 4:
		goto loc_82C96D38;
	case 5:
		goto loc_82C96D38;
	case 6:
		goto loc_82C96D38;
	case 7:
		goto loc_82C96D38;
	case 8:
		goto loc_82C96D38;
	case 9:
		goto loc_82C96D38;
	case 10:
		goto loc_82C96D38;
	case 11:
		goto loc_82C96D38;
	case 12:
		goto loc_82C96D38;
	case 13:
		goto loc_82C96D38;
	case 14:
		goto loc_82C96D38;
	case 15:
		goto loc_82C96D38;
	case 16:
		goto loc_82C96D38;
	case 17:
		goto loc_82C96C38;
	case 18:
		goto loc_82C96C38;
	case 19:
		goto loc_82C96C38;
	case 20:
		goto loc_82C96C38;
	case 21:
		goto loc_82C96C38;
	case 22:
		goto loc_82C96C38;
	case 23:
		goto loc_82C96D38;
	case 24:
		goto loc_82C96C38;
	default:
		__builtin_unreachable();
	}
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
loc_82C96D38:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96D50"))) PPC_WEAK_FUNC(sub_82C96D50);
PPC_FUNC_IMPL(__imp__sub_82C96D50) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c96d9c
	if (ctx.cr6.eq) goto loc_82C96D9C;
loc_82C96D60:
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c96dac
	if (ctx.cr6.eq) goto loc_82C96DAC;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96dac
	if (!ctx.cr6.eq) goto loc_82C96DAC;
	// lbz r10,1(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82c96dac
	if (!ctx.cr6.eq) goto loc_82C96DAC;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// lbz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c96d60
	if (!ctx.cr6.eq) goto loc_82C96D60;
loc_82C96D9C:
	// subf r11,r4,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r3,r10,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// blr 
	return;
loc_82C96DAC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96DB8"))) PPC_WEAK_FUNC(sub_82C96DB8);
PPC_FUNC_IMPL(__imp__sub_82C96DB8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C96DD0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96dec
	if (!ctx.cr6.eq) goto loc_82C96DEC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96df4
	goto loc_82C96DF4;
loc_82C96DEC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96DF4;
	sub_82C8DAE8(ctx, base);
loc_82C96DF4:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c96e94
	if (ctx.cr6.gt) goto loc_82C96E94;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,28184
	ctx.r12.s64 = ctx.r12.s64 + 28184;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96E7C;
	case 1:
		goto loc_82C96E84;
	case 2:
		goto loc_82C96E8C;
	case 3:
		goto loc_82C96E94;
	case 4:
		goto loc_82C96E94;
	case 5:
		goto loc_82C96E94;
	case 6:
		goto loc_82C96E94;
	case 7:
		goto loc_82C96E94;
	case 8:
		goto loc_82C96E94;
	case 9:
		goto loc_82C96E94;
	case 10:
		goto loc_82C96E94;
	case 11:
		goto loc_82C96E94;
	case 12:
		goto loc_82C96E94;
	case 13:
		goto loc_82C96E94;
	case 14:
		goto loc_82C96E94;
	case 15:
		goto loc_82C96E94;
	case 16:
		goto loc_82C96E94;
	case 17:
		goto loc_82C96E7C;
	case 18:
		goto loc_82C96E7C;
	case 19:
		goto loc_82C96E7C;
	case 20:
		goto loc_82C96E7C;
	case 21:
		goto loc_82C96E7C;
	case 22:
		goto loc_82C96E7C;
	case 23:
		goto loc_82C96E94;
	case 24:
		goto loc_82C96E7C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28292(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28292);
	// lwz r22,28300(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28300);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
loc_82C96E7C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c96dd0
	goto loc_82C96DD0;
loc_82C96E84:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c96dd0
	goto loc_82C96DD0;
loc_82C96E8C:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c96dd0
	goto loc_82C96DD0;
loc_82C96E94:
	// subf r3,r8,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r8.s64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96EA8"))) PPC_WEAK_FUNC(sub_82C96EA8);
PPC_FUNC_IMPL(__imp__sub_82C96EA8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C96EBC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96ed8
	if (!ctx.cr6.eq) goto loc_82C96ED8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96ee0
	goto loc_82C96EE0;
loc_82C96ED8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96EE0;
	sub_82C8DAE8(ctx, base);
loc_82C96EE0:
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// blt cr6,0x82c96f00
	if (ctx.cr6.lt) goto loc_82C96F00;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// ble cr6,0x82c96ef8
	if (!ctx.cr6.gt) goto loc_82C96EF8;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// bne cr6,0x82c96f00
	if (!ctx.cr6.eq) goto loc_82C96F00;
loc_82C96EF8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c96ebc
	goto loc_82C96EBC;
loc_82C96F00:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96F18"))) PPC_WEAK_FUNC(sub_82C96F18);
PPC_FUNC_IMPL(__imp__sub_82C96F18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c96fd0
	if (ctx.cr6.eq) goto loc_82C96FD0;
	// li r9,-1
	ctx.r9.s64 = -1;
loc_82C96F38:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96f54
	if (!ctx.cr6.eq) goto loc_82C96F54;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96f5c
	goto loc_82C96F5C;
loc_82C96F54:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96F5C;
	sub_82C8DAE8(ctx, base);
loc_82C96F5C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// bgt cr6,0x82c96fb8
	if (ctx.cr6.gt) goto loc_82C96FB8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,28544
	ctx.r12.s64 = ctx.r12.s64 + 28544;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96FB8;
	case 1:
		goto loc_82C96F98;
	case 2:
		goto loc_82C96FA0;
	case 3:
		goto loc_82C96FB8;
	case 4:
		goto loc_82C96FE0;
	case 5:
		goto loc_82C96FA8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,28600(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28600);
	// lwz r22,28568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28568);
	// lwz r22,28576(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28576);
	// lwz r22,28600(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28600);
	// lwz r22,28640(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28640);
	// lwz r22,28584(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28584);
loc_82C96F98:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c96fbc
	goto loc_82C96FBC;
loc_82C96FA0:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c96fbc
	goto loc_82C96FBC;
loc_82C96FA8:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C96FB8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C96FBC:
	// lwz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r11.u32);
	// bne cr6,0x82c96f38
	if (!ctx.cr6.eq) goto loc_82C96F38;
loc_82C96FD0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96FE0:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// beq cr6,0x82c97028
	if (ctx.cr6.eq) goto loc_82C97028;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c97014
	if (!ctx.cr6.eq) goto loc_82C97014;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9701c
	goto loc_82C9701C;
loc_82C97014:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9701C;
	sub_82C8DAE8(ctx, base);
loc_82C9701C:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c97028
	if (!ctx.cr6.eq) goto loc_82C97028;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C97028:
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// b 0x82c96fbc
	goto loc_82C96FBC;
}

